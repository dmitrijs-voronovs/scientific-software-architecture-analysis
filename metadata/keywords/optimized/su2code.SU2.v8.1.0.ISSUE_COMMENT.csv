quality_attribute,sentence,source,author,repo,version,id,keyword,matched_word,match_idx,wiki,url,total_similar,target_keywords,target_matched_words
Availability," -c conftest.c -o conftest2.o >&5; configure:4427: $? = 0; configure:4445: result: yes; configure:4513: checking for ranlib; configure:4529: found /usr/bin/ranlib; configure:4540: result: ranlib; configure:4574: checking how to run the C preprocessor; configure:4605: gcc -E conftest.c; configure:4605: $? = 0; configure:4619: gcc -E conftest.c; conftest.c:11:28: error: ac_nonexistent.h: No such file or directory; configure:4619: $? = 1; configure: failed program was:; | /* confdefs.h */; | #define PACKAGE_NAME ""SU2""; | #define PACKAGE_TARNAME ""SU2""; | #define PACKAGE_VERSION ""4.1.0""; | #define PACKAGE_STRING ""SU2 4.1.0""; | #define PACKAGE_BUGREPORT ""su2code-dev@lists.stanford.edu""; | #define PACKAGE_URL ""https://github.com/su2code""; | #define PACKAGE ""SU2""; | #define VERSION ""4.1.0""; | /* end confdefs.h. */; | #include <ac_nonexistent.h>; configure:4644: result: gcc -E; configure:4664: gcc -E conftest.c; configure:4664: $? = 0; configure:4678: gcc -E conftest.c; conftest.c:11:28: error: ac_nonexistent.h: No such file or directory; configure:4678: $? = 1; configure: failed program was:; | /* confdefs.h */; | #define PACKAGE_NAME ""SU2""; | #define PACKAGE_TARNAME ""SU2""; | #define PACKAGE_VERSION ""4.1.0""; | #define PACKAGE_STRING ""SU2 4.1.0""; | #define PACKAGE_BUGREPORT ""su2code-dev@lists.stanford.edu""; | #define PACKAGE_URL ""https://github.com/su2code""; | #define PACKAGE ""SU2""; | #define VERSION ""4.1.0""; | /* end confdefs.h. */; | #include <ac_nonexistent.h>; configure:4707: checking for grep that handles long lines and -e; configure:4765: result: /bin/grep; configure:4770: checking for egrep; configure:4832: result: /bin/grep -E; configure:4837: checking for ANSI C header files; configure:4857: gcc -c -g -O2 conftest.c >&5; configure:4857: $? = 0; configure:4930: gcc -o conftest -g -O2 conftest.c >&5; configure:4930: $? = 0; configure:4930: ./conftest; configure:4930: $? = 0; configure:4941: result: yes; configure:4954: checking for sys/types.h; configure:4954: gcc -c -",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:8730,error,error,8730,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,1,['error'],['error']
Availability," >; > My research group at UT Austing has implemented a unit testing framework; > on our branch, which we're happy with. Some choices were arbitrary, and; > some choices were made based on our development environment. Those choices; > may be different for other groups. Here's what we have done:; >; > The unit testing framework is compiled and run using autotools. For more; > information on autotool's setup, see their documentation; > <https://www.gnu.org/software/automake/manual/html_node/Tests.html>.; > Since autotools is the build system for SU2, this involves minimal changes.; >; > Using automake, the build process for building unit tests becomes:; >; > '''; > ./bootstrap; > ./configure; > make; > make check; > '''; >; > We use Boost's unit testing framework; > <https://www.boost.org/doc/libs/1_70_0/libs/test/doc/html/index.html>.; > This provides a convenient set of macros for instatiating tests, grouping; > tests into suites, and running checks. This choice was based on what is; > available in our development setup.; >; > We have integrated our unit tests into our Travis CI regression testing.; > Every time we push commits or submit a pull request, the unit tests are run; > and checked.; > What is my vision for unit testing in SU2?; >; > I am *not* proposing that we start trying to get 100% code coverage with; > pre-existing code. That would not provide a good return on investment.; >; > Instead, I see people adding unit tests as they write new code and as they; > find bugs. For each new behavior added to SU2, tests are first added to; > document the related existing behavior. These tests serve to check that the; > existing behavior isn't damaged by the new code. Then new tests are added; > to prove that the new behavior is working correctly. For bug fixes, the; > process is simpler. A test is added to confirm that something is not; > behaving as expected. Then the code is fixed to make the test pass.; > What frameworks are available?; >; > For a unit testing f",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499278427:4488,avail,available,4488,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427,1,['avail'],['available']
Availability," Clark Pederson <notifications@github.com>; > wrote:; >; > I propose adding a unit-testing framework and unit-tests to SU2. After; > chatting with @economon <https://github.com/economon>, I've decided to; > move the discussion here to get additional input.; > What is unit testing?; >; > For those not familiar with unit testing, unit testing allows the testing; > of small bits of behavior, ideally using isolated bits of code. It is not; > intended to replace validation testing or formal verification tests.; > Instead, it serves a unique purpose. Consider the three following use cases:; >; > - You're developing a new feature, and you want to test it to see if; > it works. You could do a full simulation, but that takes a lot of time and; > computing power. You want to check if your new behavior behaves as you; > suspect before you throw a lot of resources at it.; > - You submit a PR and discover that one of the regression tests has; > failed. But...why? You know that something is broken, but its hard to track; > down what broke. You want more granular test coverage that can demonstrate; > what broke.; > - You are fixing a very small bug. You know that you should prove that; > your bug fix worked, but it doesn't seem logical to dedicate an entire; > validation case to one small bug fix. You want to write a small test for a; > small fix.; >; > In all of these cases, unit testing fills a unique role. Unit testing; > increases time spent in development, but decreases the amount of time spent; > in bug-fixing and maintaining.; >; > For more information, see this relevant Stack Exchange question.; > <https://scicomp.stackexchange.com/questions/206/is-it-worthwhile-to-write-unit-tests-for-scientific-research-codes>; > What do I propose?; >; > My research group at UT Austing has implemented a unit testing framework; > on our branch, which we're happy with. Some choices were arbitrary, and; > some choices were made based on our development environment. Those choices; > may be di",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499278427:2755,down,down,2755,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427,1,['down'],['down']
Availability," scheme for a multi-physics problem. To obtain the design accuracy in time, this implies that the loop over the number of time stages is outside the loop over the number of physical disciplines. Hence at a very high level in the hierarchy, the details of the time integration should then be known. The situation becomes even more complicated when one would like to employ time integration schemes that allow for time accurate local time stepping, e.g. the ones we are currently working on for the DG solver. I won't bore you with all the details here, but those schemes basically require the loop over the multiple disciplines to be between the predictor and corrector step, while both these steps consist of multiple stages. Although it is probably possible to come up with a data structure that supports all this, the question is whether this is desirable. Apart from the fact that it would require a major overhaul in the high level design of SU2, the implementation will be less readable, especially for people that will be starting with the code. Also the parallelization may become significantly more complicated. The alternative is that for unsteady multi-physics problems, we put the restriction that only single stage time integration schemes can be used, e.g. DT_STEPPING_1ST and DT_STEPPING_2ND. In that case, the details of the time integration scheme can be hidden at the driver level, where we then simply have a loop over the number of physical disciplines. The consequence of course is that more advanced time integration schemes will not be available for multi-physics problems. In the above I just tried to picture what, in my opinion, the consequences are for either option. I don't have a preference for one of them. The only thing I wanted to make clear is that it is not possible to hide all the details of the time integration scheme at the driver level, while also having support for all possible time integration schemes for an unsteady multi-physics problem. Regards,. Edwin",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/437#issuecomment-328441926:1925,avail,available,1925,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328441926,1,['avail'],['available']
Availability," the solution at the inlet corner is completely wrong, while the outlet is ok most likely because characteristics are outgoing as it is supersonic. The artifacts disappear if we disable MUSCL everywhere (1st order solution) or disable it only on boundaries (not ideal solution, but disabling only on corners would still be good enough for now I believe). Using ```WEIGHTED_LEAST_SQUARES``` seems to not present the same issue, in this test case at least, as the stencil ""does not care"" about the boundary states. The boundary conditions are:; - ```MARKER_SYMMETRY``` at centerline; - ```MARKER_EULER``` at wall; - ```MARKER_RIEMANN= (INLET, TOTAL_CONDITIONS_PT, 904388, 542.13, 1.0, 0.0, 0.0)``` at inlet; - ```MARKER_RIEMANN= (OUTLET, STATIC_PRESSURE, 200000.0, 0.0, 0.0, 0.0, 0.0)``` at outlet. I tried both with and without a slope limiter as there are no discontinuities, but it makes no difference on the artifacts:. ```; SLOPE_LIMITER_FLOW= VENKATAKRISHNAN_WANG; VENKAT_LIMITER_COEFF= 0.1; ```. # Complete test case ZIP; [mdm_coolprop_nozzle.zip](https://github.com/su2code/SU2/files/15403732/mdm_coolprop_nozzle.zip). # Inlet pressure zoom; ![Screenshot from 2024-05-22 15-06-36](https://github.com/su2code/SU2/assets/79575547/9ba71127-cb12-4c5f-8e49-3ea9e839b1f4). # Notation: ; - ""1st order"" no MUSCL; - ""2nd order"" MUSCL as implemented in SU2; - ""2nd order (BC 1st order)"" I simply disabled MUSCL on ALL physical boundaries in the upwind residual computations, see code snippet below. # Proof of concept code modification for ""2nd order (BC 1st order)"":; To show that the error lies in MUSCL/gradients at boundaries I added these two lines of code in the upwind gradient computation; ![image](https://github.com/su2code/SU2/assets/79575547/27f2a79b-824d-4a32-a626-73cd87750c0c). # Residuals:; ![image](https://github.com/su2code/SU2/assets/79575547/3f0800fe-478e-433d-8495-cd4964d0f8ee). # Mesh:; ![image](https://github.com/su2code/SU2/assets/79575547/0ebaf86b-fbf9-40b1-aeb9-8764a90a1440)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/2285#issuecomment-2124781449:1890,error,error,1890,https://su2code.github.io,https://github.com/su2code/SU2/issues/2285#issuecomment-2124781449,1,['error'],['error']
Availability," to SU2 in one of our branches. >@pcarruscag; >(...) being able to use PETSc or HYPRE would be interesting as it would give us access to AMG, and @talbring 's branch feature_template_linear_solver would make such an integration compatible with AD. (...). >@EduardoMolina; >(...) When Brian (@bmunguia ) and I mentioned PETSc, it was an idea to try a different Newton-Krylov (with preconditioner) library in order to improve the convergence of SU2.; Since the slow convergence of the SU2-FV is the main feedback that I received from other users from industry and academia, I think it worth try an external library and evaluate the performance. (...). >@pcarruscag ; >(...) That is something I am also interested in as for some of my structural cases the current linear solvers simply do not converge. (...). >@economon ; >I would add one practical comment for consideration: it is worth checking whether the main restriction we have is related to approximations in the Jacobian that limit the effective CFL we can use or whether the convergence of the linear solver itself is a problem (speed or complete lack of convergence). A quick test without resorting to another library is to increase the fill-in for ILU-preconditioned GMRES, which is very expensive/slow but should converge difficult problems, and to check how high we can take the CFL when allowing each nonlinear iteration to converge to a tight tolerance in the linear solver, say 1e-14 (you can output the linear solver residuals to verify convergence). If we can take the CFL higher with a more performant linear solver, then it could be worth the effort to try other options.; >If the CFL must remain low for stability, then perhaps we should look at the quality of the Jacobians we construct to see if we can improve, or even try exact Jacobians with AD if we can afford it. A more advanced CFL ramping strategy could also be helpful here to get us closer to a solution before trying to aggressively converge. I think that is everyone.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/648#issuecomment-460853218:3725,toler,tolerance,3725,https://su2code.github.io,https://github.com/su2code/SU2/issues/648#issuecomment-460853218,1,['toler'],['tolerance']
Availability," would likely perform better as it avoids the pesky gather/scatter operations.; Processing multiple geometric primitives can make full utilization of whatever register size (important on GPU's), the code is just as readable (as I hope to show), but gather/scatter cannot be avoided. ### Intro to SPMD; This one is simpler, in a nutshell multiple threads operate on the sub domain of an MPI rank.; The typical implementation has each thread executing a chunk of an edge or cell loop. **Why should we care about SPMD?**; Reduce the communication overhead resulting from domain decomposition and improve load balancing, important for strong scaling.; Some algorithms are more efficient that way, e.g. the ADT (as mentioned by Edwin), the current MG also seems to work better on fewer partitions, and additive versions of preconditioners like the ILU or LU-SGS lose effectiveness with number of partitions.; Optimum hardware utilization, for routines that are bandwidth-bound it may be beneficial to use all threads available, while for compute-bound or ""algorithm-bound"" ones this may not be the case. **Relation with algorithms**; A typical edge loop reads from 2 locations and writes to 2 locations (gather / scatter access pattern, not to be confused with the instructions) processing multiple edges at the same time can therefore result in race conditions where multiple threads try to update the data of the same point.; There are 3 ways to address this:; - **Coloring**: Edges are colored (grouped) such that edges of the same color have no risk of race conditions, i.e. each endpoint is referenced only once per color (this definition gives you the basis of a greedy algorithm to color edges).; - **Scatter to gather transformations**: Edge quantities (e.g. fluxes) are computed and stored on one pass (i.e. we read from 2 locations and write to 1), on a second pass, over points, we reduce (e.g. sum) the edge quantities for each point, again a gather access pattern. It may also be possible to ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-529662724:3586,avail,available,3586,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-529662724,1,['avail'],['available']
Availability,"### Intro to SIMD; The ALU of modern CPU are capable of processing multiple elements of built-in types simultaneously by applying one instruction (e.g. add) to a register of those elements. Registers are at the very top of the memory hierarchy, for any computation to be performed data needs to be in registers.; An AVX register is 256 bits wide, that means 4 lanes of doubles or 8 of floats, AVX-512 (available in Xeon-Phi and SkylakeX processors) doubles the size. By GPU standards these are rookie numbers. **Why should we care about SIMD?**; Because it is the only way to use the whole silicon, by and large vector instructions have the same latency and throughput of their scalar versions, therefore speedups proportional to the number of SIMD lanes are possible in compute-bound code.; As we saw in #716 there is some of that in the numerics, do not expect 4x speed-ups though, low order unstructured FVM is known to be bandwidth-bound, vectorization helps a bit there too (instructions are also data that needs to travel to the CPU) (maybe for explicit schemes and 8 SIMD lanes, maybe). **Relation with data structures**; There is only one efficient way to move data between memory and registers, via `load` and `store` instructions (they do come in multiple flavors). That is, pointing to a memory location and reading or writing N elements of contiguous data.; It is not the only way, it is also possible to `gather` and `scatter` data. That is populating the register from non-contiguous locations and vice versa. This is about one order of magnitude slower, to the point where if the computations are very simple it may not pay-off to vectorize. **Relation with algorithms**; Some form of `gather` and `scatter` is required in unstructured CFD, which means SIMD has a price of admission. Some thought needs to go into designing algorithms that amortize that cost by maximizing the so called FLOP/Byte ratio, and mask the latency of those operations by being able to start computing as soon ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-529662724:402,avail,available,402,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-529662724,1,['avail'],['available']
Availability,");; }; }. for(size_t iVar=0; iVar<nVar; ++iVar); {; FltVec lim = vmin(FltVec(2.0), vmin(; (phiMax[iVar]-phi.getVec(iPoint,iVar))/prjMax[iVar],; (phiMin[iVar]-phi.getVec(iPoint,iVar))/prjMin[iVar]));. limiter.setVec(iPoint,iVar, lim*(lim+2.0)/(lim*lim+lim+2.0));; }; }; }; ```; In terms of algorithm, for each point we find the min and max neighbor values and the min (negative) and max (positive) projections, those are then combined in a final `min(2, max/max, min/min)` to which the limiter function is applied (this would also be applicable to Venkatakrishnan-[Wang] limiters).; This is equivalent to the edge-loop, if statements are not required as due to cells being closed, if the positive projection is not zero, the negative one will also not be zero, therefore it is correct to always evaluate both ratios.; This algorithm only needs min and max neighbors as small local variables instead of large global ones due to the way those values are determined. This is where the memory from the extra adjacency information is recovered. Like @economon said, fusing the gradient kernel with the limiter kernel is trivial with these point loops, and I do not think it affects readability much since one can clearly tell ""what is what"" (I will not put it here but it really is a matter of copy paste), including the boundaries could be a bit more challenging, but I will give performance number nevertheless. **Performance summary**. | Code | Edge | Edge, SIMD on vars | Point | Point, SIMD on points |; | ---- | ---- | ---- | ---- | ---- |; | **Speed 1 core** | 1.0 | 1.75 | 1.25 | 2.0 |; | **Speed 4 cores** | 2.45 | 2.7 | 4.5 | 7.0 |. The basic point version does not lose to edge based because, contrary to gradients, it does not require duplication of computations while benefiting from sequential access to gradients.; Again the point-based implementation does really well in parallel, limiters are more compute intensive and so the scaling is almost perfect.; For reference, limiters are 1.9 ti",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-530593912:9835,recover,recovered,9835,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530593912,1,['recover'],['recovered']
Availability,", 2019, at 2:14 PM, Clark Pederson <notifications@github.com<mailto:notifications@github.com>> wrote:. I propose adding a unit-testing framework and unit-tests to SU2. After chatting with @economon<https://github.com/economon>, I've decided to move the discussion here to get additional input. What is unit testing?. For those not familiar with unit testing, unit testing allows the testing of small bits of behavior, ideally using isolated bits of code. It is not intended to replace validation testing or formal verification tests. Instead, it serves a unique purpose. Consider the three following use cases:. * You're developing a new feature, and you want to test it to see if it works. You could do a full simulation, but that takes a lot of time and computing power. You want to check if your new behavior behaves as you suspect before you throw a lot of resources at it.; * You submit a PR and discover that one of the regression tests has failed. But...why? You know that something is broken, but its hard to track down what broke. You want more granular test coverage that can demonstrate what broke.; * You are fixing a very small bug. You know that you should prove that your bug fix worked, but it doesn't seem logical to dedicate an entire validation case to one small bug fix. You want to write a small test for a small fix. In all of these cases, unit testing fills a unique role. Unit testing increases time spent in development, but decreases the amount of time spent in bug-fixing and maintaining. For more information, see this relevant Stack Exchange question.<https://scicomp.stackexchange.com/questions/206/is-it-worthwhile-to-write-unit-tests-for-scientific-research-codes>. What do I propose?. My research group at UT Austing has implemented a unit testing framework on our branch, which we're happy with. Some choices were arbitrary, and some choices were made based on our development environment. Those choices may be different for other groups. Here's what we have done:. ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499250240:1717,down,down,1717,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240,1,['down'],['down']
Availability,"-------------------- Surface grid deformation ----------------------; Performing the deformation of the surface grid. ----------------------- Volumetric grid deformation ---------------------; Performing the deformation of the volumetric grid. # FGMRES residual history. # Residual tolerance target = 4.14044e-11. # Initial residual norm = 15.8102. ```; 0 1; 50 2.17385e-06; 100 1.08998e-10; ```. # FGMRES final (true) residual:. # Iteration = 105: |res|/|res0| = 3.50764e-11. Non-linear iter.: 1/1. Linear iter.: 105. Min. area: 4.1019e-08. Error: 5.54565e-10. ----------------------- Write deformed grid files -----------------------; Merging grid connectivity.; Merging grid coordinates.; Writing volume mesh file.; Writing surface mesh file.; Writing .su2 file.; Adding any FFD information to the SU2 file. Completed in 1.039217 seconds on 1 core. ------------------------- Exit Success (SU2_DEF) ------------------------. [image]https://cloud.githubusercontent.com/assets/5167760/9294056/7be9439a-440f-11e5-862f-742246ef1565.png; SU2_DEF: output when deforming with all markers included:. ------------------------- Surface grid deformation ----------------------; Performing the deformation of the surface grid.; No surface deformation (scaling, rotation, or translation). ----------------------- Volumetric grid deformation ---------------------; Performing a translation of the volumetric grid.; Translational displacement: (1, 0, 0). ----------------------- Write deformed grid files -----------------------; Merging grid connectivity.; Merging grid coordinates.; Writing volume mesh file.; Writing surface mesh file.; Writing .su2 file.; Adding any FFD information to the SU2 file. Completed in 0.716938 seconds on 1 core. as far as I can tell the regression test failure is the same as for the current develop branch; I'll update this pull request whenever that is resolved. —; Reply to this email directly or view it on GitHubhttps://github.com/su2code/SU2/pull/187#issuecomment-131578218.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/187#issuecomment-132065067:3277,failure,failure,3277,https://su2code.github.io,https://github.com/su2code/SU2/pull/187#issuecomment-132065067,1,['failure'],['failure']
Availability,".py script. The command used was:. ```; python3 $SU2_RUN/mesh_adaptation_amg.py -f adapt_Mesh.cfg -n 4; ```; The script initiates the mesh adaptation process as expected, with the following output:. ```; SU2-AMG Anisotropic Mesh Adaptation. Mesh adaptation options:; PYADAP_COMPLEXITY : (30000, 60000, 120000); PYADAP_SUBITE : (2, 2, 2); PYADAP_SENSOR : GOAL; PYADAP_HMAX : 500.0; PYADAP_HMIN : 1e-9; PYADAP_HGRAD : 1.8. ./adap exists. Removing old mesh adaptation in 10s.; The ./adap folder was deleted. Generating GMF background surface mesh.; Initial CFD solution is provided.; ```; However, no _adap\ite0_ folder gets created. ; The log.err file in the _adap/ini_ directory provides this traceback:. ```; Traceback (most recent call last):; File "".../mesh_adaptation_amg.py"", line 111, in <module>; ...; RuntimeError: ...; Error in TokenizeString(): two or more options before an ""="" sign in the configuration file.; terminate called after throwing an instance of 'int'; ...; *** Process received signal ***; Signal: Aborted (6); Signal code: (-6); ...; ```. The critical part of this error seems to be the Error in TokenizeString() message, suggesting an issue with parsing the configuration file. This error typically indicates a syntax problem, such as having multiple options on a single line without proper separation by an equal sign (=). However, upon reviewing _adap/ini/config_CFD.cfg_, was unable to find any lines that clearly violated this syntax rule. Could this error be indicative of a more subtle issue within the configuration file, or might it be related to specific aspects of the feature_adap branch? Any insights, suggestions, or guidance on how to troubleshoot this error would be greatly appreciated. If anyone has a working adapt_mesh.cfg file for a similar setup or for the feature_adap branch, I would be very interested in seeing it. Understanding the configuration details of a working example could be highly beneficial in resolving my issue. Thank you for your help!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/948#issuecomment-1847333809:1426,error,error,1426,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-1847333809,4,['error'],['error']
Availability,"2357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; 14368 Vertex ; 3 Boundary Vertices ; 58189 Tetrahedra ; 1 Triangles ; 0 Edges ; 1 Surface(s) ; % Output subdom.meshb Mesh ndimn=3, mpoin=14368, melem=58189, mface=1; Corners 0 Required 0 ; ## ERROR : TETRAHEDRON 2 BOUNDARY FACE 1 2; 9 IS MISSING ; ## ERROR : TETRAHEDRON 4 BOUNDARY FACE 3 7; 2324 IS MISSING ; ···; ## ERROR: FEFLO.A: 16740 BOUNDARY FACES ARE MISSING ; CHECK YOUR MESH . ## FATAL ERROR: FEFLOA: INITIAL OR CURRENT MESH HAS AN INCONSISTANT TOPOLOGY . Thank you for using feflo.a . ```; Which in turn creates an invalid `amg.su2` mesh in the `adap/ite0 folder`, which triggers the fault.; I'm a bit puzzled as the domain is very simple, and the `log.out` is going well (with no complains of SU2 about any negative volume or trias with wrong normals). The mesh is only made of TRIAS and TETRAS, it should work in principle.; Am I missing something in the setup / mesh? I know you have little control on the `amg.out`, but maybe there some special hint that I'm missing. . Btw the final error in the terminal is but I think the problem arises before reaching `flo.csv` file:; ```; Traceback (most recent call last):; File ""/usr/local/bin/mesh_adaptation_amg.py"", line 111, in <module>; main(); File ""/usr/local/bin/mesh_adaptation_amg.py"", line 72, in main; options.save_all ); File ""/usr/local/bin/mesh_adaptation_amg.py"", line 101, in mesh_adaptation_amg; SU2.run.amg(config); File ""/usr/local/bin/SU2/run/amg.py"", line 464, in amg; os.rename(cur_solfil, cur_solfil_ini); FileNotFoundError: [Errno 2] No such file or directory: 'flo.csv' -> 'flo_ini.csv'. ```; Thanks!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/948#issuecomment-623572280:2556,error,error,2556,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-623572280,1,['error'],['error']
Availability,"; configure:5041: ./conftest; configure:5041: $? = 0; configure:5055: result: 4; configure:5069: checking size of long int; configure:5074: gcc -o conftest -g -O2 conftest.c >&5; configure:5074: $? = 0; configure:5074: ./conftest; configure:5074: $? = 0; configure:5088: result: 8; configure:5102: checking size of float; configure:5107: gcc -o conftest -g -O2 conftest.c >&5; configure:5107: $? = 0; configure:5107: ./conftest; configure:5107: $? = 0; configure:5121: result: 4; configure:5135: checking size of double; configure:5140: gcc -o conftest -g -O2 conftest.c >&5; configure:5140: $? = 0; configure:5140: ./conftest; configure:5140: $? = 0; configure:5154: result: 8; configure:5168: checking size of void *; configure:5173: gcc -o conftest -g -O2 conftest.c >&5; configure:5173: $? = 0; configure:5173: ./conftest; configure:5173: $? = 0; configure:5187: result: 8; configure:5409: checking X11/Intrinsic.h usability; configure:5409: gcc -c -g -O2 conftest.c >&5; conftest.c:61:27: error: X11/Intrinsic.h: No such file or directory; configure:5409: $? = 1; configure: failed program was:; | /* confdefs.h */; | #define PACKAGE_NAME ""SU2""; | #define PACKAGE_TARNAME ""SU2""; | #define PACKAGE_VERSION ""4.1.0""; | #define PACKAGE_STRING ""SU2 4.1.0""; | #define PACKAGE_BUGREPORT ""su2code-dev@lists.stanford.edu""; | #define PACKAGE_URL ""https://github.com/su2code""; | #define PACKAGE ""SU2""; | #define VERSION ""4.1.0""; | #define STDC_HEADERS 1; | #define HAVE_SYS_TYPES_H 1; | #define HAVE_SYS_STAT_H 1; | #define HAVE_STDLIB_H 1; | #define HAVE_STRING_H 1; | #define HAVE_MEMORY_H 1; | #define HAVE_STRINGS_H 1; | #define HAVE_INTTYPES_H 1; | #define HAVE_STDINT_H 1; | #define HAVE_UNISTD_H 1; | #define SIZEOF_SHORT_INT 2; | #define SIZEOF_INT 4; | #define SIZEOF_UNSIGNED_INT 4; | #define SIZEOF_LONG_INT 8; | #define SIZEOF_FLOAT 4; | #define SIZEOF_DOUBLE 8; | #define SIZEOF_VOID_P 8; | /* end confdefs.h. */; | #include <stdio.h>; | #ifdef HAVE_SYS_TYPES_H; | # include <sys/types.h>; | #",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:12437,error,error,12437,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,1,['error'],['error']
Availability,";. #pragma omp simd; for(size_t k=0; k<blkSz; ++k); {; coeffs[bii+k] += blk_i[k]; coeffs[bij+k] = +blk_j[k];; coeffs[bji+k] = -blk_i[k]; coeffs[bjj+k] -= blk_j[k];; }; }; ```; This is **47% faster**, which for a memory bound task is massive!; Yes, this does increase the memory footprint a bit (makes CSysMatrix 4% larger for a 3D problem) but I can get that back by sharing sparsity patterns and maps across turbulence and bulk flow (I think @talbring was already working on this in the template linear solver branch he had started). We could also parallelize the matrix updates without colouring by setting only the off-diagonal coefficients and then setting the diagonal entries to the column sum.; It turns out that this is worse (by about 10%), maybe if the matrix were symmetric (row sum) but a column sum accesses blocks very far apart. Also we want to interleave compute and load/stores as much as possible to allow the CPU pipelining magic to mask the latency of the latter (even if it looks like you can only write the block after it is computed, CPU's have all kinds of buffers that allow the next loop iteration to begin while data is in flight). **Therefore colouring is the way to go.**. _Note: With vectorized numerics we insert blocks for 4 or 8 edges into the matrix at a time, the data for those inserts will be in a slightly weird format, which will make `SparseMatrix::updateBlocks` a bit harder on the eye, more on that later._. ## MUSCL Reconstruction; The MUSCL reconstruction, characteristic of upwind schemes, is the simplest building block to show the (negative) implications of storing the data as structures of arrays (SoA) on the performance of some operations.; Here is the most basic numerics you can think of, reconstruct and average (the dummy matrix loop was to benchmark the writes this is to benchmark the reads); ```c++; void computeResidual(size_t nVar,; size_t nDim,; const vector<size_t>& colorStart,; const vector<size_t>& edgeIdx,; const vector<pair<size_t,si",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-535977206:5090,mask,mask,5090,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206,1,['mask'],['mask']
Availability,"> ; > ; > Dear Daumantas,; > ; > I appreciate your effort in adding support for cmake in SU2. We have recently introduced the Meson build system (https://mesonbuild.com/) (#685, #745) as a candidate to replace automake. A guide on how to use can be found [here](https://su2code.github.io/docs_v7/Build-SU2-From-Source/). The idea is that we will have this system along automake at least for the upcoming version 7 and that we get rid of automake afterwards. Considering that, I don't think that it makes sense to maintain 3 different build systems **at the moment**. I really hate turning contributions down, but this one is three months too late. However, we might reconsider adding support for another build system once we got rid of automake, or, if we feel that meson does not fit our needs.; > ; > I am all ears to hear other opinions. However, let's not start a discussion on the advantages/disadvantages of the build systems. Some benefits can be found in the Issue/PR linked above. Ok, I tried meson with MinGW but couldn't figure out how to link with MSMPI since it's not a part of MinGW. However, using CMake and with a few source code fixes, I managed to compile nearly every configuration with MSVC. Surprisingly, there were very few errors in SU2. The externals only had a few preprocessor issues. At the moment only MeDiPack fails to compile with MSVC but not with MinGW even though the MPI headers are the same so I suspect it's an issue with MSVC itself, I'm using the latest preview version.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/814#issuecomment-553571450:603,down,down,603,https://su2code.github.io,https://github.com/su2code/SU2/pull/814#issuecomment-553571450,2,"['down', 'error']","['down', 'errors']"
Availability,"> > I find your work really interesting. I've been studying the internal flow field in compressors and have had good results using SU2's SA_EDDES for calculating the cantilevered stator with a tip clearance. If you need help with code verification, I'd be glad to assist.; > ; > Hi @Linnnnnn23, every help on the validation/verification is gladly accepted! Let me know if you need anything by my side.; Thank you for your response. Firstly, I would like to know what Verification and Validation (V&V) work has been conducted on the SST-based DDES (Delayed Detached Eddy Simulation) model to date. Secondly, we can provide a compressor cascade validation, with an inlet Mach number of 0.4, a Reynolds number of approximately 500,000, and a spanwise height of about 20% of the chord length, ensuring that the vortices resolved by DDES can develop in three dimensions. Thirdly, as I am a rookie to GitHub, I have not yet found out how to download your pull request code. For further communication, you can contact me via email at linnnnnn2308@gmail.com",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/2150#issuecomment-2072057976:935,down,download,935,https://su2code.github.io,https://github.com/su2code/SU2/pull/2150#issuecomment-2072057976,1,['down'],['download']
Availability,"> @kursatyurt Hello, thank you so much for the lead.; > ; > Our initial scope mostly involved writing our own kernels and I did explore some libraries at the start - I was planning on using CUSP as well but my main concern was its lack of being updated to the newly compatible versions of the toolkit. cuSolver and cuBLAS do exist, but I chose to go ahead with a ""simple"" kernel implementation to have more control. I also felt that if I could keep the block size of the grid in optimal territory then they could be just as fast as those options (please do correct me if my reading of the literature or the situation was incorrect). To learn the basics, it's a good idea, but for large-scale projects, I prefer using existing libraries if possible.; Those libraries generally exploit state-of-the-art solution like mixed-precision computing. A gaming GPU is not way faster than a good CPU in double precision, but way faster in single precision, most of them have 64:1 ratio, however server class GPU have 2:1 ratio. Also when available they use vendor libraries like cuBLAS or hipBLAS. It is always nice to have you only care about connection and somebody else handle the solver as performant as possible. In future probably they will provide more and more solvers and it will be automagically works. It is kind of light-weight too, not a huge dependency like Trilinos or PETSc. ; > ; > I was not aware of Ginkgo and I will surely give it a go and try to produce some comparative results. I am currently super busy for this month and will get to working on the code with some delay.; > ; > Again, thank you for the lead!. I can test on various GPUs (P100/V100/A100 and 4070Mobile) on single node multi-gpu etc.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/2346#issuecomment-2397803409:1027,avail,available,1027,https://su2code.github.io,https://github.com/su2code/SU2/pull/2346#issuecomment-2397803409,1,['avail'],['available']
Availability,"> Aside from my last two comments, and the possibility I broke the code :), this looks ready. Is this missing anything, or is it ready to merge?. Thank you so much @pcarruscag for your feedback. there is one thing left, it is about the residuals of the test case (species2_primitiveVenturi_mixingmodel.cfg) that I added in the previous pull request, they have changed exceeding in some outputs the tolerance 0.00001 with respect to the values stored in the parallel_regression.py, however the test case converges very well, so could it be possible to modify the values stored in that test case in order to not have this discrepancy between values stored and computed? Thank you so much in advance!!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1690#issuecomment-1194029520:398,toler,tolerance,398,https://su2code.github.io,https://github.com/su2code/SU2/pull/1690#issuecomment-1194029520,1,['toler'],['tolerance']
Availability,"> Do I understand correctly that two gradients are always computed per iteration?; > Is there any downside to using the unweighted LS for viscous flux correction? Is the statement that this type of gradient is better for reconstruction based on your observations or is it one of those well known things?. Yes - the gradient for now is computed twice and stored separately for viscous flows with 2nd-order upwind. Could be combined into one loop eventually. It is known that weighted LSQ / GG is more accurate (see Mavriplis, ""Revisiting the Least-Squares Procedure for Gradient Reconstruction on Unstructured Meshes"" for instance). However, unweighted LSQ is known to be more robust.. so a good compromise is to use it only for the reconstruction step (which is more susceptible to robustness issues than the viscous term) and then use WLSQ or GG for all other gradients in the viscous flux/sources for accuracy. > Sometimes high CFL leads to limit-cycle oscillations of the residuals and the solution is to reduce it, is this something this controller can pick up?; > High CFL also makes the linear systems harder to solve and as Edwin pointed out _somewhere_ there is not much point going above reasonable values with weakly coupled turbulence. Do you think it would be reasonable to build in some feedback from the linear solver (e.g. it is taking too much time or did not converge -> drop the CFL)?. Yes, I would also like to couple it to the linear solver so that we can remove the need to tune that as well. Ideally the user will not need to adjust parameters. There are some things I am going to try for that..",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/790#issuecomment-531890295:98,down,downside,98,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-531890295,3,"['down', 'robust']","['downside', 'robust', 'robustness']"
Availability,"> Every time we push commits or submit a pull request, the unit tests are run; > and checked.; > What is my vision for unit testing in SU2?; >; > I am *not* proposing that we start trying to get 100% code coverage with; > pre-existing code. That would not provide a good return on investment.; >; > Instead, I see people adding unit tests as they write new code and as they; > find bugs. For each new behavior added to SU2, tests are first added to; > document the related existing behavior. These tests serve to check that the; > existing behavior isn't damaged by the new code. Then new tests are added; > to prove that the new behavior is working correctly. For bug fixes, the; > process is simpler. A test is added to confirm that something is not; > behaving as expected. Then the code is fixed to make the test pass.; > What frameworks are available?; >; > For a unit testing framework, here are the most popular options, with the; > following pros and cons:; > Roll-your-own; >; > - Requires no external dependencies; > - The most flexible option; > - Involves the most work to setup; > - Will lack some of the more advances features of mature unit-testing; > frameworks.; >; > Boost Test; >; > - Can be header only, statically linked, or dynamically linked; > - If statically or dynamically linked, then Boost is not very; > lightweight; > - Easy to add if you're already using Boost; >; > Google Test; >; > - Most common unit-testing framework; > - Can be easily combined with Google's powerful GMock mocking library; > - Compiling and linking can be somewhat painful; >; > Catch2; >; > - Used by FEniCS; > - Makes unit tests easily readable with lots of syntactic sugar.; > - Has a very simple syntax; > - Is header-only; > - Requires C++11 compilation; > - Not as feature rich as Google Test or Boost Test; >; > Questions; >; > - How do developers feel about adding unit tests to SU2?; > - If a unit-testing framework were added to SU2, would you actually; > use it?; > - Do developers hav",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499278427:5450,avail,available,5450,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427,1,['avail'],['available']
Availability,"> I don't known how the process to find the alpha that gives you a given CL works, but could the derivative not be obtained from this process? i.e. you could avoid the FD step entirely. It is a simple proportional controller that will change the angle of attack after a number of iterations depending on the difference between the current CL and the target CL. . So if the the option `ITER_DCL_DALPHA = 0` then it will do exactly what you suggest. It calculates the derivative based on the last update. The only problem with that is, there is no guarantee that the simulation at the previous update was converged, so the derivative might be incorrect. . But you are correct, I could just do a really tiny update (order of delta AoA ~10^-6) at the end and calculate the finite difference using that value. Let me try that and see if the gradients it calculates are reasonable, or if the update is too small and it gets clouded by numerical errors.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/780#issuecomment-539606698:939,error,errors,939,https://su2code.github.io,https://github.com/su2code/SU2/pull/780#issuecomment-539606698,1,['error'],['errors']
Availability,"> Nice! By the way, did you use some scripts for going through all the files and returning 'bad' naming conventions?. No, now I am just going through it by hand probably some linters are available to at least detect them. Actually, I am a bit confused as it is not so clear in the guide. It looks like the beginning of the project was just abbreviated from the Google style guide and was not enforced. Enforcing function names in UpperCamelCase and leaving variable names to the developer seems reasonable. > Can you explain the snake/camel terminology? :). Let's say we have a variable we want to name as `number of nodes per mesh` there are 2 common choices as . ```cpp; number_of_nodes_per_mesh = 42;; numberOfNodesPerMesh = 42;; ```; The first case is called the [snake case](https://en.wikipedia.org/wiki/Snake_case) and the second one is the [camel case ](https://en.wikipedia.org/wiki/Camel_case). Snake case is generally used in Python as [PEP8](https://peps.python.org/pep-0008/) suggests. . > Please revert the python accessor changes. I merged develop many of them vanished, should I revert the remaining ones?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1981#issuecomment-1482062542:187,avail,available,187,https://su2code.github.io,https://github.com/su2code/SU2/pull/1981#issuecomment-1482062542,1,['avail'],['available']
Availability,"> Note that you need to checkout this branch `fix_2d_periodic_rotation` (it is not in `develop` yet). Hi Pedro,; I checked the files you sent but building SU2 from source provided some errors:. - _MinGW64_ files provided from SU2 official website are corrupted and the installation crashes; however, it is possible to install the software but the .exe file mentioned in the installation guide won't be present. ; - After building _meson.py_ , the ninja installation command was line typed and the following alert message appeared "" **ninja: fatal: chdir to 'build' - No such file or directory** "". On a different laptop (with different user, to avoid the same mistakes) the following ERROR came up after the mason.py command line:; "" **'meson.py' is not recognized as an internal or external command, operable program or batch file** "". I don't know if any other user might have experienced the same errors. ; Anyway, are the bugfix files you published already available in the pre-compiled version? ; In the meanwhile, I'll try to figure out this inconvenient. Thank you in advance.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1562#issuecomment-1069325722:185,error,errors,185,https://su2code.github.io,https://github.com/su2code/SU2/issues/1562#issuecomment-1069325722,3,"['avail', 'error']","['available', 'errors']"
Availability,"> Sounds good, with that it will be easier to reason about when the recording types are created and used, right now someone would have to sit down and reverse-engineer the process. My intuition is that we can use some of the machinery introduced for multizone (partial tape evaluation) to simplify the recording management. And just to be clear I am very interested in having this feature in the code for comparison with the FP approach. That's exactly right. We started investigating the multizone driver a while back but we didn't get very far... It's been a while so i will need a refresher. Sure, there's broader interest in comparison with FP. Ole, Nico, and I talked about doing a detailed characterization last summer and we briefly brought it up in Varenna last week",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1750#issuecomment-1785913088:142,down,down,142,https://su2code.github.io,https://github.com/su2code/SU2/pull/1750#issuecomment-1785913088,1,['down'],['down']
Availability,"> Thank you for the feedback but for 99% of cases it is easier for users if we download the dependencies for them. The philosophy behind SU2 has always been to provide as much of a self contained package as possible. But this check will allow users to use external dependencies just fine, as long as they happen to use an external 0.61.1?. ... I am not entirely sure I understand the issue here. You want to make it *easier* for users by downloading the dependencies, so you make it harder if they went and got their own dependencies? If someone has gone to the effort of getting their own dependencies instead of using your documented meson.py, it would seem like that inherently means they are the 1% of use cases and you could probably just leave them to it. Is the issue rather that only Meson 0.61.1 has been tested to work?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1945#issuecomment-1450921338:79,down,download,79,https://su2code.github.io,https://github.com/su2code/SU2/issues/1945#issuecomment-1450921338,2,['down'],"['download', 'downloading']"
Availability,"> Thanks for the fast reply! I changed the hardcoded 2 (just as a remark: the hardcoded values also appear in the calculations), added myself as an author and inserted some lines for throwing an error if the issue in #1565 occurs. I did not know exactly where to put it best.; > ; > Concerning a regression test: I strongly support the idea of introducing an axisymmetric regression test. However, I was using a testcase from @bigfooted , and I never set up such a test case on my own. There do not seem to be any axisymmetric pipe setups in the Testcases folder so far. @bigfooted , could we maybe use your mesh for the jet flow test case and, if necessary, switch to a standard flow setup?. Yes, you can use that mesh. It can be used for pipe flow setup and jets with coflows, so we can reuse it in different testcases as well if needed. But any simple rectangular mesh is fine, so a mesh from the existing testcases as @pcarruscag mentions would also work.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1571#issuecomment-1075656956:195,error,error,195,https://su2code.github.io,https://github.com/su2code/SU2/pull/1571#issuecomment-1075656956,1,['error'],['error']
Availability,"> There was a lot of talk about refactoring the shape optimization framework to be able to work completely in memory.; > I think the idea was not to have more drivers but simply to have more granularity such that you could manipulate the geometry from python (without writing it to files).; > We also wanted introspection, i.e. you could probe SU2 via python for what variables and functions are available.; > We also talked about having the projection step (DOT) included in CFD_AD so that you only need to worry about surface sensitivities, note that DEF is already part of CFD for forward mode AD.; > (talking does not go very far); > ; > If you want to lead this work, we can help you understand the inner workings. We meet every Wednesday at 4pm CET https://meet.jit.si/SU2_DevMeeting to discuss this type of issue. Thank you for the quick reply. The discussions you mention sound very promising, I would be glad to join tomorrow afternoon and learn more, so that I might contribute. One quick remark: I am aware that it is indeed possible to deform the mesh within `SU2_CFD`, I use this extensively for static aero-elastic analysis. However, I have not been able to have the deformed mesh be written to file at output (in SU2 or CGNS format). This is fine for aero-elastic updates (movement of the surface due to _structural displacements_), where it is sufficient to see the deformed mesh in the post-processing files. It becomes impractical though, for design updates (movement of the surface to due to _design displacements_, i.e. representing changes in the design variables) where the new mesh is a useful intermediate result. Even if this is just an issue in my configuration file, I think that a stand-alone driver or equivalent of `SU2_DEF` would remain useful. For each new set of updated design variables during shape optimisation, a single mesh deformation is sufficient to provide the new, updated jig geometry which all of the aerodynamic or aero-elastic analyses (one for each oper",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1262#issuecomment-818839696:396,avail,available,396,https://su2code.github.io,https://github.com/su2code/SU2/issues/1262#issuecomment-818839696,1,['avail'],['available']
Availability,"@AmauryBilocq Thanks for your post. Can you please check that you are actually not running out of memory, as that can also raise such errors? Second, if Giles BC is the issue I think you will still be able to run the case with Riemann which is a bit simpler than Giles. Can you also test that?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1429#issuecomment-1025177015:134,error,errors,134,https://su2code.github.io,https://github.com/su2code/SU2/issues/1429#issuecomment-1025177015,1,['error'],['errors']
Availability,"@Nicola-Fonzi, you may as well want to consider importing as well the structural velocities in the interface from your external solver. That information is always available and gives a consistent definition of the displacement and velocity on both the grid motions and the interface for dynamic FSI problems -- not to mention simplifying the evaluation of the mesh adjoints.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1174#issuecomment-778326558:163,avail,available,163,https://su2code.github.io,https://github.com/su2code/SU2/pull/1174#issuecomment-778326558,1,['avail'],['available']
Availability,"@pcarruscag It is ready for some external feedback.; Some things that you might want to take a look at:; - the implementation of objectives using surface_scalar_01, surface_scalar_02,... This is a simple extension to multiple scalars but could be generalized in the future.; - the implementation of axisymmetric source terms using the already available CSourceAxisymmetric_Species, this framework was present in the species implementation. It works, but this might need some more polishing in the future.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1917#issuecomment-1466044654:343,avail,available,343,https://su2code.github.io,https://github.com/su2code/SU2/pull/1917#issuecomment-1466044654,1,['avail'],['available']
Availability,"@talbring Thanks for the quick and helpful answer! I'm looking at creating an ebuild/package for gentoo, compilation is a lot simpler than OpenFoam :P which is a big plus :). Anyway, I was looking at the old docs (the main docs still point to 6.0, I missed the red text that mentioned that somehow :P), not sure why, but you're right it's indeed mentioned in the 7.0 docs here https://su2code.github.io/docs_v7/Build-SU2-Linux-MacOS/#configuration-and-compilation. The ""Automatically installed dependencies"" section left me a bit confused because it sounded like the things listed there, which includes meson and ninja, would always get installed.; Maybe merging that section into the configuration and compilation section might help to make it more clear?. If you don't mind I have some additional questions:; - I didn't initialize the git submodule at all and configuration, compilation and running worked fine. Does this mean the CoDiPack and MeDiPack dependencies are optional? Or does this mean I could have a crash at runtime somewhere?; - Would it be possible to add a source package to the GitHub releases (in addition to the binary ones) that includes the (CoDiPack and MeDiPack) submodules? Unfortunately the GitHub provided source downloads don't include submodules.; - Are MKL and OpenBLAS build-time and exclusive options or can they both be compiled in and chosen at runtime?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/911#issuecomment-598751341:1242,down,downloads,1242,https://su2code.github.io,https://github.com/su2code/SU2/issues/911#issuecomment-598751341,1,['down'],['downloads']
Availability,"@timjim333, I checked your grid with just connectivity info and I get the following error messages. Boundary marker BODY, surface element 77477: No corresponding volume element found.; Coordinates of the points; 0.1815790.04981870.0020471; 0.181850.04994770.00205104; 0.1816670.04971090.00204381. Boundary marker BODY, surface element 133348: No corresponding volume element found.; Coordinates of the points; 0.1814850.04947420.00203657; 0.1813090.04968980.00204316; 0.181230.04944470.00204356. Boundary marker BODY, surface element 134774: No corresponding volume element found.; Coordinates of the points; 0.181230.04944470.00204356; 0.1813020.04923740.00202934; 0.1814850.04947420.00203657. Boundary marker BODY, surface element 135217: No corresponding volume element found.; Coordinates of the points; 0.1816670.04971090.00204381; 0.181850.04994770.00205104; 0.1815790.04981870.0020471. So clearly the grid is invalid.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/683#issuecomment-494393404:84,error,error,84,https://su2code.github.io,https://github.com/su2code/SU2/issues/683#issuecomment-494393404,1,['error'],['error']
Availability,@timjim333. The guidelines you mentioned are perfect but geometry complexity/time constraints at times push it beyond those numbers. Infact most of the Solvers (especially commercial) are robust enough to take (as I mentioned) the mesh crossing these specific guidelines. I think SU2 also handles it reasonably well. Latest version of Pointwise has direct export to SU2 (I think 17.3 onwards or so). Did you try CGNS format? . Best; Amit,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/683#issuecomment-495921430:188,robust,robust,188,https://su2code.github.io,https://github.com/su2code/SU2/issues/683#issuecomment-495921430,1,['robust'],['robust']
Availability,"A short summary of the things I did in the additional commits:. - I added a consistent error handling that can be used throughout the code. For example if a marker is not specified the error looks like that: ; ```; -------------------------------- Error ---------------------------------; In ""short unsigned int CConfig::GetMarker_CfgFile_TagBound(std::__cxx11::string)"": ; ------------------------------------------------------------------------; The configuration file doesn't have any definition for marker airfoil; ------------------------------------------------------------------------; Exiting now ...; ```; or if a solution cannot be found:. ```; -------------------------------- Error ---------------------------------; In ""void CSolver::Read_SU2_Restart_Metadata(CGeometry*, CConfig*, bool, std::__cxx11::string)"": ; ------------------------------------------------------------------------; Unable to open SU2 restart file solution_flow.dat; ------------------------------------------------------------------------; Exiting now ...; ```; In case you want to throw an error, you can simply call the function `SU2_MPI::Error(""Error Message"", CURRENT_FUNCTION)` where `CURRENT_FUNCTION` is a predefined macro which expands to the name of the routine at compile time. I already replaced almost all error messages in the code. - More MPI functions are included in the MPI Wrapper. - The rank/size is now stored in most of the bigger classes and initialized in the constructor. That means there are no calls to MPI_Comm_rank / MPI_Comm_size anymore in every routine ... For convenience there is also a SU2_MPI::GetRank() / SU2_MPI::GetSize(), in case you need it outside of the main classes. Let me know what you think. Not everything I did has to stay the way I implemented it :)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/473#issuecomment-347663941:87,error,error,87,https://su2code.github.io,https://github.com/su2code/SU2/pull/473#issuecomment-347663941,4,['error'],['error']
Availability,"A simple workaround would be to add an if line before the split:; Line 84 of parse_config.py; if np.size(s2) > 1:; thisval = s2.split('""')[1]; Yes, it requires also ; import numpy as np; at the beginning of the script.; Now it runs with no error message but no output produced.; Also config_gui.py is running, but it opens an empty window,; so apparently this is not good enough. best,; Eran",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/216#issuecomment-241208818:240,error,error,240,https://su2code.github.io,https://github.com/su2code/SU2/issues/216#issuecomment-241208818,1,['error'],['error']
Availability,"All,. The following page has performance comparisons between eigen and mkl (and others):. http://eigen.tuxfamily.org/index.php?title=Benchmark. They are dated 2011, so they are a bit old, but if the quoted performance is real, I would say it is a no-brainer to switch to eigen. If the performance tests (for at least simple things like daxpy and gemm) could be repeated to verify the numbers, that would help us make a final decision. Best,. Juan. On Feb 2, 2019, at 1:58 AM, Edwin van der Weide <notifications@github.com<mailto:notifications@github.com>> wrote:. @pcarruscag<https://github.com/pcarruscag>, I agree with you it will be hard to beat the MKL (running at 60 percent peak for most of the gemm calls for the DG-solver), but if you don't have any performance loss, that would already be nice, as it improves readability. Furthermore, the performance of the DG solver in combination with the discrete adjoint is horrible, because it relies on my very naive implementation of the matrix products. So it would already be something if we can get an improvement there, although we do not use the DG adjoint solver (yet). For me the easiest way to test things out for the DG-solver would actually be in SU2 itself. @economon<https://github.com/economon> put some nice profiling routines in there for the gemm calls, which can be used without any additional work to test eigen. @pcarruscag<https://github.com/pcarruscag> (or somebody else), could you create a branch in which eigen is downloaded in the external directory? I think I can manage from there. Thanks,. Edwin. —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/643#issuecomment-459952137>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADpSxCgydwy1nS3qPJvyCMJXLXWNMSFsks5vJWEkgaJpZM4adbAo>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/643#issuecomment-459986613:1489,down,downloaded,1489,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459986613,1,['down'],['downloaded']
Availability,"Alright. I've copied over my changes, with a few improvements. They're on the branch `feature_fileprofile`. One important change is that the user no longer needs to specify the node numbers. For each inlet node on the mesh, the code looks for the closest point from the inlet file. If that closest point is within a specified distance, it deems it a match. If not, it returns an error. Some points:. + The code will generate an example inlet file if the inlet file is missing / is invalid.; + I have not added interpolation. Since python makes interpolation easy, I didn't view this as a high priority.; + I have not added support for multigrid. I'm unsure of how to do this, since I'm not familiar with the multigrid code. It's not as simple as copying what's done for the restarts in the volume mesh. That's a volume based agglomeration, whereas the boundaries are faces. Feel free to modify my implementation however you want.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/467#issuecomment-368990059:379,error,error,379,https://su2code.github.io,https://github.com/su2code/SU2/issues/467#issuecomment-368990059,1,['error'],['error']
Availability,"As we mentioned in the dev meeting where you exposed the problem, the implementation is not good for strongly coupled flows, and I would guess that it is worse for diffusion than convection (because diffusion is elliptic).; I suspect the main problem is that the linear system does not contain information from the other side of the interface, meaning the solution of the two domains is effectively decoupled.; You could try running the case at much lower CFL (below 1) even with an explicit method.; It is also possible that the current treatment could be improved, since it is an example of multiplicative Schwartz decomposition, maybe there is an ""optimal"" way of implementing that from a physics point of view. Just speculating here, but maybe it would help treating the interface as an outlet if flow is going out, and as an inlet if flow is coming in.; On the numerics side, you can also try hacking the MZ driver to use something more stable than block-Gauss-Seidel (e.g. some quasi-Newton thing for the interface). But those are all band-aids IMO, if you want a robust fluid-fluid interface you need the coupling to be present in the linear system. The simplest way to do that is to have an internal boundary and treat the problem as single zone.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1414#issuecomment-951848509:1070,robust,robust,1070,https://su2code.github.io,https://github.com/su2code/SU2/issues/1414#issuecomment-951848509,1,['robust'],['robust']
Availability,"CATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; 14368 Vertex ; 3 Boundary Vertices ; 58189 Tetrahedra ; 1 Triangles ; 0 Edges ; 1 Surface(s) ; % Output subdom.meshb Mesh ndimn=3, mpoin=14368, melem=58189, mface=1; Corners 0 Required 0 ; ## ERROR : TETRAHEDRON 2 BOUNDARY FACE 1 2; 9 IS MISSING ; ## ERROR : TETRAHEDRON 4 BOUNDARY FACE 3 7; 2324 IS MISSING ; ···; ## ERROR: FEFLO.A: 16740 BOUNDARY FACES ARE MISSING ; CHECK YOUR MESH . ## FATAL ERROR: FEFLOA: INITIAL OR CURRENT MESH HAS AN INCONSISTANT TOPOLOGY . Thank you for using feflo.a . ```; Which in turn creates an invalid `amg.su2` mesh in the `adap/ite0 folder`, which triggers the fault.; I'm a bit puzzled as the domain is very simple, and the `log.out` is going well (with no complains of SU2 about any negative volume or trias with wrong normals). The mesh is only made of TRIAS and TETRAS, it should work in principle.; Am I missing something in the setup / mesh? I know you have little control on the `amg.out`, but maybe there some special hint that I'm missing. . Btw the final error in the terminal is but I think the problem arises before reaching `flo.csv` file:; ```; Traceback (most recent call last):; File ""/usr/local/bin/mesh_adaptation_amg.py"", line 111, in <module>; main(); File ""/usr/local/bin/mesh_adaptation_amg.py"", line 72, in main; options.save_all ); File ""/usr/local/bin/mesh_adaptation_amg.py"", line 101, in mesh_adaptation_amg; SU2.run.amg(config); File ""/usr/local/bin/SU2/run/amg.py"", line 464, in amg; os.rename(cur_solfil, cur_solfil_ini); FileNotFoundError: [Errno 2] No such file or directory: 'flo.csv' -> 'flo_ini.csv'. ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/948#issuecomment-623572280:2152,fault,fault,2152,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-623572280,1,['fault'],['fault']
Availability,"Charanya,. thanks for the detailed answer. Let me ask you some more info. Apparently, you where able to reproduce the results I had comparing the two code versions simply using different boundary conditions on the latest code version. Can you specify me how?. Tobi,. In the meanwhile, to narrow down the problem, I ran also a couple tests in 2D to seek confirmation. For the (Euler) **pitching_NACA64A010.cfg** test case in the repository I rerun the same test at AoA of 1 deg and removing the pitching (no mesh deforming). I attach config files and summaries relative to the test cases. [config_CFD_6_2_0.txt](https://github.com/su2code/SU2/files/3938858/config_CFD_6_2_0.txt); [Summary_6_2_0.txt](https://github.com/su2code/SU2/files/3938859/Summary_6_2_0.txt); [config_CFD_6_0_1.txt](https://github.com/su2code/SU2/files/3938863/config_CFD_6_0_1.txt); [Summary_6_0_1.txt](https://github.com/su2code/SU2/files/3938865/Summary_6_0_1.txt). In this case the situation is definitely better as the two solvers give the same results. It looks like it is an issue related to the 3D case. <img width=""1220"" alt=""Screenshot 2019-12-09 at 11 27 27"" src=""https://user-images.githubusercontent.com/23583209/70424365-f316a780-1a77-11ea-8f68-4fc83e188ed7.png"">. I also quote Charanya in saying that it is definitely good that convergence to same values is reached but the transient response is fundamental and holds physical/mathematical values (I think of Wagner et similia) :). I would also suggest to add a regression test in this sense. Best, ; Rocco",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/828#issuecomment-563150217:295,down,down,295,https://su2code.github.io,https://github.com/su2code/SU2/issues/828#issuecomment-563150217,1,['down'],['down']
Availability,"Config options and their options can be found in:; https://github.com/su2code/SU2/blob/master/config_template.cfg; As a part of the code repository, this document will remain up to date with whatever version of the code you have. I believe that this is the single document to which you refer. I apologize that its location or purpose may not have been clear - I will shortly go edit the wiki to see if I can make it clearer that this file exists. . Additionally, the file config_template_basic.cfg in the same directory is a shorter version with only the options most commonly used. . Further documentation of the config options is also available in the comments of:; https://github.com/su2code/SU2/blob/master/Common/src/config_structure.cpp. And although it has not been up to date as we moved towards the wiki and config file template rather than keeping doxygen up to date, additional documentation can be produced using the files in su2code/Documentation/Doxygen.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/183#issuecomment-111755617:637,avail,available,637,https://su2code.github.io,https://github.com/su2code/SU2/issues/183#issuecomment-111755617,1,['avail'],['available']
Availability,"Dear Daumantas,. I appreciate your effort in adding support for cmake in SU2. We have recently introduced the Meson build system (https://mesonbuild.com/) (#685, #745) as a candidate to replace automake. A guide on how to use can be found [here](https://su2code.github.io/docs_v7/Build-SU2-From-Source/). The idea is that we will have this system along automake at least for the upcoming version 7 and that we get rid of automake afterwards. Considering that, I don't think that it makes sense to maintain 3 different build systems **at the moment**. I really hate turning contributions down, but this one is three months too late. However, we might reconsider adding support for another build system once we got rid of automake, or, if we feel that meson does not fit our needs. I am all ears to hear other opinions. However, let's not start a discussion on the advantages/disadvantages of the build systems. Some benefits can be found in the Issue/PR linked above.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/814#issuecomment-552360147:587,down,down,587,https://su2code.github.io,https://github.com/su2code/SU2/pull/814#issuecomment-552360147,1,['down'],['down']
Availability,"Dear Dr Albring,. I just followed the procedures and included the files to create a test case to SU2_CFD_AD [a coarse mesh, a TargetCp.dat and a config file for an Arina nozzle. The coarse mesh is a 2000 triangles one; which is enough to give us an idea of the shockwave location and the geometry modifications. The next mesh I have would be an ~85000 elements which gives us a good information on the 27th function call]. ; I had some segmentation faults during long jobs: Is there some recommended tuning I can do on OS/HW or SU2 in order to minimize them?. With kind regards,. Jairo. > On Dec 7, 2018, at 09:45, Jairo Paes Cavalcante Filho <jairo.pcfilho@gmail.com> wrote:; > ; > Hello Dr. Albring,; > ; > Yes! Sorry for the delay due some internal presentations and events here.; > I just finished a small model and successfully tested it on openSUSE. I expect to upload it today.; > ; > With kind regards,; > ; > Jairo; > ; >> On Dec 7, 2018, at 06:35, Tim Albring <notifications@github.com <mailto:notifications@github.com>> wrote:; >> ; >> Hi Jairo,; >> ; >> what is the status here ? Is it possible to provide a simpler (smaller) case ?; >> ; >> —; >> You are receiving this because you were mentioned.; >> Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/pull/600#issuecomment-445175541>, or mute the thread <https://github.com/notifications/unsubscribe-auth/Ac180u4PogeqhPW9rrfY4mW705IYKjvhks5u2jZpgaJpZM4X34F2>.; >> ; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/600#issuecomment-445429636:449,fault,faults,449,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-445429636,1,['fault'],['faults']
Availability,"Dear Heather,; I am analyzing a propeller of an UAV. I have static thrust measurements such that when I used Euler results I got 3.5 lbf thrust as compared to the measured 6 lbs. My next step was to perform an NS equation with SA turb model. I got 7 times over predicted results such that the mesh has a Y+ of less than 1. Then I thought of doing an SST but was not long enough that it gave me error with divergence. I have been setting up my SST case as per the tutorial example of NACA0012. However, I do not happen to see any entry with regards to eddy frequency etc. (usually required by SST) in the config file. Any guidance will be great.; Thanks; Jehan; From: Heather Kline notifications@github.com; To: su2code/SU2 SU2@noreply.github.com ; Sent: Tuesday, May 12, 2015 11:43 AM; Subject: [SU2] Feature deallocation (#174). Bringing this branch up to date with current develop branch. ; Various deallocation changes; Some regression tests fail but all run. (previously was not the case); You can view, comment on, or merge this pull request online at:;   https://github.com/su2code/SU2/pull/174; Commit Summary; - Updated GetEngine_Properties; - Fix to the last commit; - Small bug; - Merge branch 'develop' into feature_MPI; - merging; - SU2_SOL and SU2_CFD are working; - Preliminary, but complete, implementation of SU2_DEF; - More updates; - Working version; - Complete implementation (validate); - Working version of SU2_DEF; - Final push before moving to the develop branch; - New MPI (removing SU2_PRT); - Merged in Ben's ParMETIS integration and fixed some conflicts.; - Merge branch 'benkirk-parmetis_integration' into feature_MPI; - ParMETIS geometry routines have been copied over but are not activated yet.; - Small change to ParMETIS include.; - ParMETIS can now be activated for testing (PARMETIS=YES in config).; - Updated MG; - Updated EA subrotuine; - Small fix; - Fixing memory leak; - Fixing memory leaks; - Dev release v.3.2.6; - Increasing MAX_NUMBER_MARKER; - Working versi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:394,error,error,394,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['error'],['error']
Availability,"E=''; BUILD_DIRECTDIFF_TRUE='#'; BUILD_DOT_FALSE='#'; BUILD_DOT_TRUE=''; BUILD_GEO_FALSE='#'; BUILD_GEO_TRUE=''; BUILD_HDF5_FALSE=''; BUILD_HDF5_TRUE='#'; BUILD_JSONCPP_FALSE=''; BUILD_JSONCPP_TRUE='#'; BUILD_LAPACK_FALSE=''; BUILD_LAPACK_TRUE='#'; BUILD_METIS_FALSE=''; BUILD_METIS_TRUE='#'; BUILD_MSH_FALSE='#'; BUILD_MSH_TRUE=''; BUILD_MUTATIONPP_FALSE=''; BUILD_MUTATIONPP_TRUE='#'; BUILD_NORMAL_FALSE='#'; BUILD_NORMAL_TRUE=''; BUILD_PARMETIS_FALSE=''; BUILD_PARMETIS_TRUE='#'; BUILD_REVERSE_FALSE=''; BUILD_REVERSE_TRUE='#'; BUILD_SOL_FALSE='#'; BUILD_SOL_TRUE=''; BUILD_SZIP_FALSE=''; BUILD_SZIP_TRUE='#'; BUILD_TECIO_FALSE=''; BUILD_TECIO_TRUE='#'; BUILD_ZLIB_FALSE=''; BUILD_ZLIB_TRUE='#'; CC='gcc'; CCDEPMODE='depmode=gcc3'; CFLAGS='-g -O2'; CGNS_CXX='-DHAVE_CGNS -I/gshare/soft/code_saturne/4.0.0/prod/cgnslib_3.2.1/include'; CGNS_LD='/gshare/soft/code_saturne/4.0.0/prod/cgnslib_3.2.1/lib/libcgns.a'; CPP='gcc -E'; CPPFLAGS=''; CXX='g++'; CXXDEPMODE='depmode=gcc3'; CXXFLAGS='-g -O2'; CYGPATH_W='echo'; DEFS='-DPACKAGE_NAME=\""SU2\"" -DPACKAGE_TARNAME=\""SU2\"" -DPACKAGE_VERSION=\""4.1.0\"" -DPACKAGE_STRING=\""SU2\ 4.1.0\"" -DPACKAGE_BUGREPORT=\""su2code-dev@lists.stanford.edu\"" -DPACKAGE_URL=\""https://github.com/su2code\"" -DPACKAGE=\""SU2\"" -DVERSION=\""4.1.0\"" -DSTDC_HEADERS=1 -DHAVE_SYS_TYPES_H=1 -DHAVE_SYS_STAT_H=1 -DHAVE_STDLIB_H=1 -DHAVE_STRING_H=1 -DHAVE_MEMORY_H=1 -DHAVE_STRINGS_H=1 -DHAVE_INTTYPES_H=1 -DHAVE_STDINT_H=1 -DHAVE_UNISTD_H=1 -DSIZEOF_SHORT_INT=2 -DSIZEOF_INT=4 -DSIZEOF_UNSIGNED_INT=4 -DSIZEOF_LONG_INT=8 -DSIZEOF_FLOAT=4 -DSIZEOF_DOUBLE=8 -DSIZEOF_VOID_P=8'; DEPDIR='.deps'; DIRECTDIFF_CXX=''; DIRECTDIFF_LIBS=''; ECHO_C=''; ECHO_N='-n'; ECHO_T=''; EGREP='/bin/grep -E'; EXEEXT=''; GREP='/bin/grep'; HDF5_CXX=''; HDF5_LD=''; INSTALL_DATA='${INSTALL} -m 644'; INSTALL_PROGRAM='${INSTALL}'; INSTALL_SCRIPT='${INSTALL}'; INSTALL_STRIP_PROGRAM='$(install_sh) -c -s'; JSONCPP_CXX=''; JSONCPP_LD=''; LAPACK_CXX=''; LAPACK_LD=''; LDFLAGS=''; LIBOBJS=''; LIBS=''; LTLIBOBJS=''; ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:23186,echo,echo,23186,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,1,['echo'],['echo']
Availability,"From the SU2 paper, talking about ""guiding principles"":. <img width=""574"" alt=""Screen Shot 2019-10-09 at 3 26 46 PM"" src=""https://user-images.githubusercontent.com/19416354/66525312-edb5d480-eaa9-11e9-9c0f-158b3941b407.png"">. I particularly like. > Full documentation, including a comprehensive set of tutorials. (""including"" implying that the tutorials are a subset of the documentation), and . > expose the full set of options [...] to the practitioner. This conflicts with our ""operating principle"", laid out on the tutorials page:. > Rather than writing a long manual on all available (and constantly evolving) configuration options available in SU2[...]. The Guide to V7 is a good start, but I think at the bare minimum (since I agree that full documentation would be a huge task, though one that's apparently promised on a paper we link on our homepage), we should provide more information about the existing options beyond forcing the user to scroll through config_template.cfg or dig through the tutorials.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/775#issuecomment-540239931:579,avail,available,579,https://su2code.github.io,https://github.com/su2code/SU2/issues/775#issuecomment-540239931,2,['avail'],['available']
Availability,"Hello @aditya12398 ,. No such thing as a noob question!. To use your system meson, instead of using: `./meson.py <arguments>` in your SU2 root dir, use `meson <arguments>`. This assumes your system meson is in front of your current directory in your path, of course. Likewise, to use system ninja, instead of using: `./ninja -C build install`, simply use `ninja -C build install`. I found, for some reason, that when using my system meson and ninja with the changes made in `fix_python_3.8`, I am not getting errors, but when I use SU2's included `./meson.py`, I'm still getting those errors. Not sure why this is happening, though. -Paul",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/991#issuecomment-631584658:509,error,errors,509,https://su2code.github.io,https://github.com/su2code/SU2/issues/991#issuecomment-631584658,2,['error'],['errors']
Availability,"Hello Pedro. While searching a small sample dataset, I have run some; variations on the jobs, and my findings were:; (Please note that *all* ""markers"" I have mentioned in the next items refer; to solid walls in the mesh, using the RANS solver); 1- When I impose HEATFLUX=0 *and* ISOTHERMAL=290 Kelvin, for the same; markers, there are no complaints from SU2. It shows that SU2 ignores the; imposition of HEATFLUX=0, in this case.; 2- Just setting ISOTHERMAL=290 Kelvin (using all of the same markers as in; (item 1), above), without any HEATFLUX setting, then SU2 produces the same; results as in (item1).; 3- When some markers are set with HEATFLUX=0 and the rest of them are set; with ISOTHERMAL=290 Kelvin (so that each wall marker in the mesh is; referenced), there are no complaints from SU2, and the job goes as expected.; 4-The error message mentioned earlier, appears when one or more solid wall; markers *is not marked* concerning HEATFLUX or ISOTHERMAL; .; My conclusion then is that the error message appeared when I mistakenly; have not included a wall marker (assigning it as a HEATFLUX or an; ISOTHERMAL marker!); Does it make sense?; Kind regards,. On Mon, Oct 23, 2023 at 7:48 PM Jairo Cavalcante ***@***.***>; wrote:. > Unfortunately, my example involves a swirler and nozzle for the; > Navier-Stokes solver with Menter model, so the dataset is relatively large.; > Let me check whether some older small Euler mesh exhibits the same message!; > I will let you know! Thank you very much.; >; > On Mon, Oct 23, 2023 at 6:34 PM Pedro Gomes ***@***.***>; > wrote:; >; >> Is there a simple example to reproduce the issue?; >>; >> —; >> Reply to this email directly, view it on GitHub; >> <https://github.com/su2code/SU2/pull/2109#issuecomment-1776057496>, or; >> unsubscribe; >> <https://github.com/notifications/unsubscribe-auth/AHGXZUV3DNRF3O55YAWT563YA3PETAVCNFSM6AAAAAA3QKLVDWVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMYTONZWGA2TONBZGY>; >> .; >> You are receiving this because you commen",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/2109#issuecomment-1777018035:835,error,error,835,https://su2code.github.io,https://github.com/su2code/SU2/pull/2109#issuecomment-1777018035,1,['error'],['error']
Availability,"Hello all, ; as I have mentioned before, this PR is the first of a series that are coming soon for general maintenance and improved usability of the code. As you all know, we are working hard to improve the generality and usability of the code and to maintain it healthy. ; We have some other improvements/generalizations that rely on this one. Therefore, I think it would be a good idea to merge this in sooner than later, to transition smoothly to this new structure.; Best,; Ruben",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/585#issuecomment-441210349:107,mainten,maintenance,107,https://su2code.github.io,https://github.com/su2code/SU2/pull/585#issuecomment-441210349,1,['mainten'],['maintenance']
Availability,"Hello,. So, to clarify, there were two issues:. 1) With the old commit (382e82f), we were seeing the assertion failure at line 1881 of numerics_structure.cpp, but only with the very large mesh (180 million cells). 2) With the newer commit (c093a62), we were seeing the assertion failure at line 294 of C2DContainer.hpp, which was occurring even with smaller meshes (7 million cells). The solution to (2) appears to be to change `geometry->node[iPoint]->GetnNeighbor()` to `geometry->node[iPoint]->GetnPoint()` at line 3759 of CEulerSolver.cpp, in the `CEulerSolver::SetUpwind_Ducros_Sensor()` method. I made this change locally, and attempted to run on our large mesh. Issue (2) seems to be fixed, but we still run into issue (1). I have now gone through the read restart routines, and have found a potential issue:. For reference, the restart file for our large mesh with averaging data included consists of:; 39 fields * 75,107,967 points = 2,929,210,713 variable values (which is larger than `INT_MAX`). Beginning at line 3931 of CSolver.cpp, in method `CSolver::Read_SU2_Restart_Binary(...)`, we have the following:. ```; int *blocklen = new int[geometry->GetnPointDomain()];; int *displace = new int[geometry->GetnPointDomain()];; int counter = 0;; for (iPoint_Global = 0; iPoint_Global < geometry->GetGlobal_nPointDomain(); iPoint_Global++ ) {; if (geometry->GetGlobal_to_Local_Point(iPoint_Global) > -1) {; blocklen[counter] = nFields;; displace[counter] = iPoint_Global*nFields;; counter++;; }; }; MPI_Type_indexed(geometry->GetnPointDomain(), blocklen, displace, MPI_DOUBLE, &filetype);; ```; The problem here is that for our case, where `iPoint_Global` can get up to 75,107,967 and `nFields` = 39, the value assigned to `displace[counter]` in the loop can over-run `INT_MAX`. This would result in potential garbage / incorrect displace values being passed to `MPI_Type_indexed(...)`. Unfortunately, simply changing `displace` to a `long int *` won't work, as the expected argument type for `",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/949#issuecomment-622026420:111,failure,failure,111,https://su2code.github.io,https://github.com/su2code/SU2/issues/949#issuecomment-622026420,2,['failure'],['failure']
Availability,Here is a quick summary for the inviscid wedge case using different NEMO schemes. There is clearly work to be done in the convergence/robustness world.; [nemo_scheme_regressions.pdf](https://github.com/su2code/SU2/files/10441554/nemo_scheme_regressions.pdf),MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1885#issuecomment-1386403998:134,robust,robustness,134,https://su2code.github.io,https://github.com/su2code/SU2/pull/1885#issuecomment-1386403998,1,['robust'],['robustness']
Availability,"Hey Rocco,. > And both versions are/were on the develop branches -> what exactly do you refer to here: config-files, code, mesh. The code tags 6.0.1 and 6.2.0 refer to specific master-commits of the code. So I want to know what is exactly of the develop branch, can't be the code if you understand the tags as I do. Maybe you refer to the develop code at the time where these tags were introduced. But maybe sth different. > I guess they converge eventually to the same values. I tried to compare the same case but steady (I attach the summary). Results in this case are fairly similar and (in my opinion) raise no warnings. That is good to hear. ; Luckily @cvencro (Thanks for that 👍 ) ran some tests and found that #740 (which rewrites Euler Wall boundaries for compressible and incompressible flows ... which was me btw) introduces the changes you see. The Euler wall for compressible is changed a bit in the way the boundary condition is enforced. Upon convergence both version should recover (close to) the same value. If the results in a steady state are the same/very-similar and if an unsteady simulation at low enough Reynolds-number converges to the same steady result (or oscillate in the same bounds) -> I would say it is simply some purely numerical effect based on the unphysical initialization and different treatment of the euler wall boundary. . 1 thing one could test additionally is to force a very high convergence in each physical timestep, i.e. usually one converges ~3 orders of magnitude in each ts -> now try converging until residual stalling in each ts. If the code versions get the same/closer results in the temporal evolution my euler wall boundary explanation would be quite reasonable.; Together with the long running unsteady simulation proposed above, I would feel more comfortable to judge. @cvencro (bringing the conversation to this place 😉 ) concerning the pitching case: the `if (dynamic_grid)` statements in the 'old' version are not necessary as that is handle",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/828#issuecomment-562621057:989,recover,recover,989,https://su2code.github.io,https://github.com/su2code/SU2/issues/828#issuecomment-562621057,1,['recover'],['recover']
Availability,"Hey,. @cvencro and I were discussing this issue quite a bit this morning and here an attempt of a summary:. We are looking at the following cases:; 1. 3D Onera m6, compressible euler, including euler_wall and sym_plane ; a. steady state; b. unsteady (no pitching, deforming); 2. 2D NACA64A010, compressible euler, including euler_wall; a. unsteady (no pitching/ deformation); b. pitching (with rigid and with deforming mesh -> used for the gradient validation of @cvencro 's post ). We are rather certain that the differences between the code-versions are due to the new euler_wall boundary which was introduced in #740 (by me :) ). @cvencro did a test where the old euler_wall was simply pasted into the newer function body (which currently directly calls the sym_plane boundary) -> that recovered the results obtained with the 'older' version. The steady state results (onera m6) show that both codes deliver the same results (of course with some minor differences). So far so good. Unsteady cases are a bit trickier: the latest 2D results of @RoccoBombardieri show pretty much no difference including the first timesteps. The onera m6 case in contrast converges to the same (steady-state) results for both code version eventually but their initial transient phase differs quite significantly. . A possible explanation for the different initial transient phase: In both implementations a ""reflected state"" is constructed where the normal component of the velocity is subtracted [once in the older code version & twice in the newer version]. I.e. subtracting the normal component of velocity twice means mirroring the velocity along the symmetry plane. The newer code version is a bit ""stronger"" in enforcing the boundary conditions which could lead to the reduced oscillation in CD and CL. If we agree that both code versions produce physically correct results for steady cases and unsteady cases that were integrated long enough in time to get rid of the influence of the initial condition ... then",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/828#issuecomment-563314747:789,recover,recovered,789,https://su2code.github.io,https://github.com/su2code/SU2/issues/828#issuecomment-563314747,1,['recover'],['recovered']
Availability,"Hi @bmunguia ,; I was in the same situation as @MiracAydin1, so thanks for the hint. Nevertheless I'm having some problems. I followed your instructions to install the branch:. 1. downloaded the [feature_adapt_sst](https://github.com/su2code/SU2/tree/feature_adap_sst) branch.; 2. Used meson to configure the build; `./meson.py build -Denable-autodiff=true -Denable-directdiff=true`; 3. Added the environment variables to the .bashrc; 4. ninja build.; `./ninja -C build install`. The build didn't show any errors, only few warnings during meson ( `gcc1: warning: command line option ‘-Wno-non-virtual-dtor’ is valid for C++/ObjC++ but not for C`). When I try to run the mesh_adaption (or even run simply the solver through parallel_computation.py):. `$SU2_RUN/mesh_adaptation_amg.py -f invCyl.cfg -n 6`. It immediately shows an error (without even showing the SU2 splash screen) :; `Traceback (most recent call last):`; ` File ""/usr/local/bin/mesh_adaptation_amg.py"", line 38, in <module>`; ` import SU2`; ` File ""/usr/local/bin/SU2/__init__.py"", line 14, in <module>`; ` from SU2 import amginria`; ` File ""/usr/local/bin/SU2/amginria/__init__.py"", line 4, in <module>`; ` from .interface import *`; ` File ""/usr/local/bin/SU2/amginria/interface.py"", line 41, in <module>`; ` import _amgio as amgio`; `ImportError: No module named _amgio`. Am I missing any dependencies? ; Please note that I previously compiled SU2 master branch without issues, and have already installed mpich, numpy, scipy.; Any help would be really appreciated.; Thanks",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/948#issuecomment-619332650:180,down,downloaded,180,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-619332650,3,"['down', 'error']","['downloaded', 'error', 'errors']"
Availability,"Hi @cvencro , I think it would be good to add that Testcase to the regression tests to 'guard' the code. ; I actually wanted to do that real quick but it guess that with `SINGLEZONE_DRIVER` one cannot access `TIME_ITER`, only `EXT_ITER` with the` .test_iter` variable of the python Testcase class. Not sure if that is addressed in #724 , maybe @rsanfer or @talbring can give a quick info as this is probably affecting all unsteady regression tests. . Concerning the Testcase repo: You can simply open a PR for the develop branch of the Testcase repo, and refer to the corresponding PR here (and vice versa). As far as I know the Testcase repo is not protected, i.e. you can merge without any check. And as it is just one added mesh and no other change you could do it right now from my point of view. Another point: What about the rotating_frame for incompressible flow? If it is untested I would like an error catch in place that this feature can't be used out of the box.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/767#issuecomment-527167827:905,error,error,905,https://su2code.github.io,https://github.com/su2code/SU2/pull/767#issuecomment-527167827,1,['error'],['error']
Availability,"Hi @koodlyakshay thanks for making the changes.; By default MPI barriers are ""never"" needed, the normal communication routines already do all synchronization required. Efficiency is probably not fundamental for that routine but this solution feels too complicated somehow, can you attend tomorrow's developers meeting? (I'm getting the ""there's gotta be a simpler way"" feeling, and if we pick the brains of a few people we are certain to find it). In the meantime, if you specify the roughness as a string+double list (exactly like MARKER_HEATFLUX), which is read with `addStringDoubleListOption` you could probably simplify the logic around heatflux and isothermal markers, which would make the setup more user friendly (having to stick with an order is bound to trip someone at some point).; Also the cht interface is ""just"" an isothermal boundary, any reason not to make this feature available for that?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/877#issuecomment-630788337:887,avail,available,887,https://su2code.github.io,https://github.com/su2code/SU2/pull/877#issuecomment-630788337,1,['avail'],['available']
Availability,"Hi @pcarruscag I just tried a simpler mesh and using MPI I get the UCX crash.; [err_log_SU2v7.0.3.txt](https://github.com/su2code/SU2/files/5810207/err_log_SU2v7.0.3.txt). To double check, I also used the master v7.0.8 SU2_CFD. When I run with MPI, I get the UCX error but when I run in serial, the solution appears to converge fine. I suspect that this means it's probably not the mesh that is causing the issues - what are your thoughts?; [su2_out_serial.txt](https://github.com/su2code/SU2/files/5810208/su2_out_serial.txt)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1156#issuecomment-759607361:263,error,error,263,https://su2code.github.io,https://github.com/su2code/SU2/issues/1156#issuecomment-759607361,1,['error'],['error']
Availability,"Hi @themrdjj,; Thank you for the feedback, there was already a similar report in #796 (which incidentally went stale and was closed), I will try to do something about it, or if you would like to contribute code to the project I can point you to right place to add an error message. Meanwhile my best advice is to not start a config from scratch until you know SU2 very well (and even then...) look for a test case that uses similar features and go from there.; The minimal config is the one in Quickstart, the template is more of a catalog :) I don't think we'll ever have a unified minimal config, SU2 does many things, some mutually exclusive.; Convective options are reasonably well documented here: https://su2code.github.io/docs_v7/Convective-Schemes/; The output messages before ""Begin Solver"" can be helpful (although in this particular case you would need to know what to expect). Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/842#issuecomment-566642727:267,error,error,267,https://su2code.github.io,https://github.com/su2code/SU2/issues/842#issuecomment-566642727,1,['error'],['error']
Availability,"Hi Economon,. I encountered an issue very similar to what Auzbaig reported: the error message ""OBJECTIVE_FUNCTION: invalid option value EntropyGeneration"" during optimization with SU2. (I am using SU2 version 8.0.1 ""Harrier.""). After thoroughly examining the existing Python optimization framework, I found that one of the steps in the optimization chain is generating different config.cfg files, with a focus on DV_VALUE and OBJECTIVE_FUNCTION. DV_VALUE controls the geometry deformation;; OBJECTIVE_FUNCTION determines the type of objective/constraints.; Then the framework calls SU2_CFD and SU2_DOT to obtain performance metrics or gradient information.; As you mentioned, ""You might need to run updateHistoryMap.py to register new outputs with Python."" Initially, I thought it meant simply providing a new input for OBJECTIVE_FUNCTION in the Python optimization framework. However, it seems that this may not work at the C++ level. To verify this, I ran $ SU2_CFD your_config.cfg -d and observed all available history outputs. However, I suspect that OBJECTIVE_FUNCTION cannot use every history output, meaning that the adjoint solver might not recognize some objective functions. Does this imply that additional modifications in the C++ code are required?. Additionally, I would appreciate more information regarding CUSTOM_OBJFUNC. From TestCases/user_defined_functions/lam_flatplate.cfg, I understand that CUSTOM_OBJFUNC allows combinations of existing OBJECTIVE_FUNCTIONs and can also utilize CUSTOM_OUTPUTS. The flexibility of CUSTOM_OUTPUTS seems to enable the construction of various desired variables. However, I am unsure whether using OBJECTIVE_FUNCTION= CUSTOM_OBJFUNC along with CUSTOM_OUTPUTS can entirely replace the need for additional modifications in the C++ code. Since I’m not very proficient in C++, I would greatly appreciate your guidance. Sincerely,; Tongtong",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/889#issuecomment-2324575133:80,error,error,80,https://su2code.github.io,https://github.com/su2code/SU2/issues/889#issuecomment-2324575133,2,"['avail', 'error']","['available', 'error']"
Availability,"Hi Eduardo,. both, 'symmetry plane' and 'symmetry as the slip wall' should work in the code (upon fixing this) and it should be made clear (e.g. in the config_template.cfg) what the BC is suitable for, independent of how it is named in the end. ; The simplest solution is probably the patch I provided together with a short note in the config_template (maybe even a reference to this issue), as both 'options' will work as expected (using the very same code). It will basically 'restore' the behaviour of MARKER_SYM of before the fix in #657. The downside is some more computational cost (in case of a plane) which has to be done for each vertex on the marker. I cant say to which extend this takes more time but I would guess it is not too costly. Depends on the case as well. I can do a little check with your case here. . That's it for the diplomatic part :) (Please take the following with a grain). For me a symmetry has to be a line or plane. To cite Jiri Blazek's book 'Computational Fluid Dynamics'(...) 3rd edition using a screenshot:. ![blazekbook](https://user-images.githubusercontent.com/31306376/61662377-9ab05a80-acce-11e9-85bf-5998db204d92.png). The chapter is called 'symmetry plane' which already is kinda biased. But there is no 'slip wall for viscous flow' mentioned to my knowledge. In another book (from Ferziger&Peric, which I only have in german) symmetry is only used in the context of symmetry planes as well. ; To me, symmetry BC's are also linked to visualization using mirroring. And mirroring (as the word is commonly meant) is only possible along planes and its little brother, the straight line. I can be wrong or it might be a question of research background. So how to proceed? Trial by combat might have some unpleasant aftermath for the winner so we might go the democratic way and do a poll :) . Cheers, ; Tobi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/735#issuecomment-513957018:547,down,downside,547,https://su2code.github.io,https://github.com/su2code/SU2/issues/735#issuecomment-513957018,1,['down'],['downside']
Availability,"Hi Jean,; Sorry for the delay. The hypothesis I have for the less robust behavior of periodic BC's is that the linear solver is not completely aware of the periodicity. In fact after the linear solve we have to force the matching nodes to have the same value.; This is done in CFVMFlowSolverBase.hpp::CompleteImplicitIteration_impl, in the call to InitiatePeriodicComms.; The idea is to make the linear solver aware of the periodicity, to do so would require including periodic communications in the preconditioners and the matrix-vector product.; These are all in CSysMatrix.cpp, so before each of the `/*--- MPI Parallelization ---*/` bits we would need periodic comms, for preconditioners these comms would simply make the values equal, like in CSolver::InitiatePeriodicComms(PERIODIC_IMPLICIT) whereas for the matrix-vector product we need to add the values (effectively periodicity splits a row of the matrix into two ""half rows"") and this would be similar to what is done with the linear residual in CSolver::InitiatePeriodicComms(PERIODIC_RESIDUAL).; I think @TobiKattmann was also interested in having a look into this.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1467#issuecomment-1017640248:66,robust,robust,66,https://su2code.github.io,https://github.com/su2code/SU2/issues/1467#issuecomment-1017640248,1,['robust'],['robust']
Availability,"Hi Josip,. in the current develop/master these features are still included. However, the plan is to remove these. The reason is simply because of maintenance. We have nobody that can spare time to test the current implementation. If you are willing to do this, please let use know. Tim",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/348#issuecomment-268010192:146,mainten,maintenance,146,https://su2code.github.io,https://github.com/su2code/SU2/issues/348#issuecomment-268010192,1,['mainten'],['maintenance']
Availability,"Hi Pedro, ; I'm slightly confused right now and not sure if I'm able to do the necessary modifications. I understand that it is unlikely someone else might implement this but I think that this is beyond my abilities right now. If you don't mind, do you have some time to talk through my options in a video call? I hope that will help me to get a clearer picture. Next week, I'm generally available except for Monday, which is a public holiday here. Germany is 9 hours in advance of California, so your morning / my evening might work?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1954#issuecomment-1497398492:388,avail,available,388,https://su2code.github.io,https://github.com/su2code/SU2/pull/1954#issuecomment-1497398492,1,['avail'],['available']
Availability,"Hi Soumen,. As Tom said, the routines are all in place and I have been putting them; together for solution interpolation from one mesh to another for unsteady; simulation as post-processing step. So probing at a particular location for; unsteady solution can be also done with this framework. The probe search; implementation is in place for 2D configuration currently. It will be; extended to 3D and probably available in the main branch in the next 2; months.; The implementation so far is in feature_MeshInterpolation branch if you; want to take a look. Sravya. On Thu, Nov 2, 2017 at 10:09 PM, Thomas D. Economon <; notifications@github.com> wrote:. > Hi Soumen: yes, this is something that the developers are actively working; > on at the moment (in particular, @sravya91 <https://github.com/sravya91>; > has been taking the lead on this). It is true that most of the ingredients; > are already available in SU2 (fast searches, interpolation routines, etc.),; > but the trick is combining them all and making it general.; >; > Do you have any other requirements beyond simple probes? I am guessing we; > should have something available in the next few months, but it's not set; > yet.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/issues/466#issuecomment-341623660>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/AHenII5B0Xtb2U_hj2vbBesf5Oc51uvzks5syqAEgaJpZM4QPYh8>; > .; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/466#issuecomment-342266341:410,avail,available,410,https://su2code.github.io,https://github.com/su2code/SU2/issues/466#issuecomment-342266341,3,['avail'],['available']
Availability,"Hi Soumen: yes, this is something that the developers are actively working on at the moment (in particular, @sravya91 has been taking the lead on this). It is true that most of the ingredients are already available in SU2 (fast searches, interpolation routines, etc.), but the trick is combining them all and making it general. Do you have any other requirements beyond simple probes? I am guessing we should have something available in the next few months, but it's not set yet.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/466#issuecomment-341623660:205,avail,available,205,https://su2code.github.io,https://github.com/su2code/SU2/issues/466#issuecomment-341623660,2,['avail'],['available']
Availability,"Hi all, . After the initial excitement of clearing all tabs and trailing whitespaces... I guess it is more reasonable to follow @pcarruscag proposal:; > What about running the solution you propose only on subfolders? i.e. on src/something/ . I now trimmed all `C*.cpp`, `C*.hpp` and `C*.inl` files in `SU2_CFD` which is equivalent to all restructured files in the Sub-folders. I added a basic script `replace-tabs-...sh ` in `externals/utils` which provides this functionality. I would enhance that script if this is the way to go.; The commit size now shrunk down to ~4k changed lines. Possible merge problems will be much smaller. . I found to have to no problem when merging the develop first -> clearing all tabs/whitespaces in the feature_branch with the provided script -> merge this develop_noWhitespaces using the `--strategy-option=ours` option. Merge conflicts will be purely due to tabs/whitespaces therefore one always wants the own code in case of conflict, as all conflicts with the develop related to other stuff were already resolved in the first merge. . Now that the commit is a lot smaller, there should be even less problems. Maybe some folks will have no problems at all. . After some back and forth in the commits I briefly chatted with @talbring to do a git rebase / squash to not have these huge commits in the history. Otherwise one could open a new & clean PR if we can agree on an approach here to keep the discussion in one place.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/808#issuecomment-553412130:560,down,down,560,https://su2code.github.io,https://github.com/su2code/SU2/pull/808#issuecomment-553412130,1,['down'],['down']
Availability,"Hi everyone,; I was tring to use the mesh adaptation feature but the whole procedure is not clear to me.; Following the previous indications I:. 1. downloaded the `feature_adapt branch`. 2. downloaded the Adaptive 2D NACA 0012 example (https://pyamg.saclay.inria.fr/pyamgexamples.html#2dnaca): `adap_NACA0012.cfg`, `mesh_NACA0012_inv.su2`, `NACA0012_ini.dat`. 3. added the following lines to the config:; ```; % Type of sensor used for adaptation; % Options include GOAL (adjoint-based), MACH, PRES; PYADAP_SENSOR= GOAL; % Objective function used for goal-oriented adaptation; OBJECTIVE_FUNCTION= LIFT; % Maximum cell size for adaptation; PYADAP_HMAX= 500.0; % Minimum cell size for adaptation; PYADAP_HMIN= 1e-9; % Gradation factor (typically 1.2-1.8); PYADAP_HGRAD= 1.8; % Norm used for adaptation; % 1.0 or 2.0 recommended for inviscid flows; % 4.0 recommeneded for viscid; ADAP_NORM= 4.0; % Approximate mesh size (NPOI) at each level; PYADAP_COMPLEXITY= (30000, 60000, 120000); % Number of adaptations performed at each level; PYADAP_SUBITE= (3, 3, 3); ```. 4. run the following command: `$ python3 SU2_RUN/mesh_adaptation_amg.py -f adap_ONERAM6.cfg -n 8`. The response I have obtained is the following:; ```; SU2-AMG Anisotropic Mesh Adaptation. Mesh adaptation options:; PYADAP_COMPLEXITY : (30000, 60000, 120000); PYADAP_SUBITE : (2, 2, 2); PYADAP_SENSOR : MACH; PYADAP_HMAX : 500.0; PYADAP_HMIN : 1e-9; PYADAP_HGRAD : 1.8; PYADAP_FLOW_ITER : (2999, 4999, 6999); PYADAP_ADJ_ITER : (2999, 4999, 6999); PYADAP_CFL : (10.0, 15.0, 20.0); PYADAP_RDG : NO. The ./adap folder was deleted. Generating GMF background surface mesh.; ## WARNING: MISSING SU2 MESH FILE KEYWORD: NCORNERS=.; Initial CFD solution is provided.; ```. As expected, a `./ADAP` folder was created, containing these docs: `amg_back_meshb`, `config_CFD.cfd`, `log.err`, `log.out` (sizes 0 byte), `mesh_NACA0012_inv.su2` (link to the mesh), `NACA0012_ini.dat` (link to the file.dat). Did I perform the procedure correctly? Or did I m",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/948#issuecomment-737134105:148,down,downloaded,148,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-737134105,2,['down'],['downloaded']
Availability,"Hi, ; thanks for this contribution, I will get a more detailed feedback soon. A first comment about the CSymmetricMatrix class came up to my mind, from a first brief review.; There is already a CSysMatrix class and a few routines added in this pull request look redundant (matvect product for instance).; On the other hand, many of those routines (cholesky decomposition and so on) could turn out to be very useful also for other future code developments.; That said, perhaps it would be nice to collect all the matrix-related routines into the CSymmetricMatrix class (removing redundancies) to make them available at an higher level. Cheers,; Giulio",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/555#issuecomment-406370798:262,redundant,redundant,262,https://su2code.github.io,https://github.com/su2code/SU2/pull/555#issuecomment-406370798,2,"['avail', 'redundant']","['available', 'redundant']"
Availability,"Hi,. Thank you for your quick answer, It indeed seems that I had some parameters that were passed that did not match su2 version 7.0.3. I am experiencing an issue while running the mesh adaptation process in SU2. The process starts but fails during the mesh generation phase, leading to a FileNotFoundError. I am looking for assistance in resolving this error.; `; SU2-AMG Anisotropic Mesh Adaptation. Mesh adaptation options:; PYADAP_COMPLEXITY : (100, 200, 300); PYADAP_SUBITE : (2, 2, 2); PYADAP_SENSOR : MACH; PYADAP_HMAX : 200; PYADAP_HMIN : 1e-8; PYADAP_HGRAD : 1.3; PYADAP_RESIDUAL_REDUCTION : (3, 3, 3); PYADAP_FLOW_ITER : (500, 500, 500). ./adap exists. Removing old mesh adaptation in 10s.; The ./adap folder was deleted. Generating GMF background surface mesh.; Initial CFD solution is provided. Starting mesh adaptation process. Iteration 0 - Mesh size coefficient 100.0; (1/2) Generating adapted mesh using AMG; AMG done: ; Running CFD; Traceback (most recent call last):; File ""/path/to/SU2/install/bin/mesh_adaptation_amg.py"", line 111, in <module>; main(); File ""/path/to/SU2/install/bin/mesh_adaptation_amg.py"", line 72, in main; options.save_all ); File ""/path/to/SU2/install/bin/mesh_adaptation_amg.py"", line 101, in mesh_adaptation_amg; SU2.run.amg(config); File ""/path/to/SU2/install/bin/SU2/run/amg.py"", line 466, in amg; os.rename(cur_solfil, cur_solfil_ini); FileNotFoundError: [Errno 2] No such file or directory: 'flo.dat' -> 'flo_ini.dat'`. and it0 folder is created, with some log.err and log.out, but they are empty, . I would appreciate any guidance or suggestions on how to resolve this issue. Thank you!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/948#issuecomment-1855842105:354,error,error,354,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-1855842105,1,['error'],['error']
Availability,"Hi,. This error simply occurs because the prototype of the CDriver (and child classes) has changed. There is an additional `bool val_periodic` argument that have to be passed. The current fsi_computation.py is not up-to-date. Here are solutions to fix that:. - Change the fsi_computation.py and pass an extra `False` argument between the number of dimensions and the communicator. or. - Do you need the very last develop branch ? Because it seems like in the master branch the constructor of the CDriver is still the compatible one. So you could use this branch without modifying anything. I hope this will help. Cheers,. David",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/531#issuecomment-388288297:10,error,error,10,https://su2code.github.io,https://github.com/su2code/SU2/issues/531#issuecomment-388288297,1,['error'],['error']
Availability,"I agree with the proposed changes, but I also think this could go farther. Some of the most common issues for users involve misuse of the *_ORDER options, dissipation coefficients, and limiters. Overall, it is still not very clear for a user how the centered schemes work. For instance, Lax is always first order and JST is always second order, but sometimes there are not error messages when trying to change the ""ORDER"" option when using these schemes. Also, if we rename the coefficients for JST as proposed, shouldn't we also separate the first coefficient that is only used for Lax? It would make treating the dissipation more clear.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/451#issuecomment-335205189:373,error,error,373,https://su2code.github.io,https://github.com/su2code/SU2/pull/451#issuecomment-335205189,1,['error'],['error']
Availability,"I am using Intel MPI as well, but on Ubuntu 18.04 and I get a clear error message. The likely reason why it hangs for you for this grid and not for the others is that this grid has an issue and the others do not. . Can you run it on one core of your supercomputer?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/683#issuecomment-493914393:68,error,error,68,https://su2code.github.io,https://github.com/su2code/SU2/issues/683#issuecomment-493914393,1,['error'],['error']
Availability,"I haven't looked at the python wrapper in detail, we had previously tracked several properties which are not available in the conventional convergence tracker (such as Cmy) and used the stop file to obtain the data when appropriate. We have considered increasing the save frequency, but there are several files which are not created at every save point; thereby forcing each ""standard"" run to become a ""run to nearest save"" then ""resume for 1 time-step to get the actual output data"". As the decomposition and some of the file writes take a significant amount of time, it is a non-starter for commercial applications. We would switch back to v6 (which had the capability) but we need some of the other features in v7. I'll take a look at the python wrapper. Thank you for your candor.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1304#issuecomment-862344695:109,avail,available,109,https://su2code.github.io,https://github.com/su2code/SU2/issues/1304#issuecomment-862344695,1,['avail'],['available']
Availability,"I just found [a blog post](https://codingnest.com/the-future-of-catch2/) on the future directions of Catch2. There's a couple of important points for our discussion. The developer plans to adopt a hybrid approach, with:. 1. A stripped-down, header-only version.; 2. A full-feature, typical library (i.e. it must be compiled and linked). This approach is very similar to Boost's setup. Google Test does not offer a header-only version. Additionally, the developer plans to drop C++11 support, and move to C++14. A simpler branch will still support C++03. It's not clear which features are supported in the C++03 variant, and which ones aren't. Google Test is also moving to support only C++11 in their next release, but their current release fully supports pre-C++11. All of this discussion raises the question: Do we want to require C++11 for unit tests?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-500411194:235,down,down,235,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-500411194,1,['down'],['down']
Availability,"I know that it can be frustrating sometimes operating within the constraints of an open-source project such as ours. However, I can assure you that folks do indeed care about performance, and sometimes I have the impression that we stress over relatively small performance issues (remember to keep the total pie chart of where the major work of the solver resides in mind). . The option WRT_PERFORMANCE= YES is available to get timings for runs broken down by preprocessing, compute, and output phases, and I think we should focus our performance concerns first on issues within the compute phase, unless a major bottleneck appears in the other two phases that completely prohibits us from running larger cases (we have been clearing many of those out lately). We do not have the resources of a professional software company, but what we do have is a great community of folks who are putting in lots of effort on a volunteer basis. @pcarruscag: your reviews have been very helpful for improving contributions - thank you for that effort. Let's keep supporting each other, but let's also make sure we stay positive and foster a welcoming environment to encourage more participation.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/724#issuecomment-534682406:411,avail,available,411,https://su2code.github.io,https://github.com/su2code/SU2/pull/724#issuecomment-534682406,2,"['avail', 'down']","['available', 'down']"
Availability,"I noticed the addition of the Guide to V7 page being introduced to the SU2 page. I think this would make a great starting point to beef up our documentation/tutorial pages. Using a similar format, we could discuss the available options in SU2. Speaking from experience, new SU2 users face an extremely high learning curve, often scaring them away. I believe this would help alleviate that problem. I understand this is no small task, and welcome others thoughts on the issue",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/775#issuecomment-536031012:218,avail,available,218,https://su2code.github.io,https://github.com/su2code/SU2/issues/775#issuecomment-536031012,1,['avail'],['available']
Availability,"I simple wrote a program to test the grid, which searches for the boundary elements in the single faces, i.e. faces that are only part of one volume element, of the volume grid. What the error message means is that for 4 triangular surface elements of boundary marker BODY there is no corresponding face of the volume elements that is only part of one volume element. . When I include the faces that are shared by two volume elements, only two boundary elements are not found. So in short, you have two boundary elements in boundary marker BODY that are no part of any volume element and two boundary elements that are shared by two volume elements.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/683#issuecomment-494675549:187,error,error,187,https://su2code.github.io,https://github.com/su2code/SU2/issues/683#issuecomment-494675549,1,['error'],['error']
Availability,"I suggest that you incorporate Wray-Agarwal (WA) one equation RANS model listed on NASA TMR in SU2. NASA is planning to list two equation WA-gamma transition model on NASA TMR next month. WA model is available on Github and WA model will also be posted on Github as source code. If you need any additional information or help, let me know.; Ramesh Agarwal; ________________________________; From: Pedro Gomes <notifications@github.com>; Sent: Wednesday, January 6, 2021 10:13 AM; To: su2code/SU2 <SU2@noreply.github.com>; Cc: Agarwal, Ramesh <rka@wustl.edu>; Comment <comment@noreply.github.com>; Subject: Re: [su2code/SU2] Info on current status of LM transition model in SU2 (#1130). @lorenzob95<https://github.com/lorenzob95> we talked about this issue in our weekly developers meeting.; The current implementation of LM in the code is not stable enough and it has known bugs, so we will not re enable it for now.; A revised implementation by @vdweide<https://github.com/vdweide> exist in branch https://github.com/su2code/SU2/tree/feature_LM_model, but this is based on SU2 v6.2, it has been used on simple problems, convergence is not ideal on more complicated ones.; The decision is to wait for some developments that will make it easier to bring this revised implementation into version 7 (which is different in many ways from 6).; You can follow this issue to know when this gets implemented, it will probably take a few months. —; You are receiving this because you commented.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/1130#issuecomment-755395168>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/ASK3WAEG3LW3AZJRUPORJPDSYSD2VANCNFSM4UVYXAAA>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1130#issuecomment-755440165:200,avail,available,200,https://su2code.github.io,https://github.com/su2code/SU2/issues/1130#issuecomment-755440165,1,['avail'],['available']
Availability,"I tend to agree w Eran on this topic. When it is working as it should, it is very convenient to have the makefiles already available in the repo. I switch between Mac, Ubuntu, and a red hat cluster without needing to update anything or call the bootstrap script. I rarely use it.. basically only when adding or removing files to the build. Also, it is good to minimize dependencies, as sometimes old machines or clusters have limited tool sets. But, clearly we should at a minimum fix the issue that some of you are finding with the autotools, which should just need an update. What systems are you having trouble with? It’s important that we don’t jump too far ahead for portability reasons (that’s why we have kept the old versions for so long). Do you have an idea of the minimum autotools you need for the failing systems? We could start by updating to that version and see if things stabilize.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/586#issuecomment-424210049:123,avail,available,123,https://su2code.github.io,https://github.com/su2code/SU2/pull/586#issuecomment-424210049,1,['avail'],['available']
Availability,"I totally agree. On real meshes, Omega usually drops to extremely low values. In cases where the cross-diffusion term is negative (allowed to be negative), it behaves as a sink term, further amplifying the drop of Omega. A simple addition of this term to the implicit diagonal is insufficient (I tried this). Other more rigorous methods are required (some available in the open literature). . My main argument is that the factor (1-F1) guarantees only the k-epsilon branch outside the boundary layer, in which the cross-diffusion term is already positive. It may not be so because of numerical errors.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/2329#issuecomment-2253297698:356,avail,available,356,https://su2code.github.io,https://github.com/su2code/SU2/pull/2329#issuecomment-2253297698,2,"['avail', 'error']","['available', 'errors']"
Availability,"I'll try to break down each request to make it clearer. Request: Use nomenclature consistent with the C++ interface (point instead of node, etc.); Reason: People who know the C++ interface will know how to use the python wrapper straight away, people who learn how to use the python wrapper will be able to understand the C++ implementation (without needing a translation layer in their mind all the time). Request: Return connectivity/adjacency as local indices instead of global; Reason: This is the natural way of referencing data in an MPI code, local indices correspond directly to data stored in the partition thereby making it more efficient to access (without global-to-local conversions, which are much more expensive than local-to-global). Furthermore, the local ordering strategy improves the efficiency of loops (over edges, neighboring points, etc.). Request: Do not apply unnecessary ""transformations"" to the connectivity/adjacency as part of the API; Reason: Increases the maintenance burden and makes for a less versatile API. By returning the local indices that form a marker or element, it is trivial to retrieve any other data for those indices (the ""transformation""). For example, the solution at those points, the point coordinates, whether the points are halo or domain points, the global indices, etc.; This way, by adding a **single** function to the API e.g. get the global index of a point of element, the functionality of the API grows a lot more because the user can apply the function to **any** connectivity/adjacency function. Request: Do not offer too many overloads of the same function; Reason: Increases the maintenance burden and it's returning the data in structures that are not very efficient, namely vector of vectors. It is much easier to offer domain-wide data access on the python side, as a very small function that can be part of wrapper utilities (i.e. live only in python but not c++). It may even be more efficient since you make a numpy array/matrix in",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1300#issuecomment-1402197827:18,down,down,18,https://su2code.github.io,https://github.com/su2code/SU2/pull/1300#issuecomment-1402197827,2,"['down', 'mainten']","['down', 'maintenance']"
Availability,"I'll weigh in with a more in depth answer on a second email, but yes I've; found great value in being able to have a good set of unit tests. Particularly when you don't have good acceptance tests (hard in a fast; moving research code), it gives a developer confidence that new changes; aren't being fundamental assumptions in the code. It lets sub module; developers build ""armor"" around those assumptions. It is a bit of a cultural thing. People who want robust bits write more.; Some people wire less. At the bank I once worked at, unit tests were required for every module.; Some people wrote code that tested almost nothing. And it would get; through code review that way. Eventually, I added coverage analysis to the check in that exposed this; practice that gave a false assurance that things were ok. More when I can think a bit more on this and get to a real keyboard!. Pat. On Wed, Jun 5, 2019 at 1:50 PM Juan Jose Alonso <jjalonso@stanford.edu>; wrote:. > Clark,; >; > Thanks for putting this idea out there. In my experience, unit testing; > has been an intrinsic part of the the modus operandi in many multi-physics; > codes at DoE and has been well worth the additional effort. In cases where; > it makes sense (as described by Clark and in the Stack Exchange discussion); > I would advocate for using it moving forward. There may also be some; > issues that arise multiple times in existing code where a retroactive; > application of unit testing may also make sense. I am copying Pat Miller,; > formerly with DoE, who may have more experience on whether such unit; > testing approaches were useful/worth the investment in some major codes he; > worked on.; >; > Best,; >; > Juan; >; >; > On Jun 4, 2019, at 2:14 PM, Clark Pederson <notifications@github.com>; > wrote:; >; > I propose adding a unit-testing framework and unit-tests to SU2. After; > chatting with @economon <https://github.com/economon>, I've decided to; > move the discussion here to get additional input.; > What is uni",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499278427:456,robust,robust,456,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427,1,['robust'],['robust']
Availability,"If you look at the testing history, commit 4f5f3ed doesn't pass the regression tests, while commit 8551cac does. Only two tests are failing on 4f5f3ed: `discadj_topol_optim` and `discadj_fsi_airfoil`. The difference between the two commits is a simple change. I changed the `SU2_MPI::Error` routine to give a return status of `EXIT_FAILURE` instead of `0`. Since `0` is conventionally defined as a successful program exit, returning `EXIT_FAILURE` makes more sense than returning `0` when `SU2_MPI::Error` is called. So why did that change cause the regression tests to fail? My suspicion is that these two tests have been exiting with an error for some time, but these regressions were not picked up by Travis since SU2 kept on returning `0` (i.e. success). Changing the exit code of `SU2_MPI::Error` doesn't cause any errors, but it will expose errors that are (sometimes silently) occurring. @pcarruscag I think you added these tests. Any idea why they're failing?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/649#issuecomment-462951152:639,error,error,639,https://su2code.github.io,https://github.com/su2code/SU2/pull/649#issuecomment-462951152,3,['error'],"['error', 'errors']"
Availability,"It seems like your situation may have been resolved, but for archival purposes, I'll list my workaround here. This problem occurs when you've installed python packages in two different locations. This could be due to installing some python packages in a system directory (e.g. `/usr/lib/`) and some in a user directory (e.g. `~/.local/`). SU2's build process is set to automatically detect the default package location, but it's not equipped to handle multiple package locations. There are some hardcoded includes, but these only work for python 2.7. I don't consider this a bug *per se* because multiple python package directories is not a standard use case. #### The symptoms. When building SU2 with the python wrapper you'll see the following error during the swig build:; ```; <install directory>/../SU2_PY/pySU2/pySU2.i:64: Error: Unable to find 'mpi4py/mpi4py.i'; ```; But mpi4py is indeed installed on your system and it's on your python path, as confirmed by opening a python terminal and running `import mpi4py`. #### The easiest workaround. Switch to a [virtualenv](https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/). This will ensure that all of your python packages are stored in single location. #### Alternate workaround. In this method, you change the hardcoded includes to match mpi4py's package location. First I figure out where my mpi4py is installed. I start a terminal session of python using the python environment I want to use (in this case, it's python 3.6), and then run:; ```; from mpi4py import MPI; MPI; ```. Since I have mpi4py installed on your system and it's on my python path, I see something like:; ```; <module 'mpi4py.MPI' from '/home/clarkpede/.local/lib/python3.6/site-packages/mpi4py/MPI.cpython-34m.so'>; ```. The `/home/clarkpede/.local/lib/python3.6/` directory is where my mpi4py package is installed. But the swig compile command includes `/home/clarkpede/.local/lib/python2.7/`. That's not the right directory! So first I ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/722#issuecomment-515693590:746,error,error,746,https://su2code.github.io,https://github.com/su2code/SU2/issues/722#issuecomment-515693590,1,['error'],['error']
Availability,"LGTM. Thanks for the fix and updating all regressions, @TobiKattmann . Final question: in the end, the Euler and symmetry BCs are identical implementations, so do we have a practical guideline for when to use one or the other (or some error check), or will we just carry both and allow them to be used interchangeably?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/740#issuecomment-536752462:235,error,error,235,https://su2code.github.io,https://github.com/su2code/SU2/pull/740#issuecomment-536752462,1,['error'],['error']
Availability,"Nice progress @pcarruscag!. I like the concept of your SIMD-friendly class that will take care of the data structure under the hood coupled with a standard type of loop statement (w/ +SIMDLEN). This should make it pretty easy for folks to still modify the kernels without having to worry about the data alignment, and they can reuse the same simple 'for' construct repeatedly. . Another reason to have our own lightweight class for this is that you can avoid dependence on OpenMP for SIMD (although that feature looks to have potential and wasn't available until somewhat recently) as well as the intrinsics. In my experience, the latter is especially bad for portability and readability (part of why we left the CaF work in a separate repo). It starts to become so specialized that compiling and modifying become difficult. W.r.t. OpenMP, another roadblock there a few years ago was making sure it is interoperable with CoDi for the adjoint, but I know this has been worked on and may be available by now. Might keep an open mind about point vs. edge. In some places, we may be able to pump up the compute in our loops by fusing kernels, as previously discussed (and I am guessing you are working on this already with gradients/limiters). Could change the final performance numbers significantly. Lastly, I know you are not there yet, but it is worth considering whether you can reuse anything you are developing in the kernels here for the linear solver routines. At some point, you will successfully reduce the cost of the residual kernels (RHS) to the bandwidth limit, and the majority of the iteration cost will be in the linear solver (it is already about 50% of the iteration cost before optimization, if I recall). Before making final decisions on strategy, you should consider if it will help in any of the linear solver routines too.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-530440072:547,avail,available,547,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530440072,2,['avail'],['available']
Availability,"No… I can’t. I’m sorry. Great to hear from you. Machine learning is a very valuable research work and I will add it as a feature branch. . Removing code from the main release is a complex task and, as in the past, I have taken tough decisions. Anyway, to maintain a clean code is critical for its growing, it is like trimming a large tree. Basic criteria to maintain forever an implementation on the develop->master branch are: - Clear benefit to the CFD community (more accurate, robust, etc.) - Existing community of users or active developers - Minimal code documentation (at least the options should be in the config file). - Easy to install and use. - The implementation style should be aligned with the SU2 style - Regressions tests. Best,; Francisco. > On Oct 28, 2015, at 11:35 PM, Brendan Tracey notifications@github.com wrote:; > ; > Could you leave in the machine learning section a bit longer?; > ; > —; > Reply to this email directly or view it on GitHub https://github.com/su2code/SU2/pull/208#issuecomment-152095697.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/208#issuecomment-152384158:481,robust,robust,481,https://su2code.github.io,https://github.com/su2code/SU2/pull/208#issuecomment-152384158,1,['robust'],['robust']
Availability,"Ok, I went back to try varying the `.cfg` settings on the simple v7.0.3 repo `TestCases/euler/naca0012` case and managed to get `mesh_adaptation_amg.py` to run successfully. It seems that one bit of advice [from here](https://www.cfd-online.com/Forums/su2/214613-grid-adaptation-options.html) is no longer true, i.e. one needs to set:; ```; % Write binary restart files (YES, NO); WRT_BINARY_RESTART= YES; %; % Read binary restart files (YES, NO); READ_BINARY_RESTART= YES; ```; in order for the amg mesh adaptation to function. However, for some reason, I can't get it working for my actual mesh of interest. When using the same settings, I get a different ParMETIS error (from the `adap/ini/log.out`):; ```; ------------------- Geometry Preprocessing ( Zone 0 ) -------------------; Three dimensional problem.; 4929018 grid points before partitioning.; 7406196 volume elements before partitioning.; 3 surface markers.; 18040 boundary elements in index 0 (Marker = BODY).; 50968 boundary elements in index 1 (Marker = FARFIELD).; 284054 boundary elements in index 2 (Marker = SYMMETRY).; Executing the partitioning functions.; Building the graph adjacency structure.; [ 1] ***ASSERTION failed on line 207 of file ../externals/parmetis/libparmetis/comm.c:sendind[i] >= firstvtx && sendind[i] < lastvtx; [ 1] 361316 123226 246452; [1609857970.901920] [super:1060888:0] sock.c:344 UCX ERROR recv(fd=62) failed: Connection reset by peer; ```. The only difference that I can think of is that my flow is fully supersonic and my mesh is an unstructured core with a structured collar - might this be causing the issue? Kind regards.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/948#issuecomment-754686447:667,error,error,667,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-754686447,1,['error'],['error']
Availability,"Ok. Thanks for the reply. If it's not simple to separate into a branch, don't worry. I have already downloaded the current master and can maintain a local copy. I see that there is at least one issue related to that segment (I would have responded had I seen it). Are users interested in using that segment of the code? If so, I'd be more than happy to add documentation and a usage example I the develop branch. When thus code went live we decided it was better to not add documentation since the feature is experimental. This is certainly a fixable situation on the develop branch.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/208#issuecomment-152404327:100,down,downloaded,100,https://su2code.github.io,https://github.com/su2code/SU2/pull/208#issuecomment-152404327,1,['down'],['downloaded']
Availability,"On the subject of virtual functions I would like to put another idea forward.; After moving things around in #725 I noticed that we have tons of `inline virtual` methods.; The keyword `inline` has two meanings to the compiler:; - ""Dear merciful compiler please copy paste the body of this function and then do all your wonderful optimizations, if that pleases your excellency.""; - ""Dear forgiving compiler, you will find this method defined in multiple units, please don't be mad"" (i.e. ignore the one-definition-rule). `virtual` means determine what version of the method to call at runtime. This is not compatible with the first (and often the intended one) meaning of inline, therefore the compiler will in general not inline those methods.; They will only be inlined if they are being called on a pointer to the derived class that does not declare the method to be virtual anymore. CSolver knows what variables it creates and so in hot areas of the code it could do a static downcast to allow inlining (e.g. `static_cast<CEulerVariable*>(node[iNode])->DoStuff()`).; Where is this important? For example when computing gradients, where simple additions and subtractions are hidden behind virtual functions.; If you are worried about maintenance each solver can typedef its most safe downcast level or better yet (or just more modern), methods that could benefit from this can be templated for the type of downcast.; Those in favour say Yea those against say Nay.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/716#issuecomment-509273008:979,down,downcast,979,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-509273008,4,"['down', 'mainten']","['downcast', 'maintenance']"
Availability,Problem solved. Script Workshop now. Just a simple DOS/Windows-Unix fileformat error. -.-,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/279#issuecomment-222963559:79,error,error,79,https://su2code.github.io,https://github.com/su2code/SU2/issues/279#issuecomment-222963559,1,['error'],['error']
Availability,"Python's ""self"" which; // makes this solution reasonably idiomatic.; Base::Compute(wv, sol);. // Then do our specific job.; wv.area = 0.0;; for(int i=0; i<nDim; ++i); wv.area += pow(sol.areaVector[i],2);; wv.area = sqrt(wv.area);; }; };. // Same mechanics as above; template<typename Base>; class ComputeFlux : Base; {; protected:; enum : int {nDim = Base::nDim};. struct WorkVarsType : Base::WorkVarsType ; {; double flux; // ...add new member; };. template<typename WV>; void Compute(WV& wv, const SolutionContainer& sol) const; {; // ...call base; Base::Compute(wv,sol);. // ...do aditional work; wv.flux = 0.0;; for(int i=0; i<nDim; ++i); wv.flux += sol.velocity[i]*sol.areaVector[i];; }; };. // This class is used to terminate the chain, it makes the link; // with the interface and it is used to specify any fixed sizes.; template<int NDIM>; class Terminator : private VirtualInterface; {; protected:; enum : int {nDim = NDIM};. struct WorkVarsType {};. template<typename... Ts>; void Compute(Ts&...) const {}; };. // Finally we use the building blocks to implement Compute.; // The blocks can be reordered depending on application to; // help the compiler fuse loops or minimize register spillage,; // the resulting WorkVarsType definition will be equivalent.; class ComposedClass: public; ComputeFlux< ComputeArea< Terminator<3> > >; {; public:; ResultType Compute(const SolutionContainer& sol) const;; };. ResultType ComposedClass::Compute(const SolutionContainer& sol) const; {; // Create the working variables on the stack.; ComputeFlux::WorkVarsType wv;. // Pass down the working variables and whatever other arguments.; // If the convention was followed, all building blocks will run.; // Recall that all Compute's were templates, they will be; // instantiated here and we can force them to be inlined.; ComputeFlux::Compute(wv, sol);. // Do some additional work if needed and return result.; return wv.flux / wv.area;; }; ```; [Care for some assembly?](https://gcc.godbolt.org/z/os-gNg)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-622941617:5184,down,down,5184,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-622941617,1,['down'],['down']
Availability,"Reviving the parsing script can be a simple and effective solution for syncing the defaults.; I shall be out of the country for the next three weeks. I shall try my hand at your suggestion once I return. Meanwhile, I hope the current PR will complete its approval cycle. Current Travis failures are marked by ! only.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/520#issuecomment-377499319:286,failure,failures,286,https://su2code.github.io,https://github.com/su2code/SU2/pull/520#issuecomment-377499319,1,['failure'],['failures']
Availability,"SIGNED_INT 4; | #define SIZEOF_LONG_INT 8; | #define SIZEOF_FLOAT 4; | #define SIZEOF_DOUBLE 8; | #define SIZEOF_VOID_P 8; | /* end confdefs.h. */; | #include <stdio.h>; | #ifdef HAVE_SYS_TYPES_H; | # include <sys/types.h>; | #endif; | #ifdef HAVE_SYS_STAT_H; | # include <sys/stat.h>; | #endif; | #ifdef STDC_HEADERS; | # include <stdlib.h>; | # include <stddef.h>; | #else; | # ifdef HAVE_STDLIB_H; | # include <stdlib.h>; | # endif; | #endif; | #ifdef HAVE_STRING_H; | # if !defined STDC_HEADERS && defined HAVE_MEMORY_H; | # include <memory.h>; | # endif; | # include <string.h>; | #endif; | #ifdef HAVE_STRINGS_H; | # include <strings.h>; | #endif; | #ifdef HAVE_INTTYPES_H; | # include <inttypes.h>; | #endif; | #ifdef HAVE_STDINT_H; | # include <stdint.h>; | #endif; | #ifdef HAVE_UNISTD_H; | # include <unistd.h>; | #endif; | #include <X11/Intrinsic.h>; configure:5409: result: no; configure:5409: checking X11/Intrinsic.h presence; configure:5409: gcc -E conftest.c; conftest.c:28:27: error: X11/Intrinsic.h: No such file or directory; configure:5409: $? = 1; configure: failed program was:; | /* confdefs.h */; | #define PACKAGE_NAME ""SU2""; | #define PACKAGE_TARNAME ""SU2""; | #define PACKAGE_VERSION ""4.1.0""; | #define PACKAGE_STRING ""SU2 4.1.0""; | #define PACKAGE_BUGREPORT ""su2code-dev@lists.stanford.edu""; | #define PACKAGE_URL ""https://github.com/su2code""; | #define PACKAGE ""SU2""; | #define VERSION ""4.1.0""; | #define STDC_HEADERS 1; | #define HAVE_SYS_TYPES_H 1; | #define HAVE_SYS_STAT_H 1; | #define HAVE_STDLIB_H 1; | #define HAVE_STRING_H 1; | #define HAVE_MEMORY_H 1; | #define HAVE_STRINGS_H 1; | #define HAVE_INTTYPES_H 1; | #define HAVE_STDINT_H 1; | #define HAVE_UNISTD_H 1; | #define SIZEOF_SHORT_INT 2; | #define SIZEOF_INT 4; | #define SIZEOF_UNSIGNED_INT 4; | #define SIZEOF_LONG_INT 8; | #define SIZEOF_FLOAT 4; | #define SIZEOF_DOUBLE 8; | #define SIZEOF_VOID_P 8; | /* end confdefs.h. */; | #include <X11/Intrinsic.h>; configure:5409: result: no; configure:5409: check",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:14210,error,error,14210,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,1,['error'],['error']
Availability,"SU2/commit/ac8b3bf7636cc66ca7f47e15935942a6598e1a9f), the `SetRoe_Dissipation` function checked to see if the sensor values were valid regardless of the type of blending selected. Commit [ac8b3bf](https://github.com/su2code/SU2/commit/ac8b3bf7636cc66ca7f47e15935942a6598e1a9f) changed the behavior to only check the sensor values if they will be used. The unit test sets the convective blending to `NTS`, feeds invalid sensor values into `SetRoe_Dissipation` and checks the output. ```cpp; // Used to set the Roe-low-dissipation option; void WriteCfgFile(unsigned short nDim, const char* filename,; std::string blending) {; std::ofstream cfg_file;. cfg_file.open(filename, ios::out);; cfg_file << ""PHYSICAL_PROBLEM= NAVIER_STOKES"" << std::endl;; cfg_file << ""ROE_LOW_DISSIPATION= "" << blending << std::endl;. cfg_file.close();; }. BOOST_AUTO_TEST_CASE(BadSensorsAllowedForNTS) {. /*--- Setup ---*/. const unsigned short nDim = 3;. /*--- Set up the config class for the test ---*/; char cfg_filename[100] = ""convective_blending_test.cfg"";; WriteCfgFile(nDim, cfg_filename, ""NTS"");; CConfig* config = new CConfig(cfg_filename, SU2_CFD, 0, 1, 2, VERB_NONE);; std::remove(cfg_filename);. /*--- Inputs ---*/; const su2double dissipation_i = 0.4;; const su2double dissipation_j = 0.6;; const su2double sensor_i = NAN; // Intentionally unphysical:; const su2double sensor_j = NAN; // Intentionally unphysical:. /*--- Outputs ---*/; su2double dissipation;. /*--- Test ---*/. CNumerics numerics;; numerics.SetRoe_Dissipation(dissipation_i, dissipation_j,; sensor_i, sensor_j,; dissipation, config);. const su2double tolerance = std::numeric_limits<su2double>::epsilon();; BOOST_CHECK_CLOSE_FRACTION(dissipation, 0.5, tolerance);. /*--- Teardown ---*/; delete config;; }; ```. There's a couple problems I would fix if I had more time. Ideally, I would be writing the cfg file to an in-memory stream and not to a file. And realistically, I shouldn't need to use a config file at all for a simple test like this.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499999225:1926,toler,tolerance,1926,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499999225,2,['toler'],['tolerance']
Availability,"Simplest is to just copy the saved file again, with an iteration number appended. No keeping track of what the iteration number at the previous write was, no copying of the final saved file with manually appending the final iteration number, no lag of WRT_FREQ in the availability of the restart_xxx.dat file. It does mean that we do a copy instead of a rename. But I think this is the better (because the simplest) solution. I will extend it to the other file options.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1465#issuecomment-1005529868:268,avail,availability,268,https://su2code.github.io,https://github.com/su2code/SU2/pull/1465#issuecomment-1005529868,1,['avail'],['availability']
Availability,"Sounds good, with that it will be easier to reason about when the recording types are created and used, right now someone would have to sit down and reverse-engineer the process.; My intuition is that we can use some of the machinery introduced for multizone (partial tape evaluation) to simplify the recording management.; And just to be clear I am very interested in having this feature in the code for comparison with the FP approach.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1750#issuecomment-1780662970:140,down,down,140,https://su2code.github.io,https://github.com/su2code/SU2/pull/1750#issuecomment-1780662970,1,['down'],['down']
Availability,"Sure; If you want to install Su2 version 7.0.0 from scratch, you need python 3.5; atleast; The installation guide says just python 3; One of the functions used in meson.py is only available in python 3.5. On Mon, Feb 3, 2020, 12:51 AM Tim Albring <notifications@github.com> wrote:. > Thanks for opening the issue. Can you give a little bit more details on; > what you mean exactly ?; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/issues/855?email_source=notifications&email_token=AIENZ3WCJDNJV4LP655MB33RA7LI5A5CNFSM4KNO4QLKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEKS7V6I#issuecomment-581303033>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AIENZ3TDY7ZCOS27JO7IYXTRA7LI5ANCNFSM4KNO4QLA>; > .; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/855#issuecomment-581453436:180,avail,available,180,https://su2code.github.io,https://github.com/su2code/SU2/issues/855#issuecomment-581453436,1,['avail'],['available']
Availability,Thank you for the feedback but for 99% of cases it is easier for users if we download the dependencies for them. The philosophy behind SU2 has always been to provide as much of a self contained package as possible.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1945#issuecomment-1450323672:77,down,download,77,https://su2code.github.io,https://github.com/su2code/SU2/issues/1945#issuecomment-1450323672,1,['down'],['download']
Availability,"Thanks Edwin, the vectorized loops in the code are probably very simple array copies, hence the low efficiency? I would put money on not a single vector instruction being generated for the important stuff. I was surprised by the 1.25 to 1.3 factor you are seeing, for the exact same case I measured 1.39 (to be more precise). Initially I thought it had something to do with running single core, thus leaving vast amounts of L3 for only that core to use, so on the same 24c platform I ran 2 processes (30MB of cache for each) (very uncivilised) and the factor went down to 1.37, so cache was not the reason.; So then I thought maybe the Intel compilers are very good at optimizing polymorphism away, but the development branch compiled with icc 17 runs at exactly the same speed as when compiled with gcc 5.4. Then I compiled feature_contiguous_cvariable with icc 17 and it runs 9% slower than the gcc binaries, and so with icc 17 the speedup for this case was 1.27 errrrr... Anyone got a buddy at Intel?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/716#issuecomment-523930905:564,down,down,564,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-523930905,1,['down'],['down']
Availability,Thanks for the improvements! Just a quick suggestion: maybe we should use for the distance computation the already available ADT structure ? Just have a look at CPhysicalGeometry::ComputeWall_Distance on how to use it. Should be more or less a simple copy/paste.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/444#issuecomment-331841826:115,avail,available,115,https://su2code.github.io,https://github.com/su2code/SU2/pull/444#issuecomment-331841826,1,['avail'],['available']
Availability,"The motivation of having it as the default was to make the code as user-friendly as possible (fewer knobs exposed in the config), but options are good of course. I would propose then that we add an option for the reconstruction gradient, something like:; ```; NUM_METHOD_GRAD_RECON= LEAST_SQUARES; ```; to let users decide if they want a separate option for the reconstruction gradients. If it does not appear, then the default is to use the same method as defined by NUM_METHOD_GRAD without a second gradient computation (basically what we have now). The nice thing about that is we can even try out other combos such as WLS+GG for the two different gradients. I will throw an error if users try to use LSQ for the viscous/source gradients, to avoid accuracy issues. What do you think?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/790#issuecomment-533259202:678,error,error,678,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-533259202,1,['error'],['error']
Availability,"There was a lot of talk about refactoring the shape optimization framework to be able to work completely in memory.; I think the idea was not to have more drivers but simply to have more granularity such that you could manipulate the geometry from python (without writing it to files).; We also wanted introspection, i.e. you could probe SU2 via python for what variables and functions are available.; We also talked about having the projection step (DOT) included in CFD_AD so that you only need to worry about surface sensitivities, note that DEF is already part of CFD for forward mode AD.; (talking does not go very far). If you want to lead this work, we can help you understand the inner workings. We meet every Wednesday at 4pm CET https://meet.jit.si/SU2_DevMeeting to discuss this type of issue.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1262#issuecomment-818786416:390,avail,available,390,https://su2code.github.io,https://github.com/su2code/SU2/issues/1262#issuecomment-818786416,1,['avail'],['available']
Availability,"These timings were all run this morning on the same cluster. . Using qperf, I'm seeing 80 microsecond latency. I'm also seeing the expected bandwidth using qperf as well. I would think that mpi would behave similarly but 100% sure. . I'm quite sure that the jobs are being launched correctly. I've checked that a bunch of times since that was my first instinct. I've both logged into all the machines and watched top and everything looked normal. And I've tried running SU2 v6 before and after v7, launching them the same way, and I keep getting the same numbers. I'm not sure how to check whether there is any reason non blocking comm would be ineffective. If you have any ideas I can certainly try something. I tried to download vampirtrace which seemingly can profile mpi, but it failed to compile against my version of mpi. When I get the chance I can try a different version of openmpi and see if I can get it running. The networking setup is pretty simple with all 4 machines plugged into the same switch and they share their own vlan as part of a bigger network. As I said, I ordered some faster networking equipment to see if it makes a difference (though I'm honestly not 100% sure that what I ordered will work with my comps but we'll see.)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/894#issuecomment-593144776:722,down,download,722,https://su2code.github.io,https://github.com/su2code/SU2/issues/894#issuecomment-593144776,1,['down'],['download']
Availability,"This one is all set after a little more cleanup. I left some low-level changes to the EoS models for later. @CatarinaGarbacz @MarcoFossati : we can use a simple directory name, as you suggest. Let's just go with fluid/ since we also treat liquids with the incompressible solver. Bonus: adds a rotating frame calculation test and some extra error checks on CFL adapt params that should help avoid unreported problems with old configs.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1010#issuecomment-640170715:340,error,error,340,https://su2code.github.io,https://github.com/su2code/SU2/pull/1010#issuecomment-640170715,1,['error'],['error']
Availability,"Todo list:; - [x] Make sure the code can handle arbitrary many species equtions. Especially the output has to be adapted. Note the MAXNVAR of the ScalarSolver has to adapted to that need as well. Make a suitable Testcase for that.; - [x] Implement weak inlet and outlet BC. The weak approach is used in the turb and mean flow and is most likely conservative opposed to the strong one. Here a simple switch will be put in place to compare both versions.; - [x] Consolidate nVar, nSpecies, ... variable to only use 1 consistently (The choice was `nSpecies` which was already introduced for NEMO and it just makes sense to use the same container); - [x] Make the numerous reviewers happy; - [x] Check inlet profiles for Species solver (have a testcase for that) See #1427 ; - [x] Create Objective functions of Surface avg quantities (Area and Massflow? prob. And a variance-style output to capture mixing); - [x] Avoid redundant operations (pre/post processings) during solver restarts. 156d0c5. What will be done in follow-up PR's:; - Viscous contributions for BC_inlet and outlet which are currently not used (also then for Turb-solver) https://github.com/su2code/SU2/pull/1388#discussion_r752384956; - Axissymmetric source term addtion and testing; - multi-component mixing from #1332 ; - gradient validation between DA and FD",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1388#issuecomment-935901996:916,redundant,redundant,916,https://su2code.github.io,https://github.com/su2code/SU2/pull/1388#issuecomment-935901996,1,['redundant'],['redundant']
Availability,"We are wondering what the status with the merge request is. Am I supposed to do something more? is it just waiting for an additional review? . Additionally, we have many more proposed modifications, we have worked on, adding robustness to the existing turbulence models. It is expected, many of these changes will effect the test cases behaviour, are there any guidelines how to compile the code to run the full set of tests locally, or should I just open pull requests, and base upon the github test results? ; ; I am sorry if I may be asking the obvious, but I am new to contributing to open code..",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/2295#issuecomment-2219624152:225,robust,robustness,225,https://su2code.github.io,https://github.com/su2code/SU2/pull/2295#issuecomment-2219624152,1,['robust'],['robustness']
Availability,"What advantages does meson provide over Cmake? I have experience with CMake, but not with meson. @talbring I'm not sure what you mean by ""the syntax is also not very comfortable and it has too many features which we actually don't need."". I recently did a survey of the some of the most popular open-source C++ libraries, both inside and outside and outside of scientific computing. The most popular build system was CMake (60% of the 15 open source libraries). If ""everyone else"" is using CMake, then why should we use meson? I'm not trying to be adversarial. I'm curious about why meson is better. Is the syntax simpler? Is meson more flexible? Is it more robust during changes? Is it faster?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/685#issuecomment-498827230:658,robust,robust,658,https://su2code.github.io,https://github.com/su2code/SU2/issues/685#issuecomment-498827230,1,['robust'],['robust']
Availability,"When I enter the ""shape_optimization.py -f unsteady_naca0012_opt.cfg"" in the commend the error is:; ```; Traceback (most recent call last):; File ""C:\Users\74351\Desktop\SU2\SU2\bin\test2\shape_optimization.py"", line 116, in <module>; main(); File ""C:\Users\74351\Desktop\SU2\SU2\bin\test2\shape_optimization.py"", line 34, in main; shape_optimization( options.filename ,; File ""C:\Users\74351\Desktop\SU2\SU2\bin\test2\shape_optimization.py"", line 51, in shape_optimization; config = SU2.io.Config(filename); File ""C:\Users\74351\Desktop\SU2\SU2\bin\SU2\io\config.py"", line 88, in __init__; super(Config,self).__init__(*args,**kwarg); File ""C:\Users\74351\Desktop\SU2\SU2\bin\SU2\util\ordered_bunch.py"", line 83, in __init__; super(OrderedBunch,self).__init__(*args,**kwarg); File ""C:\Users\74351\Desktop\SU2\SU2\bin\SU2\util\ordered_dict.py"", line 48, in __init__; self.__update(*args, **kwds); File ""C:\Users\74351\Desktop\SU2\SU2\bin\SU2\util\ordered_dict.py"", line 174, in update; for key, value in other:; TypeError: 'NoneType' object is not iterable; ```; When I enter the ""parallel_computation.py -f turb_naca0012.cfg -n NP in the commend the error is:; ```; Traceback (most recent call last):; File ""C:\Users\74351\Desktop\SU2\SU2\bin\parallel_computation.py"", line 110, in <module>; main(); File ""C:\Users\74351\Desktop\SU2\SU2\bin\parallel_computation.py"", line 53, in main; raise Exception(""No config file provided. Use -f flag""); Exception: No config file provided. Use -f flag; ```; Any solvers related to "".py"" cannot be executed, but I can run any cases with SU2_CFD. So I wonder if this situation is a problem with the Python Wrapper? . I will be very appreciated if I could get some feedback on this issue.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1567#issuecomment-1074910200:89,error,error,89,https://su2code.github.io,https://github.com/su2code/SU2/issues/1567#issuecomment-1074910200,2,['error'],['error']
Availability,"Wonderful contribution. Thanks for doing all that. Streamlining the dev process is very helpful and cmake is definitely becoming a standard. Best,. Juan. On Nov 10, 2019, at 11:24 AM, Daumantas Kavolis <notifications@github.com> wrote:. ﻿; Proposed Changes. Added CMake build support for SU2. With this, many popular IDEs will be able to use SU2 as a project with minimal setup. CMake also enables to add dependencies more easily since most libraries have CMake support. vcpkg is great for the libraries available there. SU2 CMake has the same build options as autotools but uses CMake to find system libraries and compilers (MKL, Mutationpp, MPI and Python currently). No longer need to specify paths to compilers/libraries if they are in standard locations. In addition, compile flags can be modified from CMake. There is no need to use preconfigure.py anymore since downloading/unpacking is handled by CMake and is system-agnostic. At the moment, all library targets are static but that could be easily changed to be configurable from CMake. The installation directory is ${CMAKE_PREFIX_PATH}/bin. Similarly to autotools, some build options are disabled if built with Codi forward/reverse datatypes or without MPI. Note that SWIG fails to compile pySU2ad with Nothing known about namespace 'medi' in Common/include/mpi_structure.hpp:57 without -includeall SWIG option but then it takes forever to generate the wrapper (more than 15 minutes on my machine, stopped early). I suggest removing using namespace declarations and either importing used symbols explicitly with using or prepending namespace name, clang-tidy warns against them by default and it makes the code clearer. SU2 CMake options are:. * Build modules:; * SU2_BUILD_CFD: ON|OFF; * SU2_BUILD_DEF: ON|OFF, disabled when building with Codi; * SU2_BUILD_DOT: ON|OFF, disabled when building with Codi forward; * SU2_BUILD_GEO: ON|OFF, disabled when building with Codi; * SU2_BUILD_MSH: ON|OFF, disabled when building with Codi; * SU2_BUIL",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/814#issuecomment-552242380:504,avail,available,504,https://su2code.github.io,https://github.com/su2code/SU2/pull/814#issuecomment-552242380,2,"['avail', 'down']","['available', 'downloading']"
Availability,"Yet another doubt on the same subject: I just realized that SU2V7.31 (I; have not tested it on later SU2 releases) accepts imposing both adiabatic; walls plus isothermal boundary condition on some walls (when running Menter; model), but when I simply impose only isothermal conditions (leaving; commented out the adiabatic markers), I get the message: SU2 process; returned error '1'. Is there a workaround for this? Kind regards. On Thu, Sep 28, 2023 at 8:25 PM Pedro Gomes ***@***.***>; wrote:. > you are correct, there is a discussion on CFD-online about it. we impose 0; > heat flux, but report an ""apparent heat flux"" most codes will simply give; > you back the imposed heat flux value you specify, nevertheless there will; > probably be a temperature gradient close to the wall; >; > —; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/pull/2109#issuecomment-1740118992>, or; > unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AHGXZUUZNE6B63SH7XJLY2DX4YBMZANCNFSM6AAAAAA3QKLVDU>; > .; > You are receiving this because you commented.Message ID:; > ***@***.***>; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/2109#issuecomment-1775968391:374,error,error,374,https://su2code.github.io,https://github.com/su2code/SU2/pull/2109#issuecomment-1775968391,1,['error'],['error']
Availability,"Yikes. Thanks, @LaSerpe, for the heads up. There is clearly something wrong with SU2_SOL for many of the cases, although the compute portion is fine. We should get a test case set up for SU2_SOL, or at least try to catch these errors too. @fpalacios, can you please take a look at this problem when you have a moment? It seems to have shown up with the merging of feature_cte_cl. Just fyi for all: the Travis CI folks have generously granted extra time for our regression tests, up to 70 minutes now. This fixes the time-out issues in the short term, but there are a few strategies we should look at for caching or further decomposing our builds to keep under the time limits in the future as we keep growing.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/325#issuecomment-262118156:227,error,errors,227,https://su2code.github.io,https://github.com/su2code/SU2/pull/325#issuecomment-262118156,1,['error'],['errors']
Availability,"You're right about that bug with vel_i_corr. Thanks for finding it, I'll submit a correction. Yes, it's possible to modify the config file so that your implementation works. But is this simply masking the problem of reduced stability? Do you expect the direct formulation to be less stable? And do the benefits of the direct formulation make the loss of stability worthwhile? If so, then I think you should change the config file. I hope this answers your question, I'm not sure if I understood it correctly. Regards,; Daniel",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/232#issuecomment-182655391:193,mask,masking,193,https://su2code.github.io,https://github.com/su2code/SU2/pull/232#issuecomment-182655391,1,['mask'],['masking']
Availability,"```diff; $ git --no-pager diff --cached ; diff --git a/meson.build b/meson.build; index ca86992ea..b68a03c52 100644; --- a/meson.build; +++ b/meson.build; @@ -1,15 +1,12 @@; project('SU2', 'c', 'cpp',; version: '7.5.1 ""Blackbird""',; + meson_version: '0.61.1',; license: 'LGPL2',; default_options: ['buildtype=release',; 'warning_level=0',; 'c_std=c99',; 'cpp_std=c++11']); ; -if meson.version() != '0.61.1'; - error('SU2 must be configured with the extended Meson script (./meson.py) in the SU2 root directory.'); -endif; -; pymod = import('python'); python = pymod.find_installation(); ; ```. I used this patch, and then ran the following:. ```; $ meson setup builddir --wipe; The Meson build system; Version: 1.0.1; Source dir: /tmp/SU2; Build dir: /tmp/SU2/builddir; Build type: native build. meson.build:1:0: ERROR: Meson version is 1.0.1 but project requires 0.61.1; ```. Using the >= comparison, it configures fine, and downloads a git submodule for mutationpp/coolprop on demand. From a hasty look around, it seems like the other git submodules are used as externals/ directories, not meson subprojects. Another project I know uses e.g. ```; if not fs.exists('submoduledir/README.md'); error('Missing the `submoduledir` submodule! Run `git submodule update --init` to fix this.'); endif; ```. for each submodule before it gets processed by meson. This is less automatic than wrapping it in meson.py, but does provide pretty clear directions... the sticking point is if people download tarballs. You currently point people to github's autogenerated archives, which is NOT sufficient as it doesn't have submodules included. I would actually suggest using `meson dist --include-subprojects --no-tests` to produce your own tarballs and attach them as additional releases artifacts. Meson *does* include submodules (whether or not they are subprojects) automatically to the tarball it creates.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1945#issuecomment-1451057434:410,error,error,410,https://su2code.github.io,https://github.com/su2code/SU2/issues/1945#issuecomment-1451057434,4,"['down', 'error']","['download', 'downloads', 'error']"
Availability,"aybe you refer to the develop code at the time where these tags were introduced. But maybe sth different. > I guess they converge eventually to the same values. I tried to compare the same case but steady (I attach the summary). Results in this case are fairly similar and (in my opinion) raise no warnings. That is good to hear. ; Luckily @cvencro (Thanks for that 👍 ) ran some tests and found that #740 (which rewrites Euler Wall boundaries for compressible and incompressible flows ... which was me btw) introduces the changes you see. The Euler wall for compressible is changed a bit in the way the boundary condition is enforced. Upon convergence both version should recover (close to) the same value. If the results in a steady state are the same/very-similar and if an unsteady simulation at low enough Reynolds-number converges to the same steady result (or oscillate in the same bounds) -> I would say it is simply some purely numerical effect based on the unphysical initialization and different treatment of the euler wall boundary. . 1 thing one could test additionally is to force a very high convergence in each physical timestep, i.e. usually one converges ~3 orders of magnitude in each ts -> now try converging until residual stalling in each ts. If the code versions get the same/closer results in the temporal evolution my euler wall boundary explanation would be quite reasonable.; Together with the long running unsteady simulation proposed above, I would feel more comfortable to judge. @cvencro (bringing the conversation to this place 😉 ) concerning the pitching case: the `if (dynamic_grid)` statements in the 'old' version are not necessary as that is handled by the numerics class. In the new version an appropriate 'reflected state' is constructed and the numerics container is called to compute the residual. Before, the code of one numerics ->ComputeResidual Routine was simply copied and slightly modified. But of course there is always room for errors 🐛 . Cheers, Tobi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/828#issuecomment-562621057:2294,error,errors,2294,https://su2code.github.io,https://github.com/su2code/SU2/issues/828#issuecomment-562621057,1,['error'],['errors']
Availability,"ch request to make it clearer. Request: Use nomenclature consistent with the C++ interface (point instead of node, etc.); Reason: People who know the C++ interface will know how to use the python wrapper straight away, people who learn how to use the python wrapper will be able to understand the C++ implementation (without needing a translation layer in their mind all the time). Request: Return connectivity/adjacency as local indices instead of global; Reason: This is the natural way of referencing data in an MPI code, local indices correspond directly to data stored in the partition thereby making it more efficient to access (without global-to-local conversions, which are much more expensive than local-to-global). Furthermore, the local ordering strategy improves the efficiency of loops (over edges, neighboring points, etc.). Request: Do not apply unnecessary ""transformations"" to the connectivity/adjacency as part of the API; Reason: Increases the maintenance burden and makes for a less versatile API. By returning the local indices that form a marker or element, it is trivial to retrieve any other data for those indices (the ""transformation""). For example, the solution at those points, the point coordinates, whether the points are halo or domain points, the global indices, etc.; This way, by adding a **single** function to the API e.g. get the global index of a point of element, the functionality of the API grows a lot more because the user can apply the function to **any** connectivity/adjacency function. Request: Do not offer too many overloads of the same function; Reason: Increases the maintenance burden and it's returning the data in structures that are not very efficient, namely vector of vectors. It is much easier to offer domain-wide data access on the python side, as a very small function that can be part of wrapper utilities (i.e. live only in python but not c++). It may even be more efficient since you make a numpy array/matrix instead of lists of lists.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1300#issuecomment-1402197827:1643,mainten,maintenance,1643,https://su2code.github.io,https://github.com/su2code/SU2/pull/1300#issuecomment-1402197827,1,['mainten'],['maintenance']
Availability,"ed the linear solvers stay the same and routines that are light see more speedup than their arithmetic-intensive friends.; What is surprising to me is how intensive the convective residuals appear to be with only a 7% improvement, so surprising in fact, I do not think the above paints the full picture. Maybe the outlet bandwidth bottleneck (into the Jacobian matrix) is more important.; To put that do the test I switched to Euler-explicit time marching and repeated the measurements:; ![image](https://user-images.githubusercontent.com/38071223/63293351-d8010b80-c2bf-11e9-8135-2502eac1128e.png); Better, but not by much, which means upwind and viscous residuals computations might gain a lot from vectorization (SIMD). And like @economon mentioned even more if they are somehow fused together.; It also means the writes to CSysMatrix are relatively expensive, I think there are two-three reasons for it.; - We do a linear search on each Add/SubtractBlock - This could be replaced by a map.; - The Jacobian contributions are first written into a temporary block - Interleaving the writes with the computation could help mask latency.; - That temporary is not stored contiguously - Which makes it hard to vectorize the writes to CSysMatrix. **So what do I think should be tackled next?**; Hybrid parallelism (wait what?!) from messing about with this case (and more refined versions) it is clear the MG puts some limits on how many cores can be used before it stops being able to produce coarse grids, both in number and quality. Going to an MPI+Threads strategy would move that limit by one order of magnitude, giving us some robustness and performance for folks hoping to rely on strong scaling. I think I'll break it off here and keep my thoughts about SIMD and hybrid parallel for a later occasion (I have to do some ""real"" PhD work for a while) but please, if anyone has ideias, comments, corrections, suggestions, similar ongoing developments (specially)... I am all ears/eyes. Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/716#issuecomment-522730951:5076,mask,mask,5076,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-522730951,2,"['mask', 'robust']","['mask', 'robustness']"
Availability,"firmed by opening a python terminal and running `import mpi4py`. #### The easiest workaround. Switch to a [virtualenv](https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/). This will ensure that all of your python packages are stored in single location. #### Alternate workaround. In this method, you change the hardcoded includes to match mpi4py's package location. First I figure out where my mpi4py is installed. I start a terminal session of python using the python environment I want to use (in this case, it's python 3.6), and then run:; ```; from mpi4py import MPI; MPI; ```. Since I have mpi4py installed on your system and it's on my python path, I see something like:; ```; <module 'mpi4py.MPI' from '/home/clarkpede/.local/lib/python3.6/site-packages/mpi4py/MPI.cpython-34m.so'>; ```. The `/home/clarkpede/.local/lib/python3.6/` directory is where my mpi4py package is installed. But the swig compile command includes `/home/clarkpede/.local/lib/python2.7/`. That's not the right directory! So first I find the hardcoded paths of the makefile by running (on a bash terminal):; ```; grep -rn python2\.7 SU2_PY/ ; ```; On my system, this prints out four lines. I don't care about the `Makefile.in` files, because those are generated automatically and will be overwritten every time I run ""configure"" or ""preconfigure.py."" The `NUMPY_INCLUDE` line is also commented out, so I ignore that too. That leaves me with one line, line 51 of `SU2_PY/pySU2/Makefile.am`:. ```; SU2_PY/pySU2/Makefile.am:51:MPI4PY_INCLUDE = ${HOME}/.local/lib/python2.7/site-packages/mpi4py/include \; ```. I now modify line 51 of Makefile.am to read:. ```; MPI4PY_INCLUDE = ${HOME}/.local/lib/python3.6/site-packages/mpi4py/include \; ```. Then run configure or preconfigure.py again, and then run make again. You should be good to go!. #### tl;dr. If you're having this error, modify the `MPI4PY_INCLUDE` line of `SU2_PY/pySU2/Makefile.am` to include the location of your mpi4py package.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/722#issuecomment-515693590:2840,error,error,2840,https://su2code.github.io,https://github.com/su2code/SU2/issues/722#issuecomment-515693590,1,['error'],['error']
Availability,"formance, here is the effect of color group size on the execution time of the scalar code on one thread:; ![image](https://user-images.githubusercontent.com/38071223/64686801-2e0d3d00-d481-11e9-82a0-c56e5554cd83.png); The hassle-free option of not sorting by color ""never"" recovers the performance of the base algorithm, things are even worse for the SIMD version where even at group size of 8192 with re-sorting the slowdown is 14%. Running the edge-loop version on 4 cores (8192 group + sorting) we get speedups (relative to reference) of **1.98** and **2.04** for the scalar and SIMD versions respectively (yes I quadruple checked).; If you are keeping track of the number two things should surprise you, the first is that there is no difference between scalar and SIMD now (the vector instruction are still there though), the second is that 4 cores give only a 2x speedup. The reason for both is: the implementation is very memory-bound, and so throwing more compute at it, either in the form of more cores or more lanes, does not help much. This is the 4 core summary:. | Code | Edge | Edge, SIMD on vars | Point | Point, SIMD on points |; | ---- | ---- | ---- | ---- | ---- |; | **Speed** | 2.0 | 2.0 | 3.8 | 2.8 |. I think the point-based versions scale better because they are a bit less memory-bound as they write to the gradient sequentially and they have a bit more compute due to the duplicated computations. **Conclusion**; Computing gradients via point-loops allows simpler and more generic SIMD and SPMD strategies, the resulting implementation seems to do better in the bandwidth-starved conditions typical of modern hardware (3 or more cores per memory channel). However, additional adjacency information is required to support point-based loops. Next I will talk about limiters, almost all concepts are introduced so it will be shorter (promise). As a little appetizer let me tell you we can recover the extra memory and we could be looking at a 2.7x speedup for gradients+limiters.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-530328194:15713,recover,recover,15713,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530328194,1,['recover'],['recover']
Availability,"h>. // An example type to use instead of the container that stores solution data for all vertices.; struct SolutionContainer; {; std::array<double,3> velocity;; std::array<double,3> areaVector;; };. using ResultType = double;. // We want classes with this interface.; class VirtualInterface; {; public:; virtual ResultType Compute(const SolutionContainer&) const = 0;; };. // The Compute method is to be composed via an inheritance chain, to do this; // we allow each building block to inherit from any class. These classes should; // be function objects that have no member variables, all data used in the; // resulting Compute method will be on the stack.; template<typename Base>; class ComputeArea : Base; {; protected:; // Different template instantiations will be made for; // 2D/3D to allow perfect loop unrolling.; enum : int {nDim = Base::nDim};. // To share variables between building blocks we will pass; // down a struct which is also composed by inheritance; struct WorkVarsType : Base::WorkVarsType; {; double area; // add ""area"" to the variables of Base; };; ; // The final implementation of Compute will be a call down the chain.; // The final constructed WorkVarsType is not known at this stage,; // hence we also template the method.; template<typename WV>; void Compute(WV& wv, const SolutionContainer& sol) const; {; // Boilerplate, call base first. This is akin to the decorator design pattern; // without polymorphism. The working variables resemble Python's ""self"" which; // makes this solution reasonably idiomatic.; Base::Compute(wv, sol);. // Then do our specific job.; wv.area = 0.0;; for(int i=0; i<nDim; ++i); wv.area += pow(sol.areaVector[i],2);; wv.area = sqrt(wv.area);; }; };. // Same mechanics as above; template<typename Base>; class ComputeFlux : Base; {; protected:; enum : int {nDim = Base::nDim};. struct WorkVarsType : Base::WorkVarsType ; {; double flux; // ...add new member; };. template<typename WV>; void Compute(WV& wv, const SolutionContainer& sol) cons",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-622941617:3056,down,down,3056,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-622941617,2,['down'],['down']
Availability,"hing known about namespace 'medi' in Common/include/mpi_structure.hpp:57 without -includeall SWIG option but then it takes forever to generate the wrapper (more than 15 minutes on my machine, stopped early). I suggest removing using namespace declarations and either importing used symbols explicitly with using or prepending namespace name, clang-tidy warns against them by default and it makes the code clearer. SU2 CMake options are:. * Build modules:; * SU2_BUILD_CFD: ON|OFF; * SU2_BUILD_DEF: ON|OFF, disabled when building with Codi; * SU2_BUILD_DOT: ON|OFF, disabled when building with Codi forward; * SU2_BUILD_GEO: ON|OFF, disabled when building with Codi; * SU2_BUILD_MSH: ON|OFF, disabled when building with Codi; * SU2_BUILD_PY_WRAPPER: ON|OFF, disabled when building with Codi forward; * SU2_BUILD_SOL: ON|OFF, disabled when building with Codi; * Enable modules:; * SU2_ENABLE_CGNS:; * SU2_CGNS_CPPFLAGS: flags to pass when compiling CGNS; * SU2_ENABLE_CODI: no|forward|reverse; * SU2_CODI_CPPFLAGS: flags to pass to SU2 modules when compiling with Codi; * SU2_ENABLE_METIS: ON|OFF; * SU2_METIS_CPPFLAGS: flags to pass when compiling Metis; * SU2_ENABLE_MKL: ON|OFF; * SU2_ENABLE_MPI: ON|OFF; * SU2_ENABLE_MUTATIONPP: ON|OFF; * SU2_ENABLE_PARMETIS: ON|OFF, only available when SU2_ENABLE_MPI is ON; * SU2_PARMETIS_CPPFLAGS: flags to pass when compiling Parmetis; * SU2_ENABLE_TECIO: ON|OFF; * SU2_TECIO_CPPFLAGS: flags to pass when compiling Tecio and TecioMPI; * SU2_TECIOMPI_CPPFLAGS: flags to pass when compiling TecioMPI, requires SU2_ENABLE_MPI. There is an additional variable that is recognized by CMake scripts - DEBUG, turning it ON enables additional STATUS messages, mainly to check that correct include directories, compile definitions and linked libraries were set up correctly. The remaining options like install location and compilers are handled by CMake. Tested this on Ubuntu with CMake 3.15.5 and everything except pySU2ad wrapper compiles. Haven't tested on earlier C",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/814#issuecomment-552242380:2541,avail,available,2541,https://su2code.github.io,https://github.com/su2code/SU2/pull/814#issuecomment-552242380,1,['avail'],['available']
Availability,"iating tests, grouping tests into suites, and running checks. This choice was based on what is available in our development setup. We have integrated our unit tests into our Travis CI regression testing. Every time we push commits or submit a pull request, the unit tests are run and checked. What is my vision for unit testing in SU2?. I am not proposing that we start trying to get 100% code coverage with pre-existing code. That would not provide a good return on investment. Instead, I see people adding unit tests as they write new code and as they find bugs. For each new behavior added to SU2, tests are first added to document the related existing behavior. These tests serve to check that the existing behavior isn't damaged by the new code. Then new tests are added to prove that the new behavior is working correctly. For bug fixes, the process is simpler. A test is added to confirm that something is not behaving as expected. Then the code is fixed to make the test pass. What frameworks are available?. For a unit testing framework, here are the most popular options, with the following pros and cons:. Roll-your-own. * Requires no external dependencies; * The most flexible option; * Involves the most work to setup; * Will lack some of the more advances features of mature unit-testing frameworks. Boost Test. * Can be header only, statically linked, or dynamically linked; * If statically or dynamically linked, then Boost is not very lightweight; * Easy to add if you're already using Boost. Google Test. * Most common unit-testing framework; * Can be easily combined with Google's powerful GMock mocking library; * Compiling and linking can be somewhat painful. Catch2. * Used by FEniCS; * Makes unit tests easily readable with lots of syntactic sugar.; * Has a very simple syntax; * Is header-only; * Requires C++11 compilation; * Not as feature rich as Google Test or Boost Test. Questions. * How do developers feel about adding unit tests to SU2?; * If a unit-testing framework ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499250240:4254,avail,available,4254,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240,1,['avail'],['available']
Availability,"igure:4118: checking for gcc option to accept ISO C89; configure:4181: gcc -c -g -O2 conftest.c >&5; configure:4181: $? = 0; configure:4194: result: none needed; configure:4216: checking dependency style of gcc; configure:4327: result: gcc3; configure:4345: checking whether gcc and cc understand -c and -o together; configure:4376: gcc -c conftest.c -o conftest2.o >&5; configure:4380: $? = 0; configure:4386: gcc -c conftest.c -o conftest2.o >&5; configure:4390: $? = 0; configure:4401: cc -c conftest.c >&5; configure:4405: $? = 0; configure:4413: cc -c conftest.c -o conftest2.o >&5; configure:4417: $? = 0; configure:4423: cc -c conftest.c -o conftest2.o >&5; configure:4427: $? = 0; configure:4445: result: yes; configure:4513: checking for ranlib; configure:4529: found /usr/bin/ranlib; configure:4540: result: ranlib; configure:4574: checking how to run the C preprocessor; configure:4605: gcc -E conftest.c; configure:4605: $? = 0; configure:4619: gcc -E conftest.c; conftest.c:11:28: error: ac_nonexistent.h: No such file or directory; configure:4619: $? = 1; configure: failed program was:; | /* confdefs.h */; | #define PACKAGE_NAME ""SU2""; | #define PACKAGE_TARNAME ""SU2""; | #define PACKAGE_VERSION ""4.1.0""; | #define PACKAGE_STRING ""SU2 4.1.0""; | #define PACKAGE_BUGREPORT ""su2code-dev@lists.stanford.edu""; | #define PACKAGE_URL ""https://github.com/su2code""; | #define PACKAGE ""SU2""; | #define VERSION ""4.1.0""; | /* end confdefs.h. */; | #include <ac_nonexistent.h>; configure:4644: result: gcc -E; configure:4664: gcc -E conftest.c; configure:4664: $? = 0; configure:4678: gcc -E conftest.c; conftest.c:11:28: error: ac_nonexistent.h: No such file or directory; configure:4678: $? = 1; configure: failed program was:; | /* confdefs.h */; | #define PACKAGE_NAME ""SU2""; | #define PACKAGE_TARNAME ""SU2""; | #define PACKAGE_VERSION ""4.1.0""; | #define PACKAGE_STRING ""SU2 4.1.0""; | #define PACKAGE_BUGREPORT ""su2code-dev@lists.stanford.edu""; | #define PACKAGE_URL ""https://github.com/su2code"";",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:8100,error,error,8100,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,1,['error'],['error']
Availability,"ill be required. Here is what the scalar version of the point-based loop looks like:; ```C++; void computeGradients(size_t nPoint,; size_t nVar,; size_t nDim,; const Adjacency& adj,; const Matrix& area,; const vector<double>& volume,; const Matrix& phi,; VectorOfMatrix& grad); {; for(size_t iPoint=0; iPoint<nPoint; ++iPoint); {; for(size_t iVar=0; iVar<nVar; ++iVar); for(size_t iDim=0; iDim<nDim; ++iDim); grad(iPoint,iVar,iDim) = 0.0;. for(size_t iNeigh=0; iNeigh<adj.nNeighbor(iPoint); ++iNeigh); {; size_t jPoint = adj.jPoint(iPoint,iNeigh);; size_t iEdge = adj.iEdge(iPoint,iNeigh);; double dir = adj.dir(iPoint,iNeigh);. for(size_t iVar=0; iVar<nVar; ++iVar); {; double phi_ave = 0.5*(phi(iPoint,iVar)+phi(jPoint,iVar));. for(size_t iDim=0; iDim<nDim; ++iDim); grad(iPoint,iVar,iDim) += phi_ave*dir*area(iEdge,iDim);; }; }. for(size_t iVar=0; iVar<nVar; ++iVar); for(size_t iDim=0; iDim<nDim; ++iDim); grad(iPoint,iVar,iDim) /= volume[iPoint];; }; }; ```; The `Adjacency` class stores for each point: the surrounding neighbor points (this is available in SU2), the neighbor edges, and the direction (in or out, -1 or 1) of the area vector relative to the point.; The speedup is **0.83** (i.e. not a speedup), that is actually not that bad considering the same computation is repeated for each edge, the reason it is not that bad is the sequential access to the gradient. Note that this loop is one #pragma away from parallelization. The SIMD version of this code is:; ```C++; void computeGradients(size_t nPoint,; size_t nVar,; size_t nDim,; const Adjacency<4>& adj,; const Matrix& area,; const Vector& volume,; const Matrix& phi,; VectorOfMatrix& grad); {; const size_t SIMDLEN = 4;. for(size_t iPoint=0; iPoint<nPoint; iPoint+=SIMDLEN); {; for(size_t iVar=0; iVar<nVar; ++iVar); for(size_t iDim=0; iDim<nDim; ++iDim); grad.setVec(iPoint,iVar,iDim,Array<double,SIMDLEN>(0.0));. for(size_t iNeigh=0; iNeigh<adj.nNeighbor_vec(iPoint); ++iNeigh); {; auto jPoint = adj.jPoint_vec(iPoint,iNeigh);",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-530328194:4718,avail,available,4718,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530328194,1,['avail'],['available']
Availability,"irst;; size_t jPoint = connectivity[iEdge].second;; ```; Apologies for the macro but it is just to illustrate that if we re-sort edge data after coloring the edge index is the loop index, otherwise the edge indices for each color need to be stored in a separate array.; Note that for each edge loop we first loop over colors, then over same-color edges, it is this inner loop that can run in parallel in chunk sizes that are multiple of the group size considered during coloring. There is some runtime cost on entry to every #omp parallel section, with coloring we enter one such section once by color. I mentioned in the introduction coloring reduces locality and therefore performance, here is the effect of color group size on the execution time of the scalar code on one thread:; ![image](https://user-images.githubusercontent.com/38071223/64686801-2e0d3d00-d481-11e9-82a0-c56e5554cd83.png); The hassle-free option of not sorting by color ""never"" recovers the performance of the base algorithm, things are even worse for the SIMD version where even at group size of 8192 with re-sorting the slowdown is 14%. Running the edge-loop version on 4 cores (8192 group + sorting) we get speedups (relative to reference) of **1.98** and **2.04** for the scalar and SIMD versions respectively (yes I quadruple checked).; If you are keeping track of the number two things should surprise you, the first is that there is no difference between scalar and SIMD now (the vector instruction are still there though), the second is that 4 cores give only a 2x speedup. The reason for both is: the implementation is very memory-bound, and so throwing more compute at it, either in the form of more cores or more lanes, does not help much. This is the 4 core summary:. | Code | Edge | Edge, SIMD on vars | Point | Point, SIMD on points |; | ---- | ---- | ---- | ---- | ---- |; | **Speed** | 2.0 | 2.0 | 3.8 | 2.8 |. I think the point-based versions scale better because they are a bit less memory-bound as they write ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-530328194:14076,recover,recovers,14076,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530328194,1,['recover'],['recovers']
Availability,"n for SU2_DEF; - Merge branch 'develop' into feature_dualoutput; - Removed deprecated options from quicstart config.; - Working version of the compressible actuator disk; - Updated fixed CL mode.; - Very minor change; - Merge branch 'develop' into feature_dualoutput; - Final push to 3.2.9; - Merge branch 'develop'; - Minor change; - Minor change; - Small change; - Minor change; - Bug fixing: unsigned short val_vertex --> unsigned long val_vertex; - CFL adapt now works for adjoint problems; - Merge branch 'develop' into feature_dualoutput; - Fixing a typo; - Fix in the Euler BC for grid movement cases; - merging and fixing conflicts bwtn feature_dealloc and develop; - dealloc; - Time spectral fix.; - Merging some recent bug fixes from master into the develop branch to keep nsync.; - Merge branch 'feature_gridvel_fix' into develop; - Merge remote-tracking branch 'upstream/develop' into feature_Deallocation; - correcting issues, adding more deallocation; - fixed uninitialized pointers in CConfig; - further deallocation; - some corrections needed to pass reg tests; - fixed some dealloc issues that caused errors in euler adj; - modifications needed to (mostly) pass reg tests; all run w/o segfault. File Changes; - D Articles/AIAA_2013-0287.pdf (0) ; - D Articles/AIAA_2014-0243.pdf (0) ; - M Common/doc/docmain.hpp (46) ; - M Common/include/config_structure.hpp (1038) ; - M Common/include/config_structure.inl (191) ; - M Common/include/dual_grid_structure.hpp (43) ; - M Common/include/dual_grid_structure.inl (17) ; - M Common/include/geometry_structure.hpp (432) ; - M Common/include/geometry_structure.inl (39) ; - M Common/include/grid_adaptation_structure.hpp (24) ; - M Common/include/grid_adaptation_structure.inl (15) ; - M Common/include/grid_movement_structure.hpp (330) ; - M Common/include/grid_movement_structure.inl (45) ; - M Common/include/linear_solvers_structure.hpp (78) ; - M Common/include/linear_solvers_structure.inl (15) ; - M Common/include/matrix_structure.h",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:10517,error,errors,10517,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['error'],['errors']
Availability,"of SU2_DEF; - Final push before moving to the develop branch; - New MPI (removing SU2_PRT); - Merged in Ben's ParMETIS integration and fixed some conflicts.; - Merge branch 'benkirk-parmetis_integration' into feature_MPI; - ParMETIS geometry routines have been copied over but are not activated yet.; - Small change to ParMETIS include.; - ParMETIS can now be activated for testing (PARMETIS=YES in config).; - Updated MG; - Updated EA subrotuine; - Small fix; - Fixing memory leak; - Fixing memory leaks; - Dev release v.3.2.6; - Increasing MAX_NUMBER_MARKER; - Working version with ParMETIS. Fixed bug in global index. Now clean up and testing...; - Cleaned version of ParMETIS routines with better console output during partitioning.; - Small bug in initial element division.; - Made arrays in ParMETIS call dynamic.; - Fixed compiler warnings and added MPI directives so that the pure serial code works with the ParMETIS routines.; - Bootstrap on zion.; - Added some typecasts. Still tracking down a memory problem...; - Critical bug fix for vtxdist array.; - Partial fix; - More MPI improvements.; - Fixing a bug in SU2_DEF; - Updated BC_ActDisk_Boundary (MPI); - Merge remote-tracking branch 'upstream/develop' into develop; - changing solidboundary setting to be heatflux OR euler etc instead of AND, also working on doxygen documentation; - Dynamic allocation for some marker-related arrays.; - visualize part taken out to match upstream/dev; - Collection of improvements; - Release 3.2.7; - Fixing LOW_MEMORY_OUTPUT; - Updated LOW_MEMORY_OUTPUT option; - Updated configure.ac; - After autoconf; - Updated MPI; - Updated BC_Engine_Exhaust and BC_Engine_Bleed; - Small change; - Fixing subsonic engine intake option; - Small output change; - Added output_su2.cpp; - Updated Engine BC; - Working on Engine BCs; - Added Supersonic Outlet BC; - Minor change; - Merge remote-tracking branch 'upstream/develop' into develop; - adjoints, solid boundary, doxygen in config; - continued fixing; - re-a",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:2422,down,down,2422,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['down'],['down']
Availability,"ple dataset, I have run some; variations on the jobs, and my findings were:; (Please note that *all* ""markers"" I have mentioned in the next items refer; to solid walls in the mesh, using the RANS solver); 1- When I impose HEATFLUX=0 *and* ISOTHERMAL=290 Kelvin, for the same; markers, there are no complaints from SU2. It shows that SU2 ignores the; imposition of HEATFLUX=0, in this case.; 2- Just setting ISOTHERMAL=290 Kelvin (using all of the same markers as in; (item 1), above), without any HEATFLUX setting, then SU2 produces the same; results as in (item1).; 3- When some markers are set with HEATFLUX=0 and the rest of them are set; with ISOTHERMAL=290 Kelvin (so that each wall marker in the mesh is; referenced), there are no complaints from SU2, and the job goes as expected.; 4-The error message mentioned earlier, appears when one or more solid wall; markers *is not marked* concerning HEATFLUX or ISOTHERMAL; .; My conclusion then is that the error message appeared when I mistakenly; have not included a wall marker (assigning it as a HEATFLUX or an; ISOTHERMAL marker!); Does it make sense?; Kind regards,. On Mon, Oct 23, 2023 at 7:48 PM Jairo Cavalcante ***@***.***>; wrote:. > Unfortunately, my example involves a swirler and nozzle for the; > Navier-Stokes solver with Menter model, so the dataset is relatively large.; > Let me check whether some older small Euler mesh exhibits the same message!; > I will let you know! Thank you very much.; >; > On Mon, Oct 23, 2023 at 6:34 PM Pedro Gomes ***@***.***>; > wrote:; >; >> Is there a simple example to reproduce the issue?; >>; >> —; >> Reply to this email directly, view it on GitHub; >> <https://github.com/su2code/SU2/pull/2109#issuecomment-1776057496>, or; >> unsubscribe; >> <https://github.com/notifications/unsubscribe-auth/AHGXZUV3DNRF3O55YAWT563YA3PETAVCNFSM6AAAAAA3QKLVDWVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMYTONZWGA2TONBZGY>; >> .; >> You are receiving this because you commented.Message ID:; >> ***@***.***>; >>; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/2109#issuecomment-1777018035:998,error,error,998,https://su2code.github.io,https://github.com/su2code/SU2/pull/2109#issuecomment-1777018035,1,['error'],['error']
Availability,"r SU2_MSH. The nice thing here is that we keep the intent separate, i.e., only design variables are listed with the other design variables while the mesh transformations are elsewhere. A different, possibly simpler way would be to just create separate names for these two types in the list of available options so that there is no ambiguity. Any thoughts?. On Aug 16, 2015, at 9:21 AM, Heather Kline <notifications@github.com<mailto:notifications@github.com>> wrote:. Some illustrative images/output in case my description was hard to understand:; [image]https://cloud.githubusercontent.com/assets/5167760/9294050/52a764b2-440f-11e5-8681-b68318da0ce7.png. SU2_DEF output when only ""airfoil"" marker included:. ------------------------- Surface grid deformation ----------------------; Performing the deformation of the surface grid. ----------------------- Volumetric grid deformation ---------------------; Performing the deformation of the volumetric grid. # FGMRES residual history. # Residual tolerance target = 4.14044e-11. # Initial residual norm = 15.8102. ```; 0 1; 50 2.17385e-06; 100 1.08998e-10; ```. # FGMRES final (true) residual:. # Iteration = 105: |res|/|res0| = 3.50764e-11. Non-linear iter.: 1/1. Linear iter.: 105. Min. area: 4.1019e-08. Error: 5.54565e-10. ----------------------- Write deformed grid files -----------------------; Merging grid connectivity.; Merging grid coordinates.; Writing volume mesh file.; Writing surface mesh file.; Writing .su2 file.; Adding any FFD information to the SU2 file. Completed in 1.039217 seconds on 1 core. ------------------------- Exit Success (SU2_DEF) ------------------------. [image]https://cloud.githubusercontent.com/assets/5167760/9294056/7be9439a-440f-11e5-862f-742246ef1565.png; SU2_DEF: output when deforming with all markers included:. ------------------------- Surface grid deformation ----------------------; Performing the deformation of the surface grid.; No surface deformation (scaling, rotation, or translation). ---------",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/187#issuecomment-132065067:1786,toler,tolerance,1786,https://su2code.github.io,https://github.com/su2code/SU2/pull/187#issuecomment-132065067,1,['toler'],['tolerance']
Availability,"rite-unit-tests-for-scientific-research-codes>. What do I propose?. My research group at UT Austing has implemented a unit testing framework on our branch, which we're happy with. Some choices were arbitrary, and some choices were made based on our development environment. Those choices may be different for other groups. Here's what we have done:. The unit testing framework is compiled and run using autotools. For more information on autotool's setup, see their documentation<https://www.gnu.org/software/automake/manual/html_node/Tests.html>. Since autotools is the build system for SU2, this involves minimal changes. Using automake, the build process for building unit tests becomes:. '''; ./bootstrap; ./configure; make; make check; '''. We use Boost's unit testing framework<https://www.boost.org/doc/libs/1_70_0/libs/test/doc/html/index.html>. This provides a convenient set of macros for instatiating tests, grouping tests into suites, and running checks. This choice was based on what is available in our development setup. We have integrated our unit tests into our Travis CI regression testing. Every time we push commits or submit a pull request, the unit tests are run and checked. What is my vision for unit testing in SU2?. I am not proposing that we start trying to get 100% code coverage with pre-existing code. That would not provide a good return on investment. Instead, I see people adding unit tests as they write new code and as they find bugs. For each new behavior added to SU2, tests are first added to document the related existing behavior. These tests serve to check that the existing behavior isn't damaged by the new code. Then new tests are added to prove that the new behavior is working correctly. For bug fixes, the process is simpler. A test is added to confirm that something is not behaving as expected. Then the code is fixed to make the test pass. What frameworks are available?. For a unit testing framework, here are the most popular options, with the follo",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499250240:3344,avail,available,3344,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240,1,['avail'],['available']
Availability,"t trickier: the latest 2D results of @RoccoBombardieri show pretty much no difference including the first timesteps. The onera m6 case in contrast converges to the same (steady-state) results for both code version eventually but their initial transient phase differs quite significantly. . A possible explanation for the different initial transient phase: In both implementations a ""reflected state"" is constructed where the normal component of the velocity is subtracted [once in the older code version & twice in the newer version]. I.e. subtracting the normal component of velocity twice means mirroring the velocity along the symmetry plane. The newer code version is a bit ""stronger"" in enforcing the boundary conditions which could lead to the reduced oscillation in CD and CL. If we agree that both code versions produce physically correct results for steady cases and unsteady cases that were integrated long enough in time to get rid of the influence of the initial condition ... then we are left with this initial transient phase that differs. Of course if there is more evidence that one or the other version produces physically ""better"" results I would love to see that. Until then, both initial oscillations are equally correct/uncorrect in my opinion. [I'll add a few words about the adjoint here later]. [I'll add the idea of an FSI case of @cvencro here later where the initial phase has a major impact]; Consider an FSI computation of an airfoil where the trailing edge can exhibit flutter (periodic up-and-down-movement of the trailing edge) in certain flow regimes. Now if during the initial transient the forces on the airfoil are higher than in the converged state then the fluttering can be excited where the initial transient can be seen as an activation energy. If you were to e.g. ramp up flow speed/conditions slowly up to the same magnitude as before one might end up without fluttering. So based on the flow history there might exist multiple ""stable"" states. Cheers, Tobi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/828#issuecomment-563314747:2532,down,down-movement,2532,https://su2code.github.io,https://github.com/su2code/SU2/issues/828#issuecomment-563314747,1,['down'],['down-movement']
Availability,"this is a very nice contribution.. we’re working on the regressions and will pull this in once we have everything straightened out (and this branch passes). In the meantime, you got me thinking: the scale, rotate, translate options might be confusing now if a user doesn’t know whether to include the markers or not. Perhaps this is a chance for separating some of the “design” options from “mesh” options. One way I could see us do this is by moving the implementation I had just committed for the “volume” scale, rotate, and translate options over into the SU2_MSH executable, which might be a more logical home for it. However, this would require adding an extra set of config options for reading in a scale/rotate/translate options for SU2_MSH. The nice thing here is that we keep the intent separate, i.e., only design variables are listed with the other design variables while the mesh transformations are elsewhere. A different, possibly simpler way would be to just create separate names for these two types in the list of available options so that there is no ambiguity. Any thoughts?. On Aug 16, 2015, at 9:21 AM, Heather Kline <notifications@github.com<mailto:notifications@github.com>> wrote:. Some illustrative images/output in case my description was hard to understand:; [image]https://cloud.githubusercontent.com/assets/5167760/9294050/52a764b2-440f-11e5-8681-b68318da0ce7.png. SU2_DEF output when only ""airfoil"" marker included:. ------------------------- Surface grid deformation ----------------------; Performing the deformation of the surface grid. ----------------------- Volumetric grid deformation ---------------------; Performing the deformation of the volumetric grid. # FGMRES residual history. # Residual tolerance target = 4.14044e-11. # Initial residual norm = 15.8102. ```; 0 1; 50 2.17385e-06; 100 1.08998e-10; ```. # FGMRES final (true) residual:. # Iteration = 105: |res|/|res0| = 3.50764e-11. Non-linear iter.: 1/1. Linear iter.: 105. Min. area: 4.1019e-08. Error: ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/187#issuecomment-132065067:1083,avail,available,1083,https://su2code.github.io,https://github.com/su2code/SU2/pull/187#issuecomment-132065067,1,['avail'],['available']
Availability,"to be bandwidth-bound, vectorization helps a bit there too (instructions are also data that needs to travel to the CPU) (maybe for explicit schemes and 8 SIMD lanes, maybe). **Relation with data structures**; There is only one efficient way to move data between memory and registers, via `load` and `store` instructions (they do come in multiple flavors). That is, pointing to a memory location and reading or writing N elements of contiguous data.; It is not the only way, it is also possible to `gather` and `scatter` data. That is populating the register from non-contiguous locations and vice versa. This is about one order of magnitude slower, to the point where if the computations are very simple it may not pay-off to vectorize. **Relation with algorithms**; Some form of `gather` and `scatter` is required in unstructured CFD, which means SIMD has a price of admission. Some thought needs to go into designing algorithms that amortize that cost by maximizing the so called FLOP/Byte ratio, and mask the latency of those operations by being able to start computing as soon as the first element of data is available. **What elements should we try to process simultaneously?**; The choice is between multiple geometric primitives (edges/points) or multiple solution primitives (variables). The latter sounds like a sensible idea until we get to areas of the code where different primitives require different treatment, that and the fact that the number of variables might not fit evenly in the number of lanes can lead to very tricky and non-generic code. Nevertheless if the same code were to be applied to e.g. 4 solution variables, this strategy would likely perform better as it avoids the pesky gather/scatter operations.; Processing multiple geometric primitives can make full utilization of whatever register size (important on GPU's), the code is just as readable (as I hope to show), but gather/scatter cannot be avoided. ### Intro to SPMD; This one is simpler, in a nutshell multiple t",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-529662724:1923,mask,mask,1923,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-529662724,2,"['avail', 'mask']","['available', 'mask']"
Availability,"ut; - Adjacency building for Parmetis improve to account for VTK structure; - added if viscous steps to some adjeuler bcs; - Minor changes; - Back to previous version of ParMetis; - Small change; - Final update.; - Minor bug fixed.; - Updated SU2_DEF (cgns); - CGNS global element ID bug fix.; - Heat flux bug fix.; - Small fix.; - Merge branch 'master' into develop; - changed history output to match # of residuals printed in header and body; - further correction to history output; - history file fix; - fixed history output such that massflowrate can be output while in rans; - Removed Parmetis updates to adjacency; - Minor changes; - Merge branch 'develop' of https://github.com/su2code/SU2 into develop; - Bug fixing; - ver 3.2.8.3; - Updated CGNS in parallel.; - Added the ability to writting 2 files at each checkpoint when using 2nd order dual time stepping; - Merge branch 'develop' into feature_dualoutput; - Updated FieldView; - Preliminary implementation (ASCII); - Minor changes; - Update code; - Updated FieldView format; - Merge branch 'develop' into feature_dualoutput; - Bug fixing; - Updated FieldView ASCII format; - Complete implementation of the FFD_CONTINUITY capability; - Updated FFD intersections; - ver 3.2.9; - adding targetea file to equivalent area adjoint folder. address issue #160; - Merge branch 'develop' of github.com:su2code/SU2 into develop; - Final push to v3.2.9; - after bootstrap; - updates to comments in config_structure to make doxygen pretty; - Bug fixing; - Merge branch 'develop'; - EA in ft^2; - further update to config; - Merge remote-tracking branch 'upstream/develop' into upstream_dev; - Minor changes; - Updated NF BC; - More adjustments; - Small update; - Final update Nearfield BC; - added massflowrate as option for cauchy criteria, more config file comments; - Merge remote-tracking branch 'upstream/develop' into upstream_dev; - paraview output modified/added back in for current version for SU2_DEF; - Merge branch 'develop' into feature_",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:8269,checkpoint,checkpoint,8269,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['checkpoint'],['checkpoint']
Availability,"ze_t iPoint = connectivity[iEdge].first;; size_t jPoint = connectivity[iEdge].second;. // i to j vector; double d_ij[3] = {0.0, 0.0, 0.0};. for(size_t iDim=0; iDim<nDim; ++iDim); d_ij[iDim] = 0.5*(coords(jPoint,iDim)-coords(iPoint,iDim));. // projections; double proj_i[nVar], proj_j[nVar];. #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); proj_i[iVar] = proj_j[iVar] = 0.0;. for(size_t iDim=0; iDim<nDim; ++iDim); {; #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); {; proj_i[iVar] += d_ij[iDim]*grad(iPoint,iVar,iDim);; proj_j[iVar] -= d_ij[iDim]*grad(jPoint,iVar,iDim);; }; }. // choose the ""right"" delta based on sign of projection; // and avoid division by zero; double lim_i[nVar], lim_j[nVar];. #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); {; lim_i[iVar] = phiMax(iPoint,iVar);; lim_j[iVar] = phiMax(jPoint,iVar);; }. const double eps = numeric_limits<double>::epsilon();. // very simple if's are required to get vectorization; // trough vector comparisons and masked blends; #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); {; if(proj_i[iVar] <= 0.0); {; lim_i[iVar] = phiMin(iPoint,iVar);; proj_i[iVar] = min(proj_i[iVar], -eps);; }. if(proj_j[iVar] <= 0.0); {; lim_j[iVar] = phiMin(jPoint,iVar);; proj_j[iVar] = min(proj_j[iVar], -eps);; }; }. #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); {; lim_i[iVar] = (lim_i[iVar]-phi(iPoint,iVar))/proj_i[iVar];; limiter(iPoint,iVar) = min(limiter(iPoint,iVar), lim_i[iVar]);. lim_j[iVar] = (lim_j[iVar]-phi(jPoint,iVar))/proj_j[iVar];; limiter(jPoint,iVar) = min(limiter(jPoint,iVar), lim_j[iVar]);; }; }. #pragma omp parallel for schedule(dynamic,TARGET_CHUNK_SIZE); for(size_t iPoint=0; iPoint<nPoint; ++iPoint); {; #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); {; double lim = limiter(iPoint,iVar);; limiter(iPoint,iVar) = lim*(lim+2)/(lim*lim+lim+2);; }; }; }; ```; Again to keep things short here is the parallel and SIMD point-loop version (like for gradients it is very similar to the",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-530593912:6436,mask,masked,6436,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530593912,1,['mask'],['masked']
Deployability," and that other proposals are put forward so the discussion can be finalized at the developer’s meeting. Best,. Juan. On Sep 10, 2017, at 1:09 PM, Edwin van der Weide <notifications@github.com<mailto:notifications@github.com>> wrote:. Dear @rsanfer<https://github.com/rsanfer>,. I agree with you that the outer loop should be the loop over the number of physical disciplines involved in the problem and not the zones. Whether the individual disciplines contain one or multiple zones is irrelevant at this level, in my opinion. The loop over the multiple zones of a single discipline should take place at a much lower level, namely where the spatial residual is computed. At least, this should be the case for the fluid dynamics part. I don't know whether this is also the case for other disciplines, like structures. What about the following high level structure?. * Loop over the number of iterations, or time steps for unsteady problems.; * Loop over the number of pseudo-time steps for implicit time integration schemes; (DT_STEPPING_1ST and DT_STEPPING_2ND). For other cases this loop is 1.; * Loop over the number of disciplines involved; Call iterate for each of the disciplines.; In iterate:; * Loop over the (Runge-Kutta) stages; * Loop over the zones of a single discipline; Compute spatial residual.; Update the state vector.; * End loop over the zones of a single discipline.; Exchange halo data. This includes the halo data between zones of a single discipline.; * End loop over the (Runge-Kutta) stages; * End loop over the disciplines; * End loop over the pseudo time steps.; * End loop over the number of iterations, or time steps for unsteady problems. The weakness of this approach is that it still does not work when one would like to employ multi-stage time integration schemes for an unsteady, multi-disciplinary problem (does not work for the current implementation either), but maybe this is something we simply have to accept. The alternative is that all the details of the diff",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/437#issuecomment-328403160:2251,integrat,integration,2251,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328403160,1,['integrat'],['integration']
Deployability," per rank participates in the message passing, I have no experience here though so this might be a bad strategy, idk. **Back to business:**; I went silent for a bit because in prototyping a typical residual computation and matrix update loop I made some realisations that made me go back to the drawing board regarding data structures, and eventually back to square 0. . ## Parallel strategy for flux computation; Because significant computation is required to obtain each edge's flux, it does not make sense to attempt a ""point-loop"" strategy (which would double the effort).; However, one can either use colouring to avoid the race conditions that would result from updating the residual of cells i and j, or store the edge fluxes and then, on a second point-loop perform the summation of fluxes for each cell, with the direction being accounted by the same adjacency information used in the point-loop GG gradient computation.; If we consider only the update of residuals the two strategies are fairly equivalent performance wise, the tie breaker is the matrix updates. ## Matrix Updates; By this I mean the `addBlock`, `subBlock` we do (two times each) to update diagonal and off-diagonal blocks for each edge.; Here is a dummy numerics loop that does nothing else but setting blocks in the matrix (with colouring).; ```c++; void testLoop1(const vector<size_t>& colorStart,; const vector<size_t>& edgeIdx,; const vector<pair<size_t,size_t> >& connectivity,; double** blk_i, double** blk_j,; SparseMatrix& matrix); {; matrix.setZero();. for(size_t color=0; color<colorStart.size()-1; ++color); #pragma omp parallel for schedule(dynamic,CHUNK_SIZE); for(size_t k=colorStart[color]; k<colorStart[color+1]; ++k); {; size_t iEdge = edgeIdx[k];; size_t iPoint = connectivity[iEdge].first;; size_t jPoint = connectivity[iEdge].second;. matrix.addBlock(iPoint, iPoint, blk_i);; matrix.addBlock(iPoint, jPoint, blk_j);. matrix.subBlock(jPoint, jPoint, blk_j);; matrix.subBlock(jPoint, iPoint, blk_i);; }; }",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-535977206:1160,update,update,1160,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206,2,['update'],"['update', 'updates']"
Deployability," scheme for a multi-physics problem. To obtain the design accuracy in time, this implies that the loop over the number of time stages is outside the loop over the number of physical disciplines. Hence at a very high level in the hierarchy, the details of the time integration should then be known. The situation becomes even more complicated when one would like to employ time integration schemes that allow for time accurate local time stepping, e.g. the ones we are currently working on for the DG solver. I won't bore you with all the details here, but those schemes basically require the loop over the multiple disciplines to be between the predictor and corrector step, while both these steps consist of multiple stages. Although it is probably possible to come up with a data structure that supports all this, the question is whether this is desirable. Apart from the fact that it would require a major overhaul in the high level design of SU2, the implementation will be less readable, especially for people that will be starting with the code. Also the parallelization may become significantly more complicated. The alternative is that for unsteady multi-physics problems, we put the restriction that only single stage time integration schemes can be used, e.g. DT_STEPPING_1ST and DT_STEPPING_2ND. In that case, the details of the time integration scheme can be hidden at the driver level, where we then simply have a loop over the number of physical disciplines. The consequence of course is that more advanced time integration schemes will not be available for multi-physics problems. In the above I just tried to picture what, in my opinion, the consequences are for either option. I don't have a preference for one of them. The only thing I wanted to make clear is that it is not possible to hide all the details of the time integration scheme at the driver level, while also having support for all possible time integration schemes for an unsteady multi-physics problem. Regards,. Edwin",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/437#issuecomment-328441926:1599,integrat,integration,1599,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328441926,5,['integrat'],['integration']
Deployability," using the [decorator](https://en.wikipedia.org/wiki/Decorator_pattern) pattern) so that we write to the matrix only once per iteration, which means we only need to clear the diagonal blocks and not the entire matrix because we can **set** the off-diagonals instead of **updating** them. Assuming these modification our dummy loop becomes; ```c++; void testLoop2(const vector<size_t>& colorStart,; const vector<size_t>& edgeIdx,; const vector<pair<size_t,size_t> >& connectivity,; const double* blk_i, const double* blk_j,; SparseMatrix& matrix); {; matrix.setDiagZero();. for(size_t color=0; color<colorStart.size()-1; ++color); #pragma omp parallel for schedule(dynamic,CHUNK_SIZE); for(size_t k=colorStart[color]; k<colorStart[color+1]; ++k); {; size_t iEdge = edgeIdx[k];; size_t iPoint = connectivity[iEdge].first;; size_t jPoint = connectivity[iEdge].second;. matrix.updateBlocks(iEdge, iPoint, jPoint, blk_i, blk_j);; }; }; ```; where; ```c++; STRONGINLINE void SparseMatrix::updateBlocks(size_t edge,; size_t row, size_t col, const double* blk_i, const double* blk_j); {; size_t bii = diagMap[row], bij = edgeMap[edge].first,; bjj = diagMap[col], bji = edgeMap[edge].second;. #pragma omp simd; for(size_t k=0; k<blkSz; ++k); {; coeffs[bii+k] += blk_i[k]; coeffs[bij+k] = +blk_j[k];; coeffs[bji+k] = -blk_i[k]; coeffs[bjj+k] -= blk_j[k];; }; }; ```; This is **47% faster**, which for a memory bound task is massive!; Yes, this does increase the memory footprint a bit (makes CSysMatrix 4% larger for a 3D problem) but I can get that back by sharing sparsity patterns and maps across turbulence and bulk flow (I think @talbring was already working on this in the template linear solver branch he had started). We could also parallelize the matrix updates without colouring by setting only the off-diagonal coefficients and then setting the diagonal entries to the column sum.; It turns out that this is worse (by about 10%), maybe if the matrix were symmetric (row sum) but a column sum accesse",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-535977206:3830,update,updateBlocks,3830,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206,2,['update'],['updateBlocks']
Deployability,"'; am__include='include'; am__isrc=''; am__leading_dot='.'; am__nodep='_no'; am__quote=''; am__tar='$${TAR-tar} chof - ""$$tardir""'; am__untar='$${TAR-tar} xf -'; bindir='${exec_prefix}/bin'; build='x86_64-unknown-linux-gnu'; build_alias=''; build_cpu='x86_64'; build_os='linux-gnu'; build_vendor='unknown'; datadir='${datarootdir}'; datarootdir='${prefix}/share'; docdir='${datarootdir}/doc/${PACKAGE_TARNAME}'; dvidir='${docdir}'; exec_prefix='${prefix}'; host='x86_64-unknown-linux-gnu'; host_alias=''; host_cpu='x86_64'; host_os='linux-gnu'; host_vendor='unknown'; htmldir='${docdir}'; includedir='${prefix}/include'; infodir='${datarootdir}/info'; install_sh='${SHELL} /home/antodech/SU2-4.1.0/install-sh'; libdir='${exec_prefix}/lib'; libexecdir='${exec_prefix}/libexec'; localedir='${datarootdir}/locale'; localstatedir='${prefix}/var'; mandir='${datarootdir}/man'; mkdir_p='$(MKDIR_P)'; oldincludedir='/usr/include'; pdfdir='${docdir}'; prefix='/gshare/work/hpascalj/CodeSU2-master'; program_transform_name='s,x,x,'; psdir='${docdir}'; sbindir='${exec_prefix}/sbin'; sharedstatedir='${prefix}/com'; su2_externals_INCLUDES=''; su2_externals_LIBS=''; sysconfdir='${prefix}/etc'; target='x86_64-unknown-linux-gnu'; target_alias=''; target_cpu='x86_64'; target_os='linux-gnu'; target_vendor='unknown'. ## ----------- ##; ## confdefs.h. ##; ## ----------- ##. /* confdefs.h */; #define PACKAGE_NAME ""SU2""; #define PACKAGE_TARNAME ""SU2""; #define PACKAGE_VERSION ""4.1.0""; #define PACKAGE_STRING ""SU2 4.1.0""; #define PACKAGE_BUGREPORT ""su2code-dev@lists.stanford.edu""; #define PACKAGE_URL ""https://github.com/su2code""; #define PACKAGE ""SU2""; #define VERSION ""4.1.0""; #define STDC_HEADERS 1; #define HAVE_SYS_TYPES_H 1; #define HAVE_SYS_STAT_H 1; #define HAVE_STDLIB_H 1; #define HAVE_STRING_H 1; #define HAVE_MEMORY_H 1; #define HAVE_STRINGS_H 1; #define HAVE_INTTYPES_H 1; #define HAVE_STDINT_H 1; #define HAVE_UNISTD_H 1; #define SIZEOF_SHORT_INT 2; #define SIZEOF_INT 4; #define SIZEOF_UNSIGNED_INT",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:25728,install,install-sh,25728,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,1,['install'],['install-sh']
Deployability,"'mpi4py/mpi4py.i'; ```; But mpi4py is indeed installed on your system and it's on your python path, as confirmed by opening a python terminal and running `import mpi4py`. #### The easiest workaround. Switch to a [virtualenv](https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/). This will ensure that all of your python packages are stored in single location. #### Alternate workaround. In this method, you change the hardcoded includes to match mpi4py's package location. First I figure out where my mpi4py is installed. I start a terminal session of python using the python environment I want to use (in this case, it's python 3.6), and then run:; ```; from mpi4py import MPI; MPI; ```. Since I have mpi4py installed on your system and it's on my python path, I see something like:; ```; <module 'mpi4py.MPI' from '/home/clarkpede/.local/lib/python3.6/site-packages/mpi4py/MPI.cpython-34m.so'>; ```. The `/home/clarkpede/.local/lib/python3.6/` directory is where my mpi4py package is installed. But the swig compile command includes `/home/clarkpede/.local/lib/python2.7/`. That's not the right directory! So first I find the hardcoded paths of the makefile by running (on a bash terminal):; ```; grep -rn python2\.7 SU2_PY/ ; ```; On my system, this prints out four lines. I don't care about the `Makefile.in` files, because those are generated automatically and will be overwritten every time I run ""configure"" or ""preconfigure.py."" The `NUMPY_INCLUDE` line is also commented out, so I ignore that too. That leaves me with one line, line 51 of `SU2_PY/pySU2/Makefile.am`:. ```; SU2_PY/pySU2/Makefile.am:51:MPI4PY_INCLUDE = ${HOME}/.local/lib/python2.7/site-packages/mpi4py/include \; ```. I now modify line 51 of Makefile.am to read:. ```; MPI4PY_INCLUDE = ${HOME}/.local/lib/python3.6/site-packages/mpi4py/include \; ```. Then run configure or preconfigure.py again, and then run make again. You should be good to go!. #### tl;dr. If you're having this error, modi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/722#issuecomment-515693590:1868,install,installed,1868,https://su2code.github.io,https://github.com/su2code/SU2/issues/722#issuecomment-515693590,1,['install'],['installed']
Deployability,"(I was not expecting this many comments so quickly, thanks guys!). First let me clarify the intent.; I do not propose replacing the routines that deal with CSysMatrix, or change its format, all that (Krylov solvers, sparse approximate factorizations, etc.) is relatively independent from what I have in mind.; Nevertheless being able to use PETSc or HYPRE would be interesting as it would give us access to AMG, and @talbring 's branch feature_template_linear_solver would make such an integration compatible with AD.; What I would like is to have a ""CMatrixDense"" class, to give concrete examples:; - For RBF interpolation the guy who worked on it before me implemented his own Cholesky and LU factorizations, matrix-matrix, matrix-vector routines, etc.; - @jayantmukho recently needed some eigenvector decomposition's for the uncertainty quantification feature.; - I imagine in some other places of the code similar routines were needed, for example small matrix inversion when computing gradients by weighted least squares (indeed what I need now is a QR decomposition). And, as an added bonus, I think some other areas of the code could be simplified / optimized by adopting a dense matrix format, for example:; - This snipped from the viscous numerics refactoring`for (iDim = 0; iDim < nDim; iDim++) {; TauElem[iDim] = 0.0;; for (jDim = 0; jDim < nDim; jDim++); TauElem[iDim] += tau[iDim][jDim]*UnitNormal[jDim];; }` would simply become `TauElem=tau*UnitNormal`; - Cumbersome allocations like `tau_jacobian_i = new su2double* [nDim];; for (iDim = 0; iDim < nDim; iDim++) {; tau_jacobian_i[iDim] = new su2double [nVar];; }` become `Matrix tau_jacobian_i(nDim,nVar);` and the cleanup is dealt with by the destructor of the object automatically. Now to answer some questions.; @juanjosealonso @erangit LAPACK and BLAS are indeed the standard, so much so that most (all?) newer libraries will call their routines behind the scenes.; However they considerably simplify the user interface by encapsulat",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/643#issuecomment-459653772:486,integrat,integration,486,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459653772,1,['integrat'],['integration']
Deployability,",; const Vector& volume,; const Matrix& phi,; VectorOfMatrix& grad); {; const size_t SIMDLEN = 4;. for(size_t iPoint=0; iPoint<nPoint; iPoint+=SIMDLEN); {; for(size_t iVar=0; iVar<nVar; ++iVar); for(size_t iDim=0; iDim<nDim; ++iDim); grad.setVec(iPoint,iVar,iDim,Array<double,SIMDLEN>(0.0));. for(size_t iNeigh=0; iNeigh<adj.nNeighbor_vec(iPoint); ++iNeigh); {; auto jPoint = adj.jPoint_vec(iPoint,iNeigh);; auto iEdge = adj.iEdge_vec(iPoint,iNeigh);; auto dir = adj.dir_vec(iPoint,iNeigh);. for(size_t iVar=0; iVar<nVar; ++iVar); {; auto phi_ave = (phi.getVec(iPoint,iVar)+; phi.getVec(jPoint,iVar))*0.5;. for(size_t iDim=0; iDim<nDim; ++iDim); grad.addVec(iPoint,iVar,iDim,; phi_ave*dir*area.getVec(iEdge,iDim));; }; }. for(size_t iVar=0; iVar<nVar; ++iVar); for(size_t iDim=0; iDim<nDim; ++iDim); grad.setVec(iPoint,iVar,iDim,; grad.getVec(iPoint,iVar,iDim)/volume.getVec(iPoint));; }; }; ```; I think this is just as readable especially considering that in SU2 we always need to use some Set/Get/Add/Sub method to update a variable, the difference is that here those methods have overloads to operate on small fixed size vectors. The speedup is **1.35** (i.e. 35% faster than edge-based reference) note that the improvement relative to scalar-point-based is only 1.6, those pesky gathers... The loop advances `SIMDLEN` points on each iteration, yet there are no pragmas and small simd-loops in sight, in good C++ fashion that trickery has been encapsulated in a ""simd-friendly"" class.; Such a class can look something like this:; ```C++; template<class T, size_t N>; class Array; {; #define FOREACH for(size_t k=0; k<N; ++k); public:; enum : size_t {Size = N};; enum : size_t {Align = N*sizeof(T)};; private:; // fixed size and aligned array of internal data, naturally maps to a SIMD register; alignas(Align) T vals_[N];; /*; * Some helper methods go here; */; public:; // **** CONSTRUCTORS **** //; // We want to be able to construct this type from single scalars,; // a memory location from whi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-530328194:6280,update,update,6280,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530328194,1,['update'],['update']
Deployability,- Updated SetCFL_Number; - Small update; - Small change; - Small adjustments; - Minor changes; - Updated release 3.2.8; - MPI disabled by default in build. Added --enable-mpi flag to configure.; - Merged the ParMETIS implementation. Updated the build files.; - bootstrap; - Started parallel CGNS reader.; - Memory fix.; - Minor change; - Merge branch 'develop' of https://github.com/su2code/SU2 into develop; - Updated binaries; - Small change to configure.ac. Bootstrap.; - Small change; - Cleaning the code; - Updated grid deformation subroutine; - Fixing the mesh deformation; - Updated SU2_MSH; - Bug fixing; - Initial implementation of parallel CGNS reader. Works on 1 rank.; - Merged in recent changes to geometry_structure.cpp.; - Periodic BC working in serial; - Update option_structure.hpp; - Merge pull request #154 from su2code/fixCOptionEnumList; - Bug fixing (periodic bc); - Merge branch 'develop' of https://github.com/su2code/SU2 into develop; - Another important updated to BC in parallel; - More implementation and clean up of the parallel CGNS reader.; - Merge branch 'develop' of https://github.com/su2code/SU2 into develop; - CGNS reader bug fix.; - Updated adj. NS solver with primitive variables and farfield bc including viscous contribution.; - Merge branch 'develop' of https://github.com/su2code/SU2 into develop; - Small change; - Back to the previous version; - Fixed some loop variables.; - Merge branch 'develop' of https://github.com/su2code/SU2 into develop; - Bug fixes for CGNS.; - New slope limiter based on the wall distance; - Merge branch 'develop' of https://github.com/su2code/SU2 into develop; - Bug fixing; - Non-dimensional adjoint bc; - CGNS bug.; - Mixed-element support in new CGNS reader.; - Memory fix for mixed-element CGNS in parallel.; - Activated the parallel CGNS reader.; - New FFD input; - Adjacency building for Parmetis improve to account for VTK structure; - added if viscous steps to some adjeuler bcs; - Minor changes; - Back to previous v,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:6592,update,updated,6592,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['update'],['updated']
Deployability,"-------------------- Surface grid deformation ----------------------; Performing the deformation of the surface grid. ----------------------- Volumetric grid deformation ---------------------; Performing the deformation of the volumetric grid. # FGMRES residual history. # Residual tolerance target = 4.14044e-11. # Initial residual norm = 15.8102. ```; 0 1; 50 2.17385e-06; 100 1.08998e-10; ```. # FGMRES final (true) residual:. # Iteration = 105: |res|/|res0| = 3.50764e-11. Non-linear iter.: 1/1. Linear iter.: 105. Min. area: 4.1019e-08. Error: 5.54565e-10. ----------------------- Write deformed grid files -----------------------; Merging grid connectivity.; Merging grid coordinates.; Writing volume mesh file.; Writing surface mesh file.; Writing .su2 file.; Adding any FFD information to the SU2 file. Completed in 1.039217 seconds on 1 core. ------------------------- Exit Success (SU2_DEF) ------------------------. [image]https://cloud.githubusercontent.com/assets/5167760/9294056/7be9439a-440f-11e5-862f-742246ef1565.png; SU2_DEF: output when deforming with all markers included:. ------------------------- Surface grid deformation ----------------------; Performing the deformation of the surface grid.; No surface deformation (scaling, rotation, or translation). ----------------------- Volumetric grid deformation ---------------------; Performing a translation of the volumetric grid.; Translational displacement: (1, 0, 0). ----------------------- Write deformed grid files -----------------------; Merging grid connectivity.; Merging grid coordinates.; Writing volume mesh file.; Writing surface mesh file.; Writing .su2 file.; Adding any FFD information to the SU2 file. Completed in 0.716938 seconds on 1 core. as far as I can tell the regression test failure is the same as for the current develop branch; I'll update this pull request whenever that is resolved. —; Reply to this email directly or view it on GitHubhttps://github.com/su2code/SU2/pull/187#issuecomment-131578218.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/187#issuecomment-132065067:3337,update,update,3337,https://su2code.github.io,https://github.com/su2code/SU2/pull/187#issuecomment-132065067,1,['update'],['update']
Deployability,". ; Various deallocation changes; Some regression tests fail but all run. (previously was not the case); You can view, comment on, or merge this pull request online at:;   https://github.com/su2code/SU2/pull/174; Commit Summary; - Updated GetEngine_Properties; - Fix to the last commit; - Small bug; - Merge branch 'develop' into feature_MPI; - merging; - SU2_SOL and SU2_CFD are working; - Preliminary, but complete, implementation of SU2_DEF; - More updates; - Working version; - Complete implementation (validate); - Working version of SU2_DEF; - Final push before moving to the develop branch; - New MPI (removing SU2_PRT); - Merged in Ben's ParMETIS integration and fixed some conflicts.; - Merge branch 'benkirk-parmetis_integration' into feature_MPI; - ParMETIS geometry routines have been copied over but are not activated yet.; - Small change to ParMETIS include.; - ParMETIS can now be activated for testing (PARMETIS=YES in config).; - Updated MG; - Updated EA subrotuine; - Small fix; - Fixing memory leak; - Fixing memory leaks; - Dev release v.3.2.6; - Increasing MAX_NUMBER_MARKER; - Working version with ParMETIS. Fixed bug in global index. Now clean up and testing...; - Cleaned version of ParMETIS routines with better console output during partitioning.; - Small bug in initial element division.; - Made arrays in ParMETIS call dynamic.; - Fixed compiler warnings and added MPI directives so that the pure serial code works with the ParMETIS routines.; - Bootstrap on zion.; - Added some typecasts. Still tracking down a memory problem...; - Critical bug fix for vtxdist array.; - Partial fix; - More MPI improvements.; - Fixing a bug in SU2_DEF; - Updated BC_ActDisk_Boundary (MPI); - Merge remote-tracking branch 'upstream/develop' into develop; - changing solidboundary setting to be heatflux OR euler etc instead of AND, also working on doxygen documentation; - Dynamic allocation for some marker-related arrays.; - visualize part taken out to match upstream/dev; - Collection o",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:1937,release,release,1937,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['release'],['release']
Deployability,".2.8.3; - Updated CGNS in parallel.; - Added the ability to writting 2 files at each checkpoint when using 2nd order dual time stepping; - Merge branch 'develop' into feature_dualoutput; - Updated FieldView; - Preliminary implementation (ASCII); - Minor changes; - Update code; - Updated FieldView format; - Merge branch 'develop' into feature_dualoutput; - Bug fixing; - Updated FieldView ASCII format; - Complete implementation of the FFD_CONTINUITY capability; - Updated FFD intersections; - ver 3.2.9; - adding targetea file to equivalent area adjoint folder. address issue #160; - Merge branch 'develop' of github.com:su2code/SU2 into develop; - Final push to v3.2.9; - after bootstrap; - updates to comments in config_structure to make doxygen pretty; - Bug fixing; - Merge branch 'develop'; - EA in ft^2; - further update to config; - Merge remote-tracking branch 'upstream/develop' into upstream_dev; - Minor changes; - Updated NF BC; - More adjustments; - Small update; - Final update Nearfield BC; - added massflowrate as option for cauchy criteria, more config file comments; - Merge remote-tracking branch 'upstream/develop' into upstream_dev; - paraview output modified/added back in for current version for SU2_DEF; - Merge branch 'develop' into feature_dualoutput; - Removed deprecated options from quicstart config.; - Working version of the compressible actuator disk; - Updated fixed CL mode.; - Very minor change; - Merge branch 'develop' into feature_dualoutput; - Final push to 3.2.9; - Merge branch 'develop'; - Minor change; - Minor change; - Small change; - Minor change; - Bug fixing: unsigned short val_vertex --> unsigned long val_vertex; - CFL adapt now works for adjoint problems; - Merge branch 'develop' into feature_dualoutput; - Fixing a typo; - Fix in the Euler BC for grid movement cases; - merging and fixing conflicts bwtn feature_dealloc and develop; - dealloc; - Time spectral fix.; - Merging some recent bug fixes from master into the develop branch to keep nsy",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:8878,update,updates,8878,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,4,['update'],"['update', 'updates']"
Deployability,".cmake<https://github.com/su2code/SU2/pull/814/files#diff-19> (12); * A cmake/ConfigureParmetis.cmake<https://github.com/su2code/SU2/pull/814/files#diff-20> (15); * A cmake/ConfigureTecio.cmake<https://github.com/su2code/SU2/pull/814/files#diff-21> (18); * A cmake/ConfigureThreads.cmake<https://github.com/su2code/SU2/pull/814/files#diff-22> (12); * A cmake/FindMKL.cmake<https://github.com/su2code/SU2/pull/814/files#diff-23> (318); * A cmake/FindMPI4PY.cmake<https://github.com/su2code/SU2/pull/814/files#diff-24> (50); * A cmake/LibraryUtils.cmake<https://github.com/su2code/SU2/pull/814/files#diff-25> (239); * A cmake/TLS.cmake<https://github.com/su2code/SU2/pull/814/files#diff-26> (28); * A cmake/check_thread_storage.c<https://github.com/su2code/SU2/pull/814/files#diff-27> (5); * A cmake/functions.cmake<https://github.com/su2code/SU2/pull/814/files#diff-28> (416); * A externals/cgns/CMakeLists.txt<https://github.com/su2code/SU2/pull/814/files#diff-29> (26); * A externals/metis/CMakeLists.txt<https://github.com/su2code/SU2/pull/814/files#diff-30> (108); * A externals/parmetis/CMakeLists.txt<https://github.com/su2code/SU2/pull/814/files#diff-31> (70); * A externals/tecio/CMakeLists.txt<https://github.com/su2code/SU2/pull/814/files#diff-32> (36); * M externals/tecio/teciompisrc/CMakeLists.txt<https://github.com/su2code/SU2/pull/814/files#diff-33> (119); * M externals/tecio/teciosrc/CMakeLists.txt<https://github.com/su2code/SU2/pull/814/files#diff-34> (264). Patch Links:. * https://github.com/su2code/SU2/pull/814.patch; * https://github.com/su2code/SU2/pull/814.diff. —; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/pull/814?email_source=notifications&email_token=AA5FFRFS4TZSJGYCKUPXXHTQTBNV7A5CNFSM4JLN2P32YY3PNVWWK3TUL52HS4DFUVEXG43VMWVGG33NNVSW45C7NFSM4HYINCSQ>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AA5FFRBIPVWMMOXUKXI3BZDQTBNV7ANCNFSM4JLN2P3Q>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/814#issuecomment-552242380:7526,patch,patch,7526,https://su2code.github.io,https://github.com/su2code/SU2/pull/814#issuecomment-552242380,1,['patch'],['patch']
Deployability,".py script. The command used was:. ```; python3 $SU2_RUN/mesh_adaptation_amg.py -f adapt_Mesh.cfg -n 4; ```; The script initiates the mesh adaptation process as expected, with the following output:. ```; SU2-AMG Anisotropic Mesh Adaptation. Mesh adaptation options:; PYADAP_COMPLEXITY : (30000, 60000, 120000); PYADAP_SUBITE : (2, 2, 2); PYADAP_SENSOR : GOAL; PYADAP_HMAX : 500.0; PYADAP_HMIN : 1e-9; PYADAP_HGRAD : 1.8. ./adap exists. Removing old mesh adaptation in 10s.; The ./adap folder was deleted. Generating GMF background surface mesh.; Initial CFD solution is provided.; ```; However, no _adap\ite0_ folder gets created. ; The log.err file in the _adap/ini_ directory provides this traceback:. ```; Traceback (most recent call last):; File "".../mesh_adaptation_amg.py"", line 111, in <module>; ...; RuntimeError: ...; Error in TokenizeString(): two or more options before an ""="" sign in the configuration file.; terminate called after throwing an instance of 'int'; ...; *** Process received signal ***; Signal: Aborted (6); Signal code: (-6); ...; ```. The critical part of this error seems to be the Error in TokenizeString() message, suggesting an issue with parsing the configuration file. This error typically indicates a syntax problem, such as having multiple options on a single line without proper separation by an equal sign (=). However, upon reviewing _adap/ini/config_CFD.cfg_, was unable to find any lines that clearly violated this syntax rule. Could this error be indicative of a more subtle issue within the configuration file, or might it be related to specific aspects of the feature_adap branch? Any insights, suggestions, or guidance on how to troubleshoot this error would be greatly appreciated. If anyone has a working adapt_mesh.cfg file for a similar setup or for the feature_adap branch, I would be very interested in seeing it. Understanding the configuration details of a working example could be highly beneficial in resolving my issue. Thank you for your help!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/948#issuecomment-1847333809:1520,configurat,configuration,1520,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-1847333809,3,['configurat'],['configuration']
Deployability,"092: result: yes; configure:3117: checking for style of include used by make; configure:3145: result: GNU; configure:3196: result: >>> MPI support disabled by default <<<; configure:3269: checking for g++; configure:3285: found /usr/bin/g++; configure:3296: result: g++; configure:3323: checking for C++ compiler version; configure:3332: g++ --version >&5; g++ (GCC) 4.4.6 20120305 (Red Hat 4.4.6-4); Copyright (C) 2010 Free Software Foundation, Inc.; This is free software; see the source for copying conditions. There is NO; warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. configure:3343: $? = 0; configure:3332: g++ -v >&5; Using built-in specs.; Target: x86_64-redhat-linux; Configured with: ../configure --prefix=/usr --mandir=/usr/share/man --infodir=/usr/share/info --with-bugurl=http://bugzilla.redhat.com/bugzilla --enable-bootstrap --enable-shared --enable-threads=posix --enable-checking=release --with-system-zlib --enable-__cxa_atexit --disable-libunwind-exceptions --enable-gnu-unique-object --enable-languages=c,c++,objc,obj-c++,java,fortran,ada --enable-java-awt=gtk --disable-dssi --with-java-home=/usr/lib/jvm/java-1.5.0-gcj-1.5.0.0/jre --enable-libgcj-multifile --enable-java-maintainer-mode --with-ecj-jar=/usr/share/java/eclipse-ecj.jar --disable-libjava-multilib --with-ppl --with-cloog --with-tune=generic --with-arch_32=i686 --build=x86_64-redhat-linux; Thread model: posix; gcc version 4.4.6 20120305 (Red Hat 4.4.6-4) (GCC) ; configure:3343: $? = 0; configure:3332: g++ -V >&5; g++: '-V' option must have argument; configure:3343: $? = 1; configure:3332: g++ -qversion >&5; g++: unrecognized option '-qversion'; g++: no input files; configure:3343: $? = 1; configure:3363: checking whether the C++ compiler works; configure:3385: g++ conftest.cpp >&5; configure:3389: $? = 0; configure:3437: result: yes; configure:3440: checking for C++ compiler default output file name; configure:3442: result: a.out; configure:3448: checking for suffix of exec",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:3336,release,release,3336,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,1,['release'],['release']
Deployability,"> ; > ; > @tollennaert, can you comment on the points raised by @pcarruscag ? I think you tried to address all points in your latest update? That makes it clear to everybody that all points have been addressed. I hope you still have time for this. I indeed tried to solve all issues that were mentioned earlier. Could you take another look to see whether I have done this well enough?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1076#issuecomment-741601433:133,update,update,133,https://su2code.github.io,https://github.com/su2code/SU2/pull/1076#issuecomment-741601433,1,['update'],['update']
Deployability,"> ; > ; > Dear Daumantas,; > ; > I appreciate your effort in adding support for cmake in SU2. We have recently introduced the Meson build system (https://mesonbuild.com/) (#685, #745) as a candidate to replace automake. A guide on how to use can be found [here](https://su2code.github.io/docs_v7/Build-SU2-From-Source/). The idea is that we will have this system along automake at least for the upcoming version 7 and that we get rid of automake afterwards. Considering that, I don't think that it makes sense to maintain 3 different build systems **at the moment**. I really hate turning contributions down, but this one is three months too late. However, we might reconsider adding support for another build system once we got rid of automake, or, if we feel that meson does not fit our needs.; > ; > I am all ears to hear other opinions. However, let's not start a discussion on the advantages/disadvantages of the build systems. Some benefits can be found in the Issue/PR linked above. Ok, I tried meson with MinGW but couldn't figure out how to link with MSMPI since it's not a part of MinGW. However, using CMake and with a few source code fixes, I managed to compile nearly every configuration with MSVC. Surprisingly, there were very few errors in SU2. The externals only had a few preprocessor issues. At the moment only MeDiPack fails to compile with MSVC but not with MinGW even though the MPI headers are the same so I suspect it's an issue with MSVC itself, I'm using the latest preview version.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/814#issuecomment-553571450:1187,configurat,configuration,1187,https://su2code.github.io,https://github.com/su2code/SU2/pull/814#issuecomment-553571450,1,['configurat'],['configuration']
Deployability,"> @SumanVajjala gcc 5+ have full c++ 11 support (even more than that actually). As a last resort, if you cannot figure out what is going on with the compilers (simpler guess is that there are other versions installed and they are getting mixed up?), you can try replacing the file ""allocation_toolbox.hpp"" by this:; > [allocation_toolbox_PATCH.txt](https://github.com/su2code/SU2/files/4550786/allocation_toolbox_PATCH.txt). @pcarruscag Thank you very much. This works. I have installed a sequential version and a parallel version with tecio,codipack and medipack enabled. I will try the same with Intel compilers and see if it works. Regards; Suman",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/955#issuecomment-621164605:207,install,installed,207,https://su2code.github.io,https://github.com/su2code/SU2/issues/955#issuecomment-621164605,2,['install'],['installed']
Deployability,"> @kursatyurt Hello, thank you so much for the lead.; > ; > Our initial scope mostly involved writing our own kernels and I did explore some libraries at the start - I was planning on using CUSP as well but my main concern was its lack of being updated to the newly compatible versions of the toolkit. cuSolver and cuBLAS do exist, but I chose to go ahead with a ""simple"" kernel implementation to have more control. I also felt that if I could keep the block size of the grid in optimal territory then they could be just as fast as those options (please do correct me if my reading of the literature or the situation was incorrect). To learn the basics, it's a good idea, but for large-scale projects, I prefer using existing libraries if possible.; Those libraries generally exploit state-of-the-art solution like mixed-precision computing. A gaming GPU is not way faster than a good CPU in double precision, but way faster in single precision, most of them have 64:1 ratio, however server class GPU have 2:1 ratio. Also when available they use vendor libraries like cuBLAS or hipBLAS. It is always nice to have you only care about connection and somebody else handle the solver as performant as possible. In future probably they will provide more and more solvers and it will be automagically works. It is kind of light-weight too, not a huge dependency like Trilinos or PETSc. ; > ; > I was not aware of Ginkgo and I will surely give it a go and try to produce some comparative results. I am currently super busy for this month and will get to working on the code with some delay.; > ; > Again, thank you for the lead!. I can test on various GPUs (P100/V100/A100 and 4070Mobile) on single node multi-gpu etc.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/2346#issuecomment-2397803409:245,update,updated,245,https://su2code.github.io,https://github.com/su2code/SU2/pull/2346#issuecomment-2397803409,1,['update'],['updated']
Deployability,"> How should I update my branch with upstream/develop? Should I merge upstream/develop into my branch (and push to my fork on github)? Or may I rebase my branch on top of upstream/develop (and force push to my fork on github)?. Both ways are legit, feel free to use which one is easier for you [here](https://www.freecodecamp.org/news/the-ultimate-guide-to-git-merge-and-git-rebase/) a comparison between them. It depends on the taste of the developer. . > I assume I should add myself to the _Individual Contributors_ section of AUTHORS.md, is that correct?. Yes",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1951#issuecomment-1466144727:15,update,update,15,https://su2code.github.io,https://github.com/su2code/SU2/pull/1951#issuecomment-1466144727,1,['update'],['update']
Deployability,"> I don't known how the process to find the alpha that gives you a given CL works, but could the derivative not be obtained from this process? i.e. you could avoid the FD step entirely. It is a simple proportional controller that will change the angle of attack after a number of iterations depending on the difference between the current CL and the target CL. . So if the the option `ITER_DCL_DALPHA = 0` then it will do exactly what you suggest. It calculates the derivative based on the last update. The only problem with that is, there is no guarantee that the simulation at the previous update was converged, so the derivative might be incorrect. . But you are correct, I could just do a really tiny update (order of delta AoA ~10^-6) at the end and calculate the finite difference using that value. Let me try that and see if the gradients it calculates are reasonable, or if the update is too small and it gets clouded by numerical errors.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/780#issuecomment-539606698:495,update,update,495,https://su2code.github.io,https://github.com/su2code/SU2/pull/780#issuecomment-539606698,4,['update'],['update']
Deployability,"> Note that you need to checkout this branch `fix_2d_periodic_rotation` (it is not in `develop` yet). Hi Pedro,; I checked the files you sent but building SU2 from source provided some errors:. - _MinGW64_ files provided from SU2 official website are corrupted and the installation crashes; however, it is possible to install the software but the .exe file mentioned in the installation guide won't be present. ; - After building _meson.py_ , the ninja installation command was line typed and the following alert message appeared "" **ninja: fatal: chdir to 'build' - No such file or directory** "". On a different laptop (with different user, to avoid the same mistakes) the following ERROR came up after the mason.py command line:; "" **'meson.py' is not recognized as an internal or external command, operable program or batch file** "". I don't know if any other user might have experienced the same errors. ; Anyway, are the bugfix files you published already available in the pre-compiled version? ; In the meanwhile, I'll try to figure out this inconvenient. Thank you in advance.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1562#issuecomment-1069325722:269,install,installation,269,https://su2code.github.io,https://github.com/su2code/SU2/issues/1562#issuecomment-1069325722,4,['install'],"['install', 'installation']"
Deployability,"> Our working branch is 'develop', so you should have started from that and also merge into it. Every 6 months or so we then make the current develop into master. I changed the target branch to develop, and also updated your branch with current develop. Can you have a look at the failed check for clang-format coding style and format the changed file accordingly? https://su2code.github.io/docs_v7/Style-Guide/. Thanks a lot! It's very much appreciated. I have implemented the clang-format according to the guide and force formatting all files by using 'pre-commit run -a'. I think the new commits should be conformed to the coding style but not sure if the previous commit is also changed.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/2173#issuecomment-1951941110:212,update,updated,212,https://su2code.github.io,https://github.com/su2code/SU2/pull/2173#issuecomment-1951941110,1,['update'],['updated']
Deployability,"> Thank you for updating the solution file @snow54 , there's quite a big difference in the adjoint residuals, do the final derivatives still make sense? Is the flow field noticeably different (for the better, e.g. smoother? or equivalent to not having the boundary at all?) now that nearfield is treated as an internal boundary?; > If so let's update the residuals and merge. I think we can update the residuals. Gradients between adjoint and finite difference match quite well as shown below. I haven't finished calculating for all design variables, but I think it is enough. ![Comparison_gradient](https://user-images.githubusercontent.com/18245846/129564585-d7812108-d315-4606-83d9-e39a8c9403b3.png). In terms of flow field, the capture below is from the current develop branch. The boundary between structured grid and unstructured gird is a nearfield boundary. An object is above this capture and pressure wave propagates from there. Since this grid is inclined by Mach angle, pressure distribution on the nearfield should be fairly similar to the region above but this capture shows some strange pressure disturbance. Limiter: VAN_ALBADA_EDGE; ![NF_before](https://user-images.githubusercontent.com/18245846/129564639-030fe1b7-7e50-4bb1-9951-21f5ea27bb52.png). Limiter: VENKATAKRISHNAN_WANG; ![NF_before_VEN](https://user-images.githubusercontent.com/18245846/129568934-137681db-04db-40f1-819f-7bcc8c7e0d88.png). The capture below is from the branch with this PR. The issue I mentioned above does not exist. Limiter: VAN_ALBADA_EDGE; ![NF_after](https://user-images.githubusercontent.com/18245846/129564659-cec5a848-1b0b-4051-8298-e3d383dacc6d.png). I think the residuals for direct solver will be different like the adjoint if you run it for some hundreds more iterations (currently, the test case has only 20 iterations). However, since the nearfield boundary is a bit far from an object, it takes some iterations for pressure waves to reach the nearfield boundary. This PR also solves an issu",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1351#issuecomment-899498618:344,update,update,344,https://su2code.github.io,https://github.com/su2code/SU2/pull/1351#issuecomment-899498618,2,['update'],['update']
Deployability,"> the off-PR comments can be integrated in this PR to clear that up a bit. If not that is OK as well. It's more than OK, the CHT implementation suffers a bit from being a single person's project.. you're very welcome to have a look over it! :-). > Can you add that option to the config_template.cfg together with that description, the valid inputs and the default. Actually I'm hesitating a bit adding it to the config template right now. I'd prefer to have `DIRECT_TEMPERATURE_ROBIN_HEATFLUX` as the default and ""hide"" the rest as developer's options for the moment.; The reason simply is that those different methods need to checked and validated against each other before we make them public.; E.g. I figured that for the incompressible CHT test case from the repo, there is a severe gap between the heatfluxes obtained from the ""averaged"" approach and the direct one, see below. ![heatflux_convergence](https://user-images.githubusercontent.com/22639394/72885197-bb9e4a80-3d07-11ea-9fad-a4d709dc511e.png). That needs to be cleared up first...",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/839#issuecomment-577108935:29,integrat,integrated,29,https://su2code.github.io,https://github.com/su2code/SU2/pull/839#issuecomment-577108935,1,['integrat'],['integrated']
Deployability,"@SumanVajjala gcc 5+ have full c++ 11 support (even more than that actually). As a last resort, if you cannot figure out what is going on with the compilers (simpler guess is that there are other versions installed and they are getting mixed up?), you can try replacing the file ""allocation_toolbox.hpp"" by this:; [allocation_toolbox_PATCH.txt](https://github.com/su2code/SU2/files/4550786/allocation_toolbox_PATCH.txt)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/955#issuecomment-621090526:205,install,installed,205,https://su2code.github.io,https://github.com/su2code/SU2/issues/955#issuecomment-621090526,1,['install'],['installed']
Deployability,"@bigfooted @economon and @pcarruscag . I created separate repo to demonstrate what I'm after in the simplest way possible: [FoamScience/AutoRegistering-Cpp-Classes](https://github.com/FoamScience/AutoRegistering-Cpp-Classes/commits/master). > If you're going to check the code, check CSolver first, then CEulerSolver ... - Commit FoamScience/AutoRegistering-Cpp-Classes@20ca601 implements the concept for a single Factory.; - (Make-believe) Standard solver classes are compiled to a library; - A (Make-beleive) Custom solver class is compiled to its own shared library; - By default, the make program knows only about CEulerSolver (from standard solvers lib); - But if you pass in a library name (eg. libCCustomSolvers.so), it gets loaded, symbols pulled and the registration map for CSolver gets updated with the new Solver automatically. - But it would bloat the code if things went this way, so commit FoamScience/AutoRegistering-Cpp-Classes@380c052 isolates self-registration code into 3 macros to:; - Declare the registration map and associated members; - Define and initialize registration-related members on the base class; - Register a class. If you only care about the interface and not how the thing is implemented, commit 380c052 is your target.; I took care to document the important parts of the code, so, please, dig in and let me know what you think. At this point, integrating this with SU2 (and at what parts, and when) is your call but If you decide to do so, l will help.; > And yes, I wrote my own build script so I can have direct control over the compiler and the linker. **One last note: I used ""dlopen"", so you will have to compile the code on Linux I suppose.**",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1058#issuecomment-680962672:797,update,updated,797,https://su2code.github.io,https://github.com/su2code/SU2/issues/1058#issuecomment-680962672,2,"['integrat', 'update']","['integrating', 'updated']"
Deployability,"@bigfooted Has there ever been any discussion regarding implementation of a `START_TIME=` capability into the config file? After going through the code a bit, it looks like doing this would be a good starting point for implementing ability to adjust deltaT mid-runs, as in general the code presumes `TimeIter*deltaT` as being the current time. This would be problematic for unsteady restarts that have a varying timestep. Plus, this would allow one to, without using the Python wrapper, use a different timestep in the config file for an unsteady restart. It also may clear up some confusion to have an explicit option for this, as in #2071. It can maybe look something like:. % Start time for restarting unsteady simulations; % = -1 for default calculation (START_TIME=RESTART_ITER*TIME_STEP); START_TIME=-1. Then `CConfig::GetPhysicalTime` could be appropriately updated and used in-place of all locations in the code where a physical time is manually calculated.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/2190#issuecomment-1870730956:865,update,updated,865,https://su2code.github.io,https://github.com/su2code/SU2/pull/2190#issuecomment-1870730956,1,['update'],['updated']
Deployability,"@clarkpede @EduardoMolina : yep, the issue is that the periodic and MPI communications are tangled up together in the current implementation. The main issue occurs when there are periodic points that are also ghost nodes. . Ideally the periodic and MPI would be separated, and the periodic communications would happen first so that all periodic BCs are synchronized before trying to send across partitions. Right now, the comms are mixed, so sometimes, we send old data at periodic points to their matching pair, which then gets updated in a later MPI comm. Therefore, the second call you have added to the MPI resends the periodic update to with the correct data that was updated with MPI in the first call. I hope this is clear.. Anyway, please go with this change as you have it. All of the MPI and periodic comms will be replaced with a cleaner/separated version right after v6.2.0 (you can see what I am working on in feature_mpi_periodic). I will likely need some help testing that soon :).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/649#issuecomment-463711280:529,update,updated,529,https://su2code.github.io,https://github.com/su2code/SU2/pull/649#issuecomment-463711280,3,['update'],"['update', 'updated']"
Deployability,"@clarkpede Great, thanks for the details. I see your point. In general, vortex shedding cases are indeed challenging to match with the experiments, but that's what makes them interesting at the end. For a start, I am aiming to obtain comparable behaviours with both the compressible and the incompressible unsteady solvers under similar settings, rather than matching with experiments; mostly as an acceptance test as well. I am now working with standard SST turbulence model, but if you could share some simple meshes/cfg files to have a first go with hybrid RANS/LES, I would really appreciate it. > Good catch. I just pushed a commit that adds SetMaxLength calculations in all the instances I could find where the geometry updates. Thanks for the fix!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/552#issuecomment-404097397:726,update,updates,726,https://su2code.github.io,https://github.com/su2code/SU2/pull/552#issuecomment-404097397,1,['update'],['updates']
Deployability,"@economon I was envisioning something similar to the TestCases folder. With v&v cases grouped according to what they are testing. Something along the lines of: . 1) Inviscid Simulations: ; a) 2D Inviscid bump; b) 2D oblique shocks interaction; c) ...; 2) RANS simulations: ; a) Flatplate; b) NACA0012; c) ...; 3) Unsteady simulations:; a) Square Cylinder; b) ...; 4) Turbomachinary: ; a) ... And so on. Each of the directories would have sub-directories for different mesh sizes, with configuration files for each mesh level that have optimized parameters for best results. So for example if we are talking about the NACA0012 case, we would have something along the lines of: . a) NACA0012; i) 113 x 33; ii) 225 x 65 ; iii) 449 x 129; iv) ... This way we have a family of meshes and configuration files that are specifically built for the purpose of validating the code and comparing with other solvers. I might be useful to compress meshes that are larger than a certain size (say 10MB). We should also put a limit on the size of a single mesh that the repository can handle (say 50MB?). . Within the home directory, the README file should list all the cases in the repository, who the custodian of the test case is (person with meshes in case the meshes are too large), and which version it was last run on. . I thought about splitting it up into Verification cases and Validation cases, but I thought it would be more informative and intuitive to split up according to the physics of the simulations. My thinking might be limited because that's how I have seen the TestCases folder organized, so any other suggestions are welcome. I think it is imperative that this is accompanied with a section on the SU2 website that showcases just the results of the validation test cases (grid convergence studies, residual reductions etc) and links to the v&v repo appropriately. This way, if people are just inquisitive about SU2's performance, they can get a quick snapshot of the results, without the need ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/581#issuecomment-426026053:485,configurat,configuration,485,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-426026053,2,['configurat'],['configuration']
Deployability,"@fpalacios - For the continuous adjoint it is NOT required to run multiple adjoints, you can actually combine them. Whether or not to do so is controlled by the OPT_COMBINE_OBJECTIVE option - I will try to add in some more comments as you suggest to make this clearer, along with other updates next week.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/385#issuecomment-294324095:21,continuous,continuous,21,https://su2code.github.io,https://github.com/su2code/SU2/pull/385#issuecomment-294324095,2,"['continuous', 'update']","['continuous', 'updates']"
Deployability,"@hlkline : it is true that we have been experimenting a lot to find the best formula, and no doubt we will continue to tweak things as we constantly evolve. But, one constant you can always trust is that the repo will be the home for important decisions on issues and PRs, so there is no need to worry about missing critical updates. . With slack and now rocket chat, we are looking to improve communication efficiency as people collaborate on particular developments in the code (say in pairs or small groups), or perhaps in the future, it can be opened to the public as a sort of support channel. This is to be seen as we gather some experience and feedback.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/645#issuecomment-464602965:325,update,updates,325,https://su2code.github.io,https://github.com/su2code/SU2/issues/645#issuecomment-464602965,1,['update'],['updates']
Deployability,"@kursatyurt Hello, thank you so much for the lead. Our initial scope mostly involved writing our own kernels and I did explore some libraries at the start - I was planning on using CUSP as well but my main concern was its lack of being updated to the newly compatible versions of the toolkit. cuSolver and cuBLAS do exist, but I chose to go ahead with a ""simple"" kernel implementation to have more control. I also felt that if I could keep the block size of the grid in optimal territory then they could be just as fast as those options (please do correct me if my reading of the literature or the situation was incorrect). I was not aware of Ginkgo and I will surely give it a go and try to produce some comparative results. I am currently super busy for this month and will get to working on the code with some delay. Again, thank you for the lead!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/2346#issuecomment-2397639761:236,update,updated,236,https://su2code.github.io,https://github.com/su2code/SU2/pull/2346#issuecomment-2397639761,1,['update'],['updated']
Deployability,@pcarruscag Based on your 2nd review we have updated the code according to your suggestions. It was not clear how to restore the accidental changes to the sha versions of submodules externals/codi/ and subprojects/CoolProp/. Please instruct us howto or override yourselves for the same if possible. Request you to please review and instruct for proceeding further.; Thank you very much.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/2142#issuecomment-1793649845:45,update,updated,45,https://su2code.github.io,https://github.com/su2code/SU2/pull/2142#issuecomment-1793649845,1,['update'],['updated']
Deployability,"@rsanfer and me had a discussion on it. We both came to the agreement that it might the best if we just remove the generated files from the repo in general. Since buildtools are already required to have 'make' it shouldn't be much of a burden to also require autotools/automake to be installed. Furthermore, we eventually could provide a simple way of installing/compiling it within the preconfigure.py script if necessary.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/586#issuecomment-423942141:284,install,installed,284,https://su2code.github.io,https://github.com/su2code/SU2/pull/586#issuecomment-423942141,2,['install'],"['installed', 'installing']"
Deployability,"@talbring Thanks for the quick and helpful answer! I'm looking at creating an ebuild/package for gentoo, compilation is a lot simpler than OpenFoam :P which is a big plus :). Anyway, I was looking at the old docs (the main docs still point to 6.0, I missed the red text that mentioned that somehow :P), not sure why, but you're right it's indeed mentioned in the 7.0 docs here https://su2code.github.io/docs_v7/Build-SU2-Linux-MacOS/#configuration-and-compilation. The ""Automatically installed dependencies"" section left me a bit confused because it sounded like the things listed there, which includes meson and ninja, would always get installed.; Maybe merging that section into the configuration and compilation section might help to make it more clear?. If you don't mind I have some additional questions:; - I didn't initialize the git submodule at all and configuration, compilation and running worked fine. Does this mean the CoDiPack and MeDiPack dependencies are optional? Or does this mean I could have a crash at runtime somewhere?; - Would it be possible to add a source package to the GitHub releases (in addition to the binary ones) that includes the (CoDiPack and MeDiPack) submodules? Unfortunately the GitHub provided source downloads don't include submodules.; - Are MKL and OpenBLAS build-time and exclusive options or can they both be compiled in and chosen at runtime?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/911#issuecomment-598751341:434,configurat,configuration-and-compilation,434,https://su2code.github.io,https://github.com/su2code/SU2/issues/911#issuecomment-598751341,6,"['configurat', 'install', 'release']","['configuration', 'configuration-and-compilation', 'installed', 'releases']"
Deployability,"@talbring Yes, I do. I can't uninstall it since it breaks other packages. @pcarruscag Yeah same for me. You can see it here:; ```; slimshady@arch-linux-hp-probook-g3-450: ~$ mpicc -v; mpicc for MPICH version 3.3.2; Using built-in specs.; COLLECT_GCC=gcc; COLLECT_LTO_WRAPPER=/usr/lib/gcc/x86_64-pc-linux-gnu/9.2.1/lto-wrapper; Target: x86_64-pc-linux-gnu; Configured with: /build/gcc/src/gcc/configure --prefix=/usr --libdir=/usr/lib --libexecdir=/usr/lib --mandir=/usr/share/man --infodir=/usr/share/info --with-pkgversion='Arch Linux 9.2.1+20200130-2' --with-bugurl=https://bugs.archlinux.org/ --enable-languages=c,c++,ada,fortran,go,lto,objc,obj-c++,d --enable-shared --enable-threads=posix --with-system-zlib --with-isl --enable-__cxa_atexit --disable-libunwind-exceptions --enable-clocale=gnu --disable-libstdcxx-pch --disable-libssp --enable-gnu-unique-object --enable-linker-build-id --enable-lto --enable-plugin --enable-install-libiberty --with-linker-hash-style=gnu --enable-gnu-indirect-function --enable-multilib --disable-werror --enable-checking=release --enable-default-pie --enable-default-ssp --enable-cet=auto gdc_include_dir=/usr/include/dlang/gdc; Thread model: posix; gcc version 9.2.1 20200130 (Arch Linux 9.2.1+20200130-2) ; ```; I did what you suggested and here is how my meson.build file looks.; ```; # If custom mpi mode is enabled, include and library pathes for MPI have to be set manually to env variables; if get_option('custom-mpi'); mpi_dep = []; mpi = true; # Otherwise they are automatically determined; else; mpi_dep = [dependency('mpich', required : get_option('with-mpi'))]; # mpi_dep = [dependency('mpi', language:'c', required : get_option('with-mpi')),; # dependency('mpi', language:'cpp', required : get_option('with-mpi'))]; #if mpi_dep[0].found() or mpi_dep[1].found(); # mpi = true; #endif; endif; ```; My SU2 build was successful but there were a couple of warnings.; Also, instead of 870 there were only 772 files in total. Is that okay?; ```; slimshady@",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1000#issuecomment-633139474:929,install,install-libiberty,929,https://su2code.github.io,https://github.com/su2code/SU2/issues/1000#issuecomment-633139474,2,"['install', 'release']","['install-libiberty', 'release']"
Deployability,"@talbring: thanks for adding the regressions. One iteration is perfect just to check they're running, if they have the originals still being tested in the TestCases. I think the idea of having the written tutorials/documentation for the test cases in the main repository is a very good one, for several reasons. In particular, it will make it easier for people to add documentation, and we could eventually even test for its existence in Travis or make it a strict requirement for PRs in the future. My only concern at the moment is making sure that they look ""nice"" when viewed and that the links are easy to update/follow. We should probably add a title at the top of each tutorial markdown file now (above the first image), since the titles from the wiki page are missing. The image files should be moved from the website repo (su2code.github.io/github_wiki/) to these Tutorials folders. Another idea is to put a top-level ""Tutorials"" markdown file that will be linked from the wiki at the root Tutorials/ directory so that one only has to update the links to new tutorials in that file in the main repo, rather than always updating both the main repo and manually updating the wiki too. Any other ideas for making this seamless and user-friendly are most welcome! Let me know if you need any help.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/485#issuecomment-355216605:610,update,update,610,https://su2code.github.io,https://github.com/su2code/SU2/pull/485#issuecomment-355216605,2,['update'],['update']
Deployability,"@tollennaert, can you comment on the points raised by @pcarruscag ? I think you tried to address all points in your latest update? That makes it clear to everybody that all points have been addressed. I hope you still have time for this.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1076#issuecomment-733607872:123,update,update,123,https://su2code.github.io,https://github.com/su2code/SU2/pull/1076#issuecomment-733607872,1,['update'],['update']
Deployability,"A short summary of the things I did in the additional commits:. - I added a consistent error handling that can be used throughout the code. For example if a marker is not specified the error looks like that: ; ```; -------------------------------- Error ---------------------------------; In ""short unsigned int CConfig::GetMarker_CfgFile_TagBound(std::__cxx11::string)"": ; ------------------------------------------------------------------------; The configuration file doesn't have any definition for marker airfoil; ------------------------------------------------------------------------; Exiting now ...; ```; or if a solution cannot be found:. ```; -------------------------------- Error ---------------------------------; In ""void CSolver::Read_SU2_Restart_Metadata(CGeometry*, CConfig*, bool, std::__cxx11::string)"": ; ------------------------------------------------------------------------; Unable to open SU2 restart file solution_flow.dat; ------------------------------------------------------------------------; Exiting now ...; ```; In case you want to throw an error, you can simply call the function `SU2_MPI::Error(""Error Message"", CURRENT_FUNCTION)` where `CURRENT_FUNCTION` is a predefined macro which expands to the name of the routine at compile time. I already replaced almost all error messages in the code. - More MPI functions are included in the MPI Wrapper. - The rank/size is now stored in most of the bigger classes and initialized in the constructor. That means there are no calls to MPI_Comm_rank / MPI_Comm_size anymore in every routine ... For convenience there is also a SU2_MPI::GetRank() / SU2_MPI::GetSize(), in case you need it outside of the main classes. Let me know what you think. Not everything I did has to stay the way I implemented it :)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/473#issuecomment-347663941:452,configurat,configuration,452,https://su2code.github.io,https://github.com/su2code/SU2/pull/473#issuecomment-347663941,1,['configurat'],['configuration']
Deployability,"Agreed that the style needs some attention. I am open to ideas about this. You may have noticed that I integrated Codacy recently to test it out: https://www.codacy.com. We have the style guide, but honestly, it's not getting much attention. We should automate checks or have scripts that automatically enforce style constraints. Vera++ sounds interesting in this regard. A little while back, @rsanfer and I had been working on indentation issues with the uncrustify tool. Should we open this as an issue and get some input? Find volunteers to look into these things?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/426#issuecomment-323636235:103,integrat,integrated,103,https://su2code.github.io,https://github.com/su2code/SU2/pull/426#issuecomment-323636235,1,['integrat'],['integrated']
Deployability,"All,. For whatever it is worth, here are some thoughts. It is clear that we need to strike the right level and hierarchy of abstraction: at the highest level one really ought to be describing the physical problem, not the number of zones or the specific time-stepping algorithm that would be used. But preventing future multi-zone calculations from reaching the (time) order of accuracy desired is also an important issue that SU2 must support (and that I think would be very important for those doing unsteady turbomachinery calculations). Just as important: even for multi-physics problems (say fluid-structure interaction, when the fluid and structural solvers are not closely integrated into the same source) we need to ensure that the time accuracy of the full multi-physics calculation is as high as those of the component physics solvers. This is a very valid and useful discussion and some proposals are on the table. Given that we are planning a developer’s meeting sometime before the end of the year, this may actually be one of the items in the agenda for discussion, so some decisions can be reached that both make sense and minimize the pain of changes for any part of the existing code. I would suggest that the conversation continue and that other proposals are put forward so the discussion can be finalized at the developer’s meeting. Best,. Juan. On Sep 10, 2017, at 1:09 PM, Edwin van der Weide <notifications@github.com<mailto:notifications@github.com>> wrote:. Dear @rsanfer<https://github.com/rsanfer>,. I agree with you that the outer loop should be the loop over the number of physical disciplines involved in the problem and not the zones. Whether the individual disciplines contain one or multiple zones is irrelevant at this level, in my opinion. The loop over the multiple zones of a single discipline should take place at a much lower level, namely where the spatial residual is computed. At least, this should be the case for the fluid dynamics part. I don't know whethe",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/437#issuecomment-328403160:680,integrat,integrated,680,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328403160,1,['integrat'],['integrated']
Deployability,"Alright. I did some digging, and the problem has nothing to do with the warning message. It goes much deeper. In a recent release, SU2 switched to reading and writing binary restart files instead of ASCII. The grid adaptation code is still written only for ASCII. If I'm right, then trying to read a binary restart file with the flow solution breaks the program. I'll submit an issue detailing the bug. For now, try adding the following lines to your cfg file when you run `SU2_CFD`:. %; % Write binary restart files (YES, NO); WRT_BINARY_RESTART= NO; %; % Read binary restart files (YES, NO); READ_BINARY_RESTART= NO. Then run `SU2_MSH`, just like you have been. Does that clear things up?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/606#issuecomment-436131167:122,release,release,122,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-436131167,1,['release'],['release']
Deployability,"Also, this might be more of a question I guess, why does this `meson.py` script exist/why isn't the normal way of using meson (simply running `meson <builddir>`) used?. [edit] Just noticed `meson build` also works and uses the system installed `ninja` as expected. Still not really sure what the script is for.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/911#issuecomment-598376736:234,install,installed,234,https://su2code.github.io,https://github.com/su2code/SU2/issues/911#issuecomment-598376736,1,['install'],['installed']
Deployability,"As @gbaty said, it's usually easy to support both. Many times it can be done with a simple. ``` python; from __future__ import division, print_function; ```. at the top of each file, and tweaking the `print` and `import` statements. In my experience, the Anaconda (or miniconda) Python distribution makes it very easy to setup just about any version of Python you like on a cluster, since it's installed in the user's home directory by default. . Most scientific packages (NumPy, SciPy, Matplotlib, Pandas) already support both 2.7 and 3.x within a single codebase. Python 3 is the future!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/246#issuecomment-195767843:394,install,installed,394,https://su2code.github.io,https://github.com/su2code/SU2/issues/246#issuecomment-195767843,1,['install'],['installed']
Deployability,"By the way, there's also this cool tool called vera++ that allows you to check the style of the entire codebase. This could be integrated with Travis so make sure PRs are consistent with the coding style guide.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/426#issuecomment-323580700:127,integrat,integrated,127,https://su2code.github.io,https://github.com/su2code/SU2/pull/426#issuecomment-323580700,1,['integrat'],['integrated']
Deployability,"Dear @rsanfer,. I agree with you that the outer loop should be the loop over the number of physical disciplines involved in the problem and not the zones. Whether the individual disciplines contain one or multiple zones is irrelevant at this level, in my opinion. The loop over the multiple zones of a single discipline should take place at a much lower level, namely where the spatial residual is computed. At least, this should be the case for the fluid dynamics part. I don't know whether this is also the case for other disciplines, like structures. What about the following high level structure?. - Loop over the number of iterations, or time steps for unsteady problems.; - Loop over the number of pseudo-time steps for implicit time integration schemes; (DT_STEPPING_1ST and DT_STEPPING_2ND). For other cases this loop is 1.; - Loop over the number of disciplines involved; Call iterate for each of the disciplines.; In iterate: ; - Loop over the (Runge-Kutta) stages; - Loop over the zones of a single discipline; Compute spatial residual.; Update the state vector.; - End loop over the zones of a single discipline.; Exchange halo data. This includes the halo data between zones of a single discipline.; - End loop over the (Runge-Kutta) stages ; - End loop over the disciplines; - End loop over the pseudo time steps.; - End loop over the number of iterations, or time steps for unsteady problems. The weakness of this approach is that it still does not work when one would like to employ multi-stage time integration schemes for an unsteady, multi-disciplinary problem (does not work for the current implementation either), but maybe this is something we simply have to accept. The alternative is that all the details of the different time integration schemes have to be moved to the driver classes, which is highly undesirable, I think. The structure above implies that the iteration_container and the integration_container should be defined per discipline and not per zone anymore. The ge",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/437#issuecomment-328368371:740,integrat,integration,740,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328368371,1,['integrat'],['integration']
Deployability,"Dear @vdweide,. I clearly see your point. However, this can be quite a big structural change of the code and I think we should plan very well how to address this issue. The reason of having a driver class was to facilitate the extension of SU2 to multi-physics applications both for analysis (direct solver) and design (adjoint). Thanks to the high level of abstraction of the CInterpolator, CTransfer and the CIteration classes, it was kind of natural to treat fluid-fluid problems similarly to multi-physics problem (i.e. fluid-structure and fluid-heat). As a matter of fact, the multi-stage turbomachinery approach , its adjoint counterpart, the sliding interface they all rely on this driver structure in which we loop among all the zones. If i understood correctly, you suggest to move only the fluid-fluid multi-zone loop at lower level in order to integrate in time only after having coupled all the fluid zones. Right? If so, we need to design the code in such a way that the fluid zones loop is separated from the multi-physics one.; To solve this issue, I think, we just need to find a smart way to differentiate fluid-zones from the rest. Perhaps we can do that by instantiating one Iteration per physical problem instead than per zone. So that inside the iteration we can couple all the fluid zones, and in the driver we can couple the different physics (Iteration). Indeed, this is just a preliminary idea. In general I think we should aim to a structure that can flexibly accommodate multi-physics problems with multi-zones for different physics. A good example is solving fluid-structure in multi-stage turbomachinery, in which we have multiple fluid-zones and multiple structure-zones. ; ; I would like to hear on this matter also from @fpalacios @talbring , @economon , @rsanfer @oleburghardt ,@LaSerpe and @arubino. Thanks @vdweide againg for raising this issue. cheers. Salvo",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/437#issuecomment-328274125:855,integrat,integrate,855,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328274125,1,['integrat'],['integrate']
Deployability,"Dear Dr. Economon,. I just finished the run on AD with the files you have adjusted and it did; converge. I also have successfully run some simple inverse design tests; with a limit on the number of cycles.; Thank you very much for your guidance and help. With kind regards,. Jairo. On Wed, Jan 30, 2019 at 2:13 PM Thomas D. Economon <notifications@github.com>; wrote:. > *@economon* approved this pull request.; >; > LGMT. Thanks @jaspe55 <https://github.com/jaspe55>; >; > Just one request: I have adjusted the number of iterations for the; > regression test and updated the residual values in the python script. I; > also had to move around some files. Can you please run the case (to; > convergence) and verify that the results are what you expect? Note that the; > config file and target Cp are in the code repository and the mesh and; > solution file are in the testcases repository. If everything looks ok, then; > this is ready to be merged.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/pull/600#pullrequestreview-198200089>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/Ac180hqzVnSUPCnSBkQrTPfIv0kIltygks5vIdKrgaJpZM4X34F2>; > .; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/600#issuecomment-459568514:564,update,updated,564,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-459568514,1,['update'],['updated']
Deployability,"ER_MONITORING) so that one can control which markers get wall functions applied. If a list of markers is not specified in the config file, the default behavior should be that all no-slip walls get wall function BCs. If a list of markers is specified, then those and only those markers listed get wall function Bfs (with the others getting integration to the wall treatment). Now, what you point out in the second half of your message is the ultimate in flexibility: not only specifying wall functions in a subset of the no-slip wall markers, but also allowing for different kinds of wall functions to be used in those markers. I imagine that this would be a seldom used capability…but someone out there might have the need. I guess it does not seem to me that the coding of the most flexible logic is that much more complicated, so we may as well do that. If you guys think it is too complicated, the advertised options in the config file can allow some simpler behavior. My two cents,. Juan. On Sep 5, 2017, at 9:58 PM, Edwin van der Weide <notifications@github.com<mailto:notifications@github.com>> wrote:. Juan,. I think that having the flexibility to apply wall functions on only a subset of the viscous wall boundaries would be useful. E.g., if you are interested in a wing, you can apply integration to the wall there, but apply wall functions on the fuselage. My preference would be to have a dedicated BC type for that, i.e. Tom's second suggestion. Apart from this, we can have the different wall model types as a single input parameter, i.e. you apply the same wall model type for all viscous boundaries. Or would you like to have the flexibility to specify this as well per individual marker?. Edwin. —; You are receiving this because you commented.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/399#issuecomment-327374728>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADpSxOEhKLW_U0n9PDoz5m6cJoCScV3_ks5sfiZdgaJpZM4NvG6w>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/399#issuecomment-327377108:1711,integrat,integration,1711,https://su2code.github.io,https://github.com/su2code/SU2/issues/399#issuecomment-327377108,1,['integrat'],['integration']
Deployability,"Edwin,. I think it is a good idea to be able to have some level of control over the application of the wall functions on a marker-by-marker basis: as you say, it would be fairly common to have a wing marker where integration to the wall makes sense and a fuselage marker where wall functions (or even an inviscid BC) is the right thing to do. So let’s indeed do something like what Tom suggests (in the spirit of MARKER_MONITORING) so that one can control which markers get wall functions applied. If a list of markers is not specified in the config file, the default behavior should be that all no-slip walls get wall function BCs. If a list of markers is specified, then those and only those markers listed get wall function Bfs (with the others getting integration to the wall treatment). Now, what you point out in the second half of your message is the ultimate in flexibility: not only specifying wall functions in a subset of the no-slip wall markers, but also allowing for different kinds of wall functions to be used in those markers. I imagine that this would be a seldom used capability…but someone out there might have the need. I guess it does not seem to me that the coding of the most flexible logic is that much more complicated, so we may as well do that. If you guys think it is too complicated, the advertised options in the config file can allow some simpler behavior. My two cents,. Juan. On Sep 5, 2017, at 9:58 PM, Edwin van der Weide <notifications@github.com<mailto:notifications@github.com>> wrote:. Juan,. I think that having the flexibility to apply wall functions on only a subset of the viscous wall boundaries would be useful. E.g., if you are interested in a wing, you can apply integration to the wall there, but apply wall functions on the fuselage. My preference would be to have a dedicated BC type for that, i.e. Tom's second suggestion. Apart from this, we can have the different wall model types as a single input parameter, i.e. you apply the same wall model ty",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/399#issuecomment-327377108:213,integrat,integration,213,https://su2code.github.io,https://github.com/su2code/SU2/issues/399#issuecomment-327377108,2,['integrat'],['integration']
Deployability,"From the SU2 paper, talking about ""guiding principles"":. <img width=""574"" alt=""Screen Shot 2019-10-09 at 3 26 46 PM"" src=""https://user-images.githubusercontent.com/19416354/66525312-edb5d480-eaa9-11e9-9c0f-158b3941b407.png"">. I particularly like. > Full documentation, including a comprehensive set of tutorials. (""including"" implying that the tutorials are a subset of the documentation), and . > expose the full set of options [...] to the practitioner. This conflicts with our ""operating principle"", laid out on the tutorials page:. > Rather than writing a long manual on all available (and constantly evolving) configuration options available in SU2[...]. The Guide to V7 is a good start, but I think at the bare minimum (since I agree that full documentation would be a huge task, though one that's apparently promised on a paper we link on our homepage), we should provide more information about the existing options beyond forcing the user to scroll through config_template.cfg or dig through the tutorials.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/775#issuecomment-540239931:615,configurat,configuration,615,https://su2code.github.io,https://github.com/su2code/SU2/issues/775#issuecomment-540239931,1,['configurat'],['configuration']
Deployability,"Guys, we cannot simply change defaults like that, update regressions, and call it a day... Even fixing #1551 is a major change that should warrant a major version update. We want SU2 users to be able to rely and trust the code we release...; That is why I suggested that this PR should be used only to change the way of specifying SST options, and introduce simple ones like the V and KL modifications. Then the validation work for SST 2003 (with and w/o modification) would be done in #1557.; But ok, let me look at this and propose a way forward that gets in develop ASAP, **please don't start updating regressions**.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1560#issuecomment-1084549672:50,update,update,50,https://su2code.github.io,https://github.com/su2code/SU2/pull/1560#issuecomment-1084549672,3,"['release', 'update']","['release', 'update']"
Deployability,"Hello @aditya12398 ,. No such thing as a noob question!. To use your system meson, instead of using: `./meson.py <arguments>` in your SU2 root dir, use `meson <arguments>`. This assumes your system meson is in front of your current directory in your path, of course. Likewise, to use system ninja, instead of using: `./ninja -C build install`, simply use `ninja -C build install`. I found, for some reason, that when using my system meson and ninja with the changes made in `fix_python_3.8`, I am not getting errors, but when I use SU2's included `./meson.py`, I'm still getting those errors. Not sure why this is happening, though. -Paul",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/991#issuecomment-631584658:334,install,install,334,https://su2code.github.io,https://github.com/su2code/SU2/issues/991#issuecomment-631584658,2,['install'],['install']
Deployability,"Hello @aditya12398 ,. The fifth line of the file you attached shows a call to `c++`, rather than `mpicxx`, which could cause those undefined references. Basically, the linker is not seeing your mpi libraries. I believe that, in order to use the `-Dcustom-mpi=true` flag, you may need to define your compiler environment variables (such as `$CC`, `$CXX`, `$LD`, `$MPICXX`, etc). Having both OpenMPI and MPICH installed on your system is complicating things, I think. Without some manual configuration of your system's environment, it may not be clear to meson/ninja which mpi implementation should be used. You may need to do some digging around on the internet to see how to properly resolve which MPI implementation gets used for different applications. -Paul",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1000#issuecomment-634825410:408,install,installed,408,https://su2code.github.io,https://github.com/su2code/SU2/issues/1000#issuecomment-634825410,2,"['configurat', 'install']","['configuration', 'installed']"
Deployability,"Hello @pcarruscag @TobiKattmann and SU2 developers,. We have been busy making several code updates, performing cleanup, etc. for this PR. Can you please review and provide feedback when you get the chance? Thank you in advance!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1300#issuecomment-1061224541:91,update,updates,91,https://su2code.github.io,https://github.com/su2code/SU2/pull/1300#issuecomment-1061224541,1,['update'],['updates']
Deployability,"Hello everyone. I am working with SU2 on the feature_adap branch and have come across an issue during the execution of the mesh adaptation script. After following the standard installation procedure and verifying the installation (the exact same steps that @chesiv presented), I encountered a problem when running the mesh_adaptation_amg.py script. The command used was:. ```; python3 $SU2_RUN/mesh_adaptation_amg.py -f adapt_Mesh.cfg -n 4; ```; The script initiates the mesh adaptation process as expected, with the following output:. ```; SU2-AMG Anisotropic Mesh Adaptation. Mesh adaptation options:; PYADAP_COMPLEXITY : (30000, 60000, 120000); PYADAP_SUBITE : (2, 2, 2); PYADAP_SENSOR : GOAL; PYADAP_HMAX : 500.0; PYADAP_HMIN : 1e-9; PYADAP_HGRAD : 1.8. ./adap exists. Removing old mesh adaptation in 10s.; The ./adap folder was deleted. Generating GMF background surface mesh.; Initial CFD solution is provided.; ```; However, no _adap\ite0_ folder gets created. ; The log.err file in the _adap/ini_ directory provides this traceback:. ```; Traceback (most recent call last):; File "".../mesh_adaptation_amg.py"", line 111, in <module>; ...; RuntimeError: ...; Error in TokenizeString(): two or more options before an ""="" sign in the configuration file.; terminate called after throwing an instance of 'int'; ...; *** Process received signal ***; Signal: Aborted (6); Signal code: (-6); ...; ```. The critical part of this error seems to be the Error in TokenizeString() message, suggesting an issue with parsing the configuration file. This error typically indicates a syntax problem, such as having multiple options on a single line without proper separation by an equal sign (=). However, upon reviewing _adap/ini/config_CFD.cfg_, was unable to find any lines that clearly violated this syntax rule. Could this error be indicative of a more subtle issue within the configuration file, or might it be related to specific aspects of the feature_adap branch? Any insights, suggestions, or guidance ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/948#issuecomment-1847333809:176,install,installation,176,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-1847333809,2,['install'],['installation']
Deployability,"Here is the patch from the develop branch. As I stated before, this adds the 'increment-progress' logic to the vertex export process; this causes the sub-progress bar to shows the progress of the vertex export for a more accurate experience. Thanks again,. Ethan Alan",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/72#issuecomment-56592650:12,patch,patch,12,https://su2code.github.io,https://github.com/su2code/SU2/pull/72#issuecomment-56592650,1,['patch'],['patch']
Deployability,"Hey @timjim333 that's nice to hear,. I would put it in the .bashrc if you consistently call SU2 with your command, like that you can always switch the SU2-build and still have your clear settings already in place. Image having the master, develop and feature_whatever installed, you don't need to apply your patch to all of these versions if you put it in the bashrc.; But editing interface.py has the same effect, so its up to you what you prefer. Tobi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/526#issuecomment-429668015:268,install,installed,268,https://su2code.github.io,https://github.com/su2code/SU2/issues/526#issuecomment-429668015,2,"['install', 'patch']","['installed', 'patch']"
Deployability,"Hi @Eduardo-Carvalho ,. your request is now merged into the develop branch and you can test/use it if you like. It will be in one of the next releases, if no further issues occur.; Handling is intuitive: Just set your restart iteration in the config file as you would do normally and activate the restart solution option. Furthermore, place your restart file (two in the case of 2nd order time integration) in the same directory as the config file of your test case. Then you are set up and can run the scripts as normal. ; For more details, I refer to pull request #964. . Best; Steffen",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/909#issuecomment-630289600:142,release,releases,142,https://su2code.github.io,https://github.com/su2code/SU2/issues/909#issuecomment-630289600,2,"['integrat', 'release']","['integration', 'releases']"
Deployability,"Hi @bmunguia ,; I was in the same situation as @MiracAydin1, so thanks for the hint. Nevertheless I'm having some problems. I followed your instructions to install the branch:. 1. downloaded the [feature_adapt_sst](https://github.com/su2code/SU2/tree/feature_adap_sst) branch.; 2. Used meson to configure the build; `./meson.py build -Denable-autodiff=true -Denable-directdiff=true`; 3. Added the environment variables to the .bashrc; 4. ninja build.; `./ninja -C build install`. The build didn't show any errors, only few warnings during meson ( `gcc1: warning: command line option ‘-Wno-non-virtual-dtor’ is valid for C++/ObjC++ but not for C`). When I try to run the mesh_adaption (or even run simply the solver through parallel_computation.py):. `$SU2_RUN/mesh_adaptation_amg.py -f invCyl.cfg -n 6`. It immediately shows an error (without even showing the SU2 splash screen) :; `Traceback (most recent call last):`; ` File ""/usr/local/bin/mesh_adaptation_amg.py"", line 38, in <module>`; ` import SU2`; ` File ""/usr/local/bin/SU2/__init__.py"", line 14, in <module>`; ` from SU2 import amginria`; ` File ""/usr/local/bin/SU2/amginria/__init__.py"", line 4, in <module>`; ` from .interface import *`; ` File ""/usr/local/bin/SU2/amginria/interface.py"", line 41, in <module>`; ` import _amgio as amgio`; `ImportError: No module named _amgio`. Am I missing any dependencies? ; Please note that I previously compiled SU2 master branch without issues, and have already installed mpich, numpy, scipy.; Any help would be really appreciated.; Thanks",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/948#issuecomment-619332650:156,install,install,156,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-619332650,3,['install'],"['install', 'installed']"
Deployability,Hi @simonvanderveldt. Thanks for the questions. The custom meson.py script shipped with su2 also initializes the git submodules. You can of course also use an installed version of meson/ninja for building (should be also noted in the documentation on the website) by simply replacing `./meson.py` with `meson`.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/911#issuecomment-598496636:159,install,installed,159,https://su2code.github.io,https://github.com/su2code/SU2/issues/911#issuecomment-598496636,1,['install'],['installed']
Deployability,"Hi Economon,. I encountered an issue very similar to what Auzbaig reported: the error message ""OBJECTIVE_FUNCTION: invalid option value EntropyGeneration"" during optimization with SU2. (I am using SU2 version 8.0.1 ""Harrier.""). After thoroughly examining the existing Python optimization framework, I found that one of the steps in the optimization chain is generating different config.cfg files, with a focus on DV_VALUE and OBJECTIVE_FUNCTION. DV_VALUE controls the geometry deformation;; OBJECTIVE_FUNCTION determines the type of objective/constraints.; Then the framework calls SU2_CFD and SU2_DOT to obtain performance metrics or gradient information.; As you mentioned, ""You might need to run updateHistoryMap.py to register new outputs with Python."" Initially, I thought it meant simply providing a new input for OBJECTIVE_FUNCTION in the Python optimization framework. However, it seems that this may not work at the C++ level. To verify this, I ran $ SU2_CFD your_config.cfg -d and observed all available history outputs. However, I suspect that OBJECTIVE_FUNCTION cannot use every history output, meaning that the adjoint solver might not recognize some objective functions. Does this imply that additional modifications in the C++ code are required?. Additionally, I would appreciate more information regarding CUSTOM_OBJFUNC. From TestCases/user_defined_functions/lam_flatplate.cfg, I understand that CUSTOM_OBJFUNC allows combinations of existing OBJECTIVE_FUNCTIONs and can also utilize CUSTOM_OUTPUTS. The flexibility of CUSTOM_OUTPUTS seems to enable the construction of various desired variables. However, I am unsure whether using OBJECTIVE_FUNCTION= CUSTOM_OBJFUNC along with CUSTOM_OUTPUTS can entirely replace the need for additional modifications in the C++ code. Since I’m not very proficient in C++, I would greatly appreciate your guidance. Sincerely,; Tongtong",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/889#issuecomment-2324575133:699,update,updateHistoryMap,699,https://su2code.github.io,https://github.com/su2code/SU2/issues/889#issuecomment-2324575133,1,['update'],['updateHistoryMap']
Deployability,"Hi Eduardo,. both, 'symmetry plane' and 'symmetry as the slip wall' should work in the code (upon fixing this) and it should be made clear (e.g. in the config_template.cfg) what the BC is suitable for, independent of how it is named in the end. ; The simplest solution is probably the patch I provided together with a short note in the config_template (maybe even a reference to this issue), as both 'options' will work as expected (using the very same code). It will basically 'restore' the behaviour of MARKER_SYM of before the fix in #657. The downside is some more computational cost (in case of a plane) which has to be done for each vertex on the marker. I cant say to which extend this takes more time but I would guess it is not too costly. Depends on the case as well. I can do a little check with your case here. . That's it for the diplomatic part :) (Please take the following with a grain). For me a symmetry has to be a line or plane. To cite Jiri Blazek's book 'Computational Fluid Dynamics'(...) 3rd edition using a screenshot:. ![blazekbook](https://user-images.githubusercontent.com/31306376/61662377-9ab05a80-acce-11e9-85bf-5998db204d92.png). The chapter is called 'symmetry plane' which already is kinda biased. But there is no 'slip wall for viscous flow' mentioned to my knowledge. In another book (from Ferziger&Peric, which I only have in german) symmetry is only used in the context of symmetry planes as well. ; To me, symmetry BC's are also linked to visualization using mirroring. And mirroring (as the word is commonly meant) is only possible along planes and its little brother, the straight line. I can be wrong or it might be a question of research background. So how to proceed? Trial by combat might have some unpleasant aftermath for the winner so we might go the democratic way and do a poll :) . Cheers, ; Tobi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/735#issuecomment-513957018:285,patch,patch,285,https://su2code.github.io,https://github.com/su2code/SU2/issues/735#issuecomment-513957018,1,['patch'],['patch']
Deployability,"Hi Heather, I think we are getting closer. Something that is not clear for me is why we can only combine objective functions with the continuous adjoint. In principle, it is ""easier"" to combine objective functions with he discrete adjoint. Isn't it? Is there a particular reason for not combining the objective functions with he discrete adjoint? Thanks! Francisco",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/385#issuecomment-296408505:134,continuous,continuous,134,https://su2code.github.io,https://github.com/su2code/SU2/pull/385#issuecomment-296408505,1,['continuous'],['continuous']
Deployability,"Hi Pedro, ; As discussed last week, I now translate and rotate the whole aircraft in the elastic mesh in combination with a farfield onflow. Implementing and doing the coordinate transformations right took me a few hours, but now everything seems to work properly and fast :). 1. Currently, activating the gust resets/overwrites the grid velocities due to the deformed mesh, but I haven't found the place yet. Any ideas?. 2. Should I clean up / remove the split velocity approach as described in the first post or would you like to keep it?. 4. How to handle the new approach, should I close this pull request and open a new one? There are a few commits which I needed to undo. 5. Generally, I still need the rotating frame approach for steady maneuver load cases, e.g. to calculate the pitching, rolling or yawing aircraft in a steady simulation. The acceleration terms are zero in this case, but I understood that the Coriolis-Term with omega x velocity is missing. Is that correct? I guess they are probably important for objects like a propeller which spins at a couple of thousand RPMs but maybe it is justified to neglect them for slow objects?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1954#issuecomment-1505397240:797,rolling,rolling,797,https://su2code.github.io,https://github.com/su2code/SU2/pull/1954#issuecomment-1505397240,1,['rolling'],['rolling']
Deployability,"Hi Pedro, thanks for the idea to update the windowing directly! I've updated addValue such that the values are added for new time only (replaces existing values if it is still the same time iteration). This is a lot simpler and very happy to remove the convoluted logic. The SetUpdate_Averages was still necessary though to pass the regression test for unsteady_cylinder_windowed_average.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1259#issuecomment-819111992:33,update,update,33,https://su2code.github.io,https://github.com/su2code/SU2/pull/1259#issuecomment-819111992,2,['update'],"['update', 'updated']"
Deployability,"Hi Ruben,. Thank you for your feedback !. It is hard to tell what to do you to avoid conflicts. Anyway, the most significant part of the changes concerns the parent CDriver class, especially the constructor and some new functions that are pieces of code coming from the main function (like Output and Monitor). So if the contributions are focused on one particular driver (single, multi, ...) and if they are more or less compatible with the main ""driver->run"" then ""driver->update"" structure, it should be straightforward to solve the potential confilcts. Best,. David",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/295#issuecomment-237702911:475,update,update,475,https://su2code.github.io,https://github.com/su2code/SU2/pull/295#issuecomment-237702911,1,['update'],['update']
Deployability,"Hi Soumen,. As Tom said, the routines are all in place and I have been putting them; together for solution interpolation from one mesh to another for unsteady; simulation as post-processing step. So probing at a particular location for; unsteady solution can be also done with this framework. The probe search; implementation is in place for 2D configuration currently. It will be; extended to 3D and probably available in the main branch in the next 2; months.; The implementation so far is in feature_MeshInterpolation branch if you; want to take a look. Sravya. On Thu, Nov 2, 2017 at 10:09 PM, Thomas D. Economon <; notifications@github.com> wrote:. > Hi Soumen: yes, this is something that the developers are actively working; > on at the moment (in particular, @sravya91 <https://github.com/sravya91>; > has been taking the lead on this). It is true that most of the ingredients; > are already available in SU2 (fast searches, interpolation routines, etc.),; > but the trick is combining them all and making it general.; >; > Do you have any other requirements beyond simple probes? I am guessing we; > should have something available in the next few months, but it's not set; > yet.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/issues/466#issuecomment-341623660>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/AHenII5B0Xtb2U_hj2vbBesf5Oc51uvzks5syqAEgaJpZM4QPYh8>; > .; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/466#issuecomment-342266341:345,configurat,configuration,345,https://su2code.github.io,https://github.com/su2code/SU2/issues/466#issuecomment-342266341,1,['configurat'],['configuration']
Deployability,"Hi Tom,. Sounds like a plan then to have a look at CIntegration to see what we can do to generalize the time integration. I definitely want to help with this, but I don't think I am the appropriate person to take the lead, because I simply don't have a good overview of all the multi-physics options. Tom, are you willing to take the lead for this?. Furthermore, it is good to have other people involved as well, preferably with detailed knowledge of the different disciplines. Any volunteers?. Thanks,. Edwin",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/437#issuecomment-329096830:109,integrat,integration,109,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-329096830,1,['integrat'],['integration']
Deployability,"Hi Wally, ; I have run some axisymmetric cases earlier for pressure distribution (Cp) computation over typical payload fairing configuration (with older versions of SU2). Pressure distribution seemed to be fine with earlier runs (and also it matched well with other codes). ; Issue popped up while trying to compute heat flux for axisymmetric problems. I have seen folks and students running their cases with axisymmetric formulation. Now the issue has surfaced clearly, it need to be fixed asap.; How is solution of the case, you have been trying? . Best; Amit",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1063#issuecomment-699627809:127,configurat,configuration,127,https://su2code.github.io,https://github.com/su2code/SU2/issues/1063#issuecomment-699627809,1,['configurat'],['configuration']
Deployability,"Hi there,. I went ahead and created a dummy geometry, that is:; 1. I altered the planform so that the sweep, twist, dihedral, taper... are now different from the actual wing; 2. I replaced the airfoil by the NASA SC(2)-0712. The dummy wing has a double planform defined as:; - semi span = [5; 10]; - taper = [0.55; 0.35]; - dihedral angle = [5°; 2.5°]; - twist angle = [1°; 0°; -1°] (given for root, kink and tip airfoil sections); - sweep angle at LE = 25°; - Aspect ratio = 11.8; - semi area = 38. I defined the reference length as:; - reference (semi) area = 45; - reference chord = 3; - reference (semi) span = 15. The flight conditions remained unchanged:; - Mach number: 0.78; - Temperature = ~217 K; - Reynolds number: ~19 millions; - AoA = 0°. I created the exact same grid as before (same number of cells, same progression), ensuring my first cell was at y+<1. Things is, this time, SU2 did not have any trouble converging and computed the right z-projected area... I checked the results with another software and the pressure distribution (taken along the chord near the kink) match, see attached Figure. I am attaching the dummy configuration file (dum.txt) as well as the mesh (dum_mesh.txt) if it can be of interest to you. The mesh is a .geo gmsh file. To get the mesh, simply open with gmsh and click mesh 3D (or, from the console: gmsh dum_mesh.txt -3). At this point, I think that my problem might be related to the actual wing airfoil geometry, which is somehow not well pre-processed by SU2... I will continue investigating and keep you posted if I find a solution. Thank you for the time you took reading this issue.; ![cp](https://user-images.githubusercontent.com/39187559/40602255-3de183ae-6258-11e8-9aba-6c8d374dc34e.png); [dum.txt](https://github.com/su2code/SU2/files/2044072/dum.txt); [dum_mesh.txt](https://github.com/su2code/SU2/files/2044073/dum_mesh.txt)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/533#issuecomment-392442127:1140,configurat,configuration,1140,https://su2code.github.io,https://github.com/su2code/SU2/issues/533#issuecomment-392442127,1,['configurat'],['configuration']
Deployability,"Hi, are there any updates on this feature? Or maybe some simple example?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1750#issuecomment-2337835036:18,update,updates,18,https://su2code.github.io,https://github.com/su2code/SU2/pull/1750#issuecomment-2337835036,1,['update'],['updates']
Deployability,"Hi, thanks for this interesting discussion. Just a reminder... there is a third place where the default values are stored! the config_template.cfg file. I have had similar problems to what @erangit is describing with the multiple definition of the default values in different places, in fact, sometimes is not clear what is the minimum number of parameters that you can use in a config file. I think that the ideal scenario would be to use the config_template.cfg file as the default value keeper and create subroutines in C++ and python that update the defaults with the existing information in that file. Remember that config_template.cfg is always required otherwise the user doesn't know that are the existing options. By the way... this discussion reminds me that we should update SetRunTime_Options(void). This is an incredible useful small subroutine to modify the software parameters during runtime. EXT_ITER is the only parameters currently accepted but in the near future we should add all or most of them.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/520#issuecomment-381411950:543,update,update,543,https://su2code.github.io,https://github.com/su2code/SU2/pull/520#issuecomment-381411950,2,['update'],['update']
Deployability,"Hi,. Thank you for your quick answer, It indeed seems that I had some parameters that were passed that did not match su2 version 7.0.3. I am experiencing an issue while running the mesh adaptation process in SU2. The process starts but fails during the mesh generation phase, leading to a FileNotFoundError. I am looking for assistance in resolving this error.; `; SU2-AMG Anisotropic Mesh Adaptation. Mesh adaptation options:; PYADAP_COMPLEXITY : (100, 200, 300); PYADAP_SUBITE : (2, 2, 2); PYADAP_SENSOR : MACH; PYADAP_HMAX : 200; PYADAP_HMIN : 1e-8; PYADAP_HGRAD : 1.3; PYADAP_RESIDUAL_REDUCTION : (3, 3, 3); PYADAP_FLOW_ITER : (500, 500, 500). ./adap exists. Removing old mesh adaptation in 10s.; The ./adap folder was deleted. Generating GMF background surface mesh.; Initial CFD solution is provided. Starting mesh adaptation process. Iteration 0 - Mesh size coefficient 100.0; (1/2) Generating adapted mesh using AMG; AMG done: ; Running CFD; Traceback (most recent call last):; File ""/path/to/SU2/install/bin/mesh_adaptation_amg.py"", line 111, in <module>; main(); File ""/path/to/SU2/install/bin/mesh_adaptation_amg.py"", line 72, in main; options.save_all ); File ""/path/to/SU2/install/bin/mesh_adaptation_amg.py"", line 101, in mesh_adaptation_amg; SU2.run.amg(config); File ""/path/to/SU2/install/bin/SU2/run/amg.py"", line 466, in amg; os.rename(cur_solfil, cur_solfil_ini); FileNotFoundError: [Errno 2] No such file or directory: 'flo.dat' -> 'flo_ini.dat'`. and it0 folder is created, with some log.err and log.out, but they are empty, . I would appreciate any guidance or suggestions on how to resolve this issue. Thank you!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/948#issuecomment-1855842105:1005,install,install,1005,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-1855842105,4,['install'],['install']
Deployability,"I agree with the final conclusion here... thanks for discussing this and working toward a solution. . We have found in some of our performance optimization work that continuously allocating/deallocating memory is a performance killer, and I am in favor of uniform behavior across the code for readability/usability. Let's merge this in.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/200#issuecomment-149771091:166,continuous,continuously,166,https://su2code.github.io,https://github.com/su2code/SU2/pull/200#issuecomment-149771091,1,['continuous'],['continuously']
Deployability,"I came across this when I was working on a mesh generation program that generates an extruded boundary layer. I had checks in the program to make sure I was generating elements of positive volume and that they weren't self intersecting. While some of the elements were very badly skewed, I knew I didn't want the elements to be reoriented. However, SU2 reorients several of the prisms and tries to reorient some of the pyramids as well (which isn't a defined operation in SU2). . This is why in my particular case it was easier for me to just turn off the feature. . In general though, I think that the reorientation check could be a bit better. Currently for the prism element for example, it does a volume like calculation using the top and bottom triangles separately, and reorients if either one is negative. Obviously if only one of these calculations is negative, by reorienting, the other calculation would become negative. Similar things are done for pyramids and hexas. . A simple solution would be to change the ""or"" conditions in these calculations to ""and"", so that it is only reoriented if it fails all the checks. I think a better solution would be to decide on a volume calculation method for each element type, and then use that as a criteria. . If you'd prefer to just improve the reorientation checks instead of adding this configuration option, I could submit work on a pull request for that if you'd like.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/162#issuecomment-103679295:1342,configurat,configuration,1342,https://su2code.github.io,https://github.com/su2code/SU2/pull/162#issuecomment-103679295,1,['configurat'],['configuration']
Deployability,"I have a few updates. I found out that most of my FGMRES problems in this branch where related to the fact that I was using single precision for the linear system. You can see it in this graphs for the residuals of Rho. ![RMSRho_Mesh_3](https://github.com/user-attachments/assets/185b8195-e415-4dff-9332-cff573c069cc). The first two curves are in mixed-precision and they stop long before reaching the minimum residual required due to divergence of the linear solver. Moreover, it seems that the 2003 model here implemented (which, simply put, considers the full reynolds stress tensor for the computation of the production of k and always considers k in the stress tensor and in the thermodynamic variables) has faster convergence and increases the recirculating zone (maybe due to the reduction of turbulence kinetic energy) which is a feature that has also been seen in [DOI:10.1017/aer.2020.93]. . ![SFC_Mesh_3](https://github.com/user-attachments/assets/81a50021-6b58-4a84-9057-a18b5bab023c). There are some differences between the use of the TMR boundary conditions and the ones used before. The results improve with respect to the develop in the prediction of the SFC distribution, which has results completely off from the V&V page of SU2. ![SFC_Mesh_3_Old](https://github.com/user-attachments/assets/0f4d634b-df31-4f86-a324-d9f67947f1ff). ![RMSRho_Mesh_3_Old](https://github.com/user-attachments/assets/24d5c2f5-93fe-432f-82d9-c050a90f7339). I may keep on checking if the implementation of the v2003 model is correct or not by searching for other test cases (probably coming from DOI:10.1017/aer.2020.93).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/2329#issuecomment-2393433487:13,update,updates,13,https://su2code.github.io,https://github.com/su2code/SU2/pull/2329#issuecomment-2393433487,1,['update'],['updates']
Deployability,"I just found [a blog post](https://codingnest.com/the-future-of-catch2/) on the future directions of Catch2. There's a couple of important points for our discussion. The developer plans to adopt a hybrid approach, with:. 1. A stripped-down, header-only version.; 2. A full-feature, typical library (i.e. it must be compiled and linked). This approach is very similar to Boost's setup. Google Test does not offer a header-only version. Additionally, the developer plans to drop C++11 support, and move to C++14. A simpler branch will still support C++03. It's not clear which features are supported in the C++03 variant, and which ones aren't. Google Test is also moving to support only C++11 in their next release, but their current release fully supports pre-C++11. All of this discussion raises the question: Do we want to require C++11 for unit tests?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-500411194:706,release,release,706,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-500411194,2,['release'],['release']
Deployability,"I tend to agree w Eran on this topic. When it is working as it should, it is very convenient to have the makefiles already available in the repo. I switch between Mac, Ubuntu, and a red hat cluster without needing to update anything or call the bootstrap script. I rarely use it.. basically only when adding or removing files to the build. Also, it is good to minimize dependencies, as sometimes old machines or clusters have limited tool sets. But, clearly we should at a minimum fix the issue that some of you are finding with the autotools, which should just need an update. What systems are you having trouble with? It’s important that we don’t jump too far ahead for portability reasons (that’s why we have kept the old versions for so long). Do you have an idea of the minimum autotools you need for the failing systems? We could start by updating to that version and see if things stabilize.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/586#issuecomment-424210049:217,update,update,217,https://su2code.github.io,https://github.com/su2code/SU2/pull/586#issuecomment-424210049,2,['update'],['update']
Deployability,"I think the writing is clear, but inaccurate. The line I quote in the initial report is still there. . The code does seem to have been updated, and it now lives in CPhysicalGeometry::Read_SU2_Format_Parallel; Here is the relevant code (for 2D I think). Current lines 6100-6104 of geometry_structure.cpp. ```; #ifndef HAVE_MPI; point_line >> Coord_2D[0]; point_line >> Coord_2D[1];; #else; if (size > SINGLE_NODE) { point_line >> Coord_2D[0]; point_line >> Coord_2D[1]; point_line >> LocalIndex; point_line >> GlobalIndex; }; else { point_line >> Coord_2D[0]; point_line >> Coord_2D[1]; LocalIndex = iPoint; GlobalIndex = node_count; }; ```. In serial, the index is completely ignored. In parallel, both are used. Unlike what the documentation says, the node index is completely meaningless in parallel, and there is no documentation of a needed global index in parallel. . I don't know what the correct behavior should be. That is a team decision. I think that the behavior should be roughly the same in serial and parallel. Either the local indices matter, or they don't. If they don't matter, they should be removed. Actually implementing this behavior (in either direction), however, could break a lot of people's code, as in either direction mesh files that were previously working could be different. We could also just have different behavior in serial and parallel, but it should be documented as such. . Thoughts @economon @fpalacios ?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/47#issuecomment-104360874:135,update,updated,135,https://su2code.github.io,https://github.com/su2code/SU2/issues/47#issuecomment-104360874,1,['update'],['updated']
Deployability,"I thought of doing an SST but was not long enough that it gave me error with divergence. I have been setting up my SST case as per the tutorial example of NACA0012. However, I do not happen to see any entry with regards to eddy frequency etc. (usually required by SST) in the config file. Any guidance will be great.; Thanks; Jehan; From: Heather Kline notifications@github.com; To: su2code/SU2 SU2@noreply.github.com ; Sent: Tuesday, May 12, 2015 11:43 AM; Subject: [SU2] Feature deallocation (#174). Bringing this branch up to date with current develop branch. ; Various deallocation changes; Some regression tests fail but all run. (previously was not the case); You can view, comment on, or merge this pull request online at:;   https://github.com/su2code/SU2/pull/174; Commit Summary; - Updated GetEngine_Properties; - Fix to the last commit; - Small bug; - Merge branch 'develop' into feature_MPI; - merging; - SU2_SOL and SU2_CFD are working; - Preliminary, but complete, implementation of SU2_DEF; - More updates; - Working version; - Complete implementation (validate); - Working version of SU2_DEF; - Final push before moving to the develop branch; - New MPI (removing SU2_PRT); - Merged in Ben's ParMETIS integration and fixed some conflicts.; - Merge branch 'benkirk-parmetis_integration' into feature_MPI; - ParMETIS geometry routines have been copied over but are not activated yet.; - Small change to ParMETIS include.; - ParMETIS can now be activated for testing (PARMETIS=YES in config).; - Updated MG; - Updated EA subrotuine; - Small fix; - Fixing memory leak; - Fixing memory leaks; - Dev release v.3.2.6; - Increasing MAX_NUMBER_MARKER; - Working version with ParMETIS. Fixed bug in global index. Now clean up and testing...; - Cleaned version of ParMETIS routines with better console output during partitioning.; - Small bug in initial element division.; - Made arrays in ParMETIS call dynamic.; - Fixed compiler warnings and added MPI directives so that the pure serial code wor",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:1341,update,updates,1341,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,2,"['integrat', 'update']","['integration', 'updates']"
Deployability,"I wonder if maybe it would be a better idea to delete this (and other stuff) from externals/ and add it to subrojects/ instead. You can use `meson wrap install catch2`, and it's a simple ini file to vet instead of an 18k line file. git diffs become a lot simpler too.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1726#issuecomment-1198882302:152,install,install,152,https://su2code.github.io,https://github.com/su2code/SU2/pull/1726#issuecomment-1198882302,1,['install'],['install']
Deployability,"It seems like your situation may have been resolved, but for archival purposes, I'll list my workaround here. This problem occurs when you've installed python packages in two different locations. This could be due to installing some python packages in a system directory (e.g. `/usr/lib/`) and some in a user directory (e.g. `~/.local/`). SU2's build process is set to automatically detect the default package location, but it's not equipped to handle multiple package locations. There are some hardcoded includes, but these only work for python 2.7. I don't consider this a bug *per se* because multiple python package directories is not a standard use case. #### The symptoms. When building SU2 with the python wrapper you'll see the following error during the swig build:; ```; <install directory>/../SU2_PY/pySU2/pySU2.i:64: Error: Unable to find 'mpi4py/mpi4py.i'; ```; But mpi4py is indeed installed on your system and it's on your python path, as confirmed by opening a python terminal and running `import mpi4py`. #### The easiest workaround. Switch to a [virtualenv](https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/). This will ensure that all of your python packages are stored in single location. #### Alternate workaround. In this method, you change the hardcoded includes to match mpi4py's package location. First I figure out where my mpi4py is installed. I start a terminal session of python using the python environment I want to use (in this case, it's python 3.6), and then run:; ```; from mpi4py import MPI; MPI; ```. Since I have mpi4py installed on your system and it's on my python path, I see something like:; ```; <module 'mpi4py.MPI' from '/home/clarkpede/.local/lib/python3.6/site-packages/mpi4py/MPI.cpython-34m.so'>; ```. The `/home/clarkpede/.local/lib/python3.6/` directory is where my mpi4py package is installed. But the swig compile command includes `/home/clarkpede/.local/lib/python2.7/`. That's not the right directory! So first I ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/722#issuecomment-515693590:142,install,installed,142,https://su2code.github.io,https://github.com/su2code/SU2/issues/722#issuecomment-515693590,4,['install'],"['install', 'installed', 'installing']"
Deployability,"Juan,. Indeed, it is desirable that at the highest level the details of the time integration scheme and number of zones per discipline should not be visible. The question is whether that is achievable for all combinations you can think of. This is especially the case for the time integration schemes. E.g. suppose you would like to use a multi-stage time integration scheme for a multi-physics problem. To obtain the design accuracy in time, this implies that the loop over the number of time stages is outside the loop over the number of physical disciplines. Hence at a very high level in the hierarchy, the details of the time integration should then be known. The situation becomes even more complicated when one would like to employ time integration schemes that allow for time accurate local time stepping, e.g. the ones we are currently working on for the DG solver. I won't bore you with all the details here, but those schemes basically require the loop over the multiple disciplines to be between the predictor and corrector step, while both these steps consist of multiple stages. Although it is probably possible to come up with a data structure that supports all this, the question is whether this is desirable. Apart from the fact that it would require a major overhaul in the high level design of SU2, the implementation will be less readable, especially for people that will be starting with the code. Also the parallelization may become significantly more complicated. The alternative is that for unsteady multi-physics problems, we put the restriction that only single stage time integration schemes can be used, e.g. DT_STEPPING_1ST and DT_STEPPING_2ND. In that case, the details of the time integration scheme can be hidden at the driver level, where we then simply have a loop over the number of physical disciplines. The consequence of course is that more advanced time integration schemes will not be available for multi-physics problems. In the above I just tried to picture w",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/437#issuecomment-328441926:81,integrat,integration,81,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328441926,5,['integrat'],['integration']
Deployability,Lots of different updates have been done to incorporate all feedback and make improvements to this PR. It seems to be in a solid place to be merged with develop. @pcarruscag @talbring,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1014#issuecomment-663934671:18,update,updates,18,https://su2code.github.io,https://github.com/su2code/SU2/pull/1014#issuecomment-663934671,1,['update'],['updates']
Deployability,"N; ++k); grad(iPoint+k,iVar,iDim) = gradI[iVar][iDim][k];; ...; ```; Similarly when computing the gradient we need to first fetch/transpose it to be able to vectorize subsequent computations; ```c++; FltVec gradI[MAXNVAR][MAXNDIM];. for(size_t iVar=0; iVar<nVar; ++iVar); for(size_t iDim=0; iDim<nDim; ++iDim); for(size_t k=0; k<SIMDLEN; ++k); gradI[iVar][iDim][k] = grad(iPoint+k,iVar,iDim);; ...; ```; Performance wise this is actually better than the SoA version (4% on gradients, 35% on limiters) as it also benefits from better locality, and it is only slightly (3%) worse than zig zag storage, especially when fusing limiters and gradients as the transposition of the gradient into storage is greatly amortised.; Regarding readability, the 3 nested loops can be moved to methods of the container, but we cannot get rid off the local variable (if we want vectorization that is). **We lose the ability to vectorize primitive variable updates efficiently with AoS** but currently that only accounts for 3% of the runtime and it is a memory bound operation therefore it would not gain much from vectorization anyway. On the subject of de-swizzling data remember I said the writes into CSysMatrix would be a bit weird, that is because each Jacobian contribution will be a ""matrix of short arrays"" that needs to be transformed into a short array of matrices, the result of that is code like the above that explicitly manipulates the lanes of our SIMD type, such code can be completely hidden inside CSysMatrix which is good because a 4x4 vectorized transpose and matrix update looks like this; ```c++; // block j, subs from jj and goes to ij; T0 = blk_j[ k ].unpackLo(blk_j[k+1]); T1 = blk_j[ k ].unpackHi(blk_j[k+1]);; T2 = blk_j[k+2].unpackLo(blk_j[k+3]); T3 = blk_j[k+2].unpackHi(blk_j[k+3]);. C0 = T0.widePermuteLo(T2); C1 = T1.widePermuteLo(T3);; C2 = T0.widePermuteHi(T2); C3 = T1.widePermuteHi(T3);. (Array4d(&bjj[0][k])-C0).store(&bjj[0][k]);; (Array4d(&bjj[1][k])-C1).store(&bjj[1][k]);; (Arr",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-535977206:15145,update,updates,15145,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206,1,['update'],['updates']
Deployability,"Nice analysis @clarkpede. It is true that we simplify the Jacobians at the periodic boundaries, mostly to avoid issues with adding entries to the Jacobian from the neighbors that potentially do not live on our rank and to keep communication costs low (those neighbors are treated explicitly). This could be changed to communicate the full Jacobian.. but I am not sure it is worth the effort/cost. The approximation that is made should still be consistent though, because we only allow one of the repeated periodic nodes to participate in the linear solve with each nonlinear iteration, and then we communicate its update to its periodic pair. In short, the value of the solution should always be the same on periodic points with each iteration update, and if the problem converges to a steady-state (even in time stepping mode), the Jacobian should only affect convergence (the RHS should be the same). You could try the time stepping option with one of the RK methods to see if going fully explicit helps further isolate the issue. It could also be something related to the time step that is communicated. In the SetTime_Step() routine in the flow solver class, we do some special checks for time stepping mode to make sure that the minimum global time step is used in all cells. Might want to print out the dT communicated in the periodic comms or write the dT to the solution file to make sure everything is ok there too. Honestly, I don't think a ton of folks use the time stepping option in general with the FVM solver, so double-checking that it behaves well for a non-periodic problem could shed some light too, unless you have already done that.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/763#issuecomment-524007345:614,update,update,614,https://su2code.github.io,https://github.com/su2code/SU2/issues/763#issuecomment-524007345,2,['update'],['update']
Deployability,"No… I can’t. I’m sorry. Great to hear from you. Machine learning is a very valuable research work and I will add it as a feature branch. . Removing code from the main release is a complex task and, as in the past, I have taken tough decisions. Anyway, to maintain a clean code is critical for its growing, it is like trimming a large tree. Basic criteria to maintain forever an implementation on the develop->master branch are: - Clear benefit to the CFD community (more accurate, robust, etc.) - Existing community of users or active developers - Minimal code documentation (at least the options should be in the config file). - Easy to install and use. - The implementation style should be aligned with the SU2 style - Regressions tests. Best,; Francisco. > On Oct 28, 2015, at 11:35 PM, Brendan Tracey notifications@github.com wrote:; > ; > Could you leave in the machine learning section a bit longer?; > ; > —; > Reply to this email directly or view it on GitHub https://github.com/su2code/SU2/pull/208#issuecomment-152095697.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/208#issuecomment-152384158:167,release,release,167,https://su2code.github.io,https://github.com/su2code/SU2/pull/208#issuecomment-152384158,2,"['install', 'release']","['install', 'release']"
Deployability,"Of the two cases with larger residual changes:; - contadj_euler_naca0012 - No idea why they changed, neither primal nor adjoint compute limiters... the primal residuals are unchanged, and the case converges to the same values (residuals and solution) so I simply updated the residuals; - transonic_stator_restart - As shown above the case is fine, so I updated the restart file, however I do not know how to change the testcases branch anymore :) but I guess once the corresponding PR is merged this will start passing. I ran some other tests with the Venkatakrishnan-Wang limiter (which requires a global min/max) and is does not seem to be covered by the tests ATM (maybe I'll use that restart case to fix that), everything looks perfect, same results with different ranks/threads and so on, the results are tens of MB so I won't upload unless someone wants to double check.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/834#issuecomment-575310823:263,update,updated,263,https://su2code.github.io,https://github.com/su2code/SU2/pull/834#issuecomment-575310823,2,['update'],['updated']
Deployability,Ok thats to be expected (as I learned) because you have probably openmpi installed. The binaries are compiled with mpich.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/813#issuecomment-557430771:73,install,installed,73,https://su2code.github.io,https://github.com/su2code/SU2/pull/813#issuecomment-557430771,1,['install'],['installed']
Deployability,"Ok, SIMD update, with #753, #959, and #966 we now have a unified storage type for the data we need in CNumerics. This means that we (I) only need to implement ""SIMD accessor methods"" (i.e. that return a SIMD type instead of a su2double) for one class (C2DContainer and co.). I think to do SIMD right we need a new way of going about CNumerics, these are my design requirements for ""CNewNumerics"":; - Thread-safe (consequently const-correct), a single object must be safe to use by multiple threads.; - Minimal indirection, the polymorphic overhead will be reduced to a single call (ComputeResidual), all auxiliary functions (like the ones that live in CNumerics) will be forcefully inlined, no useless copies of data (no more numerics->SetBlaBla).; - Compile time nDim/nVar, which will: a) avoid heap allocations; b) allow effective loop-unrolling (also during the writes to CSysMatrix).; - Allow low-overhead composition, e.g. have one CRoe for Euler and one CRoeVisc for NS to fuse convective and viscous residuals (without copy pasting code).; - A lot more readable, those cryptic V_i[iDim+1] need to go (somehow...). To achieve all this, the ""CNewNumerics"" will work as a template (obvs) decorator/visitor.; A visitor in the sense that the solver calls the numerics and gives it (read-only) access to all its data, the object pulls whatever it needs directly and there is no need for numerics->SetBlaBla.; A template decorator in the sense that the class can be augmented simply by inheriting from another, along the lines of `class CRoeVisc : public CRoe, public CVisc` (to allow fusing residual and Jacobian contributions).; All this needs to be done with templates for the ""minimal indirection"" requirement. Which means for each numerical method we will have 4 explicit template instantiations (Euler2D, Euler3D, (RA)NS2D, (RA)NS3D) but in the end these are still polymorphic objects that will be instantiated by some factory function (i.e. it will look clean, especially because I will not por",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-622941617:9,update,update,9,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-622941617,1,['update'],['update']
Deployability,"On both questions the answer is yes. Option 1 can be implemented right now but will require the creation of temporary objects. Option 2 can directly forward the data to the blas routines. The tool I am developing is no tool for a specific linear algebra package. The idea is, that the tool parses the header files of the library. The user has then to define which objects are active lvalues and the derivatives for each operation in the library. For small an clear interfaces this is no problem and works already quite good. For large libraries like Eigen I adopted a whitelisting approach. That is, every function needs to be manually whitelisted to trigger the expression generation of the tool. In a prototype way I have also implemented an approach where only the active lvalues need to be defined and the tool looks then for all required functions and other objects that depend on these active objects. Long story short, the tool is designed to handle ""any"" library. It is even possible to mix several libraries together. My current status on this project is, that I am now through with the parsing of the header files and the generation of the expressions. This works quite well for Eigen which is a hardcore testcase, since every possible programming tweak in C++ is used here. The next step is to add the AD part to the expression generation process. I hope that in one or two month this will be finished and I can provide a first beta release.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/643#issuecomment-463561018:1444,release,release,1444,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-463561018,1,['release'],['release']
Deployability,"SU2. If not, see <http://www.gnu.org/licenses/>. |; -------------------------------------------------------------------------. Build Configuration Summary:. Source code location: /home/antodech/SU2-4.1.0; Install location: /gshare/work/hpascalj/CodeSU2-master; Version: 4.1.0; C++ Compiler: g++; C Compiler: gcc; Preprocessor flags: ; Compiler flags: -g -O2; Linker flags: ; MPI support: no; Metis support: no; Parmetis support: no; TecIO support: no; CGNS support: yes; HDF5 support: no; SZIP support: no; ZLIB support: no; Mutation++ support: no; Jsoncpp support: no; LAPACK support: no; Datatype support:; double yes; complex no; codi_reverse no; codi_forward no. External includes: ; External libs: . Build SU2_CFD: yes; Build SU2_DOT: yes; Build SU2_MSH: yes; Build SU2_DEF: yes; Build SU2_SOL: yes; Build SU2_GEO: yes. Please be sure to add the $SU2_HOME and $SU2_RUN environment variables,; and update your $PATH (and $PYTHONPATH if applicable) with $SU2_RUN. Based on the input to this configuration, add these lines to your .bashrc file:. export SU2_RUN=""/gshare/work/hpascalj/CodeSU2-master/bin""; export SU2_HOME=""/home/antodech/SU2-4.1.0""; export PATH=$PATH:$SU2_RUN; export PYTHONPATH=$PYTHONPATH:$SU2_RUN. ## ---------------- ##; ## Cache variables. ##; ## ---------------- ##. ac_cv_build=x86_64-unknown-linux-gnu; ac_cv_c_compiler_gnu=yes; ac_cv_cxx_compiler_gnu=yes; ac_cv_env_CCC_set=; ac_cv_env_CCC_value=; ac_cv_env_CC_set=; ac_cv_env_CC_value=; ac_cv_env_CFLAGS_set=; ac_cv_env_CFLAGS_value=; ac_cv_env_CPPFLAGS_set=; ac_cv_env_CPPFLAGS_value=; ac_cv_env_CPP_set=; ac_cv_env_CPP_value=; ac_cv_env_CXXFLAGS_set=; ac_cv_env_CXXFLAGS_value=; ac_cv_env_CXX_set=; ac_cv_env_CXX_value=; ac_cv_env_LDFLAGS_set=; ac_cv_env_LDFLAGS_value=; ac_cv_env_LIBS_set=; ac_cv_env_LIBS_value=; ac_cv_env_build_alias_set=; ac_cv_env_build_alias_value=; ac_cv_env_host_alias_set=; ac_cv_env_host_alias_value=; ac_cv_env_target_alias_set=; ac_cv_env_target_alias_value=; ac_cv_file__gshare_soft_code_sa",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:19276,configurat,configuration,19276,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,1,['configurat'],['configuration']
Deployability,"Sorry for the late reply! Thanks for all the help, and i am afraid i am using a 7.2.0 version and the newly released version 7.2.1 remains the same code. The problem is just lying on ""delta[iDim] = fabs(coord_j[iDim] - coord_i[iDim]);"" which is also in @TobiKattmann 's code post(thanks for your kind guidance ).; In deed, this part of code should give the credit to @EduardoMolina, and the function is a part of his doctoral thesis(2018) which i just couldnot found a link or doi of. But in this paper(https://www.researchgate.net/publication/318143234; ), he gives the official definition as below without the implementation in above picture.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1462#issuecomment-986239816:108,release,released,108,https://su2code.github.io,https://github.com/su2code/SU2/issues/1462#issuecomment-986239816,1,['release'],['released']
Deployability,"Sure; If you want to install Su2 version 7.0.0 from scratch, you need python 3.5; atleast; The installation guide says just python 3; One of the functions used in meson.py is only available in python 3.5. On Mon, Feb 3, 2020, 12:51 AM Tim Albring <notifications@github.com> wrote:. > Thanks for opening the issue. Can you give a little bit more details on; > what you mean exactly ?; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/issues/855?email_source=notifications&email_token=AIENZ3WCJDNJV4LP655MB33RA7LI5A5CNFSM4KNO4QLKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEKS7V6I#issuecomment-581303033>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AIENZ3TDY7ZCOS27JO7IYXTRA7LI5ANCNFSM4KNO4QLA>; > .; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/855#issuecomment-581453436:21,install,install,21,https://su2code.github.io,https://github.com/su2code/SU2/issues/855#issuecomment-581453436,2,['install'],"['install', 'installation']"
Deployability,"Surprisingly I have found the existing content related to plasma simulation in SU2. Really amazing. Could anyone give me any clues of the correspondent .cfg files? Or help me find the governing equations change which makes the plasma equations different from the neutral gas. ; ; ![image](https://user-images.githubusercontent.com/33152225/61871269-5fef3200-af1b-11e9-82c5-cd8418a6f83c.png). It already seems good enough at considering *E* field, but *B* is omitted. I can strive to supplement the equation. Could anyone give some guidance to me, a newcomer of SU2?. [Stanford University Unstructured An open-source integrated computational environment for multi-physics simula.pdf](https://github.com/su2code/SU2/files/3431264/Stanford.University.Unstructured.An.open-source.integrated.computational.environment.for.multi-physics.simula.pdf)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/741#issuecomment-515010918:616,integrat,integrated,616,https://su2code.github.io,https://github.com/su2code/SU2/issues/741#issuecomment-515010918,2,['integrat'],['integrated']
Deployability,"Thank you @TobiKattmann for your feedback. The idea behind this new regression test config file is as follows:; We should have a test case that triggers the negative part of the SA model. Depending on the flow conditions, geometry and CFD parameters it might be triggered or not. With the previous config file, it was not. ; I think there is already a regression test in SU2 that triggers the negative SA, the `turb_oneram6_nk`. However, I decided to stick to rae2822 airfoil as it is a simpler (faster) case. In order to force the negative part of the SA for the rae2822 in a reasonable amount of iterations for a regression test, I increased the angle of attack. I have removed the multigrid as it might not be stable, but I have not tested though. Anyway, with the current configuration, e.g., convective scheme, CFL number, etc, the solution is not stable and diverges after some iterations, around 15. In that sense, I reduced the number of iterations from 20 to 10. In my opinion, a diverging regression test is not a problem at all as it might not be used as a tutorial, only to verify the integrity of the commit. ""The solution should always diverge to the same results"". If the regression test should converge, let me know and I will update the config file :)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1559#issuecomment-1067926363:776,configurat,configuration,776,https://su2code.github.io,https://github.com/su2code/SU2/pull/1559#issuecomment-1067926363,2,"['configurat', 'update']","['configuration', 'update']"
Deployability,"Thank you for the pull request. ; Pull requests must be both to and from the ""develop"" branch (or the relevant feature branch if applicable). In order to make a pull request, please check out the develop branch, make your changes, and submit the pull request into to develop branch. . While this might be useful in some situations, and particularly the record of this pull request can be an example to other users who want to use Docker with SU2, it looks like this is specific to a version of Ubuntu, and that you have hard-coded some lines to refer to locations on your own file system. We try to make it such that SU2 will be usable in most operating systems, with appropriate changes to the configuration steps. . Since it is setting up a development environment this would be more appropriate to SU2_IDE/, rather than Quickstart/ - which is intended as the main tutorial for new users, who are not necessarily developers and who may not have heard of Docker.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/169#issuecomment-96786749:695,configurat,configuration,695,https://su2code.github.io,https://github.com/su2code/SU2/pull/169#issuecomment-96786749,1,['configurat'],['configuration']
Deployability,"Thank you for the thorough review @rsanfer! I'll reply to your main questions and some of the smaller ones here to centralize things. > Just a request, if it's possible that you add one or two test cases so the implementation is safe onwards (and, of course, so I can play around with the new features a little bit ). The testcases are the same, no changes there other than the one optional option introduced above. When the hybrid stuff covers most of the code I would add an entire build configuration e.g. BaseMPIOMP and corresponding testcase suite. > * Should this just run ""out of the box"" with a working installation of OpenMP in any machine, or is there anything else _fancy_ needed?. I would leave it to the community to decide what the defaults should be, probably for a lot of new users that don't run on clusters just calling SU2_CFD and not having to worry about mpi would be nice (a lot of the issues on CFD online are mpi related). > * Is the previous behaviour exactly kept, or are there any modifications in the basic, non OpenMP version of code? (Not that I mind, just curious). Other than the algorithmic changes (but mathematically equivalent) introduced to limiters and gradients in #834, yes. > What's the advantage of having one numerics term per thread?. It is a requirement, we need to write data into numerics before using them, multiple threads cannot write to the same location (i.e. the internal structures of CNumerics) therefore one per thread is required. > ...Also, I think I missed the point where the numerics container is extended beyond MAX_TERMS. The allocation of space for one numerics per thread is done above in line 1995 of my 21 Dec 2019 comment: `...MAX_TERMS*omp_get_max_threads()...`.; The instantiation of one numerics per thread is then done by executing the rest of the preprocessing in parallel and instead of using `XYZ_TERM` using `XYZ_TERM+offset` where `offset = thread_id * MAX_TERMS`.; I think someone mentioned this (maybe Tim) that we could r",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/843#issuecomment-577684728:490,configurat,configuration,490,https://su2code.github.io,https://github.com/su2code/SU2/pull/843#issuecomment-577684728,2,"['configurat', 'install']","['configuration', 'installation']"
Deployability,"Thank you, @economon. It turns out, that does indeed remove the issue. I updated to the latest version (7.0.5) at the same time. When checking the default behavior, the QuickStart case would run correctly the 1st time then it would fail if the restart file was not removed prior to the output stage of subsequent runs. Commenting out line 223 does appear to resolve the issues we have been encountering. Original:; Now it seems to get stuck (simply freezes for >60 sec) when writing surface_flow.vtu (from QuickStart). I don't suppose there's another flag like this in that code vicinity?. Update: This issue resolved itself. The file system was being taxed by other runs. Thank you all for your time!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/971#issuecomment-644968380:73,update,updated,73,https://su2code.github.io,https://github.com/su2code/SU2/issues/971#issuecomment-644968380,1,['update'],['updated']
Deployability,"Thanks @MicK7 I will have a look, my initial thought was to have a simple strategy where within each MPI rank parallelism is extracted via colouring or scatter-to-gather transformations and only one thread per rank participates in the message passing, I have no experience here though so this might be a bad strategy, idk. **Back to business:**; I went silent for a bit because in prototyping a typical residual computation and matrix update loop I made some realisations that made me go back to the drawing board regarding data structures, and eventually back to square 0. . ## Parallel strategy for flux computation; Because significant computation is required to obtain each edge's flux, it does not make sense to attempt a ""point-loop"" strategy (which would double the effort).; However, one can either use colouring to avoid the race conditions that would result from updating the residual of cells i and j, or store the edge fluxes and then, on a second point-loop perform the summation of fluxes for each cell, with the direction being accounted by the same adjacency information used in the point-loop GG gradient computation.; If we consider only the update of residuals the two strategies are fairly equivalent performance wise, the tie breaker is the matrix updates. ## Matrix Updates; By this I mean the `addBlock`, `subBlock` we do (two times each) to update diagonal and off-diagonal blocks for each edge.; Here is a dummy numerics loop that does nothing else but setting blocks in the matrix (with colouring).; ```c++; void testLoop1(const vector<size_t>& colorStart,; const vector<size_t>& edgeIdx,; const vector<pair<size_t,size_t> >& connectivity,; double** blk_i, double** blk_j,; SparseMatrix& matrix); {; matrix.setZero();. for(size_t color=0; color<colorStart.size()-1; ++color); #pragma omp parallel for schedule(dynamic,CHUNK_SIZE); for(size_t k=colorStart[color]; k<colorStart[color+1]; ++k); {; size_t iEdge = edgeIdx[k];; size_t iPoint = connectivity[iEdge].first;; size_t j",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-535977206:435,update,update,435,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206,1,['update'],['update']
Deployability,"Thanks @clarkpede to take the initiative for this topic. I think unit-tests are a useful thing and we should think about having it in addition to the regression tests. Regarding the framework I am actually a little bit hesitant to use boost. Although we are already using it for tecio, in that case it is used in a part of the code which does not change frequently so it is fine if we are just shipping it. However, if we start introducing it into the actual development process people may want to use more and more features of boost and we will have a hard time maintaining versions, compatbilities and so on. And in my opinion we should keep it as simple and lightweight as possible (one of our biggest strengths is the simple compilation/installation, which actually attracts a lot of users). So in that regard Catch2 looks like a better candidat to me. But I am happy to hear more opinions on that.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-500226914:741,install,installation,741,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-500226914,1,['install'],['installation']
Deployability,"Thanks Tom for the comments! ; I think I have covered them all but let me know if you still have comments. I will do some updates tomorrow morning. I agree this is a very large pull request, it's the result of over a year of work, so I would really appreciate any more feedback from the community! ; Thanks!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/452#issuecomment-337575805:122,update,updates,122,https://su2code.github.io,https://github.com/su2code/SU2/pull/452#issuecomment-337575805,1,['update'],['updates']
Deployability,"Thanks a lot for your feedback, we have updated the files. ; For the time being, just remove MG_CFL_REDUCTION= 0.9 in your config file.; Best,; Francisco",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/44#issuecomment-54904983:40,update,updated,40,https://su2code.github.io,https://github.com/su2code/SU2/issues/44#issuecomment-54904983,1,['update'],['updated']
Deployability,"Thanks for the commit, I've installed it using your hints (I also changed some aliases to always point to python3), and now `parallel_computation.py` it is running properly.; `mesh_adaption_amg.py` runs, until it complains about Ncorners in the SU2 mesh.; ` ## WARNING: MISSING SU2 MESH FILE KEYWORD: NCORNERS=.` ; and then mesh_adapt fails, I can't find any reference to NCORNERS in *.su2 mesh files by the way. As far as` locate Python.h` that's the output :; ```/home/antares/Downloads/SALOME-9.3.0-UB18.04-SRC/BINARIES-UB18.04/ParaView/include/paraview-5.6/vtkPython.h; /home/antares/Downloads/SALOME-9.3.0-UB18.04-SRC/BINARIES-UB18.04/Python/include/python3.6/Python.h; /home/antares/Downloads/SALOME-9.3.0-UB18.04-SRC/BINARIES-UB18.04/gmsh/include/FieldPython.h; /home/antares/Downloads/SALOME-9.3.0-UB18.04-SRC/BINARIES-UB18.04/gmsh/include/simpleFunctionPython.h; /home/antares/Downloads/ThirdParty-v1806/ParaView-v5.5.2/VTK/Utilities/Python/vtkPython.h; /home/antares/OpenFOAM/ThirdParty-v1806/ParaView-v5.5.2/VTK/Utilities/Python/vtkPython.h; /usr/include/python3.6m/Python.h; ```. Thanks",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/948#issuecomment-619409024:28,install,installed,28,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-619409024,1,['install'],['installed']
Deployability,"Thanks for the feedback. . I was not able to find any examples myself either. It looks like this is a feature that has been around for a while, but maybe has gotten lost in some updates. I will work on setting up a small test case for this and the FAN_FACE_MDOT and submit a PR.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1607#issuecomment-1100150640:178,update,updates,178,https://su2code.github.io,https://github.com/su2code/SU2/issues/1607#issuecomment-1100150640,1,['update'],['updates']
Deployability,"Thanks for the fixes, Francisco. The continuous adjoint tests are now failing, but I am guessing that it is something simple with the changes to the config option. Can you please take a look when you have a moment?. Couldn't agree more about keeping an eye on the Python scripts. We'll chat about it this week at the developer meeting (we need regressions for the Python scripts). More on that to come.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/244#issuecomment-191571633:37,continuous,continuous,37,https://su2code.github.io,https://github.com/su2code/SU2/pull/244#issuecomment-191571633,1,['continuous'],['continuous']
Deployability,"Thanks for the quick review @pcarruscag. I have cleaned up a little bit. Also added a nicer table of the output. l prefer that we always compute the min/max values, at least for the FVM CFD solvers, for a few reasons. The most important reason is that we should start to build up some intuition about the correlation between mesh quality metrics and accuracy + convergence in the solvers. This can be especially important during optimization when the mesh is deforming. I think the metrics are valuable to print every time for this reason, which might help users diagnose problems eventually. Additionally, the cost is relatively small (on par with the other pre-processing routines, it is only executed once and it is parallelized, and the memory is released if we don't write).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/778#issuecomment-526456264:751,release,released,751,https://su2code.github.io,https://github.com/su2code/SU2/pull/778#issuecomment-526456264,1,['release'],['released']
Deployability,"Thanks, I’ll take a look at that before the weekend,. Best,; Francisco. > On Mar 2, 2016, at 8:03 PM, Thomas D. Economon notifications@github.com wrote:; > ; > Thanks for the fixes, Francisco. The continuous adjoint tests are now failing, but I am guessing that it is something simple with the changes to the config option. Can you please take a look when you have a moment?; > ; > Couldn't agree more about keeping an eye on the Python scripts. We'll chat about it this week at the developer meeting (we need regressions for the Python scripts). More on that to come.; > ; > —; > Reply to this email directly or view it on GitHub https://github.com/su2code/SU2/pull/244#issuecomment-191571633.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/244#issuecomment-191590831:197,continuous,continuous,197,https://su2code.github.io,https://github.com/su2code/SU2/pull/244#issuecomment-191590831,1,['continuous'],['continuous']
Deployability,"Thanks, Tim. Adding flexibility to the FFD is a great contribution. I was just going through the changes and I have a couple of questions:; 1. I noticed that you have added AD as an option for computing the geometric sensitivity component (change in the surface location due to a delta change in the design variable) that multiplies the adjoint sensitivity. Is there a way to make this usable for the continuous adjoint too rather than using finite differencing? This assumes that the user has built the AD version, even though they use the continuous adjoint.; 2. On a related note (I think), is the finite differencing that is currently used for computing the geometric sensitivity the only roadblock to arbitrary FFD movements for the continuous adjoint?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/239#issuecomment-183462794:401,continuous,continuous,401,https://su2code.github.io,https://github.com/su2code/SU2/pull/239#issuecomment-183462794,3,['continuous'],['continuous']
Deployability,"That looks a bit strange, you still get Release 6.2.0 but in the aforementioned PR @jayantmukho clearly updated the version to 7.0.2, I use the old build system in an old computer and it is currently working...",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/910#issuecomment-598733874:104,update,updated,104,https://su2code.github.io,https://github.com/su2code/SU2/issues/910#issuecomment-598733874,1,['update'],['updated']
Deployability,The Github Actions checks passed after making two changes:. 1) https://github.com/su2code/SU2/pull/1619/commits/efe98fe6070a0cb51f1082a9599363786e4d65ea; I needed to lower the warnlevel due to problems in `externals/cgns/hdf5`.; Maybe the HDF5 files should be updated to a newer version ?! But it is not clear to me which version has been used in https://github.com/su2code/SU2/pull/1500. ; @MicK7 Do you have an idea how to fix this ?. 2) https://github.com/su2code/SU2/pull/1619/commits/26140223e5838a6856c0b3c02163a826256306b1; A workaround recommended at https://github.com/su2code/SU2/issues/1568#issuecomment-1083104460. 3) The regression tests [fail](https://github.com/su2code/SU2/runs/6387003184?check_suite_focus=true) because the new `test-su2` Docker image is `private`. I will need someone with higher privileges than me to make it public.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1619#issuecomment-1123614000:260,update,updated,260,https://su2code.github.io,https://github.com/su2code/SU2/pull/1619#issuecomment-1123614000,1,['update'],['updated']
Deployability,"The _amgio extension should be built by default. I haven't had any issues on any of the machines I've built on, so I appreciate the feedback. Just curious, are you running with python >=3.7? The shebang in all the SU2 python scripts; ```; #!/usr/bin/env python; ```; uses whatever python is set to in your environment variables, but pyamg/_amgio will only build/run with python >=3.7. Could you also check if the _amgio extension was installed in your site-packages (probably located in ~/.local/lib/python3.x/site-packages)?. If it didn't build/install, you could go into extensions/AMGIO/su2io and run; ```; python3 setup.py build_ext && python3 setup.py install; ```; If it did build/install, try the command; ```; python3 $SU2_RUN/mesh_adaptation_amg.py -f invCyl.cfg -n 6; ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/948#issuecomment-619334494:434,install,installed,434,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-619334494,4,['install'],"['install', 'installed']"
Deployability,"The documentation is now at:; https://github.com/su2code/SU2/wiki/Mesh-File. I would assume the actual behavior is still the same. Brendan, can you please check the documentation to see if you think it is clear now, and update it if not?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/47#issuecomment-104355161:220,update,update,220,https://su2code.github.io,https://github.com/su2code/SU2/issues/47#issuecomment-104355161,1,['update'],['update']
Deployability,The primary solution in the linked issue is to use a virtualenv. I quote:. > The easiest workaround: Switch to a [virtualenv](https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/). This will ensure that all of your python packages are stored in single location.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1575#issuecomment-1076307528:162,install,installing-using-pip-and-virtual-environments,162,https://su2code.github.io,https://github.com/su2code/SU2/issues/1575#issuecomment-1076307528,1,['install'],['installing-using-pip-and-virtual-environments']
Deployability,"The solver with the closest functionality to what you are trying to do is the elasticity solver, it may be worth having a look there. But in a nutshell there the variables we want to differentiate are held by (members of) the discrete adjoint solver, they are reset before being registered as inputs to clear the derivative information, and it is important that they are left alone during the recording phase.; You will see that the adjoint iteration class for this solver then needs to update the numerics classes (in SetDependencies), at least for the source term the SA coefficients are set in the constructor of the corresponding numerics so maybe this step is missing?; The key point is that whenever a coefficient is used you need to be able to trace its value back to the original variable you registered.; Also the derivatives should be extracted in the same order they were registered, and you cannot access them multiple times by calling ""GetDerivative"" on them repeatedly (not 100% sure if this restriction still exists after the update of CoDi).; If none of this makes sense point me to branch you are working on.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/679#issuecomment-491910935:487,update,update,487,https://su2code.github.io,https://github.com/su2code/SU2/issues/679#issuecomment-491910935,2,['update'],['update']
Deployability,"This could be a very interesting contribution! Please, feel free to work on this and create a push request to the developer release. SU2 is looking forward for contributions from the open-source community. Thanks!; Francisco. Sent from my iPhone. > On Mar 12, 2016, at 8:07 AM, Pete Bachant notifications@github.com wrote:; > ; > As @gbaty said, it's usually easy to support both. Many times it can be done with a simple; > ; > from **future** import division, print_function; > at the top of each file, and tweaking the print and import statements. In my experience, the Anaconda (or miniconda) Python distribution makes it very easy to setup just about any version of Python you like on a cluster, since it's installed in the user's home directory by default.; > ; > Most scientific packages (NumPy, SciPy, Matplotlib, Pandas) already support both 2.7 and 3.x within a single codebase. Python 3 is the future!; > ; > —; > Reply to this email directly or view it on GitHub.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/246#issuecomment-195781648:124,release,release,124,https://su2code.github.io,https://github.com/su2code/SU2/issues/246#issuecomment-195781648,2,"['install', 'release']","['installed', 'release']"
Deployability,"This has been a long long exposition (nerd joke) but bear with me I am almost done, and I will summarise the results in the form of a proposal (I'll probably put that at the top of the first post). ## ""Real"" numerics; Real in the sense that the flop to byte ratio (amount of computation per amount of data) is comparable to a real numerics scheme, say Roe for example.; The simplest way to do this is to combine the example code for MUSCL reconstruction with the matrix updates code and add something compute heavy between input and output, e.g. a number of matrix-matrix multiplications, here is some pseudo code for what I did:; ```c++; void computeResidual(size_t nVar,; size_t nDim,; const vector<Connectivity<SIMDLEN> >& connectivities,; const Matrix& coords,; const Matrix& phi,; const VectorOfMatrix& grad,; const Matrix& limiter,; RowMajorMatrix& residual,; SparseMatrix& matrix); {; using FltVec = Array<double,SIMDLEN>;. residual.setZero();; matrix.setDiagZero();. size_t color = 0;; for(const auto& connectivity : connectivities); {; #pragma omp parallel for schedule(dynamic,CHUNK_SIZE); for(size_t iEdge=0; iEdge<connectivity.size(); iEdge+=SIMDLEN); {; auto iPoint = connectivity.first_vec(iEdge);; auto jPoint = connectivity.second_vec(iEdge);. FltVec d_ij[MAXNDIM];; for(size_t iDim=0; iDim<nDim; ++iDim); d_ij[iDim] = (coords.getVec(jPoint,iDim)-coords.getVec(iPoint,iDim))*0.5;. FltVec phiL[MAXNVAR], phiR[MAXNVAR], flux[MAXNVAR],; blk_i[MAXNVAR*MAXNVAR],; blk_j[MAXNVAR*MAXNVAR];. for(size_t iVar=0; iVar<nVar; ++iVar); {; // Reconstruction goes here. flux[iVar] = (phiL[iVar]+phiR[iVar])*0.5;; }. // some silly way to make the Jacobians depend on the reconstruction; for(size_t iVar=0; iVar<nVar; ++iVar); for(size_t jVar=0; jVar<nVar; ++jVar); blk_j[iVar*nVar+jVar] = (phiL[iVar]*phiR[jVar]-phiL[jVar]*phiR[iVar])*0.5;. // the matrix-matrix multiplications; for(size_t i=0; i<WORKITERS; ++i) {; // blk_i = blk_j * blk_j; for(size_t k=0; k<nVar*nVar; ++k) blk_j[k] = blk_i[k];; }. ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-539177957:470,update,updates,470,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-539177957,1,['update'],['updates']
Deployability,"This is simply the way how the cmd.exe shell works on Windows - file and folder names containing spaces or special characters must be quoted into `""` to be handled correctly.; The title says it all - *to make them [executables] run*. The patch prepends one `""` and appends one `""` to the command name. This could be refactored further to reduce repetition much more by putting the different executable file names into a map and have a single place to combine quote + executable + quote.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/332#issuecomment-321264218:238,patch,patch,238,https://su2code.github.io,https://github.com/su2code/SU2/pull/332#issuecomment-321264218,1,['patch'],['patch']
Deployability,"Those two cases are not part of the regression suite, and so they were probably not updated as some of the options were renamed.; You can have a look at the other turbomachinery examples (at least two of them are part of the regressions) it should be simple to adapt those options.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1086#issuecomment-706417999:84,update,updated,84,https://su2code.github.io,https://github.com/su2code/SU2/issues/1086#issuecomment-706417999,1,['update'],['updated']
Deployability,"Was playing around with the turbomachinery cases with the new multi-zone config. I like the new changes, makes it much clearer!. Just a remark, don't know if this is on purpose, but for the configuration parameter TURBOMACHINERY_KIND, you still need to supply them in the general configuration file for both zones (so in case of a two zone problem: TURBOMACHINERY_KIND = CENTRIFUGAL CENTRIFUGAL). Wouldnt it make more sense to have this per zone specified in the respective configuration file?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/715#issuecomment-514208185:190,configurat,configuration,190,https://su2code.github.io,https://github.com/su2code/SU2/pull/715#issuecomment-514208185,3,['configurat'],['configuration']
Deployability,"When I enter the ""shape_optimization.py -f unsteady_naca0012_opt.cfg"" in the commend the error is:; ```; Traceback (most recent call last):; File ""C:\Users\74351\Desktop\SU2\SU2\bin\test2\shape_optimization.py"", line 116, in <module>; main(); File ""C:\Users\74351\Desktop\SU2\SU2\bin\test2\shape_optimization.py"", line 34, in main; shape_optimization( options.filename ,; File ""C:\Users\74351\Desktop\SU2\SU2\bin\test2\shape_optimization.py"", line 51, in shape_optimization; config = SU2.io.Config(filename); File ""C:\Users\74351\Desktop\SU2\SU2\bin\SU2\io\config.py"", line 88, in __init__; super(Config,self).__init__(*args,**kwarg); File ""C:\Users\74351\Desktop\SU2\SU2\bin\SU2\util\ordered_bunch.py"", line 83, in __init__; super(OrderedBunch,self).__init__(*args,**kwarg); File ""C:\Users\74351\Desktop\SU2\SU2\bin\SU2\util\ordered_dict.py"", line 48, in __init__; self.__update(*args, **kwds); File ""C:\Users\74351\Desktop\SU2\SU2\bin\SU2\util\ordered_dict.py"", line 174, in update; for key, value in other:; TypeError: 'NoneType' object is not iterable; ```; When I enter the ""parallel_computation.py -f turb_naca0012.cfg -n NP in the commend the error is:; ```; Traceback (most recent call last):; File ""C:\Users\74351\Desktop\SU2\SU2\bin\parallel_computation.py"", line 110, in <module>; main(); File ""C:\Users\74351\Desktop\SU2\SU2\bin\parallel_computation.py"", line 53, in main; raise Exception(""No config file provided. Use -f flag""); Exception: No config file provided. Use -f flag; ```; Any solvers related to "".py"" cannot be executed, but I can run any cases with SU2_CFD. So I wonder if this situation is a problem with the Python Wrapper? . I will be very appreciated if I could get some feedback on this issue.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1567#issuecomment-1074910200:977,update,update,977,https://su2code.github.io,https://github.com/su2code/SU2/issues/1567#issuecomment-1074910200,1,['update'],['update']
Deployability,"Yes it definitely is confusing. Then we have to use set_ffd_design_var.py giving i,j,k which are not really 'units' in x,y,z. The website should be updated to show this. I am wondering how does SU2_DEF will determine the ""logic axis"". Won't a simple x,y,z approach have been simpler?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/977#issuecomment-626875076:148,update,updated,148,https://su2code.github.io,https://github.com/su2code/SU2/issues/977#issuecomment-626875076,1,['update'],['updated']
Deployability,"Yes, nothing more from me on this. Once this is merged, the comparison in PR #1260 should become simpler too. I've just updated this branch with develop, we can merge once the regression tests pass again.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1174#issuecomment-827981242:120,update,updated,120,https://su2code.github.io,https://github.com/su2code/SU2/pull/1174#issuecomment-827981242,1,['update'],['updated']
Deployability,"Yet another doubt on the same subject: I just realized that SU2V7.31 (I; have not tested it on later SU2 releases) accepts imposing both adiabatic; walls plus isothermal boundary condition on some walls (when running Menter; model), but when I simply impose only isothermal conditions (leaving; commented out the adiabatic markers), I get the message: SU2 process; returned error '1'. Is there a workaround for this? Kind regards. On Thu, Sep 28, 2023 at 8:25 PM Pedro Gomes ***@***.***>; wrote:. > you are correct, there is a discussion on CFD-online about it. we impose 0; > heat flux, but report an ""apparent heat flux"" most codes will simply give; > you back the imposed heat flux value you specify, nevertheless there will; > probably be a temperature gradient close to the wall; >; > —; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/pull/2109#issuecomment-1740118992>, or; > unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AHGXZUUZNE6B63SH7XJLY2DX4YBMZANCNFSM6AAAAAA3QKLVDU>; > .; > You are receiving this because you commented.Message ID:; > ***@***.***>; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/2109#issuecomment-1775968391:105,release,releases,105,https://su2code.github.io,https://github.com/su2code/SU2/pull/2109#issuecomment-1775968391,1,['release'],['releases']
Deployability,"```diff; $ git --no-pager diff --cached ; diff --git a/meson.build b/meson.build; index ca86992ea..b68a03c52 100644; --- a/meson.build; +++ b/meson.build; @@ -1,15 +1,12 @@; project('SU2', 'c', 'cpp',; version: '7.5.1 ""Blackbird""',; + meson_version: '0.61.1',; license: 'LGPL2',; default_options: ['buildtype=release',; 'warning_level=0',; 'c_std=c99',; 'cpp_std=c++11']); ; -if meson.version() != '0.61.1'; - error('SU2 must be configured with the extended Meson script (./meson.py) in the SU2 root directory.'); -endif; -; pymod = import('python'); python = pymod.find_installation(); ; ```. I used this patch, and then ran the following:. ```; $ meson setup builddir --wipe; The Meson build system; Version: 1.0.1; Source dir: /tmp/SU2; Build dir: /tmp/SU2/builddir; Build type: native build. meson.build:1:0: ERROR: Meson version is 1.0.1 but project requires 0.61.1; ```. Using the >= comparison, it configures fine, and downloads a git submodule for mutationpp/coolprop on demand. From a hasty look around, it seems like the other git submodules are used as externals/ directories, not meson subprojects. Another project I know uses e.g. ```; if not fs.exists('submoduledir/README.md'); error('Missing the `submoduledir` submodule! Run `git submodule update --init` to fix this.'); endif; ```. for each submodule before it gets processed by meson. This is less automatic than wrapping it in meson.py, but does provide pretty clear directions... the sticking point is if people download tarballs. You currently point people to github's autogenerated archives, which is NOT sufficient as it doesn't have submodules included. I would actually suggest using `meson dist --include-subprojects --no-tests` to produce your own tarballs and attach them as additional releases artifacts. Meson *does* include submodules (whether or not they are subprojects) automatically to the tarball it creates.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1945#issuecomment-1451057434:309,release,release,309,https://su2code.github.io,https://github.com/su2code/SU2/issues/1945#issuecomment-1451057434,4,"['patch', 'release', 'update']","['patch', 'release', 'releases', 'update']"
Deployability,"ails. |; | |; | You should have received a copy of the GNU Lesser General Public |; | License along with SU2. If not, see <http://www.gnu.org/licenses/>. |; -------------------------------------------------------------------------. Build Configuration Summary:. Source code location: /home/antodech/SU2-4.1.0; Install location: /gshare/work/hpascalj/CodeSU2-master; Version: 4.1.0; C++ Compiler: g++; C Compiler: gcc; Preprocessor flags: ; Compiler flags: -g -O2; Linker flags: ; MPI support: no; Metis support: no; Parmetis support: no; TecIO support: no; CGNS support: yes; HDF5 support: no; SZIP support: no; ZLIB support: no; Mutation++ support: no; Jsoncpp support: no; LAPACK support: no; Datatype support:; double yes; complex no; codi_reverse no; codi_forward no. External includes: ; External libs: . Build SU2_CFD: yes; Build SU2_DOT: yes; Build SU2_MSH: yes; Build SU2_DEF: yes; Build SU2_SOL: yes; Build SU2_GEO: yes. Please be sure to add the $SU2_HOME and $SU2_RUN environment variables,; and update your $PATH (and $PYTHONPATH if applicable) with $SU2_RUN. Based on the input to this configuration, add these lines to your .bashrc file:. export SU2_RUN=""/gshare/work/hpascalj/CodeSU2-master/bin""; export SU2_HOME=""/home/antodech/SU2-4.1.0""; export PATH=$PATH:$SU2_RUN; export PYTHONPATH=$PYTHONPATH:$SU2_RUN. ## ---------------- ##; ## Cache variables. ##; ## ---------------- ##. ac_cv_build=x86_64-unknown-linux-gnu; ac_cv_c_compiler_gnu=yes; ac_cv_cxx_compiler_gnu=yes; ac_cv_env_CCC_set=; ac_cv_env_CCC_value=; ac_cv_env_CC_set=; ac_cv_env_CC_value=; ac_cv_env_CFLAGS_set=; ac_cv_env_CFLAGS_value=; ac_cv_env_CPPFLAGS_set=; ac_cv_env_CPPFLAGS_value=; ac_cv_env_CPP_set=; ac_cv_env_CPP_value=; ac_cv_env_CXXFLAGS_set=; ac_cv_env_CXXFLAGS_value=; ac_cv_env_CXX_set=; ac_cv_env_CXX_value=; ac_cv_env_LDFLAGS_set=; ac_cv_env_LDFLAGS_value=; ac_cv_env_LIBS_set=; ac_cv_env_LIBS_value=; ac_cv_env_build_alias_set=; ac_cv_env_build_alias_value=; ac_cv_env_host_alias_set=; ac_cv_env_host_",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:19184,update,update,19184,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,1,['update'],['update']
Deployability,"ally detect the default package location, but it's not equipped to handle multiple package locations. There are some hardcoded includes, but these only work for python 2.7. I don't consider this a bug *per se* because multiple python package directories is not a standard use case. #### The symptoms. When building SU2 with the python wrapper you'll see the following error during the swig build:; ```; <install directory>/../SU2_PY/pySU2/pySU2.i:64: Error: Unable to find 'mpi4py/mpi4py.i'; ```; But mpi4py is indeed installed on your system and it's on your python path, as confirmed by opening a python terminal and running `import mpi4py`. #### The easiest workaround. Switch to a [virtualenv](https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/). This will ensure that all of your python packages are stored in single location. #### Alternate workaround. In this method, you change the hardcoded includes to match mpi4py's package location. First I figure out where my mpi4py is installed. I start a terminal session of python using the python environment I want to use (in this case, it's python 3.6), and then run:; ```; from mpi4py import MPI; MPI; ```. Since I have mpi4py installed on your system and it's on my python path, I see something like:; ```; <module 'mpi4py.MPI' from '/home/clarkpede/.local/lib/python3.6/site-packages/mpi4py/MPI.cpython-34m.so'>; ```. The `/home/clarkpede/.local/lib/python3.6/` directory is where my mpi4py package is installed. But the swig compile command includes `/home/clarkpede/.local/lib/python2.7/`. That's not the right directory! So first I find the hardcoded paths of the makefile by running (on a bash terminal):; ```; grep -rn python2\.7 SU2_PY/ ; ```; On my system, this prints out four lines. I don't care about the `Makefile.in` files, because those are generated automatically and will be overwritten every time I run ""configure"" or ""preconfigure.py."" The `NUMPY_INCLUDE` line is also commented out, so I ignore ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/722#issuecomment-515693590:1393,install,installed,1393,https://su2code.github.io,https://github.com/su2code/SU2/issues/722#issuecomment-515693590,1,['install'],['installed']
Deployability,"ble-multilib --disable-werror --enable-checking=release --enable-default-pie --enable-default-ssp --enable-cet=auto gdc_include_dir=/usr/include/dlang/gdc; Thread model: posix; gcc version 9.2.1 20200130 (Arch Linux 9.2.1+20200130-2) ; ```; I did what you suggested and here is how my meson.build file looks.; ```; # If custom mpi mode is enabled, include and library pathes for MPI have to be set manually to env variables; if get_option('custom-mpi'); mpi_dep = []; mpi = true; # Otherwise they are automatically determined; else; mpi_dep = [dependency('mpich', required : get_option('with-mpi'))]; # mpi_dep = [dependency('mpi', language:'c', required : get_option('with-mpi')),; # dependency('mpi', language:'cpp', required : get_option('with-mpi'))]; #if mpi_dep[0].found() or mpi_dep[1].found(); # mpi = true; #endif; endif; ```; My SU2 build was successful but there were a couple of warnings.; Also, instead of 870 there were only 772 files in total. Is that okay?; ```; slimshady@arch-linux-hp-probook-g3-450: SU2HOME$ ./ninja -C build install; ninja: Entering directory `build'; [756/772] Generating 'SU2_PY/pySU2/_pysu2.so.p/pySU2.cxx'.; ../SU2_PY/pySU2/../../Common/include/mpi_structure.hpp:348: Warning 325: Nested struct not currently supported (Status ignored); [760/772] Generating 'SU2_PY/pySU2/_pysu2ad.so.p/pySU2ad.cxx'.; ../SU2_PY/pySU2/../../Common/include/mpi_structure.hpp:348: Warning 325: Nested struct not currently supported (Status ignored); [771/772] Installing files.; .; .; ```; Here is the [entire output for `./ninja`](https://github.com/su2code/SU2/files/4672490/ninja_build_mpich.log). Even though the build was successful, SU2 does not seem to run properly. It displays the same thing ""NP"" (`mpirun -n NP ...`) number of times. And the console prints the output in chunks, like 57 iterations suddenly ""NP"" times, then a pause, then 57-119 ""NP"" times and so on. You can see the [logfile here](https://github.com/su2code/SU2/files/4672491/mpirun_SU2_CFD_error.log).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1000#issuecomment-633139474:2057,install,install,2057,https://su2code.github.io,https://github.com/su2code/SU2/issues/1000#issuecomment-633139474,1,['install'],['install']
Deployability,"both codes deliver the same results (of course with some minor differences). So far so good. Unsteady cases are a bit trickier: the latest 2D results of @RoccoBombardieri show pretty much no difference including the first timesteps. The onera m6 case in contrast converges to the same (steady-state) results for both code version eventually but their initial transient phase differs quite significantly. . A possible explanation for the different initial transient phase: In both implementations a ""reflected state"" is constructed where the normal component of the velocity is subtracted [once in the older code version & twice in the newer version]. I.e. subtracting the normal component of velocity twice means mirroring the velocity along the symmetry plane. The newer code version is a bit ""stronger"" in enforcing the boundary conditions which could lead to the reduced oscillation in CD and CL. If we agree that both code versions produce physically correct results for steady cases and unsteady cases that were integrated long enough in time to get rid of the influence of the initial condition ... then we are left with this initial transient phase that differs. Of course if there is more evidence that one or the other version produces physically ""better"" results I would love to see that. Until then, both initial oscillations are equally correct/uncorrect in my opinion. [I'll add a few words about the adjoint here later]. [I'll add the idea of an FSI case of @cvencro here later where the initial phase has a major impact]; Consider an FSI computation of an airfoil where the trailing edge can exhibit flutter (periodic up-and-down-movement of the trailing edge) in certain flow regimes. Now if during the initial transient the forces on the airfoil are higher than in the converged state then the fluttering can be excited where the initial transient can be seen as an activation energy. If you were to e.g. ramp up flow speed/conditions slowly up to the same magnitude as before one mig",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/828#issuecomment-563314747:1909,integrat,integrated,1909,https://su2code.github.io,https://github.com/su2code/SU2/issues/828#issuecomment-563314747,1,['integrat'],['integrated']
Deployability,"bsonic engine intake option; - Small output change; - Added output_su2.cpp; - Updated Engine BC; - Working on Engine BCs; - Added Supersonic Outlet BC; - Minor change; - Merge remote-tracking branch 'upstream/develop' into develop; - adjoints, solid boundary, doxygen in config; - continued fixing; - re-added adjoint bc mods; - re-adding avg outlet pressure (static pressure adjoint); - re-adding avg outlet pressure (static pressure adjoint); - Merge branch 'temp' of https://github.com/hlkline/SU2 into temp; - continued fixing; - average total pressure and fixes to avg outlet pressure; - adding stagnation pressure output to SU2_DOT; - Merge pull request #146 from hlkline/temp; - Updated Entropy fix (now it is active).; - Another change in BC_Engine_Exhaust; - Updated CGNS in parallel; - Added runtime file; - Small typo; - Adjustment of the Entropy fix coefficient; - Bug in SU2_GEO; - Debug version with print statements.; - Updated release 3.2.7.1; - Small change; - Updated config file; - Code update; - MPI Status and Request fix.; - Another MPI Status/Request fix.; - Actuator disk update.; - Small update; - Initial implementation of pyramids and prisms for Tecplot binary.; - Small fix for Tecplot binaries. Closes #56. Closes #57.; - Removed extra allocation related to markers during partitioning.; - Non-working version; - Small update; - Updated memory deallocation.; - Merge branch 'feature_MarkerMax' into develop; - Time and date in the header.; - Small fix to the latest commit.; - Simplification of entropy correction; - Critical stability improvement.; - Minor release 3.2.7.2; - Fixing issues to run with the latest intel compiler; - Fix for Tecplot binary solutions for unsteady flows. Fixes #150.; - Now SU2 should work with the latest version of the Intel compiler.; - Merge branch 'develop' of https://github.com/su2code/SU2 into develop; - Working on the O3 stuff; - Small change.; - Add another check to improve stability.; - Collection of improvements.; - Updated ac",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:4126,update,update,4126,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['update'],['update']
Deployability,"c` we resolve 4/8 row/column pairs into 1D indexes, while this calculation is vectorized, it seems to be less optimizable by compilers, for example this; ```c++; for(size_t iDim=0; iDim<nDim; ++iDim); phiL += grad.getVec(iPoint,iVar,iDim)*d_ij[iDim];; ```; gets compiled into this monstrosity; ```asm; .L13:; vpmuludq ymm0, ymm4, ymm1; vmovq xmm15, rax; vmovapd ymm6, ymm11; mov rdx, rax; vpbroadcastq ymm15, xmm15; sal rdx, 5; add rax, 1; vpaddq ymm0, ymm0, ymm2; vpsllq ymm0, ymm0, 32; vpaddq ymm0, ymm5, ymm0; vmovdqa YMMWORD PTR [rbp-240], ymm0; vpaddq ymm0, ymm3, ymm0; vmovdqa YMMWORD PTR [rbp-208], ymm0; vpaddq ymm0, ymm15, ymm0; vmovdqa YMMWORD PTR [rbp-176], ymm0; vgatherqpd ymm15, QWORD PTR [rdi+ymm0*8], ymm6; vmovapd ymm0, YMMWORD PTR [rsi+rdx]; vfmadd213pd ymm0, ymm15, YMMWORD PTR [rbp-336]; vmovapd YMMWORD PTR [rbp-336], ymm0; cmp rbx, rax; jne .L13; ```; the meat of which is `vgatherqpd` (`getVec`) and `vfmadd213pd` fused-multiply-add to update `phiL`, everything else is integer arithmetic which in the scalar version gets factored out of the inner loop so that the resulting assembly looks much simpler:; ```asm; .L15:; vmovsd xmm5, QWORD PTR [rsp-40+rax*8]; vfmadd231sd xmm0, xmm5, QWORD PTR [r15+rax*8]; add rax, 1; cmp rcx, rax; jne .L15; ```; I think the reason for this is that there are plenty of integer registers (64bit) to keep memory locations (rsp, rax, r15 in the above) but there are only 16 ymm registers (256bit). In any case we need to give the compiler a hand, the calculation we need is; `index = iPoint*nVar*nDim + iVar*nDim + iDim` where iPoint is an array of ints; Note that as we loop by nDim and then by nVar all we need is to compute `iPoint*nVar*nDim` outside the loops and then add 1 on each access (which is more or less what the compiler does for the scalar code), in other words we need an **iterator**, something silly like; ```c++; template<size_t VecLen, size_t Incr = VecLen>; class GatherIterator; {; private:; using IntVec = Array<size_t,VecLe",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-535977206:10097,update,update,10097,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206,1,['update'],['update']
Deployability,che variables. ##; ## ---------------- ##. ac_cv_build=x86_64-unknown-linux-gnu; ac_cv_c_compiler_gnu=yes; ac_cv_cxx_compiler_gnu=yes; ac_cv_env_CCC_set=; ac_cv_env_CCC_value=; ac_cv_env_CC_set=; ac_cv_env_CC_value=; ac_cv_env_CFLAGS_set=; ac_cv_env_CFLAGS_value=; ac_cv_env_CPPFLAGS_set=; ac_cv_env_CPPFLAGS_value=; ac_cv_env_CPP_set=; ac_cv_env_CPP_value=; ac_cv_env_CXXFLAGS_set=; ac_cv_env_CXXFLAGS_value=; ac_cv_env_CXX_set=; ac_cv_env_CXX_value=; ac_cv_env_LDFLAGS_set=; ac_cv_env_LDFLAGS_value=; ac_cv_env_LIBS_set=; ac_cv_env_LIBS_value=; ac_cv_env_build_alias_set=; ac_cv_env_build_alias_value=; ac_cv_env_host_alias_set=; ac_cv_env_host_alias_value=; ac_cv_env_target_alias_set=; ac_cv_env_target_alias_value=; ac_cv_file__gshare_soft_code_saturne_4_0_0_prod_cgnslib_3_2_1_include_cgnslib_h=yes; ac_cv_file__gshare_soft_code_saturne_4_0_0_prod_cgnslib_3_2_1_lib_libcgns_a=yes; ac_cv_header_X11_Intrinsic_h=no; ac_cv_header_inttypes_h=yes; ac_cv_header_memory_h=yes; ac_cv_header_stdc=yes; ac_cv_header_stdint_h=yes; ac_cv_header_stdlib_h=yes; ac_cv_header_string_h=yes; ac_cv_header_strings_h=yes; ac_cv_header_sys_stat_h=yes; ac_cv_header_sys_types_h=yes; ac_cv_header_unistd_h=yes; ac_cv_host=x86_64-unknown-linux-gnu; ac_cv_objext=o; ac_cv_path_EGREP='/bin/grep -E'; ac_cv_path_GREP=/bin/grep; ac_cv_path_install='/usr/bin/install -c'; ac_cv_path_mkdir=/bin/mkdir; ac_cv_prog_AWK=gawk; ac_cv_prog_CPP='gcc -E'; ac_cv_prog_ac_ct_CC=gcc; ac_cv_prog_ac_ct_CXX=g++; ac_cv_prog_ac_ct_RANLIB=ranlib; ac_cv_prog_cc_c89=; ac_cv_prog_cc_g=yes; ac_cv_prog_cc_gcc_c_o=yes; ac_cv_prog_cxx_g=yes; ac_cv_prog_make_make_set=yes; ac_cv_sizeof_double=8; ac_cv_sizeof_float=4; ac_cv_sizeof_int=4; ac_cv_sizeof_long_int=8; ac_cv_sizeof_short_int=2; ac_cv_sizeof_unsigned_int=4; ac_cv_sizeof_void_p=8; ac_cv_target=x86_64-unknown-linux-gnu; am_cv_CC_dependencies_compiler_type=gcc3; am_cv_CXX_dependencies_compiler_type=gcc3; am_cv_make_support_nested_variables=yes. ## ----------------- ##; ## Output variab,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:20866,install,install,20866,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,1,['install'],['install']
Deployability,"ctivity[iEdge].first;; size_t jPoint = connectivity[iEdge].second;. matrix.updateBlocks(iEdge, iPoint, jPoint, blk_i, blk_j);; }; }; ```; where; ```c++; STRONGINLINE void SparseMatrix::updateBlocks(size_t edge,; size_t row, size_t col, const double* blk_i, const double* blk_j); {; size_t bii = diagMap[row], bij = edgeMap[edge].first,; bjj = diagMap[col], bji = edgeMap[edge].second;. #pragma omp simd; for(size_t k=0; k<blkSz; ++k); {; coeffs[bii+k] += blk_i[k]; coeffs[bij+k] = +blk_j[k];; coeffs[bji+k] = -blk_i[k]; coeffs[bjj+k] -= blk_j[k];; }; }; ```; This is **47% faster**, which for a memory bound task is massive!; Yes, this does increase the memory footprint a bit (makes CSysMatrix 4% larger for a 3D problem) but I can get that back by sharing sparsity patterns and maps across turbulence and bulk flow (I think @talbring was already working on this in the template linear solver branch he had started). We could also parallelize the matrix updates without colouring by setting only the off-diagonal coefficients and then setting the diagonal entries to the column sum.; It turns out that this is worse (by about 10%), maybe if the matrix were symmetric (row sum) but a column sum accesses blocks very far apart. Also we want to interleave compute and load/stores as much as possible to allow the CPU pipelining magic to mask the latency of the latter (even if it looks like you can only write the block after it is computed, CPU's have all kinds of buffers that allow the next loop iteration to begin while data is in flight). **Therefore colouring is the way to go.**. _Note: With vectorized numerics we insert blocks for 4 or 8 edges into the matrix at a time, the data for those inserts will be in a slightly weird format, which will make `SparseMatrix::updateBlocks` a bit harder on the eye, more on that later._. ## MUSCL Reconstruction; The MUSCL reconstruction, characteristic of upwind schemes, is the simplest building block to show the (negative) implications of storing the ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-535977206:4710,update,updates,4710,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206,1,['update'],['updates']
Deployability,"e more granularity such that you could manipulate the geometry from python (without writing it to files).; > We also wanted introspection, i.e. you could probe SU2 via python for what variables and functions are available.; > We also talked about having the projection step (DOT) included in CFD_AD so that you only need to worry about surface sensitivities, note that DEF is already part of CFD for forward mode AD.; > (talking does not go very far); > ; > If you want to lead this work, we can help you understand the inner workings. We meet every Wednesday at 4pm CET https://meet.jit.si/SU2_DevMeeting to discuss this type of issue. Thank you for the quick reply. The discussions you mention sound very promising, I would be glad to join tomorrow afternoon and learn more, so that I might contribute. One quick remark: I am aware that it is indeed possible to deform the mesh within `SU2_CFD`, I use this extensively for static aero-elastic analysis. However, I have not been able to have the deformed mesh be written to file at output (in SU2 or CGNS format). This is fine for aero-elastic updates (movement of the surface due to _structural displacements_), where it is sufficient to see the deformed mesh in the post-processing files. It becomes impractical though, for design updates (movement of the surface to due to _design displacements_, i.e. representing changes in the design variables) where the new mesh is a useful intermediate result. Even if this is just an issue in my configuration file, I think that a stand-alone driver or equivalent of `SU2_DEF` would remain useful. For each new set of updated design variables during shape optimisation, a single mesh deformation is sufficient to provide the new, updated jig geometry which all of the aerodynamic or aero-elastic analyses (one for each operating point) have in common. There would be no need to initialise the entire `SU2_CFD` machinery for this step, or to apply the design update separately for each of the SU2 instances.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1262#issuecomment-818839696:1279,update,updates,1279,https://su2code.github.io,https://github.com/su2code/SU2/issues/1262#issuecomment-818839696,6,"['configurat', 'update']","['configuration', 'update', 'updated', 'updates']"
Deployability,"e_Exhaust and BC_Engine_Bleed; - Small change; - Fixing subsonic engine intake option; - Small output change; - Added output_su2.cpp; - Updated Engine BC; - Working on Engine BCs; - Added Supersonic Outlet BC; - Minor change; - Merge remote-tracking branch 'upstream/develop' into develop; - adjoints, solid boundary, doxygen in config; - continued fixing; - re-added adjoint bc mods; - re-adding avg outlet pressure (static pressure adjoint); - re-adding avg outlet pressure (static pressure adjoint); - Merge branch 'temp' of https://github.com/hlkline/SU2 into temp; - continued fixing; - average total pressure and fixes to avg outlet pressure; - adding stagnation pressure output to SU2_DOT; - Merge pull request #146 from hlkline/temp; - Updated Entropy fix (now it is active).; - Another change in BC_Engine_Exhaust; - Updated CGNS in parallel; - Added runtime file; - Small typo; - Adjustment of the Entropy fix coefficient; - Bug in SU2_GEO; - Debug version with print statements.; - Updated release 3.2.7.1; - Small change; - Updated config file; - Code update; - MPI Status and Request fix.; - Another MPI Status/Request fix.; - Actuator disk update.; - Small update; - Initial implementation of pyramids and prisms for Tecplot binary.; - Small fix for Tecplot binaries. Closes #56. Closes #57.; - Removed extra allocation related to markers during partitioning.; - Non-working version; - Small update; - Updated memory deallocation.; - Merge branch 'feature_MarkerMax' into develop; - Time and date in the header.; - Small fix to the latest commit.; - Simplification of entropy correction; - Critical stability improvement.; - Minor release 3.2.7.2; - Fixing issues to run with the latest intel compiler; - Fix for Tecplot binary solutions for unsteady flows. Fixes #150.; - Now SU2 should work with the latest version of the Intel compiler.; - Merge branch 'develop' of https://github.com/su2code/SU2 into develop; - Working on the O3 stuff; - Small change.; - Add another check to impro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:4063,release,release,4063,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['release'],['release']
Deployability,"easier implementation experience. Certainly, this is not the only consideration but it should be taken into account. Currently, resulting from the significant contributions of the members of this developers group, SU2 implementation works like a charm. I think we should strive to conserve this feature, especially if we aim at attracting more users and developers into the community. (...). >@vdweide; >(...) @bmunguia and @EduardoMolina, what type of application did you have in mind for PETSc? The only thing I can think of is a full Newton solver. And no matter how much I like PETSc, @juanjosealonso and @erangit have a point here. Looks like I start to belong to the group of old conservatives as well.... >@economon ; >(...) If you really would like to give PETSc a shot, I recommend talking with @anilvar who had an interface for connecting it to SU2 in one of our branches. >@pcarruscag; >(...) being able to use PETSc or HYPRE would be interesting as it would give us access to AMG, and @talbring 's branch feature_template_linear_solver would make such an integration compatible with AD. (...). >@EduardoMolina; >(...) When Brian (@bmunguia ) and I mentioned PETSc, it was an idea to try a different Newton-Krylov (with preconditioner) library in order to improve the convergence of SU2.; Since the slow convergence of the SU2-FV is the main feedback that I received from other users from industry and academia, I think it worth try an external library and evaluate the performance. (...). >@pcarruscag ; >(...) That is something I am also interested in as for some of my structural cases the current linear solvers simply do not converge. (...). >@economon ; >I would add one practical comment for consideration: it is worth checking whether the main restriction we have is related to approximations in the Jacobian that limit the effective CFL we can use or whether the convergence of the linear solver itself is a problem (speed or complete lack of convergence). A quick test without re",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/648#issuecomment-460853218:2535,integrat,integration,2535,https://su2code.github.io,https://github.com/su2code/SU2/issues/648#issuecomment-460853218,1,['integrat'],['integration']
Deployability,"eps for unsteady problems.; * Loop over the number of pseudo-time steps for implicit time integration schemes; (DT_STEPPING_1ST and DT_STEPPING_2ND). For other cases this loop is 1.; * Loop over the number of disciplines involved; Call iterate for each of the disciplines.; In iterate:; * Loop over the (Runge-Kutta) stages; * Loop over the zones of a single discipline; Compute spatial residual.; Update the state vector.; * End loop over the zones of a single discipline.; Exchange halo data. This includes the halo data between zones of a single discipline.; * End loop over the (Runge-Kutta) stages; * End loop over the disciplines; * End loop over the pseudo time steps.; * End loop over the number of iterations, or time steps for unsteady problems. The weakness of this approach is that it still does not work when one would like to employ multi-stage time integration schemes for an unsteady, multi-disciplinary problem (does not work for the current implementation either), but maybe this is something we simply have to accept. The alternative is that all the details of the different time integration schemes have to be moved to the driver classes, which is highly undesirable, I think. The structure above implies that the iteration_container and the integration_container should be defined per discipline and not per zone anymore. The geometry_container and solver_container should still be defined per zone. Well, I suppose this leaves plenty of room for discussion, so I would say to continue the online discussion a bit further, such that things become a bit clearer how to tackle this issue. After that having a telecon would be good to iron out the details. Regards,. Edwin. —; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/437#issuecomment-328368371>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADpSxHiNAbZtzVEvIm0XDsNvQmZ6lrwwks5shEHjgaJpZM4PQ90s>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/437#issuecomment-328403160:3260,integrat,integration,3260,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328403160,1,['integrat'],['integration']
Deployability,"es is not a standard use case. #### The symptoms. When building SU2 with the python wrapper you'll see the following error during the swig build:; ```; <install directory>/../SU2_PY/pySU2/pySU2.i:64: Error: Unable to find 'mpi4py/mpi4py.i'; ```; But mpi4py is indeed installed on your system and it's on your python path, as confirmed by opening a python terminal and running `import mpi4py`. #### The easiest workaround. Switch to a [virtualenv](https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/). This will ensure that all of your python packages are stored in single location. #### Alternate workaround. In this method, you change the hardcoded includes to match mpi4py's package location. First I figure out where my mpi4py is installed. I start a terminal session of python using the python environment I want to use (in this case, it's python 3.6), and then run:; ```; from mpi4py import MPI; MPI; ```. Since I have mpi4py installed on your system and it's on my python path, I see something like:; ```; <module 'mpi4py.MPI' from '/home/clarkpede/.local/lib/python3.6/site-packages/mpi4py/MPI.cpython-34m.so'>; ```. The `/home/clarkpede/.local/lib/python3.6/` directory is where my mpi4py package is installed. But the swig compile command includes `/home/clarkpede/.local/lib/python2.7/`. That's not the right directory! So first I find the hardcoded paths of the makefile by running (on a bash terminal):; ```; grep -rn python2\.7 SU2_PY/ ; ```; On my system, this prints out four lines. I don't care about the `Makefile.in` files, because those are generated automatically and will be overwritten every time I run ""configure"" or ""preconfigure.py."" The `NUMPY_INCLUDE` line is also commented out, so I ignore that too. That leaves me with one line, line 51 of `SU2_PY/pySU2/Makefile.am`:. ```; SU2_PY/pySU2/Makefile.am:51:MPI4PY_INCLUDE = ${HOME}/.local/lib/python2.7/site-packages/mpi4py/include \; ```. I now modify line 51 of Makefile.am to read:. ```; MPI",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/722#issuecomment-515693590:1591,install,installed,1591,https://su2code.github.io,https://github.com/su2code/SU2/issues/722#issuecomment-515693590,1,['install'],['installed']
Deployability,"et BC; - Minor change; - Merge remote-tracking branch 'upstream/develop' into develop; - adjoints, solid boundary, doxygen in config; - continued fixing; - re-added adjoint bc mods; - re-adding avg outlet pressure (static pressure adjoint); - re-adding avg outlet pressure (static pressure adjoint); - Merge branch 'temp' of https://github.com/hlkline/SU2 into temp; - continued fixing; - average total pressure and fixes to avg outlet pressure; - adding stagnation pressure output to SU2_DOT; - Merge pull request #146 from hlkline/temp; - Updated Entropy fix (now it is active).; - Another change in BC_Engine_Exhaust; - Updated CGNS in parallel; - Added runtime file; - Small typo; - Adjustment of the Entropy fix coefficient; - Bug in SU2_GEO; - Debug version with print statements.; - Updated release 3.2.7.1; - Small change; - Updated config file; - Code update; - MPI Status and Request fix.; - Another MPI Status/Request fix.; - Actuator disk update.; - Small update; - Initial implementation of pyramids and prisms for Tecplot binary.; - Small fix for Tecplot binaries. Closes #56. Closes #57.; - Removed extra allocation related to markers during partitioning.; - Non-working version; - Small update; - Updated memory deallocation.; - Merge branch 'feature_MarkerMax' into develop; - Time and date in the header.; - Small fix to the latest commit.; - Simplification of entropy correction; - Critical stability improvement.; - Minor release 3.2.7.2; - Fixing issues to run with the latest intel compiler; - Fix for Tecplot binary solutions for unsteady flows. Fixes #150.; - Now SU2 should work with the latest version of the Intel compiler.; - Merge branch 'develop' of https://github.com/su2code/SU2 into develop; - Working on the O3 stuff; - Small change.; - Add another check to improve stability.; - Collection of improvements.; - Updated actuator disk; - Merge branch 'develop' of https://github.com/su2code/SU2 into develop; - Preliminary implementation of the Neg SA; - Minor updates;",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:4233,update,update,4233,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['update'],['update']
Deployability,"figure:3654: g++ -c -g conftest.cpp >&5; configure:3654: $? = 0; configure:3695: result: yes; configure:3720: checking dependency style of g++; configure:3831: result: gcc3; configure:3921: checking for gcc; configure:3937: found /usr/bin/gcc; configure:3948: result: gcc; configure:3979: checking for C compiler version; configure:3988: gcc --version >&5; gcc (GCC) 4.4.6 20120305 (Red Hat 4.4.6-4); Copyright (C) 2010 Free Software Foundation, Inc.; This is free software; see the source for copying conditions. There is NO; warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. configure:3999: $? = 0; configure:3988: gcc -v >&5; Using built-in specs.; Target: x86_64-redhat-linux; Configured with: ../configure --prefix=/usr --mandir=/usr/share/man --infodir=/usr/share/info --with-bugurl=http://bugzilla.redhat.com/bugzilla --enable-bootstrap --enable-shared --enable-threads=posix --enable-checking=release --with-system-zlib --enable-__cxa_atexit --disable-libunwind-exceptions --enable-gnu-unique-object --enable-languages=c,c++,objc,obj-c++,java,fortran,ada --enable-java-awt=gtk --disable-dssi --with-java-home=/usr/lib/jvm/java-1.5.0-gcj-1.5.0.0/jre --enable-libgcj-multifile --enable-java-maintainer-mode --with-ecj-jar=/usr/share/java/eclipse-ecj.jar --disable-libjava-multilib --with-ppl --with-cloog --with-tune=generic --with-arch_32=i686 --build=x86_64-redhat-linux; Thread model: posix; gcc version 4.4.6 20120305 (Red Hat 4.4.6-4) (GCC) ; configure:3999: $? = 0; configure:3988: gcc -V >&5; gcc: '-V' option must have argument; configure:3999: $? = 1; configure:3988: gcc -qversion >&5; gcc: unrecognized option '-qversion'; gcc: no input files; configure:3999: $? = 1; configure:4003: checking whether we are using the GNU C compiler; configure:4022: gcc -c conftest.c >&5; configure:4022: $? = 0; configure:4031: result: yes; configure:4040: checking whether gcc accepts -g; configure:4060: gcc -c -g conftest.c >&5; configure:4060: $? = 0; configure:4101: r",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:6016,release,release,6016,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,1,['release'],['release']
Deployability,"hort array of matrices, the result of that is code like the above that explicitly manipulates the lanes of our SIMD type, such code can be completely hidden inside CSysMatrix which is good because a 4x4 vectorized transpose and matrix update looks like this; ```c++; // block j, subs from jj and goes to ij; T0 = blk_j[ k ].unpackLo(blk_j[k+1]); T1 = blk_j[ k ].unpackHi(blk_j[k+1]);; T2 = blk_j[k+2].unpackLo(blk_j[k+3]); T3 = blk_j[k+2].unpackHi(blk_j[k+3]);. C0 = T0.widePermuteLo(T2); C1 = T1.widePermuteLo(T3);; C2 = T0.widePermuteHi(T2); C3 = T1.widePermuteHi(T3);. (Array4d(&bjj[0][k])-C0).store(&bjj[0][k]);; (Array4d(&bjj[1][k])-C1).store(&bjj[1][k]);; (Array4d(&bjj[2][k])-C2).store(&bjj[2][k]);; (Array4d(&bjj[3][k])-C3).store(&bjj[3][k]);. C0.store(&bij[0][k]); C1.store(&bij[1][k]);; C2.store(&bij[2][k]); C3.store(&bij[3][k]);; ```; I am showing this because it represents a readability worst case in terms of manipulating SIMD types, we might end up with one or two of these to get the best performance possible but they will always be encapsulated and deep in kernel-type areas of SU2 that are almost never touched. ## Conclusions; - Over 45% faster CSysMatrix updates by mapping off-diagonal blocks to edges and diagonal blocks to points.; - Colouring is the best strategy for hybrid parallelism of compute-heavy edge loops and matrix updates as it interleaves compute and memory operations.; - AoS storage should be kept to avoid significant loss of performance in compute-light edge loops due to poor locality of SoA storage.; - Major implication of AoS is on point loops where some data needs to be fetched (transposed) into local variables for effective vectorization.; - An intermediate storage scheme, AoSoA, can provide both good locality and vectorization of point loops, however it requires that data be accessed via special iterators and scalar code based on it would have poor performance. Next I will try to estimate how much we can gain for a ""realistic"" numerics class.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-535977206:16719,update,updates,16719,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206,2,['update'],['updates']
Deployability,"im);; ...; ```; Performance wise this is actually better than the SoA version (4% on gradients, 35% on limiters) as it also benefits from better locality, and it is only slightly (3%) worse than zig zag storage, especially when fusing limiters and gradients as the transposition of the gradient into storage is greatly amortised.; Regarding readability, the 3 nested loops can be moved to methods of the container, but we cannot get rid off the local variable (if we want vectorization that is). **We lose the ability to vectorize primitive variable updates efficiently with AoS** but currently that only accounts for 3% of the runtime and it is a memory bound operation therefore it would not gain much from vectorization anyway. On the subject of de-swizzling data remember I said the writes into CSysMatrix would be a bit weird, that is because each Jacobian contribution will be a ""matrix of short arrays"" that needs to be transformed into a short array of matrices, the result of that is code like the above that explicitly manipulates the lanes of our SIMD type, such code can be completely hidden inside CSysMatrix which is good because a 4x4 vectorized transpose and matrix update looks like this; ```c++; // block j, subs from jj and goes to ij; T0 = blk_j[ k ].unpackLo(blk_j[k+1]); T1 = blk_j[ k ].unpackHi(blk_j[k+1]);; T2 = blk_j[k+2].unpackLo(blk_j[k+3]); T3 = blk_j[k+2].unpackHi(blk_j[k+3]);. C0 = T0.widePermuteLo(T2); C1 = T1.widePermuteLo(T3);; C2 = T0.widePermuteHi(T2); C3 = T1.widePermuteHi(T3);. (Array4d(&bjj[0][k])-C0).store(&bjj[0][k]);; (Array4d(&bjj[1][k])-C1).store(&bjj[1][k]);; (Array4d(&bjj[2][k])-C2).store(&bjj[2][k]);; (Array4d(&bjj[3][k])-C3).store(&bjj[3][k]);. C0.store(&bij[0][k]); C1.store(&bij[1][k]);; C2.store(&bij[2][k]); C3.store(&bij[3][k]);; ```; I am showing this because it represents a readability worst case in terms of manipulating SIMD types, we might end up with one or two of these to get the best performance possible but they will always be enc",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-535977206:15777,update,update,15777,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206,1,['update'],['update']
Deployability,"ing the installation (the exact same steps that @chesiv presented), I encountered a problem when running the mesh_adaptation_amg.py script. The command used was:. ```; python3 $SU2_RUN/mesh_adaptation_amg.py -f adapt_Mesh.cfg -n 4; ```; The script initiates the mesh adaptation process as expected, with the following output:. ```; SU2-AMG Anisotropic Mesh Adaptation. Mesh adaptation options:; PYADAP_COMPLEXITY : (30000, 60000, 120000); PYADAP_SUBITE : (2, 2, 2); PYADAP_SENSOR : GOAL; PYADAP_HMAX : 500.0; PYADAP_HMIN : 1e-9; PYADAP_HGRAD : 1.8. ./adap exists. Removing old mesh adaptation in 10s.; The ./adap folder was deleted. Generating GMF background surface mesh.; Initial CFD solution is provided.; ```; However, no _adap\ite0_ folder gets created. ; The log.err file in the _adap/ini_ directory provides this traceback:. ```; Traceback (most recent call last):; File "".../mesh_adaptation_amg.py"", line 111, in <module>; ...; RuntimeError: ...; Error in TokenizeString(): two or more options before an ""="" sign in the configuration file.; terminate called after throwing an instance of 'int'; ...; *** Process received signal ***; Signal: Aborted (6); Signal code: (-6); ...; ```. The critical part of this error seems to be the Error in TokenizeString() message, suggesting an issue with parsing the configuration file. This error typically indicates a syntax problem, such as having multiple options on a single line without proper separation by an equal sign (=). However, upon reviewing _adap/ini/config_CFD.cfg_, was unable to find any lines that clearly violated this syntax rule. Could this error be indicative of a more subtle issue within the configuration file, or might it be related to specific aspects of the feature_adap branch? Any insights, suggestions, or guidance on how to troubleshoot this error would be greatly appreciated. If anyone has a working adapt_mesh.cfg file for a similar setup or for the feature_adap branch, I would be very interested in seeing it. Underst",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/948#issuecomment-1847333809:1237,configurat,configuration,1237,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-1847333809,1,['configurat'],['configuration']
Deployability,itical stability improvement.; - Minor release 3.2.7.2; - Fixing issues to run with the latest intel compiler; - Fix for Tecplot binary solutions for unsteady flows. Fixes #150.; - Now SU2 should work with the latest version of the Intel compiler.; - Merge branch 'develop' of https://github.com/su2code/SU2 into develop; - Working on the O3 stuff; - Small change.; - Add another check to improve stability.; - Collection of improvements.; - Updated actuator disk; - Merge branch 'develop' of https://github.com/su2code/SU2 into develop; - Preliminary implementation of the Neg SA; - Minor updates; - Preliminary implementation of the Negative SA; - Bug fixing; - Fixed memory issued for very large meshes with ParMETIS.; - Clear evaluation of Vorticity and StrainMag; - Viscous limiter; - Updated RELAXATION_FACTOR; - RANS MG; - Partial fix to no MPI output; - Updated I/O; - Updated Adapt CFL; - Updated Adaptive CFL number; - Release 3.2.8; - Updated SetCFL_Number; - Small update; - Small change; - Small adjustments; - Minor changes; - Updated release 3.2.8; - MPI disabled by default in build. Added --enable-mpi flag to configure.; - Merged the ParMETIS implementation. Updated the build files.; - bootstrap; - Started parallel CGNS reader.; - Memory fix.; - Minor change; - Merge branch 'develop' of https://github.com/su2code/SU2 into develop; - Updated binaries; - Small change to configure.ac. Bootstrap.; - Small change; - Cleaning the code; - Updated grid deformation subroutine; - Fixing the mesh deformation; - Updated SU2_MSH; - Bug fixing; - Initial implementation of parallel CGNS reader. Works on 1 rank.; - Merged in recent changes to geometry_structure.cpp.; - Periodic BC working in serial; - Update option_structure.hpp; - Merge pull request #154 from su2code/fixCOptionEnumList; - Bug fixing (periodic bc); - Merge branch 'develop' of https://github.com/su2code/SU2 into develop; - Another important updated to BC in parallel; - More implementation and clean up of the paralle,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:5645,update,update,5645,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,2,"['release', 'update']","['release', 'update']"
Deployability,"lux = 0.5*(phiL+phiR);. residual(iPoint,iVar) += flux;; residual(jPoint,iVar) -= flux;; }; }; }; ```; after vectorizing this to handle multiple edges simultaneously with the SIMD-friendly type the core of the loop becomes; ```c++; using FltVec = Array<double,SIMDLEN>;; ... FltVec d_ij[MAXNDIM];; for(size_t iDim=0; iDim<nDim; ++iDim); d_ij[iDim] = (coords.getVec(jPoint,iDim)-coords.getVec(iPoint,iDim))*0.5;. for(size_t iVar=0; iVar<nVar; ++iVar); {; FltVec phiL = 0.0;; FltVec phiR = 0.0;. for(size_t iDim=0; iDim<nDim; ++iDim); {; phiL += grad.getVec(iPoint,iVar,iDim)*d_ij[iDim];; phiR -= grad.getVec(jPoint,iVar,iDim)*d_ij[iDim];; }. phiL = phi.getVec(iPoint,iVar) + limiter.getVec(iPoint,iVar)*phiL;; phiR = phi.getVec(jPoint,iVar) + limiter.getVec(jPoint,iVar)*phiR;. FltVec flux = (phiL+phiR)*0.5;. for(size_t k=0; k<SIMDLEN; ++k) {; residual(iPoint[k],iVar) += flux[k];; residual(jPoint[k],iVar) -= flux[k];; }; }; ```; Note that at the end of the loop we need to de-swizzle the flux to update the multiple indexes references by iPoint and jPoint, which are now short arrays of integers (this operation can be moved to the container, akin to `getVec` but I show it here for clarity). **With SoA (aka column major storage) this code is 1.5 times slower than the scalar version.**. The reason for that is poor locality (of the spacial variety), as we loop through the number of variables and dimensions we are accessing the data in strides of nPoint, as the contiguous index is the first one so that we can perform vector read/writes when computing gradients and limiters.; With the scalar version the data for each point is contiguous which means on the first access we get whatever extra data is on the same cache line for free and subsequent accesses will be hardware prefetched since the stride is small (1 in this case). We lose all this with SoA storage. If we go back to arrays of structures (AoS, aka row major storage, basically what we have in #753) performance is only 9% worse (th",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-535977206:8006,update,update,8006,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206,1,['update'],['update']
Deployability,mall change; - Back to the previous version; - Fixed some loop variables.; - Merge branch 'develop' of https://github.com/su2code/SU2 into develop; - Bug fixes for CGNS.; - New slope limiter based on the wall distance; - Merge branch 'develop' of https://github.com/su2code/SU2 into develop; - Bug fixing; - Non-dimensional adjoint bc; - CGNS bug.; - Mixed-element support in new CGNS reader.; - Memory fix for mixed-element CGNS in parallel.; - Activated the parallel CGNS reader.; - New FFD input; - Adjacency building for Parmetis improve to account for VTK structure; - added if viscous steps to some adjeuler bcs; - Minor changes; - Back to previous version of ParMetis; - Small change; - Final update.; - Minor bug fixed.; - Updated SU2_DEF (cgns); - CGNS global element ID bug fix.; - Heat flux bug fix.; - Small fix.; - Merge branch 'master' into develop; - changed history output to match # of residuals printed in header and body; - further correction to history output; - history file fix; - fixed history output such that massflowrate can be output while in rans; - Removed Parmetis updates to adjacency; - Minor changes; - Merge branch 'develop' of https://github.com/su2code/SU2 into develop; - Bug fixing; - ver 3.2.8.3; - Updated CGNS in parallel.; - Added the ability to writting 2 files at each checkpoint when using 2nd order dual time stepping; - Merge branch 'develop' into feature_dualoutput; - Updated FieldView; - Preliminary implementation (ASCII); - Minor changes; - Update code; - Updated FieldView format; - Merge branch 'develop' into feature_dualoutput; - Bug fixing; - Updated FieldView ASCII format; - Complete implementation of the FFD_CONTINUITY capability; - Updated FFD intersections; - ver 3.2.9; - adding targetea file to equivalent area adjoint folder. address issue #160; - Merge branch 'develop' of github.com:su2code/SU2 into develop; - Final push to v3.2.9; - after bootstrap; - updates to comments in config_structure to make doxygen pretty; - Bug fixing; -,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:8051,update,updates,8051,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['update'],['updates']
Deployability,"ne BC; - Working on Engine BCs; - Added Supersonic Outlet BC; - Minor change; - Merge remote-tracking branch 'upstream/develop' into develop; - adjoints, solid boundary, doxygen in config; - continued fixing; - re-added adjoint bc mods; - re-adding avg outlet pressure (static pressure adjoint); - re-adding avg outlet pressure (static pressure adjoint); - Merge branch 'temp' of https://github.com/hlkline/SU2 into temp; - continued fixing; - average total pressure and fixes to avg outlet pressure; - adding stagnation pressure output to SU2_DOT; - Merge pull request #146 from hlkline/temp; - Updated Entropy fix (now it is active).; - Another change in BC_Engine_Exhaust; - Updated CGNS in parallel; - Added runtime file; - Small typo; - Adjustment of the Entropy fix coefficient; - Bug in SU2_GEO; - Debug version with print statements.; - Updated release 3.2.7.1; - Small change; - Updated config file; - Code update; - MPI Status and Request fix.; - Another MPI Status/Request fix.; - Actuator disk update.; - Small update; - Initial implementation of pyramids and prisms for Tecplot binary.; - Small fix for Tecplot binaries. Closes #56. Closes #57.; - Removed extra allocation related to markers during partitioning.; - Non-working version; - Small update; - Updated memory deallocation.; - Merge branch 'feature_MarkerMax' into develop; - Time and date in the header.; - Small fix to the latest commit.; - Simplification of entropy correction; - Critical stability improvement.; - Minor release 3.2.7.2; - Fixing issues to run with the latest intel compiler; - Fix for Tecplot binary solutions for unsteady flows. Fixes #150.; - Now SU2 should work with the latest version of the Intel compiler.; - Merge branch 'develop' of https://github.com/su2code/SU2 into develop; - Working on the O3 stuff; - Small change.; - Add another check to improve stability.; - Collection of improvements.; - Updated actuator disk; - Merge branch 'develop' of https://github.com/su2code/SU2 into develop; - Pre",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:4216,update,update,4216,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['update'],['update']
Deployability,"nectivity.second_vec(iEdge);. FltVec d_ij[MAXNDIM];; for(size_t iDim=0; iDim<nDim; ++iDim); d_ij[iDim] = (coords.getVec(jPoint,iDim)-coords.getVec(iPoint,iDim))*0.5;. FltVec phiL[MAXNVAR], phiR[MAXNVAR], flux[MAXNVAR],; blk_i[MAXNVAR*MAXNVAR],; blk_j[MAXNVAR*MAXNVAR];. for(size_t iVar=0; iVar<nVar; ++iVar); {; // Reconstruction goes here. flux[iVar] = (phiL[iVar]+phiR[iVar])*0.5;; }. // some silly way to make the Jacobians depend on the reconstruction; for(size_t iVar=0; iVar<nVar; ++iVar); for(size_t jVar=0; jVar<nVar; ++jVar); blk_j[iVar*nVar+jVar] = (phiL[iVar]*phiR[jVar]-phiL[jVar]*phiR[iVar])*0.5;. // the matrix-matrix multiplications; for(size_t i=0; i<WORKITERS; ++i) {; // blk_i = blk_j * blk_j; for(size_t k=0; k<nVar*nVar; ++k) blk_j[k] = blk_i[k];; }. // something akin to a dissipation term; for(size_t iVar=0; iVar<nVar; ++iVar) {; FltVec sum = flux[iVar];; for(size_t kVar=0; kVar<nVar; ++kVar); sum += blk_j[iVar*nVar+kVar]*(phiL[kVar]-phiR[kVar])*0.5;. // residuals for iPoint and jPoint updated here. matrix.updateBlocks_v(color, iEdge, iPoint, jPoint, blk_i, blk_j);; }; ++color;; }; }; ```; The more WORKITERS we have the better the vectorized code is going to look, I used a conservative number based on:; For the Roe scheme 4 matrices are generated (Jacobian i, Jacobian j, P tensor, P^-1 tensor), each coefficient of those matrices requires a reasonable number of floating point ops, and two of those matrices are indeed multiplied by each other.; So lets say 5 matrix-matrix multiplications are representative, this should be a conservative estimate as I am not considering the eventual fusion of convective and diffusive discretizations. **The vectorized code is 1.5 times faster.**; This is a fair 1.5 as the code is running on 4 fast cores (parallel via colouring for the reasons I explained previously) and 2 memory channels (scalar code can eventually saturate the memory bandwidth too, but it would take an unreasonable ratio of cores to channels to do so).; Furth",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-539177957:2242,update,updated,2242,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-539177957,1,['update'],['updated']
Deployability,"ng with Codi; * Enable modules:; * SU2_ENABLE_CGNS:; * SU2_CGNS_CPPFLAGS: flags to pass when compiling CGNS; * SU2_ENABLE_CODI: no|forward|reverse; * SU2_CODI_CPPFLAGS: flags to pass to SU2 modules when compiling with Codi; * SU2_ENABLE_METIS: ON|OFF; * SU2_METIS_CPPFLAGS: flags to pass when compiling Metis; * SU2_ENABLE_MKL: ON|OFF; * SU2_ENABLE_MPI: ON|OFF; * SU2_ENABLE_MUTATIONPP: ON|OFF; * SU2_ENABLE_PARMETIS: ON|OFF, only available when SU2_ENABLE_MPI is ON; * SU2_PARMETIS_CPPFLAGS: flags to pass when compiling Parmetis; * SU2_ENABLE_TECIO: ON|OFF; * SU2_TECIO_CPPFLAGS: flags to pass when compiling Tecio and TecioMPI; * SU2_TECIOMPI_CPPFLAGS: flags to pass when compiling TecioMPI, requires SU2_ENABLE_MPI. There is an additional variable that is recognized by CMake scripts - DEBUG, turning it ON enables additional STATUS messages, mainly to check that correct include directories, compile definitions and linked libraries were set up correctly. The remaining options like install location and compilers are handled by CMake. Tested this on Ubuntu with CMake 3.15.5 and everything except pySU2ad wrapper compiles. Haven't tested on earlier CMake versions so there might be bugs with them but they should be easy to resolve if any. Related Work. Resolve any issues (bug fix or feature request), note any related PRs, or mention interactions with the work of others, if any. PR Checklist. Put an X by all that apply. You can fill this out after submitting the PR. If you have any questions, don't hesitate to ask! We want to help. These are a guide for you to know what the reviewers will be looking for in your contribution. * I am submitting my contribution to the develop branch.; * My contribution generates no new compiler warnings (try with the '-Wall -Wextra -Wno-unused-parameter -Wno-empty-body' compiler flags).; * My contribution is commented and consistent with SU2 style.; * I have added a test case that demonstrates my contribution, if necessary. _________________________",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/814#issuecomment-552242380:3098,install,install,3098,https://su2code.github.io,https://github.com/su2code/SU2/pull/814#issuecomment-552242380,1,['install'],['install']
Deployability,ode/SU2 into develop; - Another important updated to BC in parallel; - More implementation and clean up of the parallel CGNS reader.; - Merge branch 'develop' of https://github.com/su2code/SU2 into develop; - CGNS reader bug fix.; - Updated adj. NS solver with primitive variables and farfield bc including viscous contribution.; - Merge branch 'develop' of https://github.com/su2code/SU2 into develop; - Small change; - Back to the previous version; - Fixed some loop variables.; - Merge branch 'develop' of https://github.com/su2code/SU2 into develop; - Bug fixes for CGNS.; - New slope limiter based on the wall distance; - Merge branch 'develop' of https://github.com/su2code/SU2 into develop; - Bug fixing; - Non-dimensional adjoint bc; - CGNS bug.; - Mixed-element support in new CGNS reader.; - Memory fix for mixed-element CGNS in parallel.; - Activated the parallel CGNS reader.; - New FFD input; - Adjacency building for Parmetis improve to account for VTK structure; - added if viscous steps to some adjeuler bcs; - Minor changes; - Back to previous version of ParMetis; - Small change; - Final update.; - Minor bug fixed.; - Updated SU2_DEF (cgns); - CGNS global element ID bug fix.; - Heat flux bug fix.; - Small fix.; - Merge branch 'master' into develop; - changed history output to match # of residuals printed in header and body; - further correction to history output; - history file fix; - fixed history output such that massflowrate can be output while in rans; - Removed Parmetis updates to adjacency; - Minor changes; - Merge branch 'develop' of https://github.com/su2code/SU2 into develop; - Bug fixing; - ver 3.2.8.3; - Updated CGNS in parallel.; - Added the ability to writting 2 files at each checkpoint when using 2nd order dual time stepping; - Merge branch 'develop' into feature_dualoutput; - Updated FieldView; - Preliminary implementation (ASCII); - Minor changes; - Update code; - Updated FieldView format; - Merge branch 'develop' into feature_dualoutput; - Bug fixi,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:7656,update,update,7656,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['update'],['update']
Deployability,"ogramming may become an entrance barrier to new additions to the community. As I wrote in the preamble of #789:; ""But please participate even if you never heard of these topics, your opinion about readability and ""developability"" of the code is important! I think the code-style should be accessible to people starting a PhD (after they read a bit about C++...).""; I try to encapsulate and hide the tricky bits as much as possible to make the code as readable as possible, whether I am succeeding or not is for the community to decide, in all these PR's I've been pointing to the areas I think are trickier, if someone, anyone, feels they are absolutely incomprehensible please say something... either here, or trough slack, or by email (I think it shows in the commits) (I understand not everyone is keen on github exposure). > I'm aware that you have been doing very well at documenting the code and the various PRs, but I'd say we should try to find an strategy to ease the learning curve on potential new developers (maybe some developer tutorials? a collection of the comments/discussions on the PRs moved to the wiki? a list of links/useful resources?). I agree with documentation of broad design decisions, that is the intent of #789, and developer tutorials (how to implement a new X) once we are content with the restructurings, otherwise they will quickly go outdated... or actually...; We should probably first think about the answers to ""how to implement a new X"" and restructure/refactor as a function of that.; Based on previous efforts of maintaining wiki's updated while code is being developed, I much prefer this github style where you can clearly tell what version of the code the comments refer to. A collection of comments/discussions organized by topic and linked to a feature is somewhat what I had in mind when I opened a ""big PR"" (#824) with little branches such as this one, I can try to complete that with a list of links/useful resources, references as it were, good idea!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/843#issuecomment-577684728:5176,update,updated,5176,https://su2code.github.io,https://github.com/su2code/SU2/pull/843#issuecomment-577684728,1,['update'],['updated']
Deployability,"opt/xcat/sbin; PATH: /usr/lib64/qt-3.3/bin; PATH: /opt/pbs/default/bin; PATH: /opt/pbs/tools/bin; PATH: /usr/lpp/mmfs/bin/; PATH: /usr/local/bin; PATH: /bin; PATH: /usr/bin; PATH: /usr/local/sbin; PATH: /usr/sbin; PATH: /sbin; PATH: /gshare/soft/init; PATH: /gshare/soft/scripts; PATH: .; PATH: /gshare/soft/init; PATH: /gshare/soft/scripts; PATH: . ## ----------- ##; ## Core tests. ##; ## ----------- ##. configure:2465: checking build system type; configure:2479: result: x86_64-unknown-linux-gnu; configure:2499: checking host system type; configure:2512: result: x86_64-unknown-linux-gnu; configure:2532: checking target system type; configure:2545: result: x86_64-unknown-linux-gnu; configure:2587: checking for a BSD-compatible install; configure:2655: result: /usr/bin/install -c; configure:2666: checking whether build environment is sane; configure:2721: result: yes; configure:2872: checking for a thread-safe mkdir -p; configure:2911: result: /bin/mkdir -p; configure:2918: checking for gawk; configure:2934: found /bin/gawk; configure:2945: result: gawk; configure:2956: checking whether make sets $(MAKE); configure:2978: result: yes; configure:3075: checking whether make supports nested variables; configure:3092: result: yes; configure:3117: checking for style of include used by make; configure:3145: result: GNU; configure:3196: result: >>> MPI support disabled by default <<<; configure:3269: checking for g++; configure:3285: found /usr/bin/g++; configure:3296: result: g++; configure:3323: checking for C++ compiler version; configure:3332: g++ --version >&5; g++ (GCC) 4.4.6 20120305 (Red Hat 4.4.6-4); Copyright (C) 2010 Free Software Foundation, Inc.; This is free software; see the source for copying conditions. There is NO; warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. configure:3343: $? = 0; configure:3332: g++ -v >&5; Using built-in specs.; Target: x86_64-redhat-linux; Configured with: ../configure --prefix=/usr --mandir=/usr/share/man ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:1919,install,install,1919,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,2,['install'],['install']
Deployability,"ork; > on our branch, which we're happy with. Some choices were arbitrary, and; > some choices were made based on our development environment. Those choices; > may be different for other groups. Here's what we have done:; >; > The unit testing framework is compiled and run using autotools. For more; > information on autotool's setup, see their documentation; > <https://www.gnu.org/software/automake/manual/html_node/Tests.html>.; > Since autotools is the build system for SU2, this involves minimal changes.; >; > Using automake, the build process for building unit tests becomes:; >; > '''; > ./bootstrap; > ./configure; > make; > make check; > '''; >; > We use Boost's unit testing framework; > <https://www.boost.org/doc/libs/1_70_0/libs/test/doc/html/index.html>.; > This provides a convenient set of macros for instatiating tests, grouping; > tests into suites, and running checks. This choice was based on what is; > available in our development setup.; >; > We have integrated our unit tests into our Travis CI regression testing.; > Every time we push commits or submit a pull request, the unit tests are run; > and checked.; > What is my vision for unit testing in SU2?; >; > I am *not* proposing that we start trying to get 100% code coverage with; > pre-existing code. That would not provide a good return on investment.; >; > Instead, I see people adding unit tests as they write new code and as they; > find bugs. For each new behavior added to SU2, tests are first added to; > document the related existing behavior. These tests serve to check that the; > existing behavior isn't damaged by the new code. Then new tests are added; > to prove that the new behavior is working correctly. For bug fixes, the; > process is simpler. A test is added to confirm that something is not; > behaving as expected. Then the code is fixed to make the test pass.; > What frameworks are available?; >; > For a unit testing framework, here are the most popular options, with the; > following pros and ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499278427:4538,integrat,integrated,4538,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427,1,['integrat'],['integrated']
Deployability,"output classes, we should find a common level of abstraction for all the different physical problems we might want to have. Right now there isn't even a unified way of specifying the kind of problem for each zone (what is fluid, what is solid etc) and the kind of coupling. This might also affect the actual implementation/restructuring since we somehow have to decide what driver we have to instantiate and so on. Hopefully we can gather all the people involved to have a discussion on that. Since we have a lot of people working in their branches on multizone problems we should tackle that better sooner than later. As Edwin already suggested, maybe it is a good idea to put some people in charge of organizing some of the bigger structural changes. Furthermore in case some people don't know, we have a slack channel for the dev team. I think that makes it easier to communicate, arrange meetings, discuss problems and ask questions. In case you need an invite, let me know, everybody who wants to contribute is welcome. Thanks for the discussion, I still think that communication is the key of success !. Tim. On Sep 13, 2017 10:30 AM, Edwin van der Weide <notifications@github.com> wrote:. Hi Tom,. Sounds like a plan then to have a look at CIntegration to see what we can do to generalize the time integration. I definitely want to help with this, but I don't think I am the appropriate person to take the lead, because I simply don't have a good overview of all the multi-physics options. Tom, are you willing to take the lead for this?. Furthermore, it is good to have other people involved as well, preferably with detailed knowledge of the different disciplines. Any volunteers?. Thanks,. Edwin. —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/437#issuecomment-329096830>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AEtI5MkXdqhqPPMuaDziLuDRzWCJfYwrks5sh5KagaJpZM4PQ90s>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/437#issuecomment-329146567:1347,integrat,integration,1347,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-329146567,1,['integrat'],['integration']
Deployability,pressure (static pressure adjoint); - re-adding avg outlet pressure (static pressure adjoint); - Merge branch 'temp' of https://github.com/hlkline/SU2 into temp; - continued fixing; - average total pressure and fixes to avg outlet pressure; - adding stagnation pressure output to SU2_DOT; - Merge pull request #146 from hlkline/temp; - Updated Entropy fix (now it is active).; - Another change in BC_Engine_Exhaust; - Updated CGNS in parallel; - Added runtime file; - Small typo; - Adjustment of the Entropy fix coefficient; - Bug in SU2_GEO; - Debug version with print statements.; - Updated release 3.2.7.1; - Small change; - Updated config file; - Code update; - MPI Status and Request fix.; - Another MPI Status/Request fix.; - Actuator disk update.; - Small update; - Initial implementation of pyramids and prisms for Tecplot binary.; - Small fix for Tecplot binaries. Closes #56. Closes #57.; - Removed extra allocation related to markers during partitioning.; - Non-working version; - Small update; - Updated memory deallocation.; - Merge branch 'feature_MarkerMax' into develop; - Time and date in the header.; - Small fix to the latest commit.; - Simplification of entropy correction; - Critical stability improvement.; - Minor release 3.2.7.2; - Fixing issues to run with the latest intel compiler; - Fix for Tecplot binary solutions for unsteady flows. Fixes #150.; - Now SU2 should work with the latest version of the Intel compiler.; - Merge branch 'develop' of https://github.com/su2code/SU2 into develop; - Working on the O3 stuff; - Small change.; - Add another check to improve stability.; - Collection of improvements.; - Updated actuator disk; - Merge branch 'develop' of https://github.com/su2code/SU2 into develop; - Preliminary implementation of the Neg SA; - Minor updates; - Preliminary implementation of the Negative SA; - Bug fixing; - Fixed memory issued for very large meshes with ParMETIS.; - Clear evaluation of Vorticity and StrainMag; - Viscous limiter; - Updated RELAX,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:4468,update,update,4468,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['update'],['update']
Deployability,prisms for Tecplot binary.; - Small fix for Tecplot binaries. Closes #56. Closes #57.; - Removed extra allocation related to markers during partitioning.; - Non-working version; - Small update; - Updated memory deallocation.; - Merge branch 'feature_MarkerMax' into develop; - Time and date in the header.; - Small fix to the latest commit.; - Simplification of entropy correction; - Critical stability improvement.; - Minor release 3.2.7.2; - Fixing issues to run with the latest intel compiler; - Fix for Tecplot binary solutions for unsteady flows. Fixes #150.; - Now SU2 should work with the latest version of the Intel compiler.; - Merge branch 'develop' of https://github.com/su2code/SU2 into develop; - Working on the O3 stuff; - Small change.; - Add another check to improve stability.; - Collection of improvements.; - Updated actuator disk; - Merge branch 'develop' of https://github.com/su2code/SU2 into develop; - Preliminary implementation of the Neg SA; - Minor updates; - Preliminary implementation of the Negative SA; - Bug fixing; - Fixed memory issued for very large meshes with ParMETIS.; - Clear evaluation of Vorticity and StrainMag; - Viscous limiter; - Updated RELAXATION_FACTOR; - RANS MG; - Partial fix to no MPI output; - Updated I/O; - Updated Adapt CFL; - Updated Adaptive CFL number; - Release 3.2.8; - Updated SetCFL_Number; - Small update; - Small change; - Small adjustments; - Minor changes; - Updated release 3.2.8; - MPI disabled by default in build. Added --enable-mpi flag to configure.; - Merged the ParMETIS implementation. Updated the build files.; - bootstrap; - Started parallel CGNS reader.; - Memory fix.; - Minor change; - Merge branch 'develop' of https://github.com/su2code/SU2 into develop; - Updated binaries; - Small change to configure.ac. Bootstrap.; - Small change; - Cleaning the code; - Updated grid deformation subroutine; - Fixing the mesh deformation; - Updated SU2_MSH; - Bug fixing; - Initial implementation of parallel CGNS reader. Works o,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:5258,update,updates,5258,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['update'],['updates']
Deployability,"process is very helpful and cmake is definitely becoming a standard. Best,. Juan. On Nov 10, 2019, at 11:24 AM, Daumantas Kavolis <notifications@github.com> wrote:. ﻿; Proposed Changes. Added CMake build support for SU2. With this, many popular IDEs will be able to use SU2 as a project with minimal setup. CMake also enables to add dependencies more easily since most libraries have CMake support. vcpkg is great for the libraries available there. SU2 CMake has the same build options as autotools but uses CMake to find system libraries and compilers (MKL, Mutationpp, MPI and Python currently). No longer need to specify paths to compilers/libraries if they are in standard locations. In addition, compile flags can be modified from CMake. There is no need to use preconfigure.py anymore since downloading/unpacking is handled by CMake and is system-agnostic. At the moment, all library targets are static but that could be easily changed to be configurable from CMake. The installation directory is ${CMAKE_PREFIX_PATH}/bin. Similarly to autotools, some build options are disabled if built with Codi forward/reverse datatypes or without MPI. Note that SWIG fails to compile pySU2ad with Nothing known about namespace 'medi' in Common/include/mpi_structure.hpp:57 without -includeall SWIG option but then it takes forever to generate the wrapper (more than 15 minutes on my machine, stopped early). I suggest removing using namespace declarations and either importing used symbols explicitly with using or prepending namespace name, clang-tidy warns against them by default and it makes the code clearer. SU2 CMake options are:. * Build modules:; * SU2_BUILD_CFD: ON|OFF; * SU2_BUILD_DEF: ON|OFF, disabled when building with Codi; * SU2_BUILD_DOT: ON|OFF, disabled when building with Codi forward; * SU2_BUILD_GEO: ON|OFF, disabled when building with Codi; * SU2_BUILD_MSH: ON|OFF, disabled when building with Codi; * SU2_BUILD_PY_WRAPPER: ON|OFF, disabled when building with Codi forward; * SU2_B",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/814#issuecomment-552242380:1049,install,installation,1049,https://su2code.github.io,https://github.com/su2code/SU2/pull/814#issuecomment-552242380,1,['install'],['installation']
Deployability,"r a 3D problem) but I can get that back by sharing sparsity patterns and maps across turbulence and bulk flow (I think @talbring was already working on this in the template linear solver branch he had started). We could also parallelize the matrix updates without colouring by setting only the off-diagonal coefficients and then setting the diagonal entries to the column sum.; It turns out that this is worse (by about 10%), maybe if the matrix were symmetric (row sum) but a column sum accesses blocks very far apart. Also we want to interleave compute and load/stores as much as possible to allow the CPU pipelining magic to mask the latency of the latter (even if it looks like you can only write the block after it is computed, CPU's have all kinds of buffers that allow the next loop iteration to begin while data is in flight). **Therefore colouring is the way to go.**. _Note: With vectorized numerics we insert blocks for 4 or 8 edges into the matrix at a time, the data for those inserts will be in a slightly weird format, which will make `SparseMatrix::updateBlocks` a bit harder on the eye, more on that later._. ## MUSCL Reconstruction; The MUSCL reconstruction, characteristic of upwind schemes, is the simplest building block to show the (negative) implications of storing the data as structures of arrays (SoA) on the performance of some operations.; Here is the most basic numerics you can think of, reconstruct and average (the dummy matrix loop was to benchmark the writes this is to benchmark the reads); ```c++; void computeResidual(size_t nVar,; size_t nDim,; const vector<size_t>& colorStart,; const vector<size_t>& edgeIdx,; const vector<pair<size_t,size_t> >& connectivity,; const Matrix& coords,; const Matrix& phi,; const VectorOfMatrix& grad,; const Matrix& limiter,; Matrix& residual); {; residual.setZero();. for(size_t color=0; color<colorStart.size()-1; ++color); #pragma omp parallel for schedule(dynamic,CHUNK_SIZE); for(size_t k=colorStart[color]; k<colorStart[col",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-535977206:5527,update,updateBlocks,5527,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206,1,['update'],['updateBlocks']
Deployability,re; - adding stagnation pressure output to SU2_DOT; - Merge pull request #146 from hlkline/temp; - Updated Entropy fix (now it is active).; - Another change in BC_Engine_Exhaust; - Updated CGNS in parallel; - Added runtime file; - Small typo; - Adjustment of the Entropy fix coefficient; - Bug in SU2_GEO; - Debug version with print statements.; - Updated release 3.2.7.1; - Small change; - Updated config file; - Code update; - MPI Status and Request fix.; - Another MPI Status/Request fix.; - Actuator disk update.; - Small update; - Initial implementation of pyramids and prisms for Tecplot binary.; - Small fix for Tecplot binaries. Closes #56. Closes #57.; - Removed extra allocation related to markers during partitioning.; - Non-working version; - Small update; - Updated memory deallocation.; - Merge branch 'feature_MarkerMax' into develop; - Time and date in the header.; - Small fix to the latest commit.; - Simplification of entropy correction; - Critical stability improvement.; - Minor release 3.2.7.2; - Fixing issues to run with the latest intel compiler; - Fix for Tecplot binary solutions for unsteady flows. Fixes #150.; - Now SU2 should work with the latest version of the Intel compiler.; - Merge branch 'develop' of https://github.com/su2code/SU2 into develop; - Working on the O3 stuff; - Small change.; - Add another check to improve stability.; - Collection of improvements.; - Updated actuator disk; - Merge branch 'develop' of https://github.com/su2code/SU2 into develop; - Preliminary implementation of the Neg SA; - Minor updates; - Preliminary implementation of the Negative SA; - Bug fixing; - Fixed memory issued for very large meshes with ParMETIS.; - Clear evaluation of Vorticity and StrainMag; - Viscous limiter; - Updated RELAXATION_FACTOR; - RANS MG; - Partial fix to no MPI output; - Updated I/O; - Updated Adapt CFL; - Updated Adaptive CFL number; - Release 3.2.8; - Updated SetCFL_Number; - Small update; - Small change; - Small adjustments; - Minor changes; ,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:4707,release,release,4707,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['release'],['release']
Deployability,"research group at UT Austing has implemented a unit testing framework on our branch, which we're happy with. Some choices were arbitrary, and some choices were made based on our development environment. Those choices may be different for other groups. Here's what we have done:. The unit testing framework is compiled and run using autotools. For more information on autotool's setup, see their documentation<https://www.gnu.org/software/automake/manual/html_node/Tests.html>. Since autotools is the build system for SU2, this involves minimal changes. Using automake, the build process for building unit tests becomes:. '''; ./bootstrap; ./configure; make; make check; '''. We use Boost's unit testing framework<https://www.boost.org/doc/libs/1_70_0/libs/test/doc/html/index.html>. This provides a convenient set of macros for instatiating tests, grouping tests into suites, and running checks. This choice was based on what is available in our development setup. We have integrated our unit tests into our Travis CI regression testing. Every time we push commits or submit a pull request, the unit tests are run and checked. What is my vision for unit testing in SU2?. I am not proposing that we start trying to get 100% code coverage with pre-existing code. That would not provide a good return on investment. Instead, I see people adding unit tests as they write new code and as they find bugs. For each new behavior added to SU2, tests are first added to document the related existing behavior. These tests serve to check that the existing behavior isn't damaged by the new code. Then new tests are added to prove that the new behavior is working correctly. For bug fixes, the process is simpler. A test is added to confirm that something is not behaving as expected. Then the code is fixed to make the test pass. What frameworks are available?. For a unit testing framework, here are the most popular options, with the following pros and cons:. Roll-your-own. * Requires no external dependencies",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499250240:3388,integrat,integrated,3388,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240,1,['integrat'],['integrated']
Deployability,"tter cannot be avoided. ### Intro to SPMD; This one is simpler, in a nutshell multiple threads operate on the sub domain of an MPI rank.; The typical implementation has each thread executing a chunk of an edge or cell loop. **Why should we care about SPMD?**; Reduce the communication overhead resulting from domain decomposition and improve load balancing, important for strong scaling.; Some algorithms are more efficient that way, e.g. the ADT (as mentioned by Edwin), the current MG also seems to work better on fewer partitions, and additive versions of preconditioners like the ILU or LU-SGS lose effectiveness with number of partitions.; Optimum hardware utilization, for routines that are bandwidth-bound it may be beneficial to use all threads available, while for compute-bound or ""algorithm-bound"" ones this may not be the case. **Relation with algorithms**; A typical edge loop reads from 2 locations and writes to 2 locations (gather / scatter access pattern, not to be confused with the instructions) processing multiple edges at the same time can therefore result in race conditions where multiple threads try to update the data of the same point.; There are 3 ways to address this:; - **Coloring**: Edges are colored (grouped) such that edges of the same color have no risk of race conditions, i.e. each endpoint is referenced only once per color (this definition gives you the basis of a greedy algorithm to color edges).; - **Scatter to gather transformations**: Edge quantities (e.g. fluxes) are computed and stored on one pass (i.e. we read from 2 locations and write to 1), on a second pass, over points, we reduce (e.g. sum) the edge quantities for each point, again a gather access pattern. It may also be possible to convert the entire algorithm to a loop over points instead of edges.; - **Atomic operations or locks**: Here when a thread wants to write to a memory location it either needs to do so atomically (this is essentially an operations that always goes through main ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-529662724:3961,update,update,3961,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-529662724,1,['update'],['update']
Deployability,"uch lower level, namely where the spatial residual is computed. At least, this should be the case for the fluid dynamics part. I don't know whether this is also the case for other disciplines, like structures. What about the following high level structure?. - Loop over the number of iterations, or time steps for unsteady problems.; - Loop over the number of pseudo-time steps for implicit time integration schemes; (DT_STEPPING_1ST and DT_STEPPING_2ND). For other cases this loop is 1.; - Loop over the number of disciplines involved; Call iterate for each of the disciplines.; In iterate: ; - Loop over the (Runge-Kutta) stages; - Loop over the zones of a single discipline; Compute spatial residual.; Update the state vector.; - End loop over the zones of a single discipline.; Exchange halo data. This includes the halo data between zones of a single discipline.; - End loop over the (Runge-Kutta) stages ; - End loop over the disciplines; - End loop over the pseudo time steps.; - End loop over the number of iterations, or time steps for unsteady problems. The weakness of this approach is that it still does not work when one would like to employ multi-stage time integration schemes for an unsteady, multi-disciplinary problem (does not work for the current implementation either), but maybe this is something we simply have to accept. The alternative is that all the details of the different time integration schemes have to be moved to the driver classes, which is highly undesirable, I think. The structure above implies that the iteration_container and the integration_container should be defined per discipline and not per zone anymore. The geometry_container and solver_container should still be defined per zone. Well, I suppose this leaves plenty of room for discussion, so I would say to continue the online discussion a bit further, such that things become a bit clearer how to tackle this issue. After that having a telecon would be good to iron out the details. . Regards,. Edwin",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/437#issuecomment-328368371:1516,integrat,integration,1516,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328368371,2,['integrat'],['integration']
Deployability,"uctures. What about the following high level structure?. * Loop over the number of iterations, or time steps for unsteady problems.; * Loop over the number of pseudo-time steps for implicit time integration schemes; (DT_STEPPING_1ST and DT_STEPPING_2ND). For other cases this loop is 1.; * Loop over the number of disciplines involved; Call iterate for each of the disciplines.; In iterate:; * Loop over the (Runge-Kutta) stages; * Loop over the zones of a single discipline; Compute spatial residual.; Update the state vector.; * End loop over the zones of a single discipline.; Exchange halo data. This includes the halo data between zones of a single discipline.; * End loop over the (Runge-Kutta) stages; * End loop over the disciplines; * End loop over the pseudo time steps.; * End loop over the number of iterations, or time steps for unsteady problems. The weakness of this approach is that it still does not work when one would like to employ multi-stage time integration schemes for an unsteady, multi-disciplinary problem (does not work for the current implementation either), but maybe this is something we simply have to accept. The alternative is that all the details of the different time integration schemes have to be moved to the driver classes, which is highly undesirable, I think. The structure above implies that the iteration_container and the integration_container should be defined per discipline and not per zone anymore. The geometry_container and solver_container should still be defined per zone. Well, I suppose this leaves plenty of room for discussion, so I would say to continue the online discussion a bit further, such that things become a bit clearer how to tackle this issue. After that having a telecon would be good to iron out the details. Regards,. Edwin. —; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/437#issuecomment-328368371>, or mute the thread<",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/437#issuecomment-328403160:3025,integrat,integration,3025,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328403160,1,['integrat'],['integration']
Deployability,"went silent for a bit because in prototyping a typical residual computation and matrix update loop I made some realisations that made me go back to the drawing board regarding data structures, and eventually back to square 0. . ## Parallel strategy for flux computation; Because significant computation is required to obtain each edge's flux, it does not make sense to attempt a ""point-loop"" strategy (which would double the effort).; However, one can either use colouring to avoid the race conditions that would result from updating the residual of cells i and j, or store the edge fluxes and then, on a second point-loop perform the summation of fluxes for each cell, with the direction being accounted by the same adjacency information used in the point-loop GG gradient computation.; If we consider only the update of residuals the two strategies are fairly equivalent performance wise, the tie breaker is the matrix updates. ## Matrix Updates; By this I mean the `addBlock`, `subBlock` we do (two times each) to update diagonal and off-diagonal blocks for each edge.; Here is a dummy numerics loop that does nothing else but setting blocks in the matrix (with colouring).; ```c++; void testLoop1(const vector<size_t>& colorStart,; const vector<size_t>& edgeIdx,; const vector<pair<size_t,size_t> >& connectivity,; double** blk_i, double** blk_j,; SparseMatrix& matrix); {; matrix.setZero();. for(size_t color=0; color<colorStart.size()-1; ++color); #pragma omp parallel for schedule(dynamic,CHUNK_SIZE); for(size_t k=colorStart[color]; k<colorStart[color+1]; ++k); {; size_t iEdge = edgeIdx[k];; size_t iPoint = connectivity[iEdge].first;; size_t jPoint = connectivity[iEdge].second;. matrix.addBlock(iPoint, iPoint, blk_i);; matrix.addBlock(iPoint, jPoint, blk_j);. matrix.subBlock(jPoint, jPoint, blk_j);; matrix.subBlock(jPoint, iPoint, blk_i);; }; }; ```; This and a few more memory reads is why we can't have nice things, i.e. massive speedups with vectorization. Believe it or not this loo",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-535977206:1365,update,update,1365,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206,1,['update'],['update']
Deployability,"when you've installed python packages in two different locations. This could be due to installing some python packages in a system directory (e.g. `/usr/lib/`) and some in a user directory (e.g. `~/.local/`). SU2's build process is set to automatically detect the default package location, but it's not equipped to handle multiple package locations. There are some hardcoded includes, but these only work for python 2.7. I don't consider this a bug *per se* because multiple python package directories is not a standard use case. #### The symptoms. When building SU2 with the python wrapper you'll see the following error during the swig build:; ```; <install directory>/../SU2_PY/pySU2/pySU2.i:64: Error: Unable to find 'mpi4py/mpi4py.i'; ```; But mpi4py is indeed installed on your system and it's on your python path, as confirmed by opening a python terminal and running `import mpi4py`. #### The easiest workaround. Switch to a [virtualenv](https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/). This will ensure that all of your python packages are stored in single location. #### Alternate workaround. In this method, you change the hardcoded includes to match mpi4py's package location. First I figure out where my mpi4py is installed. I start a terminal session of python using the python environment I want to use (in this case, it's python 3.6), and then run:; ```; from mpi4py import MPI; MPI; ```. Since I have mpi4py installed on your system and it's on my python path, I see something like:; ```; <module 'mpi4py.MPI' from '/home/clarkpede/.local/lib/python3.6/site-packages/mpi4py/MPI.cpython-34m.so'>; ```. The `/home/clarkpede/.local/lib/python3.6/` directory is where my mpi4py package is installed. But the swig compile command includes `/home/clarkpede/.local/lib/python2.7/`. That's not the right directory! So first I find the hardcoded paths of the makefile by running (on a bash terminal):; ```; grep -rn python2\.7 SU2_PY/ ; ```; On my system, t",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/722#issuecomment-515693590:1112,install,installing-using-pip-and-virtual-environments,1112,https://su2code.github.io,https://github.com/su2code/SU2/issues/722#issuecomment-515693590,1,['install'],['installing-using-pip-and-virtual-environments']
Deployability,xcbkptlist (0) ; - I SU2_IDE/Xcode/SU2_CFD.xcodeproj/xcuserdata/fpalacios.xcuserdatad/xcschemes/SU2_CFD.xcscheme (0) ; - I SU2_IDE/Xcode/SU2_DEF.xcodeproj/project.pbxproj (0) ; - I SU2_IDE/Xcode/SU2_DOT.xcodeproj/project.xcworkspace/xcshareddata/SU2_DOT.xccheckout (0) ; - I SU2_IDE/Xcode/SU2_GEO.xcodeproj/project.xcworkspace/xcshareddata/SU2_GEO.xccheckout (0) ; - I SU2_IDE/Xcode/SU2_MSH.xcodeproj/project.pbxproj (0) ; - D SU2_IDE/Xcode/SU2_PRT.xcodeproj/fpalacios.mode1v3 (0) ; - D SU2_IDE/Xcode/SU2_PRT.xcodeproj/fpalacios.pbxuser (0) ; - D SU2_IDE/Xcode/SU2_PRT.xcodeproj/project.pbxproj (0) ; - D SU2_IDE/Xcode/SU2_PRT.xcodeproj/project.xcworkspace/contents.xcworkspacedata (0) ; - D SU2_IDE/Xcode/SU2_PRT.xcodeproj/project.xcworkspace/xcshareddata/SU2_DDC.xccheckout (0) ; - I SU2_IDE/Xcode/SU2_SOL.xcodeproj/project.pbxproj (0) ; - I SU2_IDE/Xcode/SU2_SOL.xcodeproj/xcuserdata/fpalacios.xcuserdatad/xcschemes/SU2_SOL.xcscheme (0) ; - I SU2_MSH/include/SU2_MSH.hpp (0) ; - I SU2_MSH/obj/Makefile.am (0) ; - I SU2_MSH/obj/Makefile.in (0) ; - I SU2_MSH/src/SU2_MSH.cpp (0) ; - D SU2_PRT/bin/.gitignore (0) ; - D SU2_PRT/include/SU2_PRT.hpp (0) ; - D SU2_PRT/obj/Makefile.am (0) ; - I SU2_PRT/obj/Makefile.in (0) ; - D SU2_PRT/src/SU2_PRT.cpp (0) ; - D SU2_PY/2DChannel.py (0) ; - D SU2_PY/3DChannel.py (0) ; - I SU2_PY/Makefile.am (0) ; - I SU2_PY/Makefile.in (0) ; - I SU2_PY/SU2/**init**.py (0) ; - I SU2_PY/SU2/eval/design.py (0) ; - I SU2_PY/SU2/eval/functions.py (0) ; - I SU2_PY/SU2/eval/gradients.py (0) ; - I SU2_PY/SU2/io/config.py (0) ; - I SU2_PY/SU2/io/config_options.py (0) ; - I SU2_PY/SU2/io/data.py (0) ; - I SU2_PY/SU2/io/filelock.py (0) ; - I SU2_PY/SU2/io/redirect.py (0) ; - I SU2_PY/SU2/io/state.py (0) ; - I SU2_PY/SU2/io/tools.py (0) ; - I SU2_PY/SU2/mesh/adapt.py (0) ; - I SU2_PY/SU2/mesh/tools.py (0) . Patch Links:; - https://github.com/su2code/SU2/pull/174.patch; - https://github.com/su2code/SU2/pull/174.diff; —; Reply to this email directly or view it on GitHub.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:27733,patch,patch,27733,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['patch'],['patch']
Energy Efficiency," are first added to; > document the related existing behavior. These tests serve to check that the; > existing behavior isn't damaged by the new code. Then new tests are added; > to prove that the new behavior is working correctly. For bug fixes, the; > process is simpler. A test is added to confirm that something is not; > behaving as expected. Then the code is fixed to make the test pass.; > What frameworks are available?; >; > For a unit testing framework, here are the most popular options, with the; > following pros and cons:; > Roll-your-own; >; > - Requires no external dependencies; > - The most flexible option; > - Involves the most work to setup; > - Will lack some of the more advances features of mature unit-testing; > frameworks.; >; > Boost Test; >; > - Can be header only, statically linked, or dynamically linked; > - If statically or dynamically linked, then Boost is not very; > lightweight; > - Easy to add if you're already using Boost; >; > Google Test; >; > - Most common unit-testing framework; > - Can be easily combined with Google's powerful GMock mocking library; > - Compiling and linking can be somewhat painful; >; > Catch2; >; > - Used by FEniCS; > - Makes unit tests easily readable with lots of syntactic sugar.; > - Has a very simple syntax; > - Is header-only; > - Requires C++11 compilation; > - Not as feature rich as Google Test or Boost Test; >; > Questions; >; > - How do developers feel about adding unit tests to SU2?; > - If a unit-testing framework were added to SU2, would you actually; > use it?; > - Do developers have a preference (or experience with) any of the unit; > testing frameworks?; > - Should unit tests be expected when submitting PRs?; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/issues/698?email_source=notifications&email_token=AA5FFRG5U3Z55N4W2XWQED3PY3LJ5A5CNFSM4HTDQXQKYY3PNVWWK3TUL52HS4DFUVEXG43VMWVGG33NNVSW4",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499278427:6099,power,powerful,6099,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427,1,['power'],['powerful']
Energy Efficiency," case, we would have something along the lines of: . a) NACA0012; i) 113 x 33; ii) 225 x 65 ; iii) 449 x 129; iv) ... This way we have a family of meshes and configuration files that are specifically built for the purpose of validating the code and comparing with other solvers. I might be useful to compress meshes that are larger than a certain size (say 10MB). We should also put a limit on the size of a single mesh that the repository can handle (say 50MB?). . Within the home directory, the README file should list all the cases in the repository, who the custodian of the test case is (person with meshes in case the meshes are too large), and which version it was last run on. . I thought about splitting it up into Verification cases and Validation cases, but I thought it would be more informative and intuitive to split up according to the physics of the simulations. My thinking might be limited because that's how I have seen the TestCases folder organized, so any other suggestions are welcome. I think it is imperative that this is accompanied with a section on the SU2 website that showcases just the results of the validation test cases (grid convergence studies, residual reductions etc) and links to the v&v repo appropriately. This way, if people are just inquisitive about SU2's performance, they can get a quick snapshot of the results, without the need to run the cases themselves. . I also wanted to broach the topic of convergence here. Would it be a good idea to standardize the termination criteria wherever possible? For example, in the NACA0012 case we can ensure that residuals are reduced by 8 orders of magnitude for all meshes. Or for the ONERAM6, we use Cauchy convergence and make sure the C_L is converged to 6 orders of magnitude. This would have to be flexible since the same level of convergence might not apply to all the cases in the repository. But for within a test case, I think it would be good to use the same convergence criteria for a family of meshes.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/581#issuecomment-426026053:2237,reduce,reduced,2237,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-426026053,1,['reduce'],['reduced']
Energy Efficiency,") = min(limiter(jPoint,iVar), lim_j[iVar]);; }; }. #pragma omp parallel for schedule(dynamic,TARGET_CHUNK_SIZE); for(size_t iPoint=0; iPoint<nPoint; ++iPoint); {; #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); {; double lim = limiter(iPoint,iVar);; limiter(iPoint,iVar) = lim*(lim+2)/(lim*lim+lim+2);; }; }; }; ```; Again to keep things short here is the parallel and SIMD point-loop version (like for gradients it is very similar to the scalar and sequential version).; ```C++; void computeLimiters(size_t nPoint,; size_t nVar,; size_t nDim,; const Adjacency<4>& adj,; const Matrix& coords,; const Matrix& phi,; const VectorOfMatrix& grad,; Matrix& limiter); {; const size_t SIMDLEN = 4;; using FltVec = Array<double,SIMDLEN>;. // working variables; FltVec phiMax[MAXNVAR], phiMin[MAXNVAR], prjMax[MAXNVAR], prjMin[MAXNVAR];. const double eps = numeric_limits<double>::epsilon();. #pragma omp parallel for schedule(dynamic,128) private(phiMax,phiMin,prjMax,prjMin); for(size_t iPoint=0; iPoint<nPoint; iPoint+=SIMDLEN); {; for(size_t iVar=0; iVar<nVar; ++iVar); {; phiMin[iVar] = phiMax[iVar] = phi.getVec(iPoint,iVar);; prjMax[iVar] = eps;; prjMin[iVar] = -eps;; }. for(size_t iNeigh=0; iNeigh<adj.nNeighbor(iPoint); ++iNeigh); {; auto jPoint = adj.jPoint_vec(iPoint,iNeigh);. FltVec d_ij[3] = {FltVec(0.0), FltVec(0.0), FltVec(0.0)};. for(size_t iDim=0; iDim<nDim; ++iDim); d_ij[iDim] = (coords.getVec(jPoint,iDim)-; coords.getVec(iPoint,iDim))*0.5;. for(size_t iVar=0; iVar<nVar; ++iVar); {; FltVec prj = 0.0;. for(size_t iDim=0; iDim<nDim; ++iDim); prj += d_ij[iDim]*grad.getVec(iPoint,iVar,iDim);. prjMax[iVar] = vmax(prjMax[iVar], prj);; prjMin[iVar] = vmin(prjMin[iVar], prj);. phiMax[iVar] = vmax(phiMax[iVar], phi.getVec(jPoint,iVar));; phiMin[iVar] = vmin(phiMin[iVar], phi.getVec(jPoint,iVar));; }; }. for(size_t iVar=0; iVar<nVar; ++iVar); {; FltVec lim = vmin(FltVec(2.0), vmin(; (phiMax[iVar]-phi.getVec(iPoint,iVar))/prjMax[iVar],; (phiMin[iVar]-phi.getVec(iPoint,iVar))/prjM",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-530593912:7910,schedul,schedule,7910,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530593912,1,['schedul'],['schedule']
Energy Efficiency,"---- | ---- |; | **Speed** | 1.0 | 2.2 | 0.83 | 1.35 |. **Parallel execution**. I will start at the end for this, all it takes to parallellize the points loops with OpenMP is to take this:; ```C++; for(size_t iPoint=0; iPoint<nPoint; iPoint+=SIMDLEN); ```; And add some pixie dust; ```C++; #pragma omp parallel for schedule(dynamic,128); for(size_t iPoint=0; iPoint<nPoint; iPoint+=SIMDLEN); ```; This means each thread gets chunks of 128 loop iterations (512 points) to work on, assigned in a dynamic way, the 4 core speedup (still relative to our reference) is **3.8** for the SIMD code and **2.8** for the scalar code. Parallelizing the edge loops is a bit more intricate, as this:; ```C++; for(size_t iEdge=0; iEdge<nEdge; ++iEdge); {; size_t iPoint = connectivity[iEdge].first;; size_t jPoint = connectivity[iEdge].second;; ```; Becomes:; ```C++; for(size_t color=0; color<colorStart.size()-1; ++color); #pragma omp parallel for schedule(dynamic,CHUNK_SIZE); for(size_t k=colorStart[color]; k<colorStart[color+1]; ++k); {; #if SORT_BY_COLOR==1; size_t iEdge = k;; #else; size_t iEdge = edgeIdx[k];; #endif. size_t iPoint = connectivity[iEdge].first;; size_t jPoint = connectivity[iEdge].second;; ```; Apologies for the macro but it is just to illustrate that if we re-sort edge data after coloring the edge index is the loop index, otherwise the edge indices for each color need to be stored in a separate array.; Note that for each edge loop we first loop over colors, then over same-color edges, it is this inner loop that can run in parallel in chunk sizes that are multiple of the group size considered during coloring. There is some runtime cost on entry to every #omp parallel section, with coloring we enter one such section once by color. I mentioned in the introduction coloring reduces locality and therefore performance, here is the effect of color group size on the execution time of the scalar code on one thread:; ![image](https://user-images.githubusercontent.com/38071223/6468680",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-530328194:12910,schedul,schedule,12910,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530328194,1,['schedul'],['schedule']
Energy Efficiency,". Trying to process multiple edges instead of multiple variables has all the problems I mentioned for the gradients, so again we use the trick of templating on the number of variables.; ```C++; template<size_t nVar>; void computeLimiters_impl(size_t nPoint,; size_t nDim,; const vector<size_t>& colorStart,; const vector<size_t>& edgeIdx,; const vector<pair<size_t,size_t> >& connectivity,; const Matrix& coords,; const Matrix& phi,; const VectorOfMatrix& grad,; Matrix& phiMax,; Matrix& phiMin,; Matrix& limiter); {; // initialize; #pragma omp parallel for schedule(dynamic,TARGET_CHUNK_SIZE); for(size_t iPoint=0; iPoint<nPoint; ++iPoint); {; #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); {; phiMax(iPoint,iVar) = phi(iPoint,iVar);; phiMin(iPoint,iVar) = phi(iPoint,iVar);; limiter(iPoint,iVar) = 2.0;; }; }. // find min and max neighbor; for(size_t color=0; color<colorStart.size()-1; ++color); #pragma omp parallel for schedule(dynamic,CHUNK_SIZE); for(size_t k=colorStart[color]; k<colorStart[color+1]; ++k); {; #if SORT_BY_COLOR==1; size_t iEdge = k;; #else; size_t iEdge = edgeIdx[k];; #endif. size_t iPoint = connectivity[iEdge].first;; size_t jPoint = connectivity[iEdge].second;. // some hand-holding needed for simd min/max with gcc,; // one of the min/max operands needs to be on the stack; // (so the compiler knows the two do not overlap?); double phi_i[nVar], phi_j[nVar];. #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); {; phi_i[iVar] = phi(iPoint,iVar);; phi_j[iVar] = phi(jPoint,iVar);; }. #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); {; phiMax(iPoint,iVar) = max(phiMax(iPoint,iVar), phi_j[iVar]);; phiMin(iPoint,iVar) = min(phiMin(iPoint,iVar), phi_j[iVar]);; phiMax(jPoint,iVar) = max(phiMax(jPoint,iVar), phi_i[iVar]);; phiMin(jPoint,iVar) = min(phiMin(jPoint,iVar), phi_i[iVar]);; }; }. for(size_t color=0; color<colorStart.size()-1; ++color); #pragma omp parallel for schedule(dynamic,CHUNK_SIZE); for(size_t k=colorStart[color]; k<colorStart[",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-530593912:4268,schedul,schedule,4268,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530593912,1,['schedul'],['schedule']
Energy Efficiency,"> ; > ; > Dark mode?; > ""Is it possible to learn this power?"". 🧙 Sure, if you just go to your front page (i.e. just github.com) there should be a big button directly on the right side. ; Or Settings->Appearance->Dark. Enjoy :)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1129#issuecomment-743130745:54,power,power,54,https://su2code.github.io,https://github.com/su2code/SU2/pull/1129#issuecomment-743130745,1,['power'],['power']
Energy Efficiency,"> @aeroamit What does temperature do? Could you compute the heat flux from the temperature in e.g. paraview? Is the root cause the computation of the energy equation or the computation of heat flux?. Hi @bigfooted, Temperature boundary condition for wall corresponds to Isothermal wall BC (cold wall condition). This condition is applied to obtain heat flux unlike adiabatic wall (no heat transfer). ; The snapshot, I posted from ParaView shows heat flux variation with x. This is obtained directly from surface_flow.vtu. You can simply go to Filters -> Data Analysis -> Plot data and select Points_X for X Array and heat flux in variable. Regarding computing heat flux from temperature field, I am not sure, but ParaView is having calculator utility as well as option to compute gradient of unstructured grid (from there you can obtain temperature gradients in 3 directions). ; Coming to last question, root cause of the problem - @WallyMaier has run the case yesterday, we will be posting some details soon.; Best ; Amit",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1106#issuecomment-741947377:150,energy,energy,150,https://su2code.github.io,https://github.com/su2code/SU2/pull/1106#issuecomment-741947377,1,['energy'],['energy']
Energy Efficiency,"> Do I understand correctly that two gradients are always computed per iteration?; > Is there any downside to using the unweighted LS for viscous flux correction? Is the statement that this type of gradient is better for reconstruction based on your observations or is it one of those well known things?. Yes - the gradient for now is computed twice and stored separately for viscous flows with 2nd-order upwind. Could be combined into one loop eventually. It is known that weighted LSQ / GG is more accurate (see Mavriplis, ""Revisiting the Least-Squares Procedure for Gradient Reconstruction on Unstructured Meshes"" for instance). However, unweighted LSQ is known to be more robust.. so a good compromise is to use it only for the reconstruction step (which is more susceptible to robustness issues than the viscous term) and then use WLSQ or GG for all other gradients in the viscous flux/sources for accuracy. > Sometimes high CFL leads to limit-cycle oscillations of the residuals and the solution is to reduce it, is this something this controller can pick up?; > High CFL also makes the linear systems harder to solve and as Edwin pointed out _somewhere_ there is not much point going above reasonable values with weakly coupled turbulence. Do you think it would be reasonable to build in some feedback from the linear solver (e.g. it is taking too much time or did not converge -> drop the CFL)?. Yes, I would also like to couple it to the linear solver so that we can remove the need to tune that as well. Ideally the user will not need to adjust parameters. There are some things I am going to try for that..",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/790#issuecomment-531890295:1008,reduce,reduce,1008,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-531890295,1,['reduce'],['reduce']
Energy Efficiency,"> You are proposing the exact opposite of the conclusion of the paper:; > ; > ""From the above findings, it is **recommended that all three of these terms be included** when running hypersonic, or even supersonic, turbulent flow simulations, especially for flows with shock wave-induced separations.""; > ; > And they clearly say this: ""While the full inclusion of these terms does not always result in predictions that agree better with DNS/experimental data, this is likely caused by the fact that their exclusion cancels out effects of other flaws in the RANS models employed.""; > ; > If your strategy is to get a better match with experiments by neglecting physics terms, then you should rethink your strategy. Thank you for your comment @bigfooted . The above paper is not presented to improve the current k-w SST model. . As you can see in the first post, there is a problem with the high Mach number and freestream turbulence intensity case. If high turbulence kinetic energy(TKE) and Mach number condition, the boundary condition cannot be maintained the imposed value. (I think there seems to be a bug in the temperature calculation using total energy when including the TKE). The introduction of C1 was intended to provide a 'temporary' solution at the level of first aid (simply commenting out conditional statements in code).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1851#issuecomment-1521383702:974,energy,energy,974,https://su2code.github.io,https://github.com/su2code/SU2/issues/1851#issuecomment-1521383702,2,['energy'],['energy']
Energy Efficiency,"> You may want to remove the string based interface since it's known to be inneficient. When replacing the string-based with index-based look-up methods, the performance improves substantially. The figure below shows the average measured evaluation time (measured with chrono library) vs the number of output variables. It's clear that using index-based look-up methods results in reduced query time, as well as improved scaling. ![scaling_nVars](https://github.com/su2code/SU2/assets/38651601/31252439-ac6e-4f1b-82d4-e13a55d54c98)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/2214#issuecomment-1952521226:381,reduce,reduced,381,https://su2code.github.io,https://github.com/su2code/SU2/pull/2214#issuecomment-1952521226,1,['reduce'],['reduced']
Energy Efficiency,"@clarkpede I have not used the mesh adaptation tools since my last post (I was simply learning to use them for an undergrad project). With that said, I do not have any other concerns. It worked well for my application. I appreciate your help.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/606#issuecomment-500491744:36,adapt,adaptation,36,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-500491744,1,['adapt'],['adaptation']
Energy Efficiency,"@pcarruscag I tried to restart the solution with zero mach number for config. However, for some reason, convergence takes so much longer than simply solving mach=0.1 config. Indeed, i started my simulation when you post your suggestion and it still haven't converged yet. Residual getting smaller but it is so slow. Therefore it might not be an efficient solution. Thanks for advice anyway.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/997#issuecomment-632892959:345,efficient,efficient,345,https://su2code.github.io,https://github.com/su2code/SU2/issues/997#issuecomment-632892959,1,['efficient'],['efficient']
Energy Efficiency,"Alright. I did some digging, and the problem has nothing to do with the warning message. It goes much deeper. In a recent release, SU2 switched to reading and writing binary restart files instead of ASCII. The grid adaptation code is still written only for ASCII. If I'm right, then trying to read a binary restart file with the flow solution breaks the program. I'll submit an issue detailing the bug. For now, try adding the following lines to your cfg file when you run `SU2_CFD`:. %; % Write binary restart files (YES, NO); WRT_BINARY_RESTART= NO; %; % Read binary restart files (YES, NO); READ_BINARY_RESTART= NO. Then run `SU2_MSH`, just like you have been. Does that clear things up?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/606#issuecomment-436131167:215,adapt,adaptation,215,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-436131167,1,['adapt'],['adaptation']
Energy Efficiency,"And here is a simple test case demonstrating potential use. A major benefit of the supersonic inlet is being able to model supersonic propulsion systems, such as a scramjet, where the propulsion system exit boundary is modeled as a supersonic inlet, with distinct properties from the farfield flow conditions. Here we have a two dimensional test case demonstrating the interaction of exhaust flow with free-stream flow at the exit plane of a 2D scramjet system. Flow conditions adapted from [A Design Method for Three-Dimensional Scramjet Nozzles with Shape Transition](https://arc-aiaa-org.stanford.idm.oclc.org/doi/abs/10.2514/1.B38293); Jens Kunze, Michael K. Smart, and Rowan Gollan; Journal of Propulsion and Power 2022 38:1, 3-17. <img width=""1262"" alt=""image"" src=""https://user-images.githubusercontent.com/44848904/211415971-b6122204-0d95-43ca-903b-d60fd6326c39.png"">",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1862#issuecomment-1375043856:478,adapt,adapted,478,https://su2code.github.io,https://github.com/su2code/SU2/pull/1862#issuecomment-1375043856,1,['adapt'],['adapted']
Energy Efficiency,"As requested, here's an example of a unit test that I made. For context: There's a couple of different modes for the Roe-low-dissipation convective blending. If one of the ""DUCROS"" modes is selected, then the Ducros sensor values are used. Otherwise, they're ignored. Before commit [ac8b3bf](https://github.com/su2code/SU2/commit/ac8b3bf7636cc66ca7f47e15935942a6598e1a9f), the `SetRoe_Dissipation` function checked to see if the sensor values were valid regardless of the type of blending selected. Commit [ac8b3bf](https://github.com/su2code/SU2/commit/ac8b3bf7636cc66ca7f47e15935942a6598e1a9f) changed the behavior to only check the sensor values if they will be used. The unit test sets the convective blending to `NTS`, feeds invalid sensor values into `SetRoe_Dissipation` and checks the output. ```cpp; // Used to set the Roe-low-dissipation option; void WriteCfgFile(unsigned short nDim, const char* filename,; std::string blending) {; std::ofstream cfg_file;. cfg_file.open(filename, ios::out);; cfg_file << ""PHYSICAL_PROBLEM= NAVIER_STOKES"" << std::endl;; cfg_file << ""ROE_LOW_DISSIPATION= "" << blending << std::endl;. cfg_file.close();; }. BOOST_AUTO_TEST_CASE(BadSensorsAllowedForNTS) {. /*--- Setup ---*/. const unsigned short nDim = 3;. /*--- Set up the config class for the test ---*/; char cfg_filename[100] = ""convective_blending_test.cfg"";; WriteCfgFile(nDim, cfg_filename, ""NTS"");; CConfig* config = new CConfig(cfg_filename, SU2_CFD, 0, 1, 2, VERB_NONE);; std::remove(cfg_filename);. /*--- Inputs ---*/; const su2double dissipation_i = 0.4;; const su2double dissipation_j = 0.6;; const su2double sensor_i = NAN; // Intentionally unphysical:; const su2double sensor_j = NAN; // Intentionally unphysical:. /*--- Outputs ---*/; su2double dissipation;. /*--- Test ---*/. CNumerics numerics;; numerics.SetRoe_Dissipation(dissipation_i, dissipation_j,; sensor_i, sensor_j,; dissipation, config);. const su2double tolerance = std::numeric_limits<su2double>::epsilon();; BOOST_CHECK_CLOSE_F",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499999225:216,sensor,sensor,216,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499999225,4,['sensor'],['sensor']
Energy Efficiency,"Dark mode?; ""Is it possible to learn this power?""",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1129#issuecomment-743123950:42,power,power,42,https://su2code.github.io,https://github.com/su2code/SU2/pull/1129#issuecomment-743123950,1,['power'],['power']
Energy Efficiency,"GS lose effectiveness with number of partitions.; Optimum hardware utilization, for routines that are bandwidth-bound it may be beneficial to use all threads available, while for compute-bound or ""algorithm-bound"" ones this may not be the case. **Relation with algorithms**; A typical edge loop reads from 2 locations and writes to 2 locations (gather / scatter access pattern, not to be confused with the instructions) processing multiple edges at the same time can therefore result in race conditions where multiple threads try to update the data of the same point.; There are 3 ways to address this:; - **Coloring**: Edges are colored (grouped) such that edges of the same color have no risk of race conditions, i.e. each endpoint is referenced only once per color (this definition gives you the basis of a greedy algorithm to color edges).; - **Scatter to gather transformations**: Edge quantities (e.g. fluxes) are computed and stored on one pass (i.e. we read from 2 locations and write to 1), on a second pass, over points, we reduce (e.g. sum) the edge quantities for each point, again a gather access pattern. It may also be possible to convert the entire algorithm to a loop over points instead of edges.; - **Atomic operations or locks**: Here when a thread wants to write to a memory location it either needs to do so atomically (this is essentially an operations that always goes through main memory and forces cache coherency) or it needs to acquire a *lock* for the point it is writing to, if it fails to acquire the *lock* (because another thread has it) it needs to wait. None of these is without drawbacks.; - **Coloring** reduces temporal locality, edges are sorted in increasing order of the point indices to reduce cache misses, this means small groups of contiguous edges will share the same ""iPoint"", coloring single edges destroys this. Furthermore coloring either requires edges to be re-sorted by color, or if the edge indices of each color are instead kept in arrays, perfor",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-529662724:4462,reduce,reduce,4462,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-529662724,1,['reduce'],['reduce']
Energy Efficiency,"Good point about making the eigen-functions static. That makes it a lot more accessible in other parts of the code. Will include that in the changes along with the option name changes. . I like the idea about the static allocation, but I foresee a problem that you actually mention. If I convert the variables to be statically defined, I would have to make the eigen-functions accept statically defined arrays. Since most arrays in SU2 are dynamically allocated, this would cause some compatibility issues. . In general, I see the value in making a math library associated with matrix operations. Maybe you could pitch the idea in an issue and get feedback on it?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/570#issuecomment-433963723:452,allocate,allocated,452,https://su2code.github.io,https://github.com/su2code/SU2/pull/570#issuecomment-433963723,1,['allocate'],['allocated']
Energy Efficiency,"Guys,. Thanks for your feedback. @pcarruscag, the reason why I made a different enum rather than a boolean USE_SST_SUSTAINING_TERMS is that all different SA versions also have a different enum. So I thought this was more consistent. But if there is a strong preference for an additional boolean, I'm fine with that as well. What we can do is to keep the enum and set the boolean USE_SST_SUSTAINING_TERMS internally and overwrite SST_SUST to SST. @talbring, @jayantmukho, I am in favor of keeping the original version of SST. Although the difference between the models is rather small, basically the addition of one term, the difference in results can be quite significant, especially for relatively low Reynolds numbers and large value of the turbulent intensity. . @economon, you are right that a lot of the checks for SST are actually more general checks for a two equation model. So I think that most, if not all, checks for SST can be replaced be a check for the number of turbulent equations. That is more general as well, in case we want to add additional turbulence models in the future, assuming that an equation is present for the turbulent kinetic energy if the number of turbulence equations is two or bigger.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/765#issuecomment-524053082:1158,energy,energy,1158,https://su2code.github.io,https://github.com/su2code/SU2/pull/765#issuecomment-524053082,1,['energy'],['energy']
Energy Efficiency,"Hello everyone. I am working with SU2 on the feature_adap branch and have come across an issue during the execution of the mesh adaptation script. After following the standard installation procedure and verifying the installation (the exact same steps that @chesiv presented), I encountered a problem when running the mesh_adaptation_amg.py script. The command used was:. ```; python3 $SU2_RUN/mesh_adaptation_amg.py -f adapt_Mesh.cfg -n 4; ```; The script initiates the mesh adaptation process as expected, with the following output:. ```; SU2-AMG Anisotropic Mesh Adaptation. Mesh adaptation options:; PYADAP_COMPLEXITY : (30000, 60000, 120000); PYADAP_SUBITE : (2, 2, 2); PYADAP_SENSOR : GOAL; PYADAP_HMAX : 500.0; PYADAP_HMIN : 1e-9; PYADAP_HGRAD : 1.8. ./adap exists. Removing old mesh adaptation in 10s.; The ./adap folder was deleted. Generating GMF background surface mesh.; Initial CFD solution is provided.; ```; However, no _adap\ite0_ folder gets created. ; The log.err file in the _adap/ini_ directory provides this traceback:. ```; Traceback (most recent call last):; File "".../mesh_adaptation_amg.py"", line 111, in <module>; ...; RuntimeError: ...; Error in TokenizeString(): two or more options before an ""="" sign in the configuration file.; terminate called after throwing an instance of 'int'; ...; *** Process received signal ***; Signal: Aborted (6); Signal code: (-6); ...; ```. The critical part of this error seems to be the Error in TokenizeString() message, suggesting an issue with parsing the configuration file. This error typically indicates a syntax problem, such as having multiple options on a single line without proper separation by an equal sign (=). However, upon reviewing _adap/ini/config_CFD.cfg_, was unable to find any lines that clearly violated this syntax rule. Could this error be indicative of a more subtle issue within the configuration file, or might it be related to specific aspects of the feature_adap branch? Any insights, suggestions, or guidance ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/948#issuecomment-1847333809:128,adapt,adaptation,128,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-1847333809,4,['adapt'],['adaptation']
Energy Efficiency,"Hi @antares190,. Glad to see that things seem to be starting to work for you. We (Brian) are trying to improve this capability in the solver and any experiences / suggestions / help will be welcome. With that said, this seems like an interesting result. Would you mind submitting it (or other pictures that you like better) so the SU2 Foundation can use it to show this capability to others in the future? The link where you can do this is here<http://su2foundation.org/su2-promotional-material/?utm_source=hs_email&utm_medium=email&utm_content=76584389&_hsenc=p2ANqtz-9fEq2awKk2vd155cCcN_N4mWBCZK-rJ-TqNsZhqSJs-VWn-w7q-H6w8sdiA3LyuOTqlK4eqZhFFstKi-LQFyyGqYPdkwYc9JsNdB1yyd7pqMwTFzA&_hsmi=76584389>. Thanks a lot,. Juan. On Apr 29, 2020, at 1:38 PM, antares190 <notifications@github.com<mailto:notifications@github.com>> wrote:. Thanks Brian,; my bad, I misinterpreted the carpets / logs structure. I successfully ran a test of a very simple case. In the results there are some small artifacts, but the shocks are resolution improved consistently after mesh adaption.; Thanks for the support. [Comparison]<https://user-images.githubusercontent.com/41752169/80644172-84a7a580-8a69-11ea-9f16-58e98c808b73.png>; [ComparisonMesh]<https://user-images.githubusercontent.com/41752169/80644174-85403c00-8a69-11ea-819f-2ac00550a089.png>. —; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/948#issuecomment-621450497>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AA5FFRCGLBHJCB3FS4JSSV3RPCF5RANCNFSM4MQACOXA>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/948#issuecomment-621483859:1058,adapt,adaption,1058,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-621483859,1,['adapt'],['adaption']
Energy Efficiency,"Hi @pcarruscag,; thank you very much for the insight and the well thought proposed solution. I wasn't aware that there was such a loss in performance, it seems clear that something needs to be done. The only question I have is regarding the following comment . > There are no free lunches and this performance improvement would come at the cost of losing the ability to have different types of variables in different parts of the domain. I'm using this feature more and more, I was planning to extend it in the structural solver to remove the `if fsi` statements, and I also used it in the rework of the mesh solver, as defining variables at the interface only reduces greatly the memory footprint (sort of like the node-vertex structures in geometry). You mention there are options to keep this versatility, how difficult do you think would be to implement them?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/716#issuecomment-507998889:661,reduce,reduces,661,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-507998889,1,['reduce'],['reduces']
Energy Efficiency,"Hi Pedro,. It is indeed a good idea to keep similar schemes (with minor variations) under one umbrella, especially central scheme as only the dissipation term calculation differs. . - In case of AUSM+-up1/2 and SLAU1/2, each can be reduced by having a separate pressure flux definition. - But if we try to combine AUSM+-up and SLAU, will it be a clear/helpful implementation as mass flux definitions/calculations (which is substantial portion) are different (unlike the central scheme, where only dissipation term varies)?. - Also could you please shed some light on Jacobian part for these schemes (as you mentioned - “...Isolating the computation of mass and pressure fluxes could be an interesting way to compute the Jacobians of these schemes in a hybrid way ...”). Best; Amit",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/691#issuecomment-499205201:232,reduce,reduced,232,https://su2code.github.io,https://github.com/su2code/SU2/pull/691#issuecomment-499205201,1,['reduce'],['reduced']
Energy Efficiency,"Hi all,. as with the restructuring of the output classes, we should find a common level of abstraction for all the different physical problems we might want to have. Right now there isn't even a unified way of specifying the kind of problem for each zone (what is fluid, what is solid etc) and the kind of coupling. This might also affect the actual implementation/restructuring since we somehow have to decide what driver we have to instantiate and so on. Hopefully we can gather all the people involved to have a discussion on that. Since we have a lot of people working in their branches on multizone problems we should tackle that better sooner than later. As Edwin already suggested, maybe it is a good idea to put some people in charge of organizing some of the bigger structural changes. Furthermore in case some people don't know, we have a slack channel for the dev team. I think that makes it easier to communicate, arrange meetings, discuss problems and ask questions. In case you need an invite, let me know, everybody who wants to contribute is welcome. Thanks for the discussion, I still think that communication is the key of success !. Tim. On Sep 13, 2017 10:30 AM, Edwin van der Weide <notifications@github.com> wrote:. Hi Tom,. Sounds like a plan then to have a look at CIntegration to see what we can do to generalize the time integration. I definitely want to help with this, but I don't think I am the appropriate person to take the lead, because I simply don't have a good overview of all the multi-physics options. Tom, are you willing to take the lead for this?. Furthermore, it is good to have other people involved as well, preferably with detailed knowledge of the different disciplines. Any volunteers?. Thanks,. Edwin. —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/437#issuecomment-329096830>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AEtI5MkXdqhqP",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/437#issuecomment-329146567:735,charge,charge,735,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-329146567,1,['charge'],['charge']
Energy Efficiency,"Hi everyone,; I was tring to use the mesh adaptation feature but the whole procedure is not clear to me.; Following the previous indications I:. 1. downloaded the `feature_adapt branch`. 2. downloaded the Adaptive 2D NACA 0012 example (https://pyamg.saclay.inria.fr/pyamgexamples.html#2dnaca): `adap_NACA0012.cfg`, `mesh_NACA0012_inv.su2`, `NACA0012_ini.dat`. 3. added the following lines to the config:; ```; % Type of sensor used for adaptation; % Options include GOAL (adjoint-based), MACH, PRES; PYADAP_SENSOR= GOAL; % Objective function used for goal-oriented adaptation; OBJECTIVE_FUNCTION= LIFT; % Maximum cell size for adaptation; PYADAP_HMAX= 500.0; % Minimum cell size for adaptation; PYADAP_HMIN= 1e-9; % Gradation factor (typically 1.2-1.8); PYADAP_HGRAD= 1.8; % Norm used for adaptation; % 1.0 or 2.0 recommended for inviscid flows; % 4.0 recommeneded for viscid; ADAP_NORM= 4.0; % Approximate mesh size (NPOI) at each level; PYADAP_COMPLEXITY= (30000, 60000, 120000); % Number of adaptations performed at each level; PYADAP_SUBITE= (3, 3, 3); ```. 4. run the following command: `$ python3 SU2_RUN/mesh_adaptation_amg.py -f adap_ONERAM6.cfg -n 8`. The response I have obtained is the following:; ```; SU2-AMG Anisotropic Mesh Adaptation. Mesh adaptation options:; PYADAP_COMPLEXITY : (30000, 60000, 120000); PYADAP_SUBITE : (2, 2, 2); PYADAP_SENSOR : MACH; PYADAP_HMAX : 500.0; PYADAP_HMIN : 1e-9; PYADAP_HGRAD : 1.8; PYADAP_FLOW_ITER : (2999, 4999, 6999); PYADAP_ADJ_ITER : (2999, 4999, 6999); PYADAP_CFL : (10.0, 15.0, 20.0); PYADAP_RDG : NO. The ./adap folder was deleted. Generating GMF background surface mesh.; ## WARNING: MISSING SU2 MESH FILE KEYWORD: NCORNERS=.; Initial CFD solution is provided.; ```. As expected, a `./ADAP` folder was created, containing these docs: `amg_back_meshb`, `config_CFD.cfd`, `log.err`, `log.out` (sizes 0 byte), `mesh_NACA0012_inv.su2` (link to the mesh), `NACA0012_ini.dat` (link to the file.dat). Did I perform the procedure correctly? Or did I m",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/948#issuecomment-737134105:42,adapt,adaptation,42,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-737134105,8,"['adapt', 'sensor']","['adaptation', 'adaptations', 'sensor']"
Energy Efficiency,"Hi,. Thank you for your quick answer, It indeed seems that I had some parameters that were passed that did not match su2 version 7.0.3. I am experiencing an issue while running the mesh adaptation process in SU2. The process starts but fails during the mesh generation phase, leading to a FileNotFoundError. I am looking for assistance in resolving this error.; `; SU2-AMG Anisotropic Mesh Adaptation. Mesh adaptation options:; PYADAP_COMPLEXITY : (100, 200, 300); PYADAP_SUBITE : (2, 2, 2); PYADAP_SENSOR : MACH; PYADAP_HMAX : 200; PYADAP_HMIN : 1e-8; PYADAP_HGRAD : 1.3; PYADAP_RESIDUAL_REDUCTION : (3, 3, 3); PYADAP_FLOW_ITER : (500, 500, 500). ./adap exists. Removing old mesh adaptation in 10s.; The ./adap folder was deleted. Generating GMF background surface mesh.; Initial CFD solution is provided. Starting mesh adaptation process. Iteration 0 - Mesh size coefficient 100.0; (1/2) Generating adapted mesh using AMG; AMG done: ; Running CFD; Traceback (most recent call last):; File ""/path/to/SU2/install/bin/mesh_adaptation_amg.py"", line 111, in <module>; main(); File ""/path/to/SU2/install/bin/mesh_adaptation_amg.py"", line 72, in main; options.save_all ); File ""/path/to/SU2/install/bin/mesh_adaptation_amg.py"", line 101, in mesh_adaptation_amg; SU2.run.amg(config); File ""/path/to/SU2/install/bin/SU2/run/amg.py"", line 466, in amg; os.rename(cur_solfil, cur_solfil_ini); FileNotFoundError: [Errno 2] No such file or directory: 'flo.dat' -> 'flo_ini.dat'`. and it0 folder is created, with some log.err and log.out, but they are empty, . I would appreciate any guidance or suggestions on how to resolve this issue. Thank you!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/948#issuecomment-1855842105:186,adapt,adaptation,186,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-1855842105,5,['adapt'],"['adaptation', 'adapted']"
Energy Efficiency,"I am not sure about why periodic boundaries are allowed to deform. It doesn't seem to be a good idea unless there is a way to deform its periodic pair in the same way. As for @auzbaig's question about why SLSQP converges in one step: There is a huge difference in the magnitude of the objective function, O(1) and the gradient O(-11). I am guessing the optimizer doesn't think it can reduce the function value any further since the gradient with respect to the DVs is so small. . To change the relative magnitudes of the objective and gradient, you need to change the DV scaling. This isn't intuitive and is one of the things we are hoping to address in #922 . Check out the `obj_df` function in `SU2_PY/SU2/eval/design.py` (line 386 in the develop branch). There you see how the gradient is scaled: . `grad[k] = grad[k] * sign * scale * global_factor / dv_scl` . Here `scale` is the objective function scaling factor, `global_factor` is what you specify for the `OPT_GRADIENT_FACTOR`, the `dv_scl` is the design variable scaling. . So if you wanted to bring the gradient norm to O(1), you'd have to specify a DV scaling of 1e-11. Usually a gradient norm of O(-6) is what seems to work best with SLSQP.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/976#issuecomment-628724163:384,reduce,reduce,384,https://su2code.github.io,https://github.com/su2code/SU2/issues/976#issuecomment-628724163,1,['reduce'],['reduce']
Energy Efficiency,"I could but I do not think updating that branch will fix your problem. We have not found any mesh handling bugs recently.; Creating / modifying meshes manually can get tricky (at least in my experience).; Have you tried simpler problems? Try starting with a problem that is known to work (there is a long issue with success stories, do a search for mesh adaptation here on github). Then build up from it, e.g. take the same problem and use a finer grid, change the physics to what you need, use a grid for your problem (ideally change one thing at a time).; Also keep in mind that if that branch was finished work it would probably have been merged into develop by now...",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1156#issuecomment-757123547:354,adapt,adaptation,354,https://su2code.github.io,https://github.com/su2code/SU2/issues/1156#issuecomment-757123547,1,['adapt'],['adaptation']
Energy Efficiency,"I have a few updates. I found out that most of my FGMRES problems in this branch where related to the fact that I was using single precision for the linear system. You can see it in this graphs for the residuals of Rho. ![RMSRho_Mesh_3](https://github.com/user-attachments/assets/185b8195-e415-4dff-9332-cff573c069cc). The first two curves are in mixed-precision and they stop long before reaching the minimum residual required due to divergence of the linear solver. Moreover, it seems that the 2003 model here implemented (which, simply put, considers the full reynolds stress tensor for the computation of the production of k and always considers k in the stress tensor and in the thermodynamic variables) has faster convergence and increases the recirculating zone (maybe due to the reduction of turbulence kinetic energy) which is a feature that has also been seen in [DOI:10.1017/aer.2020.93]. . ![SFC_Mesh_3](https://github.com/user-attachments/assets/81a50021-6b58-4a84-9057-a18b5bab023c). There are some differences between the use of the TMR boundary conditions and the ones used before. The results improve with respect to the develop in the prediction of the SFC distribution, which has results completely off from the V&V page of SU2. ![SFC_Mesh_3_Old](https://github.com/user-attachments/assets/0f4d634b-df31-4f86-a324-d9f67947f1ff). ![RMSRho_Mesh_3_Old](https://github.com/user-attachments/assets/24d5c2f5-93fe-432f-82d9-c050a90f7339). I may keep on checking if the implementation of the v2003 model is correct or not by searching for other test cases (probably coming from DOI:10.1017/aer.2020.93).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/2329#issuecomment-2393433487:819,energy,energy,819,https://su2code.github.io,https://github.com/su2code/SU2/pull/2329#issuecomment-2393433487,1,['energy'],['energy']
Energy Efficiency,"I have added the new option NUM_METHOD_GRAD_RECON to specify a separate method for computing the reconstruction gradient. If that option is not present, then no additional memory is allocated and no extra gradient computation occurs. I have also put in simple feedback from the linear solver residual and the nonlinear residual to the nonlinear controller. If the linear system converges less than a half an order of magnitude, then the CFL is lowered. A Cauchy-like criteria checks for stall in the nonlinear residuals and drops the CFL to the minimum floor to kick the solver out of a rut. Both of these use factors that are empirical from my tests. Will probably be improved with time and more testing, but they do seem to improve behavior. @koodlyakshay : I had success with the inc. laminar backward facing step after adding extra iterations to the linear solve. For some cases, this is necessary to get a large speedup. I am seeing good speedup for most of the cases within our TestCases repo. If you have some tough cases not covered by the repo, please give those a try.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/790#issuecomment-536145232:182,allocate,allocated,182,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-536145232,1,['allocate'],['allocated']
Energy Efficiency,"I just ran the case and I see this as well, even after complete convergence. You clearly can see this in the energy and pressure (and density) but not in the momentum terms. The temperature field also looks smooth. So may be related to density/pressure.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1373#issuecomment-932510910:109,energy,energy,109,https://su2code.github.io,https://github.com/su2code/SU2/issues/1373#issuecomment-932510910,1,['energy'],['energy']
Energy Efficiency,"I was running some tests using a simple geometry but for the refinement seems to be chewing up the geometry. Has anyone who has worked on 3D geometries experienced this or figured out a way to avoid this?. I was using the following settings:; ```; % ------------- MESH ADAPTATION PARAMETER ------------%; %; % Type of sensor used for adaptation; % Options include GOAL (adjoint-based), MACH, PRES; PYADAP_SENSOR= MACH; % Maximum cell size for adaptation; PYADAP_HMAX= 500.0; % Minimum cell size for adaptation; PYADAP_HMIN= 1e-9; % Gradation factor (typically 1.2-1.8); PYADAP_HGRAD= 1.8; % Norm used for adaptation; % 1.0 or 2.0 recommended for inviscid flows; % 4.0 recommeneded for viscid; ADAP_NORM= 2.0; % Approximate mesh size (NPOI) at each level; PYADAP_COMPLEXITY= (1000000, 1300000, 1500000); % Number of adaptations performed at each level; PYADAP_SUBITE= (2, 2, 2); ```. ![refine](https://user-images.githubusercontent.com/16842258/104834786-0b94fa80-58e5-11eb-9018-687ffc5aaa9d.png). I noticed a few comments up, there is the `PYADAP_BACK` setting, which sounds like it might solve this, but how should one use this? Should the geometry alone be re-meshed to a high resolution and the whole volume exported as a SU2 block? Or should it be just a surface mesh? (It seems that Pointwise is not able to output only the surface mesh in SU2 format.)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/948#issuecomment-761751741:318,sensor,sensor,318,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-761751741,6,"['adapt', 'sensor']","['adaptation', 'adaptations', 'sensor']"
Energy Efficiency,"I'll try to break down each request to make it clearer. Request: Use nomenclature consistent with the C++ interface (point instead of node, etc.); Reason: People who know the C++ interface will know how to use the python wrapper straight away, people who learn how to use the python wrapper will be able to understand the C++ implementation (without needing a translation layer in their mind all the time). Request: Return connectivity/adjacency as local indices instead of global; Reason: This is the natural way of referencing data in an MPI code, local indices correspond directly to data stored in the partition thereby making it more efficient to access (without global-to-local conversions, which are much more expensive than local-to-global). Furthermore, the local ordering strategy improves the efficiency of loops (over edges, neighboring points, etc.). Request: Do not apply unnecessary ""transformations"" to the connectivity/adjacency as part of the API; Reason: Increases the maintenance burden and makes for a less versatile API. By returning the local indices that form a marker or element, it is trivial to retrieve any other data for those indices (the ""transformation""). For example, the solution at those points, the point coordinates, whether the points are halo or domain points, the global indices, etc.; This way, by adding a **single** function to the API e.g. get the global index of a point of element, the functionality of the API grows a lot more because the user can apply the function to **any** connectivity/adjacency function. Request: Do not offer too many overloads of the same function; Reason: Increases the maintenance burden and it's returning the data in structures that are not very efficient, namely vector of vectors. It is much easier to offer domain-wide data access on the python side, as a very small function that can be part of wrapper utilities (i.e. live only in python but not c++). It may even be more efficient since you make a numpy array/matrix in",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1300#issuecomment-1402197827:639,efficient,efficient,639,https://su2code.github.io,https://github.com/su2code/SU2/pull/1300#issuecomment-1402197827,1,['efficient'],['efficient']
Energy Efficiency,"I've run into some headaches getting the optimization to run efficiently on my end, which is why I ask. Playing with a toy problem, SLSQP actually does a great job on its own (with all tuning parameters set to 1.0) if the following conditions are met:. + The constraints and bounds effectively bound ""reasonable"" solutions, so you don't have to worry about unrealistic deformations.; + The optimization function is (relatively) convex. If those conditions are met, then playing with any of the tuning parameters makes SLSQP converge more slowly, sometimes with 10x the iterations. So its not clear to me when the tuning parameters are necessary, and how those tuning parameters affect the convergence in those cases. I'm not arguing that the tuning parameters aren't necessary, just that their effects aren't clear. And I agree, the proper way to nondimensionalize and regularize these problems is not clear from a brief search of the literature.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/733#issuecomment-616825497:61,efficient,efficiently,61,https://su2code.github.io,https://github.com/su2code/SU2/issues/733#issuecomment-616825497,1,['efficient'],['efficiently']
Energy Efficiency,"It does output the file, Paraview & Tecplot formats (binary & ASCII) both work. However, I need the raw data as I will be subjecting it to a Machine Learning Algorithm in Python. Manually deleting the lines for cell numbers in Tecplot format is an additional time consuming step, that hinders full automation. Hence a simple file as flow.csv (CSV format) may help me run it more efficiently. 1. Ganti, Himakar & Khare, Prashant. (2018). Spatio-Temporal Prediction of Gaseous and Liquid Spray Fields using Machine Learning. 10.2514/6.2018-4760. . 2. Ganti, Himakar & Kamin, Manu & Khare, Prashant. (2019). Design Space Exploration for Vaporizing Liquid Jet in Air Crossflow using Machine Learning. 10.2514/6.2019-2211.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/787#issuecomment-528453362:379,efficient,efficiently,379,https://su2code.github.io,https://github.com/su2code/SU2/issues/787#issuecomment-528453362,1,['efficient'],['efficiently']
Energy Efficiency,"N; ++k); grad(iPoint+k,iVar,iDim) = gradI[iVar][iDim][k];; ...; ```; Similarly when computing the gradient we need to first fetch/transpose it to be able to vectorize subsequent computations; ```c++; FltVec gradI[MAXNVAR][MAXNDIM];. for(size_t iVar=0; iVar<nVar; ++iVar); for(size_t iDim=0; iDim<nDim; ++iDim); for(size_t k=0; k<SIMDLEN; ++k); gradI[iVar][iDim][k] = grad(iPoint+k,iVar,iDim);; ...; ```; Performance wise this is actually better than the SoA version (4% on gradients, 35% on limiters) as it also benefits from better locality, and it is only slightly (3%) worse than zig zag storage, especially when fusing limiters and gradients as the transposition of the gradient into storage is greatly amortised.; Regarding readability, the 3 nested loops can be moved to methods of the container, but we cannot get rid off the local variable (if we want vectorization that is). **We lose the ability to vectorize primitive variable updates efficiently with AoS** but currently that only accounts for 3% of the runtime and it is a memory bound operation therefore it would not gain much from vectorization anyway. On the subject of de-swizzling data remember I said the writes into CSysMatrix would be a bit weird, that is because each Jacobian contribution will be a ""matrix of short arrays"" that needs to be transformed into a short array of matrices, the result of that is code like the above that explicitly manipulates the lanes of our SIMD type, such code can be completely hidden inside CSysMatrix which is good because a 4x4 vectorized transpose and matrix update looks like this; ```c++; // block j, subs from jj and goes to ij; T0 = blk_j[ k ].unpackLo(blk_j[k+1]); T1 = blk_j[ k ].unpackHi(blk_j[k+1]);; T2 = blk_j[k+2].unpackLo(blk_j[k+3]); T3 = blk_j[k+2].unpackHi(blk_j[k+3]);. C0 = T0.widePermuteLo(T2); C1 = T1.widePermuteLo(T3);; C2 = T0.widePermuteHi(T2); C3 = T1.widePermuteHi(T3);. (Array4d(&bjj[0][k])-C0).store(&bjj[0][k]);; (Array4d(&bjj[1][k])-C1).store(&bjj[1][k]);; (Arr",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-535977206:15153,efficient,efficiently,15153,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206,1,['efficient'],['efficiently']
Energy Efficiency,"Nice progress @pcarruscag!. I like the concept of your SIMD-friendly class that will take care of the data structure under the hood coupled with a standard type of loop statement (w/ +SIMDLEN). This should make it pretty easy for folks to still modify the kernels without having to worry about the data alignment, and they can reuse the same simple 'for' construct repeatedly. . Another reason to have our own lightweight class for this is that you can avoid dependence on OpenMP for SIMD (although that feature looks to have potential and wasn't available until somewhat recently) as well as the intrinsics. In my experience, the latter is especially bad for portability and readability (part of why we left the CaF work in a separate repo). It starts to become so specialized that compiling and modifying become difficult. W.r.t. OpenMP, another roadblock there a few years ago was making sure it is interoperable with CoDi for the adjoint, but I know this has been worked on and may be available by now. Might keep an open mind about point vs. edge. In some places, we may be able to pump up the compute in our loops by fusing kernels, as previously discussed (and I am guessing you are working on this already with gradients/limiters). Could change the final performance numbers significantly. Lastly, I know you are not there yet, but it is worth considering whether you can reuse anything you are developing in the kernels here for the linear solver routines. At some point, you will successfully reduce the cost of the residual kernels (RHS) to the bandwidth limit, and the majority of the iteration cost will be in the linear solver (it is already about 50% of the iteration cost before optimization, if I recall). Before making final decisions on strategy, you should consider if it will help in any of the linear solver routines too.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-530440072:1503,reduce,reduce,1503,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530440072,1,['reduce'],['reduce']
Energy Efficiency,"Ok, I went back to try varying the `.cfg` settings on the simple v7.0.3 repo `TestCases/euler/naca0012` case and managed to get `mesh_adaptation_amg.py` to run successfully. It seems that one bit of advice [from here](https://www.cfd-online.com/Forums/su2/214613-grid-adaptation-options.html) is no longer true, i.e. one needs to set:; ```; % Write binary restart files (YES, NO); WRT_BINARY_RESTART= YES; %; % Read binary restart files (YES, NO); READ_BINARY_RESTART= YES; ```; in order for the amg mesh adaptation to function. However, for some reason, I can't get it working for my actual mesh of interest. When using the same settings, I get a different ParMETIS error (from the `adap/ini/log.out`):; ```; ------------------- Geometry Preprocessing ( Zone 0 ) -------------------; Three dimensional problem.; 4929018 grid points before partitioning.; 7406196 volume elements before partitioning.; 3 surface markers.; 18040 boundary elements in index 0 (Marker = BODY).; 50968 boundary elements in index 1 (Marker = FARFIELD).; 284054 boundary elements in index 2 (Marker = SYMMETRY).; Executing the partitioning functions.; Building the graph adjacency structure.; [ 1] ***ASSERTION failed on line 207 of file ../externals/parmetis/libparmetis/comm.c:sendind[i] >= firstvtx && sendind[i] < lastvtx; [ 1] 361316 123226 246452; [1609857970.901920] [super:1060888:0] sock.c:344 UCX ERROR recv(fd=62) failed: Connection reset by peer; ```. The only difference that I can think of is that my flow is fully supersonic and my mesh is an unstructured core with a structured collar - might this be causing the issue? Kind regards.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/948#issuecomment-754686447:268,adapt,adaptation-options,268,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-754686447,2,['adapt'],"['adaptation', 'adaptation-options']"
Energy Efficiency,"Ok, SIMD update, with #753, #959, and #966 we now have a unified storage type for the data we need in CNumerics. This means that we (I) only need to implement ""SIMD accessor methods"" (i.e. that return a SIMD type instead of a su2double) for one class (C2DContainer and co.). I think to do SIMD right we need a new way of going about CNumerics, these are my design requirements for ""CNewNumerics"":; - Thread-safe (consequently const-correct), a single object must be safe to use by multiple threads.; - Minimal indirection, the polymorphic overhead will be reduced to a single call (ComputeResidual), all auxiliary functions (like the ones that live in CNumerics) will be forcefully inlined, no useless copies of data (no more numerics->SetBlaBla).; - Compile time nDim/nVar, which will: a) avoid heap allocations; b) allow effective loop-unrolling (also during the writes to CSysMatrix).; - Allow low-overhead composition, e.g. have one CRoe for Euler and one CRoeVisc for NS to fuse convective and viscous residuals (without copy pasting code).; - A lot more readable, those cryptic V_i[iDim+1] need to go (somehow...). To achieve all this, the ""CNewNumerics"" will work as a template (obvs) decorator/visitor.; A visitor in the sense that the solver calls the numerics and gives it (read-only) access to all its data, the object pulls whatever it needs directly and there is no need for numerics->SetBlaBla.; A template decorator in the sense that the class can be augmented simply by inheriting from another, along the lines of `class CRoeVisc : public CRoe, public CVisc` (to allow fusing residual and Jacobian contributions).; All this needs to be done with templates for the ""minimal indirection"" requirement. Which means for each numerical method we will have 4 explicit template instantiations (Euler2D, Euler3D, (RA)NS2D, (RA)NS3D) but in the end these are still polymorphic objects that will be instantiated by some factory function (i.e. it will look clean, especially because I will not por",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-622941617:556,reduce,reduced,556,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-622941617,1,['reduce'],['reduced']
Energy Efficiency,Okay @pcarruscag I believe ; I reverted all the annoying format changes. Can you please review the code when you get the chance?. BTW I am aware about the boilerplate code in `python_wrapper_structure.cpp` and I plan to adapt `CPyWrapperMatrixView`. Would appreciate some feedback anyways,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1750#issuecomment-1779150012:220,adapt,adapt,220,https://su2code.github.io,https://github.com/su2code/SU2/pull/1750#issuecomment-1779150012,1,['adapt'],['adapt']
Energy Efficiency,"Overall some solid looking code @jayantmukho, thanks!; I have a few suggestions:; 1 - Some of the config variables have fairly broad names, ""permute"" for example, I think prefixing them with UQ would more clearly identify what they are meant for.; 2 - There are a lot of dynamic allocations of static size, if the current implementation is compatible with 2 and 3 dimensions I would allocate those variables statically, makes for cleaner and faster code (stack allocations are much faster and subsequent loops would likely be unrolled by the compiler).; 3 - It looks like some of the new methods in CNumerics are for generic ""Eigenvalue-stuff"" for re-usability I suggest moving those methods to a helper class, even if for now that class becomes just a collection of static methods. In the implementation of those methods the dimension of the inputs is being assumed, if you do move them please make them generic.; Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/570#issuecomment-427468893:383,allocate,allocate,383,https://su2code.github.io,https://github.com/su2code/SU2/pull/570#issuecomment-427468893,1,['allocate'],['allocate']
Energy Efficiency,"So just to be clear: In my opinion, after calling SU2Driver.Run() the iteration count should be increased immediately. Now we postpone it in the python scripts, which means we have to add +1 in monitor to get the correct iteration count.; With the current change, Monitor has the correct (imo) behavior.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1960#issuecomment-1464364540:194,monitor,monitor,194,https://su2code.github.io,https://github.com/su2code/SU2/pull/1960#issuecomment-1464364540,1,['monitor'],['monitor']
Energy Efficiency,"Thank you @TobiKattmann for your feedback. The idea behind this new regression test config file is as follows:; We should have a test case that triggers the negative part of the SA model. Depending on the flow conditions, geometry and CFD parameters it might be triggered or not. With the previous config file, it was not. ; I think there is already a regression test in SU2 that triggers the negative SA, the `turb_oneram6_nk`. However, I decided to stick to rae2822 airfoil as it is a simpler (faster) case. In order to force the negative part of the SA for the rae2822 in a reasonable amount of iterations for a regression test, I increased the angle of attack. I have removed the multigrid as it might not be stable, but I have not tested though. Anyway, with the current configuration, e.g., convective scheme, CFL number, etc, the solution is not stable and diverges after some iterations, around 15. In that sense, I reduced the number of iterations from 20 to 10. In my opinion, a diverging regression test is not a problem at all as it might not be used as a tutorial, only to verify the integrity of the commit. ""The solution should always diverge to the same results"". If the regression test should converge, let me know and I will update the config file :)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1559#issuecomment-1067926363:924,reduce,reduced,924,https://su2code.github.io,https://github.com/su2code/SU2/pull/1559#issuecomment-1067926363,1,['reduce'],['reduced']
Energy Efficiency,"Thank you for replying while busy preparing the High Lift Prediction Workshop 5. Sorry, I didn't clearly understand. From what I understand, I can suggest another energy equation calculating method instead of the current SU2 method(reading calculated TKE from inlet boundary condition and using it as an energy equation). Is that right? If not, could you please explain in more detail?. > @sun5k maybe you can try implementing the alternative I suggested of obtaining turbulence kinetic energy at inlets from the turbulence solver instead of assuming that the free stream value is imposed exactly? In the SWBLI case the SST-m versions (without divergence terms in the stress tensor) seem to underpredict the separation region https://su2code.github.io/vandv/swbli/",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1851#issuecomment-1525805374:163,energy,energy,163,https://su2code.github.io,https://github.com/su2code/SU2/issues/1851#issuecomment-1525805374,3,['energy'],['energy']
Energy Efficiency,"Thanks Brian,; my bad, I misinterpreted the carpets / logs structure. I successfully ran a test of a very simple case. In the results there are some small artifacts, but the shocks are resolution improved consistently after mesh adaption.; Thanks for the support. ![Comparison](https://user-images.githubusercontent.com/41752169/80644172-84a7a580-8a69-11ea-9f16-58e98c808b73.png); ![ComparisonMesh](https://user-images.githubusercontent.com/41752169/80644174-85403c00-8a69-11ea-819f-2ac00550a089.png)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/948#issuecomment-621450497:229,adapt,adaption,229,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-621450497,1,['adapt'],['adaption']
Energy Efficiency,"Thanks Tom; I agree that we should make things easy to understand. ; My thinking was that most users will want to know what parts of the mesh they are moving, but don't necessarily need to know what's happening underneath - if they specify the entire mesh the code just reverts to the more efficient method. But (from the users perspective) it may be just as easy to have a separate specification for scaling the entire mesh. . In terms of moving it to SU2_MSH; I think it may make sense to include scale/rotate/translate in SU2_MSH, but I think it would be confusing to have two options that do the same thing. I would side with separate option names (this would also eliminate a loop over markers in this pull request). On this topic, I have sometimes found MARKER_DESIGNING and DV_MARKER to be confusing; on their own they sound very similar, in the description MARKER_DESIGNING is where the objective function is evaluated - but in the code, it's not clear what MARKER_DESIGNING does - the surfaces specified by MARKER_MONITORING are what are actually used to evaluate the objective function value. . There may be other similar areas where config file options could be clarified or compressed.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/187#issuecomment-132181536:290,efficient,efficient,290,https://su2code.github.io,https://github.com/su2code/SU2/pull/187#issuecomment-132181536,1,['efficient'],['efficient']
Energy Efficiency,"Thanks for the comments, Tom! I understand it's a big change, so I would welcome some more feedback! . I am working in other ways to improve the generalization/sustainability of the code, so any comments would also be considered for that stage :D",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/528#issuecomment-388799884:160,sustainab,sustainability,160,https://su2code.github.io,https://github.com/su2code/SU2/pull/528#issuecomment-388799884,1,['sustainab'],['sustainability']
Energy Efficiency,"Thanks for the explanation @suargi . I would personally advocate for that the testcases should converge to some reasonable solution people might use it as a starting point (copy the cfg and doing mild adaptions) for their own stuff. And the Testcases show off the capabilities to some degree, to do so, convergence is beneficial. But as we have a bunch of working 2D airfoils in regression already I recon that adding a clear explanation and warning to the cfg as suggested by Pedro is fine. Otherwise you might try to bisect the AoA ... maybe there is a value that triggers negative SA and does not diverge :thinking: . Knowingly adding a diverging test without a clear warning is not good imo :)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1559#issuecomment-1067977083:201,adapt,adaptions,201,https://su2code.github.io,https://github.com/su2code/SU2/pull/1559#issuecomment-1067977083,1,['adapt'],['adaptions']
Energy Efficiency,"Thanks for the feedback @pcarruscag. @jayantmukho and I discussed this when we implemented the objective function. The main motivation was that since our implementation of the separation sensor is computed using the skin friction coefficient, we only defined the variables Buffet_Sensor, Buffet_Metric, etc. for the NSSolver class. Since the NSSolver needs to be able to evaluate all the same objectives as the EulerSolver, but the buffet objective is exclusive to the NSSolver, I copy pasted the function and added the new objective. Let me know if you have any suggestions for a cleaner implementation. We were basically choosing between defining all the Buffet_* variables in EulerSolver which would just add unnecessary variables to the constantly growing list of variables, or copying EvaluateObj_Func to allow for NS-specific objectives.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/614#issuecomment-441300657:187,sensor,sensor,187,https://su2code.github.io,https://github.com/su2code/SU2/pull/614#issuecomment-441300657,1,['sensor'],['sensor']
Energy Efficiency,"Thanks for the hint, just uploaded a screenshot of the mesh adaption!; Now I'm trying to run a simple 3D case, but unfortunately the amg.out fails during the first try (in the adap/ini folder):; ```; ## 16739 TRIANGLE(S) DISCARDED ; fefloa_Python2Mesh : 3d mesh on input ; fefloa_Python2Mesh : msh->NbrVer 14368 ; fefloa_Python2Mesh : msh->NbrTet 58189 ; fefloa_Python2Mesh : leaving with 14368 ver. 16740 tri. 0 edg. ; -- Maximal memory ; Maximum number of Points 53800000 ; Maximun number of Bnd Points 10760000; Maximum number of Triangles 21520000 ; Maximum number of Tetrahedra 295900000 ; Allocated Memory 50.105 Gb ; Physical Memory 62.729 Gb; bounding box x: -100 200 y: -150 150 z: -150 150 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; 14368 Vertex ; 3 Boundary Vertices ; 58189 Tetrahedra ; 1 Triangles ; 0 Edges ; 1 Surface(s) ; % Output subdom.meshb Mesh ndimn=3, mpoin=14368, melem=58189, mface=1; Corners 0 Required 0 ; ## ERROR : TETRAHEDRON 2 BOUNDARY FACE 1 2; 9 IS MISSING ; ## ERROR : TETRAHEDRON 4 BOUNDARY FACE 3 7; 2324 IS MISSING ; ···; ## ERROR: FEFLO.A: 16740 BOUNDARY FACES ARE MISSING ; CHECK YOUR MESH . ## FATAL ERROR: FEFLOA: INITIAL OR CURRENT MESH HAS AN IN",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/948#issuecomment-623572280:60,adapt,adaption,60,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-623572280,1,['adapt'],['adaption']
Energy Efficiency,"Thanks for your comments! Except for mixing plane and frozen rotor, sliding plane is also pretty common in turbomachinery simulation, it is indeed implemented in some, if not all, in-house codes. ; MRF is quite useful in turbomachinery simulation, expecially when we deal with transient simulation. Actually it is really rare to move the rotor mesh like in reality. One reason is that MRF is more efficient and accurate. Otherwise, you introduce new disturbance into the transient flow field every physical time step, which is not good. Because when you rotate the mesh, the velocity direction of each grid point inherited from last time step is not rotated. To make it more clear, you will have a flow going towards casing instead of parallel to, at the start of next physical time step. So you need more pseudo time steps to get a proper velocity variable. As a result, you get a zig-zag shape in the residual history.; I'm not actually moving the interface. The rotor mesh is not rotated, so as the interface at rotor zone. I'm just virtually rotating the rotor interface to find the new matching points between rotor and stator for each physical time step, so that the variable could be passed across the interface. In other words, only the passing variables are actually rotated. If I understand it correctly, there is no additional moving mesh restriction introduced here.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/2173#issuecomment-1953783506:397,efficient,efficient,397,https://su2code.github.io,https://github.com/su2code/SU2/pull/2173#issuecomment-1953783506,1,['efficient'],['efficient']
Energy Efficiency,"Thanks for your feedback! I agree, `OMP_NUM_THREADS` is better than having the number of threads in the constructor. I adapted `disc_adj_flow` and `disc_adj_fea` for MPI and added both to parallel AD and hybrid AD tests.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1966#issuecomment-1472198978:119,adapt,adapted,119,https://su2code.github.io,https://github.com/su2code/SU2/pull/1966#issuecomment-1472198978,1,['adapt'],['adapted']
Energy Efficiency,"Thanks, @clarkpede, for this PR and for the clear explanation of the features proposed. LGTM in terms of implementation and code style. I'll just wait for @EduardoMolina to comment on the contents. I only have a couple of minor questions:. > I moved the calculation of the maximum cell width to the CPhysicalGeometry class. This makes inclusion in the central/upwind blending easier. For DES and DDES, the cell lengthscale is not dependent on the flow. So there's no need to compute it every iteration in the flow solver. I can see this approach reduces the computational cost of computing the MaxLength every time at the cost of having one more double in memory per point. However, would a call to SetMaxLength() be necessary in case of deformable meshes? . Also, from PR #532:; > As for code verification, I would propose using one of the cases examined by Travin, Stretlets, Mockett, or Xiao for comparison. (...) The cases I can see where they explicitly show the results of the blending function are: Circular cylinder at Re = 50,000 (Travin et al. 2002) (...). I guess this is the case for which you are showing the rough tests results in the Code Verification section. I am currently looking into some test cases at similar Re regimes. Are you using the unsteady compressible solver for this verification? I noticed that in Ref.[1] they use artificial compressibility, and I was wondering if we could also use this test case to look into the unsteady, incompressible (preconditioned) version of the solver (PR #514).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/552#issuecomment-403842613:546,reduce,reduces,546,https://su2code.github.io,https://github.com/su2code/SU2/pull/552#issuecomment-403842613,1,['reduce'],['reduces']
Energy Efficiency,"Thanks, Edwin. I had originally toyed around with this too, but I thought using the system-specific versions would be most portable at first. However, for something this simple, I agree that we should just do it ourselves. I have reused your implementation with some minor modifications. Could you please just confirm that the code posted above is yours, you are ok with me adapting it, and that I can name you as an author at the top of the file (I have added you there)?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/562#issuecomment-414092502:374,adapt,adapting,374,https://su2code.github.io,https://github.com/su2code/SU2/pull/562#issuecomment-414092502,1,['adapt'],['adapting']
Energy Efficiency,"This is simply the way how the cmd.exe shell works on Windows - file and folder names containing spaces or special characters must be quoted into `""` to be handled correctly.; The title says it all - *to make them [executables] run*. The patch prepends one `""` and appends one `""` to the command name. This could be refactored further to reduce repetition much more by putting the different executable file names into a map and have a single place to combine quote + executable + quote.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/332#issuecomment-321264218:338,reduce,reduce,338,https://su2code.github.io,https://github.com/su2code/SU2/pull/332#issuecomment-321264218,1,['reduce'],['reduce']
Energy Efficiency,"This may be relevant, and it may not be. Is there a reason that the molecular and turbulent diffusion of turbulent kinetic energy is not included in the total energy terms? I'm talking about terms like:. ![molecular and turbulent diffusion of tke](https://latex.codecogs.com/gif.latex?\left(&space;\mu&space;&plus;&space;\frac{\mu_t}{\sigma_k}\right)\frac{\partial&space;k}{\partial&space;x_j}). This term is listed both in Wilcox's ""Turbulence Modeling for CFD"" book and the [NASA TMR website](https://turbmodels.larc.nasa.gov/implementrans.html). NASA's page basically just copies what Wilcox states, and then says ""This expression in the energy equation is also sometimes neglected."". Rumsey clarified his position in a [2009 report](https://ntrs.nasa.gov/archive/nasa/casi.ntrs.nasa.gov/20090015399.pdf), saying that ""when considering high Mach number compressible boundary layer flows using k-omega models, the conservation of total energy should be configured to include the contribution of the turbulent kinetic energy k... It is sometimes common practice to ignore these effects, which is certainly justified when k is signficantly smaller than the square of the mean velocity."" . But he also states: ""Note that in CFL3D, the turbulence models are decoupled from the mean flow equations, k is *not* included in the definition of the total energy, and the diffusion of k does not appear in the mean flow energy equation for its models tested here."" He also omitted the 2/3 \rho k term in both the production and the turbulent stress tensor, and found that it made little difference even for M=10 wall-bounded flows. SU2's version of SST is in a weird spot right now, where it's using the turbulent kinetic energy in some places but not others. It's using it here:. + Total energy definition; + Production of turbulent kinetic energy; + RANS evolution equations; + Eddy viscosity definition. But not here:. + Molecular and turbulent diffusion of turbulent kinetic energy in the total energy cons",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/797#issuecomment-548886007:123,energy,energy,123,https://su2code.github.io,https://github.com/su2code/SU2/issues/797#issuecomment-548886007,5,['energy'],['energy']
Energy Efficiency,"This one is all set after a little more cleanup. I left some low-level changes to the EoS models for later. @CatarinaGarbacz @MarcoFossati : we can use a simple directory name, as you suggest. Let's just go with fluid/ since we also treat liquids with the incompressible solver. Bonus: adds a rotating frame calculation test and some extra error checks on CFL adapt params that should help avoid unreported problems with old configs.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1010#issuecomment-640170715:360,adapt,adapt,360,https://su2code.github.io,https://github.com/su2code/SU2/pull/1010#issuecomment-640170715,1,['adapt'],['adapt']
Energy Efficiency,"Those two cases are not part of the regression suite, and so they were probably not updated as some of the options were renamed.; You can have a look at the other turbomachinery examples (at least two of them are part of the regressions) it should be simple to adapt those options.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1086#issuecomment-706417999:261,adapt,adapt,261,https://su2code.github.io,https://github.com/su2code/SU2/issues/1086#issuecomment-706417999,1,['adapt'],['adapt']
Energy Efficiency,"Todo list:; - [x] Make sure the code can handle arbitrary many species equtions. Especially the output has to be adapted. Note the MAXNVAR of the ScalarSolver has to adapted to that need as well. Make a suitable Testcase for that.; - [x] Implement weak inlet and outlet BC. The weak approach is used in the turb and mean flow and is most likely conservative opposed to the strong one. Here a simple switch will be put in place to compare both versions.; - [x] Consolidate nVar, nSpecies, ... variable to only use 1 consistently (The choice was `nSpecies` which was already introduced for NEMO and it just makes sense to use the same container); - [x] Make the numerous reviewers happy; - [x] Check inlet profiles for Species solver (have a testcase for that) See #1427 ; - [x] Create Objective functions of Surface avg quantities (Area and Massflow? prob. And a variance-style output to capture mixing); - [x] Avoid redundant operations (pre/post processings) during solver restarts. 156d0c5. What will be done in follow-up PR's:; - Viscous contributions for BC_inlet and outlet which are currently not used (also then for Turb-solver) https://github.com/su2code/SU2/pull/1388#discussion_r752384956; - Axissymmetric source term addtion and testing; - multi-component mixing from #1332 ; - gradient validation between DA and FD",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1388#issuecomment-935901996:113,adapt,adapted,113,https://su2code.github.io,https://github.com/su2code/SU2/pull/1388#issuecomment-935901996,2,['adapt'],['adapted']
Energy Efficiency,"We will merge this PR next in order to have enough time for testing and for you to solve conflicts (if you need any help to solve those, please contact me). Even if this PR is merged, please continue to give feedback on the usability. We will still continue to work on that. Refer to the user documentation in order to learn how to adapt your config files. Let me know if you have any questions.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/724#issuecomment-534522241:332,adapt,adapt,332,https://su2code.github.io,https://github.com/su2code/SU2/pull/724#issuecomment-534522241,1,['adapt'],['adapt']
Energy Efficiency,"YES! I am excited to try this out. I can probably test it on some of the other TMR cases (airfoils, flatplates). Will post the results when I get those done. . Side note, there was one issue that @bmunguia and I encountered when performing optimizations with adaptive CFL. Say the DIRECT simulation is run with adaptive CFL and is well converged (6 to 8 orders of residual reduction). When the discrete adjoint performs the one direct iteration to store the computational graph, it uses the initial CFL value, not the CFL that the adaptive CFL routine ended at. This results in the residuals being very high for that one iteration, which then affects the convergence of the discrete adjoint. . I will try to run an adjoint on one of these cases as well to see if the problem persists. Perhaps could be overcome with a simple additional field for CFL in the restart meta-data",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/790#issuecomment-531520526:259,adapt,adaptive,259,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-531520526,3,['adapt'],['adaptive']
Energy Efficiency,"You're right about that bug with vel_i_corr. Thanks for finding it, I'll submit a correction. Yes, it's possible to modify the config file so that your implementation works. But is this simply masking the problem of reduced stability? Do you expect the direct formulation to be less stable? And do the benefits of the direct formulation make the loss of stability worthwhile? If so, then I think you should change the config file. I hope this answers your question, I'm not sure if I understood it correctly. Regards,; Daniel",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/232#issuecomment-182655391:216,reduce,reduced,216,https://su2code.github.io,https://github.com/su2code/SU2/pull/232#issuecomment-182655391,1,['reduce'],['reduced']
Energy Efficiency,"_j[iVar] = phiMax(jPoint,iVar);; }. const double eps = numeric_limits<double>::epsilon();. // very simple if's are required to get vectorization; // trough vector comparisons and masked blends; #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); {; if(proj_i[iVar] <= 0.0); {; lim_i[iVar] = phiMin(iPoint,iVar);; proj_i[iVar] = min(proj_i[iVar], -eps);; }. if(proj_j[iVar] <= 0.0); {; lim_j[iVar] = phiMin(jPoint,iVar);; proj_j[iVar] = min(proj_j[iVar], -eps);; }; }. #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); {; lim_i[iVar] = (lim_i[iVar]-phi(iPoint,iVar))/proj_i[iVar];; limiter(iPoint,iVar) = min(limiter(iPoint,iVar), lim_i[iVar]);. lim_j[iVar] = (lim_j[iVar]-phi(jPoint,iVar))/proj_j[iVar];; limiter(jPoint,iVar) = min(limiter(jPoint,iVar), lim_j[iVar]);; }; }. #pragma omp parallel for schedule(dynamic,TARGET_CHUNK_SIZE); for(size_t iPoint=0; iPoint<nPoint; ++iPoint); {; #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); {; double lim = limiter(iPoint,iVar);; limiter(iPoint,iVar) = lim*(lim+2)/(lim*lim+lim+2);; }; }; }; ```; Again to keep things short here is the parallel and SIMD point-loop version (like for gradients it is very similar to the scalar and sequential version).; ```C++; void computeLimiters(size_t nPoint,; size_t nVar,; size_t nDim,; const Adjacency<4>& adj,; const Matrix& coords,; const Matrix& phi,; const VectorOfMatrix& grad,; Matrix& limiter); {; const size_t SIMDLEN = 4;; using FltVec = Array<double,SIMDLEN>;. // working variables; FltVec phiMax[MAXNVAR], phiMin[MAXNVAR], prjMax[MAXNVAR], prjMin[MAXNVAR];. const double eps = numeric_limits<double>::epsilon();. #pragma omp parallel for schedule(dynamic,128) private(phiMax,phiMin,prjMax,prjMin); for(size_t iPoint=0; iPoint<nPoint; iPoint+=SIMDLEN); {; for(size_t iVar=0; iVar<nVar; ++iVar); {; phiMin[iVar] = phiMax[iVar] = phi.getVec(iPoint,iVar);; prjMax[iVar] = eps;; prjMin[iVar] = -eps;; }. for(size_t iNeigh=0; iNeigh<adj.nNeighbor(iPoint); ++iNeigh); {; auto jPoint = adj.jPoi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-530593912:7069,schedul,schedule,7069,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530593912,1,['schedul'],['schedule']
Energy Efficiency,"a for those inserts will be in a slightly weird format, which will make `SparseMatrix::updateBlocks` a bit harder on the eye, more on that later._. ## MUSCL Reconstruction; The MUSCL reconstruction, characteristic of upwind schemes, is the simplest building block to show the (negative) implications of storing the data as structures of arrays (SoA) on the performance of some operations.; Here is the most basic numerics you can think of, reconstruct and average (the dummy matrix loop was to benchmark the writes this is to benchmark the reads); ```c++; void computeResidual(size_t nVar,; size_t nDim,; const vector<size_t>& colorStart,; const vector<size_t>& edgeIdx,; const vector<pair<size_t,size_t> >& connectivity,; const Matrix& coords,; const Matrix& phi,; const VectorOfMatrix& grad,; const Matrix& limiter,; Matrix& residual); {; residual.setZero();. for(size_t color=0; color<colorStart.size()-1; ++color); #pragma omp parallel for schedule(dynamic,CHUNK_SIZE); for(size_t k=colorStart[color]; k<colorStart[color+1]; ++k); {; size_t iEdge = edgeIdx[k];; size_t iPoint = connectivity[iEdge].first;; size_t jPoint = connectivity[iEdge].second;. double d_ij[MAXNDIM];; for(size_t iDim=0; iDim<nDim; ++iDim); d_ij[iDim] = 0.5*(coords(jPoint,iDim)-coords(iPoint,iDim));. for(size_t iVar=0; iVar<nVar; ++iVar); {; double phiL = phi(iPoint,iVar);; double phiR = phi(jPoint,iVar);. for(size_t iDim=0; iDim<nDim; ++iDim); {; phiL += limiter(iPoint,iVar)*grad(iPoint,iVar,iDim)*d_ij[iDim];; phiR -= limiter(jPoint,iVar)*grad(jPoint,iVar,iDim)*d_ij[iDim];; }. double flux = 0.5*(phiL+phiR);. residual(iPoint,iVar) += flux;; residual(jPoint,iVar) -= flux;; }; }; }; ```; after vectorizing this to handle multiple edges simultaneously with the SIMD-friendly type the core of the loop becomes; ```c++; using FltVec = Array<double,SIMDLEN>;; ... FltVec d_ij[MAXNDIM];; for(size_t iDim=0; iDim<nDim; ++iDim); d_ij[iDim] = (coords.getVec(jPoint,iDim)-coords.getVec(iPoint,iDim))*0.5;. for(size_t iVar=0; iV",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-535977206:6384,schedul,schedule,6384,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206,1,['schedul'],['schedule']
Energy Efficiency,"cally equivalent) introduced to limiters and gradients in #834, yes. > What's the advantage of having one numerics term per thread?. It is a requirement, we need to write data into numerics before using them, multiple threads cannot write to the same location (i.e. the internal structures of CNumerics) therefore one per thread is required. > ...Also, I think I missed the point where the numerics container is extended beyond MAX_TERMS. The allocation of space for one numerics per thread is done above in line 1995 of my 21 Dec 2019 comment: `...MAX_TERMS*omp_get_max_threads()...`.; The instantiation of one numerics per thread is then done by executing the rest of the preprocessing in parallel and instead of using `XYZ_TERM` using `XYZ_TERM+offset` where `offset = thread_id * MAX_TERMS`.; I think someone mentioned this (maybe Tim) that we could revisit the ownership relations of the numerics classes, i.e. allocate them as members of their respective solvers, which if we do, we can think of having a purpose built container that automates the per-thread creation and access. > Why are they redefined each time inside the loop?; > Is this for efficiency reasons?. Referring to variables being declared inside loops. One stylist reason is that declaring everything at the top of a function is the C way of doing things, the C++ people whose books/blogs I've read and talks I've watched, recommend keeping namespaces (the inside of the loop being one) as clean as possible.; The only reason not to do this is if you explicitly want re-use, in the case of trivial types this does not improve efficiency, and in the context of OpenMP code it can create issues. Just like we need one numerics per thread, if we declare variables outside a parallel loop the default OpenMP behaviour is to consider them shared, and concurrent writes to shared locations = gdb and many bad words xD.; **EDIT:** I should mention here that if the parallel region is started before the variable declarations they beco",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/843#issuecomment-577684728:2062,allocate,allocate,2062,https://su2code.github.io,https://github.com/su2code/SU2/pull/843#issuecomment-577684728,1,['allocate'],['allocate']
Energy Efficiency,"ch request to make it clearer. Request: Use nomenclature consistent with the C++ interface (point instead of node, etc.); Reason: People who know the C++ interface will know how to use the python wrapper straight away, people who learn how to use the python wrapper will be able to understand the C++ implementation (without needing a translation layer in their mind all the time). Request: Return connectivity/adjacency as local indices instead of global; Reason: This is the natural way of referencing data in an MPI code, local indices correspond directly to data stored in the partition thereby making it more efficient to access (without global-to-local conversions, which are much more expensive than local-to-global). Furthermore, the local ordering strategy improves the efficiency of loops (over edges, neighboring points, etc.). Request: Do not apply unnecessary ""transformations"" to the connectivity/adjacency as part of the API; Reason: Increases the maintenance burden and makes for a less versatile API. By returning the local indices that form a marker or element, it is trivial to retrieve any other data for those indices (the ""transformation""). For example, the solution at those points, the point coordinates, whether the points are halo or domain points, the global indices, etc.; This way, by adding a **single** function to the API e.g. get the global index of a point of element, the functionality of the API grows a lot more because the user can apply the function to **any** connectivity/adjacency function. Request: Do not offer too many overloads of the same function; Reason: Increases the maintenance burden and it's returning the data in structures that are not very efficient, namely vector of vectors. It is much easier to offer domain-wide data access on the python side, as a very small function that can be part of wrapper utilities (i.e. live only in python but not c++). It may even be more efficient since you make a numpy array/matrix instead of lists of lists.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1300#issuecomment-1402197827:1722,efficient,efficient,1722,https://su2code.github.io,https://github.com/su2code/SU2/pull/1300#issuecomment-1402197827,2,['efficient'],['efficient']
Energy Efficiency,"dy (which currently directly calls the sym_plane boundary) -> that recovered the results obtained with the 'older' version. The steady state results (onera m6) show that both codes deliver the same results (of course with some minor differences). So far so good. Unsteady cases are a bit trickier: the latest 2D results of @RoccoBombardieri show pretty much no difference including the first timesteps. The onera m6 case in contrast converges to the same (steady-state) results for both code version eventually but their initial transient phase differs quite significantly. . A possible explanation for the different initial transient phase: In both implementations a ""reflected state"" is constructed where the normal component of the velocity is subtracted [once in the older code version & twice in the newer version]. I.e. subtracting the normal component of velocity twice means mirroring the velocity along the symmetry plane. The newer code version is a bit ""stronger"" in enforcing the boundary conditions which could lead to the reduced oscillation in CD and CL. If we agree that both code versions produce physically correct results for steady cases and unsteady cases that were integrated long enough in time to get rid of the influence of the initial condition ... then we are left with this initial transient phase that differs. Of course if there is more evidence that one or the other version produces physically ""better"" results I would love to see that. Until then, both initial oscillations are equally correct/uncorrect in my opinion. [I'll add a few words about the adjoint here later]. [I'll add the idea of an FSI case of @cvencro here later where the initial phase has a major impact]; Consider an FSI computation of an airfoil where the trailing edge can exhibit flutter (periodic up-and-down-movement of the trailing edge) in certain flow regimes. Now if during the initial transient the forces on the airfoil are higher than in the converged state then the fluttering can be e",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/828#issuecomment-563314747:1758,reduce,reduced,1758,https://su2code.github.io,https://github.com/su2code/SU2/issues/828#issuecomment-563314747,1,['reduce'],['reduced']
Energy Efficiency,"eature_adapt branch`. 2. downloaded the Adaptive 2D NACA 0012 example (https://pyamg.saclay.inria.fr/pyamgexamples.html#2dnaca): `adap_NACA0012.cfg`, `mesh_NACA0012_inv.su2`, `NACA0012_ini.dat`. 3. added the following lines to the config:; ```; % Type of sensor used for adaptation; % Options include GOAL (adjoint-based), MACH, PRES; PYADAP_SENSOR= GOAL; % Objective function used for goal-oriented adaptation; OBJECTIVE_FUNCTION= LIFT; % Maximum cell size for adaptation; PYADAP_HMAX= 500.0; % Minimum cell size for adaptation; PYADAP_HMIN= 1e-9; % Gradation factor (typically 1.2-1.8); PYADAP_HGRAD= 1.8; % Norm used for adaptation; % 1.0 or 2.0 recommended for inviscid flows; % 4.0 recommeneded for viscid; ADAP_NORM= 4.0; % Approximate mesh size (NPOI) at each level; PYADAP_COMPLEXITY= (30000, 60000, 120000); % Number of adaptations performed at each level; PYADAP_SUBITE= (3, 3, 3); ```. 4. run the following command: `$ python3 SU2_RUN/mesh_adaptation_amg.py -f adap_ONERAM6.cfg -n 8`. The response I have obtained is the following:; ```; SU2-AMG Anisotropic Mesh Adaptation. Mesh adaptation options:; PYADAP_COMPLEXITY : (30000, 60000, 120000); PYADAP_SUBITE : (2, 2, 2); PYADAP_SENSOR : MACH; PYADAP_HMAX : 500.0; PYADAP_HMIN : 1e-9; PYADAP_HGRAD : 1.8; PYADAP_FLOW_ITER : (2999, 4999, 6999); PYADAP_ADJ_ITER : (2999, 4999, 6999); PYADAP_CFL : (10.0, 15.0, 20.0); PYADAP_RDG : NO. The ./adap folder was deleted. Generating GMF background surface mesh.; ## WARNING: MISSING SU2 MESH FILE KEYWORD: NCORNERS=.; Initial CFD solution is provided.; ```. As expected, a `./ADAP` folder was created, containing these docs: `amg_back_meshb`, `config_CFD.cfd`, `log.err`, `log.out` (sizes 0 byte), `mesh_NACA0012_inv.su2` (link to the mesh), `NACA0012_ini.dat` (link to the file.dat). Did I perform the procedure correctly? Or did I miss something?; If it is correct and complete, which file contains the adaptive mesh? How can I use it since there is no new .su2 file? . Thank you for the big help",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/948#issuecomment-737134105:1256,adapt,adaptation,1256,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-737134105,2,['adapt'],"['adaptation', 'adaptive']"
Energy Efficiency,"enced only once per color (this definition gives you the basis of a greedy algorithm to color edges).; - **Scatter to gather transformations**: Edge quantities (e.g. fluxes) are computed and stored on one pass (i.e. we read from 2 locations and write to 1), on a second pass, over points, we reduce (e.g. sum) the edge quantities for each point, again a gather access pattern. It may also be possible to convert the entire algorithm to a loop over points instead of edges.; - **Atomic operations or locks**: Here when a thread wants to write to a memory location it either needs to do so atomically (this is essentially an operations that always goes through main memory and forces cache coherency) or it needs to acquire a *lock* for the point it is writing to, if it fails to acquire the *lock* (because another thread has it) it needs to wait. None of these is without drawbacks.; - **Coloring** reduces temporal locality, edges are sorted in increasing order of the point indices to reduce cache misses, this means small groups of contiguous edges will share the same ""iPoint"", coloring single edges destroys this. Furthermore coloring either requires edges to be re-sorted by color, or if the edge indices of each color are instead kept in arrays, performance will suffer due to increased indirection which confounds the hardware pre-fetcher.; This can be mitigated to some extent by coloring groups of edges, groups of edges of the same color can be processed simultaneously, but within each group edges need to be processed serially. However grouping will reduce how much parallelism can be exploited within each color.; - **Gather to scatter** will in general use more memory due to the intermediate variables and extra adjacency information needed. If the entire algorithm is transformed performance may suffer as some computations may have to be repeated.; However, some reductions are possible without intermediate variables, for example when assembling the system matrix for implicit sche",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-529662724:5069,reduce,reduces,5069,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-529662724,2,['reduce'],"['reduce', 'reduces']"
Energy Efficiency,"ents. Registers are at the very top of the memory hierarchy, for any computation to be performed data needs to be in registers.; An AVX register is 256 bits wide, that means 4 lanes of doubles or 8 of floats, AVX-512 (available in Xeon-Phi and SkylakeX processors) doubles the size. By GPU standards these are rookie numbers. **Why should we care about SIMD?**; Because it is the only way to use the whole silicon, by and large vector instructions have the same latency and throughput of their scalar versions, therefore speedups proportional to the number of SIMD lanes are possible in compute-bound code.; As we saw in #716 there is some of that in the numerics, do not expect 4x speed-ups though, low order unstructured FVM is known to be bandwidth-bound, vectorization helps a bit there too (instructions are also data that needs to travel to the CPU) (maybe for explicit schemes and 8 SIMD lanes, maybe). **Relation with data structures**; There is only one efficient way to move data between memory and registers, via `load` and `store` instructions (they do come in multiple flavors). That is, pointing to a memory location and reading or writing N elements of contiguous data.; It is not the only way, it is also possible to `gather` and `scatter` data. That is populating the register from non-contiguous locations and vice versa. This is about one order of magnitude slower, to the point where if the computations are very simple it may not pay-off to vectorize. **Relation with algorithms**; Some form of `gather` and `scatter` is required in unstructured CFD, which means SIMD has a price of admission. Some thought needs to go into designing algorithms that amortize that cost by maximizing the so called FLOP/Byte ratio, and mask the latency of those operations by being able to start computing as soon as the first element of data is available. **What elements should we try to process simultaneously?**; The choice is between multiple geometric primitives (edges/points) or multiple s",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-529662724:1147,efficient,efficient,1147,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-529662724,1,['efficient'],['efficient']
Energy Efficiency,"gy terms? I'm talking about terms like:. ![molecular and turbulent diffusion of tke](https://latex.codecogs.com/gif.latex?\left(&space;\mu&space;&plus;&space;\frac{\mu_t}{\sigma_k}\right)\frac{\partial&space;k}{\partial&space;x_j}). This term is listed both in Wilcox's ""Turbulence Modeling for CFD"" book and the [NASA TMR website](https://turbmodels.larc.nasa.gov/implementrans.html). NASA's page basically just copies what Wilcox states, and then says ""This expression in the energy equation is also sometimes neglected."". Rumsey clarified his position in a [2009 report](https://ntrs.nasa.gov/archive/nasa/casi.ntrs.nasa.gov/20090015399.pdf), saying that ""when considering high Mach number compressible boundary layer flows using k-omega models, the conservation of total energy should be configured to include the contribution of the turbulent kinetic energy k... It is sometimes common practice to ignore these effects, which is certainly justified when k is signficantly smaller than the square of the mean velocity."" . But he also states: ""Note that in CFL3D, the turbulence models are decoupled from the mean flow equations, k is *not* included in the definition of the total energy, and the diffusion of k does not appear in the mean flow energy equation for its models tested here."" He also omitted the 2/3 \rho k term in both the production and the turbulent stress tensor, and found that it made little difference even for M=10 wall-bounded flows. SU2's version of SST is in a weird spot right now, where it's using the turbulent kinetic energy in some places but not others. It's using it here:. + Total energy definition; + Production of turbulent kinetic energy; + RANS evolution equations; + Eddy viscosity definition. But not here:. + Molecular and turbulent diffusion of turbulent kinetic energy in the total energy conservation equation; + Isotropic part of the turbulent stress tensor. Is there any rationale behind this split, aside from simply stating that ""this seems to work?""",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/797#issuecomment-548886007:1347,energy,energy,1347,https://su2code.github.io,https://github.com/su2code/SU2/issues/797#issuecomment-548886007,7,['energy'],['energy']
Energy Efficiency,"he residual of cells i and j, or store the edge fluxes and then, on a second point-loop perform the summation of fluxes for each cell, with the direction being accounted by the same adjacency information used in the point-loop GG gradient computation.; If we consider only the update of residuals the two strategies are fairly equivalent performance wise, the tie breaker is the matrix updates. ## Matrix Updates; By this I mean the `addBlock`, `subBlock` we do (two times each) to update diagonal and off-diagonal blocks for each edge.; Here is a dummy numerics loop that does nothing else but setting blocks in the matrix (with colouring).; ```c++; void testLoop1(const vector<size_t>& colorStart,; const vector<size_t>& edgeIdx,; const vector<pair<size_t,size_t> >& connectivity,; double** blk_i, double** blk_j,; SparseMatrix& matrix); {; matrix.setZero();. for(size_t color=0; color<colorStart.size()-1; ++color); #pragma omp parallel for schedule(dynamic,CHUNK_SIZE); for(size_t k=colorStart[color]; k<colorStart[color+1]; ++k); {; size_t iEdge = edgeIdx[k];; size_t iPoint = connectivity[iEdge].first;; size_t jPoint = connectivity[iEdge].second;. matrix.addBlock(iPoint, iPoint, blk_i);; matrix.addBlock(iPoint, jPoint, blk_j);. matrix.subBlock(jPoint, jPoint, blk_j);; matrix.subBlock(jPoint, iPoint, blk_i);; }; }; ```; This and a few more memory reads is why we can't have nice things, i.e. massive speedups with vectorization. Believe it or not this loop sets ~75% of the maximum speed at which the residual edge loop can run (bandwidth bottleneck).; Don't be sad though, we can make a few things about it better:; - We can store the blocks we insert contiguously so the writes can be vectorized (this would be done using a container so that we still have `(i,j)` access syntax);; - On each insertion we have to first look for the block by traversing the `colInd` (column index) array, we can instead map the diagonal blocks to the corresponding points and the off-diagonal blocks to the e",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-535977206:1827,schedul,schedule,1827,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206,1,['schedul'],['schedule']
Energy Efficiency,"here a retroactive application of unit testing may also make sense. I am copying Pat Miller, formerly with DoE, who may have more experience on whether such unit testing approaches were useful/worth the investment in some major codes he worked on. Best,. Juan. On Jun 4, 2019, at 2:14 PM, Clark Pederson <notifications@github.com<mailto:notifications@github.com>> wrote:. I propose adding a unit-testing framework and unit-tests to SU2. After chatting with @economon<https://github.com/economon>, I've decided to move the discussion here to get additional input. What is unit testing?. For those not familiar with unit testing, unit testing allows the testing of small bits of behavior, ideally using isolated bits of code. It is not intended to replace validation testing or formal verification tests. Instead, it serves a unique purpose. Consider the three following use cases:. * You're developing a new feature, and you want to test it to see if it works. You could do a full simulation, but that takes a lot of time and computing power. You want to check if your new behavior behaves as you suspect before you throw a lot of resources at it.; * You submit a PR and discover that one of the regression tests has failed. But...why? You know that something is broken, but its hard to track down what broke. You want more granular test coverage that can demonstrate what broke.; * You are fixing a very small bug. You know that you should prove that your bug fix worked, but it doesn't seem logical to dedicate an entire validation case to one small bug fix. You want to write a small test for a small fix. In all of these cases, unit testing fills a unique role. Unit testing increases time spent in development, but decreases the amount of time spent in bug-fixing and maintaining. For more information, see this relevant Stack Exchange question.<https://scicomp.stackexchange.com/questions/206/is-it-worthwhile-to-write-unit-tests-for-scientific-research-codes>. What do I propose?. My research g",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499250240:1460,power,power,1460,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240,1,['power'],['power']
Energy Efficiency,"iEdge repeated. This concept of padding is important for something else, you may have noticed that the SIMD point-loops I showed make no provisions for values of nPoint that are not multiples of SIMDLEN, that is because the containers already took care of that by rounding up the number of columns, and so that seemingly out-of-bounds access is safe (ain't encapsulation great). Padding also aligns the start of each column, thus it is a generally good thing to have (on large dimensions) whether used or not. Here is a relative performance recap before we talk bout parallelization. | Code | Edge | Edge, SIMD on vars | Point | Point, SIMD on points |; | ---- | ---- | ---- | ---- | ---- |; | **Speed** | 1.0 | 2.2 | 0.83 | 1.35 |. **Parallel execution**. I will start at the end for this, all it takes to parallellize the points loops with OpenMP is to take this:; ```C++; for(size_t iPoint=0; iPoint<nPoint; iPoint+=SIMDLEN); ```; And add some pixie dust; ```C++; #pragma omp parallel for schedule(dynamic,128); for(size_t iPoint=0; iPoint<nPoint; iPoint+=SIMDLEN); ```; This means each thread gets chunks of 128 loop iterations (512 points) to work on, assigned in a dynamic way, the 4 core speedup (still relative to our reference) is **3.8** for the SIMD code and **2.8** for the scalar code. Parallelizing the edge loops is a bit more intricate, as this:; ```C++; for(size_t iEdge=0; iEdge<nEdge; ++iEdge); {; size_t iPoint = connectivity[iEdge].first;; size_t jPoint = connectivity[iEdge].second;; ```; Becomes:; ```C++; for(size_t color=0; color<colorStart.size()-1; ++color); #pragma omp parallel for schedule(dynamic,CHUNK_SIZE); for(size_t k=colorStart[color]; k<colorStart[color+1]; ++k); {; #if SORT_BY_COLOR==1; size_t iEdge = k;; #else; size_t iEdge = edgeIdx[k];; #endif. size_t iPoint = connectivity[iEdge].first;; size_t jPoint = connectivity[iEdge].second;; ```; Apologies for the macro but it is just to illustrate that if we re-sort edge data after coloring the edge index is th",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-530328194:12291,schedul,schedule,12291,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530328194,1,['schedul'],['schedule']
Energy Efficiency,"it testing may also make sense. I am copying Pat Miller,; > formerly with DoE, who may have more experience on whether such unit; > testing approaches were useful/worth the investment in some major codes he; > worked on.; >; > Best,; >; > Juan; >; >; > On Jun 4, 2019, at 2:14 PM, Clark Pederson <notifications@github.com>; > wrote:; >; > I propose adding a unit-testing framework and unit-tests to SU2. After; > chatting with @economon <https://github.com/economon>, I've decided to; > move the discussion here to get additional input.; > What is unit testing?; >; > For those not familiar with unit testing, unit testing allows the testing; > of small bits of behavior, ideally using isolated bits of code. It is not; > intended to replace validation testing or formal verification tests.; > Instead, it serves a unique purpose. Consider the three following use cases:; >; > - You're developing a new feature, and you want to test it to see if; > it works. You could do a full simulation, but that takes a lot of time and; > computing power. You want to check if your new behavior behaves as you; > suspect before you throw a lot of resources at it.; > - You submit a PR and discover that one of the regression tests has; > failed. But...why? You know that something is broken, but its hard to track; > down what broke. You want more granular test coverage that can demonstrate; > what broke.; > - You are fixing a very small bug. You know that you should prove that; > your bug fix worked, but it doesn't seem logical to dedicate an entire; > validation case to one small bug fix. You want to write a small test for a; > small fix.; >; > In all of these cases, unit testing fills a unique role. Unit testing; > increases time spent in development, but decreases the amount of time spent; > in bug-fixing and maintaining.; >; > For more information, see this relevant Stack Exchange question.; > <https://scicomp.stackexchange.com/questions/206/is-it-worthwhile-to-write-unit-tests-for-scientific-re",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499278427:2487,power,power,2487,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427,1,['power'],['power']
Energy Efficiency,"le (and the user will decide which one turn on of off using templet of paraview); > ; > MARKER_MONITORING, MARKER_DESIGNING: The main idea is to be able to compute to different integrals over the surfaces: one for simulation and the other for design. e.g. You maybe want to include all the solid surfaces and fan faces, and charging stations in MARKER_MONITORING to compute (Drag-Thrust) but in MArKER DESIGN you are only interested on the wing surface for design.; > ; > DV_MARKER. This is an unfortunately name. At the very beginning the mesh deformation capability was developed only for shape design (DV = Design Variables). We should generalize the names of the grid deformation parameters without using DV. Thanks!; Francisco. On Aug 18, 2015, at 4:31 AM, Heather Kline notifications@github.com wrote:. > Thanks Tom; > I agree that we should make things easy to understand. ; > My thinking was that most users will want to know what parts of the mesh they are moving, but don't necessarily need to know what's happening underneath - if they specify the entire mesh the code just reverts to the more efficient method. But (from the users perspective) it may be just as easy to have a separate specification for scaling the entire mesh.; > ; > In terms of moving it to SU2_MSH; I think it may make sense to include scale/rotate/translate in SU2_MSH, but I think it would be confusing to have two options that do the same thing. I would side with separate option names (this would also eliminate a loop over markers in this pull request); > ; > On this topic, I have sometimes found MARKER_DESIGNING and DV_MARKER to be confusing; on their own they sound very similar, in the description MARKER_DESIGNING is where the objective function is evaluated - but in the code, it's not clear what MARKER_DESIGNING does - the surfaces specified by MARKER_MONITORING are what are actually used to evaluate the objective function value.; > ; > There may be other similar areas where config file options could ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/187#issuecomment-133010923:1470,efficient,efficient,1470,https://su2code.github.io,https://github.com/su2code/SU2/pull/187#issuecomment-133010923,1,['efficient'],['efficient']
Energy Efficiency,"nd max neighbors as small local variables instead of large global ones due to the way those values are determined. This is where the memory from the extra adjacency information is recovered. Like @economon said, fusing the gradient kernel with the limiter kernel is trivial with these point loops, and I do not think it affects readability much since one can clearly tell ""what is what"" (I will not put it here but it really is a matter of copy paste), including the boundaries could be a bit more challenging, but I will give performance number nevertheless. **Performance summary**. | Code | Edge | Edge, SIMD on vars | Point | Point, SIMD on points |; | ---- | ---- | ---- | ---- | ---- |; | **Speed 1 core** | 1.0 | 1.75 | 1.25 | 2.0 |; | **Speed 4 cores** | 2.45 | 2.7 | 4.5 | 7.0 |. The basic point version does not lose to edge based because, contrary to gradients, it does not require duplication of computations while benefiting from sequential access to gradients.; Again the point-based implementation does really well in parallel, limiters are more compute intensive and so the scaling is almost perfect.; For reference, limiters are 1.9 times more expensive to compute than gradients with the reference edge version. With point loops, SIMD, and in parallel, gradients and limiters cost the same. If we consider the combined cost of gradients and limiters, and compare the scalar ""edge+edge"" with the SIMD ""point+point"" and ""fused point"" we get:. | G+L Approach | Edge+Edge | Point+Point | Fused Point |; | ---- | ---- | ---- | ---- |; | **Speed 1 core** | 1.0 | 1.75 | 1.85 |; | **Speed 4 cores** | 2.3 | 5.35 | 6.1 |. Fusing point loops only gives a 14% improvement vs separate loops due to the difference in gathered data, only one gather is amortized and the remaining memory accesses are very efficient.; Nevertheless if it can be done nicely while accounting for boundaries (which may have to be handled outside the loop) it could allow some memory savings for the discrete adjoint.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-530593912:11465,efficient,efficient,11465,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530593912,1,['efficient'],['efficient']
Energy Efficiency,"ntax);; - On each insertion we have to first look for the block by traversing the `colInd` (column index) array, we can instead map the diagonal blocks to the corresponding points and the off-diagonal blocks to the edge (remember we insert ""by the edge"").; - We can fuse numerics (possibly using the [decorator](https://en.wikipedia.org/wiki/Decorator_pattern) pattern) so that we write to the matrix only once per iteration, which means we only need to clear the diagonal blocks and not the entire matrix because we can **set** the off-diagonals instead of **updating** them. Assuming these modification our dummy loop becomes; ```c++; void testLoop2(const vector<size_t>& colorStart,; const vector<size_t>& edgeIdx,; const vector<pair<size_t,size_t> >& connectivity,; const double* blk_i, const double* blk_j,; SparseMatrix& matrix); {; matrix.setDiagZero();. for(size_t color=0; color<colorStart.size()-1; ++color); #pragma omp parallel for schedule(dynamic,CHUNK_SIZE); for(size_t k=colorStart[color]; k<colorStart[color+1]; ++k); {; size_t iEdge = edgeIdx[k];; size_t iPoint = connectivity[iEdge].first;; size_t jPoint = connectivity[iEdge].second;. matrix.updateBlocks(iEdge, iPoint, jPoint, blk_i, blk_j);; }; }; ```; where; ```c++; STRONGINLINE void SparseMatrix::updateBlocks(size_t edge,; size_t row, size_t col, const double* blk_i, const double* blk_j); {; size_t bii = diagMap[row], bij = edgeMap[edge].first,; bjj = diagMap[col], bji = edgeMap[edge].second;. #pragma omp simd; for(size_t k=0; k<blkSz; ++k); {; coeffs[bii+k] += blk_i[k]; coeffs[bij+k] = +blk_j[k];; coeffs[bji+k] = -blk_i[k]; coeffs[bjj+k] -= blk_j[k];; }; }; ```; This is **47% faster**, which for a memory bound task is massive!; Yes, this does increase the memory footprint a bit (makes CSysMatrix 4% larger for a 3D problem) but I can get that back by sharing sparsity patterns and maps across turbulence and bulk flow (I think @talbring was already working on this in the template linear solver branch he had starte",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-535977206:3612,schedul,schedule,3612,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206,1,['schedul'],['schedule']
Energy Efficiency,"o so atomically (this is essentially an operations that always goes through main memory and forces cache coherency) or it needs to acquire a *lock* for the point it is writing to, if it fails to acquire the *lock* (because another thread has it) it needs to wait. None of these is without drawbacks.; - **Coloring** reduces temporal locality, edges are sorted in increasing order of the point indices to reduce cache misses, this means small groups of contiguous edges will share the same ""iPoint"", coloring single edges destroys this. Furthermore coloring either requires edges to be re-sorted by color, or if the edge indices of each color are instead kept in arrays, performance will suffer due to increased indirection which confounds the hardware pre-fetcher.; This can be mitigated to some extent by coloring groups of edges, groups of edges of the same color can be processed simultaneously, but within each group edges need to be processed serially. However grouping will reduce how much parallelism can be exploited within each color.; - **Gather to scatter** will in general use more memory due to the intermediate variables and extra adjacency information needed. If the entire algorithm is transformed performance may suffer as some computations may have to be repeated.; However, some reductions are possible without intermediate variables, for example when assembling the system matrix for implicit schemes only the diagonal entries can result in race conditions, now it just so happens that each diagonal entry is equal to the negated corresponding column sum.; - **Atomics** are terrible for the performance of code that writes frequently to memory (i.e. bandwidth-bound code), they do not increase the memory footprint and so make sense for compute-bound code.; Bugs due to a missing atomic can be very hard to debug (but any race condition is). Coloring is what one sees most in the literature, and yet I lean towards gather-to-scatter. Fewer things can go wrong with it as it is ea",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-529662724:5733,reduce,reduce,5733,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-529662724,1,['reduce'],['reduce']
Energy Efficiency,"oj_i <= 0.0) {; lim_i = phiMin(iPoint,iVar);; proj_i = min(proj_i, -eps);; }; ```; This is the bit of code that selects the right delta based on the sign of the projection and avoids division by zero, this less readable version does the same with one branch instead of three, simplifying ""if"" statements is essential for vectorization, so to make the comparison fair I used the same strategy in the scalar code. To make this post shorter I will show the SIMD and parallel version of the code right away. Trying to process multiple edges instead of multiple variables has all the problems I mentioned for the gradients, so again we use the trick of templating on the number of variables.; ```C++; template<size_t nVar>; void computeLimiters_impl(size_t nPoint,; size_t nDim,; const vector<size_t>& colorStart,; const vector<size_t>& edgeIdx,; const vector<pair<size_t,size_t> >& connectivity,; const Matrix& coords,; const Matrix& phi,; const VectorOfMatrix& grad,; Matrix& phiMax,; Matrix& phiMin,; Matrix& limiter); {; // initialize; #pragma omp parallel for schedule(dynamic,TARGET_CHUNK_SIZE); for(size_t iPoint=0; iPoint<nPoint; ++iPoint); {; #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); {; phiMax(iPoint,iVar) = phi(iPoint,iVar);; phiMin(iPoint,iVar) = phi(iPoint,iVar);; limiter(iPoint,iVar) = 2.0;; }; }. // find min and max neighbor; for(size_t color=0; color<colorStart.size()-1; ++color); #pragma omp parallel for schedule(dynamic,CHUNK_SIZE); for(size_t k=colorStart[color]; k<colorStart[color+1]; ++k); {; #if SORT_BY_COLOR==1; size_t iEdge = k;; #else; size_t iEdge = edgeIdx[k];; #endif. size_t iPoint = connectivity[iEdge].first;; size_t jPoint = connectivity[iEdge].second;. // some hand-holding needed for simd min/max with gcc,; // one of the min/max operands needs to be on the stack; // (so the compiler knows the two do not overlap?); double phi_i[nVar], phi_j[nVar];. #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); {; phi_i[iVar] = phi(iPoint,iVar);; phi_j",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-530593912:3892,schedul,schedule,3892,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530593912,1,['schedul'],['schedule']
Energy Efficiency,"or]; k<colorStart[color+1]; ++k); {; #if SORT_BY_COLOR==1; size_t iEdge = k;; #else; size_t iEdge = edgeIdx[k];; #endif. size_t iPoint = connectivity[iEdge].first;; size_t jPoint = connectivity[iEdge].second;. // some hand-holding needed for simd min/max with gcc,; // one of the min/max operands needs to be on the stack; // (so the compiler knows the two do not overlap?); double phi_i[nVar], phi_j[nVar];. #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); {; phi_i[iVar] = phi(iPoint,iVar);; phi_j[iVar] = phi(jPoint,iVar);; }. #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); {; phiMax(iPoint,iVar) = max(phiMax(iPoint,iVar), phi_j[iVar]);; phiMin(iPoint,iVar) = min(phiMin(iPoint,iVar), phi_j[iVar]);; phiMax(jPoint,iVar) = max(phiMax(jPoint,iVar), phi_i[iVar]);; phiMin(jPoint,iVar) = min(phiMin(jPoint,iVar), phi_i[iVar]);; }; }. for(size_t color=0; color<colorStart.size()-1; ++color); #pragma omp parallel for schedule(dynamic,CHUNK_SIZE); for(size_t k=colorStart[color]; k<colorStart[color+1]; ++k); {; #if SORT_BY_COLOR==1; size_t iEdge = k;; #else; size_t iEdge = edgeIdx[k];; #endif. size_t iPoint = connectivity[iEdge].first;; size_t jPoint = connectivity[iEdge].second;. // i to j vector; double d_ij[3] = {0.0, 0.0, 0.0};. for(size_t iDim=0; iDim<nDim; ++iDim); d_ij[iDim] = 0.5*(coords(jPoint,iDim)-coords(iPoint,iDim));. // projections; double proj_i[nVar], proj_j[nVar];. #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); proj_i[iVar] = proj_j[iVar] = 0.0;. for(size_t iDim=0; iDim<nDim; ++iDim); {; #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); {; proj_i[iVar] += d_ij[iDim]*grad(iPoint,iVar,iDim);; proj_j[iVar] -= d_ij[iDim]*grad(jPoint,iVar,iDim);; }; }. // choose the ""right"" delta based on sign of projection; // and avoid division by zero; double lim_i[nVar], lim_j[nVar];. #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); {; lim_i[iVar] = phiMax(iPoint,iVar);; lim_j[iVar] = phiMax(jPoint,iVar);; }. const double eps = numeric_limit",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-530593912:5259,schedul,schedule,5259,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530593912,1,['schedul'],['schedule']
Energy Efficiency,"r with me I am almost done, and I will summarise the results in the form of a proposal (I'll probably put that at the top of the first post). ## ""Real"" numerics; Real in the sense that the flop to byte ratio (amount of computation per amount of data) is comparable to a real numerics scheme, say Roe for example.; The simplest way to do this is to combine the example code for MUSCL reconstruction with the matrix updates code and add something compute heavy between input and output, e.g. a number of matrix-matrix multiplications, here is some pseudo code for what I did:; ```c++; void computeResidual(size_t nVar,; size_t nDim,; const vector<Connectivity<SIMDLEN> >& connectivities,; const Matrix& coords,; const Matrix& phi,; const VectorOfMatrix& grad,; const Matrix& limiter,; RowMajorMatrix& residual,; SparseMatrix& matrix); {; using FltVec = Array<double,SIMDLEN>;. residual.setZero();; matrix.setDiagZero();. size_t color = 0;; for(const auto& connectivity : connectivities); {; #pragma omp parallel for schedule(dynamic,CHUNK_SIZE); for(size_t iEdge=0; iEdge<connectivity.size(); iEdge+=SIMDLEN); {; auto iPoint = connectivity.first_vec(iEdge);; auto jPoint = connectivity.second_vec(iEdge);. FltVec d_ij[MAXNDIM];; for(size_t iDim=0; iDim<nDim; ++iDim); d_ij[iDim] = (coords.getVec(jPoint,iDim)-coords.getVec(iPoint,iDim))*0.5;. FltVec phiL[MAXNVAR], phiR[MAXNVAR], flux[MAXNVAR],; blk_i[MAXNVAR*MAXNVAR],; blk_j[MAXNVAR*MAXNVAR];. for(size_t iVar=0; iVar<nVar; ++iVar); {; // Reconstruction goes here. flux[iVar] = (phiL[iVar]+phiR[iVar])*0.5;; }. // some silly way to make the Jacobians depend on the reconstruction; for(size_t iVar=0; iVar<nVar; ++iVar); for(size_t jVar=0; jVar<nVar; ++jVar); blk_j[iVar*nVar+jVar] = (phiL[iVar]*phiR[jVar]-phiL[jVar]*phiR[iVar])*0.5;. // the matrix-matrix multiplications; for(size_t i=0; i<WORKITERS; ++i) {; // blk_i = blk_j * blk_j; for(size_t k=0; k<nVar*nVar; ++k) blk_j[k] = blk_i[k];; }. // something akin to a dissipation term; for(size_t iVar",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-539177957:1070,schedul,schedule,1070,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-539177957,1,['schedul'],['schedule']
Energy Efficiency,"sible idea until we get to areas of the code where different primitives require different treatment, that and the fact that the number of variables might not fit evenly in the number of lanes can lead to very tricky and non-generic code. Nevertheless if the same code were to be applied to e.g. 4 solution variables, this strategy would likely perform better as it avoids the pesky gather/scatter operations.; Processing multiple geometric primitives can make full utilization of whatever register size (important on GPU's), the code is just as readable (as I hope to show), but gather/scatter cannot be avoided. ### Intro to SPMD; This one is simpler, in a nutshell multiple threads operate on the sub domain of an MPI rank.; The typical implementation has each thread executing a chunk of an edge or cell loop. **Why should we care about SPMD?**; Reduce the communication overhead resulting from domain decomposition and improve load balancing, important for strong scaling.; Some algorithms are more efficient that way, e.g. the ADT (as mentioned by Edwin), the current MG also seems to work better on fewer partitions, and additive versions of preconditioners like the ILU or LU-SGS lose effectiveness with number of partitions.; Optimum hardware utilization, for routines that are bandwidth-bound it may be beneficial to use all threads available, while for compute-bound or ""algorithm-bound"" ones this may not be the case. **Relation with algorithms**; A typical edge loop reads from 2 locations and writes to 2 locations (gather / scatter access pattern, not to be confused with the instructions) processing multiple edges at the same time can therefore result in race conditions where multiple threads try to update the data of the same point.; There are 3 ways to address this:; - **Coloring**: Edges are colored (grouped) such that edges of the same color have no risk of race conditions, i.e. each endpoint is referenced only once per color (this definition gives you the basis of a greedy ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-529662724:3247,efficient,efficient,3247,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-529662724,1,['efficient'],['efficient']
Energy Efficiency,"size_t color=0; color<colorStart.size()-1; ++color); #pragma omp parallel for schedule(dynamic,CHUNK_SIZE); for(size_t k=colorStart[color]; k<colorStart[color+1]; ++k); {; #if SORT_BY_COLOR==1; size_t iEdge = k;; #else; size_t iEdge = edgeIdx[k];; #endif. size_t iPoint = connectivity[iEdge].first;; size_t jPoint = connectivity[iEdge].second;; ```; Apologies for the macro but it is just to illustrate that if we re-sort edge data after coloring the edge index is the loop index, otherwise the edge indices for each color need to be stored in a separate array.; Note that for each edge loop we first loop over colors, then over same-color edges, it is this inner loop that can run in parallel in chunk sizes that are multiple of the group size considered during coloring. There is some runtime cost on entry to every #omp parallel section, with coloring we enter one such section once by color. I mentioned in the introduction coloring reduces locality and therefore performance, here is the effect of color group size on the execution time of the scalar code on one thread:; ![image](https://user-images.githubusercontent.com/38071223/64686801-2e0d3d00-d481-11e9-82a0-c56e5554cd83.png); The hassle-free option of not sorting by color ""never"" recovers the performance of the base algorithm, things are even worse for the SIMD version where even at group size of 8192 with re-sorting the slowdown is 14%. Running the edge-loop version on 4 cores (8192 group + sorting) we get speedups (relative to reference) of **1.98** and **2.04** for the scalar and SIMD versions respectively (yes I quadruple checked).; If you are keeping track of the number two things should surprise you, the first is that there is no difference between scalar and SIMD now (the vector instruction are still there though), the second is that 4 cores give only a 2x speedup. The reason for both is: the implementation is very memory-bound, and so throwing more compute at it, either in the form of more cores or more lanes, does",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-530328194:13769,reduce,reduces,13769,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530328194,1,['reduce'],['reduces']
Energy Efficiency,"t the initialization routines of CSysMatrix and CSysVector are only called by the master thread.; For the second issue I made the associated classes as const-correct as possible, that should at least make someone think twice before changing a member variable of those classes. The risk is still there for input variables as an algorithm development aspect... For example `MatrixVectorProductTransposed` cannot be made thread-parallel as simply/naively as its normal counterpart. ### Communication Model; The MPI + Threads communication model is very simple, currently only the master thread calls MPI routines (including `Error`), this requires thread barriers before and after the communication to make sure the correct values are passed and _seen_ by all threads.; We can test other alternatives in the future but at the moment this does not seem to be a significant bottleneck.; _Worksharing_ constructs have implicit barriers at completion, for CSysVector routines I used `nowait` modifiers, it is safe to call those routines in sequence since the loop sizes, and static work scheduling specifications are identical.; However, routines that access a CSysVector in a different way, should have an explicit barrier before using the vector (or risk having undefined behaviour). You will see these barriers on entry to matrix-vector product, and every `ComputeXXXPreconditioner` (if you don't, let me know xD). I think those routines are large enough to amortise the cost of this. ### Performance; Disclaimer:; - We are talking about linear solvers only, **you will not see a global improvement yet**.; - The large global improvements from ""hybridization"" will come from the multigrid behaving better on less decomposed domains, and from the ability to independently tune the number of cores used in the linear preconditioners. For now the objective is ""just"" not to loose performance while gaining flexibility.; - The performance of MPI+threads with 1 thread per rank will be worse than just MPI (no",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/830#issuecomment-562646766:2240,schedul,scheduling,2240,https://su2code.github.io,https://github.com/su2code/SU2/pull/830#issuecomment-562646766,1,['schedul'],['scheduling']
Energy Efficiency,"t trickier: the latest 2D results of @RoccoBombardieri show pretty much no difference including the first timesteps. The onera m6 case in contrast converges to the same (steady-state) results for both code version eventually but their initial transient phase differs quite significantly. . A possible explanation for the different initial transient phase: In both implementations a ""reflected state"" is constructed where the normal component of the velocity is subtracted [once in the older code version & twice in the newer version]. I.e. subtracting the normal component of velocity twice means mirroring the velocity along the symmetry plane. The newer code version is a bit ""stronger"" in enforcing the boundary conditions which could lead to the reduced oscillation in CD and CL. If we agree that both code versions produce physically correct results for steady cases and unsteady cases that were integrated long enough in time to get rid of the influence of the initial condition ... then we are left with this initial transient phase that differs. Of course if there is more evidence that one or the other version produces physically ""better"" results I would love to see that. Until then, both initial oscillations are equally correct/uncorrect in my opinion. [I'll add a few words about the adjoint here later]. [I'll add the idea of an FSI case of @cvencro here later where the initial phase has a major impact]; Consider an FSI computation of an airfoil where the trailing edge can exhibit flutter (periodic up-and-down-movement of the trailing edge) in certain flow regimes. Now if during the initial transient the forces on the airfoil are higher than in the converged state then the fluttering can be excited where the initial transient can be seen as an activation energy. If you were to e.g. ramp up flow speed/conditions slowly up to the same magnitude as before one might end up without fluttering. So based on the flow history there might exist multiple ""stable"" states. Cheers, Tobi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/828#issuecomment-563314747:2786,energy,energy,2786,https://su2code.github.io,https://github.com/su2code/SU2/issues/828#issuecomment-563314747,1,['energy'],['energy']
Energy Efficiency,"tests are first added to document the related existing behavior. These tests serve to check that the existing behavior isn't damaged by the new code. Then new tests are added to prove that the new behavior is working correctly. For bug fixes, the process is simpler. A test is added to confirm that something is not behaving as expected. Then the code is fixed to make the test pass. What frameworks are available?. For a unit testing framework, here are the most popular options, with the following pros and cons:. Roll-your-own. * Requires no external dependencies; * The most flexible option; * Involves the most work to setup; * Will lack some of the more advances features of mature unit-testing frameworks. Boost Test. * Can be header only, statically linked, or dynamically linked; * If statically or dynamically linked, then Boost is not very lightweight; * Easy to add if you're already using Boost. Google Test. * Most common unit-testing framework; * Can be easily combined with Google's powerful GMock mocking library; * Compiling and linking can be somewhat painful. Catch2. * Used by FEniCS; * Makes unit tests easily readable with lots of syntactic sugar.; * Has a very simple syntax; * Is header-only; * Requires C++11 compilation; * Not as feature rich as Google Test or Boost Test. Questions. * How do developers feel about adding unit tests to SU2?; * If a unit-testing framework were added to SU2, would you actually use it?; * Do developers have a preference (or experience with) any of the unit testing frameworks?; * Should unit tests be expected when submitting PRs?. —; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/698?email_source=notifications&email_token=AA5FFRG5U3Z55N4W2XWQED3PY3LJ5A5CNFSM4HTDQXQKYY3PNVWWK3TUL52HS4DFUVEXG43VMWVGG33NNVSW45C7NFSM4GXUGGLA>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AA5FFRHOPE2MUJ2Z5RRV4HTPY3LJ5ANCNFSM4",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499250240:4849,power,powerful,4849,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240,1,['power'],['powerful']
Energy Efficiency,"ts in config_structure to make doxygen pretty; - Bug fixing; - Merge branch 'develop'; - EA in ft^2; - further update to config; - Merge remote-tracking branch 'upstream/develop' into upstream_dev; - Minor changes; - Updated NF BC; - More adjustments; - Small update; - Final update Nearfield BC; - added massflowrate as option for cauchy criteria, more config file comments; - Merge remote-tracking branch 'upstream/develop' into upstream_dev; - paraview output modified/added back in for current version for SU2_DEF; - Merge branch 'develop' into feature_dualoutput; - Removed deprecated options from quicstart config.; - Working version of the compressible actuator disk; - Updated fixed CL mode.; - Very minor change; - Merge branch 'develop' into feature_dualoutput; - Final push to 3.2.9; - Merge branch 'develop'; - Minor change; - Minor change; - Small change; - Minor change; - Bug fixing: unsigned short val_vertex --> unsigned long val_vertex; - CFL adapt now works for adjoint problems; - Merge branch 'develop' into feature_dualoutput; - Fixing a typo; - Fix in the Euler BC for grid movement cases; - merging and fixing conflicts bwtn feature_dealloc and develop; - dealloc; - Time spectral fix.; - Merging some recent bug fixes from master into the develop branch to keep nsync.; - Merge branch 'feature_gridvel_fix' into develop; - Merge remote-tracking branch 'upstream/develop' into feature_Deallocation; - correcting issues, adding more deallocation; - fixed uninitialized pointers in CConfig; - further deallocation; - some corrections needed to pass reg tests; - fixed some dealloc issues that caused errors in euler adj; - modifications needed to (mostly) pass reg tests; all run w/o segfault. File Changes; - D Articles/AIAA_2013-0287.pdf (0) ; - D Articles/AIAA_2014-0243.pdf (0) ; - M Common/doc/docmain.hpp (46) ; - M Common/include/config_structure.hpp (1038) ; - M Common/include/config_structure.inl (191) ; - M Common/include/dual_grid_structure.hpp (43) ; - M Common/inc",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:9856,adapt,adapt,9856,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['adapt'],['adapt']
Energy Efficiency,xcbkptlist (0) ; - I SU2_IDE/Xcode/SU2_CFD.xcodeproj/xcuserdata/fpalacios.xcuserdatad/xcschemes/SU2_CFD.xcscheme (0) ; - I SU2_IDE/Xcode/SU2_DEF.xcodeproj/project.pbxproj (0) ; - I SU2_IDE/Xcode/SU2_DOT.xcodeproj/project.xcworkspace/xcshareddata/SU2_DOT.xccheckout (0) ; - I SU2_IDE/Xcode/SU2_GEO.xcodeproj/project.xcworkspace/xcshareddata/SU2_GEO.xccheckout (0) ; - I SU2_IDE/Xcode/SU2_MSH.xcodeproj/project.pbxproj (0) ; - D SU2_IDE/Xcode/SU2_PRT.xcodeproj/fpalacios.mode1v3 (0) ; - D SU2_IDE/Xcode/SU2_PRT.xcodeproj/fpalacios.pbxuser (0) ; - D SU2_IDE/Xcode/SU2_PRT.xcodeproj/project.pbxproj (0) ; - D SU2_IDE/Xcode/SU2_PRT.xcodeproj/project.xcworkspace/contents.xcworkspacedata (0) ; - D SU2_IDE/Xcode/SU2_PRT.xcodeproj/project.xcworkspace/xcshareddata/SU2_DDC.xccheckout (0) ; - I SU2_IDE/Xcode/SU2_SOL.xcodeproj/project.pbxproj (0) ; - I SU2_IDE/Xcode/SU2_SOL.xcodeproj/xcuserdata/fpalacios.xcuserdatad/xcschemes/SU2_SOL.xcscheme (0) ; - I SU2_MSH/include/SU2_MSH.hpp (0) ; - I SU2_MSH/obj/Makefile.am (0) ; - I SU2_MSH/obj/Makefile.in (0) ; - I SU2_MSH/src/SU2_MSH.cpp (0) ; - D SU2_PRT/bin/.gitignore (0) ; - D SU2_PRT/include/SU2_PRT.hpp (0) ; - D SU2_PRT/obj/Makefile.am (0) ; - I SU2_PRT/obj/Makefile.in (0) ; - D SU2_PRT/src/SU2_PRT.cpp (0) ; - D SU2_PY/2DChannel.py (0) ; - D SU2_PY/3DChannel.py (0) ; - I SU2_PY/Makefile.am (0) ; - I SU2_PY/Makefile.in (0) ; - I SU2_PY/SU2/**init**.py (0) ; - I SU2_PY/SU2/eval/design.py (0) ; - I SU2_PY/SU2/eval/functions.py (0) ; - I SU2_PY/SU2/eval/gradients.py (0) ; - I SU2_PY/SU2/io/config.py (0) ; - I SU2_PY/SU2/io/config_options.py (0) ; - I SU2_PY/SU2/io/data.py (0) ; - I SU2_PY/SU2/io/filelock.py (0) ; - I SU2_PY/SU2/io/redirect.py (0) ; - I SU2_PY/SU2/io/state.py (0) ; - I SU2_PY/SU2/io/tools.py (0) ; - I SU2_PY/SU2/mesh/adapt.py (0) ; - I SU2_PY/SU2/mesh/tools.py (0) . Patch Links:; - https://github.com/su2code/SU2/pull/174.patch; - https://github.com/su2code/SU2/pull/174.diff; —; Reply to this email directly or view it on GitHub.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:27627,adapt,adapt,27627,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['adapt'],['adapt']
Integrability," - Updated GetEngine_Properties; - Fix to the last commit; - Small bug; - Merge branch 'develop' into feature_MPI; - merging; - SU2_SOL and SU2_CFD are working; - Preliminary, but complete, implementation of SU2_DEF; - More updates; - Working version; - Complete implementation (validate); - Working version of SU2_DEF; - Final push before moving to the develop branch; - New MPI (removing SU2_PRT); - Merged in Ben's ParMETIS integration and fixed some conflicts.; - Merge branch 'benkirk-parmetis_integration' into feature_MPI; - ParMETIS geometry routines have been copied over but are not activated yet.; - Small change to ParMETIS include.; - ParMETIS can now be activated for testing (PARMETIS=YES in config).; - Updated MG; - Updated EA subrotuine; - Small fix; - Fixing memory leak; - Fixing memory leaks; - Dev release v.3.2.6; - Increasing MAX_NUMBER_MARKER; - Working version with ParMETIS. Fixed bug in global index. Now clean up and testing...; - Cleaned version of ParMETIS routines with better console output during partitioning.; - Small bug in initial element division.; - Made arrays in ParMETIS call dynamic.; - Fixed compiler warnings and added MPI directives so that the pure serial code works with the ParMETIS routines.; - Bootstrap on zion.; - Added some typecasts. Still tracking down a memory problem...; - Critical bug fix for vtxdist array.; - Partial fix; - More MPI improvements.; - Fixing a bug in SU2_DEF; - Updated BC_ActDisk_Boundary (MPI); - Merge remote-tracking branch 'upstream/develop' into develop; - changing solidboundary setting to be heatflux OR euler etc instead of AND, also working on doxygen documentation; - Dynamic allocation for some marker-related arrays.; - visualize part taken out to match upstream/dev; - Collection of improvements; - Release 3.2.7; - Fixing LOW_MEMORY_OUTPUT; - Updated LOW_MEMORY_OUTPUT option; - Updated configure.ac; - After autoconf; - Updated MPI; - Updated BC_Engine_Exhaust and BC_Engine_Bleed; - Small change; - Fixing",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:2105,rout,routines,2105,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['rout'],['routines']
Integrability," --with-ecj-jar=/usr/share/java/eclipse-ecj.jar --disable-libjava-multilib --with-ppl --with-cloog --with-tune=generic --with-arch_32=i686 --build=x86_64-redhat-linux; Thread model: posix; gcc version 4.4.6 20120305 (Red Hat 4.4.6-4) (GCC) ; configure:3999: $? = 0; configure:3988: gcc -V >&5; gcc: '-V' option must have argument; configure:3999: $? = 1; configure:3988: gcc -qversion >&5; gcc: unrecognized option '-qversion'; gcc: no input files; configure:3999: $? = 1; configure:4003: checking whether we are using the GNU C compiler; configure:4022: gcc -c conftest.c >&5; configure:4022: $? = 0; configure:4031: result: yes; configure:4040: checking whether gcc accepts -g; configure:4060: gcc -c -g conftest.c >&5; configure:4060: $? = 0; configure:4101: result: yes; configure:4118: checking for gcc option to accept ISO C89; configure:4181: gcc -c -g -O2 conftest.c >&5; configure:4181: $? = 0; configure:4194: result: none needed; configure:4216: checking dependency style of gcc; configure:4327: result: gcc3; configure:4345: checking whether gcc and cc understand -c and -o together; configure:4376: gcc -c conftest.c -o conftest2.o >&5; configure:4380: $? = 0; configure:4386: gcc -c conftest.c -o conftest2.o >&5; configure:4390: $? = 0; configure:4401: cc -c conftest.c >&5; configure:4405: $? = 0; configure:4413: cc -c conftest.c -o conftest2.o >&5; configure:4417: $? = 0; configure:4423: cc -c conftest.c -o conftest2.o >&5; configure:4427: $? = 0; configure:4445: result: yes; configure:4513: checking for ranlib; configure:4529: found /usr/bin/ranlib; configure:4540: result: ranlib; configure:4574: checking how to run the C preprocessor; configure:4605: gcc -E conftest.c; configure:4605: $? = 0; configure:4619: gcc -E conftest.c; conftest.c:11:28: error: ac_nonexistent.h: No such file or directory; configure:4619: $? = 1; configure: failed program was:; | /* confdefs.h */; | #define PACKAGE_NAME ""SU2""; | #define PACKAGE_TARNAME ""SU2""; | #define PACKAGE_VERSION ""4.1.0""; | ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:7293,depend,dependency,7293,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,1,['depend'],['dependency']
Integrability," and that other proposals are put forward so the discussion can be finalized at the developer’s meeting. Best,. Juan. On Sep 10, 2017, at 1:09 PM, Edwin van der Weide <notifications@github.com<mailto:notifications@github.com>> wrote:. Dear @rsanfer<https://github.com/rsanfer>,. I agree with you that the outer loop should be the loop over the number of physical disciplines involved in the problem and not the zones. Whether the individual disciplines contain one or multiple zones is irrelevant at this level, in my opinion. The loop over the multiple zones of a single discipline should take place at a much lower level, namely where the spatial residual is computed. At least, this should be the case for the fluid dynamics part. I don't know whether this is also the case for other disciplines, like structures. What about the following high level structure?. * Loop over the number of iterations, or time steps for unsteady problems.; * Loop over the number of pseudo-time steps for implicit time integration schemes; (DT_STEPPING_1ST and DT_STEPPING_2ND). For other cases this loop is 1.; * Loop over the number of disciplines involved; Call iterate for each of the disciplines.; In iterate:; * Loop over the (Runge-Kutta) stages; * Loop over the zones of a single discipline; Compute spatial residual.; Update the state vector.; * End loop over the zones of a single discipline.; Exchange halo data. This includes the halo data between zones of a single discipline.; * End loop over the (Runge-Kutta) stages; * End loop over the disciplines; * End loop over the pseudo time steps.; * End loop over the number of iterations, or time steps for unsteady problems. The weakness of this approach is that it still does not work when one would like to employ multi-stage time integration schemes for an unsteady, multi-disciplinary problem (does not work for the current implementation either), but maybe this is something we simply have to accept. The alternative is that all the details of the diff",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/437#issuecomment-328403160:2251,integrat,integration,2251,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328403160,1,['integrat'],['integration']
Integrability," commits or submit a pull request, the unit tests are run and checked. What is my vision for unit testing in SU2?. I am not proposing that we start trying to get 100% code coverage with pre-existing code. That would not provide a good return on investment. Instead, I see people adding unit tests as they write new code and as they find bugs. For each new behavior added to SU2, tests are first added to document the related existing behavior. These tests serve to check that the existing behavior isn't damaged by the new code. Then new tests are added to prove that the new behavior is working correctly. For bug fixes, the process is simpler. A test is added to confirm that something is not behaving as expected. Then the code is fixed to make the test pass. What frameworks are available?. For a unit testing framework, here are the most popular options, with the following pros and cons:. Roll-your-own. * Requires no external dependencies; * The most flexible option; * Involves the most work to setup; * Will lack some of the more advances features of mature unit-testing frameworks. Boost Test. * Can be header only, statically linked, or dynamically linked; * If statically or dynamically linked, then Boost is not very lightweight; * Easy to add if you're already using Boost. Google Test. * Most common unit-testing framework; * Can be easily combined with Google's powerful GMock mocking library; * Compiling and linking can be somewhat painful. Catch2. * Used by FEniCS; * Makes unit tests easily readable with lots of syntactic sugar.; * Has a very simple syntax; * Is header-only; * Requires C++11 compilation; * Not as feature rich as Google Test or Boost Test. Questions. * How do developers feel about adding unit tests to SU2?; * If a unit-testing framework were added to SU2, would you actually use it?; * Do developers have a preference (or experience with) any of the unit testing frameworks?; * Should unit tests be expected when submitting PRs?. —; You are receiving this bec",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499250240:4404,depend,dependencies,4404,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240,1,['depend'],['dependencies']
Integrability," feature.; - I imagine in some other places of the code similar routines were needed, for example small matrix inversion when computing gradients by weighted least squares (indeed what I need now is a QR decomposition). And, as an added bonus, I think some other areas of the code could be simplified / optimized by adopting a dense matrix format, for example:; - This snipped from the viscous numerics refactoring`for (iDim = 0; iDim < nDim; iDim++) {; TauElem[iDim] = 0.0;; for (jDim = 0; jDim < nDim; jDim++); TauElem[iDim] += tau[iDim][jDim]*UnitNormal[jDim];; }` would simply become `TauElem=tau*UnitNormal`; - Cumbersome allocations like `tau_jacobian_i = new su2double* [nDim];; for (iDim = 0; iDim < nDim; iDim++) {; tau_jacobian_i[iDim] = new su2double [nVar];; }` become `Matrix tau_jacobian_i(nDim,nVar);` and the cleanup is dealt with by the destructor of the object automatically. Now to answer some questions.; @juanjosealonso @erangit LAPACK and BLAS are indeed the standard, so much so that most (all?) newer libraries will call their routines behind the scenes.; However they considerably simplify the user interface by encapsulating the aforementioned construction/destruction and by exposing natural ways of manipulating the matrices, e.g. access entire rows, columns, blocks, etc.; Another issue with using BLAS routines is that we then need to provide a portable version that can be differentiated with CoDi or to implement the exact differentiation (similar to what is done in the ""solve_b"" routines). @vdweide that is not an issue with Eigen because everything is templated and therefore compatible with any type or class that overloads the appropriate arithmetic operators.; I have used it for over 2 years and I can attest to its compatibility with AD tools (I've tried 3), and speed when linked with a BLAS library, their native implementations are also very good, peeking inside their code... you can tell they know what they are doing. P.S. I feel this post needs a disclai",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/643#issuecomment-459653772:1905,rout,routines,1905,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459653772,1,['rout'],['routines']
Integrability," for numerics->SetBlaBla.; A template decorator in the sense that the class can be augmented simply by inheriting from another, along the lines of `class CRoeVisc : public CRoe, public CVisc` (to allow fusing residual and Jacobian contributions).; All this needs to be done with templates for the ""minimal indirection"" requirement. Which means for each numerical method we will have 4 explicit template instantiations (Euler2D, Euler3D, (RA)NS2D, (RA)NS3D) but in the end these are still polymorphic objects that will be instantiated by some factory function (i.e. it will look clean, especially because I will not port all methods in one go xD). The template machinery to support this is actually not too crazy:; ```c++; #include <array>; #include <cmath>. // An example type to use instead of the container that stores solution data for all vertices.; struct SolutionContainer; {; std::array<double,3> velocity;; std::array<double,3> areaVector;; };. using ResultType = double;. // We want classes with this interface.; class VirtualInterface; {; public:; virtual ResultType Compute(const SolutionContainer&) const = 0;; };. // The Compute method is to be composed via an inheritance chain, to do this; // we allow each building block to inherit from any class. These classes should; // be function objects that have no member variables, all data used in the; // resulting Compute method will be on the stack.; template<typename Base>; class ComputeArea : Base; {; protected:; // Different template instantiations will be made for; // 2D/3D to allow perfect loop unrolling.; enum : int {nDim = Base::nDim};. // To share variables between building blocks we will pass; // down a struct which is also composed by inheritance; struct WorkVarsType : Base::WorkVarsType; {; double area; // add ""area"" to the variables of Base; };; ; // The final implementation of Compute will be a call down the chain.; // The final constructed WorkVarsType is not known at this stage,; // hence we also template the me",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-622941617:2393,interface,interface,2393,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-622941617,1,['interface'],['interface']
Integrability," make someone think twice before changing a member variable of those classes. The risk is still there for input variables as an algorithm development aspect... For example `MatrixVectorProductTransposed` cannot be made thread-parallel as simply/naively as its normal counterpart. ### Communication Model; The MPI + Threads communication model is very simple, currently only the master thread calls MPI routines (including `Error`), this requires thread barriers before and after the communication to make sure the correct values are passed and _seen_ by all threads.; We can test other alternatives in the future but at the moment this does not seem to be a significant bottleneck.; _Worksharing_ constructs have implicit barriers at completion, for CSysVector routines I used `nowait` modifiers, it is safe to call those routines in sequence since the loop sizes, and static work scheduling specifications are identical.; However, routines that access a CSysVector in a different way, should have an explicit barrier before using the vector (or risk having undefined behaviour). You will see these barriers on entry to matrix-vector product, and every `ComputeXXXPreconditioner` (if you don't, let me know xD). I think those routines are large enough to amortise the cost of this. ### Performance; Disclaimer:; - We are talking about linear solvers only, **you will not see a global improvement yet**.; - The large global improvements from ""hybridization"" will come from the multigrid behaving better on less decomposed domains, and from the ability to independently tune the number of cores used in the linear preconditioners. For now the objective is ""just"" not to loose performance while gaining flexibility.; - The performance of MPI+threads with 1 thread per rank will be worse than just MPI (no free lunches). With this [small case](https://github.com/su2code/SU2/files/3933059/small_case.zip) using 8 cores off a machine with two 2650v4 CPU, Intel MPI 2018 + GCC 8.2, the hybrid (2 ranks of 4",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/830#issuecomment-562646766:2291,rout,routines,2291,https://su2code.github.io,https://github.com/su2code/SU2/pull/830#issuecomment-562646766,1,['rout'],['routines']
Integrability," scheme for a multi-physics problem. To obtain the design accuracy in time, this implies that the loop over the number of time stages is outside the loop over the number of physical disciplines. Hence at a very high level in the hierarchy, the details of the time integration should then be known. The situation becomes even more complicated when one would like to employ time integration schemes that allow for time accurate local time stepping, e.g. the ones we are currently working on for the DG solver. I won't bore you with all the details here, but those schemes basically require the loop over the multiple disciplines to be between the predictor and corrector step, while both these steps consist of multiple stages. Although it is probably possible to come up with a data structure that supports all this, the question is whether this is desirable. Apart from the fact that it would require a major overhaul in the high level design of SU2, the implementation will be less readable, especially for people that will be starting with the code. Also the parallelization may become significantly more complicated. The alternative is that for unsteady multi-physics problems, we put the restriction that only single stage time integration schemes can be used, e.g. DT_STEPPING_1ST and DT_STEPPING_2ND. In that case, the details of the time integration scheme can be hidden at the driver level, where we then simply have a loop over the number of physical disciplines. The consequence of course is that more advanced time integration schemes will not be available for multi-physics problems. In the above I just tried to picture what, in my opinion, the consequences are for either option. I don't have a preference for one of them. The only thing I wanted to make clear is that it is not possible to hide all the details of the time integration scheme at the driver level, while also having support for all possible time integration schemes for an unsteady multi-physics problem. Regards,. Edwin",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/437#issuecomment-328441926:1599,integrat,integration,1599,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328441926,5,['integrat'],['integration']
Integrability," threads arrive to that routine. This also makes the routines safe to call in serial.; The only ""dangerous"" things to do in parallel are to: manage memory for a shared object (multiple threads call `new` but there is only one shared pointer on which to call `delete`); writing to the same memory locations concurrently.; I tried to make the first issue debugable by asserting that the initialization routines of CSysMatrix and CSysVector are only called by the master thread.; For the second issue I made the associated classes as const-correct as possible, that should at least make someone think twice before changing a member variable of those classes. The risk is still there for input variables as an algorithm development aspect... For example `MatrixVectorProductTransposed` cannot be made thread-parallel as simply/naively as its normal counterpart. ### Communication Model; The MPI + Threads communication model is very simple, currently only the master thread calls MPI routines (including `Error`), this requires thread barriers before and after the communication to make sure the correct values are passed and _seen_ by all threads.; We can test other alternatives in the future but at the moment this does not seem to be a significant bottleneck.; _Worksharing_ constructs have implicit barriers at completion, for CSysVector routines I used `nowait` modifiers, it is safe to call those routines in sequence since the loop sizes, and static work scheduling specifications are identical.; However, routines that access a CSysVector in a different way, should have an explicit barrier before using the vector (or risk having undefined behaviour). You will see these barriers on entry to matrix-vector product, and every `ComputeXXXPreconditioner` (if you don't, let me know xD). I think those routines are large enough to amortise the cost of this. ### Performance; Disclaimer:; - We are talking about linear solvers only, **you will not see a global improvement yet**.; - The large global ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/830#issuecomment-562646766:1761,rout,routines,1761,https://su2code.github.io,https://github.com/su2code/SU2/pull/830#issuecomment-562646766,1,['rout'],['routines']
Integrability," would likely perform better as it avoids the pesky gather/scatter operations.; Processing multiple geometric primitives can make full utilization of whatever register size (important on GPU's), the code is just as readable (as I hope to show), but gather/scatter cannot be avoided. ### Intro to SPMD; This one is simpler, in a nutshell multiple threads operate on the sub domain of an MPI rank.; The typical implementation has each thread executing a chunk of an edge or cell loop. **Why should we care about SPMD?**; Reduce the communication overhead resulting from domain decomposition and improve load balancing, important for strong scaling.; Some algorithms are more efficient that way, e.g. the ADT (as mentioned by Edwin), the current MG also seems to work better on fewer partitions, and additive versions of preconditioners like the ILU or LU-SGS lose effectiveness with number of partitions.; Optimum hardware utilization, for routines that are bandwidth-bound it may be beneficial to use all threads available, while for compute-bound or ""algorithm-bound"" ones this may not be the case. **Relation with algorithms**; A typical edge loop reads from 2 locations and writes to 2 locations (gather / scatter access pattern, not to be confused with the instructions) processing multiple edges at the same time can therefore result in race conditions where multiple threads try to update the data of the same point.; There are 3 ways to address this:; - **Coloring**: Edges are colored (grouped) such that edges of the same color have no risk of race conditions, i.e. each endpoint is referenced only once per color (this definition gives you the basis of a greedy algorithm to color edges).; - **Scatter to gather transformations**: Edge quantities (e.g. fluxes) are computed and stored on one pass (i.e. we read from 2 locations and write to 1), on a second pass, over points, we reduce (e.g. sum) the edge quantities for each point, again a gather access pattern. It may also be possible to ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-529662724:3512,rout,routines,3512,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-529662724,1,['rout'],['routines']
Integrability,"(I was not expecting this many comments so quickly, thanks guys!). First let me clarify the intent.; I do not propose replacing the routines that deal with CSysMatrix, or change its format, all that (Krylov solvers, sparse approximate factorizations, etc.) is relatively independent from what I have in mind.; Nevertheless being able to use PETSc or HYPRE would be interesting as it would give us access to AMG, and @talbring 's branch feature_template_linear_solver would make such an integration compatible with AD.; What I would like is to have a ""CMatrixDense"" class, to give concrete examples:; - For RBF interpolation the guy who worked on it before me implemented his own Cholesky and LU factorizations, matrix-matrix, matrix-vector routines, etc.; - @jayantmukho recently needed some eigenvector decomposition's for the uncertainty quantification feature.; - I imagine in some other places of the code similar routines were needed, for example small matrix inversion when computing gradients by weighted least squares (indeed what I need now is a QR decomposition). And, as an added bonus, I think some other areas of the code could be simplified / optimized by adopting a dense matrix format, for example:; - This snipped from the viscous numerics refactoring`for (iDim = 0; iDim < nDim; iDim++) {; TauElem[iDim] = 0.0;; for (jDim = 0; jDim < nDim; jDim++); TauElem[iDim] += tau[iDim][jDim]*UnitNormal[jDim];; }` would simply become `TauElem=tau*UnitNormal`; - Cumbersome allocations like `tau_jacobian_i = new su2double* [nDim];; for (iDim = 0; iDim < nDim; iDim++) {; tau_jacobian_i[iDim] = new su2double [nVar];; }` become `Matrix tau_jacobian_i(nDim,nVar);` and the cleanup is dealt with by the destructor of the object automatically. Now to answer some questions.; @juanjosealonso @erangit LAPACK and BLAS are indeed the standard, so much so that most (all?) newer libraries will call their routines behind the scenes.; However they considerably simplify the user interface by encapsulat",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/643#issuecomment-459653772:132,rout,routines,132,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459653772,4,"['integrat', 'rout']","['integration', 'routines']"
Integrability,"---------------------------------------------------------+. The density plot is; - different from the original `issue_simplified` singlezone solution with implicit Euler and CFL=1000. ; - similar to the `issue_simplified` multizone solution with implicit Euler and CFL=0.1. . Similarly, the TKE plots:; - `issue_simplified` singlezone implicit Euler CFL=1000; ![tke-simplified-singlezone-impliciteuler](https://user-images.githubusercontent.com/72806890/140887227-fc2ed584-53cf-413d-b5ad-18d1a12f5e4a.png); - `issue_simplified` singlezone explicit Euler CFL=0.1; ![tke-simplified-singlezone-expliciteuler](https://user-images.githubusercontent.com/72806890/140887289-0d8725a2-e51b-4704-bdae-a51b492949bf.png); (it is ""red"" throughout the domain, except for the wall marker); - `issue_simplified` multizone explicit Euler CFL=0.1: (similar image, ""red"" everywhere except wall). **Thus, the difference in solutions observed above is due to the choice of implicit vs. explicit Euler and CFL, and not due to problems regarding the interface.**. Am I doing something wrong in the explicit Euler [cfg file](https://seafile.rlp.net/d/bb0fbb16eb414263b642/files/?p=%2Fsinglezone-simplfied-expliciteuler-cfl01.cfg&dl=1), whose diff to the [SU2/TestCases/rans/naca0012/turb_NACA0012_sst.cfg](https://github.com/su2code/SU2/blob/v7.2.0/TestCases/rans/naca0012/turb_NACA0012_sst.cfg) is as follows?. 27c27; < RESTART_SOL= NO; ---; > RESTART_SOL= YES; 45c45; < REYNOLDS_NUMBER= 1.0E6; ---; > REYNOLDS_NUMBER= 6.0E6; 70c70; < MARKER_HEATFLUX= ( circle, 0.0 ); ---; > MARKER_HEATFLUX= ( airfoil, 0.0 ); 76c76; < MARKER_PLOTTING= ( circle ); ---; > MARKER_PLOTTING= ( airfoil ); 79c79; < MARKER_MONITORING= ( circle ); ---; > MARKER_MONITORING= ( airfoil ); 88c88; < CFL_NUMBER= 0.1; ---; > CFL_NUMBER= 1000.0; 101c101; < ITER= 9999900; ---; > ITER= 99999; 162c162; < TIME_DISCRE_FLOW= EULER_EXPLICIT; ---; > TIME_DISCRE_FLOW= EULER_IMPLICIT; 177c177; < TIME_DISCRE_TURB= EULER_EXPLICIT; ---; > TIME_DISCRE_TURB= EULE",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1414#issuecomment-963921195:2499,interface,interface,2499,https://su2code.github.io,https://github.com/su2code/SU2/issues/1414#issuecomment-963921195,1,['interface'],['interface']
Integrability,".py script. The command used was:. ```; python3 $SU2_RUN/mesh_adaptation_amg.py -f adapt_Mesh.cfg -n 4; ```; The script initiates the mesh adaptation process as expected, with the following output:. ```; SU2-AMG Anisotropic Mesh Adaptation. Mesh adaptation options:; PYADAP_COMPLEXITY : (30000, 60000, 120000); PYADAP_SUBITE : (2, 2, 2); PYADAP_SENSOR : GOAL; PYADAP_HMAX : 500.0; PYADAP_HMIN : 1e-9; PYADAP_HGRAD : 1.8. ./adap exists. Removing old mesh adaptation in 10s.; The ./adap folder was deleted. Generating GMF background surface mesh.; Initial CFD solution is provided.; ```; However, no _adap\ite0_ folder gets created. ; The log.err file in the _adap/ini_ directory provides this traceback:. ```; Traceback (most recent call last):; File "".../mesh_adaptation_amg.py"", line 111, in <module>; ...; RuntimeError: ...; Error in TokenizeString(): two or more options before an ""="" sign in the configuration file.; terminate called after throwing an instance of 'int'; ...; *** Process received signal ***; Signal: Aborted (6); Signal code: (-6); ...; ```. The critical part of this error seems to be the Error in TokenizeString() message, suggesting an issue with parsing the configuration file. This error typically indicates a syntax problem, such as having multiple options on a single line without proper separation by an equal sign (=). However, upon reviewing _adap/ini/config_CFD.cfg_, was unable to find any lines that clearly violated this syntax rule. Could this error be indicative of a more subtle issue within the configuration file, or might it be related to specific aspects of the feature_adap branch? Any insights, suggestions, or guidance on how to troubleshoot this error would be greatly appreciated. If anyone has a working adapt_mesh.cfg file for a similar setup or for the feature_adap branch, I would be very interested in seeing it. Understanding the configuration details of a working example could be highly beneficial in resolving my issue. Thank you for your help!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/948#issuecomment-1847333809:1474,message,message,1474,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-1847333809,1,['message'],['message']
Integrability,"2' --with-bugurl=https://bugs.archlinux.org/ --enable-languages=c,c++,ada,fortran,go,lto,objc,obj-c++,d --enable-shared --enable-threads=posix --with-system-zlib --with-isl --enable-__cxa_atexit --disable-libunwind-exceptions --enable-clocale=gnu --disable-libstdcxx-pch --disable-libssp --enable-gnu-unique-object --enable-linker-build-id --enable-lto --enable-plugin --enable-install-libiberty --with-linker-hash-style=gnu --enable-gnu-indirect-function --enable-multilib --disable-werror --enable-checking=release --enable-default-pie --enable-default-ssp --enable-cet=auto gdc_include_dir=/usr/include/dlang/gdc; Thread model: posix; gcc version 9.2.1 20200130 (Arch Linux 9.2.1+20200130-2) ; ```; I did what you suggested and here is how my meson.build file looks.; ```; # If custom mpi mode is enabled, include and library pathes for MPI have to be set manually to env variables; if get_option('custom-mpi'); mpi_dep = []; mpi = true; # Otherwise they are automatically determined; else; mpi_dep = [dependency('mpich', required : get_option('with-mpi'))]; # mpi_dep = [dependency('mpi', language:'c', required : get_option('with-mpi')),; # dependency('mpi', language:'cpp', required : get_option('with-mpi'))]; #if mpi_dep[0].found() or mpi_dep[1].found(); # mpi = true; #endif; endif; ```; My SU2 build was successful but there were a couple of warnings.; Also, instead of 870 there were only 772 files in total. Is that okay?; ```; slimshady@arch-linux-hp-probook-g3-450: SU2HOME$ ./ninja -C build install; ninja: Entering directory `build'; [756/772] Generating 'SU2_PY/pySU2/_pysu2.so.p/pySU2.cxx'.; ../SU2_PY/pySU2/../../Common/include/mpi_structure.hpp:348: Warning 325: Nested struct not currently supported (Status ignored); [760/772] Generating 'SU2_PY/pySU2/_pysu2ad.so.p/pySU2ad.cxx'.; ../SU2_PY/pySU2/../../Common/include/mpi_structure.hpp:348: Warning 325: Nested struct not currently supported (Status ignored); [771/772] Installing files.; .; .; ```; Here is the [entire output fo",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1000#issuecomment-633139474:1556,depend,dependency,1556,https://su2code.github.io,https://github.com/su2code/SU2/issues/1000#issuecomment-633139474,3,['depend'],['dependency']
Integrability,"; Jehan; From: Heather Kline notifications@github.com; To: su2code/SU2 SU2@noreply.github.com ; Sent: Tuesday, May 12, 2015 11:43 AM; Subject: [SU2] Feature deallocation (#174). Bringing this branch up to date with current develop branch. ; Various deallocation changes; Some regression tests fail but all run. (previously was not the case); You can view, comment on, or merge this pull request online at:;   https://github.com/su2code/SU2/pull/174; Commit Summary; - Updated GetEngine_Properties; - Fix to the last commit; - Small bug; - Merge branch 'develop' into feature_MPI; - merging; - SU2_SOL and SU2_CFD are working; - Preliminary, but complete, implementation of SU2_DEF; - More updates; - Working version; - Complete implementation (validate); - Working version of SU2_DEF; - Final push before moving to the develop branch; - New MPI (removing SU2_PRT); - Merged in Ben's ParMETIS integration and fixed some conflicts.; - Merge branch 'benkirk-parmetis_integration' into feature_MPI; - ParMETIS geometry routines have been copied over but are not activated yet.; - Small change to ParMETIS include.; - ParMETIS can now be activated for testing (PARMETIS=YES in config).; - Updated MG; - Updated EA subrotuine; - Small fix; - Fixing memory leak; - Fixing memory leaks; - Dev release v.3.2.6; - Increasing MAX_NUMBER_MARKER; - Working version with ParMETIS. Fixed bug in global index. Now clean up and testing...; - Cleaned version of ParMETIS routines with better console output during partitioning.; - Small bug in initial element division.; - Made arrays in ParMETIS call dynamic.; - Fixed compiler warnings and added MPI directives so that the pure serial code works with the ParMETIS routines.; - Bootstrap on zion.; - Added some typecasts. Still tracking down a memory problem...; - Critical bug fix for vtxdist array.; - Partial fix; - More MPI improvements.; - Fixing a bug in SU2_DEF; - Updated BC_ActDisk_Boundary (MPI); - Merge remote-tracking branch 'upstream/develop' into develo",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:1667,rout,routines,1667,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['rout'],['routines']
Integrability,> @EvertBunschoten even if the performance isn't great this is a pretty small change so I think we can merge it. Do you have time to wrap it up and add a simple regression test?. I just added a test case and tutorial under the TestCases and Tutorials repo under the same branch name. I'm also writing a short tutorial on the SU2 website repo.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/2152#issuecomment-2271237145:133,wrap,wrap,133,https://su2code.github.io,https://github.com/su2code/SU2/pull/2152#issuecomment-2271237145,1,['wrap'],['wrap']
Integrability,"> @kursatyurt Hello, thank you so much for the lead.; > ; > Our initial scope mostly involved writing our own kernels and I did explore some libraries at the start - I was planning on using CUSP as well but my main concern was its lack of being updated to the newly compatible versions of the toolkit. cuSolver and cuBLAS do exist, but I chose to go ahead with a ""simple"" kernel implementation to have more control. I also felt that if I could keep the block size of the grid in optimal territory then they could be just as fast as those options (please do correct me if my reading of the literature or the situation was incorrect). To learn the basics, it's a good idea, but for large-scale projects, I prefer using existing libraries if possible.; Those libraries generally exploit state-of-the-art solution like mixed-precision computing. A gaming GPU is not way faster than a good CPU in double precision, but way faster in single precision, most of them have 64:1 ratio, however server class GPU have 2:1 ratio. Also when available they use vendor libraries like cuBLAS or hipBLAS. It is always nice to have you only care about connection and somebody else handle the solver as performant as possible. In future probably they will provide more and more solvers and it will be automagically works. It is kind of light-weight too, not a huge dependency like Trilinos or PETSc. ; > ; > I was not aware of Ginkgo and I will surely give it a go and try to produce some comparative results. I am currently super busy for this month and will get to working on the code with some delay.; > ; > Again, thank you for the lead!. I can test on various GPUs (P100/V100/A100 and 4070Mobile) on single node multi-gpu etc.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/2346#issuecomment-2397803409:1345,depend,dependency,1345,https://su2code.github.io,https://github.com/su2code/SU2/pull/2346#issuecomment-2397803409,1,['depend'],['dependency']
Integrability,"> Every time we push commits or submit a pull request, the unit tests are run; > and checked.; > What is my vision for unit testing in SU2?; >; > I am *not* proposing that we start trying to get 100% code coverage with; > pre-existing code. That would not provide a good return on investment.; >; > Instead, I see people adding unit tests as they write new code and as they; > find bugs. For each new behavior added to SU2, tests are first added to; > document the related existing behavior. These tests serve to check that the; > existing behavior isn't damaged by the new code. Then new tests are added; > to prove that the new behavior is working correctly. For bug fixes, the; > process is simpler. A test is added to confirm that something is not; > behaving as expected. Then the code is fixed to make the test pass.; > What frameworks are available?; >; > For a unit testing framework, here are the most popular options, with the; > following pros and cons:; > Roll-your-own; >; > - Requires no external dependencies; > - The most flexible option; > - Involves the most work to setup; > - Will lack some of the more advances features of mature unit-testing; > frameworks.; >; > Boost Test; >; > - Can be header only, statically linked, or dynamically linked; > - If statically or dynamically linked, then Boost is not very; > lightweight; > - Easy to add if you're already using Boost; >; > Google Test; >; > - Most common unit-testing framework; > - Can be easily combined with Google's powerful GMock mocking library; > - Compiling and linking can be somewhat painful; >; > Catch2; >; > - Used by FEniCS; > - Makes unit tests easily readable with lots of syntactic sugar.; > - Has a very simple syntax; > - Is header-only; > - Requires C++11 compilation; > - Not as feature rich as Google Test or Boost Test; >; > Questions; >; > - How do developers feel about adding unit tests to SU2?; > - If a unit-testing framework were added to SU2, would you actually; > use it?; > - Do developers hav",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499278427:5615,depend,dependencies,5615,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427,1,['depend'],['dependencies']
Integrability,"> How should I update my branch with upstream/develop? Should I merge upstream/develop into my branch (and push to my fork on github)? Or may I rebase my branch on top of upstream/develop (and force push to my fork on github)?. Both ways are legit, feel free to use which one is easier for you [here](https://www.freecodecamp.org/news/the-ultimate-guide-to-git-merge-and-git-rebase/) a comparison between them. It depends on the taste of the developer. . > I assume I should add myself to the _Individual Contributors_ section of AUTHORS.md, is that correct?. Yes",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1951#issuecomment-1466144727:414,depend,depends,414,https://su2code.github.io,https://github.com/su2code/SU2/pull/1951#issuecomment-1466144727,1,['depend'],['depends']
Integrability,"> I don't known how the process to find the alpha that gives you a given CL works, but could the derivative not be obtained from this process? i.e. you could avoid the FD step entirely. It is a simple proportional controller that will change the angle of attack after a number of iterations depending on the difference between the current CL and the target CL. . So if the the option `ITER_DCL_DALPHA = 0` then it will do exactly what you suggest. It calculates the derivative based on the last update. The only problem with that is, there is no guarantee that the simulation at the previous update was converged, so the derivative might be incorrect. . But you are correct, I could just do a really tiny update (order of delta AoA ~10^-6) at the end and calculate the finite difference using that value. Let me try that and see if the gradients it calculates are reasonable, or if the update is too small and it gets clouded by numerical errors.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/780#issuecomment-539606698:291,depend,depending,291,https://su2code.github.io,https://github.com/su2code/SU2/pull/780#issuecomment-539606698,1,['depend'],['depending']
Integrability,"> Note that you need to checkout this branch `fix_2d_periodic_rotation` (it is not in `develop` yet). Hi Pedro,; I checked the files you sent but building SU2 from source provided some errors:. - _MinGW64_ files provided from SU2 official website are corrupted and the installation crashes; however, it is possible to install the software but the .exe file mentioned in the installation guide won't be present. ; - After building _meson.py_ , the ninja installation command was line typed and the following alert message appeared "" **ninja: fatal: chdir to 'build' - No such file or directory** "". On a different laptop (with different user, to avoid the same mistakes) the following ERROR came up after the mason.py command line:; "" **'meson.py' is not recognized as an internal or external command, operable program or batch file** "". I don't know if any other user might have experienced the same errors. ; Anyway, are the bugfix files you published already available in the pre-compiled version? ; In the meanwhile, I'll try to figure out this inconvenient. Thank you in advance.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1562#issuecomment-1069325722:513,message,message,513,https://su2code.github.io,https://github.com/su2code/SU2/issues/1562#issuecomment-1069325722,1,['message'],['message']
Integrability,"> Thank you for the feedback but for 99% of cases it is easier for users if we download the dependencies for them. The philosophy behind SU2 has always been to provide as much of a self contained package as possible. But this check will allow users to use external dependencies just fine, as long as they happen to use an external 0.61.1?. ... I am not entirely sure I understand the issue here. You want to make it *easier* for users by downloading the dependencies, so you make it harder if they went and got their own dependencies? If someone has gone to the effort of getting their own dependencies instead of using your documented meson.py, it would seem like that inherently means they are the 1% of use cases and you could probably just leave them to it. Is the issue rather that only Meson 0.61.1 has been tested to work?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1945#issuecomment-1450921338:92,depend,dependencies,92,https://su2code.github.io,https://github.com/su2code/SU2/issues/1945#issuecomment-1450921338,5,['depend'],['dependencies']
Integrability,"> Thanks for pointing that out. I dont think it is intentional. Maybe we can use this PR also to fix this ?. That depends on how atomic we want these PRs to be. This PR is largely a refactoring PR, and shouldn't change any underlying performance. But adding extra calculations on source terms and wall conditions might change the performance of the code. The two changes are completely compatible, so combining them wouldn't be hard. Nevertheless, I propose we keep these changes separate, so that the purpose of each PR is clear and easy to see. In my mind, two small PRs are easier to check and review than one large PR. @talbring @economon What do you think? One big PR or two small PRs?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/626#issuecomment-458177675:114,depend,depends,114,https://su2code.github.io,https://github.com/su2code/SU2/pull/626#issuecomment-458177675,1,['depend'],['depends']
Integrability,"> The ""int"" in ""intIndexBased"" is for internal then? Because its type is also int, easy mistake to make xD. Yes.. The name was the first one I gave that routine. It somehow made it through.. Now that I had to type it several times I'd love to have it changed. But anyway.. I'm a bit puzzled that it seems to be so easy but maybe it's just as simple as you said - new approach inside `CDiscAdjSolver` and old in `CDiscAdjFEASolver` (if I got that correctly?). That would come in handy for all further developments. Let's wait for the validation. I'll also do one with this branch for the CHT adjoints tomorrow, just to be sure.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/803#issuecomment-542360883:153,rout,routine,153,https://su2code.github.io,https://github.com/su2code/SU2/pull/803#issuecomment-542360883,1,['rout'],['routine']
Integrability,"> You may want to remove the string based interface since it's known to be inneficient. When replacing the string-based with index-based look-up methods, the performance improves substantially. The figure below shows the average measured evaluation time (measured with chrono library) vs the number of output variables. It's clear that using index-based look-up methods results in reduced query time, as well as improved scaling. ![scaling_nVars](https://github.com/su2code/SU2/assets/38651601/31252439-ac6e-4f1b-82d4-e13a55d54c98)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/2214#issuecomment-1952521226:42,interface,interface,42,https://su2code.github.io,https://github.com/su2code/SU2/pull/2214#issuecomment-1952521226,1,['interface'],['interface']
Integrability,"> the off-PR comments can be integrated in this PR to clear that up a bit. If not that is OK as well. It's more than OK, the CHT implementation suffers a bit from being a single person's project.. you're very welcome to have a look over it! :-). > Can you add that option to the config_template.cfg together with that description, the valid inputs and the default. Actually I'm hesitating a bit adding it to the config template right now. I'd prefer to have `DIRECT_TEMPERATURE_ROBIN_HEATFLUX` as the default and ""hide"" the rest as developer's options for the moment.; The reason simply is that those different methods need to checked and validated against each other before we make them public.; E.g. I figured that for the incompressible CHT test case from the repo, there is a severe gap between the heatfluxes obtained from the ""averaged"" approach and the direct one, see below. ![heatflux_convergence](https://user-images.githubusercontent.com/22639394/72885197-bb9e4a80-3d07-11ea-9fad-a4d709dc511e.png). That needs to be cleared up first...",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/839#issuecomment-577108935:29,integrat,integrated,29,https://su2code.github.io,https://github.com/su2code/SU2/pull/839#issuecomment-577108935,1,['integrat'],['integrated']
Integrability,@EvertBunschoten even if the performance isn't great this is a pretty small change so I think we can merge it.; Do you have time to wrap it up and add a simple regression test?,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/2152#issuecomment-2269672071:132,wrap,wrap,132,https://su2code.github.io,https://github.com/su2code/SU2/pull/2152#issuecomment-2269672071,1,['wrap'],['wrap']
Integrability,"@Mick7: yep, I’ll look at that next. You may have noticed that the other routines for Loading and preparing adjacency are now general for any mesh reader, so all we need is to move the reader for the ASCII format into its own class. . @pcarruscag: there is at least one simple stretching function I have in some old code I can put in. Other elements would also be nice. It’s easy to cut the quads into tris (I have the same implementation for this in a python script) and hexas into tets. Might wait for a compelling need to add these features though, but I have no doubt we’ll add them",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/728#issuecomment-524179517:73,rout,routines,73,https://su2code.github.io,https://github.com/su2code/SU2/pull/728#issuecomment-524179517,1,['rout'],['routines']
Integrability,"@Nicola-Fonzi, you may as well want to consider importing as well the structural velocities in the interface from your external solver. That information is always available and gives a consistent definition of the displacement and velocity on both the grid motions and the interface for dynamic FSI problems -- not to mention simplifying the evaluation of the mesh adjoints.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1174#issuecomment-778326558:99,interface,interface,99,https://su2code.github.io,https://github.com/su2code/SU2/pull/1174#issuecomment-778326558,2,['interface'],['interface']
Integrability,"@bigfooted @economon and @pcarruscag . I created separate repo to demonstrate what I'm after in the simplest way possible: [FoamScience/AutoRegistering-Cpp-Classes](https://github.com/FoamScience/AutoRegistering-Cpp-Classes/commits/master). > If you're going to check the code, check CSolver first, then CEulerSolver ... - Commit FoamScience/AutoRegistering-Cpp-Classes@20ca601 implements the concept for a single Factory.; - (Make-believe) Standard solver classes are compiled to a library; - A (Make-beleive) Custom solver class is compiled to its own shared library; - By default, the make program knows only about CEulerSolver (from standard solvers lib); - But if you pass in a library name (eg. libCCustomSolvers.so), it gets loaded, symbols pulled and the registration map for CSolver gets updated with the new Solver automatically. - But it would bloat the code if things went this way, so commit FoamScience/AutoRegistering-Cpp-Classes@380c052 isolates self-registration code into 3 macros to:; - Declare the registration map and associated members; - Define and initialize registration-related members on the base class; - Register a class. If you only care about the interface and not how the thing is implemented, commit 380c052 is your target.; I took care to document the important parts of the code, so, please, dig in and let me know what you think. At this point, integrating this with SU2 (and at what parts, and when) is your call but If you decide to do so, l will help.; > And yes, I wrote my own build script so I can have direct control over the compiler and the linker. **One last note: I used ""dlopen"", so you will have to compile the code on Linux I suppose.**",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1058#issuecomment-680962672:1178,interface,interface,1178,https://su2code.github.io,https://github.com/su2code/SU2/issues/1058#issuecomment-680962672,2,"['integrat', 'interface']","['integrating', 'interface']"
Integrability,"@bigfooted Has there ever been any discussion regarding implementation of a `START_TIME=` capability into the config file? After going through the code a bit, it looks like doing this would be a good starting point for implementing ability to adjust deltaT mid-runs, as in general the code presumes `TimeIter*deltaT` as being the current time. This would be problematic for unsteady restarts that have a varying timestep. Plus, this would allow one to, without using the Python wrapper, use a different timestep in the config file for an unsteady restart. It also may clear up some confusion to have an explicit option for this, as in #2071. It can maybe look something like:. % Start time for restarting unsteady simulations; % = -1 for default calculation (START_TIME=RESTART_ITER*TIME_STEP); START_TIME=-1. Then `CConfig::GetPhysicalTime` could be appropriately updated and used in-place of all locations in the code where a physical time is manually calculated.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/2190#issuecomment-1870730956:478,wrap,wrapper,478,https://su2code.github.io,https://github.com/su2code/SU2/pull/2190#issuecomment-1870730956,1,['wrap'],['wrapper']
Integrability,"@clarkpede @EduardoMolina : yep, the issue is that the periodic and MPI communications are tangled up together in the current implementation. The main issue occurs when there are periodic points that are also ghost nodes. . Ideally the periodic and MPI would be separated, and the periodic communications would happen first so that all periodic BCs are synchronized before trying to send across partitions. Right now, the comms are mixed, so sometimes, we send old data at periodic points to their matching pair, which then gets updated in a later MPI comm. Therefore, the second call you have added to the MPI resends the periodic update to with the correct data that was updated with MPI in the first call. I hope this is clear.. Anyway, please go with this change as you have it. All of the MPI and periodic comms will be replaced with a cleaner/separated version right after v6.2.0 (you can see what I am working on in feature_mpi_periodic). I will likely need some help testing that soon :).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/649#issuecomment-463711280:353,synchroniz,synchronized,353,https://su2code.github.io,https://github.com/su2code/SU2/pull/649#issuecomment-463711280,1,['synchroniz'],['synchronized']
Integrability,"@talbring I agree with your assessment of Boost. I think it's a heavyweight solution to a lightweight use-case. We could always include just the unit-testing header (they offer a header-only version), but ""people may want to use more and more features of boost,"" as you point out. If we as developers want to add Boost as a formal dependency for SU2, then that seems like a fine route. But I have the feeling that many developers do not want to add a Boost dependency. Honestly, Boost UTF doesn't offer anything that we can't get from Google Test. Catch2 is definitely the simplest and easiest of the unit-testing frameworks I listed. The only sticking point is that it requires c++03, and that the full-feature version requires C++11.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-500393344:331,depend,dependency,331,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-500393344,3,"['depend', 'rout']","['dependency', 'route']"
Integrability,"@talbring Thanks for the quick and helpful answer! I'm looking at creating an ebuild/package for gentoo, compilation is a lot simpler than OpenFoam :P which is a big plus :). Anyway, I was looking at the old docs (the main docs still point to 6.0, I missed the red text that mentioned that somehow :P), not sure why, but you're right it's indeed mentioned in the 7.0 docs here https://su2code.github.io/docs_v7/Build-SU2-Linux-MacOS/#configuration-and-compilation. The ""Automatically installed dependencies"" section left me a bit confused because it sounded like the things listed there, which includes meson and ninja, would always get installed.; Maybe merging that section into the configuration and compilation section might help to make it more clear?. If you don't mind I have some additional questions:; - I didn't initialize the git submodule at all and configuration, compilation and running worked fine. Does this mean the CoDiPack and MeDiPack dependencies are optional? Or does this mean I could have a crash at runtime somewhere?; - Would it be possible to add a source package to the GitHub releases (in addition to the binary ones) that includes the (CoDiPack and MeDiPack) submodules? Unfortunately the GitHub provided source downloads don't include submodules.; - Are MKL and OpenBLAS build-time and exclusive options or can they both be compiled in and chosen at runtime?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/911#issuecomment-598751341:494,depend,dependencies,494,https://su2code.github.io,https://github.com/su2code/SU2/issues/911#issuecomment-598751341,2,['depend'],['dependencies']
Integrability,"@talbring Yes, I do. I can't uninstall it since it breaks other packages. @pcarruscag Yeah same for me. You can see it here:; ```; slimshady@arch-linux-hp-probook-g3-450: ~$ mpicc -v; mpicc for MPICH version 3.3.2; Using built-in specs.; COLLECT_GCC=gcc; COLLECT_LTO_WRAPPER=/usr/lib/gcc/x86_64-pc-linux-gnu/9.2.1/lto-wrapper; Target: x86_64-pc-linux-gnu; Configured with: /build/gcc/src/gcc/configure --prefix=/usr --libdir=/usr/lib --libexecdir=/usr/lib --mandir=/usr/share/man --infodir=/usr/share/info --with-pkgversion='Arch Linux 9.2.1+20200130-2' --with-bugurl=https://bugs.archlinux.org/ --enable-languages=c,c++,ada,fortran,go,lto,objc,obj-c++,d --enable-shared --enable-threads=posix --with-system-zlib --with-isl --enable-__cxa_atexit --disable-libunwind-exceptions --enable-clocale=gnu --disable-libstdcxx-pch --disable-libssp --enable-gnu-unique-object --enable-linker-build-id --enable-lto --enable-plugin --enable-install-libiberty --with-linker-hash-style=gnu --enable-gnu-indirect-function --enable-multilib --disable-werror --enable-checking=release --enable-default-pie --enable-default-ssp --enable-cet=auto gdc_include_dir=/usr/include/dlang/gdc; Thread model: posix; gcc version 9.2.1 20200130 (Arch Linux 9.2.1+20200130-2) ; ```; I did what you suggested and here is how my meson.build file looks.; ```; # If custom mpi mode is enabled, include and library pathes for MPI have to be set manually to env variables; if get_option('custom-mpi'); mpi_dep = []; mpi = true; # Otherwise they are automatically determined; else; mpi_dep = [dependency('mpich', required : get_option('with-mpi'))]; # mpi_dep = [dependency('mpi', language:'c', required : get_option('with-mpi')),; # dependency('mpi', language:'cpp', required : get_option('with-mpi'))]; #if mpi_dep[0].found() or mpi_dep[1].found(); # mpi = true; #endif; endif; ```; My SU2 build was successful but there were a couple of warnings.; Also, instead of 870 there were only 772 files in total. Is that okay?; ```; slimshady@",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1000#issuecomment-633139474:318,wrap,wrapper,318,https://su2code.github.io,https://github.com/su2code/SU2/issues/1000#issuecomment-633139474,1,['wrap'],['wrapper']
Integrability,"@timjim333, I checked your grid with just connectivity info and I get the following error messages. Boundary marker BODY, surface element 77477: No corresponding volume element found.; Coordinates of the points; 0.1815790.04981870.0020471; 0.181850.04994770.00205104; 0.1816670.04971090.00204381. Boundary marker BODY, surface element 133348: No corresponding volume element found.; Coordinates of the points; 0.1814850.04947420.00203657; 0.1813090.04968980.00204316; 0.181230.04944470.00204356. Boundary marker BODY, surface element 134774: No corresponding volume element found.; Coordinates of the points; 0.181230.04944470.00204356; 0.1813020.04923740.00202934; 0.1814850.04947420.00203657. Boundary marker BODY, surface element 135217: No corresponding volume element found.; Coordinates of the points; 0.1816670.04971090.00204381; 0.181850.04994770.00205104; 0.1815790.04981870.0020471. So clearly the grid is invalid.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/683#issuecomment-494393404:90,message,messages,90,https://su2code.github.io,https://github.com/su2code/SU2/issues/683#issuecomment-494393404,1,['message'],['messages']
Integrability,"A short summary of the things I did in the additional commits:. - I added a consistent error handling that can be used throughout the code. For example if a marker is not specified the error looks like that: ; ```; -------------------------------- Error ---------------------------------; In ""short unsigned int CConfig::GetMarker_CfgFile_TagBound(std::__cxx11::string)"": ; ------------------------------------------------------------------------; The configuration file doesn't have any definition for marker airfoil; ------------------------------------------------------------------------; Exiting now ...; ```; or if a solution cannot be found:. ```; -------------------------------- Error ---------------------------------; In ""void CSolver::Read_SU2_Restart_Metadata(CGeometry*, CConfig*, bool, std::__cxx11::string)"": ; ------------------------------------------------------------------------; Unable to open SU2 restart file solution_flow.dat; ------------------------------------------------------------------------; Exiting now ...; ```; In case you want to throw an error, you can simply call the function `SU2_MPI::Error(""Error Message"", CURRENT_FUNCTION)` where `CURRENT_FUNCTION` is a predefined macro which expands to the name of the routine at compile time. I already replaced almost all error messages in the code. - More MPI functions are included in the MPI Wrapper. - The rank/size is now stored in most of the bigger classes and initialized in the constructor. That means there are no calls to MPI_Comm_rank / MPI_Comm_size anymore in every routine ... For convenience there is also a SU2_MPI::GetRank() / SU2_MPI::GetSize(), in case you need it outside of the main classes. Let me know what you think. Not everything I did has to stay the way I implemented it :)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/473#issuecomment-347663941:1249,rout,routine,1249,https://su2code.github.io,https://github.com/su2code/SU2/pull/473#issuecomment-347663941,3,"['message', 'rout']","['messages', 'routine']"
Integrability,"A simple workaround would be to add an if line before the split:; Line 84 of parse_config.py; if np.size(s2) > 1:; thisval = s2.split('""')[1]; Yes, it requires also ; import numpy as np; at the beginning of the script.; Now it runs with no error message but no output produced.; Also config_gui.py is running, but it opens an empty window,; so apparently this is not good enough. best,; Eran",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/216#issuecomment-241208818:246,message,message,246,https://su2code.github.io,https://github.com/su2code/SU2/issues/216#issuecomment-241208818,1,['message'],['message']
Integrability,"Agreed that the style needs some attention. I am open to ideas about this. You may have noticed that I integrated Codacy recently to test it out: https://www.codacy.com. We have the style guide, but honestly, it's not getting much attention. We should automate checks or have scripts that automatically enforce style constraints. Vera++ sounds interesting in this regard. A little while back, @rsanfer and I had been working on indentation issues with the uncrustify tool. Should we open this as an issue and get some input? Find volunteers to look into these things?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/426#issuecomment-323636235:103,integrat,integrated,103,https://su2code.github.io,https://github.com/su2code/SU2/pull/426#issuecomment-323636235,1,['integrat'],['integrated']
Integrability,"Ah, I wasn't aware of the corrected version. Thanks for pointing out my mistake. The corrected version does make more sense, and the main changes seem to be:. + Changing the location of the sqrt in the definition of `Lturb`; + Changing `ch3` from 0.5 to 2.0; + Clarifying that S and Omega should have a factor of sqrt(2). As for code verification, I would propose using one of the cases examined by Travin, Stretlets, Mockett, or Xiao for comparison. We know that they got a nice range of values for the blending constant on their tests with DDES. The cases I can see where they explicitly show the results of the blending function are:. + Circular cylinder at Re = 50,000 (Travin _et al._ 2002); + Tandem cylinders at Re = 166,000 (Xiao _et al._ 2012); + NACA0021 airfoil in deep stall (Mockett 2009). The tricky thing is that the value of the blending constant is determined by the flow solution, which is determined by the solver. So the values we obtain will be dependent both on the version of DDES used and the nature of the code. We can't expect to match any of these papers exactly. We could also use a simpler flow, such as fully developed channel flow or a flat plate boundary layer. The tradeoff would be simplicity for ease of comparison.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/532#issuecomment-388189377:966,depend,dependent,966,https://su2code.github.io,https://github.com/su2code/SU2/pull/532#issuecomment-388189377,1,['depend'],['dependent']
Integrability,"All,. For whatever it is worth, here are some thoughts. It is clear that we need to strike the right level and hierarchy of abstraction: at the highest level one really ought to be describing the physical problem, not the number of zones or the specific time-stepping algorithm that would be used. But preventing future multi-zone calculations from reaching the (time) order of accuracy desired is also an important issue that SU2 must support (and that I think would be very important for those doing unsteady turbomachinery calculations). Just as important: even for multi-physics problems (say fluid-structure interaction, when the fluid and structural solvers are not closely integrated into the same source) we need to ensure that the time accuracy of the full multi-physics calculation is as high as those of the component physics solvers. This is a very valid and useful discussion and some proposals are on the table. Given that we are planning a developer’s meeting sometime before the end of the year, this may actually be one of the items in the agenda for discussion, so some decisions can be reached that both make sense and minimize the pain of changes for any part of the existing code. I would suggest that the conversation continue and that other proposals are put forward so the discussion can be finalized at the developer’s meeting. Best,. Juan. On Sep 10, 2017, at 1:09 PM, Edwin van der Weide <notifications@github.com<mailto:notifications@github.com>> wrote:. Dear @rsanfer<https://github.com/rsanfer>,. I agree with you that the outer loop should be the loop over the number of physical disciplines involved in the problem and not the zones. Whether the individual disciplines contain one or multiple zones is irrelevant at this level, in my opinion. The loop over the multiple zones of a single discipline should take place at a much lower level, namely where the spatial residual is computed. At least, this should be the case for the fluid dynamics part. I don't know whethe",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/437#issuecomment-328403160:680,integrat,integrated,680,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328403160,1,['integrat'],['integrated']
Integrability,"All,. I looked a bit more through Eigen and, indeed, the performance is pretty impressive and generally better than MKL and Atlas (the self-tuned implementation of LAPACK) ant most/all matrix sizes. I agree with comments made by @pcarruscg that having a standard for matrix operations throughout the source would clean up /simplify the code considerably and, since it does not seem to impact the AD approach, it should be pursued. It sounds like a quick test branch like @vdweide is suggesting makes sense. A quick driver code to test the performance of the Eigen routines vs MKL makes sense too. The only thing that @vdweide should comment on is how much work it would be to change the LAPACK/BLAS based implementation in the DG-FEM solver to the interface that Eigen exposes. Best,. Juan. On Feb 1, 2019, at 4:19 AM, Edwin van der Weide <notifications@github.com<mailto:notifications@github.com>> wrote:. Would it be an idea to create a branch to test things out and make a decision based on the results? It would be interesting to see the performance for e.g. the dense matrix multiplications in the DG-solver compared to Intel's MKL. —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/643#issuecomment-459705131>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADpSxM1gm0iy_FeGBMFzxVQnYFFzEHt4ks5vJDDlgaJpZM4adbAo>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/643#issuecomment-459845576:564,rout,routines,564,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459845576,2,"['interface', 'rout']","['interface', 'routines']"
Integrability,"All,. Of course, another approach to verifying which sign is correct is to do an analytic differentiation (using CoDi?) or simply using complex-step on the residual calculation routine to get exact Jacobians (for a particular state) and confirm the correct sign. This does require some code extraction / refactoring to perform the test, but it has the benefit that you would know exactly what the correct answer is for the specific residual implementation. Best,. Juan. On Nov 16, 2018, at 11:03 AM, Thomas D. Economon <notifications@github.com<mailto:notifications@github.com>> wrote:. As Jacobians affect convergence rate and not accuracy, you could do a quick test of the same problem with the current version and the sign flipped to see if there is measurable difference in the convergence rate. If yes, then it should give you a hint about which direction. If no, then we should still correct it, but prob don't need to put in too much effort. @clarkpede<https://github.com/clarkpede> : I'm interested in your unit testing set up... —; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/609#issuecomment-439493827>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADpSxInSS3cmLF8iFkD22AoYAp0G3G2yks5uvwvxgaJpZM4YeD9V>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/609#issuecomment-439500791:177,rout,routine,177,https://su2code.github.io,https://github.com/su2code/SU2/issues/609#issuecomment-439500791,1,['rout'],['routine']
Integrability,"All,. The following page has performance comparisons between eigen and mkl (and others):. http://eigen.tuxfamily.org/index.php?title=Benchmark. They are dated 2011, so they are a bit old, but if the quoted performance is real, I would say it is a no-brainer to switch to eigen. If the performance tests (for at least simple things like daxpy and gemm) could be repeated to verify the numbers, that would help us make a final decision. Best,. Juan. On Feb 2, 2019, at 1:58 AM, Edwin van der Weide <notifications@github.com<mailto:notifications@github.com>> wrote:. @pcarruscag<https://github.com/pcarruscag>, I agree with you it will be hard to beat the MKL (running at 60 percent peak for most of the gemm calls for the DG-solver), but if you don't have any performance loss, that would already be nice, as it improves readability. Furthermore, the performance of the DG solver in combination with the discrete adjoint is horrible, because it relies on my very naive implementation of the matrix products. So it would already be something if we can get an improvement there, although we do not use the DG adjoint solver (yet). For me the easiest way to test things out for the DG-solver would actually be in SU2 itself. @economon<https://github.com/economon> put some nice profiling routines in there for the gemm calls, which can be used without any additional work to test eigen. @pcarruscag<https://github.com/pcarruscag> (or somebody else), could you create a branch in which eigen is downloaded in the external directory? I think I can manage from there. Thanks,. Edwin. —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/643#issuecomment-459952137>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADpSxCgydwy1nS3qPJvyCMJXLXWNMSFsks5vJWEkgaJpZM4adbAo>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/643#issuecomment-459986613:1283,rout,routines,1283,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459986613,1,['rout'],['routines']
Integrability,"Alright. I did some digging, and the problem has nothing to do with the warning message. It goes much deeper. In a recent release, SU2 switched to reading and writing binary restart files instead of ASCII. The grid adaptation code is still written only for ASCII. If I'm right, then trying to read a binary restart file with the flow solution breaks the program. I'll submit an issue detailing the bug. For now, try adding the following lines to your cfg file when you run `SU2_CFD`:. %; % Write binary restart files (YES, NO); WRT_BINARY_RESTART= NO; %; % Read binary restart files (YES, NO); READ_BINARY_RESTART= NO. Then run `SU2_MSH`, just like you have been. Does that clear things up?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/606#issuecomment-436131167:80,message,message,80,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-436131167,1,['message'],['message']
Integrability,"As we mentioned in the dev meeting where you exposed the problem, the implementation is not good for strongly coupled flows, and I would guess that it is worse for diffusion than convection (because diffusion is elliptic).; I suspect the main problem is that the linear system does not contain information from the other side of the interface, meaning the solution of the two domains is effectively decoupled.; You could try running the case at much lower CFL (below 1) even with an explicit method.; It is also possible that the current treatment could be improved, since it is an example of multiplicative Schwartz decomposition, maybe there is an ""optimal"" way of implementing that from a physics point of view. Just speculating here, but maybe it would help treating the interface as an outlet if flow is going out, and as an inlet if flow is coming in.; On the numerics side, you can also try hacking the MZ driver to use something more stable than block-Gauss-Seidel (e.g. some quasi-Newton thing for the interface). But those are all band-aids IMO, if you want a robust fluid-fluid interface you need the coupling to be present in the linear system. The simplest way to do that is to have an internal boundary and treat the problem as single zone.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1414#issuecomment-951848509:333,interface,interface,333,https://su2code.github.io,https://github.com/su2code/SU2/issues/1414#issuecomment-951848509,4,['interface'],['interface']
Integrability,"By the way, there's also this cool tool called vera++ that allows you to check the style of the entire codebase. This could be integrated with Travis so make sure PRs are consistent with the coding style guide.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/426#issuecomment-323580700:127,integrat,integrated,127,https://su2code.github.io,https://github.com/su2code/SU2/pull/426#issuecomment-323580700,1,['integrat'],['integrated']
Integrability,"CGNS; * SU2_ENABLE_CODI: no|forward|reverse; * SU2_CODI_CPPFLAGS: flags to pass to SU2 modules when compiling with Codi; * SU2_ENABLE_METIS: ON|OFF; * SU2_METIS_CPPFLAGS: flags to pass when compiling Metis; * SU2_ENABLE_MKL: ON|OFF; * SU2_ENABLE_MPI: ON|OFF; * SU2_ENABLE_MUTATIONPP: ON|OFF; * SU2_ENABLE_PARMETIS: ON|OFF, only available when SU2_ENABLE_MPI is ON; * SU2_PARMETIS_CPPFLAGS: flags to pass when compiling Parmetis; * SU2_ENABLE_TECIO: ON|OFF; * SU2_TECIO_CPPFLAGS: flags to pass when compiling Tecio and TecioMPI; * SU2_TECIOMPI_CPPFLAGS: flags to pass when compiling TecioMPI, requires SU2_ENABLE_MPI. There is an additional variable that is recognized by CMake scripts - DEBUG, turning it ON enables additional STATUS messages, mainly to check that correct include directories, compile definitions and linked libraries were set up correctly. The remaining options like install location and compilers are handled by CMake. Tested this on Ubuntu with CMake 3.15.5 and everything except pySU2ad wrapper compiles. Haven't tested on earlier CMake versions so there might be bugs with them but they should be easy to resolve if any. Related Work. Resolve any issues (bug fix or feature request), note any related PRs, or mention interactions with the work of others, if any. PR Checklist. Put an X by all that apply. You can fill this out after submitting the PR. If you have any questions, don't hesitate to ask! We want to help. These are a guide for you to know what the reviewers will be looking for in your contribution. * I am submitting my contribution to the develop branch.; * My contribution generates no new compiler warnings (try with the '-Wall -Wextra -Wno-unused-parameter -Wno-empty-body' compiler flags).; * My contribution is commented and consistent with SU2 style.; * I have added a test case that demonstrates my contribution, if necessary. ________________________________; You can view, comment on, or merge this pull request online at:. https://github.com/su2code/SU2",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/814#issuecomment-552242380:3221,wrap,wrapper,3221,https://su2code.github.io,https://github.com/su2code/SU2/pull/814#issuecomment-552242380,1,['wrap'],['wrapper']
Integrability,"Dear @oleburghardt, . Unfortunately, your initial reply lacks of any constructive contribution. . SU2 depends on the feedback of you all. We should not discourage anybody to change/improve, show interest, ask for clarification, etc. The tone of your initial replay was unjustified and not polite.; From now on, your profile as a member of the developer team (collaborator) will be not longer active. Peace,; Francisco",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/405#issuecomment-313775430:102,depend,depends,102,https://su2code.github.io,https://github.com/su2code/SU2/issues/405#issuecomment-313775430,1,['depend'],['depends']
Integrability,"Dear @rsanfer,. I agree with you that the outer loop should be the loop over the number of physical disciplines involved in the problem and not the zones. Whether the individual disciplines contain one or multiple zones is irrelevant at this level, in my opinion. The loop over the multiple zones of a single discipline should take place at a much lower level, namely where the spatial residual is computed. At least, this should be the case for the fluid dynamics part. I don't know whether this is also the case for other disciplines, like structures. What about the following high level structure?. - Loop over the number of iterations, or time steps for unsteady problems.; - Loop over the number of pseudo-time steps for implicit time integration schemes; (DT_STEPPING_1ST and DT_STEPPING_2ND). For other cases this loop is 1.; - Loop over the number of disciplines involved; Call iterate for each of the disciplines.; In iterate: ; - Loop over the (Runge-Kutta) stages; - Loop over the zones of a single discipline; Compute spatial residual.; Update the state vector.; - End loop over the zones of a single discipline.; Exchange halo data. This includes the halo data between zones of a single discipline.; - End loop over the (Runge-Kutta) stages ; - End loop over the disciplines; - End loop over the pseudo time steps.; - End loop over the number of iterations, or time steps for unsteady problems. The weakness of this approach is that it still does not work when one would like to employ multi-stage time integration schemes for an unsteady, multi-disciplinary problem (does not work for the current implementation either), but maybe this is something we simply have to accept. The alternative is that all the details of the different time integration schemes have to be moved to the driver classes, which is highly undesirable, I think. The structure above implies that the iteration_container and the integration_container should be defined per discipline and not per zone anymore. The ge",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/437#issuecomment-328368371:740,integrat,integration,740,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328368371,1,['integrat'],['integration']
Integrability,"Dear @vdweide,. I clearly see your point. However, this can be quite a big structural change of the code and I think we should plan very well how to address this issue. The reason of having a driver class was to facilitate the extension of SU2 to multi-physics applications both for analysis (direct solver) and design (adjoint). Thanks to the high level of abstraction of the CInterpolator, CTransfer and the CIteration classes, it was kind of natural to treat fluid-fluid problems similarly to multi-physics problem (i.e. fluid-structure and fluid-heat). As a matter of fact, the multi-stage turbomachinery approach , its adjoint counterpart, the sliding interface they all rely on this driver structure in which we loop among all the zones. If i understood correctly, you suggest to move only the fluid-fluid multi-zone loop at lower level in order to integrate in time only after having coupled all the fluid zones. Right? If so, we need to design the code in such a way that the fluid zones loop is separated from the multi-physics one.; To solve this issue, I think, we just need to find a smart way to differentiate fluid-zones from the rest. Perhaps we can do that by instantiating one Iteration per physical problem instead than per zone. So that inside the iteration we can couple all the fluid zones, and in the driver we can couple the different physics (Iteration). Indeed, this is just a preliminary idea. In general I think we should aim to a structure that can flexibly accommodate multi-physics problems with multi-zones for different physics. A good example is solving fluid-structure in multi-stage turbomachinery, in which we have multiple fluid-zones and multiple structure-zones. ; ; I would like to hear on this matter also from @fpalacios @talbring , @economon , @rsanfer @oleburghardt ,@LaSerpe and @arubino. Thanks @vdweide againg for raising this issue. cheers. Salvo",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/437#issuecomment-328274125:657,interface,interface,657,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328274125,2,"['integrat', 'interface']","['integrate', 'interface']"
Integrability,"ER_MONITORING) so that one can control which markers get wall functions applied. If a list of markers is not specified in the config file, the default behavior should be that all no-slip walls get wall function BCs. If a list of markers is specified, then those and only those markers listed get wall function Bfs (with the others getting integration to the wall treatment). Now, what you point out in the second half of your message is the ultimate in flexibility: not only specifying wall functions in a subset of the no-slip wall markers, but also allowing for different kinds of wall functions to be used in those markers. I imagine that this would be a seldom used capability…but someone out there might have the need. I guess it does not seem to me that the coding of the most flexible logic is that much more complicated, so we may as well do that. If you guys think it is too complicated, the advertised options in the config file can allow some simpler behavior. My two cents,. Juan. On Sep 5, 2017, at 9:58 PM, Edwin van der Weide <notifications@github.com<mailto:notifications@github.com>> wrote:. Juan,. I think that having the flexibility to apply wall functions on only a subset of the viscous wall boundaries would be useful. E.g., if you are interested in a wing, you can apply integration to the wall there, but apply wall functions on the fuselage. My preference would be to have a dedicated BC type for that, i.e. Tom's second suggestion. Apart from this, we can have the different wall model types as a single input parameter, i.e. you apply the same wall model type for all viscous boundaries. Or would you like to have the flexibility to specify this as well per individual marker?. Edwin. —; You are receiving this because you commented.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/399#issuecomment-327374728>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADpSxOEhKLW_U0n9PDoz5m6cJoCScV3_ks5sfiZdgaJpZM4NvG6w>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/399#issuecomment-327377108:1711,integrat,integration,1711,https://su2code.github.io,https://github.com/su2code/SU2/issues/399#issuecomment-327377108,1,['integrat'],['integration']
Integrability,"ETSc was used for the Krylov solvers and more. While indeed it worked well and in parallel mode, each new implementation was a nightmare. LAPACK/BLAS package, on the other hand, provides a much easier implementation experience. Certainly, this is not the only consideration but it should be taken into account. Currently, resulting from the significant contributions of the members of this developers group, SU2 implementation works like a charm. I think we should strive to conserve this feature, especially if we aim at attracting more users and developers into the community. (...). >@vdweide; >(...) @bmunguia and @EduardoMolina, what type of application did you have in mind for PETSc? The only thing I can think of is a full Newton solver. And no matter how much I like PETSc, @juanjosealonso and @erangit have a point here. Looks like I start to belong to the group of old conservatives as well.... >@economon ; >(...) If you really would like to give PETSc a shot, I recommend talking with @anilvar who had an interface for connecting it to SU2 in one of our branches. >@pcarruscag; >(...) being able to use PETSc or HYPRE would be interesting as it would give us access to AMG, and @talbring 's branch feature_template_linear_solver would make such an integration compatible with AD. (...). >@EduardoMolina; >(...) When Brian (@bmunguia ) and I mentioned PETSc, it was an idea to try a different Newton-Krylov (with preconditioner) library in order to improve the convergence of SU2.; Since the slow convergence of the SU2-FV is the main feedback that I received from other users from industry and academia, I think it worth try an external library and evaluate the performance. (...). >@pcarruscag ; >(...) That is something I am also interested in as for some of my structural cases the current linear solvers simply do not converge. (...). >@economon ; >I would add one practical comment for consideration: it is worth checking whether the main restriction we have is related to approxima",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/648#issuecomment-460853218:2292,interface,interface,2292,https://su2code.github.io,https://github.com/su2code/SU2/issues/648#issuecomment-460853218,1,['interface'],['interface']
Integrability,"Edwin,. I think it is a good idea to be able to have some level of control over the application of the wall functions on a marker-by-marker basis: as you say, it would be fairly common to have a wing marker where integration to the wall makes sense and a fuselage marker where wall functions (or even an inviscid BC) is the right thing to do. So let’s indeed do something like what Tom suggests (in the spirit of MARKER_MONITORING) so that one can control which markers get wall functions applied. If a list of markers is not specified in the config file, the default behavior should be that all no-slip walls get wall function BCs. If a list of markers is specified, then those and only those markers listed get wall function Bfs (with the others getting integration to the wall treatment). Now, what you point out in the second half of your message is the ultimate in flexibility: not only specifying wall functions in a subset of the no-slip wall markers, but also allowing for different kinds of wall functions to be used in those markers. I imagine that this would be a seldom used capability…but someone out there might have the need. I guess it does not seem to me that the coding of the most flexible logic is that much more complicated, so we may as well do that. If you guys think it is too complicated, the advertised options in the config file can allow some simpler behavior. My two cents,. Juan. On Sep 5, 2017, at 9:58 PM, Edwin van der Weide <notifications@github.com<mailto:notifications@github.com>> wrote:. Juan,. I think that having the flexibility to apply wall functions on only a subset of the viscous wall boundaries would be useful. E.g., if you are interested in a wing, you can apply integration to the wall there, but apply wall functions on the fuselage. My preference would be to have a dedicated BC type for that, i.e. Tom's second suggestion. Apart from this, we can have the different wall model types as a single input parameter, i.e. you apply the same wall model ty",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/399#issuecomment-327377108:213,integrat,integration,213,https://su2code.github.io,https://github.com/su2code/SU2/issues/399#issuecomment-327377108,3,"['integrat', 'message']","['integration', 'message']"
Integrability,"Hello Pedro. While searching a small sample dataset, I have run some; variations on the jobs, and my findings were:; (Please note that *all* ""markers"" I have mentioned in the next items refer; to solid walls in the mesh, using the RANS solver); 1- When I impose HEATFLUX=0 *and* ISOTHERMAL=290 Kelvin, for the same; markers, there are no complaints from SU2. It shows that SU2 ignores the; imposition of HEATFLUX=0, in this case.; 2- Just setting ISOTHERMAL=290 Kelvin (using all of the same markers as in; (item 1), above), without any HEATFLUX setting, then SU2 produces the same; results as in (item1).; 3- When some markers are set with HEATFLUX=0 and the rest of them are set; with ISOTHERMAL=290 Kelvin (so that each wall marker in the mesh is; referenced), there are no complaints from SU2, and the job goes as expected.; 4-The error message mentioned earlier, appears when one or more solid wall; markers *is not marked* concerning HEATFLUX or ISOTHERMAL; .; My conclusion then is that the error message appeared when I mistakenly; have not included a wall marker (assigning it as a HEATFLUX or an; ISOTHERMAL marker!); Does it make sense?; Kind regards,. On Mon, Oct 23, 2023 at 7:48 PM Jairo Cavalcante ***@***.***>; wrote:. > Unfortunately, my example involves a swirler and nozzle for the; > Navier-Stokes solver with Menter model, so the dataset is relatively large.; > Let me check whether some older small Euler mesh exhibits the same message!; > I will let you know! Thank you very much.; >; > On Mon, Oct 23, 2023 at 6:34 PM Pedro Gomes ***@***.***>; > wrote:; >; >> Is there a simple example to reproduce the issue?; >>; >> —; >> Reply to this email directly, view it on GitHub; >> <https://github.com/su2code/SU2/pull/2109#issuecomment-1776057496>, or; >> unsubscribe; >> <https://github.com/notifications/unsubscribe-auth/AHGXZUV3DNRF3O55YAWT563YA3PETAVCNFSM6AAAAAA3QKLVDWVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMYTONZWGA2TONBZGY>; >> .; >> You are receiving this because you commen",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/2109#issuecomment-1777018035:841,message,message,841,https://su2code.github.io,https://github.com/su2code/SU2/pull/2109#issuecomment-1777018035,1,['message'],['message']
Integrability,"Hello,. So, to clarify, there were two issues:. 1) With the old commit (382e82f), we were seeing the assertion failure at line 1881 of numerics_structure.cpp, but only with the very large mesh (180 million cells). 2) With the newer commit (c093a62), we were seeing the assertion failure at line 294 of C2DContainer.hpp, which was occurring even with smaller meshes (7 million cells). The solution to (2) appears to be to change `geometry->node[iPoint]->GetnNeighbor()` to `geometry->node[iPoint]->GetnPoint()` at line 3759 of CEulerSolver.cpp, in the `CEulerSolver::SetUpwind_Ducros_Sensor()` method. I made this change locally, and attempted to run on our large mesh. Issue (2) seems to be fixed, but we still run into issue (1). I have now gone through the read restart routines, and have found a potential issue:. For reference, the restart file for our large mesh with averaging data included consists of:; 39 fields * 75,107,967 points = 2,929,210,713 variable values (which is larger than `INT_MAX`). Beginning at line 3931 of CSolver.cpp, in method `CSolver::Read_SU2_Restart_Binary(...)`, we have the following:. ```; int *blocklen = new int[geometry->GetnPointDomain()];; int *displace = new int[geometry->GetnPointDomain()];; int counter = 0;; for (iPoint_Global = 0; iPoint_Global < geometry->GetGlobal_nPointDomain(); iPoint_Global++ ) {; if (geometry->GetGlobal_to_Local_Point(iPoint_Global) > -1) {; blocklen[counter] = nFields;; displace[counter] = iPoint_Global*nFields;; counter++;; }; }; MPI_Type_indexed(geometry->GetnPointDomain(), blocklen, displace, MPI_DOUBLE, &filetype);; ```; The problem here is that for our case, where `iPoint_Global` can get up to 75,107,967 and `nFields` = 39, the value assigned to `displace[counter]` in the loop can over-run `INT_MAX`. This would result in potential garbage / incorrect displace values being passed to `MPI_Type_indexed(...)`. Unfortunately, simply changing `displace` to a `long int *` won't work, as the expected argument type for `",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/949#issuecomment-622026420:772,rout,routines,772,https://su2code.github.io,https://github.com/su2code/SU2/issues/949#issuecomment-622026420,1,['rout'],['routines']
Integrability,"Hey @LaSerpe (Giulio),. I had a look at the new driver structure and it look clear to me. My only comments is on the name of the classes: I agree on having a GeneralDriver in place of the SingleZone and MultiZone Driver, as @tobadavid said we should distinguish the drivers for the different physics/applications, but the name CFluidDriver I think is a bit misleading considering the fact that is specifically for multizone fluid with sliding-mesh interface. Perhaps a SlidingMeshDriver sounds better??? Any suggestion from the others?. Regarding the fact that you still have to specify the FSI_MARKER, i would fix this before merging with the develop. . Anyway good job!!! . cheers. Salvo",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/322#issuecomment-255340813:448,interface,interface,448,https://su2code.github.io,https://github.com/su2code/SU2/pull/322#issuecomment-255340813,1,['interface'],['interface']
Integrability,"Hey @timjim333 that's nice to hear,. I would put it in the .bashrc if you consistently call SU2 with your command, like that you can always switch the SU2-build and still have your clear settings already in place. Image having the master, develop and feature_whatever installed, you don't need to apply your patch to all of these versions if you put it in the bashrc.; But editing interface.py has the same effect, so its up to you what you prefer. Tobi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/526#issuecomment-429668015:381,interface,interface,381,https://su2code.github.io,https://github.com/su2code/SU2/issues/526#issuecomment-429668015,1,['interface'],['interface']
Integrability,"Hi @Eduardo-Carvalho ,. your request is now merged into the develop branch and you can test/use it if you like. It will be in one of the next releases, if no further issues occur.; Handling is intuitive: Just set your restart iteration in the config file as you would do normally and activate the restart solution option. Furthermore, place your restart file (two in the case of 2nd order time integration) in the same directory as the config file of your test case. Then you are set up and can run the scripts as normal. ; For more details, I refer to pull request #964. . Best; Steffen",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/909#issuecomment-630289600:394,integrat,integration,394,https://su2code.github.io,https://github.com/su2code/SU2/issues/909#issuecomment-630289600,1,['integrat'],['integration']
Integrability,"Hi @bmunguia ,; I was in the same situation as @MiracAydin1, so thanks for the hint. Nevertheless I'm having some problems. I followed your instructions to install the branch:. 1. downloaded the [feature_adapt_sst](https://github.com/su2code/SU2/tree/feature_adap_sst) branch.; 2. Used meson to configure the build; `./meson.py build -Denable-autodiff=true -Denable-directdiff=true`; 3. Added the environment variables to the .bashrc; 4. ninja build.; `./ninja -C build install`. The build didn't show any errors, only few warnings during meson ( `gcc1: warning: command line option ‘-Wno-non-virtual-dtor’ is valid for C++/ObjC++ but not for C`). When I try to run the mesh_adaption (or even run simply the solver through parallel_computation.py):. `$SU2_RUN/mesh_adaptation_amg.py -f invCyl.cfg -n 6`. It immediately shows an error (without even showing the SU2 splash screen) :; `Traceback (most recent call last):`; ` File ""/usr/local/bin/mesh_adaptation_amg.py"", line 38, in <module>`; ` import SU2`; ` File ""/usr/local/bin/SU2/__init__.py"", line 14, in <module>`; ` from SU2 import amginria`; ` File ""/usr/local/bin/SU2/amginria/__init__.py"", line 4, in <module>`; ` from .interface import *`; ` File ""/usr/local/bin/SU2/amginria/interface.py"", line 41, in <module>`; ` import _amgio as amgio`; `ImportError: No module named _amgio`. Am I missing any dependencies? ; Please note that I previously compiled SU2 master branch without issues, and have already installed mpich, numpy, scipy.; Any help would be really appreciated.; Thanks",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/948#issuecomment-619332650:1179,interface,interface,1179,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-619332650,3,"['depend', 'interface']","['dependencies', 'interface']"
Integrability,"Hi @koodlyakshay thanks for making the changes.; By default MPI barriers are ""never"" needed, the normal communication routines already do all synchronization required. Efficiency is probably not fundamental for that routine but this solution feels too complicated somehow, can you attend tomorrow's developers meeting? (I'm getting the ""there's gotta be a simpler way"" feeling, and if we pick the brains of a few people we are certain to find it). In the meantime, if you specify the roughness as a string+double list (exactly like MARKER_HEATFLUX), which is read with `addStringDoubleListOption` you could probably simplify the logic around heatflux and isothermal markers, which would make the setup more user friendly (having to stick with an order is bound to trip someone at some point).; Also the cht interface is ""just"" an isothermal boundary, any reason not to make this feature available for that?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/877#issuecomment-630788337:118,rout,routines,118,https://su2code.github.io,https://github.com/su2code/SU2/pull/877#issuecomment-630788337,4,"['interface', 'rout', 'synchroniz']","['interface', 'routine', 'routines', 'synchronization']"
Integrability,"Hi @pcarruscag, just a small follow-up to my comment in the code section concerning the new adjoint implementation that might also help here (either by using it directly or just for getting some ideas). What I would like to change is in fact not the `CDiscAdjSolver` (which I find is very good) - but I'd like to propose some changes for the *interface* to the AD tool. And some subsequent stuff.; It will allow for a more direct control of derivatives which is favourable in case one deals with multiple zones, multiple sets of conservative variables, geometry coordinates in case of FSI, and so on. And of course in terms of performance as one needs only one tape that one can keep during all iterations, regardless of what their variables might be. In case you are interested, take a look at the implementation in [su2code:sc_develop](https://github.com/su2code/SU2/tree/sc_develop). I'll open the PR as soon as @talbring opened his one for his great rework on input/ouput. As for this PR, let me wait a second if we can clear up the issue concerning the registration and I'll leave a small review afterwards.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/615#issuecomment-457582842:343,interface,interface,343,https://su2code.github.io,https://github.com/su2code/SU2/pull/615#issuecomment-457582842,1,['interface'],['interface']
Integrability,"Hi @pcarruscag,; thank you very much for the insight and the well thought proposed solution. I wasn't aware that there was such a loss in performance, it seems clear that something needs to be done. The only question I have is regarding the following comment . > There are no free lunches and this performance improvement would come at the cost of losing the ability to have different types of variables in different parts of the domain. I'm using this feature more and more, I was planning to extend it in the structural solver to remove the `if fsi` statements, and I also used it in the rework of the mesh solver, as defining variables at the interface only reduces greatly the memory footprint (sort of like the node-vertex structures in geometry). You mention there are options to keep this versatility, how difficult do you think would be to implement them?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/716#issuecomment-507998889:646,interface,interface,646,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-507998889,1,['interface'],['interface']
Integrability,"Hi @themrdjj,; Thank you for the feedback, there was already a similar report in #796 (which incidentally went stale and was closed), I will try to do something about it, or if you would like to contribute code to the project I can point you to right place to add an error message. Meanwhile my best advice is to not start a config from scratch until you know SU2 very well (and even then...) look for a test case that uses similar features and go from there.; The minimal config is the one in Quickstart, the template is more of a catalog :) I don't think we'll ever have a unified minimal config, SU2 does many things, some mutually exclusive.; Convective options are reasonably well documented here: https://su2code.github.io/docs_v7/Convective-Schemes/; The output messages before ""Begin Solver"" can be helpful (although in this particular case you would need to know what to expect). Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/842#issuecomment-566642727:273,message,message,273,https://su2code.github.io,https://github.com/su2code/SU2/issues/842#issuecomment-566642727,2,['message'],"['message', 'messages']"
Integrability,"Hi @timjim333 ,. Exactly (concerning your first question). . For the %s : In your initial post you stated that `mpirun --use-hwthread-cpus -np 12 SU2_CFD turb_ONERAM6.cfg` worked for you. So %s is simply the place-holder for the SU2 module together with the configure script. Which in your case would be `SU2_CFD turb_ONERAM6.cfg` . But `parallel_computation.py` will also call `SU2_SOL turb_ONERAM6.cfg` for you after the solver routine to create output files for visualization. ; If you take a look into the `interface.py` (as in my previous post) and the `parallel_computation.py` you'll find exactly how its done. Cheers, Tobi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/526#issuecomment-395712721:430,rout,routine,430,https://su2code.github.io,https://github.com/su2code/SU2/issues/526#issuecomment-395712721,2,"['interface', 'rout']","['interface', 'routine']"
Integrability,"Hi Economon,. I encountered an issue very similar to what Auzbaig reported: the error message ""OBJECTIVE_FUNCTION: invalid option value EntropyGeneration"" during optimization with SU2. (I am using SU2 version 8.0.1 ""Harrier.""). After thoroughly examining the existing Python optimization framework, I found that one of the steps in the optimization chain is generating different config.cfg files, with a focus on DV_VALUE and OBJECTIVE_FUNCTION. DV_VALUE controls the geometry deformation;; OBJECTIVE_FUNCTION determines the type of objective/constraints.; Then the framework calls SU2_CFD and SU2_DOT to obtain performance metrics or gradient information.; As you mentioned, ""You might need to run updateHistoryMap.py to register new outputs with Python."" Initially, I thought it meant simply providing a new input for OBJECTIVE_FUNCTION in the Python optimization framework. However, it seems that this may not work at the C++ level. To verify this, I ran $ SU2_CFD your_config.cfg -d and observed all available history outputs. However, I suspect that OBJECTIVE_FUNCTION cannot use every history output, meaning that the adjoint solver might not recognize some objective functions. Does this imply that additional modifications in the C++ code are required?. Additionally, I would appreciate more information regarding CUSTOM_OBJFUNC. From TestCases/user_defined_functions/lam_flatplate.cfg, I understand that CUSTOM_OBJFUNC allows combinations of existing OBJECTIVE_FUNCTIONs and can also utilize CUSTOM_OUTPUTS. The flexibility of CUSTOM_OUTPUTS seems to enable the construction of various desired variables. However, I am unsure whether using OBJECTIVE_FUNCTION= CUSTOM_OBJFUNC along with CUSTOM_OUTPUTS can entirely replace the need for additional modifications in the C++ code. Since I’m not very proficient in C++, I would greatly appreciate your guidance. Sincerely,; Tongtong",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/889#issuecomment-2324575133:86,message,message,86,https://su2code.github.io,https://github.com/su2code/SU2/issues/889#issuecomment-2324575133,1,['message'],['message']
Integrability,"Hi Pedro, thanks for looking into this more. I had run into inconsistencies for FSI problems with relaxation which was the reason for the domain specific calls coming into the multizone driver Update function. With the changes I introduced, the velocity at the interface was being transferred correctly with and without relaxation, so I left it there but it is a bit messy. I'll test with the modified calls for the Relaxation as you suggest. I completely agree that if we can simplify the velocity transfer by just using the velocity directly, then we should. Especially since the predicted velocity is only zero order anyway.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1174#issuecomment-774993325:261,interface,interface,261,https://su2code.github.io,https://github.com/su2code/SU2/pull/1174#issuecomment-774993325,1,['interface'],['interface']
Integrability,"Hi Soumen,. As Tom said, the routines are all in place and I have been putting them; together for solution interpolation from one mesh to another for unsteady; simulation as post-processing step. So probing at a particular location for; unsteady solution can be also done with this framework. The probe search; implementation is in place for 2D configuration currently. It will be; extended to 3D and probably available in the main branch in the next 2; months.; The implementation so far is in feature_MeshInterpolation branch if you; want to take a look. Sravya. On Thu, Nov 2, 2017 at 10:09 PM, Thomas D. Economon <; notifications@github.com> wrote:. > Hi Soumen: yes, this is something that the developers are actively working; > on at the moment (in particular, @sravya91 <https://github.com/sravya91>; > has been taking the lead on this). It is true that most of the ingredients; > are already available in SU2 (fast searches, interpolation routines, etc.),; > but the trick is combining them all and making it general.; >; > Do you have any other requirements beyond simple probes? I am guessing we; > should have something available in the next few months, but it's not set; > yet.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/issues/466#issuecomment-341623660>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/AHenII5B0Xtb2U_hj2vbBesf5Oc51uvzks5syqAEgaJpZM4QPYh8>; > .; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/466#issuecomment-342266341:29,rout,routines,29,https://su2code.github.io,https://github.com/su2code/SU2/issues/466#issuecomment-342266341,2,['rout'],['routines']
Integrability,"Hi Soumen: yes, this is something that the developers are actively working on at the moment (in particular, @sravya91 has been taking the lead on this). It is true that most of the ingredients are already available in SU2 (fast searches, interpolation routines, etc.), but the trick is combining them all and making it general. Do you have any other requirements beyond simple probes? I am guessing we should have something available in the next few months, but it's not set yet.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/466#issuecomment-341623660:252,rout,routines,252,https://su2code.github.io,https://github.com/su2code/SU2/issues/466#issuecomment-341623660,1,['rout'],['routines']
Integrability,"Hi Sun5k,; Thanks for tackling the Transition models. As far as I see, you are adopting the CScalarSolver-Base style just as is done for the Turbulence or SpeciesTransport solver (cf #1330 #1388 ) :+1: I think you can stay close to how things are handled in these solvers. The Turbulence solver has another class in the middle though: `CScalarSolver -> CTurbSolver -> CTurbSST/SASolver` I am not sure whether sth like this makes sense for transition models? (because I have no clue of Transition models). Otherwise the CSpeciesSolver is directly based on the CScalarSolver. Please limit this PR to 1 model only! So in this case just the LM model maybe. It is much easier for you to wrap this PR up with a limited scope instead of trying to do everything at once :) (and it is easier to review for everyone else) In case you then still want to tackle another one once LM is done :D then just open another PR :+1:; ; As unfinished Transition models (or models with a questionable state) are a bit of a companion of SU2 I would also ask you to provide a meaningful testcase with this PR that proves the usability of this feature. I personally like to think of a suitable case at the beginning of development, to adopt a bit a Test-Driven-Development approach but that is of course fully up to you. In case you did not know about the Developers meeting each Wednesday 4pm Berlin time, now you do. You are kindly invited to ask any questions, just show-and-tell to get some feedback etc. it is a very open round :). Happy coding, Tobi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1496#issuecomment-1016451577:682,wrap,wrap,682,https://su2code.github.io,https://github.com/su2code/SU2/pull/1496#issuecomment-1016451577,1,['wrap'],['wrap']
Integrability,"Hi Tim,. Thanks!. I totally agree on the fact that Python-related functionalities could be in a separate file for code clarity. Anyway, considering only the C++ structure, those functionalities are still members of the CDriver (and all child classes). So if you are OK with the fact that having members of the same C++ class in different cpp files, I am OK too. . However, if you mean creating a new class for the Python wrapper (like CPyWrapper or whatever), and leave the CDriver ""clean"", this might be more tricky. Indeed, since the wrapper has to be a top-level class, it is better to have access to all the other main classes (config, geometry, solver, ...) and the CDriver was the perfect candidate (it instanciates all of them). So now if we create a new top-level class next to the CDriver, the direct link with all those classes is lost. Basically we will have to create accessors like CDriver::GetConfig(), CDriver::GetGeometry(), ... that will return the different containers to be used by the wrapper. Obviously this is possible but not in a short time, besides this might be a significant change in the top-level code structure. We could also think about exposing thoses CConfig, CGeometry, ... classes to Python in addition to just the driver, I already made some local tests and it worked great but this approach is less user-friendly. David",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/488#issuecomment-352045091:421,wrap,wrapper,421,https://su2code.github.io,https://github.com/su2code/SU2/pull/488#issuecomment-352045091,3,['wrap'],['wrapper']
Integrability,"Hi Tom,. Sounds like a plan then to have a look at CIntegration to see what we can do to generalize the time integration. I definitely want to help with this, but I don't think I am the appropriate person to take the lead, because I simply don't have a good overview of all the multi-physics options. Tom, are you willing to take the lead for this?. Furthermore, it is good to have other people involved as well, preferably with detailed knowledge of the different disciplines. Any volunteers?. Thanks,. Edwin",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/437#issuecomment-329096830:109,integrat,integration,109,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-329096830,1,['integrat'],['integration']
Integrability,"Hi, ; thanks for this contribution, I will get a more detailed feedback soon. A first comment about the CSymmetricMatrix class came up to my mind, from a first brief review.; There is already a CSysMatrix class and a few routines added in this pull request look redundant (matvect product for instance).; On the other hand, many of those routines (cholesky decomposition and so on) could turn out to be very useful also for other future code developments.; That said, perhaps it would be nice to collect all the matrix-related routines into the CSymmetricMatrix class (removing redundancies) to make them available at an higher level. Cheers,; Giulio",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/555#issuecomment-406370798:221,rout,routines,221,https://su2code.github.io,https://github.com/su2code/SU2/pull/555#issuecomment-406370798,3,['rout'],['routines']
Integrability,"Hi,. here is the contents of config.log:. ```; This file contains any messages produced by compilers while; running configure, to aid debugging if configure makes a mistake. It was created by SU2 configure 4.1.0, which was; generated by GNU Autoconf 2.69. Invocation command line was. $ ./configure --prefix=/gshare/work/hpascalj/CodeSU2-master --with-CGNS-lib=/gshare/soft/code_saturne/4.0.0/prod/cgnslib_3.2.1/lib --with-CGNS-include=/gshare/soft/code_saturne/4.0.0/prod/cgnslib_3.2.1/include. ## --------- ##; ## Platform. ##; ## --------- ##. hostname = master; uname -m = x86_64; uname -r = 2.6.32-279.el6.x86_64; uname -s = Linux; uname -v = #1 SMP Wed Jun 13 18:24:36 EDT 2012. /usr/bin/uname -p = unknown; /bin/uname -X = unknown. /bin/arch = x86_64; /usr/bin/arch -k = unknown; /usr/convex/getsysinfo = unknown; /usr/bin/hostinfo = unknown; /bin/machine = unknown; /usr/bin/oslevel = unknown; /bin/universe = unknown. PATH: /opt/xcat/bin; PATH: /opt/xcat/sbin; PATH: /opt/pbs/default/bin; PATH: /opt/pbs/tools/bin; PATH: /usr/lpp/mmfs/bin/; PATH: /gshare/soft/star-ccm+/STAR-View+9.02.007; PATH: /gshare/soft/star-ccm+/STAR-CCM+9.02.007/star/bin; PATH: /opt/xcat/bin; PATH: /opt/xcat/sbin; PATH: /usr/lib64/qt-3.3/bin; PATH: /opt/pbs/default/bin; PATH: /opt/pbs/tools/bin; PATH: /usr/lpp/mmfs/bin/; PATH: /usr/local/bin; PATH: /bin; PATH: /usr/bin; PATH: /usr/local/sbin; PATH: /usr/sbin; PATH: /sbin; PATH: /gshare/soft/init; PATH: /gshare/soft/scripts; PATH: .; PATH: /gshare/soft/init; PATH: /gshare/soft/scripts; PATH: . ## ----------- ##; ## Core tests. ##; ## ----------- ##. configure:2465: checking build system type; configure:2479: result: x86_64-unknown-linux-gnu; configure:2499: checking host system type; configure:2512: result: x86_64-unknown-linux-gnu; configure:2532: checking target system type; configure:2545: result: x86_64-unknown-linux-gnu; configure:2587: checking for a BSD-compatible install; configure:2655: result: /usr/bin/install -c; configure:2666: checking whe",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:70,message,messages,70,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,1,['message'],['messages']
Integrability,"Hi,; I just had a few (very minor) comments.; Regarding the main contribution, everything makes sense to me and I didn't find any relevant issue.; This is a very nice contribution and the implementation is quite clear, we can go ahead and merge this in soon. Regarding the matrix stuff, perhaps we could start having a new, general, matrix class in Common and then extend it to parallel in future pushes.; It may not be ideal, but at least we'll get started.; I am just afraid that if we leave those potentially useful routines there, in the interpolator, we will soon forget about them (of course it doesn't have to be addressed in this PR but we should really discuss about this). ciao,; Giulio",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/555#issuecomment-407014370:519,rout,routines,519,https://su2code.github.io,https://github.com/su2code/SU2/pull/555#issuecomment-407014370,1,['rout'],['routines']
Integrability,"I agree with the proposed changes, but I also think this could go farther. Some of the most common issues for users involve misuse of the *_ORDER options, dissipation coefficients, and limiters. Overall, it is still not very clear for a user how the centered schemes work. For instance, Lax is always first order and JST is always second order, but sometimes there are not error messages when trying to change the ""ORDER"" option when using these schemes. Also, if we rename the coefficients for JST as proposed, shouldn't we also separate the first coefficient that is only used for Lax? It would make treating the dissipation more clear.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/451#issuecomment-335205189:379,message,messages,379,https://su2code.github.io,https://github.com/su2code/SU2/pull/451#issuecomment-335205189,1,['message'],['messages']
Integrability,"I am using Intel MPI as well, but on Ubuntu 18.04 and I get a clear error message. The likely reason why it hangs for you for this grid and not for the others is that this grid has an issue and the others do not. . Can you run it on one core of your supercomputer?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/683#issuecomment-493914393:74,message,message,74,https://su2code.github.io,https://github.com/su2code/SU2/issues/683#issuecomment-493914393,1,['message'],['message']
Integrability,"I haven't looked at the python wrapper in detail, we had previously tracked several properties which are not available in the conventional convergence tracker (such as Cmy) and used the stop file to obtain the data when appropriate. We have considered increasing the save frequency, but there are several files which are not created at every save point; thereby forcing each ""standard"" run to become a ""run to nearest save"" then ""resume for 1 time-step to get the actual output data"". As the decomposition and some of the file writes take a significant amount of time, it is a non-starter for commercial applications. We would switch back to v6 (which had the capability) but we need some of the other features in v7. I'll take a look at the python wrapper. Thank you for your candor.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1304#issuecomment-862344695:31,wrap,wrapper,31,https://su2code.github.io,https://github.com/su2code/SU2/issues/1304#issuecomment-862344695,2,['wrap'],['wrapper']
Integrability,"I implemented most of the reviewers suggestions. The only suggestion I left unchanged is the upper-case consistency issue raised by Wally. Since it is an optional output and it depends on the controlling variable names the user provides, I think it would be more intuitive to keep the font case consistent between the names under `CONTROLLING_VARIABLE_NAMES` and the corresponding `RMS_` outputs.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/2057#issuecomment-1643680580:177,depend,depends,177,https://su2code.github.io,https://github.com/su2code/SU2/pull/2057#issuecomment-1643680580,1,['depend'],['depends']
Integrability,"I just committed a second round of changes that I would appreciate some feedback on. Compilation is successful with these changes, however, upon testing, I receive the following message: . Error in ""void CConfig::SetConfig_Parsing(std::istream&)"": ; -------------------------------------------------------------------------; Line 271 SPECIFIED_SUPERSONIC_INLET_PROFILE: invalid option name. Check current SU2 options in config_template.cfg.; Did you mean SPECIFIED_INLET_PROFILE?; Line 274 SUPERSONIC_INLET_FILENAME: invalid option name. Check current SU2 options in config_template.cfg.; Did you mean INLET_FILENAME?. I had already adjusted CConfig.cpp to include supersonic inlet profile inputs, but apparently I am not implementing everything I need to. I'm unsure where else I would need to make changes. Any suggestions?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1652#issuecomment-1151296832:178,message,message,178,https://su2code.github.io,https://github.com/su2code/SU2/pull/1652#issuecomment-1151296832,1,['message'],['message']
Integrability,"I simple wrote a program to test the grid, which searches for the boundary elements in the single faces, i.e. faces that are only part of one volume element, of the volume grid. What the error message means is that for 4 triangular surface elements of boundary marker BODY there is no corresponding face of the volume elements that is only part of one volume element. . When I include the faces that are shared by two volume elements, only two boundary elements are not found. So in short, you have two boundary elements in boundary marker BODY that are no part of any volume element and two boundary elements that are shared by two volume elements.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/683#issuecomment-494675549:193,message,message,193,https://su2code.github.io,https://github.com/su2code/SU2/issues/683#issuecomment-494675549,1,['message'],['message']
Integrability,"I tend to agree w Eran on this topic. When it is working as it should, it is very convenient to have the makefiles already available in the repo. I switch between Mac, Ubuntu, and a red hat cluster without needing to update anything or call the bootstrap script. I rarely use it.. basically only when adding or removing files to the build. Also, it is good to minimize dependencies, as sometimes old machines or clusters have limited tool sets. But, clearly we should at a minimum fix the issue that some of you are finding with the autotools, which should just need an update. What systems are you having trouble with? It’s important that we don’t jump too far ahead for portability reasons (that’s why we have kept the old versions for so long). Do you have an idea of the minimum autotools you need for the failing systems? We could start by updating to that version and see if things stabilize.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/586#issuecomment-424210049:369,depend,dependencies,369,https://su2code.github.io,https://github.com/su2code/SU2/pull/586#issuecomment-424210049,1,['depend'],['dependencies']
Integrability,"I think I implemented all the modifications you suggested. I am sorry you see all the commits in between, unfortunately due to Covid I work outside of office and I actually use Github to push the modified code to the office PC. I was actually working on a separate branch but, for reason that I do not understand, all the commits have been moved in the merging process... sorry about that. I am still learning git. In particular the modifications are:. - The functions related to static mesh deformation have been removed. I only included some new lines in the python wrapper ; that overwrite the initial velocities to zero and push back the solution.; - I now use the BC_Sym_Plane of the FEA solver for the deformation at the symmetry plane. I had to add a flag that avoids ; accessing LinSysReact in case of mesh deformation, as this is not initialised in that context.; - GetnMarker_Match_Deform_Mesh is not present anymore; - The marker has been renamed from MATCH_DEFORM_MESH to DEFORM_MESH_SYM_PLANE. All the functions have also ; been renamed accordingly; - I included the SU2 header in all the new files, changing the version number to 7.0.8. I did not modify the version number of ; the files that were already present in SU2 prior to this PR. I think the merging process should take care of that, am I wrong?; - The python functions that were separated in x,y,z component now give back an array and are merged into one function only; - The descriptions for the methods have been added; - The test case has been removed. I actually prepared a tutorial and all the appropriate files will be placed in the tutorial and ; website repos. I will now perform a PR for those repos so that you can see the material. Again thank you very much and sorry for the mess with the ""internal"" commits. . Please let me know if you think I missed something",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1124#issuecomment-742471972:568,wrap,wrapper,568,https://su2code.github.io,https://github.com/su2code/SU2/pull/1124#issuecomment-742471972,1,['wrap'],['wrapper']
Integrability,"I thought of doing an SST but was not long enough that it gave me error with divergence. I have been setting up my SST case as per the tutorial example of NACA0012. However, I do not happen to see any entry with regards to eddy frequency etc. (usually required by SST) in the config file. Any guidance will be great.; Thanks; Jehan; From: Heather Kline notifications@github.com; To: su2code/SU2 SU2@noreply.github.com ; Sent: Tuesday, May 12, 2015 11:43 AM; Subject: [SU2] Feature deallocation (#174). Bringing this branch up to date with current develop branch. ; Various deallocation changes; Some regression tests fail but all run. (previously was not the case); You can view, comment on, or merge this pull request online at:;   https://github.com/su2code/SU2/pull/174; Commit Summary; - Updated GetEngine_Properties; - Fix to the last commit; - Small bug; - Merge branch 'develop' into feature_MPI; - merging; - SU2_SOL and SU2_CFD are working; - Preliminary, but complete, implementation of SU2_DEF; - More updates; - Working version; - Complete implementation (validate); - Working version of SU2_DEF; - Final push before moving to the develop branch; - New MPI (removing SU2_PRT); - Merged in Ben's ParMETIS integration and fixed some conflicts.; - Merge branch 'benkirk-parmetis_integration' into feature_MPI; - ParMETIS geometry routines have been copied over but are not activated yet.; - Small change to ParMETIS include.; - ParMETIS can now be activated for testing (PARMETIS=YES in config).; - Updated MG; - Updated EA subrotuine; - Small fix; - Fixing memory leak; - Fixing memory leaks; - Dev release v.3.2.6; - Increasing MAX_NUMBER_MARKER; - Working version with ParMETIS. Fixed bug in global index. Now clean up and testing...; - Cleaned version of ParMETIS routines with better console output during partitioning.; - Small bug in initial element division.; - Made arrays in ParMETIS call dynamic.; - Fixed compiler warnings and added MPI directives so that the pure serial code wor",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:1544,integrat,integration,1544,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['integrat'],['integration']
Integrability,"I wonder if maybe it would be a better idea to delete this (and other stuff) from externals/ and add it to subrojects/ instead. You can use `meson wrap install catch2`, and it's a simple ini file to vet instead of an 18k line file. git diffs become a lot simpler too.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1726#issuecomment-1198882302:147,wrap,wrap,147,https://su2code.github.io,https://github.com/su2code/SU2/pull/1726#issuecomment-1198882302,1,['wrap'],['wrap']
Integrability,"I'll try to break down each request to make it clearer. Request: Use nomenclature consistent with the C++ interface (point instead of node, etc.); Reason: People who know the C++ interface will know how to use the python wrapper straight away, people who learn how to use the python wrapper will be able to understand the C++ implementation (without needing a translation layer in their mind all the time). Request: Return connectivity/adjacency as local indices instead of global; Reason: This is the natural way of referencing data in an MPI code, local indices correspond directly to data stored in the partition thereby making it more efficient to access (without global-to-local conversions, which are much more expensive than local-to-global). Furthermore, the local ordering strategy improves the efficiency of loops (over edges, neighboring points, etc.). Request: Do not apply unnecessary ""transformations"" to the connectivity/adjacency as part of the API; Reason: Increases the maintenance burden and makes for a less versatile API. By returning the local indices that form a marker or element, it is trivial to retrieve any other data for those indices (the ""transformation""). For example, the solution at those points, the point coordinates, whether the points are halo or domain points, the global indices, etc.; This way, by adding a **single** function to the API e.g. get the global index of a point of element, the functionality of the API grows a lot more because the user can apply the function to **any** connectivity/adjacency function. Request: Do not offer too many overloads of the same function; Reason: Increases the maintenance burden and it's returning the data in structures that are not very efficient, namely vector of vectors. It is much easier to offer domain-wide data access on the python side, as a very small function that can be part of wrapper utilities (i.e. live only in python but not c++). It may even be more efficient since you make a numpy array/matrix in",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1300#issuecomment-1402197827:106,interface,interface,106,https://su2code.github.io,https://github.com/su2code/SU2/pull/1300#issuecomment-1402197827,4,"['interface', 'wrap']","['interface', 'wrapper']"
Integrability,"If you don't mind I'll leave this question open for now.; I'm planning to provide a simplified example setup later on, once I've had time to properly dive into the wrapper API.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1553#issuecomment-1071052958:164,wrap,wrapper,164,https://su2code.github.io,https://github.com/su2code/SU2/issues/1553#issuecomment-1071052958,1,['wrap'],['wrapper']
Integrability,"If you look at the testing history, commit 4f5f3ed doesn't pass the regression tests, while commit 8551cac does. Only two tests are failing on 4f5f3ed: `discadj_topol_optim` and `discadj_fsi_airfoil`. The difference between the two commits is a simple change. I changed the `SU2_MPI::Error` routine to give a return status of `EXIT_FAILURE` instead of `0`. Since `0` is conventionally defined as a successful program exit, returning `EXIT_FAILURE` makes more sense than returning `0` when `SU2_MPI::Error` is called. So why did that change cause the regression tests to fail? My suspicion is that these two tests have been exiting with an error for some time, but these regressions were not picked up by Travis since SU2 kept on returning `0` (i.e. success). Changing the exit code of `SU2_MPI::Error` doesn't cause any errors, but it will expose errors that are (sometimes silently) occurring. @pcarruscag I think you added these tests. Any idea why they're failing?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/649#issuecomment-462951152:291,rout,routine,291,https://su2code.github.io,https://github.com/su2code/SU2/pull/649#issuecomment-462951152,1,['rout'],['routine']
Integrability,"It seems like your situation may have been resolved, but for archival purposes, I'll list my workaround here. This problem occurs when you've installed python packages in two different locations. This could be due to installing some python packages in a system directory (e.g. `/usr/lib/`) and some in a user directory (e.g. `~/.local/`). SU2's build process is set to automatically detect the default package location, but it's not equipped to handle multiple package locations. There are some hardcoded includes, but these only work for python 2.7. I don't consider this a bug *per se* because multiple python package directories is not a standard use case. #### The symptoms. When building SU2 with the python wrapper you'll see the following error during the swig build:; ```; <install directory>/../SU2_PY/pySU2/pySU2.i:64: Error: Unable to find 'mpi4py/mpi4py.i'; ```; But mpi4py is indeed installed on your system and it's on your python path, as confirmed by opening a python terminal and running `import mpi4py`. #### The easiest workaround. Switch to a [virtualenv](https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/). This will ensure that all of your python packages are stored in single location. #### Alternate workaround. In this method, you change the hardcoded includes to match mpi4py's package location. First I figure out where my mpi4py is installed. I start a terminal session of python using the python environment I want to use (in this case, it's python 3.6), and then run:; ```; from mpi4py import MPI; MPI; ```. Since I have mpi4py installed on your system and it's on my python path, I see something like:; ```; <module 'mpi4py.MPI' from '/home/clarkpede/.local/lib/python3.6/site-packages/mpi4py/MPI.cpython-34m.so'>; ```. The `/home/clarkpede/.local/lib/python3.6/` directory is where my mpi4py package is installed. But the swig compile command includes `/home/clarkpede/.local/lib/python2.7/`. That's not the right directory! So first I ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/722#issuecomment-515693590:713,wrap,wrapper,713,https://su2code.github.io,https://github.com/su2code/SU2/issues/722#issuecomment-515693590,1,['wrap'],['wrapper']
Integrability,"It's not always the case that using a restart file is continuing from a simulation. For example, if one has a simulation that has a similar solution as a seed. An example would be doing optimization and using a nearby flow solution. Here, having the iteration count start from zero is useful, because it's the more accurate measure. We would also have to this about how this interfaces with MAX_ITER. Right now it's really clear, but which does it mean when iterations don't start from zero?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/99#issuecomment-103239930:375,interface,interfaces,375,https://su2code.github.io,https://github.com/su2code/SU2/issues/99#issuecomment-103239930,1,['interface'],['interfaces']
Integrability,"Juan,. Indeed, it is desirable that at the highest level the details of the time integration scheme and number of zones per discipline should not be visible. The question is whether that is achievable for all combinations you can think of. This is especially the case for the time integration schemes. E.g. suppose you would like to use a multi-stage time integration scheme for a multi-physics problem. To obtain the design accuracy in time, this implies that the loop over the number of time stages is outside the loop over the number of physical disciplines. Hence at a very high level in the hierarchy, the details of the time integration should then be known. The situation becomes even more complicated when one would like to employ time integration schemes that allow for time accurate local time stepping, e.g. the ones we are currently working on for the DG solver. I won't bore you with all the details here, but those schemes basically require the loop over the multiple disciplines to be between the predictor and corrector step, while both these steps consist of multiple stages. Although it is probably possible to come up with a data structure that supports all this, the question is whether this is desirable. Apart from the fact that it would require a major overhaul in the high level design of SU2, the implementation will be less readable, especially for people that will be starting with the code. Also the parallelization may become significantly more complicated. The alternative is that for unsteady multi-physics problems, we put the restriction that only single stage time integration schemes can be used, e.g. DT_STEPPING_1ST and DT_STEPPING_2ND. In that case, the details of the time integration scheme can be hidden at the driver level, where we then simply have a loop over the number of physical disciplines. The consequence of course is that more advanced time integration schemes will not be available for multi-physics problems. In the above I just tried to picture w",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/437#issuecomment-328441926:81,integrat,integration,81,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328441926,5,['integrat'],['integration']
Integrability,"Nice analysis @clarkpede. It is true that we simplify the Jacobians at the periodic boundaries, mostly to avoid issues with adding entries to the Jacobian from the neighbors that potentially do not live on our rank and to keep communication costs low (those neighbors are treated explicitly). This could be changed to communicate the full Jacobian.. but I am not sure it is worth the effort/cost. The approximation that is made should still be consistent though, because we only allow one of the repeated periodic nodes to participate in the linear solve with each nonlinear iteration, and then we communicate its update to its periodic pair. In short, the value of the solution should always be the same on periodic points with each iteration update, and if the problem converges to a steady-state (even in time stepping mode), the Jacobian should only affect convergence (the RHS should be the same). You could try the time stepping option with one of the RK methods to see if going fully explicit helps further isolate the issue. It could also be something related to the time step that is communicated. In the SetTime_Step() routine in the flow solver class, we do some special checks for time stepping mode to make sure that the minimum global time step is used in all cells. Might want to print out the dT communicated in the periodic comms or write the dT to the solution file to make sure everything is ok there too. Honestly, I don't think a ton of folks use the time stepping option in general with the FVM solver, so double-checking that it behaves well for a non-periodic problem could shed some light too, unless you have already done that.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/763#issuecomment-524007345:1129,rout,routine,1129,https://su2code.github.io,https://github.com/su2code/SU2/issues/763#issuecomment-524007345,1,['rout'],['routine']
Integrability,"Nice progress @pcarruscag!. I like the concept of your SIMD-friendly class that will take care of the data structure under the hood coupled with a standard type of loop statement (w/ +SIMDLEN). This should make it pretty easy for folks to still modify the kernels without having to worry about the data alignment, and they can reuse the same simple 'for' construct repeatedly. . Another reason to have our own lightweight class for this is that you can avoid dependence on OpenMP for SIMD (although that feature looks to have potential and wasn't available until somewhat recently) as well as the intrinsics. In my experience, the latter is especially bad for portability and readability (part of why we left the CaF work in a separate repo). It starts to become so specialized that compiling and modifying become difficult. W.r.t. OpenMP, another roadblock there a few years ago was making sure it is interoperable with CoDi for the adjoint, but I know this has been worked on and may be available by now. Might keep an open mind about point vs. edge. In some places, we may be able to pump up the compute in our loops by fusing kernels, as previously discussed (and I am guessing you are working on this already with gradients/limiters). Could change the final performance numbers significantly. Lastly, I know you are not there yet, but it is worth considering whether you can reuse anything you are developing in the kernels here for the linear solver routines. At some point, you will successfully reduce the cost of the residual kernels (RHS) to the bandwidth limit, and the majority of the iteration cost will be in the linear solver (it is already about 50% of the iteration cost before optimization, if I recall). Before making final decisions on strategy, you should consider if it will help in any of the linear solver routines too.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-530440072:459,depend,dependence,459,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530440072,4,"['depend', 'interoperab', 'rout']","['dependence', 'interoperable', 'routines']"
Integrability,"ON|OFF, disabled when building with Codi; * SU2_BUILD_PY_WRAPPER: ON|OFF, disabled when building with Codi forward; * SU2_BUILD_SOL: ON|OFF, disabled when building with Codi; * Enable modules:; * SU2_ENABLE_CGNS:; * SU2_CGNS_CPPFLAGS: flags to pass when compiling CGNS; * SU2_ENABLE_CODI: no|forward|reverse; * SU2_CODI_CPPFLAGS: flags to pass to SU2 modules when compiling with Codi; * SU2_ENABLE_METIS: ON|OFF; * SU2_METIS_CPPFLAGS: flags to pass when compiling Metis; * SU2_ENABLE_MKL: ON|OFF; * SU2_ENABLE_MPI: ON|OFF; * SU2_ENABLE_MUTATIONPP: ON|OFF; * SU2_ENABLE_PARMETIS: ON|OFF, only available when SU2_ENABLE_MPI is ON; * SU2_PARMETIS_CPPFLAGS: flags to pass when compiling Parmetis; * SU2_ENABLE_TECIO: ON|OFF; * SU2_TECIO_CPPFLAGS: flags to pass when compiling Tecio and TecioMPI; * SU2_TECIOMPI_CPPFLAGS: flags to pass when compiling TecioMPI, requires SU2_ENABLE_MPI. There is an additional variable that is recognized by CMake scripts - DEBUG, turning it ON enables additional STATUS messages, mainly to check that correct include directories, compile definitions and linked libraries were set up correctly. The remaining options like install location and compilers are handled by CMake. Tested this on Ubuntu with CMake 3.15.5 and everything except pySU2ad wrapper compiles. Haven't tested on earlier CMake versions so there might be bugs with them but they should be easy to resolve if any. Related Work. Resolve any issues (bug fix or feature request), note any related PRs, or mention interactions with the work of others, if any. PR Checklist. Put an X by all that apply. You can fill this out after submitting the PR. If you have any questions, don't hesitate to ask! We want to help. These are a guide for you to know what the reviewers will be looking for in your contribution. * I am submitting my contribution to the develop branch.; * My contribution generates no new compiler warnings (try with the '-Wall -Wextra -Wno-unused-parameter -Wno-empty-body' compiler flags).; * My",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/814#issuecomment-552242380:2947,message,messages,2947,https://su2code.github.io,https://github.com/su2code/SU2/pull/814#issuecomment-552242380,1,['message'],['messages']
Integrability,"Ok the ""simple"" version of ""going parallel"" whenever we get to a linear algebra operation did not make the cut.; On an older architecture there was a 10% slowdown of the linear solvers at ~10k nodes per core and about the same on a newer architecture but only at ~1k node per core.; Since hybrid parallel is supposed to be good for strong scaling, this was not good enough... With the new strategy it is ok (see ""performance"" below), hence this is ready for review. ### Overall Strategy; The strategy now is to start a parallel section in CSysSolve::Solve that covers building the preconditioner and solving the linear system.; Linear algebra routines called within this section have _worksharing_ constructs instead of _parallel_ ones, i.e. the work is distributed by however many threads arrive to that routine. This also makes the routines safe to call in serial.; The only ""dangerous"" things to do in parallel are to: manage memory for a shared object (multiple threads call `new` but there is only one shared pointer on which to call `delete`); writing to the same memory locations concurrently.; I tried to make the first issue debugable by asserting that the initialization routines of CSysMatrix and CSysVector are only called by the master thread.; For the second issue I made the associated classes as const-correct as possible, that should at least make someone think twice before changing a member variable of those classes. The risk is still there for input variables as an algorithm development aspect... For example `MatrixVectorProductTransposed` cannot be made thread-parallel as simply/naively as its normal counterpart. ### Communication Model; The MPI + Threads communication model is very simple, currently only the master thread calls MPI routines (including `Error`), this requires thread barriers before and after the communication to make sure the correct values are passed and _seen_ by all threads.; We can test other alternatives in the future but at the moment this does n",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/830#issuecomment-562646766:643,rout,routines,643,https://su2code.github.io,https://github.com/su2code/SU2/pull/830#issuecomment-562646766,3,['rout'],"['routine', 'routines']"
Integrability,"Ok time to share some results after #753.; I deviated a bit from the original plan in that I skipped the contrived strategy of using a wrapper container with a special [] operator (as it had a slight whiff of hackery), and went straight to adding ""iNode"" to the methods of CVariable instead (me and a few lines of python...). The first rule of performance is **""measure it before changing code""**, I broke that rule because as my first post illustrated non contiguous storage at the scale we had is a real killer. With that out of the way, to some extent at least (the layout may not be optimum still) measuring is essential to decide what to do next. This is the case I am using:; ![case](https://user-images.githubusercontent.com/38071223/63288257-27d9d580-c2b4-11e9-9899-8b44b230b8bb.png); It is a bad wing design (NACA0012) with some sweep and taper and a home-brew mesh whose quality rivals that of the design (it converges and the flow does not separate...).; The mesh is just over 500k vertices (so it ""fits"" comfortably in my pc) the y+ is not great (obvs) but the aspect ratios are 200 and 2000 in the chordwise and spanwise directions respectively, so not exactly linear solver friendly either. Some settings which are kinda optimal:; - Mach 0.6, AoA 2 degrees;; - SST (1st order);; - CFL 20 (higher and residuals would limit-cycle (regardless of linear solver settings); - Roe;; - MUSCL - Green-Gauss and Venkat-Wang;; - FGMRES + LU_SGS to 0.05 residual (about 3 iters on avg.);; - 2 levels of MG (1,1,2 iterations, all zeros for other stuff and 0.7 damping both ways);. The case is light on the linear solver and therefore stands to benefit the most from better data layout. Conversely, applications that can take higher CFL / or use central schemes will not benefit as much. **Running this from scratch to residual of 10^-8 on a couple of Xeon E5-2650v4 (24c total) shows a speedup of 1.4 and just over 10% lower memory usage.**; Those numbers will be better for an equivalent 2D case sin",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/716#issuecomment-522730951:135,wrap,wrapper,135,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-522730951,1,['wrap'],['wrapper']
Integrability,"On both questions the answer is yes. Option 1 can be implemented right now but will require the creation of temporary objects. Option 2 can directly forward the data to the blas routines. The tool I am developing is no tool for a specific linear algebra package. The idea is, that the tool parses the header files of the library. The user has then to define which objects are active lvalues and the derivatives for each operation in the library. For small an clear interfaces this is no problem and works already quite good. For large libraries like Eigen I adopted a whitelisting approach. That is, every function needs to be manually whitelisted to trigger the expression generation of the tool. In a prototype way I have also implemented an approach where only the active lvalues need to be defined and the tool looks then for all required functions and other objects that depend on these active objects. Long story short, the tool is designed to handle ""any"" library. It is even possible to mix several libraries together. My current status on this project is, that I am now through with the parsing of the header files and the generation of the expressions. This works quite well for Eigen which is a hardcore testcase, since every possible programming tweak in C++ is used here. The next step is to add the AD part to the expression generation process. I hope that in one or two month this will be finished and I can provide a first beta release.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/643#issuecomment-463561018:178,rout,routines,178,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-463561018,3,"['depend', 'interface', 'rout']","['depend', 'interfaces', 'routines']"
Integrability,"Python's ""self"" which; // makes this solution reasonably idiomatic.; Base::Compute(wv, sol);. // Then do our specific job.; wv.area = 0.0;; for(int i=0; i<nDim; ++i); wv.area += pow(sol.areaVector[i],2);; wv.area = sqrt(wv.area);; }; };. // Same mechanics as above; template<typename Base>; class ComputeFlux : Base; {; protected:; enum : int {nDim = Base::nDim};. struct WorkVarsType : Base::WorkVarsType ; {; double flux; // ...add new member; };. template<typename WV>; void Compute(WV& wv, const SolutionContainer& sol) const; {; // ...call base; Base::Compute(wv,sol);. // ...do aditional work; wv.flux = 0.0;; for(int i=0; i<nDim; ++i); wv.flux += sol.velocity[i]*sol.areaVector[i];; }; };. // This class is used to terminate the chain, it makes the link; // with the interface and it is used to specify any fixed sizes.; template<int NDIM>; class Terminator : private VirtualInterface; {; protected:; enum : int {nDim = NDIM};. struct WorkVarsType {};. template<typename... Ts>; void Compute(Ts&...) const {}; };. // Finally we use the building blocks to implement Compute.; // The blocks can be reordered depending on application to; // help the compiler fuse loops or minimize register spillage,; // the resulting WorkVarsType definition will be equivalent.; class ComposedClass: public; ComputeFlux< ComputeArea< Terminator<3> > >; {; public:; ResultType Compute(const SolutionContainer& sol) const;; };. ResultType ComposedClass::Compute(const SolutionContainer& sol) const; {; // Create the working variables on the stack.; ComputeFlux::WorkVarsType wv;. // Pass down the working variables and whatever other arguments.; // If the convention was followed, all building blocks will run.; // Recall that all Compute's were templates, they will be; // instantiated here and we can force them to be inlined.; ComputeFlux::Compute(wv, sol);. // Do some additional work if needed and return result.; return wv.flux / wv.area;; }; ```; [Care for some assembly?](https://gcc.godbolt.org/z/os-gNg)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-622941617:4722,depend,depending,4722,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-622941617,1,['depend'],['depending']
Integrability,"Regarding periodic boundaries: You have two options. You can hack the code to not allow grid deformation on periodic boundaries. That's a simple code edit, since the code already prevents most boundaries from being deformed. Let me know if you want to use this option, and I can point you to those lines. Second, you can use the `HOLD_GRID_FIXED` and `HOLD_GRID_FIXED_COORD` options to prevent grid deformation outside a specific box. I have found this option to be better overall, since it also makes the linear system easier to solve in `SU2_DEF`. The `DV_VALUE` and `FINDIFF_STEP` are different. I've only seen `FINDIFF_STEP` used for the finite-differencing python script, though it may have other uses I am not aware of. The `DV_VALUE` depends on the context. When using `SU2_DOT`, `DV_VALUE` is set to its default value. But when performing shape optimization using SU2's framework, the `DV_VALUE` parameters will be set based on the output of SLSQP (or whatever optimization framework you're using).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/976#issuecomment-626799862:741,depend,depends,741,https://su2code.github.io,https://github.com/su2code/SU2/issues/976#issuecomment-626799862,1,['depend'],['depends']
Integrability,"Surprisingly I have found the existing content related to plasma simulation in SU2. Really amazing. Could anyone give me any clues of the correspondent .cfg files? Or help me find the governing equations change which makes the plasma equations different from the neutral gas. ; ; ![image](https://user-images.githubusercontent.com/33152225/61871269-5fef3200-af1b-11e9-82c5-cd8418a6f83c.png). It already seems good enough at considering *E* field, but *B* is omitted. I can strive to supplement the equation. Could anyone give some guidance to me, a newcomer of SU2?. [Stanford University Unstructured An open-source integrated computational environment for multi-physics simula.pdf](https://github.com/su2code/SU2/files/3431264/Stanford.University.Unstructured.An.open-source.integrated.computational.environment.for.multi-physics.simula.pdf)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/741#issuecomment-515010918:616,integrat,integrated,616,https://su2code.github.io,https://github.com/su2code/SU2/issues/741#issuecomment-515010918,2,['integrat'],['integrated']
Integrability,Thank you for the feedback but for 99% of cases it is easier for users if we download the dependencies for them. The philosophy behind SU2 has always been to provide as much of a self contained package as possible.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1945#issuecomment-1450323672:90,depend,dependencies,90,https://su2code.github.io,https://github.com/su2code/SU2/issues/1945#issuecomment-1450323672,1,['depend'],['dependencies']
Integrability,"Thank you for the review @economon.; I just gave the multiple constraints a try on the hybrid onera m6 mesh we have in testcases, it works, both points and edges can be balanced, but the edge cuts go up by almost 50% I guess that makes sense, more constraints less minimization.; There's another reason why I like the combined function, balancing the ""num neighbors"" metric is not exactly the same as balancing the number of edges per partition, using a small negative point weight (-1, -2) yields better results (but the ideal value will be case dependent). I think the next big improvement we can make in this area is to use a partitioner that is aware of the network topology, ParMETIS assumes that the communication cost between any two ranks is the same, this simplification can be very costly on large parallel machines that have a tree-like network topology, and in older clusters with slow interconnects (relative to intra node communication).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1059#issuecomment-671054807:547,depend,dependent,547,https://su2code.github.io,https://github.com/su2code/SU2/pull/1059#issuecomment-671054807,1,['depend'],['dependent']
Integrability,"Thanks @MicK7 I will have a look, my initial thought was to have a simple strategy where within each MPI rank parallelism is extracted via colouring or scatter-to-gather transformations and only one thread per rank participates in the message passing, I have no experience here though so this might be a bad strategy, idk. **Back to business:**; I went silent for a bit because in prototyping a typical residual computation and matrix update loop I made some realisations that made me go back to the drawing board regarding data structures, and eventually back to square 0. . ## Parallel strategy for flux computation; Because significant computation is required to obtain each edge's flux, it does not make sense to attempt a ""point-loop"" strategy (which would double the effort).; However, one can either use colouring to avoid the race conditions that would result from updating the residual of cells i and j, or store the edge fluxes and then, on a second point-loop perform the summation of fluxes for each cell, with the direction being accounted by the same adjacency information used in the point-loop GG gradient computation.; If we consider only the update of residuals the two strategies are fairly equivalent performance wise, the tie breaker is the matrix updates. ## Matrix Updates; By this I mean the `addBlock`, `subBlock` we do (two times each) to update diagonal and off-diagonal blocks for each edge.; Here is a dummy numerics loop that does nothing else but setting blocks in the matrix (with colouring).; ```c++; void testLoop1(const vector<size_t>& colorStart,; const vector<size_t>& edgeIdx,; const vector<pair<size_t,size_t> >& connectivity,; double** blk_i, double** blk_j,; SparseMatrix& matrix); {; matrix.setZero();. for(size_t color=0; color<colorStart.size()-1; ++color); #pragma omp parallel for schedule(dynamic,CHUNK_SIZE); for(size_t k=colorStart[color]; k<colorStart[color+1]; ++k); {; size_t iEdge = edgeIdx[k];; size_t iPoint = connectivity[iEdge].first;; size_t j",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-535977206:235,message,message,235,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206,1,['message'],['message']
Integrability,"Thanks for the quick review @pcarruscag. I have cleaned up a little bit. Also added a nicer table of the output. l prefer that we always compute the min/max values, at least for the FVM CFD solvers, for a few reasons. The most important reason is that we should start to build up some intuition about the correlation between mesh quality metrics and accuracy + convergence in the solvers. This can be especially important during optimization when the mesh is deforming. I think the metrics are valuable to print every time for this reason, which might help users diagnose problems eventually. Additionally, the cost is relatively small (on par with the other pre-processing routines, it is only executed once and it is parallelized, and the memory is released if we don't write).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/778#issuecomment-526456264:674,rout,routines,674,https://su2code.github.io,https://github.com/su2code/SU2/pull/778#issuecomment-526456264,1,['rout'],['routines']
Integrability,"Thanks for your comments! Except for mixing plane and frozen rotor, sliding plane is also pretty common in turbomachinery simulation, it is indeed implemented in some, if not all, in-house codes. ; MRF is quite useful in turbomachinery simulation, expecially when we deal with transient simulation. Actually it is really rare to move the rotor mesh like in reality. One reason is that MRF is more efficient and accurate. Otherwise, you introduce new disturbance into the transient flow field every physical time step, which is not good. Because when you rotate the mesh, the velocity direction of each grid point inherited from last time step is not rotated. To make it more clear, you will have a flow going towards casing instead of parallel to, at the start of next physical time step. So you need more pseudo time steps to get a proper velocity variable. As a result, you get a zig-zag shape in the residual history.; I'm not actually moving the interface. The rotor mesh is not rotated, so as the interface at rotor zone. I'm just virtually rotating the rotor interface to find the new matching points between rotor and stator for each physical time step, so that the variable could be passed across the interface. In other words, only the passing variables are actually rotated. If I understand it correctly, there is no additional moving mesh restriction introduced here.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/2173#issuecomment-1953783506:950,interface,interface,950,https://su2code.github.io,https://github.com/su2code/SU2/pull/2173#issuecomment-1953783506,4,['interface'],['interface']
Integrability,"Thanks, @clarkpede, for this PR and for the clear explanation of the features proposed. LGTM in terms of implementation and code style. I'll just wait for @EduardoMolina to comment on the contents. I only have a couple of minor questions:. > I moved the calculation of the maximum cell width to the CPhysicalGeometry class. This makes inclusion in the central/upwind blending easier. For DES and DDES, the cell lengthscale is not dependent on the flow. So there's no need to compute it every iteration in the flow solver. I can see this approach reduces the computational cost of computing the MaxLength every time at the cost of having one more double in memory per point. However, would a call to SetMaxLength() be necessary in case of deformable meshes? . Also, from PR #532:; > As for code verification, I would propose using one of the cases examined by Travin, Stretlets, Mockett, or Xiao for comparison. (...) The cases I can see where they explicitly show the results of the blending function are: Circular cylinder at Re = 50,000 (Travin et al. 2002) (...). I guess this is the case for which you are showing the rough tests results in the Code Verification section. I am currently looking into some test cases at similar Re regimes. Are you using the unsteady compressible solver for this verification? I noticed that in Ref.[1] they use artificial compressibility, and I was wondering if we could also use this test case to look into the unsteady, incompressible (preconditioned) version of the solver (PR #514).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/552#issuecomment-403842613:430,depend,dependent,430,https://su2code.github.io,https://github.com/su2code/SU2/pull/552#issuecomment-403842613,1,['depend'],['dependent']
Integrability,"The source term is pretty simple but the feature as a whole is very intrusive on the code, even the mesh deformation is getting involved in this.; Would it be viable to use the python wrapper to provide the source term?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/2273#issuecomment-2098573850:184,wrap,wrapper,184,https://su2code.github.io,https://github.com/su2code/SU2/pull/2273#issuecomment-2098573850,1,['wrap'],['wrapper']
Integrability,"This bug pops up because the periodic mesh reconstruction (in `SU2_MSH`) doesn't always create a valid mesh in 3D. Some points disappear, and some points are duplicated. When `SU2_CFD` (specifically, `CPhysicalGeometry`) tries to get the number of points in the domain, it calculates the wrong number because some of those points are duplicated. That leads to segfaults, because the output routine thinks the extra (missing) points belong to another processor. I've got a little toy problem with a simple periodic cube. It's easy to see on the simple 4x4x4 (+ periodic) problem that 3 nodes disappear, and 3 nodes are duplicated. I've never observed this problem in any of the 2D test cases I ran. As to why `SU2_MSH` is missing some points and duplicating others, I'm not sure. I tried running Valgrind to check for uninitialized variables or illegal memory access, but nothing there. I'll have to look more into the problem. The `su2_periodic.f90` script mentioned in #416 seems to be a workaround. I don't run into any problems when I use that script.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/431#issuecomment-337056131:390,rout,routine,390,https://su2code.github.io,https://github.com/su2code/SU2/issues/431#issuecomment-337056131,1,['rout'],['routine']
Integrability,"This is very interesting, since I often find that I am commenting out most of the python regression script when debugging only a couple of tests locally. Can you estimate how much work this would be? Is it just a simple wrapping of what we already have? We would also have to make sure that Travis CI can handle it.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/462#issuecomment-342593274:220,wrap,wrapping,220,https://su2code.github.io,https://github.com/su2code/SU2/issues/462#issuecomment-342593274,1,['wrap'],['wrapping']
Integrability,"Unfortunately, my example involves a swirler and nozzle for the; Navier-Stokes solver with Menter model, so the dataset is relatively large.; Let me check whether some older small Euler mesh exhibits the same message!; I will let you know! Thank you very much. On Mon, Oct 23, 2023 at 6:34 PM Pedro Gomes ***@***.***>; wrote:. > Is there a simple example to reproduce the issue?; >; > —; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/pull/2109#issuecomment-1776057496>, or; > unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AHGXZUV3DNRF3O55YAWT563YA3PETAVCNFSM6AAAAAA3QKLVDWVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMYTONZWGA2TONBZGY>; > .; > You are receiving this because you commented.Message ID:; > ***@***.***>; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/2109#issuecomment-1776143584:209,message,message,209,https://su2code.github.io,https://github.com/su2code/SU2/pull/2109#issuecomment-1776143584,1,['message'],['message']
Integrability,"We already require C++11 for some more advanced features, but it is always nice in my opinion to keep backward compatibility when possible. . However, this is not a deal breaker, I don't think, as most developers that want to use and add their own unit tests should have no problem with using C++11. If we can make it an optional dependency, to make sure the basic build still works simply, I think it could be ok.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-503685445:330,depend,dependency,330,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-503685445,1,['depend'],['dependency']
Integrability,"Wonderful contribution. Thanks for doing all that. Streamlining the dev process is very helpful and cmake is definitely becoming a standard. Best,. Juan. On Nov 10, 2019, at 11:24 AM, Daumantas Kavolis <notifications@github.com> wrote:. ﻿; Proposed Changes. Added CMake build support for SU2. With this, many popular IDEs will be able to use SU2 as a project with minimal setup. CMake also enables to add dependencies more easily since most libraries have CMake support. vcpkg is great for the libraries available there. SU2 CMake has the same build options as autotools but uses CMake to find system libraries and compilers (MKL, Mutationpp, MPI and Python currently). No longer need to specify paths to compilers/libraries if they are in standard locations. In addition, compile flags can be modified from CMake. There is no need to use preconfigure.py anymore since downloading/unpacking is handled by CMake and is system-agnostic. At the moment, all library targets are static but that could be easily changed to be configurable from CMake. The installation directory is ${CMAKE_PREFIX_PATH}/bin. Similarly to autotools, some build options are disabled if built with Codi forward/reverse datatypes or without MPI. Note that SWIG fails to compile pySU2ad with Nothing known about namespace 'medi' in Common/include/mpi_structure.hpp:57 without -includeall SWIG option but then it takes forever to generate the wrapper (more than 15 minutes on my machine, stopped early). I suggest removing using namespace declarations and either importing used symbols explicitly with using or prepending namespace name, clang-tidy warns against them by default and it makes the code clearer. SU2 CMake options are:. * Build modules:; * SU2_BUILD_CFD: ON|OFF; * SU2_BUILD_DEF: ON|OFF, disabled when building with Codi; * SU2_BUILD_DOT: ON|OFF, disabled when building with Codi forward; * SU2_BUILD_GEO: ON|OFF, disabled when building with Codi; * SU2_BUILD_MSH: ON|OFF, disabled when building with Codi; * SU2_BUIL",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/814#issuecomment-552242380:405,depend,dependencies,405,https://su2code.github.io,https://github.com/su2code/SU2/pull/814#issuecomment-552242380,1,['depend'],['dependencies']
Integrability,"Writing a simple unit test is difficult, since SU2 both doesn't have unit tests and wasn't written with unit testing in mind. That being said, I've got a unit test that I'm happy with. Our group has put our own unit-testing framework into our fork of SU2, based off of Boost and automake testing. The unit test I created runs off of that framework. That means it won't run out-of-the-box on the develop branch of SU2. When I run the unit test with no changes to `CNumerics::GetViscousProjJacs`, I get that the residuals and Jacobians match to within 10 times the machine epsilon, aside from the [4][0] value of the Jacobians. There, the relative difference is of the order 1E-6. When I switch the two lines in `CNumerics::GetViscousProjJacs` for ideal gases to be negative, the tests run with no complaints. Ideal gas and generalized variants match to within 10 times machine epsilon. I'm uploading my test file just as an example, in case anyone wants to see what I've tested.; [viscous_ideal_vs_general.zip](https://github.com/su2code/SU2/files/2590517/viscous_ideal_vs_general.zip). As for comparison to some results from another code, I think that's a lot to ask. Getting a good comparison would depend on an understanding of how the ideal gas model, viscosity, numerics, and Jacobians are handled in the external code. Small differences would make the comparison completely invalid. I completely support testing and checking the changes I'm proposing. But comparison with an external code seems to provide a very low return on investment.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/609#issuecomment-439491945:1200,depend,depend,1200,https://su2code.github.io,https://github.com/su2code/SU2/issues/609#issuecomment-439491945,1,['depend'],['depend']
Integrability,"YES! I am excited to try this out. I can probably test it on some of the other TMR cases (airfoils, flatplates). Will post the results when I get those done. . Side note, there was one issue that @bmunguia and I encountered when performing optimizations with adaptive CFL. Say the DIRECT simulation is run with adaptive CFL and is well converged (6 to 8 orders of residual reduction). When the discrete adjoint performs the one direct iteration to store the computational graph, it uses the initial CFL value, not the CFL that the adaptive CFL routine ended at. This results in the residuals being very high for that one iteration, which then affects the convergence of the discrete adjoint. . I will try to run an adjoint on one of these cases as well to see if the problem persists. Perhaps could be overcome with a simple additional field for CFL in the restart meta-data",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/790#issuecomment-531520526:544,rout,routine,544,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-531520526,1,['rout'],['routine']
Integrability,"Yes for MARKER_ROUGH, or MARKER_ROUGH_WALL to be clearer.; Or just WALL_ROUGHNESS as you have right now, since it would not really a marker, just the properties of markers (and I've seen some people on CFD online confused with similar naming e.g. MARKER_SHROUD). Regarding the MPI stuff, I had the following idea over lunch:; In CPhysicalGeometry::SetWallDistance we compute the closest distance, and in so doing we also get the mpi rank and markerID associated with the closest vertex.; So, before computing the wall distances you communicate the local marker ids and wall roughness's (via Allgather as you are doing now), with this info you can build a `unordered_map<pair<int,int>, su2double>` to map pairs of <rank,markerID> to the values of roughness.; Now when you loop over the points to compute the distances you can retrieve the roughness from this map instead of from config.; It's almost exactly the same as you have, but avoids using the config as a messenger between routines, and using a stl map should also make the code simpler. In the boundary conditions you can still get the marker roughness via the marker tag as you are doing now, and I guess the wall type (smooth / rough) can be inferred from having 0 (default) roughness (?); With the string+double list specification you also avoid having to specify 0 roughness and SMOOTH wall type for markers where you don't want to use this feature.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/877#issuecomment-630861158:980,rout,routines,980,https://su2code.github.io,https://github.com/su2code/SU2/pull/877#issuecomment-630861158,1,['rout'],['routines']
Integrability,"Yet another doubt on the same subject: I just realized that SU2V7.31 (I; have not tested it on later SU2 releases) accepts imposing both adiabatic; walls plus isothermal boundary condition on some walls (when running Menter; model), but when I simply impose only isothermal conditions (leaving; commented out the adiabatic markers), I get the message: SU2 process; returned error '1'. Is there a workaround for this? Kind regards. On Thu, Sep 28, 2023 at 8:25 PM Pedro Gomes ***@***.***>; wrote:. > you are correct, there is a discussion on CFD-online about it. we impose 0; > heat flux, but report an ""apparent heat flux"" most codes will simply give; > you back the imposed heat flux value you specify, nevertheless there will; > probably be a temperature gradient close to the wall; >; > —; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/pull/2109#issuecomment-1740118992>, or; > unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AHGXZUUZNE6B63SH7XJLY2DX4YBMZANCNFSM6AAAAAA3QKLVDU>; > .; > You are receiving this because you commented.Message ID:; > ***@***.***>; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/2109#issuecomment-1775968391:343,message,message,343,https://su2code.github.io,https://github.com/su2code/SU2/pull/2109#issuecomment-1775968391,1,['message'],['message']
Integrability,"```diff; $ git --no-pager diff --cached ; diff --git a/meson.build b/meson.build; index ca86992ea..b68a03c52 100644; --- a/meson.build; +++ b/meson.build; @@ -1,15 +1,12 @@; project('SU2', 'c', 'cpp',; version: '7.5.1 ""Blackbird""',; + meson_version: '0.61.1',; license: 'LGPL2',; default_options: ['buildtype=release',; 'warning_level=0',; 'c_std=c99',; 'cpp_std=c++11']); ; -if meson.version() != '0.61.1'; - error('SU2 must be configured with the extended Meson script (./meson.py) in the SU2 root directory.'); -endif; -; pymod = import('python'); python = pymod.find_installation(); ; ```. I used this patch, and then ran the following:. ```; $ meson setup builddir --wipe; The Meson build system; Version: 1.0.1; Source dir: /tmp/SU2; Build dir: /tmp/SU2/builddir; Build type: native build. meson.build:1:0: ERROR: Meson version is 1.0.1 but project requires 0.61.1; ```. Using the >= comparison, it configures fine, and downloads a git submodule for mutationpp/coolprop on demand. From a hasty look around, it seems like the other git submodules are used as externals/ directories, not meson subprojects. Another project I know uses e.g. ```; if not fs.exists('submoduledir/README.md'); error('Missing the `submoduledir` submodule! Run `git submodule update --init` to fix this.'); endif; ```. for each submodule before it gets processed by meson. This is less automatic than wrapping it in meson.py, but does provide pretty clear directions... the sticking point is if people download tarballs. You currently point people to github's autogenerated archives, which is NOT sufficient as it doesn't have submodules included. I would actually suggest using `meson dist --include-subprojects --no-tests` to produce your own tarballs and attach them as additional releases artifacts. Meson *does* include submodules (whether or not they are subprojects) automatically to the tarball it creates.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1945#issuecomment-1451057434:1382,wrap,wrapping,1382,https://su2code.github.io,https://github.com/su2code/SU2/issues/1945#issuecomment-1451057434,1,['wrap'],['wrapping']
Integrability,"aively as its normal counterpart. ### Communication Model; The MPI + Threads communication model is very simple, currently only the master thread calls MPI routines (including `Error`), this requires thread barriers before and after the communication to make sure the correct values are passed and _seen_ by all threads.; We can test other alternatives in the future but at the moment this does not seem to be a significant bottleneck.; _Worksharing_ constructs have implicit barriers at completion, for CSysVector routines I used `nowait` modifiers, it is safe to call those routines in sequence since the loop sizes, and static work scheduling specifications are identical.; However, routines that access a CSysVector in a different way, should have an explicit barrier before using the vector (or risk having undefined behaviour). You will see these barriers on entry to matrix-vector product, and every `ComputeXXXPreconditioner` (if you don't, let me know xD). I think those routines are large enough to amortise the cost of this. ### Performance; Disclaimer:; - We are talking about linear solvers only, **you will not see a global improvement yet**.; - The large global improvements from ""hybridization"" will come from the multigrid behaving better on less decomposed domains, and from the ability to independently tune the number of cores used in the linear preconditioners. For now the objective is ""just"" not to loose performance while gaining flexibility.; - The performance of MPI+threads with 1 thread per rank will be worse than just MPI (no free lunches). With this [small case](https://github.com/su2code/SU2/files/3933059/small_case.zip) using 8 cores off a machine with two 2650v4 CPU, Intel MPI 2018 + GCC 8.2, the hybrid (2 ranks of 4 threads) approach is about 5% faster thank the MPI-only (8 ranks), I expect larger cases to have identical performance. ### How To; - Compile: Add -fopenmp to the compiler and linker arguments.; - Run: Set number of threads with env variable `OM",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/830#issuecomment-562646766:2585,rout,routines,2585,https://su2code.github.io,https://github.com/su2code/SU2/pull/830#issuecomment-562646766,1,['rout'],['routines']
Integrability,"ares (indeed what I need now is a QR decomposition). And, as an added bonus, I think some other areas of the code could be simplified / optimized by adopting a dense matrix format, for example:; - This snipped from the viscous numerics refactoring`for (iDim = 0; iDim < nDim; iDim++) {; TauElem[iDim] = 0.0;; for (jDim = 0; jDim < nDim; jDim++); TauElem[iDim] += tau[iDim][jDim]*UnitNormal[jDim];; }` would simply become `TauElem=tau*UnitNormal`; - Cumbersome allocations like `tau_jacobian_i = new su2double* [nDim];; for (iDim = 0; iDim < nDim; iDim++) {; tau_jacobian_i[iDim] = new su2double [nVar];; }` become `Matrix tau_jacobian_i(nDim,nVar);` and the cleanup is dealt with by the destructor of the object automatically. Now to answer some questions.; @juanjosealonso @erangit LAPACK and BLAS are indeed the standard, so much so that most (all?) newer libraries will call their routines behind the scenes.; However they considerably simplify the user interface by encapsulating the aforementioned construction/destruction and by exposing natural ways of manipulating the matrices, e.g. access entire rows, columns, blocks, etc.; Another issue with using BLAS routines is that we then need to provide a portable version that can be differentiated with CoDi or to implement the exact differentiation (similar to what is done in the ""solve_b"" routines). @vdweide that is not an issue with Eigen because everything is templated and therefore compatible with any type or class that overloads the appropriate arithmetic operators.; I have used it for over 2 years and I can attest to its compatibility with AD tools (I've tried 3), and speed when linked with a BLAS library, their native implementations are also very good, peeking inside their code... you can tell they know what they are doing. P.S. I feel this post needs a disclaimer, I am not affiliated in any way to Eigen, my motivation is not to promote their work (but I obviously think they deserve it). I genuinely think adopting an algebr",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/643#issuecomment-459653772:1978,interface,interface,1978,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459653772,1,['interface'],['interface']
Integrability,"both codes deliver the same results (of course with some minor differences). So far so good. Unsteady cases are a bit trickier: the latest 2D results of @RoccoBombardieri show pretty much no difference including the first timesteps. The onera m6 case in contrast converges to the same (steady-state) results for both code version eventually but their initial transient phase differs quite significantly. . A possible explanation for the different initial transient phase: In both implementations a ""reflected state"" is constructed where the normal component of the velocity is subtracted [once in the older code version & twice in the newer version]. I.e. subtracting the normal component of velocity twice means mirroring the velocity along the symmetry plane. The newer code version is a bit ""stronger"" in enforcing the boundary conditions which could lead to the reduced oscillation in CD and CL. If we agree that both code versions produce physically correct results for steady cases and unsteady cases that were integrated long enough in time to get rid of the influence of the initial condition ... then we are left with this initial transient phase that differs. Of course if there is more evidence that one or the other version produces physically ""better"" results I would love to see that. Until then, both initial oscillations are equally correct/uncorrect in my opinion. [I'll add a few words about the adjoint here later]. [I'll add the idea of an FSI case of @cvencro here later where the initial phase has a major impact]; Consider an FSI computation of an airfoil where the trailing edge can exhibit flutter (periodic up-and-down-movement of the trailing edge) in certain flow regimes. Now if during the initial transient the forces on the airfoil are higher than in the converged state then the fluttering can be excited where the initial transient can be seen as an activation energy. If you were to e.g. ramp up flow speed/conditions slowly up to the same magnitude as before one mig",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/828#issuecomment-563314747:1909,integrat,integrated,1909,https://su2code.github.io,https://github.com/su2code/SU2/issues/828#issuecomment-563314747,1,['integrat'],['integrated']
Integrability,"ch request to make it clearer. Request: Use nomenclature consistent with the C++ interface (point instead of node, etc.); Reason: People who know the C++ interface will know how to use the python wrapper straight away, people who learn how to use the python wrapper will be able to understand the C++ implementation (without needing a translation layer in their mind all the time). Request: Return connectivity/adjacency as local indices instead of global; Reason: This is the natural way of referencing data in an MPI code, local indices correspond directly to data stored in the partition thereby making it more efficient to access (without global-to-local conversions, which are much more expensive than local-to-global). Furthermore, the local ordering strategy improves the efficiency of loops (over edges, neighboring points, etc.). Request: Do not apply unnecessary ""transformations"" to the connectivity/adjacency as part of the API; Reason: Increases the maintenance burden and makes for a less versatile API. By returning the local indices that form a marker or element, it is trivial to retrieve any other data for those indices (the ""transformation""). For example, the solution at those points, the point coordinates, whether the points are halo or domain points, the global indices, etc.; This way, by adding a **single** function to the API e.g. get the global index of a point of element, the functionality of the API grows a lot more because the user can apply the function to **any** connectivity/adjacency function. Request: Do not offer too many overloads of the same function; Reason: Increases the maintenance burden and it's returning the data in structures that are not very efficient, namely vector of vectors. It is much easier to offer domain-wide data access on the python side, as a very small function that can be part of wrapper utilities (i.e. live only in python but not c++). It may even be more efficient since you make a numpy array/matrix instead of lists of lists.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1300#issuecomment-1402197827:1875,wrap,wrapper,1875,https://su2code.github.io,https://github.com/su2code/SU2/pull/1300#issuecomment-1402197827,1,['wrap'],['wrapper']
Integrability,"connectivities,; const Matrix& coords,; const Matrix& phi,; const VectorOfMatrix& grad,; const Matrix& limiter,; RowMajorMatrix& residual,; SparseMatrix& matrix); {; using FltVec = Array<double,SIMDLEN>;. residual.setZero();; matrix.setDiagZero();. size_t color = 0;; for(const auto& connectivity : connectivities); {; #pragma omp parallel for schedule(dynamic,CHUNK_SIZE); for(size_t iEdge=0; iEdge<connectivity.size(); iEdge+=SIMDLEN); {; auto iPoint = connectivity.first_vec(iEdge);; auto jPoint = connectivity.second_vec(iEdge);. FltVec d_ij[MAXNDIM];; for(size_t iDim=0; iDim<nDim; ++iDim); d_ij[iDim] = (coords.getVec(jPoint,iDim)-coords.getVec(iPoint,iDim))*0.5;. FltVec phiL[MAXNVAR], phiR[MAXNVAR], flux[MAXNVAR],; blk_i[MAXNVAR*MAXNVAR],; blk_j[MAXNVAR*MAXNVAR];. for(size_t iVar=0; iVar<nVar; ++iVar); {; // Reconstruction goes here. flux[iVar] = (phiL[iVar]+phiR[iVar])*0.5;; }. // some silly way to make the Jacobians depend on the reconstruction; for(size_t iVar=0; iVar<nVar; ++iVar); for(size_t jVar=0; jVar<nVar; ++jVar); blk_j[iVar*nVar+jVar] = (phiL[iVar]*phiR[jVar]-phiL[jVar]*phiR[iVar])*0.5;. // the matrix-matrix multiplications; for(size_t i=0; i<WORKITERS; ++i) {; // blk_i = blk_j * blk_j; for(size_t k=0; k<nVar*nVar; ++k) blk_j[k] = blk_i[k];; }. // something akin to a dissipation term; for(size_t iVar=0; iVar<nVar; ++iVar) {; FltVec sum = flux[iVar];; for(size_t kVar=0; kVar<nVar; ++kVar); sum += blk_j[iVar*nVar+kVar]*(phiL[kVar]-phiR[kVar])*0.5;. // residuals for iPoint and jPoint updated here. matrix.updateBlocks_v(color, iEdge, iPoint, jPoint, blk_i, blk_j);; }; ++color;; }; }; ```; The more WORKITERS we have the better the vectorized code is going to look, I used a conservative number based on:; For the Roe scheme 4 matrices are generated (Jacobian i, Jacobian j, P tensor, P^-1 tensor), each coefficient of those matrices requires a reasonable number of floating point ops, and two of those matrices are indeed multiplied by each other.; So lets say 5 matri",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-539177957:1657,depend,depend,1657,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-539177957,1,['depend'],['depend']
Integrability,"dd dependencies more easily since most libraries have CMake support. vcpkg is great for the libraries available there. SU2 CMake has the same build options as autotools but uses CMake to find system libraries and compilers (MKL, Mutationpp, MPI and Python currently). No longer need to specify paths to compilers/libraries if they are in standard locations. In addition, compile flags can be modified from CMake. There is no need to use preconfigure.py anymore since downloading/unpacking is handled by CMake and is system-agnostic. At the moment, all library targets are static but that could be easily changed to be configurable from CMake. The installation directory is ${CMAKE_PREFIX_PATH}/bin. Similarly to autotools, some build options are disabled if built with Codi forward/reverse datatypes or without MPI. Note that SWIG fails to compile pySU2ad with Nothing known about namespace 'medi' in Common/include/mpi_structure.hpp:57 without -includeall SWIG option but then it takes forever to generate the wrapper (more than 15 minutes on my machine, stopped early). I suggest removing using namespace declarations and either importing used symbols explicitly with using or prepending namespace name, clang-tidy warns against them by default and it makes the code clearer. SU2 CMake options are:. * Build modules:; * SU2_BUILD_CFD: ON|OFF; * SU2_BUILD_DEF: ON|OFF, disabled when building with Codi; * SU2_BUILD_DOT: ON|OFF, disabled when building with Codi forward; * SU2_BUILD_GEO: ON|OFF, disabled when building with Codi; * SU2_BUILD_MSH: ON|OFF, disabled when building with Codi; * SU2_BUILD_PY_WRAPPER: ON|OFF, disabled when building with Codi forward; * SU2_BUILD_SOL: ON|OFF, disabled when building with Codi; * Enable modules:; * SU2_ENABLE_CGNS:; * SU2_CGNS_CPPFLAGS: flags to pass when compiling CGNS; * SU2_ENABLE_CODI: no|forward|reverse; * SU2_CODI_CPPFLAGS: flags to pass to SU2 modules when compiling with Codi; * SU2_ENABLE_METIS: ON|OFF; * SU2_METIS_CPPFLAGS: flags to pass when ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/814#issuecomment-552242380:1413,wrap,wrapper,1413,https://su2code.github.io,https://github.com/su2code/SU2/pull/814#issuecomment-552242380,1,['wrap'],['wrapper']
Integrability,"easier implementation experience. Certainly, this is not the only consideration but it should be taken into account. Currently, resulting from the significant contributions of the members of this developers group, SU2 implementation works like a charm. I think we should strive to conserve this feature, especially if we aim at attracting more users and developers into the community. (...). >@vdweide; >(...) @bmunguia and @EduardoMolina, what type of application did you have in mind for PETSc? The only thing I can think of is a full Newton solver. And no matter how much I like PETSc, @juanjosealonso and @erangit have a point here. Looks like I start to belong to the group of old conservatives as well.... >@economon ; >(...) If you really would like to give PETSc a shot, I recommend talking with @anilvar who had an interface for connecting it to SU2 in one of our branches. >@pcarruscag; >(...) being able to use PETSc or HYPRE would be interesting as it would give us access to AMG, and @talbring 's branch feature_template_linear_solver would make such an integration compatible with AD. (...). >@EduardoMolina; >(...) When Brian (@bmunguia ) and I mentioned PETSc, it was an idea to try a different Newton-Krylov (with preconditioner) library in order to improve the convergence of SU2.; Since the slow convergence of the SU2-FV is the main feedback that I received from other users from industry and academia, I think it worth try an external library and evaluate the performance. (...). >@pcarruscag ; >(...) That is something I am also interested in as for some of my structural cases the current linear solvers simply do not converge. (...). >@economon ; >I would add one practical comment for consideration: it is worth checking whether the main restriction we have is related to approximations in the Jacobian that limit the effective CFL we can use or whether the convergence of the linear solver itself is a problem (speed or complete lack of convergence). A quick test without re",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/648#issuecomment-460853218:2535,integrat,integration,2535,https://su2code.github.io,https://github.com/su2code/SU2/issues/648#issuecomment-460853218,1,['integrat'],['integration']
Integrability,"eps for unsteady problems.; * Loop over the number of pseudo-time steps for implicit time integration schemes; (DT_STEPPING_1ST and DT_STEPPING_2ND). For other cases this loop is 1.; * Loop over the number of disciplines involved; Call iterate for each of the disciplines.; In iterate:; * Loop over the (Runge-Kutta) stages; * Loop over the zones of a single discipline; Compute spatial residual.; Update the state vector.; * End loop over the zones of a single discipline.; Exchange halo data. This includes the halo data between zones of a single discipline.; * End loop over the (Runge-Kutta) stages; * End loop over the disciplines; * End loop over the pseudo time steps.; * End loop over the number of iterations, or time steps for unsteady problems. The weakness of this approach is that it still does not work when one would like to employ multi-stage time integration schemes for an unsteady, multi-disciplinary problem (does not work for the current implementation either), but maybe this is something we simply have to accept. The alternative is that all the details of the different time integration schemes have to be moved to the driver classes, which is highly undesirable, I think. The structure above implies that the iteration_container and the integration_container should be defined per discipline and not per zone anymore. The geometry_container and solver_container should still be defined per zone. Well, I suppose this leaves plenty of room for discussion, so I would say to continue the online discussion a bit further, such that things become a bit clearer how to tackle this issue. After that having a telecon would be good to iron out the details. Regards,. Edwin. —; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/437#issuecomment-328368371>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADpSxHiNAbZtzVEvIm0XDsNvQmZ6lrwwks5shEHjgaJpZM4PQ90s>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/437#issuecomment-328403160:3260,integrat,integration,3260,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328403160,1,['integrat'],['integration']
Integrability,"implified / optimized by adopting a dense matrix format, for example:; - This snipped from the viscous numerics refactoring`for (iDim = 0; iDim < nDim; iDim++) {; TauElem[iDim] = 0.0;; for (jDim = 0; jDim < nDim; jDim++); TauElem[iDim] += tau[iDim][jDim]*UnitNormal[jDim];; }` would simply become `TauElem=tau*UnitNormal`; - Cumbersome allocations like `tau_jacobian_i = new su2double* [nDim];; for (iDim = 0; iDim < nDim; iDim++) {; tau_jacobian_i[iDim] = new su2double [nVar];; }` become `Matrix tau_jacobian_i(nDim,nVar);` and the cleanup is dealt with by the destructor of the object automatically. Now to answer some questions.; @juanjosealonso @erangit LAPACK and BLAS are indeed the standard, so much so that most (all?) newer libraries will call their routines behind the scenes.; However they considerably simplify the user interface by encapsulating the aforementioned construction/destruction and by exposing natural ways of manipulating the matrices, e.g. access entire rows, columns, blocks, etc.; Another issue with using BLAS routines is that we then need to provide a portable version that can be differentiated with CoDi or to implement the exact differentiation (similar to what is done in the ""solve_b"" routines). @vdweide that is not an issue with Eigen because everything is templated and therefore compatible with any type or class that overloads the appropriate arithmetic operators.; I have used it for over 2 years and I can attest to its compatibility with AD tools (I've tried 3), and speed when linked with a BLAS library, their native implementations are also very good, peeking inside their code... you can tell they know what they are doing. P.S. I feel this post needs a disclaimer, I am not affiliated in any way to Eigen, my motivation is not to promote their work (but I obviously think they deserve it). I genuinely think adopting an algebra library (that is compatible with AD) would greatly simplify our work and further drop the entry barrier to new developers.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/643#issuecomment-459653772:2186,rout,routines,2186,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459653772,2,['rout'],['routines']
Integrability,"ing for C++ compiler default output file name; configure:3442: result: a.out; configure:3448: checking for suffix of executables; configure:3455: g++ -o conftest conftest.cpp >&5; configure:3459: $? = 0; configure:3481: result: ; configure:3503: checking whether we are cross compiling; configure:3511: g++ -o conftest conftest.cpp >&5; configure:3515: $? = 0; configure:3522: ./conftest; configure:3526: $? = 0; configure:3541: result: no; configure:3546: checking for suffix of object files; configure:3568: g++ -c conftest.cpp >&5; configure:3572: $? = 0; configure:3593: result: o; configure:3597: checking whether we are using the GNU C++ compiler; configure:3616: g++ -c conftest.cpp >&5; configure:3616: $? = 0; configure:3625: result: yes; configure:3634: checking whether g++ accepts -g; configure:3654: g++ -c -g conftest.cpp >&5; configure:3654: $? = 0; configure:3695: result: yes; configure:3720: checking dependency style of g++; configure:3831: result: gcc3; configure:3921: checking for gcc; configure:3937: found /usr/bin/gcc; configure:3948: result: gcc; configure:3979: checking for C compiler version; configure:3988: gcc --version >&5; gcc (GCC) 4.4.6 20120305 (Red Hat 4.4.6-4); Copyright (C) 2010 Free Software Foundation, Inc.; This is free software; see the source for copying conditions. There is NO; warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. configure:3999: $? = 0; configure:3988: gcc -v >&5; Using built-in specs.; Target: x86_64-redhat-linux; Configured with: ../configure --prefix=/usr --mandir=/usr/share/man --infodir=/usr/share/info --with-bugurl=http://bugzilla.redhat.com/bugzilla --enable-bootstrap --enable-shared --enable-threads=posix --enable-checking=release --with-system-zlib --enable-__cxa_atexit --disable-libunwind-exceptions --enable-gnu-unique-object --enable-languages=c,c++,objc,obj-c++,java,fortran,ada --enable-java-awt=gtk --disable-dssi --with-java-home=/usr/lib/jvm/java-1.5.0-gcj-1.5.0.0/jre --enable-libgcj-mu",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:5208,depend,dependency,5208,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,1,['depend'],['dependency']
Integrability,"it ""a"" to look at some assembly, honestly sliced bread has nothing on perf. NOTE: By and large Perf is not an intrusive tool, as such the accuracy of the measurements is limited i.e. it is probably not a good idea to draw conclusion about <1% variations. Moving on, I took the top level percentages only, normalized by that of CFluidIteration::Iterate (to exclude pre-processing time) and multiplied the results from the total ""iteration time"" from the history file. Doing that for before and after results allowed computing individual speedup factors for each important routine (in terms of time, otherwise they are all special and important in their own way) e.g. gradients, limiters, upwind/viscous residuals, etc.; ![image](https://user-images.githubusercontent.com/38071223/63292708-30cfa480-c2be-11e9-8d4a-5feb3dc61abf.png). Here is the data by the way: [results.xlsx](https://github.com/su2code/SU2/files/3517492/results.xlsx). As predicted the linear solvers stay the same and routines that are light see more speedup than their arithmetic-intensive friends.; What is surprising to me is how intensive the convective residuals appear to be with only a 7% improvement, so surprising in fact, I do not think the above paints the full picture. Maybe the outlet bandwidth bottleneck (into the Jacobian matrix) is more important.; To put that do the test I switched to Euler-explicit time marching and repeated the measurements:; ![image](https://user-images.githubusercontent.com/38071223/63293351-d8010b80-c2bf-11e9-8135-2502eac1128e.png); Better, but not by much, which means upwind and viscous residuals computations might gain a lot from vectorization (SIMD). And like @economon mentioned even more if they are somehow fused together.; It also means the writes to CSysMatrix are relatively expensive, I think there are two-three reasons for it.; - We do a linear search on each Add/SubtractBlock - This could be replaced by a map.; - The Jacobian contributions are first written into a tempor",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/716#issuecomment-522730951:3993,rout,routines,3993,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-522730951,1,['rout'],['routines']
Integrability,"j[iDim];; phiR -= (gradJ++)*d_ij[iDim];; }; ...; ```; to get better assembly; ```asm; .L7:; vmovapd ymm3, ymm13; vmovapd ymm2, YMMWORD PTR [rbp-400]; add rax, 32; vgatherqpd ymm0, QWORD PTR [rcx+ymm1*8], ymm3; vpaddq ymm1, ymm1, ymm11; vmovapd YMMWORD PTR [rbp-272], ymm0; vmovapd YMMWORD PTR [rbp-240], ymm0; vfmadd132pd ymm0, ymm2, YMMWORD PTR [rax-32]; vmovdqa YMMWORD PTR [rbp-208], ymm1; vmovapd YMMWORD PTR [rbp-400], ymm0; cmp rax, rbx; jne .L7; ```; which makes the vectorized code perform just as well as the scalar code, iterators could also be used for the other variables but that would start to hurt readability without improving the performance much. _Note: There is also a chance the compiler (gcc) is not doing this kind of optimization because of the way I wrote the code..._. **So we need AoS to avoid losing performance in lightweight numerics classes.**. Before we look into the impact of not using SoA in the gradient and limiters routines let me tell you there is a way to have the best of both worlds, enter the *_array of structures of arrays_* or as I like to call it zig zag storage, aka a right mess.; Imagine an AoS of short arrays of SIMD length, e.g. `{ {u0 u1 u2 u3} {v0 ... v3} {w0 ... w3} {u4 u5 u6 u7} ... }` with that it is possible to fully vectorize point loops as the first index (iPoint) is contiguous in groups of SIMD length and when looping along variables and dimensions in edge loops the stride is small enough (equal to SIMD length) to trigger hardware prefetching.; The catch is that we need even more integer arithmetic and so we really need iterators to amortise that cost, there is also the drawback that scalar usage of such a container would be terrible. **For these reasons I think we should sacrifice ultimate performance and keep node data in AoS storage.**. The major impact on gradients and limiters is the way the code is written, to vectorize the computation we need to compute the gradient into a local variable and then ""transpose"" it when s",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-535977206:12794,rout,routines,12794,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206,1,['rout'],['routines']
Integrability,"lete, implementation of SU2_DEF; - More updates; - Working version; - Complete implementation (validate); - Working version of SU2_DEF; - Final push before moving to the develop branch; - New MPI (removing SU2_PRT); - Merged in Ben's ParMETIS integration and fixed some conflicts.; - Merge branch 'benkirk-parmetis_integration' into feature_MPI; - ParMETIS geometry routines have been copied over but are not activated yet.; - Small change to ParMETIS include.; - ParMETIS can now be activated for testing (PARMETIS=YES in config).; - Updated MG; - Updated EA subrotuine; - Small fix; - Fixing memory leak; - Fixing memory leaks; - Dev release v.3.2.6; - Increasing MAX_NUMBER_MARKER; - Working version with ParMETIS. Fixed bug in global index. Now clean up and testing...; - Cleaned version of ParMETIS routines with better console output during partitioning.; - Small bug in initial element division.; - Made arrays in ParMETIS call dynamic.; - Fixed compiler warnings and added MPI directives so that the pure serial code works with the ParMETIS routines.; - Bootstrap on zion.; - Added some typecasts. Still tracking down a memory problem...; - Critical bug fix for vtxdist array.; - Partial fix; - More MPI improvements.; - Fixing a bug in SU2_DEF; - Updated BC_ActDisk_Boundary (MPI); - Merge remote-tracking branch 'upstream/develop' into develop; - changing solidboundary setting to be heatflux OR euler etc instead of AND, also working on doxygen documentation; - Dynamic allocation for some marker-related arrays.; - visualize part taken out to match upstream/dev; - Collection of improvements; - Release 3.2.7; - Fixing LOW_MEMORY_OUTPUT; - Updated LOW_MEMORY_OUTPUT option; - Updated configure.ac; - After autoconf; - Updated MPI; - Updated BC_Engine_Exhaust and BC_Engine_Bleed; - Small change; - Fixing subsonic engine intake option; - Small output change; - Added output_su2.cpp; - Updated Engine BC; - Working on Engine BCs; - Added Supersonic Outlet BC; - Minor change; - Merge remote",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:2350,rout,routines,2350,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['rout'],['routines']
Integrability,"mplate the method.; template<typename WV>; void Compute(WV& wv, const SolutionContainer& sol) const; {; // Boilerplate, call base first. This is akin to the decorator design pattern; // without polymorphism. The working variables resemble Python's ""self"" which; // makes this solution reasonably idiomatic.; Base::Compute(wv, sol);. // Then do our specific job.; wv.area = 0.0;; for(int i=0; i<nDim; ++i); wv.area += pow(sol.areaVector[i],2);; wv.area = sqrt(wv.area);; }; };. // Same mechanics as above; template<typename Base>; class ComputeFlux : Base; {; protected:; enum : int {nDim = Base::nDim};. struct WorkVarsType : Base::WorkVarsType ; {; double flux; // ...add new member; };. template<typename WV>; void Compute(WV& wv, const SolutionContainer& sol) const; {; // ...call base; Base::Compute(wv,sol);. // ...do aditional work; wv.flux = 0.0;; for(int i=0; i<nDim; ++i); wv.flux += sol.velocity[i]*sol.areaVector[i];; }; };. // This class is used to terminate the chain, it makes the link; // with the interface and it is used to specify any fixed sizes.; template<int NDIM>; class Terminator : private VirtualInterface; {; protected:; enum : int {nDim = NDIM};. struct WorkVarsType {};. template<typename... Ts>; void Compute(Ts&...) const {}; };. // Finally we use the building blocks to implement Compute.; // The blocks can be reordered depending on application to; // help the compiler fuse loops or minimize register spillage,; // the resulting WorkVarsType definition will be equivalent.; class ComposedClass: public; ComputeFlux< ComputeArea< Terminator<3> > >; {; public:; ResultType Compute(const SolutionContainer& sol) const;; };. ResultType ComposedClass::Compute(const SolutionContainer& sol) const; {; // Create the working variables on the stack.; ComputeFlux::WorkVarsType wv;. // Pass down the working variables and whatever other arguments.; // If the convention was followed, all building blocks will run.; // Recall that all Compute's were templates, they will be; // ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-622941617:4383,interface,interface,4383,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-622941617,1,['interface'],['interface']
Integrability,o_su2.jpg (0) ; - D Logo/su2_eagle.png (0) ; - M Makefile.am (32) ; - M Makefile.in (53) ; - D MeshTools/Matlab/MergeSU2.m (77) ; - D MeshTools/Matlab/ReadSU2.m (160) ; - D MeshTools/Matlab/WriteSU2.m (91) ; - D MeshTools/Matlab/angle2dcm.m (28) ; - D MeshTools/Matlab/example_MergeMeshes.m (38) ; - D MeshTools/Matlab/getElemTypeInfo.m (52) ; - D MeshTools/Matlab/mesh_bipara_1.su2 (38465) ; - D MeshTools/Matlab/mesh_bipara_2.su2 (3248) ; - D MeshTools/Matlab/plotElem.m (45) ; - D MeshTools/Matlab/plotFace.m (60) ; - D MeshTools/Matlab/plotMarkers.m (64) ; - D MeshTools/PointwiseSU2plugin/FLAGS.linux (33) ; - D MeshTools/PointwiseSU2plugin/FLAGS.linux_x86_64 (33) ; - D MeshTools/PointwiseSU2plugin/FLAGS.macosx (112) ; - D MeshTools/PointwiseSU2plugin/FLAGS.win (14) ; - D MeshTools/PointwiseSU2plugin/FLAGS.win32 (33) ; - D MeshTools/PointwiseSU2plugin/Makefile (304) ; - D MeshTools/PointwiseSU2plugin/PluginSDK.sln (64) ; - D MeshTools/PointwiseSU2plugin/PluginSDK.suo (0) ; - D MeshTools/PointwiseSU2plugin/depend.sh (28) ; - D MeshTools/PointwiseSU2plugin/mkplugin (10) ; - D MeshTools/PointwiseSU2plugin/mkplugin.bat (82) ; - D MeshTools/PointwiseSU2plugin/mkplugin.tcl (422) ; - D MeshTools/PointwiseSU2plugin/src/Pointwise/Win32Target.props (28) ; - D MeshTools/PointwiseSU2plugin/src/Pointwise/Win32Target.vsprops (24) ; - D MeshTools/PointwiseSU2plugin/src/Pointwise/Win64Target.props (28) ; - D MeshTools/PointwiseSU2plugin/src/Pointwise/Win64Target.vsprops (24) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/CaeStrXML.vcproj (511) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/CaeStrXML.vcproj.PWI.dgarlisch.user (121) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/CaeStrXML.vcxproj (307) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/CaeStrXML.vcxproj.filters (78) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/CaeStrXML.vcxproj.user (3) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/module.mk (239) ; - D MeshTool,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:13350,depend,depend,13350,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['depend'],['depend']
Integrability,"olvers at ~10k nodes per core and about the same on a newer architecture but only at ~1k node per core.; Since hybrid parallel is supposed to be good for strong scaling, this was not good enough... With the new strategy it is ok (see ""performance"" below), hence this is ready for review. ### Overall Strategy; The strategy now is to start a parallel section in CSysSolve::Solve that covers building the preconditioner and solving the linear system.; Linear algebra routines called within this section have _worksharing_ constructs instead of _parallel_ ones, i.e. the work is distributed by however many threads arrive to that routine. This also makes the routines safe to call in serial.; The only ""dangerous"" things to do in parallel are to: manage memory for a shared object (multiple threads call `new` but there is only one shared pointer on which to call `delete`); writing to the same memory locations concurrently.; I tried to make the first issue debugable by asserting that the initialization routines of CSysMatrix and CSysVector are only called by the master thread.; For the second issue I made the associated classes as const-correct as possible, that should at least make someone think twice before changing a member variable of those classes. The risk is still there for input variables as an algorithm development aspect... For example `MatrixVectorProductTransposed` cannot be made thread-parallel as simply/naively as its normal counterpart. ### Communication Model; The MPI + Threads communication model is very simple, currently only the master thread calls MPI routines (including `Error`), this requires thread barriers before and after the communication to make sure the correct values are passed and _seen_ by all threads.; We can test other alternatives in the future but at the moment this does not seem to be a significant bottleneck.; _Worksharing_ constructs have implicit barriers at completion, for CSysVector routines I used `nowait` modifiers, it is safe to call tho",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/830#issuecomment-562646766:1181,rout,routines,1181,https://su2code.github.io,https://github.com/su2code/SU2/pull/830#issuecomment-562646766,1,['rout'],['routines']
Integrability,"orementioned flag), for 2-3 minutes for hundreds of MB of record (hence the 500k mesh...).; Run `perf report -g ""fractal,0.5,caller""`, this will show % of time spent in a function relative to its caller and you can expand each function to see what are its children, grandchildren, etc. Like so:; ![image](https://user-images.githubusercontent.com/38071223/63290949-725e5080-c2ba-11e9-90aa-ffc834e726db.png); How cool is that!! Pro-tip hit ""a"" to look at some assembly, honestly sliced bread has nothing on perf. NOTE: By and large Perf is not an intrusive tool, as such the accuracy of the measurements is limited i.e. it is probably not a good idea to draw conclusion about <1% variations. Moving on, I took the top level percentages only, normalized by that of CFluidIteration::Iterate (to exclude pre-processing time) and multiplied the results from the total ""iteration time"" from the history file. Doing that for before and after results allowed computing individual speedup factors for each important routine (in terms of time, otherwise they are all special and important in their own way) e.g. gradients, limiters, upwind/viscous residuals, etc.; ![image](https://user-images.githubusercontent.com/38071223/63292708-30cfa480-c2be-11e9-8d4a-5feb3dc61abf.png). Here is the data by the way: [results.xlsx](https://github.com/su2code/SU2/files/3517492/results.xlsx). As predicted the linear solvers stay the same and routines that are light see more speedup than their arithmetic-intensive friends.; What is surprising to me is how intensive the convective residuals appear to be with only a 7% improvement, so surprising in fact, I do not think the above paints the full picture. Maybe the outlet bandwidth bottleneck (into the Jacobian matrix) is more important.; To put that do the test I switched to Euler-explicit time marching and repeated the measurements:; ![image](https://user-images.githubusercontent.com/38071223/63293351-d8010b80-c2bf-11e9-8135-2502eac1128e.png); Better, but not by m",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/716#issuecomment-522730951:3579,rout,routine,3579,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-522730951,1,['rout'],['routine']
Integrability,"ork; > on our branch, which we're happy with. Some choices were arbitrary, and; > some choices were made based on our development environment. Those choices; > may be different for other groups. Here's what we have done:; >; > The unit testing framework is compiled and run using autotools. For more; > information on autotool's setup, see their documentation; > <https://www.gnu.org/software/automake/manual/html_node/Tests.html>.; > Since autotools is the build system for SU2, this involves minimal changes.; >; > Using automake, the build process for building unit tests becomes:; >; > '''; > ./bootstrap; > ./configure; > make; > make check; > '''; >; > We use Boost's unit testing framework; > <https://www.boost.org/doc/libs/1_70_0/libs/test/doc/html/index.html>.; > This provides a convenient set of macros for instatiating tests, grouping; > tests into suites, and running checks. This choice was based on what is; > available in our development setup.; >; > We have integrated our unit tests into our Travis CI regression testing.; > Every time we push commits or submit a pull request, the unit tests are run; > and checked.; > What is my vision for unit testing in SU2?; >; > I am *not* proposing that we start trying to get 100% code coverage with; > pre-existing code. That would not provide a good return on investment.; >; > Instead, I see people adding unit tests as they write new code and as they; > find bugs. For each new behavior added to SU2, tests are first added to; > document the related existing behavior. These tests serve to check that the; > existing behavior isn't damaged by the new code. Then new tests are added; > to prove that the new behavior is working correctly. For bug fixes, the; > process is simpler. A test is added to confirm that something is not; > behaving as expected. Then the code is fixed to make the test pass.; > What frameworks are available?; >; > For a unit testing framework, here are the most popular options, with the; > following pros and ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499278427:4538,integrat,integrated,4538,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427,1,['integrat'],['integrated']
Integrability,"orted in increasing order of the point indices to reduce cache misses, this means small groups of contiguous edges will share the same ""iPoint"", coloring single edges destroys this. Furthermore coloring either requires edges to be re-sorted by color, or if the edge indices of each color are instead kept in arrays, performance will suffer due to increased indirection which confounds the hardware pre-fetcher.; This can be mitigated to some extent by coloring groups of edges, groups of edges of the same color can be processed simultaneously, but within each group edges need to be processed serially. However grouping will reduce how much parallelism can be exploited within each color.; - **Gather to scatter** will in general use more memory due to the intermediate variables and extra adjacency information needed. If the entire algorithm is transformed performance may suffer as some computations may have to be repeated.; However, some reductions are possible without intermediate variables, for example when assembling the system matrix for implicit schemes only the diagonal entries can result in race conditions, now it just so happens that each diagonal entry is equal to the negated corresponding column sum.; - **Atomics** are terrible for the performance of code that writes frequently to memory (i.e. bandwidth-bound code), they do not increase the memory footprint and so make sense for compute-bound code.; Bugs due to a missing atomic can be very hard to debug (but any race condition is). Coloring is what one sees most in the literature, and yet I lean towards gather-to-scatter. Fewer things can go wrong with it as it is easy to understand, one gets the maximum amount of parallelism. I will now take two familiar routines, computing gradients (Green-Gauss) and limiters, vectorize / parallelize them in different ways, and measure relative performance to illustrate some of these key points introduced here. There will be C++ snipets and there will be some x86 assembly too :)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-529662724:6844,rout,routines,6844,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-529662724,1,['rout'],['routines']
Integrability,"output classes, we should find a common level of abstraction for all the different physical problems we might want to have. Right now there isn't even a unified way of specifying the kind of problem for each zone (what is fluid, what is solid etc) and the kind of coupling. This might also affect the actual implementation/restructuring since we somehow have to decide what driver we have to instantiate and so on. Hopefully we can gather all the people involved to have a discussion on that. Since we have a lot of people working in their branches on multizone problems we should tackle that better sooner than later. As Edwin already suggested, maybe it is a good idea to put some people in charge of organizing some of the bigger structural changes. Furthermore in case some people don't know, we have a slack channel for the dev team. I think that makes it easier to communicate, arrange meetings, discuss problems and ask questions. In case you need an invite, let me know, everybody who wants to contribute is welcome. Thanks for the discussion, I still think that communication is the key of success !. Tim. On Sep 13, 2017 10:30 AM, Edwin van der Weide <notifications@github.com> wrote:. Hi Tom,. Sounds like a plan then to have a look at CIntegration to see what we can do to generalize the time integration. I definitely want to help with this, but I don't think I am the appropriate person to take the lead, because I simply don't have a good overview of all the multi-physics options. Tom, are you willing to take the lead for this?. Furthermore, it is good to have other people involved as well, preferably with detailed knowledge of the different disciplines. Any volunteers?. Thanks,. Edwin. —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/437#issuecomment-329096830>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AEtI5MkXdqhqPPMuaDziLuDRzWCJfYwrks5sh5KagaJpZM4PQ90s>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/437#issuecomment-329146567:1347,integrat,integration,1347,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-329146567,1,['integrat'],['integration']
Integrability,"ple dataset, I have run some; variations on the jobs, and my findings were:; (Please note that *all* ""markers"" I have mentioned in the next items refer; to solid walls in the mesh, using the RANS solver); 1- When I impose HEATFLUX=0 *and* ISOTHERMAL=290 Kelvin, for the same; markers, there are no complaints from SU2. It shows that SU2 ignores the; imposition of HEATFLUX=0, in this case.; 2- Just setting ISOTHERMAL=290 Kelvin (using all of the same markers as in; (item 1), above), without any HEATFLUX setting, then SU2 produces the same; results as in (item1).; 3- When some markers are set with HEATFLUX=0 and the rest of them are set; with ISOTHERMAL=290 Kelvin (so that each wall marker in the mesh is; referenced), there are no complaints from SU2, and the job goes as expected.; 4-The error message mentioned earlier, appears when one or more solid wall; markers *is not marked* concerning HEATFLUX or ISOTHERMAL; .; My conclusion then is that the error message appeared when I mistakenly; have not included a wall marker (assigning it as a HEATFLUX or an; ISOTHERMAL marker!); Does it make sense?; Kind regards,. On Mon, Oct 23, 2023 at 7:48 PM Jairo Cavalcante ***@***.***>; wrote:. > Unfortunately, my example involves a swirler and nozzle for the; > Navier-Stokes solver with Menter model, so the dataset is relatively large.; > Let me check whether some older small Euler mesh exhibits the same message!; > I will let you know! Thank you very much.; >; > On Mon, Oct 23, 2023 at 6:34 PM Pedro Gomes ***@***.***>; > wrote:; >; >> Is there a simple example to reproduce the issue?; >>; >> —; >> Reply to this email directly, view it on GitHub; >> <https://github.com/su2code/SU2/pull/2109#issuecomment-1776057496>, or; >> unsubscribe; >> <https://github.com/notifications/unsubscribe-auth/AHGXZUV3DNRF3O55YAWT563YA3PETAVCNFSM6AAAAAA3QKLVDWVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMYTONZWGA2TONBZGY>; >> .; >> You are receiving this because you commented.Message ID:; >> ***@***.***>; >>; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/2109#issuecomment-1777018035:1004,message,message,1004,https://su2code.github.io,https://github.com/su2code/SU2/pull/2109#issuecomment-1777018035,2,['message'],['message']
Integrability,"research group at UT Austing has implemented a unit testing framework on our branch, which we're happy with. Some choices were arbitrary, and some choices were made based on our development environment. Those choices may be different for other groups. Here's what we have done:. The unit testing framework is compiled and run using autotools. For more information on autotool's setup, see their documentation<https://www.gnu.org/software/automake/manual/html_node/Tests.html>. Since autotools is the build system for SU2, this involves minimal changes. Using automake, the build process for building unit tests becomes:. '''; ./bootstrap; ./configure; make; make check; '''. We use Boost's unit testing framework<https://www.boost.org/doc/libs/1_70_0/libs/test/doc/html/index.html>. This provides a convenient set of macros for instatiating tests, grouping tests into suites, and running checks. This choice was based on what is available in our development setup. We have integrated our unit tests into our Travis CI regression testing. Every time we push commits or submit a pull request, the unit tests are run and checked. What is my vision for unit testing in SU2?. I am not proposing that we start trying to get 100% code coverage with pre-existing code. That would not provide a good return on investment. Instead, I see people adding unit tests as they write new code and as they find bugs. For each new behavior added to SU2, tests are first added to document the related existing behavior. These tests serve to check that the existing behavior isn't damaged by the new code. Then new tests are added to prove that the new behavior is working correctly. For bug fixes, the process is simpler. A test is added to confirm that something is not behaving as expected. Then the code is fixed to make the test pass. What frameworks are available?. For a unit testing framework, here are the most popular options, with the following pros and cons:. Roll-your-own. * Requires no external dependencies",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499250240:3388,integrat,integrated,3388,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240,1,['integrat'],['integrated']
Integrability,"t the initialization routines of CSysMatrix and CSysVector are only called by the master thread.; For the second issue I made the associated classes as const-correct as possible, that should at least make someone think twice before changing a member variable of those classes. The risk is still there for input variables as an algorithm development aspect... For example `MatrixVectorProductTransposed` cannot be made thread-parallel as simply/naively as its normal counterpart. ### Communication Model; The MPI + Threads communication model is very simple, currently only the master thread calls MPI routines (including `Error`), this requires thread barriers before and after the communication to make sure the correct values are passed and _seen_ by all threads.; We can test other alternatives in the future but at the moment this does not seem to be a significant bottleneck.; _Worksharing_ constructs have implicit barriers at completion, for CSysVector routines I used `nowait` modifiers, it is safe to call those routines in sequence since the loop sizes, and static work scheduling specifications are identical.; However, routines that access a CSysVector in a different way, should have an explicit barrier before using the vector (or risk having undefined behaviour). You will see these barriers on entry to matrix-vector product, and every `ComputeXXXPreconditioner` (if you don't, let me know xD). I think those routines are large enough to amortise the cost of this. ### Performance; Disclaimer:; - We are talking about linear solvers only, **you will not see a global improvement yet**.; - The large global improvements from ""hybridization"" will come from the multigrid behaving better on less decomposed domains, and from the ability to independently tune the number of cores used in the linear preconditioners. For now the objective is ""just"" not to loose performance while gaining flexibility.; - The performance of MPI+threads with 1 thread per rank will be worse than just MPI (no",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/830#issuecomment-562646766:2120,rout,routines,2120,https://su2code.github.io,https://github.com/su2code/SU2/pull/830#issuecomment-562646766,2,['rout'],['routines']
Integrability,"ter types instead of arrays, and a boat load of template meta-programming (I'm guessing) there are professional libraries for this.; This quickly-hacked-together code is compatible with custom types, portable, and seems to do the trick. To pull this off we do not need to have `Vector` or `Matrix` of this class, the underlying type for those data structures is still `double`, only the `getVec` type methods need to convert on the fly to the SIMD type, for example:; ```C++; // use the ""pointer ctor"" to return an array starting at ""row0""; Array<double,4> Matrix<double>::getVec(size_t row0, size_t col) const {; return Array<double,4>(&data_[row0+col*rows_]);; }. // use the ""gather ctor"" to return an array with the indices in ""rows""; template<class U>; Array<double,4> Matrix<double>::getVec(const U& rows, size_t col) const {; return Array<double,4>(&data_[col*rows_], rows);; }; ```; After inlining those copies get optimized away.; Although the stored type, and ""scalar interface"" of the containers do not need to change, the storage order of the data does. Notice that in the above data is stored by columns instead of rows (something that @vdweide mentioned in #716) this has greater implications for gradients as instead of the familiar ""vector of matrices"" we would need a ""matrix of vectors"", i.e. the derivative of variable i w.r.t. coordinate j stored as a vector for all points. The `Adjacency` also needs to be stored in a funny way. For the scalar version of the code it was stored as a CSR sparse matrix (one array of indices into the arrays of data for each point, the rows).; For the vectorized version we want to load (small) arrays of jPoint's, arrays of iEdge's, and arrays of directions, and as we know either those are contiguous or we take a huge performance hit.; If all points had the same number of neighbors we could store the adjacency in LIL (list of lists) format, essentially a column-major matrix, but that is not true for hybrid meshes and so we would possibly wast",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-530328194:9827,interface,interface,9827,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530328194,1,['interface'],['interface']
Integrability,"uch lower level, namely where the spatial residual is computed. At least, this should be the case for the fluid dynamics part. I don't know whether this is also the case for other disciplines, like structures. What about the following high level structure?. - Loop over the number of iterations, or time steps for unsteady problems.; - Loop over the number of pseudo-time steps for implicit time integration schemes; (DT_STEPPING_1ST and DT_STEPPING_2ND). For other cases this loop is 1.; - Loop over the number of disciplines involved; Call iterate for each of the disciplines.; In iterate: ; - Loop over the (Runge-Kutta) stages; - Loop over the zones of a single discipline; Compute spatial residual.; Update the state vector.; - End loop over the zones of a single discipline.; Exchange halo data. This includes the halo data between zones of a single discipline.; - End loop over the (Runge-Kutta) stages ; - End loop over the disciplines; - End loop over the pseudo time steps.; - End loop over the number of iterations, or time steps for unsteady problems. The weakness of this approach is that it still does not work when one would like to employ multi-stage time integration schemes for an unsteady, multi-disciplinary problem (does not work for the current implementation either), but maybe this is something we simply have to accept. The alternative is that all the details of the different time integration schemes have to be moved to the driver classes, which is highly undesirable, I think. The structure above implies that the iteration_container and the integration_container should be defined per discipline and not per zone anymore. The geometry_container and solver_container should still be defined per zone. Well, I suppose this leaves plenty of room for discussion, so I would say to continue the online discussion a bit further, such that things become a bit clearer how to tackle this issue. After that having a telecon would be good to iron out the details. . Regards,. Edwin",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/437#issuecomment-328368371:1516,integrat,integration,1516,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328368371,2,['integrat'],['integration']
Integrability,"uctures. What about the following high level structure?. * Loop over the number of iterations, or time steps for unsteady problems.; * Loop over the number of pseudo-time steps for implicit time integration schemes; (DT_STEPPING_1ST and DT_STEPPING_2ND). For other cases this loop is 1.; * Loop over the number of disciplines involved; Call iterate for each of the disciplines.; In iterate:; * Loop over the (Runge-Kutta) stages; * Loop over the zones of a single discipline; Compute spatial residual.; Update the state vector.; * End loop over the zones of a single discipline.; Exchange halo data. This includes the halo data between zones of a single discipline.; * End loop over the (Runge-Kutta) stages; * End loop over the disciplines; * End loop over the pseudo time steps.; * End loop over the number of iterations, or time steps for unsteady problems. The weakness of this approach is that it still does not work when one would like to employ multi-stage time integration schemes for an unsteady, multi-disciplinary problem (does not work for the current implementation either), but maybe this is something we simply have to accept. The alternative is that all the details of the different time integration schemes have to be moved to the driver classes, which is highly undesirable, I think. The structure above implies that the iteration_container and the integration_container should be defined per discipline and not per zone anymore. The geometry_container and solver_container should still be defined per zone. Well, I suppose this leaves plenty of room for discussion, so I would say to continue the online discussion a bit further, such that things become a bit clearer how to tackle this issue. After that having a telecon would be good to iron out the details. Regards,. Edwin. —; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/437#issuecomment-328368371>, or mute the thread<",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/437#issuecomment-328403160:3025,integrat,integration,3025,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328403160,1,['integrat'],['integration']
Integrability,"{; #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); {; double flux = phi_ave[iVar]*area(iEdge,iDim);. grad(iPoint,iVar,iDim) += flux;; grad(jPoint,iVar,iDim) -= flux;; }; }; }. for(size_t iPoint=0; iPoint<nPoint; ++iPoint); for(size_t iDim=0; iDim<nDim; ++iDim); #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); grad(iPoint,iVar,iDim) /= volume[iPoint];; }; ```; Well it is not just a few pragmas, we need to make the number of variables known at compile time (via a template parameter) and we need to transpose how the gradient is stored, i.e. instead of {xyz, xyz, xyz, xyz} we need {xxxx, yyyy, zzzz}. This code gets a speed-up of **2.2**. This code is generic but the template needs to be instantiated for every possible number of variables and we need a `switch` to call the right version at runtime, not very friendly.; Processing multiple edges at the same time is not worth the effort, for one we need `gather/scatter` on a very light routine, and on top of that we need to sort the edges such that we do not attempt to `scatter` to the same point when updating the gradient (a problem similar to the race condition described for SPMD). We can switch to a point-based loop and process multiple points in a SIMD way, that avoids the `scatter` problem but `gathers` will still be required. Here is what the scalar version of the point-based loop looks like:; ```C++; void computeGradients(size_t nPoint,; size_t nVar,; size_t nDim,; const Adjacency& adj,; const Matrix& area,; const vector<double>& volume,; const Matrix& phi,; VectorOfMatrix& grad); {; for(size_t iPoint=0; iPoint<nPoint; ++iPoint); {; for(size_t iVar=0; iVar<nVar; ++iVar); for(size_t iDim=0; iDim<nDim; ++iDim); grad(iPoint,iVar,iDim) = 0.0;. for(size_t iNeigh=0; iNeigh<adj.nNeighbor(iPoint); ++iNeigh); {; size_t jPoint = adj.jPoint(iPoint,iNeigh);; size_t iEdge = adj.iEdge(iPoint,iNeigh);; double dir = adj.dir(iPoint,iNeigh);. for(size_t iVar=0; iVar<nVar; ++iVar); {; double phi_ave = 0.5*(phi(iPoint,i",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-530328194:3332,rout,routine,3332,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530328194,1,['rout'],['routine']
Modifiability, $? = 0; configure:4941: result: yes; configure:4954: checking for sys/types.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for sys/stat.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for stdlib.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for string.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for memory.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for strings.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for inttypes.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for stdint.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for unistd.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4970: checking size of short int; configure:4975: gcc -o conftest -g -O2 conftest.c >&5; configure:4975: $? = 0; configure:4975: ./conftest; configure:4975: $? = 0; configure:4989: result: 2; configure:5003: checking size of int; configure:5008: gcc -o conftest -g -O2 conftest.c >&5; configure:5008: $? = 0; configure:5008: ./conftest; configure:5008: $? = 0; configure:5022: result: 4; configure:5036: checking size of unsigned int; configure:5041: gcc -o conftest -g -O2 conftest.c >&5; configure:5041: $? = 0; configure:5041: ./conftest; configure:5041: $? = 0; configure:5055: result: 4; configure:5069: checking size of long int; configure:5074: gcc -o conftest -g -O2 conftest.c >&5; configure:5,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:10592,config,configure,10592,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,3,['config'],['configure']
Modifiability, - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtCaepSupportData.h (89) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtPwpInitItems.h (68) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtPwpPluginInfo.h (75) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtPwpVersions.h (62) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/runtimeWrite.c (347) ; - D MeshTools/PointwiseSU2plugin/src/plugins/README.txt (272) ; - D MeshTools/PointwiseSU2plugin/src/plugins/module.mk (309) ; - D MeshTools/PointwiseSU2plugin/src/plugins/modulelocal.mk (8) ; - D MeshTools/PointwiseSU2plugin/src/plugins/pluginRegistry.h (29) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEP.c (228) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEP.h (550) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEPUtils.c (290) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEPUtils.h (725) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/runtimeWrite.h (57) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWGM/apiGridModel.c (492) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWGM/apiGridModel.h (1808) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWP.c (132) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWP.h (707) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWPUtils.c (789) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWPUtils.h (1030) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiUtils.h (174) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/pwpPlatform.c (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/pwpPlatform.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/site.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/structured.props (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/structured.vsprops (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/CaeT,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:18579,plugin,plugins,18579,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['plugin'],['plugins']
Modifiability," ---------------------- ##; ## Running config.status. ##; ## ---------------------- ##. This file was extended by SU2 config.status 4.1.0, which was; generated by GNU Autoconf 2.69. Invocation command line was. CONFIG_FILES = ; CONFIG_HEADERS = ; CONFIG_LINKS = ; CONFIG_COMMANDS = ; $ ./config.status . on master. config.status:875: creating externals/tecio/Makefile; config.status:875: creating externals/metis/Makefile; config.status:875: creating externals/parmetis/Makefile; config.status:875: creating Makefile; config.status:875: creating externals/Makefile; config.status:875: creating Common/lib/Makefile; config.status:875: creating SU2_CFD/obj/Makefile; config.status:875: creating SU2_DOT/obj/Makefile; config.status:875: creating SU2_MSH/obj/Makefile; config.status:875: creating SU2_DEF/obj/Makefile; config.status:875: creating SU2_SOL/obj/Makefile; config.status:875: creating SU2_GEO/obj/Makefile; config.status:875: creating SU2_PY/Makefile; config.status:1047: executing depfiles commands; configure:8181: result:. -------------------------------------------------------------------------; | ___ _ _ ___ |; | / __| | | |_ ) Release 4.1.0 'Cardinal' |; | \__ \ |_| |/ / |; | |___/\___//___| Suite |; | |; -------------------------------------------------------------------------; | SU2 Lead Dev.: Dr. Francisco Palacios, Francisco.D.Palacios@boeing.com|; | Dr. Thomas D. Economon, economon@stanford.edu |; -------------------------------------------------------------------------; | SU2 Developers: |; | - Prof. Juan J. Alonso's group at Stanford University. |; | - Prof. Piero Colonna's group at Delft University of Technology. |; | - Prof. Nicolas R. Gauger's group at Kaiserslautern U. of Technology. |; | - Prof. Alberto Guardone's group at Polytechnic University of Milan. |; | - Prof. Rafael Palacios' group at Imperial College London. |; -------------------------------------------------------------------------; | Copyright (C) 2012-2015 SU2, the open-source CFD code. |; | ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:16676,config,configure,16676,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,1,['config'],['configure']
Modifiability," --with-ecj-jar=/usr/share/java/eclipse-ecj.jar --disable-libjava-multilib --with-ppl --with-cloog --with-tune=generic --with-arch_32=i686 --build=x86_64-redhat-linux; Thread model: posix; gcc version 4.4.6 20120305 (Red Hat 4.4.6-4) (GCC) ; configure:3999: $? = 0; configure:3988: gcc -V >&5; gcc: '-V' option must have argument; configure:3999: $? = 1; configure:3988: gcc -qversion >&5; gcc: unrecognized option '-qversion'; gcc: no input files; configure:3999: $? = 1; configure:4003: checking whether we are using the GNU C compiler; configure:4022: gcc -c conftest.c >&5; configure:4022: $? = 0; configure:4031: result: yes; configure:4040: checking whether gcc accepts -g; configure:4060: gcc -c -g conftest.c >&5; configure:4060: $? = 0; configure:4101: result: yes; configure:4118: checking for gcc option to accept ISO C89; configure:4181: gcc -c -g -O2 conftest.c >&5; configure:4181: $? = 0; configure:4194: result: none needed; configure:4216: checking dependency style of gcc; configure:4327: result: gcc3; configure:4345: checking whether gcc and cc understand -c and -o together; configure:4376: gcc -c conftest.c -o conftest2.o >&5; configure:4380: $? = 0; configure:4386: gcc -c conftest.c -o conftest2.o >&5; configure:4390: $? = 0; configure:4401: cc -c conftest.c >&5; configure:4405: $? = 0; configure:4413: cc -c conftest.c -o conftest2.o >&5; configure:4417: $? = 0; configure:4423: cc -c conftest.c -o conftest2.o >&5; configure:4427: $? = 0; configure:4445: result: yes; configure:4513: checking for ranlib; configure:4529: found /usr/bin/ranlib; configure:4540: result: ranlib; configure:4574: checking how to run the C preprocessor; configure:4605: gcc -E conftest.c; configure:4605: $? = 0; configure:4619: gcc -E conftest.c; conftest.c:11:28: error: ac_nonexistent.h: No such file or directory; configure:4619: $? = 1; configure: failed program was:; | /* confdefs.h */; | #define PACKAGE_NAME ""SU2""; | #define PACKAGE_TARNAME ""SU2""; | #define PACKAGE_VERSION ""4.1.0""; | ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:7207,config,configure,7207,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,6,['config'],['configure']
Modifiability," 4; | #define SIZEOF_DOUBLE 8; | #define SIZEOF_VOID_P 8; | /* end confdefs.h. */; | #include <stdio.h>; | #ifdef HAVE_SYS_TYPES_H; | # include <sys/types.h>; | #endif; | #ifdef HAVE_SYS_STAT_H; | # include <sys/stat.h>; | #endif; | #ifdef STDC_HEADERS; | # include <stdlib.h>; | # include <stddef.h>; | #else; | # ifdef HAVE_STDLIB_H; | # include <stdlib.h>; | # endif; | #endif; | #ifdef HAVE_STRING_H; | # if !defined STDC_HEADERS && defined HAVE_MEMORY_H; | # include <memory.h>; | # endif; | # include <string.h>; | #endif; | #ifdef HAVE_STRINGS_H; | # include <strings.h>; | #endif; | #ifdef HAVE_INTTYPES_H; | # include <inttypes.h>; | #endif; | #ifdef HAVE_STDINT_H; | # include <stdint.h>; | #endif; | #ifdef HAVE_UNISTD_H; | # include <unistd.h>; | #endif; | #include <X11/Intrinsic.h>; configure:5409: result: no; configure:5409: checking X11/Intrinsic.h presence; configure:5409: gcc -E conftest.c; conftest.c:28:27: error: X11/Intrinsic.h: No such file or directory; configure:5409: $? = 1; configure: failed program was:; | /* confdefs.h */; | #define PACKAGE_NAME ""SU2""; | #define PACKAGE_TARNAME ""SU2""; | #define PACKAGE_VERSION ""4.1.0""; | #define PACKAGE_STRING ""SU2 4.1.0""; | #define PACKAGE_BUGREPORT ""su2code-dev@lists.stanford.edu""; | #define PACKAGE_URL ""https://github.com/su2code""; | #define PACKAGE ""SU2""; | #define VERSION ""4.1.0""; | #define STDC_HEADERS 1; | #define HAVE_SYS_TYPES_H 1; | #define HAVE_SYS_STAT_H 1; | #define HAVE_STDLIB_H 1; | #define HAVE_STRING_H 1; | #define HAVE_MEMORY_H 1; | #define HAVE_STRINGS_H 1; | #define HAVE_INTTYPES_H 1; | #define HAVE_STDINT_H 1; | #define HAVE_UNISTD_H 1; | #define SIZEOF_SHORT_INT 2; | #define SIZEOF_INT 4; | #define SIZEOF_UNSIGNED_INT 4; | #define SIZEOF_LONG_INT 8; | #define SIZEOF_FLOAT 4; | #define SIZEOF_DOUBLE 8; | #define SIZEOF_VOID_P 8; | /* end confdefs.h. */; | #include <X11/Intrinsic.h>; configure:5409: result: no; configure:5409: checking for X11/Intrinsic.h; configure:5409: result: no; configure:57",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:14261,config,configure,14261,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,2,['config'],['configure']
Modifiability, ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtPwpPluginInfo.h (75) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtPwpVersions.h (62) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/runtimeWrite.c (347) ; - D MeshTools/PointwiseSU2plugin/src/plugins/README.txt (272) ; - D MeshTools/PointwiseSU2plugin/src/plugins/module.mk (309) ; - D MeshTools/PointwiseSU2plugin/src/plugins/modulelocal.mk (8) ; - D MeshTools/PointwiseSU2plugin/src/plugins/pluginRegistry.h (29) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEP.c (228) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEP.h (550) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEPUtils.c (290) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEPUtils.h (725) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/runtimeWrite.h (57) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWGM/apiGridModel.c (492) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWGM/apiGridModel.h (1808) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWP.c (132) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWP.h (707) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWPUtils.c (789) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWPUtils.h (1030) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiUtils.h (174) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/pwpPlatform.c (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/pwpPlatform.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/site.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/structured.props (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/structured.vsprops (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/CaeTemplate.suo (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/CaeTemplate.vcproj (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/C,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:18738,plugin,plugins,18738,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['plugin'],['plugins']
Modifiability, C header files; configure:4857: gcc -c -g -O2 conftest.c >&5; configure:4857: $? = 0; configure:4930: gcc -o conftest -g -O2 conftest.c >&5; configure:4930: $? = 0; configure:4930: ./conftest; configure:4930: $? = 0; configure:4941: result: yes; configure:4954: checking for sys/types.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for sys/stat.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for stdlib.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for string.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for memory.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for strings.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for inttypes.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for stdint.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for unistd.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4970: checking size of short int; configure:4975: gcc -o conftest -g -O2 conftest.c >&5; configure:4975: $? = 0; configure:4975: ./conftest; configure:4975: $? = 0; configure:4989: result: 2; configure:5003: checking size of int; configure:5008: gcc -o conftest -g -O2 conftest.c >&5; configure:5008: $? = 0; configure:5008: ./conftest; configure:5008: $? = 0; configure:5022: result: 4; configure:5036: checking size of unsigned int; configure:5041: gcc -o conftest -g -O2 conftest.c >&5; con,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:10406,config,configure,10406,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,1,['config'],['configure']
Modifiability, D MeshTools/PointwiseSU2plugin/src/plugins/module.mk (309) ; - D MeshTools/PointwiseSU2plugin/src/plugins/modulelocal.mk (8) ; - D MeshTools/PointwiseSU2plugin/src/plugins/pluginRegistry.h (29) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEP.c (228) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEP.h (550) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEPUtils.c (290) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEPUtils.h (725) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/runtimeWrite.h (57) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWGM/apiGridModel.c (492) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWGM/apiGridModel.h (1808) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWP.c (132) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWP.h (707) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWPUtils.c (789) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWPUtils.h (1030) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiUtils.h (174) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/pwpPlatform.c (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/pwpPlatform.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/site.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/structured.props (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/structured.vsprops (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/CaeTemplate.suo (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/CaeTemplate.vcproj (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/module.mk (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/modulelocal-sample.mk (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/rtCaepInitItems.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/rtCaepInstanceData.h (0) ; - D MeshTools/PointwiseSU,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:19043,plugin,plugins,19043,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['plugin'],['plugins']
Modifiability, D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWGM/apiGridModel.h (1808) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWP.c (132) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWP.h (707) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWPUtils.c (789) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWPUtils.h (1030) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiUtils.h (174) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/pwpPlatform.c (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/pwpPlatform.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/site.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/structured.props (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/structured.vsprops (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/CaeTemplate.suo (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/CaeTemplate.vcproj (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/module.mk (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/modulelocal-sample.mk (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/rtCaepInitItems.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/rtCaepInstanceData.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/rtCaepSupportData.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/runtimeWrite.c (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/PWP/rtPwpInitItems.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/PWP/rtPwpPluginInfo.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/PWP/rtPwpVersions.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/unstructured.props (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/unstructured.vsprops (0) ; - D MeshTools/PointwiseSU2plugin_Instructions.txt (0) ; - I QuickStart/inv_NACA0012.cfg (0) ; - I README (0) ; - I SU2_CFD/include/SU2_CF,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:19712,plugin,plugins,19712,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['plugin'],['plugins']
Modifiability, MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.sln (26) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.suo (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcproj (511) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcxproj (307) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcxproj.filters (78) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcxproj.user (3) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/UpgradeLog.XML (47) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport.css (207) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport.xslt (232) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport_Minus.gif (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport_Plus.gif (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/module.mk (240) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/modulelocal-sample.mk (84) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtCaepInitItems.h (142) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtCaepInstanceData.h (135) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtCaepSupportData.h (83) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtPwpInitItems.h (68) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtPwpPluginInfo.h (75) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtPwpVersions.h (64) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/runtimeWrite.c (439) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/runtimeWrite_orig.txt (60) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcproj (511) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcproj.PWI.dgarlisch.user (121) ; - D MeshTools/PointwiseSU2plugin/src/plugins,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:16054,plugin,plugins,16054,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['plugin'],['plugins']
Modifiability, MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtCaepInitItems.h (98) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtCaepInstanceData.h (135) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtCaepSupportData.h (89) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtPwpInitItems.h (68) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtPwpPluginInfo.h (75) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtPwpVersions.h (62) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/runtimeWrite.c (347) ; - D MeshTools/PointwiseSU2plugin/src/plugins/README.txt (272) ; - D MeshTools/PointwiseSU2plugin/src/plugins/module.mk (309) ; - D MeshTools/PointwiseSU2plugin/src/plugins/modulelocal.mk (8) ; - D MeshTools/PointwiseSU2plugin/src/plugins/pluginRegistry.h (29) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEP.c (228) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEP.h (550) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEPUtils.c (290) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEPUtils.h (725) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/runtimeWrite.h (57) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWGM/apiGridModel.c (492) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWGM/apiGridModel.h (1808) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWP.c (132) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWP.h (707) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWPUtils.c (789) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWPUtils.h (1030) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiUtils.h (174) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/pwpPlatform.c (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/pwpPlatform.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/site.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugi,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:18419,plugin,plugins,18419,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['plugin'],['plugins']
Modifiability, MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtCaepInstanceData.h (135) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtCaepSupportData.h (89) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtPwpInitItems.h (68) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtPwpPluginInfo.h (75) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtPwpVersions.h (62) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/runtimeWrite.c (347) ; - D MeshTools/PointwiseSU2plugin/src/plugins/README.txt (272) ; - D MeshTools/PointwiseSU2plugin/src/plugins/module.mk (309) ; - D MeshTools/PointwiseSU2plugin/src/plugins/modulelocal.mk (8) ; - D MeshTools/PointwiseSU2plugin/src/plugins/pluginRegistry.h (29) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEP.c (228) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEP.h (550) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEPUtils.c (290) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEPUtils.h (725) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/runtimeWrite.h (57) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWGM/apiGridModel.c (492) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWGM/apiGridModel.h (1808) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWP.c (132) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWP.h (707) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWPUtils.c (789) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWPUtils.h (1030) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiUtils.h (174) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/pwpPlatform.c (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/pwpPlatform.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/site.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/structured.props (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/structure,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:18499,plugin,plugins,18499,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['plugin'],['plugins']
Modifiability," case, we would have something along the lines of: . a) NACA0012; i) 113 x 33; ii) 225 x 65 ; iii) 449 x 129; iv) ... This way we have a family of meshes and configuration files that are specifically built for the purpose of validating the code and comparing with other solvers. I might be useful to compress meshes that are larger than a certain size (say 10MB). We should also put a limit on the size of a single mesh that the repository can handle (say 50MB?). . Within the home directory, the README file should list all the cases in the repository, who the custodian of the test case is (person with meshes in case the meshes are too large), and which version it was last run on. . I thought about splitting it up into Verification cases and Validation cases, but I thought it would be more informative and intuitive to split up according to the physics of the simulations. My thinking might be limited because that's how I have seen the TestCases folder organized, so any other suggestions are welcome. I think it is imperative that this is accompanied with a section on the SU2 website that showcases just the results of the validation test cases (grid convergence studies, residual reductions etc) and links to the v&v repo appropriately. This way, if people are just inquisitive about SU2's performance, they can get a quick snapshot of the results, without the need to run the cases themselves. . I also wanted to broach the topic of convergence here. Would it be a good idea to standardize the termination criteria wherever possible? For example, in the NACA0012 case we can ensure that residuals are reduced by 8 orders of magnitude for all meshes. Or for the ONERAM6, we use Cauchy convergence and make sure the C_L is converged to 6 orders of magnitude. This would have to be flexible since the same level of convergence might not apply to all the cases in the repository. But for within a test case, I think it would be good to use the same convergence criteria for a family of meshes.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/581#issuecomment-426026053:2415,flexible,flexible,2415,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-426026053,1,['flexible'],['flexible']
Modifiability," checking size of short int; configure:4975: gcc -o conftest -g -O2 conftest.c >&5; configure:4975: $? = 0; configure:4975: ./conftest; configure:4975: $? = 0; configure:4989: result: 2; configure:5003: checking size of int; configure:5008: gcc -o conftest -g -O2 conftest.c >&5; configure:5008: $? = 0; configure:5008: ./conftest; configure:5008: $? = 0; configure:5022: result: 4; configure:5036: checking size of unsigned int; configure:5041: gcc -o conftest -g -O2 conftest.c >&5; configure:5041: $? = 0; configure:5041: ./conftest; configure:5041: $? = 0; configure:5055: result: 4; configure:5069: checking size of long int; configure:5074: gcc -o conftest -g -O2 conftest.c >&5; configure:5074: $? = 0; configure:5074: ./conftest; configure:5074: $? = 0; configure:5088: result: 8; configure:5102: checking size of float; configure:5107: gcc -o conftest -g -O2 conftest.c >&5; configure:5107: $? = 0; configure:5107: ./conftest; configure:5107: $? = 0; configure:5121: result: 4; configure:5135: checking size of double; configure:5140: gcc -o conftest -g -O2 conftest.c >&5; configure:5140: $? = 0; configure:5140: ./conftest; configure:5140: $? = 0; configure:5154: result: 8; configure:5168: checking size of void *; configure:5173: gcc -o conftest -g -O2 conftest.c >&5; configure:5173: $? = 0; configure:5173: ./conftest; configure:5173: $? = 0; configure:5187: result: 8; configure:5409: checking X11/Intrinsic.h usability; configure:5409: gcc -c -g -O2 conftest.c >&5; conftest.c:61:27: error: X11/Intrinsic.h: No such file or directory; configure:5409: $? = 1; configure: failed program was:; | /* confdefs.h */; | #define PACKAGE_NAME ""SU2""; | #define PACKAGE_TARNAME ""SU2""; | #define PACKAGE_VERSION ""4.1.0""; | #define PACKAGE_STRING ""SU2 4.1.0""; | #define PACKAGE_BUGREPORT ""su2code-dev@lists.stanford.edu""; | #define PACKAGE_URL ""https://github.com/su2code""; | #define PACKAGE ""SU2""; | #define VERSION ""4.1.0""; | #define STDC_HEADERS 1; | #define HAVE_SYS_TYPES_H 1; | #define HAVE_",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:11872,config,configure,11872,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,4,['config'],['configure']
Modifiability," commits or submit a pull request, the unit tests are run and checked. What is my vision for unit testing in SU2?. I am not proposing that we start trying to get 100% code coverage with pre-existing code. That would not provide a good return on investment. Instead, I see people adding unit tests as they write new code and as they find bugs. For each new behavior added to SU2, tests are first added to document the related existing behavior. These tests serve to check that the existing behavior isn't damaged by the new code. Then new tests are added to prove that the new behavior is working correctly. For bug fixes, the process is simpler. A test is added to confirm that something is not behaving as expected. Then the code is fixed to make the test pass. What frameworks are available?. For a unit testing framework, here are the most popular options, with the following pros and cons:. Roll-your-own. * Requires no external dependencies; * The most flexible option; * Involves the most work to setup; * Will lack some of the more advances features of mature unit-testing frameworks. Boost Test. * Can be header only, statically linked, or dynamically linked; * If statically or dynamically linked, then Boost is not very lightweight; * Easy to add if you're already using Boost. Google Test. * Most common unit-testing framework; * Can be easily combined with Google's powerful GMock mocking library; * Compiling and linking can be somewhat painful. Catch2. * Used by FEniCS; * Makes unit tests easily readable with lots of syntactic sugar.; * Has a very simple syntax; * Is header-only; * Requires C++11 compilation; * Not as feature rich as Google Test or Boost Test. Questions. * How do developers feel about adding unit tests to SU2?; * If a unit-testing framework were added to SU2, would you actually use it?; * Do developers have a preference (or experience with) any of the unit testing frameworks?; * Should unit tests be expected when submitting PRs?. —; You are receiving this bec",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499250240:4429,flexible,flexible,4429,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240,1,['flexible'],['flexible']
Modifiability," configure:4405: $? = 0; configure:4413: cc -c conftest.c -o conftest2.o >&5; configure:4417: $? = 0; configure:4423: cc -c conftest.c -o conftest2.o >&5; configure:4427: $? = 0; configure:4445: result: yes; configure:4513: checking for ranlib; configure:4529: found /usr/bin/ranlib; configure:4540: result: ranlib; configure:4574: checking how to run the C preprocessor; configure:4605: gcc -E conftest.c; configure:4605: $? = 0; configure:4619: gcc -E conftest.c; conftest.c:11:28: error: ac_nonexistent.h: No such file or directory; configure:4619: $? = 1; configure: failed program was:; | /* confdefs.h */; | #define PACKAGE_NAME ""SU2""; | #define PACKAGE_TARNAME ""SU2""; | #define PACKAGE_VERSION ""4.1.0""; | #define PACKAGE_STRING ""SU2 4.1.0""; | #define PACKAGE_BUGREPORT ""su2code-dev@lists.stanford.edu""; | #define PACKAGE_URL ""https://github.com/su2code""; | #define PACKAGE ""SU2""; | #define VERSION ""4.1.0""; | /* end confdefs.h. */; | #include <ac_nonexistent.h>; configure:4644: result: gcc -E; configure:4664: gcc -E conftest.c; configure:4664: $? = 0; configure:4678: gcc -E conftest.c; conftest.c:11:28: error: ac_nonexistent.h: No such file or directory; configure:4678: $? = 1; configure: failed program was:; | /* confdefs.h */; | #define PACKAGE_NAME ""SU2""; | #define PACKAGE_TARNAME ""SU2""; | #define PACKAGE_VERSION ""4.1.0""; | #define PACKAGE_STRING ""SU2 4.1.0""; | #define PACKAGE_BUGREPORT ""su2code-dev@lists.stanford.edu""; | #define PACKAGE_URL ""https://github.com/su2code""; | #define PACKAGE ""SU2""; | #define VERSION ""4.1.0""; | /* end confdefs.h. */; | #include <ac_nonexistent.h>; configure:4707: checking for grep that handles long lines and -e; configure:4765: result: /bin/grep; configure:4770: checking for egrep; configure:4832: result: /bin/grep -E; configure:4837: checking for ANSI C header files; configure:4857: gcc -c -g -O2 conftest.c >&5; configure:4857: $? = 0; configure:4930: gcc -o conftest -g -O2 conftest.c >&5; configure:4930: $? = 0; configure:4930: ./conftest",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:8586,config,configure,8586,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,2,['config'],['configure']
Modifiability," connectivity[iEdge].first;; size_t jPoint = connectivity[iEdge].second;. double phi_ave[nVar];. #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); phi_ave[iVar] = 0.5*(phi(iPoint,iVar)+phi(jPoint,iVar));. for(size_t iDim=0; iDim<nDim; ++iDim); {; #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); {; double flux = phi_ave[iVar]*area(iEdge,iDim);. grad(iPoint,iVar,iDim) += flux;; grad(jPoint,iVar,iDim) -= flux;; }; }; }. for(size_t iPoint=0; iPoint<nPoint; ++iPoint); for(size_t iDim=0; iDim<nDim; ++iDim); #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); grad(iPoint,iVar,iDim) /= volume[iPoint];; }; ```; Well it is not just a few pragmas, we need to make the number of variables known at compile time (via a template parameter) and we need to transpose how the gradient is stored, i.e. instead of {xyz, xyz, xyz, xyz} we need {xxxx, yyyy, zzzz}. This code gets a speed-up of **2.2**. This code is generic but the template needs to be instantiated for every possible number of variables and we need a `switch` to call the right version at runtime, not very friendly.; Processing multiple edges at the same time is not worth the effort, for one we need `gather/scatter` on a very light routine, and on top of that we need to sort the edges such that we do not attempt to `scatter` to the same point when updating the gradient (a problem similar to the race condition described for SPMD). We can switch to a point-based loop and process multiple points in a SIMD way, that avoids the `scatter` problem but `gathers` will still be required. Here is what the scalar version of the point-based loop looks like:; ```C++; void computeGradients(size_t nPoint,; size_t nVar,; size_t nDim,; const Adjacency& adj,; const Matrix& area,; const vector<double>& volume,; const Matrix& phi,; VectorOfMatrix& grad); {; for(size_t iPoint=0; iPoint<nPoint; ++iPoint); {; for(size_t iVar=0; iVar<nVar; ++iVar); for(size_t iDim=0; iDim<nDim; ++iDim); grad(iPoint,iVar,iDim) = 0.0;. for(size_t iNe",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-530328194:3124,variab,variables,3124,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530328194,1,['variab'],['variables']
Modifiability," container that automates the per-thread creation and access. > Why are they redefined each time inside the loop?; > Is this for efficiency reasons?. Referring to variables being declared inside loops. One stylist reason is that declaring everything at the top of a function is the C way of doing things, the C++ people whose books/blogs I've read and talks I've watched, recommend keeping namespaces (the inside of the loop being one) as clean as possible.; The only reason not to do this is if you explicitly want re-use, in the case of trivial types this does not improve efficiency, and in the context of OpenMP code it can create issues. Just like we need one numerics per thread, if we declare variables outside a parallel loop the default OpenMP behaviour is to consider them shared, and concurrent writes to shared locations = gdb and many bad words xD.; **EDIT:** I should mention here that if the parallel region is started before the variable declarations they become local and all is well, with the exception of class members, those will be shared most of the time (this is where const correctness can give some peace of mind). > Also, just an additional (hopefully constructive) comment: I find all of these developments great, and I honestly think that you are doing an amazing job on performance and overall code improvement. However, as a non-C++-master myself, I'm just a little concerned of whether some advanced programming may become an entrance barrier to new additions to the community. As I wrote in the preamble of #789:; ""But please participate even if you never heard of these topics, your opinion about readability and ""developability"" of the code is important! I think the code-style should be accessible to people starting a PhD (after they read a bit about C++...).""; I try to encapsulate and hide the tricky bits as much as possible to make the code as readable as possible, whether I am succeeding or not is for the community to decide, in all these PR's I've been poi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/843#issuecomment-577684728:3115,variab,variable,3115,https://su2code.github.io,https://github.com/su2code/SU2/pull/843#issuecomment-577684728,1,['variab'],['variable']
Modifiability," gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4970: checking size of short int; configure:4975: gcc -o conftest -g -O2 conftest.c >&5; configure:4975: $? = 0; configure:4975: ./conftest; configure:4975: $? = 0; configure:4989: result: 2; configure:5003: checking size of int; configure:5008: gcc -o conftest -g -O2 conftest.c >&5; configure:5008: $? = 0; configure:5008: ./conftest; configure:5008: $? = 0; configure:5022: result: 4; configure:5036: checking size of unsigned int; configure:5041: gcc -o conftest -g -O2 conftest.c >&5; configure:5041: $? = 0; configure:5041: ./conftest; configure:5041: $? = 0; configure:5055: result: 4; configure:5069: checking size of long int; configure:5074: gcc -o conftest -g -O2 conftest.c >&5; configure:5074: $? = 0; configure:5074: ./conftest; configure:5074: $? = 0; configure:5088: result: 8; configure:5102: checking size of float; configure:5107: gcc -o conftest -g -O2 conftest.c >&5; configure:5107: $? = 0; configure:5107: ./conftest; configure:5107: $? = 0; configure:5121: result: 4; configure:5135: checking size of double; configure:5140: gcc -o conftest -g -O2 conftest.c >&5; configure:5140: $? = 0; configure:5140: ./conftest; configure:5140: $? = 0; configure:5154: result: 8; configure:5168: checking size of void *; configure:5173: gcc -o conftest -g -O2 conftest.c >&5; configure:5173: $? = 0; configure:5173: ./conftest; configure:5173: $? = 0; configure:5187: result: 8; configure:5409: checking X11/Intrinsic.h usability; configure:5409: gcc -c -g -O2 conftest.c >&5; conftest.c:61:27: error: X11/Intrinsic.h: No such file or directory; configure:5409: $? = 1; configure: failed program was:; | /* confdefs.h */; | #define PACKAGE_NAME ""SU2""; | #define PACKAGE_TARNAME ""SU2""; | #define PACKAGE_VERSION ""4.1.0""; | #define PACKAGE_STRING ""SU2 4.1.0""; | #define PACKAGE_BUGREPORT ""su2code-dev@lists.stanford.edu""; | #define PACKAGE_URL ""https://github.com/su2code""; | #define PACKAGE ""SU2""",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:11820,config,configure,11820,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,2,['config'],['configure']
Modifiability," means for each numerical method we will have 4 explicit template instantiations (Euler2D, Euler3D, (RA)NS2D, (RA)NS3D) but in the end these are still polymorphic objects that will be instantiated by some factory function (i.e. it will look clean, especially because I will not port all methods in one go xD). The template machinery to support this is actually not too crazy:; ```c++; #include <array>; #include <cmath>. // An example type to use instead of the container that stores solution data for all vertices.; struct SolutionContainer; {; std::array<double,3> velocity;; std::array<double,3> areaVector;; };. using ResultType = double;. // We want classes with this interface.; class VirtualInterface; {; public:; virtual ResultType Compute(const SolutionContainer&) const = 0;; };. // The Compute method is to be composed via an inheritance chain, to do this; // we allow each building block to inherit from any class. These classes should; // be function objects that have no member variables, all data used in the; // resulting Compute method will be on the stack.; template<typename Base>; class ComputeArea : Base; {; protected:; // Different template instantiations will be made for; // 2D/3D to allow perfect loop unrolling.; enum : int {nDim = Base::nDim};. // To share variables between building blocks we will pass; // down a struct which is also composed by inheritance; struct WorkVarsType : Base::WorkVarsType; {; double area; // add ""area"" to the variables of Base; };; ; // The final implementation of Compute will be a call down the chain.; // The final constructed WorkVarsType is not known at this stage,; // hence we also template the method.; template<typename WV>; void Compute(WV& wv, const SolutionContainer& sol) const; {; // Boilerplate, call base first. This is akin to the decorator design pattern; // without polymorphism. The working variables resemble Python's ""self"" which; // makes this solution reasonably idiomatic.; Base::Compute(wv, sol);. // Then do our sp",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-622941617:2712,variab,variables,2712,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-622941617,1,['variab'],['variables']
Modifiability," model: posix; gcc version 4.4.6 20120305 (Red Hat 4.4.6-4) (GCC) ; configure:3999: $? = 0; configure:3988: gcc -V >&5; gcc: '-V' option must have argument; configure:3999: $? = 1; configure:3988: gcc -qversion >&5; gcc: unrecognized option '-qversion'; gcc: no input files; configure:3999: $? = 1; configure:4003: checking whether we are using the GNU C compiler; configure:4022: gcc -c conftest.c >&5; configure:4022: $? = 0; configure:4031: result: yes; configure:4040: checking whether gcc accepts -g; configure:4060: gcc -c -g conftest.c >&5; configure:4060: $? = 0; configure:4101: result: yes; configure:4118: checking for gcc option to accept ISO C89; configure:4181: gcc -c -g -O2 conftest.c >&5; configure:4181: $? = 0; configure:4194: result: none needed; configure:4216: checking dependency style of gcc; configure:4327: result: gcc3; configure:4345: checking whether gcc and cc understand -c and -o together; configure:4376: gcc -c conftest.c -o conftest2.o >&5; configure:4380: $? = 0; configure:4386: gcc -c conftest.c -o conftest2.o >&5; configure:4390: $? = 0; configure:4401: cc -c conftest.c >&5; configure:4405: $? = 0; configure:4413: cc -c conftest.c -o conftest2.o >&5; configure:4417: $? = 0; configure:4423: cc -c conftest.c -o conftest2.o >&5; configure:4427: $? = 0; configure:4445: result: yes; configure:4513: checking for ranlib; configure:4529: found /usr/bin/ranlib; configure:4540: result: ranlib; configure:4574: checking how to run the C preprocessor; configure:4605: gcc -E conftest.c; configure:4605: $? = 0; configure:4619: gcc -E conftest.c; conftest.c:11:28: error: ac_nonexistent.h: No such file or directory; configure:4619: $? = 1; configure: failed program was:; | /* confdefs.h */; | #define PACKAGE_NAME ""SU2""; | #define PACKAGE_TARNAME ""SU2""; | #define PACKAGE_VERSION ""4.1.0""; | #define PACKAGE_STRING ""SU2 4.1.0""; | #define PACKAGE_BUGREPORT ""su2code-dev@lists.stanford.edu""; | #define PACKAGE_URL ""https://github.com/su2code""; | #define PACKAGE ""SU2"";",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:7477,config,configure,7477,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,2,['config'],['configure']
Modifiability," no; configure:5721: checking for /gshare/soft/code_saturne/4.0.0/prod/cgnslib_3.2.1/lib/libcgns.a; configure:5735: result: yes; configure:5755: checking for /gshare/soft/code_saturne/4.0.0/prod/cgnslib_3.2.1/include/cgnslib.h; configure:5769: result: yes; configure:6815: checking that generated files are newer than configure; configure:6821: result: done; configure:6952: creating ./config.status. ## ---------------------- ##; ## Running config.status. ##; ## ---------------------- ##. This file was extended by SU2 config.status 4.1.0, which was; generated by GNU Autoconf 2.69. Invocation command line was. CONFIG_FILES = ; CONFIG_HEADERS = ; CONFIG_LINKS = ; CONFIG_COMMANDS = ; $ ./config.status . on master. config.status:875: creating externals/tecio/Makefile; config.status:875: creating externals/metis/Makefile; config.status:875: creating externals/parmetis/Makefile; config.status:875: creating Makefile; config.status:875: creating externals/Makefile; config.status:875: creating Common/lib/Makefile; config.status:875: creating SU2_CFD/obj/Makefile; config.status:875: creating SU2_DOT/obj/Makefile; config.status:875: creating SU2_MSH/obj/Makefile; config.status:875: creating SU2_DEF/obj/Makefile; config.status:875: creating SU2_SOL/obj/Makefile; config.status:875: creating SU2_GEO/obj/Makefile; config.status:875: creating SU2_PY/Makefile; config.status:1047: executing depfiles commands; configure:8181: result:. -------------------------------------------------------------------------; | ___ _ _ ___ |; | / __| | | |_ ) Release 4.1.0 'Cardinal' |; | \__ \ |_| |/ / |; | |___/\___//___| Suite |; | |; -------------------------------------------------------------------------; | SU2 Lead Dev.: Dr. Francisco Palacios, Francisco.D.Palacios@boeing.com|; | Dr. Thomas D. Economon, economon@stanford.edu |; -------------------------------------------------------------------------; | SU2 Developers: |; | - Prof. Juan J. Alonso's group at Stanford University. |; | - Prof. Piero Co",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:16282,config,config,16282,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,1,['config'],['config']
Modifiability," of contiguous data.; It is not the only way, it is also possible to `gather` and `scatter` data. That is populating the register from non-contiguous locations and vice versa. This is about one order of magnitude slower, to the point where if the computations are very simple it may not pay-off to vectorize. **Relation with algorithms**; Some form of `gather` and `scatter` is required in unstructured CFD, which means SIMD has a price of admission. Some thought needs to go into designing algorithms that amortize that cost by maximizing the so called FLOP/Byte ratio, and mask the latency of those operations by being able to start computing as soon as the first element of data is available. **What elements should we try to process simultaneously?**; The choice is between multiple geometric primitives (edges/points) or multiple solution primitives (variables). The latter sounds like a sensible idea until we get to areas of the code where different primitives require different treatment, that and the fact that the number of variables might not fit evenly in the number of lanes can lead to very tricky and non-generic code. Nevertheless if the same code were to be applied to e.g. 4 solution variables, this strategy would likely perform better as it avoids the pesky gather/scatter operations.; Processing multiple geometric primitives can make full utilization of whatever register size (important on GPU's), the code is just as readable (as I hope to show), but gather/scatter cannot be avoided. ### Intro to SPMD; This one is simpler, in a nutshell multiple threads operate on the sub domain of an MPI rank.; The typical implementation has each thread executing a chunk of an edge or cell loop. **Why should we care about SPMD?**; Reduce the communication overhead resulting from domain decomposition and improve load balancing, important for strong scaling.; Some algorithms are more efficient that way, e.g. the ADT (as mentioned by Edwin), the current MG also seems to work better on",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-529662724:2382,variab,variables,2382,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-529662724,1,['variab'],['variables']
Modifiability," of time spent; > in bug-fixing and maintaining.; >; > For more information, see this relevant Stack Exchange question.; > <https://scicomp.stackexchange.com/questions/206/is-it-worthwhile-to-write-unit-tests-for-scientific-research-codes>; > What do I propose?; >; > My research group at UT Austing has implemented a unit testing framework; > on our branch, which we're happy with. Some choices were arbitrary, and; > some choices were made based on our development environment. Those choices; > may be different for other groups. Here's what we have done:; >; > The unit testing framework is compiled and run using autotools. For more; > information on autotool's setup, see their documentation; > <https://www.gnu.org/software/automake/manual/html_node/Tests.html>.; > Since autotools is the build system for SU2, this involves minimal changes.; >; > Using automake, the build process for building unit tests becomes:; >; > '''; > ./bootstrap; > ./configure; > make; > make check; > '''; >; > We use Boost's unit testing framework; > <https://www.boost.org/doc/libs/1_70_0/libs/test/doc/html/index.html>.; > This provides a convenient set of macros for instatiating tests, grouping; > tests into suites, and running checks. This choice was based on what is; > available in our development setup.; >; > We have integrated our unit tests into our Travis CI regression testing.; > Every time we push commits or submit a pull request, the unit tests are run; > and checked.; > What is my vision for unit testing in SU2?; >; > I am *not* proposing that we start trying to get 100% code coverage with; > pre-existing code. That would not provide a good return on investment.; >; > Instead, I see people adding unit tests as they write new code and as they; > find bugs. For each new behavior added to SU2, tests are first added to; > document the related existing behavior. These tests serve to check that the; > existing behavior isn't damaged by the new code. Then new tests are added; > to prove that",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499278427:4176,config,configure,4176,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427,1,['config'],['configure']
Modifiability," result: yes; configure:2872: checking for a thread-safe mkdir -p; configure:2911: result: /bin/mkdir -p; configure:2918: checking for gawk; configure:2934: found /bin/gawk; configure:2945: result: gawk; configure:2956: checking whether make sets $(MAKE); configure:2978: result: yes; configure:3075: checking whether make supports nested variables; configure:3092: result: yes; configure:3117: checking for style of include used by make; configure:3145: result: GNU; configure:3196: result: >>> MPI support disabled by default <<<; configure:3269: checking for g++; configure:3285: found /usr/bin/g++; configure:3296: result: g++; configure:3323: checking for C++ compiler version; configure:3332: g++ --version >&5; g++ (GCC) 4.4.6 20120305 (Red Hat 4.4.6-4); Copyright (C) 2010 Free Software Foundation, Inc.; This is free software; see the source for copying conditions. There is NO; warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. configure:3343: $? = 0; configure:3332: g++ -v >&5; Using built-in specs.; Target: x86_64-redhat-linux; Configured with: ../configure --prefix=/usr --mandir=/usr/share/man --infodir=/usr/share/info --with-bugurl=http://bugzilla.redhat.com/bugzilla --enable-bootstrap --enable-shared --enable-threads=posix --enable-checking=release --with-system-zlib --enable-__cxa_atexit --disable-libunwind-exceptions --enable-gnu-unique-object --enable-languages=c,c++,objc,obj-c++,java,fortran,ada --enable-java-awt=gtk --disable-dssi --with-java-home=/usr/lib/jvm/java-1.5.0-gcj-1.5.0.0/jre --enable-libgcj-multifile --enable-java-maintainer-mode --with-ecj-jar=/usr/share/java/eclipse-ecj.jar --disable-libjava-multilib --with-ppl --with-cloog --with-tune=generic --with-arch_32=i686 --build=x86_64-redhat-linux; Thread model: posix; gcc version 4.4.6 20120305 (Red Hat 4.4.6-4) (GCC) ; configure:3343: $? = 0; configure:3332: g++ -V >&5; g++: '-V' option must have argument; configure:3343: $? = 1; configure:3332: g++ -qversion >&5; g++: unreco",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:3012,config,configure,3012,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,2,['config'],['configure']
Modifiability, sys/stat.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for stdlib.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for string.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for memory.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for strings.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for inttypes.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for stdint.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for unistd.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4970: checking size of short int; configure:4975: gcc -o conftest -g -O2 conftest.c >&5; configure:4975: $? = 0; configure:4975: ./conftest; configure:4975: $? = 0; configure:4989: result: 2; configure:5003: checking size of int; configure:5008: gcc -o conftest -g -O2 conftest.c >&5; configure:5008: $? = 0; configure:5008: ./conftest; configure:5008: $? = 0; configure:5022: result: 4; configure:5036: checking size of unsigned int; configure:5041: gcc -o conftest -g -O2 conftest.c >&5; configure:5041: $? = 0; configure:5041: ./conftest; configure:5041: $? = 0; configure:5055: result: 4; configure:5069: checking size of long int; configure:5074: gcc -o conftest -g -O2 conftest.c >&5; configure:5074: $? = 0; configure:5074: ./conftest; configure:5074: $? = 0; configure:5088: result: 8; configure:5102: checking size of float; configure:5107: gcc -o conftest -g -O2 conftest.c >&5; configure:5107: $? =,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:10822,config,configure,10822,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,1,['config'],['configure']
Modifiability," where integration to the wall makes sense and a fuselage marker where wall functions (or even an inviscid BC) is the right thing to do. So let’s indeed do something like what Tom suggests (in the spirit of MARKER_MONITORING) so that one can control which markers get wall functions applied. If a list of markers is not specified in the config file, the default behavior should be that all no-slip walls get wall function BCs. If a list of markers is specified, then those and only those markers listed get wall function Bfs (with the others getting integration to the wall treatment). Now, what you point out in the second half of your message is the ultimate in flexibility: not only specifying wall functions in a subset of the no-slip wall markers, but also allowing for different kinds of wall functions to be used in those markers. I imagine that this would be a seldom used capability…but someone out there might have the need. I guess it does not seem to me that the coding of the most flexible logic is that much more complicated, so we may as well do that. If you guys think it is too complicated, the advertised options in the config file can allow some simpler behavior. My two cents,. Juan. On Sep 5, 2017, at 9:58 PM, Edwin van der Weide <notifications@github.com<mailto:notifications@github.com>> wrote:. Juan,. I think that having the flexibility to apply wall functions on only a subset of the viscous wall boundaries would be useful. E.g., if you are interested in a wing, you can apply integration to the wall there, but apply wall functions on the fuselage. My preference would be to have a dedicated BC type for that, i.e. Tom's second suggestion. Apart from this, we can have the different wall model types as a single input parameter, i.e. you apply the same wall model type for all viscous boundaries. Or would you like to have the flexibility to specify this as well per individual marker?. Edwin. —; You are receiving this because you commented.; Reply to this email directl",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/399#issuecomment-327377108:1200,flexible,flexible,1200,https://su2code.github.io,https://github.com/su2code/SU2/issues/399#issuecomment-327377108,1,['flexible'],['flexible']
Modifiability," yes; configure:4954: checking for stdint.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for unistd.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4970: checking size of short int; configure:4975: gcc -o conftest -g -O2 conftest.c >&5; configure:4975: $? = 0; configure:4975: ./conftest; configure:4975: $? = 0; configure:4989: result: 2; configure:5003: checking size of int; configure:5008: gcc -o conftest -g -O2 conftest.c >&5; configure:5008: $? = 0; configure:5008: ./conftest; configure:5008: $? = 0; configure:5022: result: 4; configure:5036: checking size of unsigned int; configure:5041: gcc -o conftest -g -O2 conftest.c >&5; configure:5041: $? = 0; configure:5041: ./conftest; configure:5041: $? = 0; configure:5055: result: 4; configure:5069: checking size of long int; configure:5074: gcc -o conftest -g -O2 conftest.c >&5; configure:5074: $? = 0; configure:5074: ./conftest; configure:5074: $? = 0; configure:5088: result: 8; configure:5102: checking size of float; configure:5107: gcc -o conftest -g -O2 conftest.c >&5; configure:5107: $? = 0; configure:5107: ./conftest; configure:5107: $? = 0; configure:5121: result: 4; configure:5135: checking size of double; configure:5140: gcc -o conftest -g -O2 conftest.c >&5; configure:5140: $? = 0; configure:5140: ./conftest; configure:5140: $? = 0; configure:5154: result: 8; configure:5168: checking size of void *; configure:5173: gcc -o conftest -g -O2 conftest.c >&5; configure:5173: $? = 0; configure:5173: ./conftest; configure:5173: $? = 0; configure:5187: result: 8; configure:5409: checking X11/Intrinsic.h usability; configure:5409: gcc -c -g -O2 conftest.c >&5; conftest.c:61:27: error: X11/Intrinsic.h: No such file or directory; configure:5409: $? = 1; configure: failed program was:; | /* confdefs.h */; | #define PACKAGE_NAME ""SU2""; | #define PACKAGE_TARNAME ""SU2""; | #define PA",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:11622,config,configure,11622,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,2,['config'],['configure']
Modifiability,"""https://github.com/su2code""; | #define PACKAGE ""SU2""; | #define VERSION ""4.1.0""; | /* end confdefs.h. */; | #include <ac_nonexistent.h>; configure:4707: checking for grep that handles long lines and -e; configure:4765: result: /bin/grep; configure:4770: checking for egrep; configure:4832: result: /bin/grep -E; configure:4837: checking for ANSI C header files; configure:4857: gcc -c -g -O2 conftest.c >&5; configure:4857: $? = 0; configure:4930: gcc -o conftest -g -O2 conftest.c >&5; configure:4930: $? = 0; configure:4930: ./conftest; configure:4930: $? = 0; configure:4941: result: yes; configure:4954: checking for sys/types.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for sys/stat.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for stdlib.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for string.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for memory.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for strings.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for inttypes.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for stdint.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for unistd.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4970: checking size of short int; configure:4975: gcc -o conftest -g -O2 conftest.c >&5; configure:4975: $? = 0; configure:4975: ./conftest; config",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:10037,config,configure,10037,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,3,['config'],['configure']
Modifiability,"$? = 0; configure:4975: ./conftest; configure:4975: $? = 0; configure:4989: result: 2; configure:5003: checking size of int; configure:5008: gcc -o conftest -g -O2 conftest.c >&5; configure:5008: $? = 0; configure:5008: ./conftest; configure:5008: $? = 0; configure:5022: result: 4; configure:5036: checking size of unsigned int; configure:5041: gcc -o conftest -g -O2 conftest.c >&5; configure:5041: $? = 0; configure:5041: ./conftest; configure:5041: $? = 0; configure:5055: result: 4; configure:5069: checking size of long int; configure:5074: gcc -o conftest -g -O2 conftest.c >&5; configure:5074: $? = 0; configure:5074: ./conftest; configure:5074: $? = 0; configure:5088: result: 8; configure:5102: checking size of float; configure:5107: gcc -o conftest -g -O2 conftest.c >&5; configure:5107: $? = 0; configure:5107: ./conftest; configure:5107: $? = 0; configure:5121: result: 4; configure:5135: checking size of double; configure:5140: gcc -o conftest -g -O2 conftest.c >&5; configure:5140: $? = 0; configure:5140: ./conftest; configure:5140: $? = 0; configure:5154: result: 8; configure:5168: checking size of void *; configure:5173: gcc -o conftest -g -O2 conftest.c >&5; configure:5173: $? = 0; configure:5173: ./conftest; configure:5173: $? = 0; configure:5187: result: 8; configure:5409: checking X11/Intrinsic.h usability; configure:5409: gcc -c -g -O2 conftest.c >&5; conftest.c:61:27: error: X11/Intrinsic.h: No such file or directory; configure:5409: $? = 1; configure: failed program was:; | /* confdefs.h */; | #define PACKAGE_NAME ""SU2""; | #define PACKAGE_TARNAME ""SU2""; | #define PACKAGE_VERSION ""4.1.0""; | #define PACKAGE_STRING ""SU2 4.1.0""; | #define PACKAGE_BUGREPORT ""su2code-dev@lists.stanford.edu""; | #define PACKAGE_URL ""https://github.com/su2code""; | #define PACKAGE ""SU2""; | #define VERSION ""4.1.0""; | #define STDC_HEADERS 1; | #define HAVE_SYS_TYPES_H 1; | #define HAVE_SYS_STAT_H 1; | #define HAVE_STDLIB_H 1; | #define HAVE_STRING_H 1; | #define HAVE_MEMORY_H 1; | #d",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:12019,config,configure,12019,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,2,['config'],['configure']
Modifiability,(121) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcxproj (307) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcxproj.filters (78) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcxproj.user (3) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/module.mk (239) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/modulelocal-sample.mk (84) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtCaepInitItems.h (98) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtCaepInstanceData.h (135) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtCaepSupportData.h (89) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtPwpInitItems.h (68) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtPwpPluginInfo.h (75) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtPwpVersions.h (62) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/runtimeWrite.c (347) ; - D MeshTools/PointwiseSU2plugin/src/plugins/README.txt (272) ; - D MeshTools/PointwiseSU2plugin/src/plugins/module.mk (309) ; - D MeshTools/PointwiseSU2plugin/src/plugins/modulelocal.mk (8) ; - D MeshTools/PointwiseSU2plugin/src/plugins/pluginRegistry.h (29) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEP.c (228) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEP.h (550) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEPUtils.c (290) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEPUtils.h (725) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/runtimeWrite.h (57) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWGM/apiGridModel.c (492) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWGM/apiGridModel.h (1808) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWP.c (132) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWP.h (707) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWPU,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:18007,plugin,plugins,18007,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['plugin'],['plugins']
Modifiability,(307) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/CaeStrXML.vcxproj.filters (78) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/CaeStrXML.vcxproj.user (3) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/module.mk (239) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/modulelocal-sample.mk (84) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtCaepInitItems.h (98) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtCaepInstanceData.h (135) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtCaepSupportData.h (89) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtPwpInitItems.h (68) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtPwpPluginInfo.h (75) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtPwpVersions.h (62) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/runtimeWrite.c (443) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.sdf (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.sln (26) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.suo (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcproj (511) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcxproj (307) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcxproj.filters (78) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcxproj.user (3) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/UpgradeLog.XML (47) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport.css (207) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport.xslt (232) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport_Minus.gif (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport_Plus.gif (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUns,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:15077,plugin,plugins,15077,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['plugin'],['plugins']
Modifiability,"(Krylov solvers, sparse approximate factorizations, etc.) is relatively independent from what I have in mind.; Nevertheless being able to use PETSc or HYPRE would be interesting as it would give us access to AMG, and @talbring 's branch feature_template_linear_solver would make such an integration compatible with AD.; What I would like is to have a ""CMatrixDense"" class, to give concrete examples:; - For RBF interpolation the guy who worked on it before me implemented his own Cholesky and LU factorizations, matrix-matrix, matrix-vector routines, etc.; - @jayantmukho recently needed some eigenvector decomposition's for the uncertainty quantification feature.; - I imagine in some other places of the code similar routines were needed, for example small matrix inversion when computing gradients by weighted least squares (indeed what I need now is a QR decomposition). And, as an added bonus, I think some other areas of the code could be simplified / optimized by adopting a dense matrix format, for example:; - This snipped from the viscous numerics refactoring`for (iDim = 0; iDim < nDim; iDim++) {; TauElem[iDim] = 0.0;; for (jDim = 0; jDim < nDim; jDim++); TauElem[iDim] += tau[iDim][jDim]*UnitNormal[jDim];; }` would simply become `TauElem=tau*UnitNormal`; - Cumbersome allocations like `tau_jacobian_i = new su2double* [nDim];; for (iDim = 0; iDim < nDim; iDim++) {; tau_jacobian_i[iDim] = new su2double [nVar];; }` become `Matrix tau_jacobian_i(nDim,nVar);` and the cleanup is dealt with by the destructor of the object automatically. Now to answer some questions.; @juanjosealonso @erangit LAPACK and BLAS are indeed the standard, so much so that most (all?) newer libraries will call their routines behind the scenes.; However they considerably simplify the user interface by encapsulating the aforementioned construction/destruction and by exposing natural ways of manipulating the matrices, e.g. access entire rows, columns, blocks, etc.; Another issue with using BLAS routines is th",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/643#issuecomment-459653772:1257,refactor,refactoring,1257,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459653772,1,['refactor'],['refactoring']
Modifiability,) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtPwpInitItems.h (68) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtPwpPluginInfo.h (75) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtPwpVersions.h (62) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/runtimeWrite.c (347) ; - D MeshTools/PointwiseSU2plugin/src/plugins/README.txt (272) ; - D MeshTools/PointwiseSU2plugin/src/plugins/module.mk (309) ; - D MeshTools/PointwiseSU2plugin/src/plugins/modulelocal.mk (8) ; - D MeshTools/PointwiseSU2plugin/src/plugins/pluginRegistry.h (29) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEP.c (228) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEP.h (550) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEPUtils.c (290) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEPUtils.h (725) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/runtimeWrite.h (57) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWGM/apiGridModel.c (492) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWGM/apiGridModel.h (1808) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWP.c (132) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWP.h (707) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWPUtils.c (789) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWPUtils.h (1030) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiUtils.h (174) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/pwpPlatform.c (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/pwpPlatform.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/site.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/structured.props (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/structured.vsprops (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/CaeTemplate.suo (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/Ca,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:18658,plugin,plugins,18658,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['plugin'],['plugins']
Modifiability,"**SOLVED** see edit. Hello! I seem to remember that it used to be possible to get angle of attack in the history file? Is this still possible? I would like to be able to just pull the angle of attack out of the history file, along with the aero coeffs.; Context:; I have looked through the custom output document and the reference config file, and (perhaps I am secretly blind), but there does not seem to be a simple output group for it.; Reason I need it: performing analysis for fixed Cl, so angle of attack is useful information. At the moment I am getting probed data:; ```; CUSTOM_OUTPUTS='m_vel_x : Macro{VELOCITY_X};\; m_vel_y : Macro{VELOCITY_Y};\; vel_x1: Probe{$m_vel_x}[-15, -15];\; vel_y1: Probe{$m_vel_y}[-15, -15]'; ```; And just getting the tan(y/x) of the probed values for angle. This works well enough.; The other option I have is stripping the angle of attack out of the forced breakdown file, would prefer to not do, but can. EDIT:. **It can be pulled out of line 2 of flow.meta**",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/2138#issuecomment-1780159397:331,config,config,331,https://su2code.github.io,https://github.com/su2code/SU2/issues/2138#issuecomment-1780159397,1,['config'],['config']
Modifiability,", this was not good enough... With the new strategy it is ok (see ""performance"" below), hence this is ready for review. ### Overall Strategy; The strategy now is to start a parallel section in CSysSolve::Solve that covers building the preconditioner and solving the linear system.; Linear algebra routines called within this section have _worksharing_ constructs instead of _parallel_ ones, i.e. the work is distributed by however many threads arrive to that routine. This also makes the routines safe to call in serial.; The only ""dangerous"" things to do in parallel are to: manage memory for a shared object (multiple threads call `new` but there is only one shared pointer on which to call `delete`); writing to the same memory locations concurrently.; I tried to make the first issue debugable by asserting that the initialization routines of CSysMatrix and CSysVector are only called by the master thread.; For the second issue I made the associated classes as const-correct as possible, that should at least make someone think twice before changing a member variable of those classes. The risk is still there for input variables as an algorithm development aspect... For example `MatrixVectorProductTransposed` cannot be made thread-parallel as simply/naively as its normal counterpart. ### Communication Model; The MPI + Threads communication model is very simple, currently only the master thread calls MPI routines (including `Error`), this requires thread barriers before and after the communication to make sure the correct values are passed and _seen_ by all threads.; We can test other alternatives in the future but at the moment this does not seem to be a significant bottleneck.; _Worksharing_ constructs have implicit barriers at completion, for CSysVector routines I used `nowait` modifiers, it is safe to call those routines in sequence since the loop sizes, and static work scheduling specifications are identical.; However, routines that access a CSysVector in a different way, s",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/830#issuecomment-562646766:1410,variab,variable,1410,https://su2code.github.io,https://github.com/su2code/SU2/pull/830#issuecomment-562646766,1,['variab'],['variable']
Modifiability,",; const Vector& volume,; const Matrix& phi,; VectorOfMatrix& grad); {; const size_t SIMDLEN = 4;. for(size_t iPoint=0; iPoint<nPoint; iPoint+=SIMDLEN); {; for(size_t iVar=0; iVar<nVar; ++iVar); for(size_t iDim=0; iDim<nDim; ++iDim); grad.setVec(iPoint,iVar,iDim,Array<double,SIMDLEN>(0.0));. for(size_t iNeigh=0; iNeigh<adj.nNeighbor_vec(iPoint); ++iNeigh); {; auto jPoint = adj.jPoint_vec(iPoint,iNeigh);; auto iEdge = adj.iEdge_vec(iPoint,iNeigh);; auto dir = adj.dir_vec(iPoint,iNeigh);. for(size_t iVar=0; iVar<nVar; ++iVar); {; auto phi_ave = (phi.getVec(iPoint,iVar)+; phi.getVec(jPoint,iVar))*0.5;. for(size_t iDim=0; iDim<nDim; ++iDim); grad.addVec(iPoint,iVar,iDim,; phi_ave*dir*area.getVec(iEdge,iDim));; }; }. for(size_t iVar=0; iVar<nVar; ++iVar); for(size_t iDim=0; iDim<nDim; ++iDim); grad.setVec(iPoint,iVar,iDim,; grad.getVec(iPoint,iVar,iDim)/volume.getVec(iPoint));; }; }; ```; I think this is just as readable especially considering that in SU2 we always need to use some Set/Get/Add/Sub method to update a variable, the difference is that here those methods have overloads to operate on small fixed size vectors. The speedup is **1.35** (i.e. 35% faster than edge-based reference) note that the improvement relative to scalar-point-based is only 1.6, those pesky gathers... The loop advances `SIMDLEN` points on each iteration, yet there are no pragmas and small simd-loops in sight, in good C++ fashion that trickery has been encapsulated in a ""simd-friendly"" class.; Such a class can look something like this:; ```C++; template<class T, size_t N>; class Array; {; #define FOREACH for(size_t k=0; k<N; ++k); public:; enum : size_t {Size = N};; enum : size_t {Align = N*sizeof(T)};; private:; // fixed size and aligned array of internal data, naturally maps to a SIMD register; alignas(Align) T vals_[N];; /*; * Some helper methods go here; */; public:; // **** CONSTRUCTORS **** //; // We want to be able to construct this type from single scalars,; // a memory location from whi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-530328194:6289,variab,variable,6289,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530328194,1,['variab'],['variable']
Modifiability,- D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWGM/apiGridModel.c (492) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWGM/apiGridModel.h (1808) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWP.c (132) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWP.h (707) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWPUtils.c (789) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWPUtils.h (1030) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiUtils.h (174) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/pwpPlatform.c (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/pwpPlatform.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/site.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/structured.props (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/structured.vsprops (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/CaeTemplate.suo (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/CaeTemplate.vcproj (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/module.mk (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/modulelocal-sample.mk (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/rtCaepInitItems.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/rtCaepInstanceData.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/rtCaepSupportData.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/runtimeWrite.c (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/PWP/rtPwpInitItems.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/PWP/rtPwpPluginInfo.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/PWP/rtPwpVersions.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/unstructured.props (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/unstructured.vsprops (0) ; - D MeshTools/PointwiseSU2plugin_Instructions.txt (0) ; ,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:19627,plugin,plugins,19627,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['plugin'],['plugins']
Modifiability,"-mode --with-ecj-jar=/usr/share/java/eclipse-ecj.jar --disable-libjava-multilib --with-ppl --with-cloog --with-tune=generic --with-arch_32=i686 --build=x86_64-redhat-linux; Thread model: posix; gcc version 4.4.6 20120305 (Red Hat 4.4.6-4) (GCC) ; configure:3343: $? = 0; configure:3332: g++ -V >&5; g++: '-V' option must have argument; configure:3343: $? = 1; configure:3332: g++ -qversion >&5; g++: unrecognized option '-qversion'; g++: no input files; configure:3343: $? = 1; configure:3363: checking whether the C++ compiler works; configure:3385: g++ conftest.cpp >&5; configure:3389: $? = 0; configure:3437: result: yes; configure:3440: checking for C++ compiler default output file name; configure:3442: result: a.out; configure:3448: checking for suffix of executables; configure:3455: g++ -o conftest conftest.cpp >&5; configure:3459: $? = 0; configure:3481: result: ; configure:3503: checking whether we are cross compiling; configure:3511: g++ -o conftest conftest.cpp >&5; configure:3515: $? = 0; configure:3522: ./conftest; configure:3526: $? = 0; configure:3541: result: no; configure:3546: checking for suffix of object files; configure:3568: g++ -c conftest.cpp >&5; configure:3572: $? = 0; configure:3593: result: o; configure:3597: checking whether we are using the GNU C++ compiler; configure:3616: g++ -c conftest.cpp >&5; configure:3616: $? = 0; configure:3625: result: yes; configure:3634: checking whether g++ accepts -g; configure:3654: g++ -c -g conftest.cpp >&5; configure:3654: $? = 0; configure:3695: result: yes; configure:3720: checking dependency style of g++; configure:3831: result: gcc3; configure:3921: checking for gcc; configure:3937: found /usr/bin/gcc; configure:3948: result: gcc; configure:3979: checking for C compiler version; configure:3988: gcc --version >&5; gcc (GCC) 4.4.6 20120305 (Red Hat 4.4.6-4); Copyright (C) 2010 Free Software Foundation, Inc.; This is free software; see the source for copying conditions. There is NO; warranty; not even for MER",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:4626,config,configure,4626,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,2,['config'],['configure']
Modifiability,"-o conftest -g -O2 conftest.c >&5; configure:5041: $? = 0; configure:5041: ./conftest; configure:5041: $? = 0; configure:5055: result: 4; configure:5069: checking size of long int; configure:5074: gcc -o conftest -g -O2 conftest.c >&5; configure:5074: $? = 0; configure:5074: ./conftest; configure:5074: $? = 0; configure:5088: result: 8; configure:5102: checking size of float; configure:5107: gcc -o conftest -g -O2 conftest.c >&5; configure:5107: $? = 0; configure:5107: ./conftest; configure:5107: $? = 0; configure:5121: result: 4; configure:5135: checking size of double; configure:5140: gcc -o conftest -g -O2 conftest.c >&5; configure:5140: $? = 0; configure:5140: ./conftest; configure:5140: $? = 0; configure:5154: result: 8; configure:5168: checking size of void *; configure:5173: gcc -o conftest -g -O2 conftest.c >&5; configure:5173: $? = 0; configure:5173: ./conftest; configure:5173: $? = 0; configure:5187: result: 8; configure:5409: checking X11/Intrinsic.h usability; configure:5409: gcc -c -g -O2 conftest.c >&5; conftest.c:61:27: error: X11/Intrinsic.h: No such file or directory; configure:5409: $? = 1; configure: failed program was:; | /* confdefs.h */; | #define PACKAGE_NAME ""SU2""; | #define PACKAGE_TARNAME ""SU2""; | #define PACKAGE_VERSION ""4.1.0""; | #define PACKAGE_STRING ""SU2 4.1.0""; | #define PACKAGE_BUGREPORT ""su2code-dev@lists.stanford.edu""; | #define PACKAGE_URL ""https://github.com/su2code""; | #define PACKAGE ""SU2""; | #define VERSION ""4.1.0""; | #define STDC_HEADERS 1; | #define HAVE_SYS_TYPES_H 1; | #define HAVE_SYS_STAT_H 1; | #define HAVE_STDLIB_H 1; | #define HAVE_STRING_H 1; | #define HAVE_MEMORY_H 1; | #define HAVE_STRINGS_H 1; | #define HAVE_INTTYPES_H 1; | #define HAVE_STDINT_H 1; | #define HAVE_UNISTD_H 1; | #define SIZEOF_SHORT_INT 2; | #define SIZEOF_INT 4; | #define SIZEOF_UNSIGNED_INT 4; | #define SIZEOF_LONG_INT 8; | #define SIZEOF_FLOAT 4; | #define SIZEOF_DOUBLE 8; | #define SIZEOF_VOID_P 8; | /* end confdefs.h. */; | #include <stdio.h>; ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:12373,config,configure,12373,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,1,['config'],['configure']
Modifiability,".2.8.3; - Updated CGNS in parallel.; - Added the ability to writting 2 files at each checkpoint when using 2nd order dual time stepping; - Merge branch 'develop' into feature_dualoutput; - Updated FieldView; - Preliminary implementation (ASCII); - Minor changes; - Update code; - Updated FieldView format; - Merge branch 'develop' into feature_dualoutput; - Bug fixing; - Updated FieldView ASCII format; - Complete implementation of the FFD_CONTINUITY capability; - Updated FFD intersections; - ver 3.2.9; - adding targetea file to equivalent area adjoint folder. address issue #160; - Merge branch 'develop' of github.com:su2code/SU2 into develop; - Final push to v3.2.9; - after bootstrap; - updates to comments in config_structure to make doxygen pretty; - Bug fixing; - Merge branch 'develop'; - EA in ft^2; - further update to config; - Merge remote-tracking branch 'upstream/develop' into upstream_dev; - Minor changes; - Updated NF BC; - More adjustments; - Small update; - Final update Nearfield BC; - added massflowrate as option for cauchy criteria, more config file comments; - Merge remote-tracking branch 'upstream/develop' into upstream_dev; - paraview output modified/added back in for current version for SU2_DEF; - Merge branch 'develop' into feature_dualoutput; - Removed deprecated options from quicstart config.; - Working version of the compressible actuator disk; - Updated fixed CL mode.; - Very minor change; - Merge branch 'develop' into feature_dualoutput; - Final push to 3.2.9; - Merge branch 'develop'; - Minor change; - Minor change; - Small change; - Minor change; - Bug fixing: unsigned short val_vertex --> unsigned long val_vertex; - CFL adapt now works for adjoint problems; - Merge branch 'develop' into feature_dualoutput; - Fixing a typo; - Fix in the Euler BC for grid movement cases; - merging and fixing conflicts bwtn feature_dealloc and develop; - dealloc; - Time spectral fix.; - Merging some recent bug fixes from master into the develop branch to keep nsy",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:9016,config,config,9016,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,3,['config'],['config']
Modifiability,.c (443) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.sdf (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.sln (26) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.suo (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcproj (511) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcxproj (307) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcxproj.filters (78) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcxproj.user (3) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/UpgradeLog.XML (47) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport.css (207) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport.xslt (232) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport_Minus.gif (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport_Plus.gif (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/module.mk (240) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/modulelocal-sample.mk (84) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtCaepInitItems.h (142) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtCaepInstanceData.h (135) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtCaepSupportData.h (83) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtPwpInitItems.h (68) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtPwpPluginInfo.h (75) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtPwpVersions.h (64) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/runtimeWrite.c (439) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/runtimeWrite_orig.txt (60) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcproj (511) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:15949,plugin,plugins,15949,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['plugin'],['plugins']
Modifiability,".c:28:27: error: X11/Intrinsic.h: No such file or directory; configure:5409: $? = 1; configure: failed program was:; | /* confdefs.h */; | #define PACKAGE_NAME ""SU2""; | #define PACKAGE_TARNAME ""SU2""; | #define PACKAGE_VERSION ""4.1.0""; | #define PACKAGE_STRING ""SU2 4.1.0""; | #define PACKAGE_BUGREPORT ""su2code-dev@lists.stanford.edu""; | #define PACKAGE_URL ""https://github.com/su2code""; | #define PACKAGE ""SU2""; | #define VERSION ""4.1.0""; | #define STDC_HEADERS 1; | #define HAVE_SYS_TYPES_H 1; | #define HAVE_SYS_STAT_H 1; | #define HAVE_STDLIB_H 1; | #define HAVE_STRING_H 1; | #define HAVE_MEMORY_H 1; | #define HAVE_STRINGS_H 1; | #define HAVE_INTTYPES_H 1; | #define HAVE_STDINT_H 1; | #define HAVE_UNISTD_H 1; | #define SIZEOF_SHORT_INT 2; | #define SIZEOF_INT 4; | #define SIZEOF_UNSIGNED_INT 4; | #define SIZEOF_LONG_INT 8; | #define SIZEOF_FLOAT 4; | #define SIZEOF_DOUBLE 8; | #define SIZEOF_VOID_P 8; | /* end confdefs.h. */; | #include <X11/Intrinsic.h>; configure:5409: result: no; configure:5409: checking for X11/Intrinsic.h; configure:5409: result: no; configure:5721: checking for /gshare/soft/code_saturne/4.0.0/prod/cgnslib_3.2.1/lib/libcgns.a; configure:5735: result: yes; configure:5755: checking for /gshare/soft/code_saturne/4.0.0/prod/cgnslib_3.2.1/include/cgnslib.h; configure:5769: result: yes; configure:6815: checking that generated files are newer than configure; configure:6821: result: done; configure:6952: creating ./config.status. ## ---------------------- ##; ## Running config.status. ##; ## ---------------------- ##. This file was extended by SU2 config.status 4.1.0, which was; generated by GNU Autoconf 2.69. Invocation command line was. CONFIG_FILES = ; CONFIG_HEADERS = ; CONFIG_LINKS = ; CONFIG_COMMANDS = ; $ ./config.status . on master. config.status:875: creating externals/tecio/Makefile; config.status:875: creating externals/metis/Makefile; config.status:875: creating externals/parmetis/Makefile; config.status:875: creating Makefile; config.status:87",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:15167,config,configure,15167,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,2,['config'],['configure']
Modifiability,.h (89) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtPwpInitItems.h (68) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtPwpPluginInfo.h (75) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtPwpVersions.h (62) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/runtimeWrite.c (443) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.sdf (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.sln (26) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.suo (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcproj (511) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcxproj (307) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcxproj.filters (78) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcxproj.user (3) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/UpgradeLog.XML (47) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport.css (207) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport.xslt (232) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport_Minus.gif (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport_Plus.gif (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/module.mk (240) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/modulelocal-sample.mk (84) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtCaepInitItems.h (142) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtCaepInstanceData.h (135) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtCaepSupportData.h (83) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtPwpInitItems.h (68) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtPwpPluginInfo.h (75) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtPwpV,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:15638,plugin,plugins,15638,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['plugin'],['plugins']
Modifiability,".py script. The command used was:. ```; python3 $SU2_RUN/mesh_adaptation_amg.py -f adapt_Mesh.cfg -n 4; ```; The script initiates the mesh adaptation process as expected, with the following output:. ```; SU2-AMG Anisotropic Mesh Adaptation. Mesh adaptation options:; PYADAP_COMPLEXITY : (30000, 60000, 120000); PYADAP_SUBITE : (2, 2, 2); PYADAP_SENSOR : GOAL; PYADAP_HMAX : 500.0; PYADAP_HMIN : 1e-9; PYADAP_HGRAD : 1.8. ./adap exists. Removing old mesh adaptation in 10s.; The ./adap folder was deleted. Generating GMF background surface mesh.; Initial CFD solution is provided.; ```; However, no _adap\ite0_ folder gets created. ; The log.err file in the _adap/ini_ directory provides this traceback:. ```; Traceback (most recent call last):; File "".../mesh_adaptation_amg.py"", line 111, in <module>; ...; RuntimeError: ...; Error in TokenizeString(): two or more options before an ""="" sign in the configuration file.; terminate called after throwing an instance of 'int'; ...; *** Process received signal ***; Signal: Aborted (6); Signal code: (-6); ...; ```. The critical part of this error seems to be the Error in TokenizeString() message, suggesting an issue with parsing the configuration file. This error typically indicates a syntax problem, such as having multiple options on a single line without proper separation by an equal sign (=). However, upon reviewing _adap/ini/config_CFD.cfg_, was unable to find any lines that clearly violated this syntax rule. Could this error be indicative of a more subtle issue within the configuration file, or might it be related to specific aspects of the feature_adap branch? Any insights, suggestions, or guidance on how to troubleshoot this error would be greatly appreciated. If anyone has a working adapt_mesh.cfg file for a similar setup or for the feature_adap branch, I would be very interested in seeing it. Understanding the configuration details of a working example could be highly beneficial in resolving my issue. Thank you for your help!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/948#issuecomment-1847333809:1520,config,configuration,1520,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-1847333809,3,['config'],['configuration']
Modifiability,"/21182966/28308831-b937bf76-6ba7-11e7-9108-e8a2ab959b74.png). Then I noticed a difference in SENS_GEO (which is the second term of the upper equation, right?) between compressible and incompressible. . ![image](https://user-images.githubusercontent.com/21182966/28310143-bb28c42a-6bab-11e7-8c14-8409b6b12027.png). So if the scale is adjusting current step size the step of dC and SENS_GEO represents the second term, then the SENS_GEO would change when the scale is changed. But this is not the case for incompressible and compressible. . In short, the only noticeable change, due to scaling, occurs in deformation folder of DSN_002. But this is after the optimization step, which is really confusing. Scaling adjusts the current step size and because it can not find a sufficient decrease it is halving the dv_value. But then one should expect different values in the adjoint folder for different scale factors, right?. I hope you can use this information and can tell me whether it is a correct behavior of the optimizer. I should also note that I did not make use of constraints, just as in the test case. I read that the optimizer will switch from optimization procedure. I think this should not matter because of the test case. . I attached also the configure files (compressible (working, scale= 0.01) and incompressible (not working, scale =0.01)) and the mesh file, which is in both cases the same file. [compressible_cfg.txt](https://github.com/su2code/SU2/files/1155421/compressible_cfg.txt); [incompressible_cfg.txt](https://github.com/su2code/SU2/files/1155427/incompressible_cfg.txt); [mesh_300_su2.txt](https://github.com/su2code/SU2/files/1155430/mesh_300_su2.txt). I hope I provide enough information so that one can clarify the behavior of the optimizer. I also appreciate if one can tell me which variables have to be kept in mind. I really want to learn from this and if more information is needed, I really do not mind to provide it. Many thanks in advance!. Floris van der Schuur",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/409#issuecomment-316018103:3795,config,configure,3795,https://su2code.github.io,https://github.com/su2code/SU2/issues/409#issuecomment-316018103,2,"['config', 'variab']","['configure', 'variables']"
Modifiability,/PointwiseSU2plugin/src/plugins/CaeStrXML/rtPwpPluginInfo.h (75) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtPwpVersions.h (62) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/runtimeWrite.c (443) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.sdf (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.sln (26) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.suo (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcproj (511) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcxproj (307) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcxproj.filters (78) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcxproj.user (3) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/UpgradeLog.XML (47) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport.css (207) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport.xslt (232) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport_Minus.gif (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport_Plus.gif (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/module.mk (240) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/modulelocal-sample.mk (84) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtCaepInitItems.h (142) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtCaepInstanceData.h (135) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtCaepSupportData.h (83) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtPwpInitItems.h (68) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtPwpPluginInfo.h (75) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtPwpVersions.h (64) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/runtimeWrite.c (439) ; - D Me,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:15740,plugin,plugins,15740,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['plugin'],['plugins']
Modifiability,/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcproj (511) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcxproj (307) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcxproj.filters (78) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcxproj.user (3) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/UpgradeLog.XML (47) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport.css (207) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport.xslt (232) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport_Minus.gif (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport_Plus.gif (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/module.mk (240) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/modulelocal-sample.mk (84) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtCaepInitItems.h (142) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtCaepInstanceData.h (135) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtCaepSupportData.h (83) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtPwpInitItems.h (68) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtPwpPluginInfo.h (75) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtPwpVersions.h (64) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/runtimeWrite.c (439) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/runtimeWrite_orig.txt (60) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcproj (511) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcproj.PWI.dgarlisch.user (121) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcxproj (307) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcxproj.filters (78) ; - D MeshTools/PointwiseSU2plugin/src/,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:16211,plugin,plugins,16211,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['plugin'],['plugins']
Modifiability,/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport_Plus.gif (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/module.mk (240) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/modulelocal-sample.mk (84) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtCaepInitItems.h (142) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtCaepInstanceData.h (135) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtCaepSupportData.h (83) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtPwpInitItems.h (68) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtPwpPluginInfo.h (75) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtPwpVersions.h (64) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/runtimeWrite.c (439) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/runtimeWrite_orig.txt (60) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcproj (511) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcproj.PWI.dgarlisch.user (121) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcxproj (307) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcxproj.filters (78) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcxproj.user (3) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/module.mk (239) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/modulelocal-sample.mk (84) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtCaepInitItems.h (98) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtCaepInstanceData.h (135) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtCaepSupportData.h (89) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtPwpInitItems.h (68) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtPwpPluginInfo.h (75) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtPwpVersions.h (62) ; - D MeshTools/PointwiseSU2plugin/,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:16937,plugin,plugins,16937,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['plugin'],['plugins']
Modifiability,"03: checking size of int; configure:5008: gcc -o conftest -g -O2 conftest.c >&5; configure:5008: $? = 0; configure:5008: ./conftest; configure:5008: $? = 0; configure:5022: result: 4; configure:5036: checking size of unsigned int; configure:5041: gcc -o conftest -g -O2 conftest.c >&5; configure:5041: $? = 0; configure:5041: ./conftest; configure:5041: $? = 0; configure:5055: result: 4; configure:5069: checking size of long int; configure:5074: gcc -o conftest -g -O2 conftest.c >&5; configure:5074: $? = 0; configure:5074: ./conftest; configure:5074: $? = 0; configure:5088: result: 8; configure:5102: checking size of float; configure:5107: gcc -o conftest -g -O2 conftest.c >&5; configure:5107: $? = 0; configure:5107: ./conftest; configure:5107: $? = 0; configure:5121: result: 4; configure:5135: checking size of double; configure:5140: gcc -o conftest -g -O2 conftest.c >&5; configure:5140: $? = 0; configure:5140: ./conftest; configure:5140: $? = 0; configure:5154: result: 8; configure:5168: checking size of void *; configure:5173: gcc -o conftest -g -O2 conftest.c >&5; configure:5173: $? = 0; configure:5173: ./conftest; configure:5173: $? = 0; configure:5187: result: 8; configure:5409: checking X11/Intrinsic.h usability; configure:5409: gcc -c -g -O2 conftest.c >&5; conftest.c:61:27: error: X11/Intrinsic.h: No such file or directory; configure:5409: $? = 1; configure: failed program was:; | /* confdefs.h */; | #define PACKAGE_NAME ""SU2""; | #define PACKAGE_TARNAME ""SU2""; | #define PACKAGE_VERSION ""4.1.0""; | #define PACKAGE_STRING ""SU2 4.1.0""; | #define PACKAGE_BUGREPORT ""su2code-dev@lists.stanford.edu""; | #define PACKAGE_URL ""https://github.com/su2code""; | #define PACKAGE ""SU2""; | #define VERSION ""4.1.0""; | #define STDC_HEADERS 1; | #define HAVE_SYS_TYPES_H 1; | #define HAVE_SYS_STAT_H 1; | #define HAVE_STDLIB_H 1; | #define HAVE_STRING_H 1; | #define HAVE_MEMORY_H 1; | #define HAVE_STRINGS_H 1; | #define HAVE_INTTYPES_H 1; | #define HAVE_STDINT_H 1; | #define HAVE_UNIST",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:12071,config,configure,12071,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,4,['config'],['configure']
Modifiability,"055: result: 4; configure:5069: checking size of long int; configure:5074: gcc -o conftest -g -O2 conftest.c >&5; configure:5074: $? = 0; configure:5074: ./conftest; configure:5074: $? = 0; configure:5088: result: 8; configure:5102: checking size of float; configure:5107: gcc -o conftest -g -O2 conftest.c >&5; configure:5107: $? = 0; configure:5107: ./conftest; configure:5107: $? = 0; configure:5121: result: 4; configure:5135: checking size of double; configure:5140: gcc -o conftest -g -O2 conftest.c >&5; configure:5140: $? = 0; configure:5140: ./conftest; configure:5140: $? = 0; configure:5154: result: 8; configure:5168: checking size of void *; configure:5173: gcc -o conftest -g -O2 conftest.c >&5; configure:5173: $? = 0; configure:5173: ./conftest; configure:5173: $? = 0; configure:5187: result: 8; configure:5409: checking X11/Intrinsic.h usability; configure:5409: gcc -c -g -O2 conftest.c >&5; conftest.c:61:27: error: X11/Intrinsic.h: No such file or directory; configure:5409: $? = 1; configure: failed program was:; | /* confdefs.h */; | #define PACKAGE_NAME ""SU2""; | #define PACKAGE_TARNAME ""SU2""; | #define PACKAGE_VERSION ""4.1.0""; | #define PACKAGE_STRING ""SU2 4.1.0""; | #define PACKAGE_BUGREPORT ""su2code-dev@lists.stanford.edu""; | #define PACKAGE_URL ""https://github.com/su2code""; | #define PACKAGE ""SU2""; | #define VERSION ""4.1.0""; | #define STDC_HEADERS 1; | #define HAVE_SYS_TYPES_H 1; | #define HAVE_SYS_STAT_H 1; | #define HAVE_STDLIB_H 1; | #define HAVE_STRING_H 1; | #define HAVE_MEMORY_H 1; | #define HAVE_STRINGS_H 1; | #define HAVE_INTTYPES_H 1; | #define HAVE_STDINT_H 1; | #define HAVE_UNISTD_H 1; | #define SIZEOF_SHORT_INT 2; | #define SIZEOF_INT 4; | #define SIZEOF_UNSIGNED_INT 4; | #define SIZEOF_LONG_INT 8; | #define SIZEOF_FLOAT 4; | #define SIZEOF_DOUBLE 8; | #define SIZEOF_VOID_P 8; | /* end confdefs.h. */; | #include <stdio.h>; | #ifdef HAVE_SYS_TYPES_H; | # include <sys/types.h>; | #endif; | #ifdef HAVE_SYS_STAT_H; | # include <sys/stat.h>; | #end",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:12488,config,configure,12488,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,2,['config'],['configure']
Modifiability,"181: gcc -c -g -O2 conftest.c >&5; configure:4181: $? = 0; configure:4194: result: none needed; configure:4216: checking dependency style of gcc; configure:4327: result: gcc3; configure:4345: checking whether gcc and cc understand -c and -o together; configure:4376: gcc -c conftest.c -o conftest2.o >&5; configure:4380: $? = 0; configure:4386: gcc -c conftest.c -o conftest2.o >&5; configure:4390: $? = 0; configure:4401: cc -c conftest.c >&5; configure:4405: $? = 0; configure:4413: cc -c conftest.c -o conftest2.o >&5; configure:4417: $? = 0; configure:4423: cc -c conftest.c -o conftest2.o >&5; configure:4427: $? = 0; configure:4445: result: yes; configure:4513: checking for ranlib; configure:4529: found /usr/bin/ranlib; configure:4540: result: ranlib; configure:4574: checking how to run the C preprocessor; configure:4605: gcc -E conftest.c; configure:4605: $? = 0; configure:4619: gcc -E conftest.c; conftest.c:11:28: error: ac_nonexistent.h: No such file or directory; configure:4619: $? = 1; configure: failed program was:; | /* confdefs.h */; | #define PACKAGE_NAME ""SU2""; | #define PACKAGE_TARNAME ""SU2""; | #define PACKAGE_VERSION ""4.1.0""; | #define PACKAGE_STRING ""SU2 4.1.0""; | #define PACKAGE_BUGREPORT ""su2code-dev@lists.stanford.edu""; | #define PACKAGE_URL ""https://github.com/su2code""; | #define PACKAGE ""SU2""; | #define VERSION ""4.1.0""; | /* end confdefs.h. */; | #include <ac_nonexistent.h>; configure:4644: result: gcc -E; configure:4664: gcc -E conftest.c; configure:4664: $? = 0; configure:4678: gcc -E conftest.c; conftest.c:11:28: error: ac_nonexistent.h: No such file or directory; configure:4678: $? = 1; configure: failed program was:; | /* confdefs.h */; | #define PACKAGE_NAME ""SU2""; | #define PACKAGE_TARNAME ""SU2""; | #define PACKAGE_VERSION ""4.1.0""; | #define PACKAGE_STRING ""SU2 4.1.0""; | #define PACKAGE_BUGREPORT ""su2code-dev@lists.stanford.edu""; | #define PACKAGE_URL ""https://github.com/su2code""; | #define PACKAGE ""SU2""; | #define VERSION ""4.1.0""; | /* end con",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:8152,config,configure,8152,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,2,['config'],['configure']
Modifiability,"1; configure: failed program was:; | /* confdefs.h */; | #define PACKAGE_NAME ""SU2""; | #define PACKAGE_TARNAME ""SU2""; | #define PACKAGE_VERSION ""4.1.0""; | #define PACKAGE_STRING ""SU2 4.1.0""; | #define PACKAGE_BUGREPORT ""su2code-dev@lists.stanford.edu""; | #define PACKAGE_URL ""https://github.com/su2code""; | #define PACKAGE ""SU2""; | #define VERSION ""4.1.0""; | #define STDC_HEADERS 1; | #define HAVE_SYS_TYPES_H 1; | #define HAVE_SYS_STAT_H 1; | #define HAVE_STDLIB_H 1; | #define HAVE_STRING_H 1; | #define HAVE_MEMORY_H 1; | #define HAVE_STRINGS_H 1; | #define HAVE_INTTYPES_H 1; | #define HAVE_STDINT_H 1; | #define HAVE_UNISTD_H 1; | #define SIZEOF_SHORT_INT 2; | #define SIZEOF_INT 4; | #define SIZEOF_UNSIGNED_INT 4; | #define SIZEOF_LONG_INT 8; | #define SIZEOF_FLOAT 4; | #define SIZEOF_DOUBLE 8; | #define SIZEOF_VOID_P 8; | /* end confdefs.h. */; | #include <X11/Intrinsic.h>; configure:5409: result: no; configure:5409: checking for X11/Intrinsic.h; configure:5409: result: no; configure:5721: checking for /gshare/soft/code_saturne/4.0.0/prod/cgnslib_3.2.1/lib/libcgns.a; configure:5735: result: yes; configure:5755: checking for /gshare/soft/code_saturne/4.0.0/prod/cgnslib_3.2.1/include/cgnslib.h; configure:5769: result: yes; configure:6815: checking that generated files are newer than configure; configure:6821: result: done; configure:6952: creating ./config.status. ## ---------------------- ##; ## Running config.status. ##; ## ---------------------- ##. This file was extended by SU2 config.status 4.1.0, which was; generated by GNU Autoconf 2.69. Invocation command line was. CONFIG_FILES = ; CONFIG_HEADERS = ; CONFIG_LINKS = ; CONFIG_COMMANDS = ; $ ./config.status . on master. config.status:875: creating externals/tecio/Makefile; config.status:875: creating externals/metis/Makefile; config.status:875: creating externals/parmetis/Makefile; config.status:875: creating Makefile; config.status:875: creating externals/Makefile; config.status:875: creating Common/lib/Makefile; ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:15241,config,configure,15241,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,2,['config'],['configure']
Modifiability,"2' --with-bugurl=https://bugs.archlinux.org/ --enable-languages=c,c++,ada,fortran,go,lto,objc,obj-c++,d --enable-shared --enable-threads=posix --with-system-zlib --with-isl --enable-__cxa_atexit --disable-libunwind-exceptions --enable-clocale=gnu --disable-libstdcxx-pch --disable-libssp --enable-gnu-unique-object --enable-linker-build-id --enable-lto --enable-plugin --enable-install-libiberty --with-linker-hash-style=gnu --enable-gnu-indirect-function --enable-multilib --disable-werror --enable-checking=release --enable-default-pie --enable-default-ssp --enable-cet=auto gdc_include_dir=/usr/include/dlang/gdc; Thread model: posix; gcc version 9.2.1 20200130 (Arch Linux 9.2.1+20200130-2) ; ```; I did what you suggested and here is how my meson.build file looks.; ```; # If custom mpi mode is enabled, include and library pathes for MPI have to be set manually to env variables; if get_option('custom-mpi'); mpi_dep = []; mpi = true; # Otherwise they are automatically determined; else; mpi_dep = [dependency('mpich', required : get_option('with-mpi'))]; # mpi_dep = [dependency('mpi', language:'c', required : get_option('with-mpi')),; # dependency('mpi', language:'cpp', required : get_option('with-mpi'))]; #if mpi_dep[0].found() or mpi_dep[1].found(); # mpi = true; #endif; endif; ```; My SU2 build was successful but there were a couple of warnings.; Also, instead of 870 there were only 772 files in total. Is that okay?; ```; slimshady@arch-linux-hp-probook-g3-450: SU2HOME$ ./ninja -C build install; ninja: Entering directory `build'; [756/772] Generating 'SU2_PY/pySU2/_pysu2.so.p/pySU2.cxx'.; ../SU2_PY/pySU2/../../Common/include/mpi_structure.hpp:348: Warning 325: Nested struct not currently supported (Status ignored); [760/772] Generating 'SU2_PY/pySU2/_pysu2ad.so.p/pySU2ad.cxx'.; ../SU2_PY/pySU2/../../Common/include/mpi_structure.hpp:348: Warning 325: Nested struct not currently supported (Status ignored); [771/772] Installing files.; .; .; ```; Here is the [entire output fo",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1000#issuecomment-633139474:1426,variab,variables,1426,https://su2code.github.io,https://github.com/su2code/SU2/issues/1000#issuecomment-633139474,1,['variab'],['variables']
Modifiability,"2357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; 14368 Vertex ; 3 Boundary Vertices ; 58189 Tetrahedra ; 1 Triangles ; 0 Edges ; 1 Surface(s) ; % Output subdom.meshb Mesh ndimn=3, mpoin=14368, melem=58189, mface=1; Corners 0 Required 0 ; ## ERROR : TETRAHEDRON 2 BOUNDARY FACE 1 2; 9 IS MISSING ; ## ERROR : TETRAHEDRON 4 BOUNDARY FACE 3 7; 2324 IS MISSING ; ···; ## ERROR: FEFLO.A: 16740 BOUNDARY FACES ARE MISSING ; CHECK YOUR MESH . ## FATAL ERROR: FEFLOA: INITIAL OR CURRENT MESH HAS AN INCONSISTANT TOPOLOGY . Thank you for using feflo.a . ```; Which in turn creates an invalid `amg.su2` mesh in the `adap/ite0 folder`, which triggers the fault.; I'm a bit puzzled as the domain is very simple, and the `log.out` is going well (with no complains of SU2 about any negative volume or trias with wrong normals). The mesh is only made of TRIAS and TETRAS, it should work in principle.; Am I missing something in the setup / mesh? I know you have little control on the `amg.out`, but maybe there some special hint that I'm missing. . Btw the final error in the terminal is but I think the problem arises before reaching `flo.csv` file:; ```; Traceback (most recent call last):; File ""/usr/local/bin/mesh_adaptation_amg.py"", line 111, in <module>; main(); File ""/usr/local/bin/mesh_adaptation_amg.py"", line 72, in main; options.save_all ); File ""/usr/local/bin/mesh_adaptation_amg.py"", line 101, in mesh_adaptation_amg; SU2.run.amg(config); File ""/usr/local/bin/SU2/run/amg.py"", line 464, in amg; os.rename(cur_solfil, cur_solfil_ini); FileNotFoundError: [Errno 2] No such file or directory: 'flo.csv' -> 'flo_ini.csv'. ```; Thanks!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/948#issuecomment-623572280:2939,config,config,2939,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-623572280,1,['config'],['config']
Modifiability,"3999: $? = 0; configure:3988: gcc -V >&5; gcc: '-V' option must have argument; configure:3999: $? = 1; configure:3988: gcc -qversion >&5; gcc: unrecognized option '-qversion'; gcc: no input files; configure:3999: $? = 1; configure:4003: checking whether we are using the GNU C compiler; configure:4022: gcc -c conftest.c >&5; configure:4022: $? = 0; configure:4031: result: yes; configure:4040: checking whether gcc accepts -g; configure:4060: gcc -c -g conftest.c >&5; configure:4060: $? = 0; configure:4101: result: yes; configure:4118: checking for gcc option to accept ISO C89; configure:4181: gcc -c -g -O2 conftest.c >&5; configure:4181: $? = 0; configure:4194: result: none needed; configure:4216: checking dependency style of gcc; configure:4327: result: gcc3; configure:4345: checking whether gcc and cc understand -c and -o together; configure:4376: gcc -c conftest.c -o conftest2.o >&5; configure:4380: $? = 0; configure:4386: gcc -c conftest.c -o conftest2.o >&5; configure:4390: $? = 0; configure:4401: cc -c conftest.c >&5; configure:4405: $? = 0; configure:4413: cc -c conftest.c -o conftest2.o >&5; configure:4417: $? = 0; configure:4423: cc -c conftest.c -o conftest2.o >&5; configure:4427: $? = 0; configure:4445: result: yes; configure:4513: checking for ranlib; configure:4529: found /usr/bin/ranlib; configure:4540: result: ranlib; configure:4574: checking how to run the C preprocessor; configure:4605: gcc -E conftest.c; configure:4605: $? = 0; configure:4619: gcc -E conftest.c; conftest.c:11:28: error: ac_nonexistent.h: No such file or directory; configure:4619: $? = 1; configure: failed program was:; | /* confdefs.h */; | #define PACKAGE_NAME ""SU2""; | #define PACKAGE_TARNAME ""SU2""; | #define PACKAGE_VERSION ""4.1.0""; | #define PACKAGE_STRING ""SU2 4.1.0""; | #define PACKAGE_BUGREPORT ""su2code-dev@lists.stanford.edu""; | #define PACKAGE_URL ""https://github.com/su2code""; | #define PACKAGE ""SU2""; | #define VERSION ""4.1.0""; | /* end confdefs.h. */; | #include <ac_nonexiste",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:7555,config,configure,7555,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,2,['config'],['configure']
Modifiability,422) ; - D MeshTools/PointwiseSU2plugin/src/Pointwise/Win32Target.props (28) ; - D MeshTools/PointwiseSU2plugin/src/Pointwise/Win32Target.vsprops (24) ; - D MeshTools/PointwiseSU2plugin/src/Pointwise/Win64Target.props (28) ; - D MeshTools/PointwiseSU2plugin/src/Pointwise/Win64Target.vsprops (24) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/CaeStrXML.vcproj (511) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/CaeStrXML.vcproj.PWI.dgarlisch.user (121) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/CaeStrXML.vcxproj (307) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/CaeStrXML.vcxproj.filters (78) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/CaeStrXML.vcxproj.user (3) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/module.mk (239) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/modulelocal-sample.mk (84) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtCaepInitItems.h (98) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtCaepInstanceData.h (135) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtCaepSupportData.h (89) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtPwpInitItems.h (68) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtPwpPluginInfo.h (75) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtPwpVersions.h (62) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/runtimeWrite.c (443) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.sdf (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.sln (26) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.suo (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcproj (511) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcxproj (307) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcxproj.filters (78) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcxproj.user,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:14521,plugin,plugins,14521,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['plugin'],['plugins']
Modifiability,5) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/runtimeWrite.h (57) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWGM/apiGridModel.c (492) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWGM/apiGridModel.h (1808) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWP.c (132) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWP.h (707) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWPUtils.c (789) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWPUtils.h (1030) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiUtils.h (174) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/pwpPlatform.c (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/pwpPlatform.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/site.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/structured.props (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/structured.vsprops (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/CaeTemplate.suo (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/CaeTemplate.vcproj (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/module.mk (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/modulelocal-sample.mk (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/rtCaepInitItems.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/rtCaepInstanceData.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/rtCaepSupportData.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/runtimeWrite.c (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/PWP/rtPwpInitItems.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/PWP/rtPwpPluginInfo.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/PWP/rtPwpVersions.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/unstructured.props (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:19545,plugin,plugins,19545,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['plugin'],['plugins']
Modifiability,54: $? = 0; configure:4954: result: yes; configure:4954: checking for sys/stat.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for stdlib.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for string.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for memory.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for strings.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for inttypes.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for stdint.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for unistd.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4970: checking size of short int; configure:4975: gcc -o conftest -g -O2 conftest.c >&5; configure:4975: $? = 0; configure:4975: ./conftest; configure:4975: $? = 0; configure:4989: result: 2; configure:5003: checking size of int; configure:5008: gcc -o conftest -g -O2 conftest.c >&5; configure:5008: $? = 0; configure:5008: ./conftest; configure:5008: $? = 0; configure:5022: result: 4; configure:5036: checking size of unsigned int; configure:5041: gcc -o conftest -g -O2 conftest.c >&5; configure:5041: $? = 0; configure:5041: ./conftest; configure:5041: $? = 0; configure:5055: result: 4; configure:5069: checking size of long int; configure:5074: gcc -o conftest -g -O2 conftest.c >&5; configure:5074: $? = 0; configure:5074: ./conftest; configure:5074: $? = 0; configure:5088: result: 8; configure:5102: checking size of float; config,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:10730,config,configure,10730,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,3,['config'],['configure']
Modifiability,75) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtPwpVersions.h (62) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/runtimeWrite.c (347) ; - D MeshTools/PointwiseSU2plugin/src/plugins/README.txt (272) ; - D MeshTools/PointwiseSU2plugin/src/plugins/module.mk (309) ; - D MeshTools/PointwiseSU2plugin/src/plugins/modulelocal.mk (8) ; - D MeshTools/PointwiseSU2plugin/src/plugins/pluginRegistry.h (29) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEP.c (228) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEP.h (550) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEPUtils.c (290) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEPUtils.h (725) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/runtimeWrite.h (57) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWGM/apiGridModel.c (492) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWGM/apiGridModel.h (1808) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWP.c (132) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWP.h (707) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWPUtils.c (789) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWPUtils.h (1030) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiUtils.h (174) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/pwpPlatform.c (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/pwpPlatform.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/site.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/structured.props (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/structured.vsprops (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/CaeTemplate.suo (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/CaeTemplate.vcproj (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/module.mk (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CA,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:18819,plugin,plugins,18819,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['plugin'],['plugins']
Modifiability,"988: gcc -v >&5; Using built-in specs.; Target: x86_64-redhat-linux; Configured with: ../configure --prefix=/usr --mandir=/usr/share/man --infodir=/usr/share/info --with-bugurl=http://bugzilla.redhat.com/bugzilla --enable-bootstrap --enable-shared --enable-threads=posix --enable-checking=release --with-system-zlib --enable-__cxa_atexit --disable-libunwind-exceptions --enable-gnu-unique-object --enable-languages=c,c++,objc,obj-c++,java,fortran,ada --enable-java-awt=gtk --disable-dssi --with-java-home=/usr/lib/jvm/java-1.5.0-gcj-1.5.0.0/jre --enable-libgcj-multifile --enable-java-maintainer-mode --with-ecj-jar=/usr/share/java/eclipse-ecj.jar --disable-libjava-multilib --with-ppl --with-cloog --with-tune=generic --with-arch_32=i686 --build=x86_64-redhat-linux; Thread model: posix; gcc version 4.4.6 20120305 (Red Hat 4.4.6-4) (GCC) ; configure:3999: $? = 0; configure:3988: gcc -V >&5; gcc: '-V' option must have argument; configure:3999: $? = 1; configure:3988: gcc -qversion >&5; gcc: unrecognized option '-qversion'; gcc: no input files; configure:3999: $? = 1; configure:4003: checking whether we are using the GNU C compiler; configure:4022: gcc -c conftest.c >&5; configure:4022: $? = 0; configure:4031: result: yes; configure:4040: checking whether gcc accepts -g; configure:4060: gcc -c -g conftest.c >&5; configure:4060: $? = 0; configure:4101: result: yes; configure:4118: checking for gcc option to accept ISO C89; configure:4181: gcc -c -g -O2 conftest.c >&5; configure:4181: $? = 0; configure:4194: result: none needed; configure:4216: checking dependency style of gcc; configure:4327: result: gcc3; configure:4345: checking whether gcc and cc understand -c and -o together; configure:4376: gcc -c conftest.c -o conftest2.o >&5; configure:4380: $? = 0; configure:4386: gcc -c conftest.c -o conftest2.o >&5; configure:4390: $? = 0; configure:4401: cc -c conftest.c >&5; configure:4405: $? = 0; configure:4413: cc -c conftest.c -o conftest2.o >&5; configure:4417: $? = 0; configure",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:6569,config,configure,6569,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,7,['config'],['configure']
Modifiability,: result: yes; configure:4954: checking for stdlib.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for string.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for memory.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for strings.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for inttypes.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for stdint.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for unistd.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4970: checking size of short int; configure:4975: gcc -o conftest -g -O2 conftest.c >&5; configure:4975: $? = 0; configure:4975: ./conftest; configure:4975: $? = 0; configure:4989: result: 2; configure:5003: checking size of int; configure:5008: gcc -o conftest -g -O2 conftest.c >&5; configure:5008: $? = 0; configure:5008: ./conftest; configure:5008: $? = 0; configure:5022: result: 4; configure:5036: checking size of unsigned int; configure:5041: gcc -o conftest -g -O2 conftest.c >&5; configure:5041: $? = 0; configure:5041: ./conftest; configure:5041: $? = 0; configure:5055: result: 4; configure:5069: checking size of long int; configure:5074: gcc -o conftest -g -O2 conftest.c >&5; configure:5074: $? = 0; configure:5074: ./conftest; configure:5074: $? = 0; configure:5088: result: 8; configure:5102: checking size of float; configure:5107: gcc -o conftest -g -O2 conftest.c >&5; configure:5107: $? = 0; configure:5107: ./conftest; configure:5107: $? = 0; configure:5121: result: 4; configure:5135,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:10868,config,configure,10868,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,4,['config'],['configure']
Modifiability,": yes; configure:6815: checking that generated files are newer than configure; configure:6821: result: done; configure:6952: creating ./config.status. ## ---------------------- ##; ## Running config.status. ##; ## ---------------------- ##. This file was extended by SU2 config.status 4.1.0, which was; generated by GNU Autoconf 2.69. Invocation command line was. CONFIG_FILES = ; CONFIG_HEADERS = ; CONFIG_LINKS = ; CONFIG_COMMANDS = ; $ ./config.status . on master. config.status:875: creating externals/tecio/Makefile; config.status:875: creating externals/metis/Makefile; config.status:875: creating externals/parmetis/Makefile; config.status:875: creating Makefile; config.status:875: creating externals/Makefile; config.status:875: creating Common/lib/Makefile; config.status:875: creating SU2_CFD/obj/Makefile; config.status:875: creating SU2_DOT/obj/Makefile; config.status:875: creating SU2_MSH/obj/Makefile; config.status:875: creating SU2_DEF/obj/Makefile; config.status:875: creating SU2_SOL/obj/Makefile; config.status:875: creating SU2_GEO/obj/Makefile; config.status:875: creating SU2_PY/Makefile; config.status:1047: executing depfiles commands; configure:8181: result:. -------------------------------------------------------------------------; | ___ _ _ ___ |; | / __| | | |_ ) Release 4.1.0 'Cardinal' |; | \__ \ |_| |/ / |; | |___/\___//___| Suite |; | |; -------------------------------------------------------------------------; | SU2 Lead Dev.: Dr. Francisco Palacios, Francisco.D.Palacios@boeing.com|; | Dr. Thomas D. Economon, economon@stanford.edu |; -------------------------------------------------------------------------; | SU2 Developers: |; | - Prof. Juan J. Alonso's group at Stanford University. |; | - Prof. Piero Colonna's group at Delft University of Technology. |; | - Prof. Nicolas R. Gauger's group at Kaiserslautern U. of Technology. |; | - Prof. Alberto Guardone's group at Polytechnic University of Milan. |; | - Prof. Rafael Palacios' group at Imperial Col",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:16532,config,config,16532,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,1,['config'],['config']
Modifiability,; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/CaeStrXML.vcxproj (307) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/CaeStrXML.vcxproj.filters (78) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/CaeStrXML.vcxproj.user (3) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/module.mk (239) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/modulelocal-sample.mk (84) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtCaepInitItems.h (98) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtCaepInstanceData.h (135) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtCaepSupportData.h (89) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtPwpInitItems.h (68) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtPwpPluginInfo.h (75) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtPwpVersions.h (62) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/runtimeWrite.c (443) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.sdf (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.sln (26) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.suo (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcproj (511) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcxproj (307) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcxproj.filters (78) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcxproj.user (3) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/UpgradeLog.XML (47) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport.css (207) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport.xslt (232) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport_Minus.gif (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/Upgra,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:15002,plugin,plugins,15002,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['plugin'],['plugins']
Modifiability,; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEPUtils.h (725) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/runtimeWrite.h (57) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWGM/apiGridModel.c (492) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWGM/apiGridModel.h (1808) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWP.c (132) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWP.h (707) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWPUtils.c (789) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWPUtils.h (1030) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiUtils.h (174) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/pwpPlatform.c (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/pwpPlatform.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/site.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/structured.props (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/structured.vsprops (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/CaeTemplate.suo (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/CaeTemplate.vcproj (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/module.mk (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/modulelocal-sample.mk (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/rtCaepInitItems.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/rtCaepInstanceData.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/rtCaepSupportData.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/runtimeWrite.c (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/PWP/rtPwpInitItems.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/PWP/rtPwpPluginInfo.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/PWP/rtPwpVersions.h (0) ; - D MeshTools/PointwiseSU2plugin/src/,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:19475,plugin,plugins,19475,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['plugin'],['plugins']
Modifiability,"; configure:2934: found /bin/gawk; configure:2945: result: gawk; configure:2956: checking whether make sets $(MAKE); configure:2978: result: yes; configure:3075: checking whether make supports nested variables; configure:3092: result: yes; configure:3117: checking for style of include used by make; configure:3145: result: GNU; configure:3196: result: >>> MPI support disabled by default <<<; configure:3269: checking for g++; configure:3285: found /usr/bin/g++; configure:3296: result: g++; configure:3323: checking for C++ compiler version; configure:3332: g++ --version >&5; g++ (GCC) 4.4.6 20120305 (Red Hat 4.4.6-4); Copyright (C) 2010 Free Software Foundation, Inc.; This is free software; see the source for copying conditions. There is NO; warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. configure:3343: $? = 0; configure:3332: g++ -v >&5; Using built-in specs.; Target: x86_64-redhat-linux; Configured with: ../configure --prefix=/usr --mandir=/usr/share/man --infodir=/usr/share/info --with-bugurl=http://bugzilla.redhat.com/bugzilla --enable-bootstrap --enable-shared --enable-threads=posix --enable-checking=release --with-system-zlib --enable-__cxa_atexit --disable-libunwind-exceptions --enable-gnu-unique-object --enable-languages=c,c++,objc,obj-c++,java,fortran,ada --enable-java-awt=gtk --disable-dssi --with-java-home=/usr/lib/jvm/java-1.5.0-gcj-1.5.0.0/jre --enable-libgcj-multifile --enable-java-maintainer-mode --with-ecj-jar=/usr/share/java/eclipse-ecj.jar --disable-libjava-multilib --with-ppl --with-cloog --with-tune=generic --with-arch_32=i686 --build=x86_64-redhat-linux; Thread model: posix; gcc version 4.4.6 20120305 (Red Hat 4.4.6-4) (GCC) ; configure:3343: $? = 0; configure:3332: g++ -V >&5; g++: '-V' option must have argument; configure:3343: $? = 1; configure:3332: g++ -qversion >&5; g++: unrecognized option '-qversion'; g++: no input files; configure:3343: $? = 1; configure:3363: checking whether the C++ compiler works; configure:3",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:3136,config,configure,3136,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,1,['config'],['configure']
Modifiability,"; configure:3546: checking for suffix of object files; configure:3568: g++ -c conftest.cpp >&5; configure:3572: $? = 0; configure:3593: result: o; configure:3597: checking whether we are using the GNU C++ compiler; configure:3616: g++ -c conftest.cpp >&5; configure:3616: $? = 0; configure:3625: result: yes; configure:3634: checking whether g++ accepts -g; configure:3654: g++ -c -g conftest.cpp >&5; configure:3654: $? = 0; configure:3695: result: yes; configure:3720: checking dependency style of g++; configure:3831: result: gcc3; configure:3921: checking for gcc; configure:3937: found /usr/bin/gcc; configure:3948: result: gcc; configure:3979: checking for C compiler version; configure:3988: gcc --version >&5; gcc (GCC) 4.4.6 20120305 (Red Hat 4.4.6-4); Copyright (C) 2010 Free Software Foundation, Inc.; This is free software; see the source for copying conditions. There is NO; warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. configure:3999: $? = 0; configure:3988: gcc -v >&5; Using built-in specs.; Target: x86_64-redhat-linux; Configured with: ../configure --prefix=/usr --mandir=/usr/share/man --infodir=/usr/share/info --with-bugurl=http://bugzilla.redhat.com/bugzilla --enable-bootstrap --enable-shared --enable-threads=posix --enable-checking=release --with-system-zlib --enable-__cxa_atexit --disable-libunwind-exceptions --enable-gnu-unique-object --enable-languages=c,c++,objc,obj-c++,java,fortran,ada --enable-java-awt=gtk --disable-dssi --with-java-home=/usr/lib/jvm/java-1.5.0-gcj-1.5.0.0/jre --enable-libgcj-multifile --enable-java-maintainer-mode --with-ecj-jar=/usr/share/java/eclipse-ecj.jar --disable-libjava-multilib --with-ppl --with-cloog --with-tune=generic --with-arch_32=i686 --build=x86_64-redhat-linux; Thread model: posix; gcc version 4.4.6 20120305 (Red Hat 4.4.6-4) (GCC) ; configure:3999: $? = 0; configure:3988: gcc -V >&5; gcc: '-V' option must have argument; configure:3999: $? = 1; configure:3988: gcc -qversion >&5; gcc: unreco",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:5692,config,configure,5692,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,2,['config'],['configure']
Modifiability,; configure:4930: $? = 0; configure:4930: ./conftest; configure:4930: $? = 0; configure:4941: result: yes; configure:4954: checking for sys/types.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for sys/stat.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for stdlib.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for string.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for memory.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for strings.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for inttypes.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for stdint.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for unistd.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4970: checking size of short int; configure:4975: gcc -o conftest -g -O2 conftest.c >&5; configure:4975: $? = 0; configure:4975: ./conftest; configure:4975: $? = 0; configure:4989: result: 2; configure:5003: checking size of int; configure:5008: gcc -o conftest -g -O2 conftest.c >&5; configure:5008: $? = 0; configure:5008: ./conftest; configure:5008: $? = 0; configure:5022: result: 4; configure:5036: checking size of unsigned int; configure:5041: gcc -o conftest -g -O2 conftest.c >&5; configure:5041: $? = 0; configure:5041: ./conftest; configure:5041: $? = 0; configure:5055: result: 4; configure:5069: checking size of long in,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:10546,config,configure,10546,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,1,['config'],['configure']
Modifiability,; configure:4954: result: yes; configure:4954: checking for strings.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for inttypes.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for stdint.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for unistd.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4970: checking size of short int; configure:4975: gcc -o conftest -g -O2 conftest.c >&5; configure:4975: $? = 0; configure:4975: ./conftest; configure:4975: $? = 0; configure:4989: result: 2; configure:5003: checking size of int; configure:5008: gcc -o conftest -g -O2 conftest.c >&5; configure:5008: $? = 0; configure:5008: ./conftest; configure:5008: $? = 0; configure:5022: result: 4; configure:5036: checking size of unsigned int; configure:5041: gcc -o conftest -g -O2 conftest.c >&5; configure:5041: $? = 0; configure:5041: ./conftest; configure:5041: $? = 0; configure:5055: result: 4; configure:5069: checking size of long int; configure:5074: gcc -o conftest -g -O2 conftest.c >&5; configure:5074: $? = 0; configure:5074: ./conftest; configure:5074: $? = 0; configure:5088: result: 8; configure:5102: checking size of float; configure:5107: gcc -o conftest -g -O2 conftest.c >&5; configure:5107: $? = 0; configure:5107: ./conftest; configure:5107: $? = 0; configure:5121: result: 4; configure:5135: checking size of double; configure:5140: gcc -o conftest -g -O2 conftest.c >&5; configure:5140: $? = 0; configure:5140: ./conftest; configure:5140: $? = 0; configure:5154: result: 8; configure:5168: checking size of void *; configure:5173: gcc -o conftest -g -O2 conftest.c >&5; configure:5173: $? = 0; configure:5173: ./conftest; configure:5173: $? = 0; configure:5187: result: 8; configure:5409:,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:11268,config,configure,11268,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,4,['config'],['configure']
Modifiability,"<nVar; ++iVar); {; FltVec phiL = 0.0;; FltVec phiR = 0.0;. for(size_t iDim=0; iDim<nDim; ++iDim); {; phiL += grad.getVec(iPoint,iVar,iDim)*d_ij[iDim];; phiR -= grad.getVec(jPoint,iVar,iDim)*d_ij[iDim];; }. phiL = phi.getVec(iPoint,iVar) + limiter.getVec(iPoint,iVar)*phiL;; phiR = phi.getVec(jPoint,iVar) + limiter.getVec(jPoint,iVar)*phiR;. FltVec flux = (phiL+phiR)*0.5;. for(size_t k=0; k<SIMDLEN; ++k) {; residual(iPoint[k],iVar) += flux[k];; residual(jPoint[k],iVar) -= flux[k];; }; }; ```; Note that at the end of the loop we need to de-swizzle the flux to update the multiple indexes references by iPoint and jPoint, which are now short arrays of integers (this operation can be moved to the container, akin to `getVec` but I show it here for clarity). **With SoA (aka column major storage) this code is 1.5 times slower than the scalar version.**. The reason for that is poor locality (of the spacial variety), as we loop through the number of variables and dimensions we are accessing the data in strides of nPoint, as the contiguous index is the first one so that we can perform vector read/writes when computing gradients and limiters.; With the scalar version the data for each point is contiguous which means on the first access we get whatever extra data is on the same cache line for free and subsequent accesses will be hardware prefetched since the stride is small (1 in this case). We lose all this with SoA storage. If we go back to arrays of structures (AoS, aka row major storage, basically what we have in #753) performance is only 9% worse (the code is identical). Those 9% are mostly due to increased integer arithmetic in the accesses to the data, on each call to `getVec` we resolve 4/8 row/column pairs into 1D indexes, while this calculation is vectorized, it seems to be less optimizable by compilers, for example this; ```c++; for(size_t iDim=0; iDim<nDim; ++iDim); phiL += grad.getVec(iPoint,iVar,iDim)*d_ij[iDim];; ```; gets compiled into this monstrosity; ```asm; .L13",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-535977206:8395,variab,variables,8395,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206,1,['variab'],['variables']
Modifiability,"= 0; configure:5008: ./conftest; configure:5008: $? = 0; configure:5022: result: 4; configure:5036: checking size of unsigned int; configure:5041: gcc -o conftest -g -O2 conftest.c >&5; configure:5041: $? = 0; configure:5041: ./conftest; configure:5041: $? = 0; configure:5055: result: 4; configure:5069: checking size of long int; configure:5074: gcc -o conftest -g -O2 conftest.c >&5; configure:5074: $? = 0; configure:5074: ./conftest; configure:5074: $? = 0; configure:5088: result: 8; configure:5102: checking size of float; configure:5107: gcc -o conftest -g -O2 conftest.c >&5; configure:5107: $? = 0; configure:5107: ./conftest; configure:5107: $? = 0; configure:5121: result: 4; configure:5135: checking size of double; configure:5140: gcc -o conftest -g -O2 conftest.c >&5; configure:5140: $? = 0; configure:5140: ./conftest; configure:5140: $? = 0; configure:5154: result: 8; configure:5168: checking size of void *; configure:5173: gcc -o conftest -g -O2 conftest.c >&5; configure:5173: $? = 0; configure:5173: ./conftest; configure:5173: $? = 0; configure:5187: result: 8; configure:5409: checking X11/Intrinsic.h usability; configure:5409: gcc -c -g -O2 conftest.c >&5; conftest.c:61:27: error: X11/Intrinsic.h: No such file or directory; configure:5409: $? = 1; configure: failed program was:; | /* confdefs.h */; | #define PACKAGE_NAME ""SU2""; | #define PACKAGE_TARNAME ""SU2""; | #define PACKAGE_VERSION ""4.1.0""; | #define PACKAGE_STRING ""SU2 4.1.0""; | #define PACKAGE_BUGREPORT ""su2code-dev@lists.stanford.edu""; | #define PACKAGE_URL ""https://github.com/su2code""; | #define PACKAGE ""SU2""; | #define VERSION ""4.1.0""; | #define STDC_HEADERS 1; | #define HAVE_SYS_TYPES_H 1; | #define HAVE_SYS_STAT_H 1; | #define HAVE_STDLIB_H 1; | #define HAVE_STRING_H 1; | #define HAVE_MEMORY_H 1; | #define HAVE_STRINGS_H 1; | #define HAVE_INTTYPES_H 1; | #define HAVE_STDINT_H 1; | #define HAVE_UNISTD_H 1; | #define SIZEOF_SHORT_INT 2; | #define SIZEOF_INT 4; | #define SIZEOF_UNSIGNED_INT 4; | #de",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:12218,config,configure,12218,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,2,['config'],['configure']
Modifiability,"= 1; configure: failed program was:; | /* confdefs.h */; | #define PACKAGE_NAME ""SU2""; | #define PACKAGE_TARNAME ""SU2""; | #define PACKAGE_VERSION ""4.1.0""; | #define PACKAGE_STRING ""SU2 4.1.0""; | #define PACKAGE_BUGREPORT ""su2code-dev@lists.stanford.edu""; | #define PACKAGE_URL ""https://github.com/su2code""; | #define PACKAGE ""SU2""; | #define VERSION ""4.1.0""; | /* end confdefs.h. */; | #include <ac_nonexistent.h>; configure:4707: checking for grep that handles long lines and -e; configure:4765: result: /bin/grep; configure:4770: checking for egrep; configure:4832: result: /bin/grep -E; configure:4837: checking for ANSI C header files; configure:4857: gcc -c -g -O2 conftest.c >&5; configure:4857: $? = 0; configure:4930: gcc -o conftest -g -O2 conftest.c >&5; configure:4930: $? = 0; configure:4930: ./conftest; configure:4930: $? = 0; configure:4941: result: yes; configure:4954: checking for sys/types.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for sys/stat.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for stdlib.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for string.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for memory.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for strings.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for inttypes.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for stdint.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: ch",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:9759,config,configure,9759,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,3,['config'],['configure']
Modifiability,"> ; > ; > @CatarinaGarbacz thanks for pushing your changes! I have left some comments and questions.; > ; > A bigger question I have is if there is a more general way to deal with SU2_INTERP, making it usable for all of develop. Just answering @WallyMaier comment, this should be possible by changing the file **fem_interpolation_structure.cpp** and change the function call:. output = COutputFactory::CreateOutput(**NEMO_NAVIER_STOKES**, input_config_container[ZONE_0],nDim);. So we have to replace **NEMO_NAVIER_STOKES** to something like **config[val_iZone]->GetKind_Solver()**.; ; I have not tested this change, but I tested changing it for NAVIER_STOKES, and it was able to interpolate the baseline SU2.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1160#issuecomment-760110555:543,config,config,543,https://su2code.github.io,https://github.com/su2code/SU2/pull/1160#issuecomment-760110555,1,['config'],['config']
Modifiability,"> ; > ; > Dear Daumantas,; > ; > I appreciate your effort in adding support for cmake in SU2. We have recently introduced the Meson build system (https://mesonbuild.com/) (#685, #745) as a candidate to replace automake. A guide on how to use can be found [here](https://su2code.github.io/docs_v7/Build-SU2-From-Source/). The idea is that we will have this system along automake at least for the upcoming version 7 and that we get rid of automake afterwards. Considering that, I don't think that it makes sense to maintain 3 different build systems **at the moment**. I really hate turning contributions down, but this one is three months too late. However, we might reconsider adding support for another build system once we got rid of automake, or, if we feel that meson does not fit our needs.; > ; > I am all ears to hear other opinions. However, let's not start a discussion on the advantages/disadvantages of the build systems. Some benefits can be found in the Issue/PR linked above. Ok, I tried meson with MinGW but couldn't figure out how to link with MSMPI since it's not a part of MinGW. However, using CMake and with a few source code fixes, I managed to compile nearly every configuration with MSVC. Surprisingly, there were very few errors in SU2. The externals only had a few preprocessor issues. At the moment only MeDiPack fails to compile with MSVC but not with MinGW even though the MPI headers are the same so I suspect it's an issue with MSVC itself, I'm using the latest preview version.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/814#issuecomment-553571450:1187,config,configuration,1187,https://su2code.github.io,https://github.com/su2code/SU2/pull/814#issuecomment-553571450,1,['config'],['configuration']
Modifiability,"> > I'm thinking about reusing the SST test case ([axisymmetric_rans/air_nozzle](https://github.com/su2code/SU2/tree/master/TestCases/axisymmetric_rans/air_nozzle)) so that the same mesh can be used. Would that be fine ?; > ; > That's a quite specific testcase. How did you test the implementation? Do you have some simple results for the turbulent axisymmetric jet? We know that the results for round jets are not super good for standard SA, but at least we know what the result should look like, here on p.32 - 35 they test SA for the round jet and compare to the Wygnanski & Fiedler measurements: https://www.researchgate.net/publication/24296213_Turbulence_Modeling_Validation_Testing_and_Development; > ; > The domain is just a rectangle so pretty simple to set up.; > ; > You could also use the V&V test that we have, but it is a variable density jet: https://su2code.github.io/vandv/SANDIA_jet/. I did some tests on a supersonic jet, since I already had the files, but it's a quite complex case so it's not that good to verify the implementation. I will look into the simpler cases you mentioned !",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/2197#issuecomment-1891046092:836,variab,variable,836,https://su2code.github.io,https://github.com/su2code/SU2/pull/2197#issuecomment-1891046092,1,['variab'],['variable']
Modifiability,"> @aeroamit What does temperature do? Could you compute the heat flux from the temperature in e.g. paraview? Is the root cause the computation of the energy equation or the computation of heat flux?. Hi @bigfooted, Temperature boundary condition for wall corresponds to Isothermal wall BC (cold wall condition). This condition is applied to obtain heat flux unlike adiabatic wall (no heat transfer). ; The snapshot, I posted from ParaView shows heat flux variation with x. This is obtained directly from surface_flow.vtu. You can simply go to Filters -> Data Analysis -> Plot data and select Points_X for X Array and heat flux in variable. Regarding computing heat flux from temperature field, I am not sure, but ParaView is having calculator utility as well as option to compute gradient of unstructured grid (from there you can obtain temperature gradients in 3 directions). ; Coming to last question, root cause of the problem - @WallyMaier has run the case yesterday, we will be posting some details soon.; Best ; Amit",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1106#issuecomment-741947377:630,variab,variable,630,https://su2code.github.io,https://github.com/su2code/SU2/pull/1106#issuecomment-741947377,1,['variab'],['variable']
Modifiability,"> Every time we push commits or submit a pull request, the unit tests are run; > and checked.; > What is my vision for unit testing in SU2?; >; > I am *not* proposing that we start trying to get 100% code coverage with; > pre-existing code. That would not provide a good return on investment.; >; > Instead, I see people adding unit tests as they write new code and as they; > find bugs. For each new behavior added to SU2, tests are first added to; > document the related existing behavior. These tests serve to check that the; > existing behavior isn't damaged by the new code. Then new tests are added; > to prove that the new behavior is working correctly. For bug fixes, the; > process is simpler. A test is added to confirm that something is not; > behaving as expected. Then the code is fixed to make the test pass.; > What frameworks are available?; >; > For a unit testing framework, here are the most popular options, with the; > following pros and cons:; > Roll-your-own; >; > - Requires no external dependencies; > - The most flexible option; > - Involves the most work to setup; > - Will lack some of the more advances features of mature unit-testing; > frameworks.; >; > Boost Test; >; > - Can be header only, statically linked, or dynamically linked; > - If statically or dynamically linked, then Boost is not very; > lightweight; > - Easy to add if you're already using Boost; >; > Google Test; >; > - Most common unit-testing framework; > - Can be easily combined with Google's powerful GMock mocking library; > - Compiling and linking can be somewhat painful; >; > Catch2; >; > - Used by FEniCS; > - Makes unit tests easily readable with lots of syntactic sugar.; > - Has a very simple syntax; > - Is header-only; > - Requires C++11 compilation; > - Not as feature rich as Google Test or Boost Test; >; > Questions; >; > - How do developers feel about adding unit tests to SU2?; > - If a unit-testing framework were added to SU2, would you actually; > use it?; > - Do developers hav",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499278427:5642,flexible,flexible,5642,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427,1,['flexible'],['flexible']
Modifiability,"> I want to be done with this PR folks... This is really tiring to maintain so if you don't want it please just tell me...; > Can we agree on:; > Instead of CSolver having the `node` field it will have a pure virtual function `CVariable* GetNodes()`, derived solvers need to implement this method and have a `nodes` field of the most appropriate type (e.g. CEulerVariable for CEulerSolver).; > ; > I know some of you do not like the name `nodes` but there is something to be said about consistency (that has always been the name) and I do not think changing a generic name for another generic name justifies breaking the formatting everywhere and having needlessly long calls to get some data. In the interest of keeping the PRs moving, I am ok with this. It will also be natural for folks in the short term to learn the new system, since everyone is already accustomed to using the solver->node* construct. We can always go for a targeted refactoring later separate from the changes in this PR if we would like.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/753#issuecomment-538218606:940,refactor,refactoring,940,https://su2code.github.io,https://github.com/su2code/SU2/pull/753#issuecomment-538218606,1,['refactor'],['refactoring']
Modifiability,"> I'm thinking about reusing the SST test case ([axisymmetric_rans/air_nozzle](https://github.com/su2code/SU2/tree/master/TestCases/axisymmetric_rans/air_nozzle)) so that the same mesh can be used. Would that be fine ?. That's a quite specific testcase. How did you test the implementation? Do you have some simple results for the turbulent axisymmetric jet? We know that the results for round jets are not super good for standard SA, but at least we know what the result should look like, here on p.32 - 35 they test SA for the round jet and compare to the Wygnanski & Fiedler measurements:; https://www.researchgate.net/publication/24296213_Turbulence_Modeling_Validation_Testing_and_Development. The domain is just a rectangle so pretty simple to set up. You could also use the V&V test that we have, but it is a variable density jet:; https://su2code.github.io/vandv/SANDIA_jet/",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/2197#issuecomment-1889612505:816,variab,variable,816,https://su2code.github.io,https://github.com/su2code/SU2/pull/2197#issuecomment-1889612505,1,['variab'],['variable']
Modifiability,"> Looks quite simple to me now, what do you think?. I fully agree. The CVariable footprint is much smaller and no more nasty address handling. (Adding another variable in another solver requires a bit more code though and a little understanding of what is going on than the ""Address""-version, but on the other hand this explicit handling of each primal-solver creates a good separation :+1: )",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1536#issuecomment-1050172065:159,variab,variable,159,https://su2code.github.io,https://github.com/su2code/SU2/pull/1536#issuecomment-1050172065,1,['variab'],['variable']
Modifiability,"> Nice! By the way, did you use some scripts for going through all the files and returning 'bad' naming conventions?. No, now I am just going through it by hand probably some linters are available to at least detect them. Actually, I am a bit confused as it is not so clear in the guide. It looks like the beginning of the project was just abbreviated from the Google style guide and was not enforced. Enforcing function names in UpperCamelCase and leaving variable names to the developer seems reasonable. > Can you explain the snake/camel terminology? :). Let's say we have a variable we want to name as `number of nodes per mesh` there are 2 common choices as . ```cpp; number_of_nodes_per_mesh = 42;; numberOfNodesPerMesh = 42;; ```; The first case is called the [snake case](https://en.wikipedia.org/wiki/Snake_case) and the second one is the [camel case ](https://en.wikipedia.org/wiki/Camel_case). Snake case is generally used in Python as [PEP8](https://peps.python.org/pep-0008/) suggests. . > Please revert the python accessor changes. I merged develop many of them vanished, should I revert the remaining ones?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1981#issuecomment-1482062542:457,variab,variable,457,https://su2code.github.io,https://github.com/su2code/SU2/pull/1981#issuecomment-1482062542,2,['variab'],['variable']
Modifiability,"> Thank you for updating the solution file @snow54 , there's quite a big difference in the adjoint residuals, do the final derivatives still make sense? Is the flow field noticeably different (for the better, e.g. smoother? or equivalent to not having the boundary at all?) now that nearfield is treated as an internal boundary?; > If so let's update the residuals and merge. I think we can update the residuals. Gradients between adjoint and finite difference match quite well as shown below. I haven't finished calculating for all design variables, but I think it is enough. ![Comparison_gradient](https://user-images.githubusercontent.com/18245846/129564585-d7812108-d315-4606-83d9-e39a8c9403b3.png). In terms of flow field, the capture below is from the current develop branch. The boundary between structured grid and unstructured gird is a nearfield boundary. An object is above this capture and pressure wave propagates from there. Since this grid is inclined by Mach angle, pressure distribution on the nearfield should be fairly similar to the region above but this capture shows some strange pressure disturbance. Limiter: VAN_ALBADA_EDGE; ![NF_before](https://user-images.githubusercontent.com/18245846/129564639-030fe1b7-7e50-4bb1-9951-21f5ea27bb52.png). Limiter: VENKATAKRISHNAN_WANG; ![NF_before_VEN](https://user-images.githubusercontent.com/18245846/129568934-137681db-04db-40f1-819f-7bcc8c7e0d88.png). The capture below is from the branch with this PR. The issue I mentioned above does not exist. Limiter: VAN_ALBADA_EDGE; ![NF_after](https://user-images.githubusercontent.com/18245846/129564659-cec5a848-1b0b-4051-8298-e3d383dacc6d.png). I think the residuals for direct solver will be different like the adjoint if you run it for some hundreds more iterations (currently, the test case has only 20 iterations). However, since the nearfield boundary is a bit far from an object, it takes some iterations for pressure waves to reach the nearfield boundary. This PR also solves an issu",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1351#issuecomment-899498618:540,variab,variables,540,https://su2code.github.io,https://github.com/su2code/SU2/pull/1351#issuecomment-899498618,1,['variab'],['variables']
Modifiability,"> Thank you for your answer. If you could share the configs and meshes that you are using I can try following the approach suggested by @pcarruscag and use the TKE from the turbulence solver instead of the freestream one.; > ; > Plus, I have some doubts on the default value of the turbulent to laminar viscosity ratio which is equal to 10 in SU2, although on the NASA page suggests to be in the range of 10^-2 to 10^-5. However, I think that this is another issue. @rois1995 Hi ~ . Can you give me a link to the NASA TMR guide for setting the viscosity ratio? I'm not sure where to find it. Sorry, I found it!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1851#issuecomment-2251837355:52,config,configs,52,https://su2code.github.io,https://github.com/su2code/SU2/issues/1851#issuecomment-2251837355,1,['config'],['configs']
Modifiability,"> Thanks for pointing that out. I dont think it is intentional. Maybe we can use this PR also to fix this ?. That depends on how atomic we want these PRs to be. This PR is largely a refactoring PR, and shouldn't change any underlying performance. But adding extra calculations on source terms and wall conditions might change the performance of the code. The two changes are completely compatible, so combining them wouldn't be hard. Nevertheless, I propose we keep these changes separate, so that the purpose of each PR is clear and easy to see. In my mind, two small PRs are easier to check and review than one large PR. @talbring @economon What do you think? One big PR or two small PRs?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/626#issuecomment-458177675:182,refactor,refactoring,182,https://su2code.github.io,https://github.com/su2code/SU2/pull/626#issuecomment-458177675,1,['refactor'],['refactoring']
Modifiability,"> There was a lot of talk about refactoring the shape optimization framework to be able to work completely in memory.; > I think the idea was not to have more drivers but simply to have more granularity such that you could manipulate the geometry from python (without writing it to files).; > We also wanted introspection, i.e. you could probe SU2 via python for what variables and functions are available.; > We also talked about having the projection step (DOT) included in CFD_AD so that you only need to worry about surface sensitivities, note that DEF is already part of CFD for forward mode AD.; > (talking does not go very far); > ; > If you want to lead this work, we can help you understand the inner workings. We meet every Wednesday at 4pm CET https://meet.jit.si/SU2_DevMeeting to discuss this type of issue. Thank you for the quick reply. The discussions you mention sound very promising, I would be glad to join tomorrow afternoon and learn more, so that I might contribute. One quick remark: I am aware that it is indeed possible to deform the mesh within `SU2_CFD`, I use this extensively for static aero-elastic analysis. However, I have not been able to have the deformed mesh be written to file at output (in SU2 or CGNS format). This is fine for aero-elastic updates (movement of the surface due to _structural displacements_), where it is sufficient to see the deformed mesh in the post-processing files. It becomes impractical though, for design updates (movement of the surface to due to _design displacements_, i.e. representing changes in the design variables) where the new mesh is a useful intermediate result. Even if this is just an issue in my configuration file, I think that a stand-alone driver or equivalent of `SU2_DEF` would remain useful. For each new set of updated design variables during shape optimisation, a single mesh deformation is sufficient to provide the new, updated jig geometry which all of the aerodynamic or aero-elastic analyses (one for each oper",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1262#issuecomment-818839696:32,refactor,refactoring,32,https://su2code.github.io,https://github.com/su2code/SU2/issues/1262#issuecomment-818839696,2,"['refactor', 'variab']","['refactoring', 'variables']"
Modifiability,"> You may want to remove the string based interface since it's known to be inneficient. When replacing the string-based with index-based look-up methods, the performance improves substantially. The figure below shows the average measured evaluation time (measured with chrono library) vs the number of output variables. It's clear that using index-based look-up methods results in reduced query time, as well as improved scaling. ![scaling_nVars](https://github.com/su2code/SU2/assets/38651601/31252439-ac6e-4f1b-82d4-e13a55d54c98)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/2214#issuecomment-1952521226:309,variab,variables,309,https://su2code.github.io,https://github.com/su2code/SU2/pull/2214#issuecomment-1952521226,1,['variab'],['variables']
Modifiability,"> the off-PR comments can be integrated in this PR to clear that up a bit. If not that is OK as well. It's more than OK, the CHT implementation suffers a bit from being a single person's project.. you're very welcome to have a look over it! :-). > Can you add that option to the config_template.cfg together with that description, the valid inputs and the default. Actually I'm hesitating a bit adding it to the config template right now. I'd prefer to have `DIRECT_TEMPERATURE_ROBIN_HEATFLUX` as the default and ""hide"" the rest as developer's options for the moment.; The reason simply is that those different methods need to checked and validated against each other before we make them public.; E.g. I figured that for the incompressible CHT test case from the repo, there is a severe gap between the heatfluxes obtained from the ""averaged"" approach and the direct one, see below. ![heatflux_convergence](https://user-images.githubusercontent.com/22639394/72885197-bb9e4a80-3d07-11ea-9fad-a4d709dc511e.png). That needs to be cleared up first...",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/839#issuecomment-577108935:412,config,config,412,https://su2code.github.io,https://github.com/su2code/SU2/pull/839#issuecomment-577108935,1,['config'],['config']
Modifiability,">; configure:4644: result: gcc -E; configure:4664: gcc -E conftest.c; configure:4664: $? = 0; configure:4678: gcc -E conftest.c; conftest.c:11:28: error: ac_nonexistent.h: No such file or directory; configure:4678: $? = 1; configure: failed program was:; | /* confdefs.h */; | #define PACKAGE_NAME ""SU2""; | #define PACKAGE_TARNAME ""SU2""; | #define PACKAGE_VERSION ""4.1.0""; | #define PACKAGE_STRING ""SU2 4.1.0""; | #define PACKAGE_BUGREPORT ""su2code-dev@lists.stanford.edu""; | #define PACKAGE_URL ""https://github.com/su2code""; | #define PACKAGE ""SU2""; | #define VERSION ""4.1.0""; | /* end confdefs.h. */; | #include <ac_nonexistent.h>; configure:4707: checking for grep that handles long lines and -e; configure:4765: result: /bin/grep; configure:4770: checking for egrep; configure:4832: result: /bin/grep -E; configure:4837: checking for ANSI C header files; configure:4857: gcc -c -g -O2 conftest.c >&5; configure:4857: $? = 0; configure:4930: gcc -o conftest -g -O2 conftest.c >&5; configure:4930: $? = 0; configure:4930: ./conftest; configure:4930: $? = 0; configure:4941: result: yes; configure:4954: checking for sys/types.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for sys/stat.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for stdlib.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for string.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for memory.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for strings.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for inttypes.h; configure:4954: gcc -c -g -O2 conftes",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:9566,config,configure,9566,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,2,['config'],['configure']
Modifiability,">I found out the other day that this: unordered_map<pair<int,int>, su2double> does not work without extra tricks,. Yes, I found some examples to do it. But I was not quite understanding what are the sizes of local maps or how to communicate them over MPI. . >so if you have it out of the config in some matrix format it is probably better. In that case, I can just move the current global arrays to physical geometry class and simplify some of the function calls.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/877#issuecomment-653479936:288,config,config,288,https://su2code.github.io,https://github.com/su2code/SU2/pull/877#issuecomment-653479936,1,['config'],['config']
Modifiability,"@JedrzejMosiezny . The reason why the mesh and config files are split into separate repos is the following: ideally we want to have the test cases being closely coupled to the current version of the code as config options change quite frequently. However, the mesh files are simply too big to have them in the main repo (it takes too much time to check them out etc.). So a compromise was to still leave the config files in the main repo in order for them to stay up-to-date. We thought that the information [here](https://github.com/su2code/SU2/wiki/Test-Cases) would be quite clear for the user on how to merge config and mesh files. Following this instructions should avoid having to search for the mesh files manually. Let us know if you think different. @economon could you add Jędrzej to the dev team here on github ? Thanks!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/485#issuecomment-355152833:47,config,config,47,https://su2code.github.io,https://github.com/su2code/SU2/pull/485#issuecomment-355152833,4,['config'],['config']
Modifiability,"@bigfooted Has there ever been any discussion regarding implementation of a `START_TIME=` capability into the config file? After going through the code a bit, it looks like doing this would be a good starting point for implementing ability to adjust deltaT mid-runs, as in general the code presumes `TimeIter*deltaT` as being the current time. This would be problematic for unsteady restarts that have a varying timestep. Plus, this would allow one to, without using the Python wrapper, use a different timestep in the config file for an unsteady restart. It also may clear up some confusion to have an explicit option for this, as in #2071. It can maybe look something like:. % Start time for restarting unsteady simulations; % = -1 for default calculation (START_TIME=RESTART_ITER*TIME_STEP); START_TIME=-1. Then `CConfig::GetPhysicalTime` could be appropriately updated and used in-place of all locations in the code where a physical time is manually calculated.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/2190#issuecomment-1870730956:110,config,config,110,https://su2code.github.io,https://github.com/su2code/SU2/pull/2190#issuecomment-1870730956,2,['config'],['config']
Modifiability,"@clarkpede I have not used the mesh adaptation tools since my last post (I was simply learning to use them for an undergrad project). With that said, I do not have any other concerns. It worked well for my application. I appreciate your help.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/606#issuecomment-500491744:36,adapt,adaptation,36,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-500491744,1,['adapt'],['adaptation']
Modifiability,"@economon I tested a couple of simpler problems at subsonic speeds, including the ONERA M6 case at M=0.8395. There's occasionally a difference of one iteration out of about 20. Usually the current develop branch is the one that requires more iterations, but not always. I included a snapshot from my tests on the ONERA M6 case at CFL=30. ![convergence_comparison](https://user-images.githubusercontent.com/13340225/48648855-6c97af80-e9b6-11e8-863a-56dfdf0903c8.png). I don't have a good supersonic, viscous test problem, but I suspect the differences in convergence won't be huge there either. This sign change affects a single term out of many and a single component of a 4x4 or 5x5 Jacobian. My take is that the differences are there, but they are very small. I wouldn't have noticed the problem myself if I hadn't been refactoring the code to enable some changes on our end.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/609#issuecomment-439538677:822,refactor,refactoring,822,https://su2code.github.io,https://github.com/su2code/SU2/issues/609#issuecomment-439538677,1,['refactor'],['refactoring']
Modifiability,"@economon I was envisioning something similar to the TestCases folder. With v&v cases grouped according to what they are testing. Something along the lines of: . 1) Inviscid Simulations: ; a) 2D Inviscid bump; b) 2D oblique shocks interaction; c) ...; 2) RANS simulations: ; a) Flatplate; b) NACA0012; c) ...; 3) Unsteady simulations:; a) Square Cylinder; b) ...; 4) Turbomachinary: ; a) ... And so on. Each of the directories would have sub-directories for different mesh sizes, with configuration files for each mesh level that have optimized parameters for best results. So for example if we are talking about the NACA0012 case, we would have something along the lines of: . a) NACA0012; i) 113 x 33; ii) 225 x 65 ; iii) 449 x 129; iv) ... This way we have a family of meshes and configuration files that are specifically built for the purpose of validating the code and comparing with other solvers. I might be useful to compress meshes that are larger than a certain size (say 10MB). We should also put a limit on the size of a single mesh that the repository can handle (say 50MB?). . Within the home directory, the README file should list all the cases in the repository, who the custodian of the test case is (person with meshes in case the meshes are too large), and which version it was last run on. . I thought about splitting it up into Verification cases and Validation cases, but I thought it would be more informative and intuitive to split up according to the physics of the simulations. My thinking might be limited because that's how I have seen the TestCases folder organized, so any other suggestions are welcome. I think it is imperative that this is accompanied with a section on the SU2 website that showcases just the results of the validation test cases (grid convergence studies, residual reductions etc) and links to the v&v repo appropriately. This way, if people are just inquisitive about SU2's performance, they can get a quick snapshot of the results, without the need ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/581#issuecomment-426026053:485,config,configuration,485,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-426026053,2,['config'],['configuration']
Modifiability,"@fertinaz the problem is that the pkg_config name for MPICH is not ""mpi"" which is what meson is configured to look for...; It is ""mpich"", please see my reply from 23 of May, it is very simple to edit the meson.build script to look for ""mpich"" instead of ""mpi"".; I have used this on numerous machines and the code works fine...; Whatever you do, please do not follow the advice to use 6.2.0, we have all worked extremely hard to make v7.x much faster, fix bugs, and add nice features... Unfortunately we cannot test every combination of compiler, operating system, and libraries.; I'm sure that somewhere, someone has fixed similar problems, sadly not all fixes make it back into the code. Other alternatives, some of which folks have suggested on this thread.; - Use ""custom-mpi"" mode, you will need to set some environment variables (CC=mpicc CXX=mpicxx etc. see above); - Use the legacy build system (i.e. follow the instructions for 6.2.0 but with the 7.0.7 code) be sure to add ""-DNDEBUG"" to the CXXFLAGS environment variable.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1000#issuecomment-721322008:96,config,configured,96,https://su2code.github.io,https://github.com/su2code/SU2/issues/1000#issuecomment-721322008,3,"['config', 'variab']","['configured', 'variable', 'variables']"
Modifiability,"@hlkline : it is true that we have been experimenting a lot to find the best formula, and no doubt we will continue to tweak things as we constantly evolve. But, one constant you can always trust is that the repo will be the home for important decisions on issues and PRs, so there is no need to worry about missing critical updates. . With slack and now rocket chat, we are looking to improve communication efficiency as people collaborate on particular developments in the code (say in pairs or small groups), or perhaps in the future, it can be opened to the public as a sort of support channel. This is to be seen as we gather some experience and feedback.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/645#issuecomment-464602965:149,evolve,evolve,149,https://su2code.github.io,https://github.com/su2code/SU2/issues/645#issuecomment-464602965,1,['evolve'],['evolve']
Modifiability,"@marcovanderbijl : thanks for the question. The original limit there is simply to impose an upper bound for memory considerations, since the first instantiation of the array of FFD boxes (before the number of FFD boxes embedded in the mesh is detected) needs a default value. We can of course change this to automatically detect the number to avoid the requirement or make it an input option in the config, but we have not run into this issue yet. For now, you should be able to increase that to a reasonable number without any issue. Please give it a try.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/684#issuecomment-495078497:399,config,config,399,https://su2code.github.io,https://github.com/su2code/SU2/issues/684#issuecomment-495078497,1,['config'],['config']
Modifiability,"@pcarruscag I tried to restart the solution with zero mach number for config. However, for some reason, convergence takes so much longer than simply solving mach=0.1 config. Indeed, i started my simulation when you post your suggestion and it still haven't converged yet. Residual getting smaller but it is so slow. Therefore it might not be an efficient solution. Thanks for advice anyway.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/997#issuecomment-632892959:70,config,config,70,https://su2code.github.io,https://github.com/su2code/SU2/issues/997#issuecomment-632892959,2,['config'],['config']
Modifiability,"@petebachant: the paper that I linked earlier on this thread had some fairly simple examples similar to the one you propose.. different flat plates and so on with varying y^+. You can likely reuse the grid(s) in the TestCases repo. @vdweide: it was very simple in this first implementation. It checks for a single boolean for whether or not to apply wall functions (WALL_FUNCTIONS= YES or NO, https://github.com/su2code/SU2/blob/43b8a4015c4b09b01d78e4243d32011c663c2b70/SU2_CFD/src/solver_direct_mean.cpp#L15339), and then assumes they should be applied to all no-slip walls (heat flux or isothermal, https://github.com/su2code/SU2/blob/43b8a4015c4b09b01d78e4243d32011c663c2b70/SU2_CFD/src/solver_direct_mean.cpp#L16653). This could of course be made more specific for individual markers using a config structure like MARKER_MONITORING to list them, or by making a dedicated BC type for it potentially.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/399#issuecomment-327308587:796,config,config,796,https://su2code.github.io,https://github.com/su2code/SU2/issues/399#issuecomment-327308587,1,['config'],['config']
Modifiability,"@talbring Thanks for the quick and helpful answer! I'm looking at creating an ebuild/package for gentoo, compilation is a lot simpler than OpenFoam :P which is a big plus :). Anyway, I was looking at the old docs (the main docs still point to 6.0, I missed the red text that mentioned that somehow :P), not sure why, but you're right it's indeed mentioned in the 7.0 docs here https://su2code.github.io/docs_v7/Build-SU2-Linux-MacOS/#configuration-and-compilation. The ""Automatically installed dependencies"" section left me a bit confused because it sounded like the things listed there, which includes meson and ninja, would always get installed.; Maybe merging that section into the configuration and compilation section might help to make it more clear?. If you don't mind I have some additional questions:; - I didn't initialize the git submodule at all and configuration, compilation and running worked fine. Does this mean the CoDiPack and MeDiPack dependencies are optional? Or does this mean I could have a crash at runtime somewhere?; - Would it be possible to add a source package to the GitHub releases (in addition to the binary ones) that includes the (CoDiPack and MeDiPack) submodules? Unfortunately the GitHub provided source downloads don't include submodules.; - Are MKL and OpenBLAS build-time and exclusive options or can they both be compiled in and chosen at runtime?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/911#issuecomment-598751341:434,config,configuration-and-compilation,434,https://su2code.github.io,https://github.com/su2code/SU2/issues/911#issuecomment-598751341,3,['config'],"['configuration', 'configuration-and-compilation']"
Modifiability,"@talbring Yes, I do. I can't uninstall it since it breaks other packages. @pcarruscag Yeah same for me. You can see it here:; ```; slimshady@arch-linux-hp-probook-g3-450: ~$ mpicc -v; mpicc for MPICH version 3.3.2; Using built-in specs.; COLLECT_GCC=gcc; COLLECT_LTO_WRAPPER=/usr/lib/gcc/x86_64-pc-linux-gnu/9.2.1/lto-wrapper; Target: x86_64-pc-linux-gnu; Configured with: /build/gcc/src/gcc/configure --prefix=/usr --libdir=/usr/lib --libexecdir=/usr/lib --mandir=/usr/share/man --infodir=/usr/share/info --with-pkgversion='Arch Linux 9.2.1+20200130-2' --with-bugurl=https://bugs.archlinux.org/ --enable-languages=c,c++,ada,fortran,go,lto,objc,obj-c++,d --enable-shared --enable-threads=posix --with-system-zlib --with-isl --enable-__cxa_atexit --disable-libunwind-exceptions --enable-clocale=gnu --disable-libstdcxx-pch --disable-libssp --enable-gnu-unique-object --enable-linker-build-id --enable-lto --enable-plugin --enable-install-libiberty --with-linker-hash-style=gnu --enable-gnu-indirect-function --enable-multilib --disable-werror --enable-checking=release --enable-default-pie --enable-default-ssp --enable-cet=auto gdc_include_dir=/usr/include/dlang/gdc; Thread model: posix; gcc version 9.2.1 20200130 (Arch Linux 9.2.1+20200130-2) ; ```; I did what you suggested and here is how my meson.build file looks.; ```; # If custom mpi mode is enabled, include and library pathes for MPI have to be set manually to env variables; if get_option('custom-mpi'); mpi_dep = []; mpi = true; # Otherwise they are automatically determined; else; mpi_dep = [dependency('mpich', required : get_option('with-mpi'))]; # mpi_dep = [dependency('mpi', language:'c', required : get_option('with-mpi')),; # dependency('mpi', language:'cpp', required : get_option('with-mpi'))]; #if mpi_dep[0].found() or mpi_dep[1].found(); # mpi = true; #endif; endif; ```; My SU2 build was successful but there were a couple of warnings.; Also, instead of 870 there were only 772 files in total. Is that okay?; ```; slimshady@",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1000#issuecomment-633139474:392,config,configure,392,https://su2code.github.io,https://github.com/su2code/SU2/issues/1000#issuecomment-633139474,2,"['config', 'plugin']","['configure', 'plugin']"
Modifiability,"A short summary of the things I did in the additional commits:. - I added a consistent error handling that can be used throughout the code. For example if a marker is not specified the error looks like that: ; ```; -------------------------------- Error ---------------------------------; In ""short unsigned int CConfig::GetMarker_CfgFile_TagBound(std::__cxx11::string)"": ; ------------------------------------------------------------------------; The configuration file doesn't have any definition for marker airfoil; ------------------------------------------------------------------------; Exiting now ...; ```; or if a solution cannot be found:. ```; -------------------------------- Error ---------------------------------; In ""void CSolver::Read_SU2_Restart_Metadata(CGeometry*, CConfig*, bool, std::__cxx11::string)"": ; ------------------------------------------------------------------------; Unable to open SU2 restart file solution_flow.dat; ------------------------------------------------------------------------; Exiting now ...; ```; In case you want to throw an error, you can simply call the function `SU2_MPI::Error(""Error Message"", CURRENT_FUNCTION)` where `CURRENT_FUNCTION` is a predefined macro which expands to the name of the routine at compile time. I already replaced almost all error messages in the code. - More MPI functions are included in the MPI Wrapper. - The rank/size is now stored in most of the bigger classes and initialized in the constructor. That means there are no calls to MPI_Comm_rank / MPI_Comm_size anymore in every routine ... For convenience there is also a SU2_MPI::GetRank() / SU2_MPI::GetSize(), in case you need it outside of the main classes. Let me know what you think. Not everything I did has to stay the way I implemented it :)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/473#issuecomment-347663941:452,config,configuration,452,https://su2code.github.io,https://github.com/su2code/SU2/pull/473#issuecomment-347663941,1,['config'],['configuration']
Modifiability,Actually I had a look at your branch and the way it is right now is not correct I believe because I had taken the other variables v and 1/y out of the derivative using the chain rule and combined them with the other derivatives to end up with the terms as they are now so only d(mu)/dy was missing. The AxiAuxVarGrad you are using is apparently d(v*mu/y)/dy so the other terms have to be different. I will change them. Why not just simply compute the viscosity gradient? Is there any reason not to pull the other variables out?. Is there not already an AuxVar being just v*mu or something? . Anyway I guess it will work the same either way,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1095#issuecomment-727969107:120,variab,variables,120,https://su2code.github.io,https://github.com/su2code/SU2/pull/1095#issuecomment-727969107,2,['variab'],['variables']
Modifiability,"Ah, that tutorial page is very important.. I don't think it was ever linked in the main wiki menu, but it is critical for making the options clear to the user (especially the surface handling). We need to make the design features as easy to use as possible - it is already hard enough for experts to use adjoints :). This is a good opportunity to move it over to the new repo where we are placing the tutorials here: https://su2code.github.io/Tutorials/docs/home/. The files, including the markdown, mesh, config, and images, can be moved to that repo. The markdown portion goes into the _docs directory, and we should make sure it's linked under the shape design tutorials. Do you have some time for this? Let me know if you need some help.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/494#issuecomment-357458143:506,config,config,506,https://su2code.github.io,https://github.com/su2code/SU2/pull/494#issuecomment-357458143,1,['config'],['config']
Modifiability,"All,. Of course, another approach to verifying which sign is correct is to do an analytic differentiation (using CoDi?) or simply using complex-step on the residual calculation routine to get exact Jacobians (for a particular state) and confirm the correct sign. This does require some code extraction / refactoring to perform the test, but it has the benefit that you would know exactly what the correct answer is for the specific residual implementation. Best,. Juan. On Nov 16, 2018, at 11:03 AM, Thomas D. Economon <notifications@github.com<mailto:notifications@github.com>> wrote:. As Jacobians affect convergence rate and not accuracy, you could do a quick test of the same problem with the current version and the sign flipped to see if there is measurable difference in the convergence rate. If yes, then it should give you a hint about which direction. If no, then we should still correct it, but prob don't need to put in too much effort. @clarkpede<https://github.com/clarkpede> : I'm interested in your unit testing set up... —; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/609#issuecomment-439493827>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADpSxInSS3cmLF8iFkD22AoYAp0G3G2yks5uvwvxgaJpZM4YeD9V>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/609#issuecomment-439500791:304,refactor,refactoring,304,https://su2code.github.io,https://github.com/su2code/SU2/issues/609#issuecomment-439500791,1,['refactor'],['refactoring']
Modifiability,"Alright. I did some digging, and the problem has nothing to do with the warning message. It goes much deeper. In a recent release, SU2 switched to reading and writing binary restart files instead of ASCII. The grid adaptation code is still written only for ASCII. If I'm right, then trying to read a binary restart file with the flow solution breaks the program. I'll submit an issue detailing the bug. For now, try adding the following lines to your cfg file when you run `SU2_CFD`:. %; % Write binary restart files (YES, NO); WRT_BINARY_RESTART= NO; %; % Read binary restart files (YES, NO); READ_BINARY_RESTART= NO. Then run `SU2_MSH`, just like you have been. Does that clear things up?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/606#issuecomment-436131167:215,adapt,adaptation,215,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-436131167,1,['adapt'],['adaptation']
Modifiability,"And here is a simple test case demonstrating potential use. A major benefit of the supersonic inlet is being able to model supersonic propulsion systems, such as a scramjet, where the propulsion system exit boundary is modeled as a supersonic inlet, with distinct properties from the farfield flow conditions. Here we have a two dimensional test case demonstrating the interaction of exhaust flow with free-stream flow at the exit plane of a 2D scramjet system. Flow conditions adapted from [A Design Method for Three-Dimensional Scramjet Nozzles with Shape Transition](https://arc-aiaa-org.stanford.idm.oclc.org/doi/abs/10.2514/1.B38293); Jens Kunze, Michael K. Smart, and Rowan Gollan; Journal of Propulsion and Power 2022 38:1, 3-17. <img width=""1262"" alt=""image"" src=""https://user-images.githubusercontent.com/44848904/211415971-b6122204-0d95-43ca-903b-d60fd6326c39.png"">",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1862#issuecomment-1375043856:478,adapt,adapted,478,https://su2code.github.io,https://github.com/su2code/SU2/pull/1862#issuecomment-1375043856,1,['adapt'],['adapted']
Modifiability,"As we mentioned in the dev meeting where you exposed the problem, the implementation is not good for strongly coupled flows, and I would guess that it is worse for diffusion than convection (because diffusion is elliptic).; I suspect the main problem is that the linear system does not contain information from the other side of the interface, meaning the solution of the two domains is effectively decoupled.; You could try running the case at much lower CFL (below 1) even with an explicit method.; It is also possible that the current treatment could be improved, since it is an example of multiplicative Schwartz decomposition, maybe there is an ""optimal"" way of implementing that from a physics point of view. Just speculating here, but maybe it would help treating the interface as an outlet if flow is going out, and as an inlet if flow is coming in.; On the numerics side, you can also try hacking the MZ driver to use something more stable than block-Gauss-Seidel (e.g. some quasi-Newton thing for the interface). But those are all band-aids IMO, if you want a robust fluid-fluid interface you need the coupling to be present in the linear system. The simplest way to do that is to have an internal boundary and treat the problem as single zone.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1414#issuecomment-951848509:1112,coupling,coupling,1112,https://su2code.github.io,https://github.com/su2code/SU2/issues/1414#issuecomment-951848509,1,['coupling'],['coupling']
Modifiability,"Both ‘**rapidjson**’ and ‘**CoolProp**’ are licensed under the shortest and simplest permissive **MIT** license. I am not an expert but whether indicating the text of the licenses and copyright marks at the beginning of each of my files is reasonable?. Honestly, I don’t like the idea to treat **rapidjson** as a git submodule because some **rapidjson** internals are Windows specific (e.g., _/include/rapidjson/msinttypes_ subfolder content) and I don’t really confident with Meson build setup procedure. . Actually, I generated the **all_cubics_extended_JSON_binary** variable in the following way.; **CoolProp** library contains dozens of json files from which I assembled the single file for my own needs. Then, I made some modifications to the _generate_headers.py_ file (under _/dev_ subfolder of the **CoolProp** root) and run it in order to translate my large json file into the C++ header file. The generated file is not as large (~1.3 MB) as it seems but verbose a little bit. Could you clarify what **tecplot** sources do you mean?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1402#issuecomment-942054879:570,variab,variable,570,https://su2code.github.io,https://github.com/su2code/SU2/pull/1402#issuecomment-942054879,1,['variab'],['variable']
Modifiability,CaeStrXML.vcxproj.user (3) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/module.mk (239) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/modulelocal-sample.mk (84) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtCaepInitItems.h (98) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtCaepInstanceData.h (135) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtCaepSupportData.h (89) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtPwpInitItems.h (68) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtPwpPluginInfo.h (75) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtPwpVersions.h (62) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/runtimeWrite.c (443) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.sdf (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.sln (26) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.suo (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcproj (511) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcxproj (307) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcxproj.filters (78) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcxproj.user (3) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/UpgradeLog.XML (47) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport.css (207) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport.xslt (232) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport_Minus.gif (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport_Plus.gif (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/module.mk (240) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/modulelocal-sample.mk (84) ; - D MeshTools/PointwiseSU2plugin/src/plugins/,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:15228,plugin,plugins,15228,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['plugin'],['plugins']
Modifiability,CaeUnsXML.vcxproj (307) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcxproj.filters (78) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcxproj.user (3) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/module.mk (239) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/modulelocal-sample.mk (84) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtCaepInitItems.h (98) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtCaepInstanceData.h (135) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtCaepSupportData.h (89) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtPwpInitItems.h (68) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtPwpPluginInfo.h (75) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtPwpVersions.h (62) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/runtimeWrite.c (347) ; - D MeshTools/PointwiseSU2plugin/src/plugins/README.txt (272) ; - D MeshTools/PointwiseSU2plugin/src/plugins/module.mk (309) ; - D MeshTools/PointwiseSU2plugin/src/plugins/modulelocal.mk (8) ; - D MeshTools/PointwiseSU2plugin/src/plugins/pluginRegistry.h (29) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEP.c (228) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEP.h (550) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEPUtils.c (290) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEPUtils.h (725) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/runtimeWrite.h (57) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWGM/apiGridModel.c (492) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWGM/apiGridModel.h (1808) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWP.c (132) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWP.h (707) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWPUtils.c (789) ; - D MeshTools/PointwiseSU2plugin/src/plugins/sha,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:18071,plugin,plugins,18071,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['plugin'],['plugins']
Modifiability,"Charanya,. thanks for the detailed answer. Let me ask you some more info. Apparently, you where able to reproduce the results I had comparing the two code versions simply using different boundary conditions on the latest code version. Can you specify me how?. Tobi,. In the meanwhile, to narrow down the problem, I ran also a couple tests in 2D to seek confirmation. For the (Euler) **pitching_NACA64A010.cfg** test case in the repository I rerun the same test at AoA of 1 deg and removing the pitching (no mesh deforming). I attach config files and summaries relative to the test cases. [config_CFD_6_2_0.txt](https://github.com/su2code/SU2/files/3938858/config_CFD_6_2_0.txt); [Summary_6_2_0.txt](https://github.com/su2code/SU2/files/3938859/Summary_6_2_0.txt); [config_CFD_6_0_1.txt](https://github.com/su2code/SU2/files/3938863/config_CFD_6_0_1.txt); [Summary_6_0_1.txt](https://github.com/su2code/SU2/files/3938865/Summary_6_0_1.txt). In this case the situation is definitely better as the two solvers give the same results. It looks like it is an issue related to the 3D case. <img width=""1220"" alt=""Screenshot 2019-12-09 at 11 27 27"" src=""https://user-images.githubusercontent.com/23583209/70424365-f316a780-1a77-11ea-8f68-4fc83e188ed7.png"">. I also quote Charanya in saying that it is definitely good that convergence to same values is reached but the transient response is fundamental and holds physical/mathematical values (I think of Wagner et similia) :). I would also suggest to add a regression test in this sense. Best, ; Rocco",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/828#issuecomment-563150217:533,config,config,533,https://su2code.github.io,https://github.com/su2code/SU2/issues/828#issuecomment-563150217,1,['config'],['config']
Modifiability,"Checkout the small_fixes branch please, I hope the problem is ""that"" simple as I will not debug that function any further because it has the world record for nested loops. If it does not work you will have to hope for help from the turbo folks.; ```c++; for (iMarker = 0; iMarker < nMarker; iMarker++){; for (iMarkerTP=1; iMarkerTP < config->GetnMarker_Turbomachinery()+1; iMarkerTP++){; if (config->GetMarker_All_Turbomachinery(iMarker) == iMarkerTP){; if (config->GetMarker_All_TurbomachineryFlag(iMarker) == marker_flag){; for (iVertex = 0; iVertex < nVertex[iMarker]; iVertex++) {; iPoint = vertex[iMarker][iVertex]->GetNode();; for (jMarker = 0; jMarker < nMarker; jMarker++){; if (config->GetMarker_All_KindBC(jMarker) == PERIODIC_BOUNDARY) {; PeriodicBoundary = config->GetMarker_All_PerBound(jMarker);; jVertex = nodes->GetVertex(iPoint, jMarker);; if ((jVertex != -1) && (PeriodicBoundary == (val_iZone + 1))){; coord = nodes->GetCoord(iPoint);; switch (config->GetKind_TurboMachinery(val_iZone)){; case CENTRIFUGAL; ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1219#issuecomment-790064117:334,config,config,334,https://su2code.github.io,https://github.com/su2code/SU2/issues/1219#issuecomment-790064117,6,['config'],['config']
Modifiability,"Config options and their options can be found in:; https://github.com/su2code/SU2/blob/master/config_template.cfg; As a part of the code repository, this document will remain up to date with whatever version of the code you have. I believe that this is the single document to which you refer. I apologize that its location or purpose may not have been clear - I will shortly go edit the wiki to see if I can make it clearer that this file exists. . Additionally, the file config_template_basic.cfg in the same directory is a shorter version with only the options most commonly used. . Further documentation of the config options is also available in the comments of:; https://github.com/su2code/SU2/blob/master/Common/src/config_structure.cpp. And although it has not been up to date as we moved towards the wiki and config file template rather than keeping doxygen up to date, additional documentation can be produced using the files in su2code/Documentation/Doxygen.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/183#issuecomment-111755617:614,config,config,614,https://su2code.github.io,https://github.com/su2code/SU2/issues/183#issuecomment-111755617,2,['config'],['config']
Modifiability,"Dear Dr Albring,. I just followed the procedures and included the files to create a test case to SU2_CFD_AD [a coarse mesh, a TargetCp.dat and a config file for an Arina nozzle. The coarse mesh is a 2000 triangles one; which is enough to give us an idea of the shockwave location and the geometry modifications. The next mesh I have would be an ~85000 elements which gives us a good information on the 27th function call]. ; I had some segmentation faults during long jobs: Is there some recommended tuning I can do on OS/HW or SU2 in order to minimize them?. With kind regards,. Jairo. > On Dec 7, 2018, at 09:45, Jairo Paes Cavalcante Filho <jairo.pcfilho@gmail.com> wrote:; > ; > Hello Dr. Albring,; > ; > Yes! Sorry for the delay due some internal presentations and events here.; > I just finished a small model and successfully tested it on openSUSE. I expect to upload it today.; > ; > With kind regards,; > ; > Jairo; > ; >> On Dec 7, 2018, at 06:35, Tim Albring <notifications@github.com <mailto:notifications@github.com>> wrote:; >> ; >> Hi Jairo,; >> ; >> what is the status here ? Is it possible to provide a simpler (smaller) case ?; >> ; >> —; >> You are receiving this because you were mentioned.; >> Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/pull/600#issuecomment-445175541>, or mute the thread <https://github.com/notifications/unsubscribe-auth/Ac180u4PogeqhPW9rrfY4mW705IYKjvhks5u2jZpgaJpZM4X34F2>.; >> ; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/600#issuecomment-445429636:145,config,config,145,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-445429636,1,['config'],['config']
Modifiability,"Dear Dr. Economon,. I just finished the run on AD with the files you have adjusted and it did; converge. I also have successfully run some simple inverse design tests; with a limit on the number of cycles.; Thank you very much for your guidance and help. With kind regards,. Jairo. On Wed, Jan 30, 2019 at 2:13 PM Thomas D. Economon <notifications@github.com>; wrote:. > *@economon* approved this pull request.; >; > LGMT. Thanks @jaspe55 <https://github.com/jaspe55>; >; > Just one request: I have adjusted the number of iterations for the; > regression test and updated the residual values in the python script. I; > also had to move around some files. Can you please run the case (to; > convergence) and verify that the results are what you expect? Note that the; > config file and target Cp are in the code repository and the mesh and; > solution file are in the testcases repository. If everything looks ok, then; > this is ready to be merged.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/pull/600#pullrequestreview-198200089>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/Ac180hqzVnSUPCnSBkQrTPfIv0kIltygks5vIdKrgaJpZM4X34F2>; > .; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/600#issuecomment-459568514:769,config,config,769,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-459568514,1,['config'],['config']
Modifiability,"Dear Heather,; I am analyzing a propeller of an UAV. I have static thrust measurements such that when I used Euler results I got 3.5 lbf thrust as compared to the measured 6 lbs. My next step was to perform an NS equation with SA turb model. I got 7 times over predicted results such that the mesh has a Y+ of less than 1. Then I thought of doing an SST but was not long enough that it gave me error with divergence. I have been setting up my SST case as per the tutorial example of NACA0012. However, I do not happen to see any entry with regards to eddy frequency etc. (usually required by SST) in the config file. Any guidance will be great.; Thanks; Jehan; From: Heather Kline notifications@github.com; To: su2code/SU2 SU2@noreply.github.com ; Sent: Tuesday, May 12, 2015 11:43 AM; Subject: [SU2] Feature deallocation (#174). Bringing this branch up to date with current develop branch. ; Various deallocation changes; Some regression tests fail but all run. (previously was not the case); You can view, comment on, or merge this pull request online at:;   https://github.com/su2code/SU2/pull/174; Commit Summary; - Updated GetEngine_Properties; - Fix to the last commit; - Small bug; - Merge branch 'develop' into feature_MPI; - merging; - SU2_SOL and SU2_CFD are working; - Preliminary, but complete, implementation of SU2_DEF; - More updates; - Working version; - Complete implementation (validate); - Working version of SU2_DEF; - Final push before moving to the develop branch; - New MPI (removing SU2_PRT); - Merged in Ben's ParMETIS integration and fixed some conflicts.; - Merge branch 'benkirk-parmetis_integration' into feature_MPI; - ParMETIS geometry routines have been copied over but are not activated yet.; - Small change to ParMETIS include.; - ParMETIS can now be activated for testing (PARMETIS=YES in config).; - Updated MG; - Updated EA subrotuine; - Small fix; - Fixing memory leak; - Fixing memory leaks; - Dev release v.3.2.6; - Increasing MAX_NUMBER_MARKER; - Working versi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:604,config,config,604,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['config'],['config']
Modifiability,"Dear all, ; I have added a pdf file here that includes some test case results obtained with our BC transition model. These zero pressure gradient and variable pressure gradient flat plate test cases are very popular for model validation. I have also included Eppler E387 airfoil results. I would appreciate if you have any 3-D test case and share it with me.; Looking forward to hear your feedback. ; Sincerely,; Samet. [BC_model_TestCaseResults.pdf](https://github.com/su2code/SU2/files/562425/BC_model_TestCaseResults.pdf)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/326#issuecomment-257360833:150,variab,variable,150,https://su2code.github.io,https://github.com/su2code/SU2/pull/326#issuecomment-257360833,1,['variab'],['variable']
Modifiability,"EOF_LONG_INT 8; | #define SIZEOF_FLOAT 4; | #define SIZEOF_DOUBLE 8; | #define SIZEOF_VOID_P 8; | /* end confdefs.h. */; | #include <X11/Intrinsic.h>; configure:5409: result: no; configure:5409: checking for X11/Intrinsic.h; configure:5409: result: no; configure:5721: checking for /gshare/soft/code_saturne/4.0.0/prod/cgnslib_3.2.1/lib/libcgns.a; configure:5735: result: yes; configure:5755: checking for /gshare/soft/code_saturne/4.0.0/prod/cgnslib_3.2.1/include/cgnslib.h; configure:5769: result: yes; configure:6815: checking that generated files are newer than configure; configure:6821: result: done; configure:6952: creating ./config.status. ## ---------------------- ##; ## Running config.status. ##; ## ---------------------- ##. This file was extended by SU2 config.status 4.1.0, which was; generated by GNU Autoconf 2.69. Invocation command line was. CONFIG_FILES = ; CONFIG_HEADERS = ; CONFIG_LINKS = ; CONFIG_COMMANDS = ; $ ./config.status . on master. config.status:875: creating externals/tecio/Makefile; config.status:875: creating externals/metis/Makefile; config.status:875: creating externals/parmetis/Makefile; config.status:875: creating Makefile; config.status:875: creating externals/Makefile; config.status:875: creating Common/lib/Makefile; config.status:875: creating SU2_CFD/obj/Makefile; config.status:875: creating SU2_DOT/obj/Makefile; config.status:875: creating SU2_MSH/obj/Makefile; config.status:875: creating SU2_DEF/obj/Makefile; config.status:875: creating SU2_SOL/obj/Makefile; config.status:875: creating SU2_GEO/obj/Makefile; config.status:875: creating SU2_PY/Makefile; config.status:1047: executing depfiles commands; configure:8181: result:. -------------------------------------------------------------------------; | ___ _ _ ___ |; | / __| | | |_ ) Release 4.1.0 'Cardinal' |; | \__ \ |_| |/ / |; | |___/\___//___| Suite |; | |; -------------------------------------------------------------------------; | SU2 Lead Dev.: Dr. Francisco Palacios, Francisco.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:16036,config,config,16036,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,1,['config'],['config']
Modifiability,"ERSION ""4.1.0""; | #define PACKAGE_STRING ""SU2 4.1.0""; | #define PACKAGE_BUGREPORT ""su2code-dev@lists.stanford.edu""; | #define PACKAGE_URL ""https://github.com/su2code""; | #define PACKAGE ""SU2""; | #define VERSION ""4.1.0""; | /* end confdefs.h. */; | #include <ac_nonexistent.h>; configure:4707: checking for grep that handles long lines and -e; configure:4765: result: /bin/grep; configure:4770: checking for egrep; configure:4832: result: /bin/grep -E; configure:4837: checking for ANSI C header files; configure:4857: gcc -c -g -O2 conftest.c >&5; configure:4857: $? = 0; configure:4930: gcc -o conftest -g -O2 conftest.c >&5; configure:4930: $? = 0; configure:4930: ./conftest; configure:4930: $? = 0; configure:4941: result: yes; configure:4954: checking for sys/types.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for sys/stat.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for stdlib.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for string.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for memory.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for strings.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for inttypes.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for stdint.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for unistd.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4970: che",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:9899,config,configure,9899,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,3,['config'],['configure']
Modifiability,"Edwin,. I think it is a good idea to be able to have some level of control over the application of the wall functions on a marker-by-marker basis: as you say, it would be fairly common to have a wing marker where integration to the wall makes sense and a fuselage marker where wall functions (or even an inviscid BC) is the right thing to do. So let’s indeed do something like what Tom suggests (in the spirit of MARKER_MONITORING) so that one can control which markers get wall functions applied. If a list of markers is not specified in the config file, the default behavior should be that all no-slip walls get wall function BCs. If a list of markers is specified, then those and only those markers listed get wall function Bfs (with the others getting integration to the wall treatment). Now, what you point out in the second half of your message is the ultimate in flexibility: not only specifying wall functions in a subset of the no-slip wall markers, but also allowing for different kinds of wall functions to be used in those markers. I imagine that this would be a seldom used capability…but someone out there might have the need. I guess it does not seem to me that the coding of the most flexible logic is that much more complicated, so we may as well do that. If you guys think it is too complicated, the advertised options in the config file can allow some simpler behavior. My two cents,. Juan. On Sep 5, 2017, at 9:58 PM, Edwin van der Weide <notifications@github.com<mailto:notifications@github.com>> wrote:. Juan,. I think that having the flexibility to apply wall functions on only a subset of the viscous wall boundaries would be useful. E.g., if you are interested in a wing, you can apply integration to the wall there, but apply wall functions on the fuselage. My preference would be to have a dedicated BC type for that, i.e. Tom's second suggestion. Apart from this, we can have the different wall model types as a single input parameter, i.e. you apply the same wall model ty",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/399#issuecomment-327377108:543,config,config,543,https://su2code.github.io,https://github.com/su2code/SU2/issues/399#issuecomment-327377108,1,['config'],['config']
Modifiability,"F_UNSIGNED_INT 4; | #define SIZEOF_LONG_INT 8; | #define SIZEOF_FLOAT 4; | #define SIZEOF_DOUBLE 8; | #define SIZEOF_VOID_P 8; | /* end confdefs.h. */; | #include <X11/Intrinsic.h>; configure:5409: result: no; configure:5409: checking for X11/Intrinsic.h; configure:5409: result: no; configure:5721: checking for /gshare/soft/code_saturne/4.0.0/prod/cgnslib_3.2.1/lib/libcgns.a; configure:5735: result: yes; configure:5755: checking for /gshare/soft/code_saturne/4.0.0/prod/cgnslib_3.2.1/include/cgnslib.h; configure:5769: result: yes; configure:6815: checking that generated files are newer than configure; configure:6821: result: done; configure:6952: creating ./config.status. ## ---------------------- ##; ## Running config.status. ##; ## ---------------------- ##. This file was extended by SU2 config.status 4.1.0, which was; generated by GNU Autoconf 2.69. Invocation command line was. CONFIG_FILES = ; CONFIG_HEADERS = ; CONFIG_LINKS = ; CONFIG_COMMANDS = ; $ ./config.status . on master. config.status:875: creating externals/tecio/Makefile; config.status:875: creating externals/metis/Makefile; config.status:875: creating externals/parmetis/Makefile; config.status:875: creating Makefile; config.status:875: creating externals/Makefile; config.status:875: creating Common/lib/Makefile; config.status:875: creating SU2_CFD/obj/Makefile; config.status:875: creating SU2_DOT/obj/Makefile; config.status:875: creating SU2_MSH/obj/Makefile; config.status:875: creating SU2_DEF/obj/Makefile; config.status:875: creating SU2_SOL/obj/Makefile; config.status:875: creating SU2_GEO/obj/Makefile; config.status:875: creating SU2_PY/Makefile; config.status:1047: executing depfiles commands; configure:8181: result:. -------------------------------------------------------------------------; | ___ _ _ ___ |; | / __| | | |_ ) Release 4.1.0 'Cardinal' |; | \__ \ |_| |/ / |; | |___/\___//___| Suite |; | |; -------------------------------------------------------------------------; | SU2 Lead Dev.: Dr.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:15982,config,config,15982,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,1,['config'],['config']
Modifiability,"Food for thought: According to his most recent AIAA talk, Spalart himself has tried to keep the model variants ""modular."" Some of the variants are compatible with each other. For example, you can add a ""rotation-curvature correction"" and a ""compressiblity correction"". The NASA TMR catalogue reflects this design by stating ""These corrections can be applied individually or together in combination with the General Model."". A simple `SA_QCR` or `SA_COMP` naming scheme doesn't match the underlying design. On the user-facing side, separate config options might be better for some of the variations. On the code side, bit flags (Issue #770) might be a good way to gather all the model variants together into a single config option.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/992#issuecomment-652446915:540,config,config,540,https://su2code.github.io,https://github.com/su2code/SU2/issues/992#issuecomment-652446915,2,['config'],['config']
Modifiability,"From the SU2 paper, talking about ""guiding principles"":. <img width=""574"" alt=""Screen Shot 2019-10-09 at 3 26 46 PM"" src=""https://user-images.githubusercontent.com/19416354/66525312-edb5d480-eaa9-11e9-9c0f-158b3941b407.png"">. I particularly like. > Full documentation, including a comprehensive set of tutorials. (""including"" implying that the tutorials are a subset of the documentation), and . > expose the full set of options [...] to the practitioner. This conflicts with our ""operating principle"", laid out on the tutorials page:. > Rather than writing a long manual on all available (and constantly evolving) configuration options available in SU2[...]. The Guide to V7 is a good start, but I think at the bare minimum (since I agree that full documentation would be a huge task, though one that's apparently promised on a paper we link on our homepage), we should provide more information about the existing options beyond forcing the user to scroll through config_template.cfg or dig through the tutorials.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/775#issuecomment-540239931:615,config,configuration,615,https://su2code.github.io,https://github.com/su2code/SU2/issues/775#issuecomment-540239931,1,['config'],['configuration']
Modifiability,"GE_BUGREPORT ""su2code-dev@lists.stanford.edu""; | #define PACKAGE_URL ""https://github.com/su2code""; | #define PACKAGE ""SU2""; | #define VERSION ""4.1.0""; | /* end confdefs.h. */; | #include <ac_nonexistent.h>; configure:4707: checking for grep that handles long lines and -e; configure:4765: result: /bin/grep; configure:4770: checking for egrep; configure:4832: result: /bin/grep -E; configure:4837: checking for ANSI C header files; configure:4857: gcc -c -g -O2 conftest.c >&5; configure:4857: $? = 0; configure:4930: gcc -o conftest -g -O2 conftest.c >&5; configure:4930: $? = 0; configure:4930: ./conftest; configure:4930: $? = 0; configure:4941: result: yes; configure:4954: checking for sys/types.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for sys/stat.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for stdlib.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for string.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for memory.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for strings.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for inttypes.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for stdint.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for unistd.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4970: checking size of short int; configure:4975: gcc -o conftest -g -O2 conft",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:9991,config,configure,9991,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,1,['config'],['configure']
Modifiability,"Good catch! yep! I implemented an interesting/important change: Before, WALL_DISTANCE was computed using only the surfaces that you have identified as moving surfaces... as you can imagine that only works when you have a very simple problem (maybe an airfoil) but... if you have a problem with more Navier-Stokes markers together and you are moving only one of them the method doesn't work (e.g. wing-fuselage). For that reason I reimplemented WALL_DISTANCE which now is computed from all the solid surfaces and I also created DEF_WALL_DISTANCE that computes the distance from the surfaces that we are moving (as before). Frankly, I haven't found a situation in which DEF_WALL_DISTANCE outperforms the new solid WALL_DISTANCE... And, my suggestion is to eliminate DEF_WALL_DISTANCE in the future. For the time being I have added DEFORM_STIFFNESS_TYPE= DEF_WALL_DISTANCE to the config files to see if that solves the problem. Thanks!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/412#issuecomment-318673304:877,config,config,877,https://su2code.github.io,https://github.com/su2code/SU2/pull/412#issuecomment-318673304,1,['config'],['config']
Modifiability,"Good point about making the eigen-functions static. That makes it a lot more accessible in other parts of the code. Will include that in the changes along with the option name changes. . I like the idea about the static allocation, but I foresee a problem that you actually mention. If I convert the variables to be statically defined, I would have to make the eigen-functions accept statically defined arrays. Since most arrays in SU2 are dynamically allocated, this would cause some compatibility issues. . In general, I see the value in making a math library associated with matrix operations. Maybe you could pitch the idea in an issue and get feedback on it?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/570#issuecomment-433963723:300,variab,variables,300,https://su2code.github.io,https://github.com/su2code/SU2/pull/570#issuecomment-433963723,1,['variab'],['variables']
Modifiability,"H 1; | #define HAVE_MEMORY_H 1; | #define HAVE_STRINGS_H 1; | #define HAVE_INTTYPES_H 1; | #define HAVE_STDINT_H 1; | #define HAVE_UNISTD_H 1; | #define SIZEOF_SHORT_INT 2; | #define SIZEOF_INT 4; | #define SIZEOF_UNSIGNED_INT 4; | #define SIZEOF_LONG_INT 8; | #define SIZEOF_FLOAT 4; | #define SIZEOF_DOUBLE 8; | #define SIZEOF_VOID_P 8; | /* end confdefs.h. */; | #include <X11/Intrinsic.h>; configure:5409: result: no; configure:5409: checking for X11/Intrinsic.h; configure:5409: result: no; configure:5721: checking for /gshare/soft/code_saturne/4.0.0/prod/cgnslib_3.2.1/lib/libcgns.a; configure:5735: result: yes; configure:5755: checking for /gshare/soft/code_saturne/4.0.0/prod/cgnslib_3.2.1/include/cgnslib.h; configure:5769: result: yes; configure:6815: checking that generated files are newer than configure; configure:6821: result: done; configure:6952: creating ./config.status. ## ---------------------- ##; ## Running config.status. ##; ## ---------------------- ##. This file was extended by SU2 config.status 4.1.0, which was; generated by GNU Autoconf 2.69. Invocation command line was. CONFIG_FILES = ; CONFIG_HEADERS = ; CONFIG_LINKS = ; CONFIG_COMMANDS = ; $ ./config.status . on master. config.status:875: creating externals/tecio/Makefile; config.status:875: creating externals/metis/Makefile; config.status:875: creating externals/parmetis/Makefile; config.status:875: creating Makefile; config.status:875: creating externals/Makefile; config.status:875: creating Common/lib/Makefile; config.status:875: creating SU2_CFD/obj/Makefile; config.status:875: creating SU2_DOT/obj/Makefile; config.status:875: creating SU2_MSH/obj/Makefile; config.status:875: creating SU2_DEF/obj/Makefile; config.status:875: creating SU2_SOL/obj/Makefile; config.status:875: creating SU2_GEO/obj/Makefile; config.status:875: creating SU2_PY/Makefile; config.status:1047: executing depfiles commands; configure:8181: result:. ------------------------------------------------------------------------",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:15769,extend,extended,15769,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,2,"['config', 'extend']","['config', 'extended']"
Modifiability,"Hello @aditya12398 ,. The fifth line of the file you attached shows a call to `c++`, rather than `mpicxx`, which could cause those undefined references. Basically, the linker is not seeing your mpi libraries. I believe that, in order to use the `-Dcustom-mpi=true` flag, you may need to define your compiler environment variables (such as `$CC`, `$CXX`, `$LD`, `$MPICXX`, etc). Having both OpenMPI and MPICH installed on your system is complicating things, I think. Without some manual configuration of your system's environment, it may not be clear to meson/ninja which mpi implementation should be used. You may need to do some digging around on the internet to see how to properly resolve which MPI implementation gets used for different applications. -Paul",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1000#issuecomment-634825410:320,variab,variables,320,https://su2code.github.io,https://github.com/su2code/SU2/issues/1000#issuecomment-634825410,2,"['config', 'variab']","['configuration', 'variables']"
Modifiability,"Hello Pedro, thanks for your quick reply! ; More than the differentiation of the mesh deformation problem I was referring to what SU2_DOT does in the specific, at least in terms of workflow.; In fact, reading your answer I realise that maybe I'm misunderstanding the process done by SU2_DOT.; I thought that, in case of Disc. Adjoint, SU2 solver was already providing the _total_ sensitivity of the objective function with respect to the boundary grid nodes displacements. This already includes the contribution of the mesh deformation. given this, I thought that SU2_DOT was simply projecting such sensitivities on the FFD box point displacements chosen as design variables. But I cannot understand then why the need to include the mesh deformation problem within SU2_DOT.; Can you let me know about that please?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1017#issuecomment-640071772:665,variab,variables,665,https://su2code.github.io,https://github.com/su2code/SU2/issues/1017#issuecomment-640071772,1,['variab'],['variables']
Modifiability,"Hello Tobi,. Thanks for your quick reply! I'll address you doubts as follows. > I used this mesh <Testcases>/control_surface/mesh_ONERAM6_inv.su2 and the boundary marker names are a bit different in the mesh, compared to your provided config (WING vs LOWER_SIDE, UPPER_SIDE, TIP + SYMMETRY vs SYMMETRY_FACE). . Yeah, the mesh you are mentioning is the same. I simply united the TIP, LOWER_SIDE and UPPER_SIDE under the marker tag WING. > The initial transient through the domain based on the initial values is unphysical to some extend and if e.g. 'steady state' results are the same for both code versions .... the problem is not that big. Although it differs quite a bit in the temporal evolution tbh; In the results (also in the mail) it looks a bit like it approaches a steady state for Cl and CD. So maybe 1000 timesteps will tell us a bit more 🤔. I guess they converge eventually to the same values. I tried to compare the same case but steady (I attach the summary). Results in this case are fairly similar and (in my opinion) raise no warnings.; [Summary_steady_6_0_1.txt](https://github.com/su2code/SU2/files/3906039/Summary_steady_6_0_1.txt); [Summary_steady_6_2_0.txt](https://github.com/su2code/SU2/files/3906010/Summary_steady_6_2_0.txt). Regarding the unsteady case, I'm aware that this test may have little physics behind (especially if comparing the first timesteps) but I wanted to investigate the reason :). Results are too different and I think these might be one of the reasons behind some discrepancies I'm encountering in my FSI framework. ; My framework for FSI features a restart from a steady solution at t=0 and an unsteady simulation with imposed boundary of the wing marker. The discrepancies in that case are huge and are clearly wrong. I went back to the root and found this weird behaviour comparing the two versions so I thought this might be one cause. > Another thing: There is no tag 6.0.2 😕 ... 6.0.1 and then 6.1.0.. Yep you are right, the version is definitely 6.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/828#issuecomment-559850074:235,config,config,235,https://su2code.github.io,https://github.com/su2code/SU2/issues/828#issuecomment-559850074,2,"['config', 'extend']","['config', 'extend']"
Modifiability,"Hello everyone. I am working with SU2 on the feature_adap branch and have come across an issue during the execution of the mesh adaptation script. After following the standard installation procedure and verifying the installation (the exact same steps that @chesiv presented), I encountered a problem when running the mesh_adaptation_amg.py script. The command used was:. ```; python3 $SU2_RUN/mesh_adaptation_amg.py -f adapt_Mesh.cfg -n 4; ```; The script initiates the mesh adaptation process as expected, with the following output:. ```; SU2-AMG Anisotropic Mesh Adaptation. Mesh adaptation options:; PYADAP_COMPLEXITY : (30000, 60000, 120000); PYADAP_SUBITE : (2, 2, 2); PYADAP_SENSOR : GOAL; PYADAP_HMAX : 500.0; PYADAP_HMIN : 1e-9; PYADAP_HGRAD : 1.8. ./adap exists. Removing old mesh adaptation in 10s.; The ./adap folder was deleted. Generating GMF background surface mesh.; Initial CFD solution is provided.; ```; However, no _adap\ite0_ folder gets created. ; The log.err file in the _adap/ini_ directory provides this traceback:. ```; Traceback (most recent call last):; File "".../mesh_adaptation_amg.py"", line 111, in <module>; ...; RuntimeError: ...; Error in TokenizeString(): two or more options before an ""="" sign in the configuration file.; terminate called after throwing an instance of 'int'; ...; *** Process received signal ***; Signal: Aborted (6); Signal code: (-6); ...; ```. The critical part of this error seems to be the Error in TokenizeString() message, suggesting an issue with parsing the configuration file. This error typically indicates a syntax problem, such as having multiple options on a single line without proper separation by an equal sign (=). However, upon reviewing _adap/ini/config_CFD.cfg_, was unable to find any lines that clearly violated this syntax rule. Could this error be indicative of a more subtle issue within the configuration file, or might it be related to specific aspects of the feature_adap branch? Any insights, suggestions, or guidance ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/948#issuecomment-1847333809:128,adapt,adaptation,128,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-1847333809,4,['adapt'],['adaptation']
Modifiability,"Hello, ; You are right, this pr cannot solve the problem but just make the solution look reasonable.; For some complicated case, it is hard to converge, not like in the simple cases.; I have read the relevant code and book, and I think maybe a good way is to rewrite the bc code and move the nonzero normal components limitation to where the flux are calculated. Or we can store the flux of the points on the sym bc, and in CFVMFlowSolverBase<V, R>::BC_Sym_Plane we just use the stored flux without recalculation.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/2174#issuecomment-1868453319:259,rewrite,rewrite,259,https://su2code.github.io,https://github.com/su2code/SU2/pull/2174#issuecomment-1868453319,1,['rewrite'],['rewrite']
Modifiability,"Hello,. So, to clarify, there were two issues:. 1) With the old commit (382e82f), we were seeing the assertion failure at line 1881 of numerics_structure.cpp, but only with the very large mesh (180 million cells). 2) With the newer commit (c093a62), we were seeing the assertion failure at line 294 of C2DContainer.hpp, which was occurring even with smaller meshes (7 million cells). The solution to (2) appears to be to change `geometry->node[iPoint]->GetnNeighbor()` to `geometry->node[iPoint]->GetnPoint()` at line 3759 of CEulerSolver.cpp, in the `CEulerSolver::SetUpwind_Ducros_Sensor()` method. I made this change locally, and attempted to run on our large mesh. Issue (2) seems to be fixed, but we still run into issue (1). I have now gone through the read restart routines, and have found a potential issue:. For reference, the restart file for our large mesh with averaging data included consists of:; 39 fields * 75,107,967 points = 2,929,210,713 variable values (which is larger than `INT_MAX`). Beginning at line 3931 of CSolver.cpp, in method `CSolver::Read_SU2_Restart_Binary(...)`, we have the following:. ```; int *blocklen = new int[geometry->GetnPointDomain()];; int *displace = new int[geometry->GetnPointDomain()];; int counter = 0;; for (iPoint_Global = 0; iPoint_Global < geometry->GetGlobal_nPointDomain(); iPoint_Global++ ) {; if (geometry->GetGlobal_to_Local_Point(iPoint_Global) > -1) {; blocklen[counter] = nFields;; displace[counter] = iPoint_Global*nFields;; counter++;; }; }; MPI_Type_indexed(geometry->GetnPointDomain(), blocklen, displace, MPI_DOUBLE, &filetype);; ```; The problem here is that for our case, where `iPoint_Global` can get up to 75,107,967 and `nFields` = 39, the value assigned to `displace[counter]` in the loop can over-run `INT_MAX`. This would result in potential garbage / incorrect displace values being passed to `MPI_Type_indexed(...)`. Unfortunately, simply changing `displace` to a `long int *` won't work, as the expected argument type for `",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/949#issuecomment-622026420:957,variab,variable,957,https://su2code.github.io,https://github.com/su2code/SU2/issues/949#issuecomment-622026420,1,['variab'],['variable']
Modifiability,"Hello,; As a simple user, when I forget to save the last history before continuing a simulation I am very frustrated, because it is lost forever... Since the new history file erases the previous one.; Also, making these history backups is not very practical...; I would very prefer an option in the config file like: ""when RESTART_SOL= YES append to the history or not?"".; I think it would not be difficult to set another variable like: ""max_it must be counted from the beginning or from the last launch?"".; I agree it makes it a bit more complex, but not too much I think :)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/99#issuecomment-103369490:299,config,config,299,https://su2code.github.io,https://github.com/su2code/SU2/issues/99#issuecomment-103369490,2,"['config', 'variab']","['config', 'variable']"
Modifiability,"Hey @pcarruscag !. Thanks for the suggestions. . 1) That's a good point. I will change the option names to be more specific. . 2) Not a 100% certain what you mean by this. To be clear, instead of allocating memory using the keyword new (MeanReynoldsStress = new su2double* [3];), I should be declaring them statically (su2double MeanReynoldsStress[3][3])? I was following the variable declaration norms I saw in the code. But I guess those were usually for allocations to nDim. Is that what you are suggesting?. 3) I have generalized the Eigen-value functions to n order matrices now. But I think I am going to keep them in the numerics class. Since it seems like that is where they would be most useful. Would you suggest otherwise?. Cheers,",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/570#issuecomment-433784029:376,variab,variable,376,https://su2code.github.io,https://github.com/su2code/SU2/pull/570#issuecomment-433784029,1,['variab'],['variable']
Modifiability,"Hey Rocco,. > And both versions are/were on the develop branches -> what exactly do you refer to here: config-files, code, mesh. The code tags 6.0.1 and 6.2.0 refer to specific master-commits of the code. So I want to know what is exactly of the develop branch, can't be the code if you understand the tags as I do. Maybe you refer to the develop code at the time where these tags were introduced. But maybe sth different. > I guess they converge eventually to the same values. I tried to compare the same case but steady (I attach the summary). Results in this case are fairly similar and (in my opinion) raise no warnings. That is good to hear. ; Luckily @cvencro (Thanks for that 👍 ) ran some tests and found that #740 (which rewrites Euler Wall boundaries for compressible and incompressible flows ... which was me btw) introduces the changes you see. The Euler wall for compressible is changed a bit in the way the boundary condition is enforced. Upon convergence both version should recover (close to) the same value. If the results in a steady state are the same/very-similar and if an unsteady simulation at low enough Reynolds-number converges to the same steady result (or oscillate in the same bounds) -> I would say it is simply some purely numerical effect based on the unphysical initialization and different treatment of the euler wall boundary. . 1 thing one could test additionally is to force a very high convergence in each physical timestep, i.e. usually one converges ~3 orders of magnitude in each ts -> now try converging until residual stalling in each ts. If the code versions get the same/closer results in the temporal evolution my euler wall boundary explanation would be quite reasonable.; Together with the long running unsteady simulation proposed above, I would feel more comfortable to judge. @cvencro (bringing the conversation to this place 😉 ) concerning the pitching case: the `if (dynamic_grid)` statements in the 'old' version are not necessary as that is handle",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/828#issuecomment-562621057:103,config,config-files,103,https://su2code.github.io,https://github.com/su2code/SU2/issues/828#issuecomment-562621057,2,"['config', 'rewrite']","['config-files', 'rewrites']"
Modifiability,"Hi @Eduardo-Carvalho ,. your request is now merged into the develop branch and you can test/use it if you like. It will be in one of the next releases, if no further issues occur.; Handling is intuitive: Just set your restart iteration in the config file as you would do normally and activate the restart solution option. Furthermore, place your restart file (two in the case of 2nd order time integration) in the same directory as the config file of your test case. Then you are set up and can run the scripts as normal. ; For more details, I refer to pull request #964. . Best; Steffen",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/909#issuecomment-630289600:243,config,config,243,https://su2code.github.io,https://github.com/su2code/SU2/issues/909#issuecomment-630289600,2,['config'],['config']
Modifiability,"Hi @Nicola-Fonzi,. I'm not 100% sure of the reasons behind the GetFSI_Simulation criteria. I'd imagine that the nMarker_Fluid_Load might have been included there to make sure that a problem is treated as FSI only if there is transfer of load from the fluid to the structural domain, even if both zones existed independently in the config. But since the GetFSI_Simulation check is set up as an ""or"" rather than ""and"", as long as one of them is satisfied, the logic will be true for an FSI simulation, which might be sufficient for your application?. For the velocity transfer, I agree with Rafa that it would be better if you could also transfer the velocity from the external structural solver. If an external structural solver is used for dynamic analysis, it probably can output the structural velocities as well as the structural displacements? I left the methods for the recalculation of the grid velocity using finite differences in the code to support fluid-only problems with dynamic grid motion, I wouldn't suggest this as the method for FSI problems. For primal analysis, results from both methods agree with FSI benchmark cases but if you are interested in adjoint analysis at any point, transferring the velocity information from the structural domain directly to the fluid domain gives a significant simplification and improvement to the gradients.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1174#issuecomment-778368854:331,config,config,331,https://su2code.github.io,https://github.com/su2code/SU2/pull/1174#issuecomment-778368854,1,['config'],['config']
Modifiability,Hi @TobiKattmann . I am OK if we clearly explain the changes in the config template as my main concern is with the users side.; Thanks!. Eduardo,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/735#issuecomment-513959331:68,config,config,68,https://su2code.github.io,https://github.com/su2code/SU2/issues/735#issuecomment-513959331,1,['config'],['config']
Modifiability,"Hi @antares190,. Glad to see that things seem to be starting to work for you. We (Brian) are trying to improve this capability in the solver and any experiences / suggestions / help will be welcome. With that said, this seems like an interesting result. Would you mind submitting it (or other pictures that you like better) so the SU2 Foundation can use it to show this capability to others in the future? The link where you can do this is here<http://su2foundation.org/su2-promotional-material/?utm_source=hs_email&utm_medium=email&utm_content=76584389&_hsenc=p2ANqtz-9fEq2awKk2vd155cCcN_N4mWBCZK-rJ-TqNsZhqSJs-VWn-w7q-H6w8sdiA3LyuOTqlK4eqZhFFstKi-LQFyyGqYPdkwYc9JsNdB1yyd7pqMwTFzA&_hsmi=76584389>. Thanks a lot,. Juan. On Apr 29, 2020, at 1:38 PM, antares190 <notifications@github.com<mailto:notifications@github.com>> wrote:. Thanks Brian,; my bad, I misinterpreted the carpets / logs structure. I successfully ran a test of a very simple case. In the results there are some small artifacts, but the shocks are resolution improved consistently after mesh adaption.; Thanks for the support. [Comparison]<https://user-images.githubusercontent.com/41752169/80644172-84a7a580-8a69-11ea-9f16-58e98c808b73.png>; [ComparisonMesh]<https://user-images.githubusercontent.com/41752169/80644174-85403c00-8a69-11ea-819f-2ac00550a089.png>. —; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/948#issuecomment-621450497>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AA5FFRCGLBHJCB3FS4JSSV3RPCF5RANCNFSM4MQACOXA>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/948#issuecomment-621483859:1058,adapt,adaption,1058,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-621483859,1,['adapt'],['adaption']
Modifiability,"Hi @bmunguia ,; I was in the same situation as @MiracAydin1, so thanks for the hint. Nevertheless I'm having some problems. I followed your instructions to install the branch:. 1. downloaded the [feature_adapt_sst](https://github.com/su2code/SU2/tree/feature_adap_sst) branch.; 2. Used meson to configure the build; `./meson.py build -Denable-autodiff=true -Denable-directdiff=true`; 3. Added the environment variables to the .bashrc; 4. ninja build.; `./ninja -C build install`. The build didn't show any errors, only few warnings during meson ( `gcc1: warning: command line option ‘-Wno-non-virtual-dtor’ is valid for C++/ObjC++ but not for C`). When I try to run the mesh_adaption (or even run simply the solver through parallel_computation.py):. `$SU2_RUN/mesh_adaptation_amg.py -f invCyl.cfg -n 6`. It immediately shows an error (without even showing the SU2 splash screen) :; `Traceback (most recent call last):`; ` File ""/usr/local/bin/mesh_adaptation_amg.py"", line 38, in <module>`; ` import SU2`; ` File ""/usr/local/bin/SU2/__init__.py"", line 14, in <module>`; ` from SU2 import amginria`; ` File ""/usr/local/bin/SU2/amginria/__init__.py"", line 4, in <module>`; ` from .interface import *`; ` File ""/usr/local/bin/SU2/amginria/interface.py"", line 41, in <module>`; ` import _amgio as amgio`; `ImportError: No module named _amgio`. Am I missing any dependencies? ; Please note that I previously compiled SU2 master branch without issues, and have already installed mpich, numpy, scipy.; Any help would be really appreciated.; Thanks",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/948#issuecomment-619332650:295,config,configure,295,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-619332650,2,"['config', 'variab']","['configure', 'variables']"
Modifiability,"Hi @cvencro , I think it would be good to add that Testcase to the regression tests to 'guard' the code. ; I actually wanted to do that real quick but it guess that with `SINGLEZONE_DRIVER` one cannot access `TIME_ITER`, only `EXT_ITER` with the` .test_iter` variable of the python Testcase class. Not sure if that is addressed in #724 , maybe @rsanfer or @talbring can give a quick info as this is probably affecting all unsteady regression tests. . Concerning the Testcase repo: You can simply open a PR for the develop branch of the Testcase repo, and refer to the corresponding PR here (and vice versa). As far as I know the Testcase repo is not protected, i.e. you can merge without any check. And as it is just one added mesh and no other change you could do it right now from my point of view. Another point: What about the rotating_frame for incompressible flow? If it is untested I would like an error catch in place that this feature can't be used out of the box.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/767#issuecomment-527167827:259,variab,variable,259,https://su2code.github.io,https://github.com/su2code/SU2/pull/767#issuecomment-527167827,1,['variab'],['variable']
Modifiability,"Hi @pcarruscag, just a small follow-up to my comment in the code section concerning the new adjoint implementation that might also help here (either by using it directly or just for getting some ideas). What I would like to change is in fact not the `CDiscAdjSolver` (which I find is very good) - but I'd like to propose some changes for the *interface* to the AD tool. And some subsequent stuff.; It will allow for a more direct control of derivatives which is favourable in case one deals with multiple zones, multiple sets of conservative variables, geometry coordinates in case of FSI, and so on. And of course in terms of performance as one needs only one tape that one can keep during all iterations, regardless of what their variables might be. In case you are interested, take a look at the implementation in [su2code:sc_develop](https://github.com/su2code/SU2/tree/sc_develop). I'll open the PR as soon as @talbring opened his one for his great rework on input/ouput. As for this PR, let me wait a second if we can clear up the issue concerning the registration and I'll leave a small review afterwards.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/615#issuecomment-457582842:542,variab,variables,542,https://su2code.github.io,https://github.com/su2code/SU2/pull/615#issuecomment-457582842,2,['variab'],['variables']
Modifiability,"Hi @pcarruscag,; You are right, it shares a lot of code with previous PR. Here constants does not change. Differences are as follows - . 1- It has different pressure flux definition (new expression); 2 - Here sum of squares of velocity components were needed for left and right state; 3- removed few variables and added few.; 4- Also left and right state split Mach numbers are Mach number polynomials only (for programming purpose) without pressure terms. Previously SLAU and SLAU2 scheme have already been implemented in the code separately. I mean some of these sucessive schemes share a lot of common formulation but differ with some expressions, constants etc. ; So it may be fine to keep them separate. . I will see your advice and further look into similar variation implementation in the code (sorry if I missed out some simple point you mentioned). . Thanks ; Amit",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/631#issuecomment-446730390:300,variab,variables,300,https://su2code.github.io,https://github.com/su2code/SU2/pull/631#issuecomment-446730390,1,['variab'],['variables']
Modifiability,"Hi @pcarruscag,; thank you very much for the insight and the well thought proposed solution. I wasn't aware that there was such a loss in performance, it seems clear that something needs to be done. The only question I have is regarding the following comment . > There are no free lunches and this performance improvement would come at the cost of losing the ability to have different types of variables in different parts of the domain. I'm using this feature more and more, I was planning to extend it in the structural solver to remove the `if fsi` statements, and I also used it in the rework of the mesh solver, as defining variables at the interface only reduces greatly the memory footprint (sort of like the node-vertex structures in geometry). You mention there are options to keep this versatility, how difficult do you think would be to implement them?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/716#issuecomment-507998889:394,variab,variables,394,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-507998889,3,"['extend', 'variab']","['extend', 'variables']"
Modifiability,"Hi @rois1995 . For now, I'm ignoring all TKE in Total Energy in personal research. I don't remember the details clearly. ; The problem was that the enthalpy added TKE was stored in the primitive variables. ; When I tried to fix it, the problem was when the enthalpy added TKE was stored in the primitive variables. For the Roe scheme in convective flux calculations (not sure about other flux scheme), the Roe speed of sound is calculated using enthalpy. But as I mentioned above, the stored enthalpy is higher than other simulation because of TKE. I thought it make a problem.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1851#issuecomment-2245163889:195,variab,variables,195,https://su2code.github.io,https://github.com/su2code/SU2/issues/1851#issuecomment-2245163889,2,['variab'],['variables']
Modifiability,"Hi @rois1995. The LM model code under the development clearly has some problems. I've not finished yet all validation cases for commonly used. So, I can't help with the E387 profile problem. but, I think I can give some helpful comments. . Check the numerical scheme which you used. like Roe and L2Roe, AUSM and SLAU. In my case, I didn't think to use the low dissipation scheme because I thought the code was wrong. I upload the configure file for the T3A flat plate case, which I used.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1592#issuecomment-1111261534:430,config,configure,430,https://su2code.github.io,https://github.com/su2code/SU2/pull/1592#issuecomment-1111261534,1,['config'],['configure']
Modifiability,"Hi @themrdjj,; Thank you for the feedback, there was already a similar report in #796 (which incidentally went stale and was closed), I will try to do something about it, or if you would like to contribute code to the project I can point you to right place to add an error message. Meanwhile my best advice is to not start a config from scratch until you know SU2 very well (and even then...) look for a test case that uses similar features and go from there.; The minimal config is the one in Quickstart, the template is more of a catalog :) I don't think we'll ever have a unified minimal config, SU2 does many things, some mutually exclusive.; Convective options are reasonably well documented here: https://su2code.github.io/docs_v7/Convective-Schemes/; The output messages before ""Begin Solver"" can be helpful (although in this particular case you would need to know what to expect). Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/842#issuecomment-566642727:325,config,config,325,https://su2code.github.io,https://github.com/su2code/SU2/issues/842#issuecomment-566642727,3,['config'],['config']
Modifiability,"Hi @timjim333 ,. Exactly (concerning your first question). . For the %s : In your initial post you stated that `mpirun --use-hwthread-cpus -np 12 SU2_CFD turb_ONERAM6.cfg` worked for you. So %s is simply the place-holder for the SU2 module together with the configure script. Which in your case would be `SU2_CFD turb_ONERAM6.cfg` . But `parallel_computation.py` will also call `SU2_SOL turb_ONERAM6.cfg` for you after the solver routine to create output files for visualization. ; If you take a look into the `interface.py` (as in my previous post) and the `parallel_computation.py` you'll find exactly how its done. Cheers, Tobi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/526#issuecomment-395712721:258,config,configure,258,https://su2code.github.io,https://github.com/su2code/SU2/issues/526#issuecomment-395712721,1,['config'],['configure']
Modifiability,"Hi Economon,. I encountered an issue very similar to what Auzbaig reported: the error message ""OBJECTIVE_FUNCTION: invalid option value EntropyGeneration"" during optimization with SU2. (I am using SU2 version 8.0.1 ""Harrier.""). After thoroughly examining the existing Python optimization framework, I found that one of the steps in the optimization chain is generating different config.cfg files, with a focus on DV_VALUE and OBJECTIVE_FUNCTION. DV_VALUE controls the geometry deformation;; OBJECTIVE_FUNCTION determines the type of objective/constraints.; Then the framework calls SU2_CFD and SU2_DOT to obtain performance metrics or gradient information.; As you mentioned, ""You might need to run updateHistoryMap.py to register new outputs with Python."" Initially, I thought it meant simply providing a new input for OBJECTIVE_FUNCTION in the Python optimization framework. However, it seems that this may not work at the C++ level. To verify this, I ran $ SU2_CFD your_config.cfg -d and observed all available history outputs. However, I suspect that OBJECTIVE_FUNCTION cannot use every history output, meaning that the adjoint solver might not recognize some objective functions. Does this imply that additional modifications in the C++ code are required?. Additionally, I would appreciate more information regarding CUSTOM_OBJFUNC. From TestCases/user_defined_functions/lam_flatplate.cfg, I understand that CUSTOM_OBJFUNC allows combinations of existing OBJECTIVE_FUNCTIONs and can also utilize CUSTOM_OUTPUTS. The flexibility of CUSTOM_OUTPUTS seems to enable the construction of various desired variables. However, I am unsure whether using OBJECTIVE_FUNCTION= CUSTOM_OBJFUNC along with CUSTOM_OUTPUTS can entirely replace the need for additional modifications in the C++ code. Since I’m not very proficient in C++, I would greatly appreciate your guidance. Sincerely,; Tongtong",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/889#issuecomment-2324575133:379,config,config,379,https://su2code.github.io,https://github.com/su2code/SU2/issues/889#issuecomment-2324575133,2,"['config', 'variab']","['config', 'variables']"
Modifiability,"Hi Eduardo,. both, 'symmetry plane' and 'symmetry as the slip wall' should work in the code (upon fixing this) and it should be made clear (e.g. in the config_template.cfg) what the BC is suitable for, independent of how it is named in the end. ; The simplest solution is probably the patch I provided together with a short note in the config_template (maybe even a reference to this issue), as both 'options' will work as expected (using the very same code). It will basically 'restore' the behaviour of MARKER_SYM of before the fix in #657. The downside is some more computational cost (in case of a plane) which has to be done for each vertex on the marker. I cant say to which extend this takes more time but I would guess it is not too costly. Depends on the case as well. I can do a little check with your case here. . That's it for the diplomatic part :) (Please take the following with a grain). For me a symmetry has to be a line or plane. To cite Jiri Blazek's book 'Computational Fluid Dynamics'(...) 3rd edition using a screenshot:. ![blazekbook](https://user-images.githubusercontent.com/31306376/61662377-9ab05a80-acce-11e9-85bf-5998db204d92.png). The chapter is called 'symmetry plane' which already is kinda biased. But there is no 'slip wall for viscous flow' mentioned to my knowledge. In another book (from Ferziger&Peric, which I only have in german) symmetry is only used in the context of symmetry planes as well. ; To me, symmetry BC's are also linked to visualization using mirroring. And mirroring (as the word is commonly meant) is only possible along planes and its little brother, the straight line. I can be wrong or it might be a question of research background. So how to proceed? Trial by combat might have some unpleasant aftermath for the winner so we might go the democratic way and do a poll :) . Cheers, ; Tobi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/735#issuecomment-513957018:681,extend,extend,681,https://su2code.github.io,https://github.com/su2code/SU2/issues/735#issuecomment-513957018,1,['extend'],['extend']
Modifiability,"Hi Giulio,; Thank you for the feedback. I inherited some of this code from a previous student of my PhD supervisor and I thought the same when I saw the CSymmetricMatrix class. However, as I understand it, CSysMatrix implements a block sparse format and here we have a simpler dense format. Another big difference is that CSymmetricMatrix does not need to be used in parallel. But I agree that making these two classes related somehow would be better, so I am open to suggestions.; Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/555#issuecomment-406516746:42,inherit,inherited,42,https://su2code.github.io,https://github.com/su2code/SU2/pull/555#issuecomment-406516746,1,['inherit'],['inherited']
Modifiability,"Hi JSmith86,. I really appreciate your effort in cleaning up the changes. But it looks like as if there are still a lot of changes in other parts that are not related to the things you describe. Furthermore I really request you to split this up in multiple commits so that it is immediately clear what you did in each single one (this can be done quite simple with a proper diff tool like [meld](http://meldmerge.org/)). Let me emphasize that this is not to bother you in any way but rather to ease understanding and maintainability. I know from my own experience that this requires some additional work, but in the end it certainly pays off. . Thanks!; Tim",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/412#issuecomment-315320576:517,maintainab,maintainability,517,https://su2code.github.io,https://github.com/su2code/SU2/pull/412#issuecomment-315320576,1,['maintainab'],['maintainability']
Modifiability,"Hi Soumen,. As Tom said, the routines are all in place and I have been putting them; together for solution interpolation from one mesh to another for unsteady; simulation as post-processing step. So probing at a particular location for; unsteady solution can be also done with this framework. The probe search; implementation is in place for 2D configuration currently. It will be; extended to 3D and probably available in the main branch in the next 2; months.; The implementation so far is in feature_MeshInterpolation branch if you; want to take a look. Sravya. On Thu, Nov 2, 2017 at 10:09 PM, Thomas D. Economon <; notifications@github.com> wrote:. > Hi Soumen: yes, this is something that the developers are actively working; > on at the moment (in particular, @sravya91 <https://github.com/sravya91>; > has been taking the lead on this). It is true that most of the ingredients; > are already available in SU2 (fast searches, interpolation routines, etc.),; > but the trick is combining them all and making it general.; >; > Do you have any other requirements beyond simple probes? I am guessing we; > should have something available in the next few months, but it's not set; > yet.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/issues/466#issuecomment-341623660>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/AHenII5B0Xtb2U_hj2vbBesf5Oc51uvzks5syqAEgaJpZM4QPYh8>; > .; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/466#issuecomment-342266341:345,config,configuration,345,https://su2code.github.io,https://github.com/su2code/SU2/issues/466#issuecomment-342266341,2,"['config', 'extend']","['configuration', 'extended']"
Modifiability,"Hi Tim,. Thanks!. I totally agree on the fact that Python-related functionalities could be in a separate file for code clarity. Anyway, considering only the C++ structure, those functionalities are still members of the CDriver (and all child classes). So if you are OK with the fact that having members of the same C++ class in different cpp files, I am OK too. . However, if you mean creating a new class for the Python wrapper (like CPyWrapper or whatever), and leave the CDriver ""clean"", this might be more tricky. Indeed, since the wrapper has to be a top-level class, it is better to have access to all the other main classes (config, geometry, solver, ...) and the CDriver was the perfect candidate (it instanciates all of them). So now if we create a new top-level class next to the CDriver, the direct link with all those classes is lost. Basically we will have to create accessors like CDriver::GetConfig(), CDriver::GetGeometry(), ... that will return the different containers to be used by the wrapper. Obviously this is possible but not in a short time, besides this might be a significant change in the top-level code structure. We could also think about exposing thoses CConfig, CGeometry, ... classes to Python in addition to just the driver, I already made some local tests and it worked great but this approach is less user-friendly. David",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/488#issuecomment-352045091:632,config,config,632,https://su2code.github.io,https://github.com/su2code/SU2/pull/488#issuecomment-352045091,1,['config'],['config']
Modifiability,"Hi Wally, ; I have run some axisymmetric cases earlier for pressure distribution (Cp) computation over typical payload fairing configuration (with older versions of SU2). Pressure distribution seemed to be fine with earlier runs (and also it matched well with other codes). ; Issue popped up while trying to compute heat flux for axisymmetric problems. I have seen folks and students running their cases with axisymmetric formulation. Now the issue has surfaced clearly, it need to be fixed asap.; How is solution of the case, you have been trying? . Best; Amit",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1063#issuecomment-699627809:127,config,configuration,127,https://su2code.github.io,https://github.com/su2code/SU2/issues/1063#issuecomment-699627809,1,['config'],['configuration']
Modifiability,"Hi all, . After the initial excitement of clearing all tabs and trailing whitespaces... I guess it is more reasonable to follow @pcarruscag proposal:; > What about running the solution you propose only on subfolders? i.e. on src/something/ . I now trimmed all `C*.cpp`, `C*.hpp` and `C*.inl` files in `SU2_CFD` which is equivalent to all restructured files in the Sub-folders. I added a basic script `replace-tabs-...sh ` in `externals/utils` which provides this functionality. I would enhance that script if this is the way to go.; The commit size now shrunk down to ~4k changed lines. Possible merge problems will be much smaller. . I found to have to no problem when merging the develop first -> clearing all tabs/whitespaces in the feature_branch with the provided script -> merge this develop_noWhitespaces using the `--strategy-option=ours` option. Merge conflicts will be purely due to tabs/whitespaces therefore one always wants the own code in case of conflict, as all conflicts with the develop related to other stuff were already resolved in the first merge. . Now that the commit is a lot smaller, there should be even less problems. Maybe some folks will have no problems at all. . After some back and forth in the commits I briefly chatted with @talbring to do a git rebase / squash to not have these huge commits in the history. Otherwise one could open a new & clean PR if we can agree on an approach here to keep the discussion in one place.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/808#issuecomment-553412130:486,enhance,enhance,486,https://su2code.github.io,https://github.com/su2code/SU2/pull/808#issuecomment-553412130,1,['enhance'],['enhance']
Modifiability,"Hi all,. as with the restructuring of the output classes, we should find a common level of abstraction for all the different physical problems we might want to have. Right now there isn't even a unified way of specifying the kind of problem for each zone (what is fluid, what is solid etc) and the kind of coupling. This might also affect the actual implementation/restructuring since we somehow have to decide what driver we have to instantiate and so on. Hopefully we can gather all the people involved to have a discussion on that. Since we have a lot of people working in their branches on multizone problems we should tackle that better sooner than later. As Edwin already suggested, maybe it is a good idea to put some people in charge of organizing some of the bigger structural changes. Furthermore in case some people don't know, we have a slack channel for the dev team. I think that makes it easier to communicate, arrange meetings, discuss problems and ask questions. In case you need an invite, let me know, everybody who wants to contribute is welcome. Thanks for the discussion, I still think that communication is the key of success !. Tim. On Sep 13, 2017 10:30 AM, Edwin van der Weide <notifications@github.com> wrote:. Hi Tom,. Sounds like a plan then to have a look at CIntegration to see what we can do to generalize the time integration. I definitely want to help with this, but I don't think I am the appropriate person to take the lead, because I simply don't have a good overview of all the multi-physics options. Tom, are you willing to take the lead for this?. Furthermore, it is good to have other people involved as well, preferably with detailed knowledge of the different disciplines. Any volunteers?. Thanks,. Edwin. —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/437#issuecomment-329096830>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AEtI5MkXdqhqP",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/437#issuecomment-329146567:306,coupling,coupling,306,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-329146567,1,['coupling'],['coupling']
Modifiability,"Hi everyone,; I was tring to use the mesh adaptation feature but the whole procedure is not clear to me.; Following the previous indications I:. 1. downloaded the `feature_adapt branch`. 2. downloaded the Adaptive 2D NACA 0012 example (https://pyamg.saclay.inria.fr/pyamgexamples.html#2dnaca): `adap_NACA0012.cfg`, `mesh_NACA0012_inv.su2`, `NACA0012_ini.dat`. 3. added the following lines to the config:; ```; % Type of sensor used for adaptation; % Options include GOAL (adjoint-based), MACH, PRES; PYADAP_SENSOR= GOAL; % Objective function used for goal-oriented adaptation; OBJECTIVE_FUNCTION= LIFT; % Maximum cell size for adaptation; PYADAP_HMAX= 500.0; % Minimum cell size for adaptation; PYADAP_HMIN= 1e-9; % Gradation factor (typically 1.2-1.8); PYADAP_HGRAD= 1.8; % Norm used for adaptation; % 1.0 or 2.0 recommended for inviscid flows; % 4.0 recommeneded for viscid; ADAP_NORM= 4.0; % Approximate mesh size (NPOI) at each level; PYADAP_COMPLEXITY= (30000, 60000, 120000); % Number of adaptations performed at each level; PYADAP_SUBITE= (3, 3, 3); ```. 4. run the following command: `$ python3 SU2_RUN/mesh_adaptation_amg.py -f adap_ONERAM6.cfg -n 8`. The response I have obtained is the following:; ```; SU2-AMG Anisotropic Mesh Adaptation. Mesh adaptation options:; PYADAP_COMPLEXITY : (30000, 60000, 120000); PYADAP_SUBITE : (2, 2, 2); PYADAP_SENSOR : MACH; PYADAP_HMAX : 500.0; PYADAP_HMIN : 1e-9; PYADAP_HGRAD : 1.8; PYADAP_FLOW_ITER : (2999, 4999, 6999); PYADAP_ADJ_ITER : (2999, 4999, 6999); PYADAP_CFL : (10.0, 15.0, 20.0); PYADAP_RDG : NO. The ./adap folder was deleted. Generating GMF background surface mesh.; ## WARNING: MISSING SU2 MESH FILE KEYWORD: NCORNERS=.; Initial CFD solution is provided.; ```. As expected, a `./ADAP` folder was created, containing these docs: `amg_back_meshb`, `config_CFD.cfd`, `log.err`, `log.out` (sizes 0 byte), `mesh_NACA0012_inv.su2` (link to the mesh), `NACA0012_ini.dat` (link to the file.dat). Did I perform the procedure correctly? Or did I m",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/948#issuecomment-737134105:42,adapt,adaptation,42,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-737134105,8,"['adapt', 'config']","['adaptation', 'adaptations', 'config']"
Modifiability,"Hi there,. I went ahead and created a dummy geometry, that is:; 1. I altered the planform so that the sweep, twist, dihedral, taper... are now different from the actual wing; 2. I replaced the airfoil by the NASA SC(2)-0712. The dummy wing has a double planform defined as:; - semi span = [5; 10]; - taper = [0.55; 0.35]; - dihedral angle = [5°; 2.5°]; - twist angle = [1°; 0°; -1°] (given for root, kink and tip airfoil sections); - sweep angle at LE = 25°; - Aspect ratio = 11.8; - semi area = 38. I defined the reference length as:; - reference (semi) area = 45; - reference chord = 3; - reference (semi) span = 15. The flight conditions remained unchanged:; - Mach number: 0.78; - Temperature = ~217 K; - Reynolds number: ~19 millions; - AoA = 0°. I created the exact same grid as before (same number of cells, same progression), ensuring my first cell was at y+<1. Things is, this time, SU2 did not have any trouble converging and computed the right z-projected area... I checked the results with another software and the pressure distribution (taken along the chord near the kink) match, see attached Figure. I am attaching the dummy configuration file (dum.txt) as well as the mesh (dum_mesh.txt) if it can be of interest to you. The mesh is a .geo gmsh file. To get the mesh, simply open with gmsh and click mesh 3D (or, from the console: gmsh dum_mesh.txt -3). At this point, I think that my problem might be related to the actual wing airfoil geometry, which is somehow not well pre-processed by SU2... I will continue investigating and keep you posted if I find a solution. Thank you for the time you took reading this issue.; ![cp](https://user-images.githubusercontent.com/39187559/40602255-3de183ae-6258-11e8-9aba-6c8d374dc34e.png); [dum.txt](https://github.com/su2code/SU2/files/2044072/dum.txt); [dum_mesh.txt](https://github.com/su2code/SU2/files/2044073/dum_mesh.txt)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/533#issuecomment-392442127:1140,config,configuration,1140,https://su2code.github.io,https://github.com/su2code/SU2/issues/533#issuecomment-392442127,1,['config'],['configuration']
Modifiability,"Hi, thanks for this interesting discussion. Just a reminder... there is a third place where the default values are stored! the config_template.cfg file. I have had similar problems to what @erangit is describing with the multiple definition of the default values in different places, in fact, sometimes is not clear what is the minimum number of parameters that you can use in a config file. I think that the ideal scenario would be to use the config_template.cfg file as the default value keeper and create subroutines in C++ and python that update the defaults with the existing information in that file. Remember that config_template.cfg is always required otherwise the user doesn't know that are the existing options. By the way... this discussion reminds me that we should update SetRunTime_Options(void). This is an incredible useful small subroutine to modify the software parameters during runtime. EXT_ITER is the only parameters currently accepted but in the near future we should add all or most of them.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/520#issuecomment-381411950:379,config,config,379,https://su2code.github.io,https://github.com/su2code/SU2/pull/520#issuecomment-381411950,1,['config'],['config']
Modifiability,"Hi,. Thank you for your quick answer, It indeed seems that I had some parameters that were passed that did not match su2 version 7.0.3. I am experiencing an issue while running the mesh adaptation process in SU2. The process starts but fails during the mesh generation phase, leading to a FileNotFoundError. I am looking for assistance in resolving this error.; `; SU2-AMG Anisotropic Mesh Adaptation. Mesh adaptation options:; PYADAP_COMPLEXITY : (100, 200, 300); PYADAP_SUBITE : (2, 2, 2); PYADAP_SENSOR : MACH; PYADAP_HMAX : 200; PYADAP_HMIN : 1e-8; PYADAP_HGRAD : 1.3; PYADAP_RESIDUAL_REDUCTION : (3, 3, 3); PYADAP_FLOW_ITER : (500, 500, 500). ./adap exists. Removing old mesh adaptation in 10s.; The ./adap folder was deleted. Generating GMF background surface mesh.; Initial CFD solution is provided. Starting mesh adaptation process. Iteration 0 - Mesh size coefficient 100.0; (1/2) Generating adapted mesh using AMG; AMG done: ; Running CFD; Traceback (most recent call last):; File ""/path/to/SU2/install/bin/mesh_adaptation_amg.py"", line 111, in <module>; main(); File ""/path/to/SU2/install/bin/mesh_adaptation_amg.py"", line 72, in main; options.save_all ); File ""/path/to/SU2/install/bin/mesh_adaptation_amg.py"", line 101, in mesh_adaptation_amg; SU2.run.amg(config); File ""/path/to/SU2/install/bin/SU2/run/amg.py"", line 466, in amg; os.rename(cur_solfil, cur_solfil_ini); FileNotFoundError: [Errno 2] No such file or directory: 'flo.dat' -> 'flo_ini.dat'`. and it0 folder is created, with some log.err and log.out, but they are empty, . I would appreciate any guidance or suggestions on how to resolve this issue. Thank you!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/948#issuecomment-1855842105:186,adapt,adaptation,186,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-1855842105,6,"['adapt', 'config']","['adaptation', 'adapted', 'config']"
Modifiability,"Hi,. here is the contents of config.log:. ```; This file contains any messages produced by compilers while; running configure, to aid debugging if configure makes a mistake. It was created by SU2 configure 4.1.0, which was; generated by GNU Autoconf 2.69. Invocation command line was. $ ./configure --prefix=/gshare/work/hpascalj/CodeSU2-master --with-CGNS-lib=/gshare/soft/code_saturne/4.0.0/prod/cgnslib_3.2.1/lib --with-CGNS-include=/gshare/soft/code_saturne/4.0.0/prod/cgnslib_3.2.1/include. ## --------- ##; ## Platform. ##; ## --------- ##. hostname = master; uname -m = x86_64; uname -r = 2.6.32-279.el6.x86_64; uname -s = Linux; uname -v = #1 SMP Wed Jun 13 18:24:36 EDT 2012. /usr/bin/uname -p = unknown; /bin/uname -X = unknown. /bin/arch = x86_64; /usr/bin/arch -k = unknown; /usr/convex/getsysinfo = unknown; /usr/bin/hostinfo = unknown; /bin/machine = unknown; /usr/bin/oslevel = unknown; /bin/universe = unknown. PATH: /opt/xcat/bin; PATH: /opt/xcat/sbin; PATH: /opt/pbs/default/bin; PATH: /opt/pbs/tools/bin; PATH: /usr/lpp/mmfs/bin/; PATH: /gshare/soft/star-ccm+/STAR-View+9.02.007; PATH: /gshare/soft/star-ccm+/STAR-CCM+9.02.007/star/bin; PATH: /opt/xcat/bin; PATH: /opt/xcat/sbin; PATH: /usr/lib64/qt-3.3/bin; PATH: /opt/pbs/default/bin; PATH: /opt/pbs/tools/bin; PATH: /usr/lpp/mmfs/bin/; PATH: /usr/local/bin; PATH: /bin; PATH: /usr/bin; PATH: /usr/local/sbin; PATH: /usr/sbin; PATH: /sbin; PATH: /gshare/soft/init; PATH: /gshare/soft/scripts; PATH: .; PATH: /gshare/soft/init; PATH: /gshare/soft/scripts; PATH: . ## ----------- ##; ## Core tests. ##; ## ----------- ##. configure:2465: checking build system type; configure:2479: result: x86_64-unknown-linux-gnu; configure:2499: checking host system type; configure:2512: result: x86_64-unknown-linux-gnu; configure:2532: checking target system type; configure:2545: result: x86_64-unknown-linux-gnu; configure:2587: checking for a BSD-compatible install; configure:2655: result: /usr/bin/install -c; configure:2666: checking whe",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:29,config,config,29,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,5,['config'],"['config', 'configure']"
Modifiability,"Hi,; I just had a few (very minor) comments.; Regarding the main contribution, everything makes sense to me and I didn't find any relevant issue.; This is a very nice contribution and the implementation is quite clear, we can go ahead and merge this in soon. Regarding the matrix stuff, perhaps we could start having a new, general, matrix class in Common and then extend it to parallel in future pushes.; It may not be ideal, but at least we'll get started.; I am just afraid that if we leave those potentially useful routines there, in the interpolator, we will soon forget about them (of course it doesn't have to be addressed in this PR but we should really discuss about this). ciao,; Giulio",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/555#issuecomment-407014370:365,extend,extend,365,https://su2code.github.io,https://github.com/su2code/SU2/pull/555#issuecomment-407014370,1,['extend'],['extend']
Modifiability,"I agree with @pcarruscag , we should try to merge options. I have been thinking for quite some time that we should make the mesh deformation a full solver on its own and homogenise all the options and procedures, be able to define different boundary conditions, etc. It should be based on the linear elasticity but have it's own variable definition, so it's usable out of the box with the adjoint solver. I have a preliminary implementation in [`feature_mesh_solver` ](https://github.com/su2code/SU2/tree/feature_mesh_solver), but I would need some help with that.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/623#issuecomment-456293206:329,variab,variable,329,https://su2code.github.io,https://github.com/su2code/SU2/pull/623#issuecomment-456293206,1,['variab'],['variable']
Modifiability,"I also agree that there should be an explicit option, and that it should; default to the current behavior, however it may be more intuitive for the; user to specify the actual step size- people who don't have Francisco's; extensive experience will not intuit that the finite difference step will; be 1/100 of the reference length, and may have difficulty figuring that out; without help. I suggest something like FD_STEP_SIZE, either way with; documentation explaining it.; -H. On Mar 6, 2017 5:26 PM, ""juanjosealonso"" <notifications@github.com> wrote:. > Agree with Francisco: the best solution is to have an input parameter that; > can be used to scale the FD step size. I would suggest FD_REFERENCE_LENGTH; > to be created (and possibly specified in the config file). If; > FD_REFERENCE_LENGTH is not specified, then it could default to; > REF_LENGTH_MOMENT.; >; > Best,; >; > Juan; >; > On Mar 5, 2017, at 6:35 PM, Francisco Palacios <notifications@github.com<; > mailto:notifications@github.com>> wrote:; >; > Hi,; >; > Yep, I changed that. I know that from the math point of view it doesn’t; > make a lot of sense but, from the practical point of view, it is useful.; >; > There are some cases, in which computing gradients using finite; > differences is the only choice. And with the shape_optimization script it; > was not possible to control the step size for the finite differences. The; > option for step size was only in finite_differences.py.; >; > The step size is scaled with the reference length because from the; > practical point of view, I have found that the size of the aircraft, wing,; > airfoil, is important to determine a meaningful step size. e.g. should we; > use the same step for an aircraft with a MAC of ~150in than for an airfoil; > with a chord of 1in.; >; > Remember that most of the times we are using FD when the adjoint is not; > converging… so we have bad convergence of the direct problem (including; > some level of unsteadiness that we want to filter with the ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/367#issuecomment-284314148:757,config,config,757,https://su2code.github.io,https://github.com/su2code/SU2/issues/367#issuecomment-284314148,1,['config'],['config']
Modifiability,"I also like the idea of renaming to ""SOLVER"" but I would also say to avoid as much churn as possible in the conditionals throughout the code... looks like a wash when reading through the PR changes (almost as many +'s as -'s). Unless the changes are going to make something much more flexible or clear, I would say just keep Kind_Regime and set it in config postprocessing.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/756#issuecomment-520705829:284,flexible,flexible,284,https://su2code.github.io,https://github.com/su2code/SU2/pull/756#issuecomment-520705829,2,"['config', 'flexible']","['config', 'flexible']"
Modifiability,"I am a little partial because I wrote it, but this https://github.com/su2code/FADO should do any kind of optimization you want.; Multiple operating points, manipulations of variables, running everything simultaneously... But I guess for something simple it is a little more work to setup.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1279#issuecomment-833754354:173,variab,variables,173,https://su2code.github.io,https://github.com/su2code/SU2/issues/1279#issuecomment-833754354,1,['variab'],['variables']
Modifiability,"I am not sure about why periodic boundaries are allowed to deform. It doesn't seem to be a good idea unless there is a way to deform its periodic pair in the same way. As for @auzbaig's question about why SLSQP converges in one step: There is a huge difference in the magnitude of the objective function, O(1) and the gradient O(-11). I am guessing the optimizer doesn't think it can reduce the function value any further since the gradient with respect to the DVs is so small. . To change the relative magnitudes of the objective and gradient, you need to change the DV scaling. This isn't intuitive and is one of the things we are hoping to address in #922 . Check out the `obj_df` function in `SU2_PY/SU2/eval/design.py` (line 386 in the develop branch). There you see how the gradient is scaled: . `grad[k] = grad[k] * sign * scale * global_factor / dv_scl` . Here `scale` is the objective function scaling factor, `global_factor` is what you specify for the `OPT_GRADIENT_FACTOR`, the `dv_scl` is the design variable scaling. . So if you wanted to bring the gradient norm to O(1), you'd have to specify a DV scaling of 1e-11. Usually a gradient norm of O(-6) is what seems to work best with SLSQP.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/976#issuecomment-628724163:1013,variab,variable,1013,https://su2code.github.io,https://github.com/su2code/SU2/issues/976#issuecomment-628724163,1,['variab'],['variable']
Modifiability,"I came across this when I was working on a mesh generation program that generates an extruded boundary layer. I had checks in the program to make sure I was generating elements of positive volume and that they weren't self intersecting. While some of the elements were very badly skewed, I knew I didn't want the elements to be reoriented. However, SU2 reorients several of the prisms and tries to reorient some of the pyramids as well (which isn't a defined operation in SU2). . This is why in my particular case it was easier for me to just turn off the feature. . In general though, I think that the reorientation check could be a bit better. Currently for the prism element for example, it does a volume like calculation using the top and bottom triangles separately, and reorients if either one is negative. Obviously if only one of these calculations is negative, by reorienting, the other calculation would become negative. Similar things are done for pyramids and hexas. . A simple solution would be to change the ""or"" conditions in these calculations to ""and"", so that it is only reoriented if it fails all the checks. I think a better solution would be to decide on a volume calculation method for each element type, and then use that as a criteria. . If you'd prefer to just improve the reorientation checks instead of adding this configuration option, I could submit work on a pull request for that if you'd like.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/162#issuecomment-103679295:1342,config,configuration,1342,https://su2code.github.io,https://github.com/su2code/SU2/pull/162#issuecomment-103679295,1,['config'],['configuration']
Modifiability,"I checked and I could not find a place in the code where this option is used explicitly. Since all the drivers split between primary recording for state variables and secondary recording for geometry variables for efficiency. My own use case was for research I did, where I needed to record a tape w.r.t. to both. Since this is not ready to become a pull request any time soon, I do not really need this option. If you suggest I can create a commit to remove the enum option for simplicity.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1492#issuecomment-1012241237:153,variab,variables,153,https://su2code.github.io,https://github.com/su2code/SU2/pull/1492#issuecomment-1012241237,2,['variab'],['variables']
Modifiability,"I could but I do not think updating that branch will fix your problem. We have not found any mesh handling bugs recently.; Creating / modifying meshes manually can get tricky (at least in my experience).; Have you tried simpler problems? Try starting with a problem that is known to work (there is a long issue with success stories, do a search for mesh adaptation here on github). Then build up from it, e.g. take the same problem and use a finer grid, change the physics to what you need, use a grid for your problem (ideally change one thing at a time).; Also keep in mind that if that branch was finished work it would probably have been merged into develop by now...",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1156#issuecomment-757123547:354,adapt,adaptation,354,https://su2code.github.io,https://github.com/su2code/SU2/issues/1156#issuecomment-757123547,1,['adapt'],['adaptation']
Modifiability,"I don't think the fix is as simple as it seems.; Indeed looking back at how we developed the CGNS reader, It was originally meant to read multiple zone in a single file. But during development, someone decided to restrict the reader to only one zone per file (and I don't know if it was validated). So now we are seating in the middle. If we replace line 169 of CGNSFVMMeshReader :; <pre>; if ( nzones > 1 ) {; SU2_MPI::Error(string(""CGNS reader currently expects only 1 zone per CGNS file."") +; string(""Multizone problems can be run with separate CGNS files for each zone.""), CURRENT_FUNCTION);; }; </pre>; by; <pre>; if ( cgnsZone > nzones) {; cgnsZone = 1;; }; </pre>. we can easily support multiple zone in one file. To support one CGNS zone per file, I guess that user should provide either the index in the cgns file of the zone we want to read or even better its name and not rely on SU2 numbering of zones. I think that supporting multiple mesh zones in the same file at the same time as one zone per mesh file should be possible as long as enough information is provided by the user. In this case, I am wondering how the option MULTIZONE_MESH and MULTIZONE option are interacting in the related issue. When MULTIZONE_MESH is set to NO do we expect one mesh file per zone ?; And in this case we can force CGNS Reader to read only the first Zone. In a more generic way something like this should be possible:; MULTIZONE=YES; CONFIG_LIST= (zone_1.cfg, zone_2.cfg, zone_3.cfg); CGNSZONENAMES = (""FluidRotor"", ""Solid"", ""FluidStator"") # To let CGNS pick the right zone in the file and if it not found the first zone can be used (current SU2 behavior). CGNSZONENAMES could also be set in each config file.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1566#issuecomment-1073204565:1695,config,config,1695,https://su2code.github.io,https://github.com/su2code/SU2/pull/1566#issuecomment-1073204565,1,['config'],['config']
Modifiability,"I have a few updates. I found out that most of my FGMRES problems in this branch where related to the fact that I was using single precision for the linear system. You can see it in this graphs for the residuals of Rho. ![RMSRho_Mesh_3](https://github.com/user-attachments/assets/185b8195-e415-4dff-9332-cff573c069cc). The first two curves are in mixed-precision and they stop long before reaching the minimum residual required due to divergence of the linear solver. Moreover, it seems that the 2003 model here implemented (which, simply put, considers the full reynolds stress tensor for the computation of the production of k and always considers k in the stress tensor and in the thermodynamic variables) has faster convergence and increases the recirculating zone (maybe due to the reduction of turbulence kinetic energy) which is a feature that has also been seen in [DOI:10.1017/aer.2020.93]. . ![SFC_Mesh_3](https://github.com/user-attachments/assets/81a50021-6b58-4a84-9057-a18b5bab023c). There are some differences between the use of the TMR boundary conditions and the ones used before. The results improve with respect to the develop in the prediction of the SFC distribution, which has results completely off from the V&V page of SU2. ![SFC_Mesh_3_Old](https://github.com/user-attachments/assets/0f4d634b-df31-4f86-a324-d9f67947f1ff). ![RMSRho_Mesh_3_Old](https://github.com/user-attachments/assets/24d5c2f5-93fe-432f-82d9-c050a90f7339). I may keep on checking if the implementation of the v2003 model is correct or not by searching for other test cases (probably coming from DOI:10.1017/aer.2020.93).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/2329#issuecomment-2393433487:698,variab,variables,698,https://su2code.github.io,https://github.com/su2code/SU2/pull/2329#issuecomment-2393433487,1,['variab'],['variables']
Modifiability,"I have seen that it is possible to specify the number of iterations in command line (shape_optimization.py)... but, I think it is clear to have both options (number of iterations and bounds - same for all the variables- ) in the config file.; Thanks!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/49#issuecomment-54920484:209,variab,variables,209,https://su2code.github.io,https://github.com/su2code/SU2/issues/49#issuecomment-54920484,2,"['config', 'variab']","['config', 'variables']"
Modifiability,"I implemented most of the reviewers suggestions. The only suggestion I left unchanged is the upper-case consistency issue raised by Wally. Since it is an optional output and it depends on the controlling variable names the user provides, I think it would be more intuitive to keep the font case consistent between the names under `CONTROLLING_VARIABLE_NAMES` and the corresponding `RMS_` outputs.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/2057#issuecomment-1643680580:204,variab,variable,204,https://su2code.github.io,https://github.com/su2code/SU2/pull/2057#issuecomment-1643680580,1,['variab'],['variable']
Modifiability,"I tend to agree w Eran on this topic. When it is working as it should, it is very convenient to have the makefiles already available in the repo. I switch between Mac, Ubuntu, and a red hat cluster without needing to update anything or call the bootstrap script. I rarely use it.. basically only when adding or removing files to the build. Also, it is good to minimize dependencies, as sometimes old machines or clusters have limited tool sets. But, clearly we should at a minimum fix the issue that some of you are finding with the autotools, which should just need an update. What systems are you having trouble with? It’s important that we don’t jump too far ahead for portability reasons (that’s why we have kept the old versions for so long). Do you have an idea of the minimum autotools you need for the failing systems? We could start by updating to that version and see if things stabilize.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/586#issuecomment-424210049:672,portab,portability,672,https://su2code.github.io,https://github.com/su2code/SU2/pull/586#issuecomment-424210049,1,['portab'],['portability']
Modifiability,"I think its a good idea to separate the weight from the objective function. This makes it more clear and flexible. However, what bothers me a little bit is that the OBJECTIVE_FUNCTION option is now used for two things. Namely for the optimization and for the individual adjoint runs. Maybe it would be good to still have another option for specifying the obj. function for the adjoint run itself (with a completely different name, so that there won't be any confusions). . Maybe it's less of a problem then I think, though.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/241#issuecomment-185126081:105,flexible,flexible,105,https://su2code.github.io,https://github.com/su2code/SU2/pull/241#issuecomment-185126081,1,['flexible'],['flexible']
Modifiability,"I understand, but it helps to keep the code more approachable and portable. That being said, there may be some work proposed soon using templates in the linear solver classes, and it would be great to have your feedback then. We really appreciate your interest!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/400#issuecomment-360075745:66,portab,portable,66,https://su2code.github.io,https://github.com/su2code/SU2/issues/400#issuecomment-360075745,1,['portab'],['portable']
Modifiability,"I was running some tests using a simple geometry but for the refinement seems to be chewing up the geometry. Has anyone who has worked on 3D geometries experienced this or figured out a way to avoid this?. I was using the following settings:; ```; % ------------- MESH ADAPTATION PARAMETER ------------%; %; % Type of sensor used for adaptation; % Options include GOAL (adjoint-based), MACH, PRES; PYADAP_SENSOR= MACH; % Maximum cell size for adaptation; PYADAP_HMAX= 500.0; % Minimum cell size for adaptation; PYADAP_HMIN= 1e-9; % Gradation factor (typically 1.2-1.8); PYADAP_HGRAD= 1.8; % Norm used for adaptation; % 1.0 or 2.0 recommended for inviscid flows; % 4.0 recommeneded for viscid; ADAP_NORM= 2.0; % Approximate mesh size (NPOI) at each level; PYADAP_COMPLEXITY= (1000000, 1300000, 1500000); % Number of adaptations performed at each level; PYADAP_SUBITE= (2, 2, 2); ```. ![refine](https://user-images.githubusercontent.com/16842258/104834786-0b94fa80-58e5-11eb-9018-687ffc5aaa9d.png). I noticed a few comments up, there is the `PYADAP_BACK` setting, which sounds like it might solve this, but how should one use this? Should the geometry alone be re-meshed to a high resolution and the whole volume exported as a SU2 block? Or should it be just a surface mesh? (It seems that Pointwise is not able to output only the surface mesh in SU2 format.)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/948#issuecomment-761751741:334,adapt,adaptation,334,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-761751741,5,['adapt'],"['adaptation', 'adaptations']"
Modifiability,"ION ""4.1.0""; | /* end confdefs.h. */; | #include <ac_nonexistent.h>; configure:4707: checking for grep that handles long lines and -e; configure:4765: result: /bin/grep; configure:4770: checking for egrep; configure:4832: result: /bin/grep -E; configure:4837: checking for ANSI C header files; configure:4857: gcc -c -g -O2 conftest.c >&5; configure:4857: $? = 0; configure:4930: gcc -o conftest -g -O2 conftest.c >&5; configure:4930: $? = 0; configure:4930: ./conftest; configure:4930: $? = 0; configure:4941: result: yes; configure:4954: checking for sys/types.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for sys/stat.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for stdlib.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for string.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for memory.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for strings.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for inttypes.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for stdint.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for unistd.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4970: checking size of short int; configure:4975: gcc -o conftest -g -O2 conftest.c >&5; configure:4975: $? = 0; configure:4975: ./conftest; configure:4975: $? = 0; configure:4989: result: 2; configure:5003: checking",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:10129,config,configure,10129,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,1,['config'],['configure']
Modifiability,InitItems.h (98) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtCaepInstanceData.h (135) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtCaepSupportData.h (89) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtPwpInitItems.h (68) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtPwpPluginInfo.h (75) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtPwpVersions.h (62) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/runtimeWrite.c (443) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.sdf (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.sln (26) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.suo (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcproj (511) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcxproj (307) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcxproj.filters (78) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcxproj.user (3) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/UpgradeLog.XML (47) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport.css (207) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport.xslt (232) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport_Minus.gif (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport_Plus.gif (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/module.mk (240) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/modulelocal-sample.mk (84) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtCaepInitItems.h (142) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtCaepInstanceData.h (135) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtCaepSupportData.h (83) ; - D MeshTools/PointwiseSU2plugin/src/plugins,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:15477,plugin,plugins,15477,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['plugin'],['plugins']
Modifiability,"KAGE_NAME ""SU2""; | #define PACKAGE_TARNAME ""SU2""; | #define PACKAGE_VERSION ""4.1.0""; | #define PACKAGE_STRING ""SU2 4.1.0""; | #define PACKAGE_BUGREPORT ""su2code-dev@lists.stanford.edu""; | #define PACKAGE_URL ""https://github.com/su2code""; | #define PACKAGE ""SU2""; | #define VERSION ""4.1.0""; | /* end confdefs.h. */; | #include <ac_nonexistent.h>; configure:4707: checking for grep that handles long lines and -e; configure:4765: result: /bin/grep; configure:4770: checking for egrep; configure:4832: result: /bin/grep -E; configure:4837: checking for ANSI C header files; configure:4857: gcc -c -g -O2 conftest.c >&5; configure:4857: $? = 0; configure:4930: gcc -o conftest -g -O2 conftest.c >&5; configure:4930: $? = 0; configure:4930: ./conftest; configure:4930: $? = 0; configure:4941: result: yes; configure:4954: checking for sys/types.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for sys/stat.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for stdlib.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for string.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for memory.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for strings.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for inttypes.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for stdint.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for unistd.h; configure:4954: gcc -c -g -O2 conftest.c >&5; con",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:9853,config,configure,9853,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,1,['config'],['configure']
Modifiability,"KER_MONITORING, MARKER_DESIGNING: The main idea is to be able to compute to different integrals over the surfaces: one for simulation and the other for design. e.g. You maybe want to include all the solid surfaces and fan faces, and charging stations in MARKER_MONITORING to compute (Drag-Thrust) but in MArKER DESIGN you are only interested on the wing surface for design.; > ; > DV_MARKER. This is an unfortunately name. At the very beginning the mesh deformation capability was developed only for shape design (DV = Design Variables). We should generalize the names of the grid deformation parameters without using DV. Thanks!; Francisco. On Aug 18, 2015, at 4:31 AM, Heather Kline notifications@github.com wrote:. > Thanks Tom; > I agree that we should make things easy to understand. ; > My thinking was that most users will want to know what parts of the mesh they are moving, but don't necessarily need to know what's happening underneath - if they specify the entire mesh the code just reverts to the more efficient method. But (from the users perspective) it may be just as easy to have a separate specification for scaling the entire mesh.; > ; > In terms of moving it to SU2_MSH; I think it may make sense to include scale/rotate/translate in SU2_MSH, but I think it would be confusing to have two options that do the same thing. I would side with separate option names (this would also eliminate a loop over markers in this pull request); > ; > On this topic, I have sometimes found MARKER_DESIGNING and DV_MARKER to be confusing; on their own they sound very similar, in the description MARKER_DESIGNING is where the objective function is evaluated - but in the code, it's not clear what MARKER_DESIGNING does - the surfaces specified by MARKER_MONITORING are what are actually used to evaluate the objective function value.; > ; > There may be other similar areas where config file options could be clarified or compressed.; > ; > —; > Reply to this email directly or view it on GitHub.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/187#issuecomment-133010923:2340,config,config,2340,https://su2code.github.io,https://github.com/su2code/SU2/pull/187#issuecomment-133010923,1,['config'],['config']
Modifiability,"Let's continue this here @suargi as it should be more visible for everyone. In principle, I like what you suggest, it is clean and concise.; However, I see one big issue with backwards compatibility of the config. KIND_TURB_MODEL is in almost every config (in the world) and we cannot simply break compatibility, something with this much impact would require SU2 v8 :smile: . This is not to say you could not implement what you propose, just that you need to make it compatible with the status quo.; For example:; KIND_TURB_MODEL= SA-NEQ; QCR= YES; (I'm not even sure if that makes sense but anyway); Needs to be converted internally to:; KIND_TURB_MODEL= SA; TURB_MODEL_CORRECTIONS= SA-NEG, SA-QCR2000. And of course, if someone uses the new option TURB_MODEL_CORRECTIONS you can enforce that KIND_TURB_MODEL only contains NONE, or SA, or SST, and that corrections do not appear in the config in any other way.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1364#issuecomment-907388593:206,config,config,206,https://su2code.github.io,https://github.com/su2code/SU2/issues/1364#issuecomment-907388593,3,['config'],['config']
Modifiability,"Maybe CNumerics is not the perfect place, but it is good enough for government work (there are much more misplaced things in there). The ""everything is class"" OO approach applied to the lowest level of abstraction is... well I think it is terrible -- and it has taken me a mighty long time to get rid of it in CPoint and CVariable and to design alternative Numerics -- because:; - Boilerplate: Set this, get that, constructor, destructor;; - Thread safety: Those classes always end up having some mutable state that renders them thread-unsafe;; - Correctness: Many of the classes we have follow this paradigm of ""pass by member variable"" - I like to know what are the inputs and outputs of something just by looking at the signature;; - Slowww: Too much virtual;; - Unnecessary complexity: A case of using a canon to kill the mosquito, good code should be as simple as possible, if a function does the job then that is the level of abstraction we should use. My introduction to C++ was also the ""everything is class"", then one day I read ""From Mathematics to Generic Programming"" and well, I started liking C++ a whole lot more.; The standard template library is incredibly successful, and it ""just"" provides some containers and generic algorithms which are functions. That is what we need in SU2, some decent containers and generic algorithms to operate on them. OO and its patterns are very good high level tools to achieve encapsulation and to isolate code, which are very important for projects with millions of lines of code, but for low level things they are overkill. Sorry for the rant, I guess I have strong feelings about tiny classes.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1127#issuecomment-742629412:628,variab,variable,628,https://su2code.github.io,https://github.com/su2code/SU2/pull/1127#issuecomment-742629412,1,['variab'],['variable']
Modifiability,MeshTools/PointwiseSU2plugin/src/Pointwise/Win32Target.vsprops (24) ; - D MeshTools/PointwiseSU2plugin/src/Pointwise/Win64Target.props (28) ; - D MeshTools/PointwiseSU2plugin/src/Pointwise/Win64Target.vsprops (24) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/CaeStrXML.vcproj (511) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/CaeStrXML.vcproj.PWI.dgarlisch.user (121) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/CaeStrXML.vcxproj (307) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/CaeStrXML.vcxproj.filters (78) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/CaeStrXML.vcxproj.user (3) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/module.mk (239) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/modulelocal-sample.mk (84) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtCaepInitItems.h (98) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtCaepInstanceData.h (135) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtCaepSupportData.h (89) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtPwpInitItems.h (68) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtPwpPluginInfo.h (75) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtPwpVersions.h (62) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/runtimeWrite.c (443) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.sdf (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.sln (26) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.suo (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcproj (511) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcxproj (307) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcxproj.filters (78) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcxproj.user (3) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/UpgradeLog.XML (47) ;,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:14605,plugin,plugins,14605,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['plugin'],['plugins']
Modifiability,MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWP.c (132) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWP.h (707) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWPUtils.c (789) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWPUtils.h (1030) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiUtils.h (174) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/pwpPlatform.c (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/pwpPlatform.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/site.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/structured.props (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/structured.vsprops (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/CaeTemplate.suo (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/CaeTemplate.vcproj (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/module.mk (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/modulelocal-sample.mk (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/rtCaepInitItems.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/rtCaepInstanceData.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/rtCaepSupportData.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/runtimeWrite.c (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/PWP/rtPwpInitItems.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/PWP/rtPwpPluginInfo.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/PWP/rtPwpVersions.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/unstructured.props (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/unstructured.vsprops (0) ; - D MeshTools/PointwiseSU2plugin_Instructions.txt (0) ; - I QuickStart/inv_NACA0012.cfg (0) ; - I README (0) ; - I SU2_CFD/include/SU2_CFD.hpp (0) ; - I SU2_CFD/include/definition_structure.hpp (0) ; - I SU2_CFD/include/f,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:19788,plugin,plugins,19788,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['plugin'],['plugins']
Modifiability,MeshTools/PointwiseSU2plugin/src/plugins/structured.props (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/structured.vsprops (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/CaeTemplate.suo (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/CaeTemplate.vcproj (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/module.mk (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/modulelocal-sample.mk (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/rtCaepInitItems.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/rtCaepInstanceData.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/rtCaepSupportData.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/runtimeWrite.c (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/PWP/rtPwpInitItems.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/PWP/rtPwpPluginInfo.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/PWP/rtPwpVersions.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/unstructured.props (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/unstructured.vsprops (0) ; - D MeshTools/PointwiseSU2plugin_Instructions.txt (0) ; - I QuickStart/inv_NACA0012.cfg (0) ; - I README (0) ; - I SU2_CFD/include/SU2_CFD.hpp (0) ; - I SU2_CFD/include/definition_structure.hpp (0) ; - I SU2_CFD/include/fluid_model.hpp (0) ; - I SU2_CFD/include/fluid_model.inl (0) ; - I SU2_CFD/include/integration_structure.hpp (0) ; - I SU2_CFD/include/integration_structure.inl (0) ; - I SU2_CFD/include/iteration_structure.hpp (0) ; - I SU2_CFD/include/numerics_machine_learning.hpp (0) ; - I SU2_CFD/include/numerics_machine_learning.inl (0) ; - I SU2_CFD/include/numerics_machine_learning_turbulent.hpp (0) ; - I SU2_CFD/include/numerics_structure.hpp (0) ; - I SU2_CFD/include/numerics_structure.inl (0) ; - I SU2_CFD/include/output_structure.hpp (0) ; - I SU2_CFD/include/solver_structure.hpp (0) ; - ,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:20379,plugin,plugins,20379,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['plugin'],['plugins']
Modifiability,"N ""4.1.0""; | /* end confdefs.h. */; | #include <ac_nonexistent.h>; configure:4644: result: gcc -E; configure:4664: gcc -E conftest.c; configure:4664: $? = 0; configure:4678: gcc -E conftest.c; conftest.c:11:28: error: ac_nonexistent.h: No such file or directory; configure:4678: $? = 1; configure: failed program was:; | /* confdefs.h */; | #define PACKAGE_NAME ""SU2""; | #define PACKAGE_TARNAME ""SU2""; | #define PACKAGE_VERSION ""4.1.0""; | #define PACKAGE_STRING ""SU2 4.1.0""; | #define PACKAGE_BUGREPORT ""su2code-dev@lists.stanford.edu""; | #define PACKAGE_URL ""https://github.com/su2code""; | #define PACKAGE ""SU2""; | #define VERSION ""4.1.0""; | /* end confdefs.h. */; | #include <ac_nonexistent.h>; configure:4707: checking for grep that handles long lines and -e; configure:4765: result: /bin/grep; configure:4770: checking for egrep; configure:4832: result: /bin/grep -E; configure:4837: checking for ANSI C header files; configure:4857: gcc -c -g -O2 conftest.c >&5; configure:4857: $? = 0; configure:4930: gcc -o conftest -g -O2 conftest.c >&5; configure:4930: $? = 0; configure:4930: ./conftest; configure:4930: $? = 0; configure:4941: result: yes; configure:4954: checking for sys/types.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for sys/stat.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for stdlib.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for string.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for memory.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for strings.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954:",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:9487,config,configure,9487,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,2,['config'],['configure']
Modifiability,"N; ++k); grad(iPoint+k,iVar,iDim) = gradI[iVar][iDim][k];; ...; ```; Similarly when computing the gradient we need to first fetch/transpose it to be able to vectorize subsequent computations; ```c++; FltVec gradI[MAXNVAR][MAXNDIM];. for(size_t iVar=0; iVar<nVar; ++iVar); for(size_t iDim=0; iDim<nDim; ++iDim); for(size_t k=0; k<SIMDLEN; ++k); gradI[iVar][iDim][k] = grad(iPoint+k,iVar,iDim);; ...; ```; Performance wise this is actually better than the SoA version (4% on gradients, 35% on limiters) as it also benefits from better locality, and it is only slightly (3%) worse than zig zag storage, especially when fusing limiters and gradients as the transposition of the gradient into storage is greatly amortised.; Regarding readability, the 3 nested loops can be moved to methods of the container, but we cannot get rid off the local variable (if we want vectorization that is). **We lose the ability to vectorize primitive variable updates efficiently with AoS** but currently that only accounts for 3% of the runtime and it is a memory bound operation therefore it would not gain much from vectorization anyway. On the subject of de-swizzling data remember I said the writes into CSysMatrix would be a bit weird, that is because each Jacobian contribution will be a ""matrix of short arrays"" that needs to be transformed into a short array of matrices, the result of that is code like the above that explicitly manipulates the lanes of our SIMD type, such code can be completely hidden inside CSysMatrix which is good because a 4x4 vectorized transpose and matrix update looks like this; ```c++; // block j, subs from jj and goes to ij; T0 = blk_j[ k ].unpackLo(blk_j[k+1]); T1 = blk_j[ k ].unpackHi(blk_j[k+1]);; T2 = blk_j[k+2].unpackLo(blk_j[k+3]); T3 = blk_j[k+2].unpackHi(blk_j[k+3]);. C0 = T0.widePermuteLo(T2); C1 = T1.widePermuteLo(T3);; C2 = T0.widePermuteHi(T2); C3 = T1.widePermuteHi(T3);. (Array4d(&bjj[0][k])-C0).store(&bjj[0][k]);; (Array4d(&bjj[1][k])-C1).store(&bjj[1][k]);; (Arr",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-535977206:15136,variab,variable,15136,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206,1,['variab'],['variable']
Modifiability,"NT 2; | #define SIZEOF_INT 4; | #define SIZEOF_UNSIGNED_INT 4; | #define SIZEOF_LONG_INT 8; | #define SIZEOF_FLOAT 4; | #define SIZEOF_DOUBLE 8; | #define SIZEOF_VOID_P 8; | /* end confdefs.h. */; | #include <stdio.h>; | #ifdef HAVE_SYS_TYPES_H; | # include <sys/types.h>; | #endif; | #ifdef HAVE_SYS_STAT_H; | # include <sys/stat.h>; | #endif; | #ifdef STDC_HEADERS; | # include <stdlib.h>; | # include <stddef.h>; | #else; | # ifdef HAVE_STDLIB_H; | # include <stdlib.h>; | # endif; | #endif; | #ifdef HAVE_STRING_H; | # if !defined STDC_HEADERS && defined HAVE_MEMORY_H; | # include <memory.h>; | # endif; | # include <string.h>; | #endif; | #ifdef HAVE_STRINGS_H; | # include <strings.h>; | #endif; | #ifdef HAVE_INTTYPES_H; | # include <inttypes.h>; | #endif; | #ifdef HAVE_STDINT_H; | # include <stdint.h>; | #endif; | #ifdef HAVE_UNISTD_H; | # include <unistd.h>; | #endif; | #include <X11/Intrinsic.h>; configure:5409: result: no; configure:5409: checking X11/Intrinsic.h presence; configure:5409: gcc -E conftest.c; conftest.c:28:27: error: X11/Intrinsic.h: No such file or directory; configure:5409: $? = 1; configure: failed program was:; | /* confdefs.h */; | #define PACKAGE_NAME ""SU2""; | #define PACKAGE_TARNAME ""SU2""; | #define PACKAGE_VERSION ""4.1.0""; | #define PACKAGE_STRING ""SU2 4.1.0""; | #define PACKAGE_BUGREPORT ""su2code-dev@lists.stanford.edu""; | #define PACKAGE_URL ""https://github.com/su2code""; | #define PACKAGE ""SU2""; | #define VERSION ""4.1.0""; | #define STDC_HEADERS 1; | #define HAVE_SYS_TYPES_H 1; | #define HAVE_SYS_STAT_H 1; | #define HAVE_STDLIB_H 1; | #define HAVE_STRING_H 1; | #define HAVE_MEMORY_H 1; | #define HAVE_STRINGS_H 1; | #define HAVE_INTTYPES_H 1; | #define HAVE_STDINT_H 1; | #define HAVE_UNISTD_H 1; | #define SIZEOF_SHORT_INT 2; | #define SIZEOF_INT 4; | #define SIZEOF_UNSIGNED_INT 4; | #define SIZEOF_LONG_INT 8; | #define SIZEOF_FLOAT 4; | #define SIZEOF_DOUBLE 8; | #define SIZEOF_VOID_P 8; | /* end confdefs.h. */; | #include <X11/Intrinsic.h>; ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:14157,config,configure,14157,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,1,['config'],['configure']
Modifiability,"Nice progress @pcarruscag!. I like the concept of your SIMD-friendly class that will take care of the data structure under the hood coupled with a standard type of loop statement (w/ +SIMDLEN). This should make it pretty easy for folks to still modify the kernels without having to worry about the data alignment, and they can reuse the same simple 'for' construct repeatedly. . Another reason to have our own lightweight class for this is that you can avoid dependence on OpenMP for SIMD (although that feature looks to have potential and wasn't available until somewhat recently) as well as the intrinsics. In my experience, the latter is especially bad for portability and readability (part of why we left the CaF work in a separate repo). It starts to become so specialized that compiling and modifying become difficult. W.r.t. OpenMP, another roadblock there a few years ago was making sure it is interoperable with CoDi for the adjoint, but I know this has been worked on and may be available by now. Might keep an open mind about point vs. edge. In some places, we may be able to pump up the compute in our loops by fusing kernels, as previously discussed (and I am guessing you are working on this already with gradients/limiters). Could change the final performance numbers significantly. Lastly, I know you are not there yet, but it is worth considering whether you can reuse anything you are developing in the kernels here for the linear solver routines. At some point, you will successfully reduce the cost of the residual kernels (RHS) to the bandwidth limit, and the majority of the iteration cost will be in the linear solver (it is already about 50% of the iteration cost before optimization, if I recall). Before making final decisions on strategy, you should consider if it will help in any of the linear solver routines too.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-530440072:660,portab,portability,660,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530440072,1,['portab'],['portability']
Modifiability,"No need for Intel buddies, I know what's up. Take [this code:](https://gcc.godbolt.org/z/siQamn); ```; class Base {; public:; inline virtual double get() const {return 0.0;}; };. class Derived : public Base {; double val;; public:; Derived(double a) : val(a) {}. inline double get() const final {return val;}; };. double fun1(Base* obj) {; return obj->get();; }. double fun2(Base* obj) {; return static_cast<Derived*>(obj)->get();; }; ```. `get` of derived has been marked `final` so in `fun2` polymorphism should be optimized away. Here is the assembly for gcc 5.4:. ```; fun1(Base*):; mov rax, QWORD PTR [rdi]; jmp [QWORD PTR [rax]]; fun2(Base*):; movsd xmm0, QWORD PTR [rdi+8]; ret; ```; `fun1` needs a jump, `fun2` knows what to return right away. Here is the assembly for icc 17:; ```; fun1(Base*):; mov rax, QWORD PTR [rdi] #16.12; mov rdx, QWORD PTR [rax] #16.12; jmp rdx #16.12; fun2(Base*):; mov rax, QWORD PTR [rdi] #20.34; mov rdx, QWORD PTR [rax] #20.34; jmp rdx #20.34; ```. @vdweide please tell me you did not use icc 19, because it performs this optimization just fine on this simple example. By the way @talbring (since you asked in #753), take away the `final` keyword and nothing gets optimized by the `static_cast`.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/716#issuecomment-523952473:494,polymorphi,polymorphism,494,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-523952473,1,['polymorphi'],['polymorphism']
Modifiability,"No, I think we're all set. I am going to merge this in. We have two issues that we are going to be clearing up very soon: the ONERA M6 adjoint case that is failing somewhat irregularly, and a reorganization of the test cases/config files to make the regression tests more effective (in particular for pull requests). Thanks for fixing the conflicts!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/186#issuecomment-127486074:225,config,config,225,https://su2code.github.io,https://github.com/su2code/SU2/pull/186#issuecomment-127486074,1,['config'],['config']
Modifiability,"No… I can’t. I’m sorry. Great to hear from you. Machine learning is a very valuable research work and I will add it as a feature branch. . Removing code from the main release is a complex task and, as in the past, I have taken tough decisions. Anyway, to maintain a clean code is critical for its growing, it is like trimming a large tree. Basic criteria to maintain forever an implementation on the develop->master branch are: - Clear benefit to the CFD community (more accurate, robust, etc.) - Existing community of users or active developers - Minimal code documentation (at least the options should be in the config file). - Easy to install and use. - The implementation style should be aligned with the SU2 style - Regressions tests. Best,; Francisco. > On Oct 28, 2015, at 11:35 PM, Brendan Tracey notifications@github.com wrote:; > ; > Could you leave in the machine learning section a bit longer?; > ; > —; > Reply to this email directly or view it on GitHub https://github.com/su2code/SU2/pull/208#issuecomment-152095697.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/208#issuecomment-152384158:614,config,config,614,https://su2code.github.io,https://github.com/su2code/SU2/pull/208#issuecomment-152384158,1,['config'],['config']
Modifiability,"OK the failing regression test were due to:; 1. One simple wrong function call in Csolver; 2. Creating new output in existing groups (AERO_COEFF, FLOW_COEFF) which invalidates some regression tests; 3. pyhton code which does not test if some config variable is present or altering the python code such that it invalidates other regression tests; 4. and finally the AVG_TEMP thing above. Now all these alone were somewhat minor things. Feature_flamelet is now up-to-date with develop with all regression test working",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1223#issuecomment-898617272:242,config,config,242,https://su2code.github.io,https://github.com/su2code/SU2/pull/1223#issuecomment-898617272,2,"['config', 'variab']","['config', 'variable']"
Modifiability,"ON|OFF, disabled when building with Codi; * SU2_BUILD_PY_WRAPPER: ON|OFF, disabled when building with Codi forward; * SU2_BUILD_SOL: ON|OFF, disabled when building with Codi; * Enable modules:; * SU2_ENABLE_CGNS:; * SU2_CGNS_CPPFLAGS: flags to pass when compiling CGNS; * SU2_ENABLE_CODI: no|forward|reverse; * SU2_CODI_CPPFLAGS: flags to pass to SU2 modules when compiling with Codi; * SU2_ENABLE_METIS: ON|OFF; * SU2_METIS_CPPFLAGS: flags to pass when compiling Metis; * SU2_ENABLE_MKL: ON|OFF; * SU2_ENABLE_MPI: ON|OFF; * SU2_ENABLE_MUTATIONPP: ON|OFF; * SU2_ENABLE_PARMETIS: ON|OFF, only available when SU2_ENABLE_MPI is ON; * SU2_PARMETIS_CPPFLAGS: flags to pass when compiling Parmetis; * SU2_ENABLE_TECIO: ON|OFF; * SU2_TECIO_CPPFLAGS: flags to pass when compiling Tecio and TecioMPI; * SU2_TECIOMPI_CPPFLAGS: flags to pass when compiling TecioMPI, requires SU2_ENABLE_MPI. There is an additional variable that is recognized by CMake scripts - DEBUG, turning it ON enables additional STATUS messages, mainly to check that correct include directories, compile definitions and linked libraries were set up correctly. The remaining options like install location and compilers are handled by CMake. Tested this on Ubuntu with CMake 3.15.5 and everything except pySU2ad wrapper compiles. Haven't tested on earlier CMake versions so there might be bugs with them but they should be easy to resolve if any. Related Work. Resolve any issues (bug fix or feature request), note any related PRs, or mention interactions with the work of others, if any. PR Checklist. Put an X by all that apply. You can fill this out after submitting the PR. If you have any questions, don't hesitate to ask! We want to help. These are a guide for you to know what the reviewers will be looking for in your contribution. * I am submitting my contribution to the develop branch.; * My contribution generates no new compiler warnings (try with the '-Wall -Wextra -Wno-unused-parameter -Wno-empty-body' compiler flags).; * My",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/814#issuecomment-552242380:2853,variab,variable,2853,https://su2code.github.io,https://github.com/su2code/SU2/pull/814#issuecomment-552242380,1,['variab'],['variable']
Modifiability,"Obviously it is possible to implement this, but it would significantly complicate the config parsing code. Right now the parser is very simple: Go through each line, and get the name and the tokens. As far as I can see there aren't good ways to allow this aside from either having a whitelist of options that can go on multiple lines (thus, only some options are allowed to do so), or to switch up the config file entirely and go to a more standard format like JSON.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/166#issuecomment-103241030:86,config,config,86,https://su2code.github.io,https://github.com/su2code/SU2/issues/166#issuecomment-103241030,2,['config'],['config']
Modifiability,"Ok, I went back to try varying the `.cfg` settings on the simple v7.0.3 repo `TestCases/euler/naca0012` case and managed to get `mesh_adaptation_amg.py` to run successfully. It seems that one bit of advice [from here](https://www.cfd-online.com/Forums/su2/214613-grid-adaptation-options.html) is no longer true, i.e. one needs to set:; ```; % Write binary restart files (YES, NO); WRT_BINARY_RESTART= YES; %; % Read binary restart files (YES, NO); READ_BINARY_RESTART= YES; ```; in order for the amg mesh adaptation to function. However, for some reason, I can't get it working for my actual mesh of interest. When using the same settings, I get a different ParMETIS error (from the `adap/ini/log.out`):; ```; ------------------- Geometry Preprocessing ( Zone 0 ) -------------------; Three dimensional problem.; 4929018 grid points before partitioning.; 7406196 volume elements before partitioning.; 3 surface markers.; 18040 boundary elements in index 0 (Marker = BODY).; 50968 boundary elements in index 1 (Marker = FARFIELD).; 284054 boundary elements in index 2 (Marker = SYMMETRY).; Executing the partitioning functions.; Building the graph adjacency structure.; [ 1] ***ASSERTION failed on line 207 of file ../externals/parmetis/libparmetis/comm.c:sendind[i] >= firstvtx && sendind[i] < lastvtx; [ 1] 361316 123226 246452; [1609857970.901920] [super:1060888:0] sock.c:344 UCX ERROR recv(fd=62) failed: Connection reset by peer; ```. The only difference that I can think of is that my flow is fully supersonic and my mesh is an unstructured core with a structured collar - might this be causing the issue? Kind regards.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/948#issuecomment-754686447:268,adapt,adaptation-options,268,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-754686447,2,['adapt'],"['adaptation', 'adaptation-options']"
Modifiability,"Ok, SIMD update, with #753, #959, and #966 we now have a unified storage type for the data we need in CNumerics. This means that we (I) only need to implement ""SIMD accessor methods"" (i.e. that return a SIMD type instead of a su2double) for one class (C2DContainer and co.). I think to do SIMD right we need a new way of going about CNumerics, these are my design requirements for ""CNewNumerics"":; - Thread-safe (consequently const-correct), a single object must be safe to use by multiple threads.; - Minimal indirection, the polymorphic overhead will be reduced to a single call (ComputeResidual), all auxiliary functions (like the ones that live in CNumerics) will be forcefully inlined, no useless copies of data (no more numerics->SetBlaBla).; - Compile time nDim/nVar, which will: a) avoid heap allocations; b) allow effective loop-unrolling (also during the writes to CSysMatrix).; - Allow low-overhead composition, e.g. have one CRoe for Euler and one CRoeVisc for NS to fuse convective and viscous residuals (without copy pasting code).; - A lot more readable, those cryptic V_i[iDim+1] need to go (somehow...). To achieve all this, the ""CNewNumerics"" will work as a template (obvs) decorator/visitor.; A visitor in the sense that the solver calls the numerics and gives it (read-only) access to all its data, the object pulls whatever it needs directly and there is no need for numerics->SetBlaBla.; A template decorator in the sense that the class can be augmented simply by inheriting from another, along the lines of `class CRoeVisc : public CRoe, public CVisc` (to allow fusing residual and Jacobian contributions).; All this needs to be done with templates for the ""minimal indirection"" requirement. Which means for each numerical method we will have 4 explicit template instantiations (Euler2D, Euler3D, (RA)NS2D, (RA)NS3D) but in the end these are still polymorphic objects that will be instantiated by some factory function (i.e. it will look clean, especially because I will not por",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-622941617:527,polymorphi,polymorphic,527,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-622941617,1,['polymorphi'],['polymorphic']
Modifiability,Okay @pcarruscag I believe ; I reverted all the annoying format changes. Can you please review the code when you get the chance?. BTW I am aware about the boilerplate code in `python_wrapper_structure.cpp` and I plan to adapt `CPyWrapperMatrixView`. Would appreciate some feedback anyways,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1750#issuecomment-1779150012:220,adapt,adapt,220,https://su2code.github.io,https://github.com/su2code/SU2/pull/1750#issuecomment-1779150012,1,['adapt'],['adapt']
Modifiability,"On the subject of virtual functions I would like to put another idea forward.; After moving things around in #725 I noticed that we have tons of `inline virtual` methods.; The keyword `inline` has two meanings to the compiler:; - ""Dear merciful compiler please copy paste the body of this function and then do all your wonderful optimizations, if that pleases your excellency.""; - ""Dear forgiving compiler, you will find this method defined in multiple units, please don't be mad"" (i.e. ignore the one-definition-rule). `virtual` means determine what version of the method to call at runtime. This is not compatible with the first (and often the intended one) meaning of inline, therefore the compiler will in general not inline those methods.; They will only be inlined if they are being called on a pointer to the derived class that does not declare the method to be virtual anymore. CSolver knows what variables it creates and so in hot areas of the code it could do a static downcast to allow inlining (e.g. `static_cast<CEulerVariable*>(node[iNode])->DoStuff()`).; Where is this important? For example when computing gradients, where simple additions and subtractions are hidden behind virtual functions.; If you are worried about maintenance each solver can typedef its most safe downcast level or better yet (or just more modern), methods that could benefit from this can be templated for the type of downcast.; Those in favour say Yea those against say Nay.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/716#issuecomment-509273008:905,variab,variables,905,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-509273008,1,['variab'],['variables']
Modifiability,"Overall some solid looking code @jayantmukho, thanks!; I have a few suggestions:; 1 - Some of the config variables have fairly broad names, ""permute"" for example, I think prefixing them with UQ would more clearly identify what they are meant for.; 2 - There are a lot of dynamic allocations of static size, if the current implementation is compatible with 2 and 3 dimensions I would allocate those variables statically, makes for cleaner and faster code (stack allocations are much faster and subsequent loops would likely be unrolled by the compiler).; 3 - It looks like some of the new methods in CNumerics are for generic ""Eigenvalue-stuff"" for re-usability I suggest moving those methods to a helper class, even if for now that class becomes just a collection of static methods. In the implementation of those methods the dimension of the inputs is being assumed, if you do move them please make them generic.; Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/570#issuecomment-427468893:98,config,config,98,https://su2code.github.io,https://github.com/su2code/SU2/pull/570#issuecomment-427468893,3,"['config', 'variab']","['config', 'variables']"
Modifiability,PointwiseSU2plugin/src/plugins/CaeUnsSU2/modulelocal-sample.mk (84) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtCaepInitItems.h (142) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtCaepInstanceData.h (135) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtCaepSupportData.h (83) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtPwpInitItems.h (68) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtPwpPluginInfo.h (75) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtPwpVersions.h (64) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/runtimeWrite.c (439) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/runtimeWrite_orig.txt (60) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcproj (511) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcproj.PWI.dgarlisch.user (121) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcxproj (307) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcxproj.filters (78) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcxproj.user (3) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/module.mk (239) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/modulelocal-sample.mk (84) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtCaepInitItems.h (98) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtCaepInstanceData.h (135) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtCaepSupportData.h (89) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtPwpInitItems.h (68) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtPwpPluginInfo.h (75) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtPwpVersions.h (62) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/runtimeWrite.c (347) ; - D MeshTools/PointwiseSU2plugin/src/plugins/README.txt (272) ; - D MeshTools/PointwiseSU2plugin/src/plugins/module.mk (309) ; - D Mesh,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:17117,plugin,plugins,17117,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['plugin'],['plugins']
Modifiability,"Python's ""self"" which; // makes this solution reasonably idiomatic.; Base::Compute(wv, sol);. // Then do our specific job.; wv.area = 0.0;; for(int i=0; i<nDim; ++i); wv.area += pow(sol.areaVector[i],2);; wv.area = sqrt(wv.area);; }; };. // Same mechanics as above; template<typename Base>; class ComputeFlux : Base; {; protected:; enum : int {nDim = Base::nDim};. struct WorkVarsType : Base::WorkVarsType ; {; double flux; // ...add new member; };. template<typename WV>; void Compute(WV& wv, const SolutionContainer& sol) const; {; // ...call base; Base::Compute(wv,sol);. // ...do aditional work; wv.flux = 0.0;; for(int i=0; i<nDim; ++i); wv.flux += sol.velocity[i]*sol.areaVector[i];; }; };. // This class is used to terminate the chain, it makes the link; // with the interface and it is used to specify any fixed sizes.; template<int NDIM>; class Terminator : private VirtualInterface; {; protected:; enum : int {nDim = NDIM};. struct WorkVarsType {};. template<typename... Ts>; void Compute(Ts&...) const {}; };. // Finally we use the building blocks to implement Compute.; // The blocks can be reordered depending on application to; // help the compiler fuse loops or minimize register spillage,; // the resulting WorkVarsType definition will be equivalent.; class ComposedClass: public; ComputeFlux< ComputeArea< Terminator<3> > >; {; public:; ResultType Compute(const SolutionContainer& sol) const;; };. ResultType ComposedClass::Compute(const SolutionContainer& sol) const; {; // Create the working variables on the stack.; ComputeFlux::WorkVarsType wv;. // Pass down the working variables and whatever other arguments.; // If the convention was followed, all building blocks will run.; // Recall that all Compute's were templates, they will be; // instantiated here and we can force them to be inlined.; ComputeFlux::Compute(wv, sol);. // Do some additional work if needed and return result.; return wv.flux / wv.area;; }; ```; [Care for some assembly?](https://gcc.godbolt.org/z/os-gNg)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-622941617:5120,variab,variables,5120,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-622941617,2,['variab'],['variables']
Modifiability,"R [rbp-208], ymm1; vmovapd YMMWORD PTR [rbp-400], ymm0; cmp rax, rbx; jne .L7; ```; which makes the vectorized code perform just as well as the scalar code, iterators could also be used for the other variables but that would start to hurt readability without improving the performance much. _Note: There is also a chance the compiler (gcc) is not doing this kind of optimization because of the way I wrote the code..._. **So we need AoS to avoid losing performance in lightweight numerics classes.**. Before we look into the impact of not using SoA in the gradient and limiters routines let me tell you there is a way to have the best of both worlds, enter the *_array of structures of arrays_* or as I like to call it zig zag storage, aka a right mess.; Imagine an AoS of short arrays of SIMD length, e.g. `{ {u0 u1 u2 u3} {v0 ... v3} {w0 ... w3} {u4 u5 u6 u7} ... }` with that it is possible to fully vectorize point loops as the first index (iPoint) is contiguous in groups of SIMD length and when looping along variables and dimensions in edge loops the stride is small enough (equal to SIMD length) to trigger hardware prefetching.; The catch is that we need even more integer arithmetic and so we really need iterators to amortise that cost, there is also the drawback that scalar usage of such a container would be terrible. **For these reasons I think we should sacrifice ultimate performance and keep node data in AoS storage.**. The major impact on gradients and limiters is the way the code is written, to vectorize the computation we need to compute the gradient into a local variable and then ""transpose"" it when storing it, i.e.; ```c++; FltVec phiI[MAXNVAR], gradI[MAXNVAR][MAXNDIM];; ...; for(size_t iVar=0; iVar<nVar; ++iVar); {; auto flux = weight*(phiI[iVar]+phi.getVec(jPoint,iVar));. for(size_t iDim=0; iDim<nDim; ++iDim); gradI[iVar][iDim] += a_ij[iDim]*flux;; }; }. for(size_t iVar=0; iVar<nVar; ++iVar); for(size_t iDim=0; iDim<nDim; ++iDim); for(size_t k=0; k<SIMDLEN; ++k); g",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-535977206:13231,variab,variables,13231,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206,1,['variab'],['variables']
Modifiability,"RING ""SU2 4.1.0""; | #define PACKAGE_BUGREPORT ""su2code-dev@lists.stanford.edu""; | #define PACKAGE_URL ""https://github.com/su2code""; | #define PACKAGE ""SU2""; | #define VERSION ""4.1.0""; | /* end confdefs.h. */; | #include <ac_nonexistent.h>; configure:4644: result: gcc -E; configure:4664: gcc -E conftest.c; configure:4664: $? = 0; configure:4678: gcc -E conftest.c; conftest.c:11:28: error: ac_nonexistent.h: No such file or directory; configure:4678: $? = 1; configure: failed program was:; | /* confdefs.h */; | #define PACKAGE_NAME ""SU2""; | #define PACKAGE_TARNAME ""SU2""; | #define PACKAGE_VERSION ""4.1.0""; | #define PACKAGE_STRING ""SU2 4.1.0""; | #define PACKAGE_BUGREPORT ""su2code-dev@lists.stanford.edu""; | #define PACKAGE_URL ""https://github.com/su2code""; | #define PACKAGE ""SU2""; | #define VERSION ""4.1.0""; | /* end confdefs.h. */; | #include <ac_nonexistent.h>; configure:4707: checking for grep that handles long lines and -e; configure:4765: result: /bin/grep; configure:4770: checking for egrep; configure:4832: result: /bin/grep -E; configure:4837: checking for ANSI C header files; configure:4857: gcc -c -g -O2 conftest.c >&5; configure:4857: $? = 0; configure:4930: gcc -o conftest -g -O2 conftest.c >&5; configure:4930: $? = 0; configure:4930: ./conftest; configure:4930: $? = 0; configure:4941: result: yes; configure:4954: checking for sys/types.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for sys/stat.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for stdlib.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for string.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for memory.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:9216,config,configure,9216,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,6,['config'],['configure']
Modifiability,"SU2. If not, see <http://www.gnu.org/licenses/>. |; -------------------------------------------------------------------------. Build Configuration Summary:. Source code location: /home/antodech/SU2-4.1.0; Install location: /gshare/work/hpascalj/CodeSU2-master; Version: 4.1.0; C++ Compiler: g++; C Compiler: gcc; Preprocessor flags: ; Compiler flags: -g -O2; Linker flags: ; MPI support: no; Metis support: no; Parmetis support: no; TecIO support: no; CGNS support: yes; HDF5 support: no; SZIP support: no; ZLIB support: no; Mutation++ support: no; Jsoncpp support: no; LAPACK support: no; Datatype support:; double yes; complex no; codi_reverse no; codi_forward no. External includes: ; External libs: . Build SU2_CFD: yes; Build SU2_DOT: yes; Build SU2_MSH: yes; Build SU2_DEF: yes; Build SU2_SOL: yes; Build SU2_GEO: yes. Please be sure to add the $SU2_HOME and $SU2_RUN environment variables,; and update your $PATH (and $PYTHONPATH if applicable) with $SU2_RUN. Based on the input to this configuration, add these lines to your .bashrc file:. export SU2_RUN=""/gshare/work/hpascalj/CodeSU2-master/bin""; export SU2_HOME=""/home/antodech/SU2-4.1.0""; export PATH=$PATH:$SU2_RUN; export PYTHONPATH=$PYTHONPATH:$SU2_RUN. ## ---------------- ##; ## Cache variables. ##; ## ---------------- ##. ac_cv_build=x86_64-unknown-linux-gnu; ac_cv_c_compiler_gnu=yes; ac_cv_cxx_compiler_gnu=yes; ac_cv_env_CCC_set=; ac_cv_env_CCC_value=; ac_cv_env_CC_set=; ac_cv_env_CC_value=; ac_cv_env_CFLAGS_set=; ac_cv_env_CFLAGS_value=; ac_cv_env_CPPFLAGS_set=; ac_cv_env_CPPFLAGS_value=; ac_cv_env_CPP_set=; ac_cv_env_CPP_value=; ac_cv_env_CXXFLAGS_set=; ac_cv_env_CXXFLAGS_value=; ac_cv_env_CXX_set=; ac_cv_env_CXX_value=; ac_cv_env_LDFLAGS_set=; ac_cv_env_LDFLAGS_value=; ac_cv_env_LIBS_set=; ac_cv_env_LIBS_value=; ac_cv_env_build_alias_set=; ac_cv_env_build_alias_value=; ac_cv_env_host_alias_set=; ac_cv_env_host_alias_value=; ac_cv_env_target_alias_set=; ac_cv_env_target_alias_value=; ac_cv_file__gshare_soft_code_sa",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:19276,config,configuration,19276,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,1,['config'],['configuration']
Modifiability,"SU2/commit/ac8b3bf7636cc66ca7f47e15935942a6598e1a9f), the `SetRoe_Dissipation` function checked to see if the sensor values were valid regardless of the type of blending selected. Commit [ac8b3bf](https://github.com/su2code/SU2/commit/ac8b3bf7636cc66ca7f47e15935942a6598e1a9f) changed the behavior to only check the sensor values if they will be used. The unit test sets the convective blending to `NTS`, feeds invalid sensor values into `SetRoe_Dissipation` and checks the output. ```cpp; // Used to set the Roe-low-dissipation option; void WriteCfgFile(unsigned short nDim, const char* filename,; std::string blending) {; std::ofstream cfg_file;. cfg_file.open(filename, ios::out);; cfg_file << ""PHYSICAL_PROBLEM= NAVIER_STOKES"" << std::endl;; cfg_file << ""ROE_LOW_DISSIPATION= "" << blending << std::endl;. cfg_file.close();; }. BOOST_AUTO_TEST_CASE(BadSensorsAllowedForNTS) {. /*--- Setup ---*/. const unsigned short nDim = 3;. /*--- Set up the config class for the test ---*/; char cfg_filename[100] = ""convective_blending_test.cfg"";; WriteCfgFile(nDim, cfg_filename, ""NTS"");; CConfig* config = new CConfig(cfg_filename, SU2_CFD, 0, 1, 2, VERB_NONE);; std::remove(cfg_filename);. /*--- Inputs ---*/; const su2double dissipation_i = 0.4;; const su2double dissipation_j = 0.6;; const su2double sensor_i = NAN; // Intentionally unphysical:; const su2double sensor_j = NAN; // Intentionally unphysical:. /*--- Outputs ---*/; su2double dissipation;. /*--- Test ---*/. CNumerics numerics;; numerics.SetRoe_Dissipation(dissipation_i, dissipation_j,; sensor_i, sensor_j,; dissipation, config);. const su2double tolerance = std::numeric_limits<su2double>::epsilon();; BOOST_CHECK_CLOSE_FRACTION(dissipation, 0.5, tolerance);. /*--- Teardown ---*/; delete config;; }; ```. There's a couple problems I would fix if I had more time. Ideally, I would be writing the cfg file to an in-memory stream and not to a file. And realistically, I shouldn't need to use a config file at all for a simple test like this.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499999225:1409,config,config,1409,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499999225,4,['config'],['config']
Modifiability,"SU2] Feature deallocation (#174). Bringing this branch up to date with current develop branch. ; Various deallocation changes; Some regression tests fail but all run. (previously was not the case); You can view, comment on, or merge this pull request online at:;   https://github.com/su2code/SU2/pull/174; Commit Summary; - Updated GetEngine_Properties; - Fix to the last commit; - Small bug; - Merge branch 'develop' into feature_MPI; - merging; - SU2_SOL and SU2_CFD are working; - Preliminary, but complete, implementation of SU2_DEF; - More updates; - Working version; - Complete implementation (validate); - Working version of SU2_DEF; - Final push before moving to the develop branch; - New MPI (removing SU2_PRT); - Merged in Ben's ParMETIS integration and fixed some conflicts.; - Merge branch 'benkirk-parmetis_integration' into feature_MPI; - ParMETIS geometry routines have been copied over but are not activated yet.; - Small change to ParMETIS include.; - ParMETIS can now be activated for testing (PARMETIS=YES in config).; - Updated MG; - Updated EA subrotuine; - Small fix; - Fixing memory leak; - Fixing memory leaks; - Dev release v.3.2.6; - Increasing MAX_NUMBER_MARKER; - Working version with ParMETIS. Fixed bug in global index. Now clean up and testing...; - Cleaned version of ParMETIS routines with better console output during partitioning.; - Small bug in initial element division.; - Made arrays in ParMETIS call dynamic.; - Fixed compiler warnings and added MPI directives so that the pure serial code works with the ParMETIS routines.; - Bootstrap on zion.; - Added some typecasts. Still tracking down a memory problem...; - Critical bug fix for vtxdist array.; - Partial fix; - More MPI improvements.; - Fixing a bug in SU2_DEF; - Updated BC_ActDisk_Boundary (MPI); - Merge remote-tracking branch 'upstream/develop' into develop; - changing solidboundary setting to be heatflux OR euler etc instead of AND, also working on doxygen documentation; - Dynamic allocation for ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:1824,config,config,1824,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['config'],['config']
Modifiability,"S_H 1; | #define HAVE_SYS_STAT_H 1; | #define HAVE_STDLIB_H 1; | #define HAVE_STRING_H 1; | #define HAVE_MEMORY_H 1; | #define HAVE_STRINGS_H 1; | #define HAVE_INTTYPES_H 1; | #define HAVE_STDINT_H 1; | #define HAVE_UNISTD_H 1; | #define SIZEOF_SHORT_INT 2; | #define SIZEOF_INT 4; | #define SIZEOF_UNSIGNED_INT 4; | #define SIZEOF_LONG_INT 8; | #define SIZEOF_FLOAT 4; | #define SIZEOF_DOUBLE 8; | #define SIZEOF_VOID_P 8; | /* end confdefs.h. */; | #include <X11/Intrinsic.h>; configure:5409: result: no; configure:5409: checking for X11/Intrinsic.h; configure:5409: result: no; configure:5721: checking for /gshare/soft/code_saturne/4.0.0/prod/cgnslib_3.2.1/lib/libcgns.a; configure:5735: result: yes; configure:5755: checking for /gshare/soft/code_saturne/4.0.0/prod/cgnslib_3.2.1/include/cgnslib.h; configure:5769: result: yes; configure:6815: checking that generated files are newer than configure; configure:6821: result: done; configure:6952: creating ./config.status. ## ---------------------- ##; ## Running config.status. ##; ## ---------------------- ##. This file was extended by SU2 config.status 4.1.0, which was; generated by GNU Autoconf 2.69. Invocation command line was. CONFIG_FILES = ; CONFIG_HEADERS = ; CONFIG_LINKS = ; CONFIG_COMMANDS = ; $ ./config.status . on master. config.status:875: creating externals/tecio/Makefile; config.status:875: creating externals/metis/Makefile; config.status:875: creating externals/parmetis/Makefile; config.status:875: creating Makefile; config.status:875: creating externals/Makefile; config.status:875: creating Common/lib/Makefile; config.status:875: creating SU2_CFD/obj/Makefile; config.status:875: creating SU2_DOT/obj/Makefile; config.status:875: creating SU2_MSH/obj/Makefile; config.status:875: creating SU2_DEF/obj/Makefile; config.status:875: creating SU2_SOL/obj/Makefile; config.status:875: creating SU2_GEO/obj/Makefile; config.status:875: creating SU2_PY/Makefile; config.status:1047: executing depfiles commands; configure:818",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:15706,config,config,15706,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,1,['config'],['config']
Modifiability,"Simplest is to just copy the saved file again, with an iteration number appended. No keeping track of what the iteration number at the previous write was, no copying of the final saved file with manually appending the final iteration number, no lag of WRT_FREQ in the availability of the restart_xxx.dat file. It does mean that we do a copy instead of a rename. But I think this is the better (because the simplest) solution. I will extend it to the other file options.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1465#issuecomment-1005529868:433,extend,extend,433,https://su2code.github.io,https://github.com/su2code/SU2/pull/1465#issuecomment-1005529868,1,['extend'],['extend']
Modifiability,"So I tested this on 4 mesh levels for a NACA0006 at 2.0 degrees AoA, at low (0.6) and high-ish (0.8) Mach number (Roe scheme).; These are the results for low Mach:; ![image](https://user-images.githubusercontent.com/38071223/61968547-3b08c680-afd0-11e9-8aae-9705a9441a00.png); Very small differences between recomputing a mass flux based on primitives (""Reconstructed"") or storing the flux computed during discretization of convection (""Consistent"").; However, the convergence rate for the latter approach is much worse:; ![image](https://user-images.githubusercontent.com/38071223/61968712-99ce4000-afd0-11e9-9c31-dafd7e26e3fb.png); Which makes sense because we are going from a Gauss-Seidel coupling of flow and turbulence to a half GS, half Jacobi (since the turbulence source terms were still computed with current velocity gradients).; After seeing this I only ran one mesh level (second to finest) at high Mach number and again differences were very small and convergence worse.; Some memory would indeed be saved in the discrete adjoint through the reduction of the number of pre-accumulation input variables, but only 30MB out of almost 9GB for a 2D case without MG. In summary the current approach seems to strike a good balance between accuracy, cost, and simplicity.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/721#issuecomment-515535554:693,coupling,coupling,693,https://su2code.github.io,https://github.com/su2code/SU2/issues/721#issuecomment-515535554,2,"['coupling', 'variab']","['coupling', 'variables']"
Modifiability,Sounds good to me. I have been prototyping the multizone driver in the last couple of weeks. It's still in the early stages but it's slowly taking shape. You can find it here:; https://github.com/su2code/SU2/tree/feature_reformat_config. I also outlined some of the changes (particularly in what respects to the config file) in the Dev-society forum: https://su2devsociety.org/forum/?view=thread&id=5 . We could keep the conversation there if you want. Happy to set up a meeting to explain a bit what I have been doing and receive some feedback (and helping hands would also be welcome!) from the different groups.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/528#issuecomment-392061901:312,config,config,312,https://su2code.github.io,https://github.com/su2code/SU2/pull/528#issuecomment-392061901,1,['config'],['config']
Modifiability,"T_H 1; | #define HAVE_UNISTD_H 1; | #define SIZEOF_SHORT_INT 2; | #define SIZEOF_INT 4; | #define SIZEOF_UNSIGNED_INT 4; | #define SIZEOF_LONG_INT 8; | #define SIZEOF_FLOAT 4; | #define SIZEOF_DOUBLE 8; | #define SIZEOF_VOID_P 8; | /* end confdefs.h. */; | #include <stdio.h>; | #ifdef HAVE_SYS_TYPES_H; | # include <sys/types.h>; | #endif; | #ifdef HAVE_SYS_STAT_H; | # include <sys/stat.h>; | #endif; | #ifdef STDC_HEADERS; | # include <stdlib.h>; | # include <stddef.h>; | #else; | # ifdef HAVE_STDLIB_H; | # include <stdlib.h>; | # endif; | #endif; | #ifdef HAVE_STRING_H; | # if !defined STDC_HEADERS && defined HAVE_MEMORY_H; | # include <memory.h>; | # endif; | # include <string.h>; | #endif; | #ifdef HAVE_STRINGS_H; | # include <strings.h>; | #endif; | #ifdef HAVE_INTTYPES_H; | # include <inttypes.h>; | #endif; | #ifdef HAVE_STDINT_H; | # include <stdint.h>; | #endif; | #ifdef HAVE_UNISTD_H; | # include <unistd.h>; | #endif; | #include <X11/Intrinsic.h>; configure:5409: result: no; configure:5409: checking X11/Intrinsic.h presence; configure:5409: gcc -E conftest.c; conftest.c:28:27: error: X11/Intrinsic.h: No such file or directory; configure:5409: $? = 1; configure: failed program was:; | /* confdefs.h */; | #define PACKAGE_NAME ""SU2""; | #define PACKAGE_TARNAME ""SU2""; | #define PACKAGE_VERSION ""4.1.0""; | #define PACKAGE_STRING ""SU2 4.1.0""; | #define PACKAGE_BUGREPORT ""su2code-dev@lists.stanford.edu""; | #define PACKAGE_URL ""https://github.com/su2code""; | #define PACKAGE ""SU2""; | #define VERSION ""4.1.0""; | #define STDC_HEADERS 1; | #define HAVE_SYS_TYPES_H 1; | #define HAVE_SYS_STAT_H 1; | #define HAVE_STDLIB_H 1; | #define HAVE_STRING_H 1; | #define HAVE_MEMORY_H 1; | #define HAVE_STRINGS_H 1; | #define HAVE_INTTYPES_H 1; | #define HAVE_STDINT_H 1; | #define HAVE_UNISTD_H 1; | #define SIZEOF_SHORT_INT 2; | #define SIZEOF_INT 4; | #define SIZEOF_UNSIGNED_INT 4; | #define SIZEOF_LONG_INT 8; | #define SIZEOF_FLOAT 4; | #define SIZEOF_DOUBLE 8; | #define SIZEOF_VOID_P 8",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:14078,config,configure,14078,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,2,['config'],['configure']
Modifiability,"Thank you @TobiKattmann for your feedback. The idea behind this new regression test config file is as follows:; We should have a test case that triggers the negative part of the SA model. Depending on the flow conditions, geometry and CFD parameters it might be triggered or not. With the previous config file, it was not. ; I think there is already a regression test in SU2 that triggers the negative SA, the `turb_oneram6_nk`. However, I decided to stick to rae2822 airfoil as it is a simpler (faster) case. In order to force the negative part of the SA for the rae2822 in a reasonable amount of iterations for a regression test, I increased the angle of attack. I have removed the multigrid as it might not be stable, but I have not tested though. Anyway, with the current configuration, e.g., convective scheme, CFL number, etc, the solution is not stable and diverges after some iterations, around 15. In that sense, I reduced the number of iterations from 20 to 10. In my opinion, a diverging regression test is not a problem at all as it might not be used as a tutorial, only to verify the integrity of the commit. ""The solution should always diverge to the same results"". If the regression test should converge, let me know and I will update the config file :)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1559#issuecomment-1067926363:84,config,config,84,https://su2code.github.io,https://github.com/su2code/SU2/pull/1559#issuecomment-1067926363,4,['config'],"['config', 'configuration']"
Modifiability,"Thank you for the pull request. ; Pull requests must be both to and from the ""develop"" branch (or the relevant feature branch if applicable). In order to make a pull request, please check out the develop branch, make your changes, and submit the pull request into to develop branch. . While this might be useful in some situations, and particularly the record of this pull request can be an example to other users who want to use Docker with SU2, it looks like this is specific to a version of Ubuntu, and that you have hard-coded some lines to refer to locations on your own file system. We try to make it such that SU2 will be usable in most operating systems, with appropriate changes to the configuration steps. . Since it is setting up a development environment this would be more appropriate to SU2_IDE/, rather than Quickstart/ - which is intended as the main tutorial for new users, who are not necessarily developers and who may not have heard of Docker.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/169#issuecomment-96786749:695,config,configuration,695,https://su2code.github.io,https://github.com/su2code/SU2/pull/169#issuecomment-96786749,1,['config'],['configuration']
Modifiability,"Thank you for the thorough review @rsanfer! I'll reply to your main questions and some of the smaller ones here to centralize things. > Just a request, if it's possible that you add one or two test cases so the implementation is safe onwards (and, of course, so I can play around with the new features a little bit ). The testcases are the same, no changes there other than the one optional option introduced above. When the hybrid stuff covers most of the code I would add an entire build configuration e.g. BaseMPIOMP and corresponding testcase suite. > * Should this just run ""out of the box"" with a working installation of OpenMP in any machine, or is there anything else _fancy_ needed?. I would leave it to the community to decide what the defaults should be, probably for a lot of new users that don't run on clusters just calling SU2_CFD and not having to worry about mpi would be nice (a lot of the issues on CFD online are mpi related). > * Is the previous behaviour exactly kept, or are there any modifications in the basic, non OpenMP version of code? (Not that I mind, just curious). Other than the algorithmic changes (but mathematically equivalent) introduced to limiters and gradients in #834, yes. > What's the advantage of having one numerics term per thread?. It is a requirement, we need to write data into numerics before using them, multiple threads cannot write to the same location (i.e. the internal structures of CNumerics) therefore one per thread is required. > ...Also, I think I missed the point where the numerics container is extended beyond MAX_TERMS. The allocation of space for one numerics per thread is done above in line 1995 of my 21 Dec 2019 comment: `...MAX_TERMS*omp_get_max_threads()...`.; The instantiation of one numerics per thread is then done by executing the rest of the preprocessing in parallel and instead of using `XYZ_TERM` using `XYZ_TERM+offset` where `offset = thread_id * MAX_TERMS`.; I think someone mentioned this (maybe Tim) that we could r",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/843#issuecomment-577684728:490,config,configuration,490,https://su2code.github.io,https://github.com/su2code/SU2/pull/843#issuecomment-577684728,1,['config'],['configuration']
Modifiability,"Thanks Brian,; my bad, I misinterpreted the carpets / logs structure. I successfully ran a test of a very simple case. In the results there are some small artifacts, but the shocks are resolution improved consistently after mesh adaption.; Thanks for the support. ![Comparison](https://user-images.githubusercontent.com/41752169/80644172-84a7a580-8a69-11ea-9f16-58e98c808b73.png); ![ComparisonMesh](https://user-images.githubusercontent.com/41752169/80644174-85403c00-8a69-11ea-819f-2ac00550a089.png)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/948#issuecomment-621450497:229,adapt,adaption,229,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-621450497,1,['adapt'],['adaption']
Modifiability,"Thanks Edwin, the vectorized loops in the code are probably very simple array copies, hence the low efficiency? I would put money on not a single vector instruction being generated for the important stuff. I was surprised by the 1.25 to 1.3 factor you are seeing, for the exact same case I measured 1.39 (to be more precise). Initially I thought it had something to do with running single core, thus leaving vast amounts of L3 for only that core to use, so on the same 24c platform I ran 2 processes (30MB of cache for each) (very uncivilised) and the factor went down to 1.37, so cache was not the reason.; So then I thought maybe the Intel compilers are very good at optimizing polymorphism away, but the development branch compiled with icc 17 runs at exactly the same speed as when compiled with gcc 5.4. Then I compiled feature_contiguous_cvariable with icc 17 and it runs 9% slower than the gcc binaries, and so with icc 17 the speedup for this case was 1.27 errrrr... Anyone got a buddy at Intel?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/716#issuecomment-523930905:680,polymorphi,polymorphism,680,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-523930905,1,['polymorphi'],['polymorphism']
Modifiability,"Thanks Pedro for hinting me at this coupling issue again, now I think I understand it! . **For the record**, here is what I talked about in today's developer meeting:; When I make the following changes in the `issue_simplified/multizone/multizone-i.cfg` :. 88c88; < CFL_NUMBER= 0.1; ---; > CFL_NUMBER= 1000.0; 162c162; < TIME_DISCRE_FLOW= EULER_EXPLICIT; ---; > TIME_DISCRE_FLOW= EULER_IMPLICIT; 177c177; < TIME_DISCRE_TURB= EULER_EXPLICIT; ---; > TIME_DISCRE_TURB= EULER_IMPLICIT. then the simplified multizone setup converges, albeit to a different solution:; ![simplified-multizone-explicit-cfl01-density](https://user-images.githubusercontent.com/72806890/139096529-5063dbe7-8ee8-4c53-a7c6-a2b6b3a031a1.png); than what the simplified singlezone setup (from above) converged to: ; ![simplified-singlezone-density](https://user-images.githubusercontent.com/72806890/139096586-7d096c5f-4d34-4ddb-94fa-0deab52df5e4.png). The same observation can be made analogously for `issue_complicated`:; The multizone setup with explicit Euler and CFL=0.1 (nearly) converges (actually the residual stalls at `avg[bgs][0]` approximately -13) to the following limit:; ![complicated-multizone-explicit-cfl01-density](https://user-images.githubusercontent.com/72806890/139096973-e9547f9f-521e-4920-aba5-2621fad79944.png); while the singlezone solution (with implicit Euler and CFL 1000) is (**EDIT**: was momentum plot, replaced by density plot); ![complicated-singlezone-density](https://user-images.githubusercontent.com/72806890/139109790-e5cae4be-041e-4c29-93a5-e086a26f72a4.png)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1414#issuecomment-953043430:36,coupling,coupling,36,https://su2code.github.io,https://github.com/su2code/SU2/issues/1414#issuecomment-953043430,1,['coupling'],['coupling']
Modifiability,"Thanks Tom; I agree that we should make things easy to understand. ; My thinking was that most users will want to know what parts of the mesh they are moving, but don't necessarily need to know what's happening underneath - if they specify the entire mesh the code just reverts to the more efficient method. But (from the users perspective) it may be just as easy to have a separate specification for scaling the entire mesh. . In terms of moving it to SU2_MSH; I think it may make sense to include scale/rotate/translate in SU2_MSH, but I think it would be confusing to have two options that do the same thing. I would side with separate option names (this would also eliminate a loop over markers in this pull request). On this topic, I have sometimes found MARKER_DESIGNING and DV_MARKER to be confusing; on their own they sound very similar, in the description MARKER_DESIGNING is where the objective function is evaluated - but in the code, it's not clear what MARKER_DESIGNING does - the surfaces specified by MARKER_MONITORING are what are actually used to evaluate the objective function value. . There may be other similar areas where config file options could be clarified or compressed.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/187#issuecomment-132181536:1144,config,config,1144,https://su2code.github.io,https://github.com/su2code/SU2/pull/187#issuecomment-132181536,1,['config'],['config']
Modifiability,"Thanks a lot for your feedback, we have updated the files. ; For the time being, just remove MG_CFL_REDUCTION= 0.9 in your config file.; Best,; Francisco",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/44#issuecomment-54904983:123,config,config,123,https://su2code.github.io,https://github.com/su2code/SU2/issues/44#issuecomment-54904983,1,['config'],['config']
Modifiability,"Thanks at all for being so responsive to this mishap. When I started contributing I learned that something like a 2-LGTM-rule was applying. But apparently it evolved to have someone merge a pull request if he or she can judge the content and feels comfortable with it, as the other approach ended up having a large list of unmerged pull requests **or** having two LGTM's of non-independent reviewers. @economon Maybe you can bring it up at the next meeting how we could address this little double bind?. So sorry again for the trouble (at least a revert of the very latest commit would not be too difficult). Still I'll wait if @pcarruscag and @talbring want to do now the way Tim suggested.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/667#issuecomment-480015080:158,evolve,evolved,158,https://su2code.github.io,https://github.com/su2code/SU2/pull/667#issuecomment-480015080,1,['evolve'],['evolved']
Modifiability,"Thanks for adding the description, Heather. I think this is a very nice contribution.. we’re working on the regressions and will pull this in once we have everything straightened out (and this branch passes). In the meantime, you got me thinking: the scale, rotate, translate options might be confusing now if a user doesn’t know whether to include the markers or not. Perhaps this is a chance for separating some of the “design” options from “mesh” options. One way I could see us do this is by moving the implementation I had just committed for the “volume” scale, rotate, and translate options over into the SU2_MSH executable, which might be a more logical home for it. However, this would require adding an extra set of config options for reading in a scale/rotate/translate options for SU2_MSH. The nice thing here is that we keep the intent separate, i.e., only design variables are listed with the other design variables while the mesh transformations are elsewhere. A different, possibly simpler way would be to just create separate names for these two types in the list of available options so that there is no ambiguity. Any thoughts?. On Aug 16, 2015, at 9:21 AM, Heather Kline <notifications@github.com<mailto:notifications@github.com>> wrote:. Some illustrative images/output in case my description was hard to understand:; [image]https://cloud.githubusercontent.com/assets/5167760/9294050/52a764b2-440f-11e5-8681-b68318da0ce7.png. SU2_DEF output when only ""airfoil"" marker included:. ------------------------- Surface grid deformation ----------------------; Performing the deformation of the surface grid. ----------------------- Volumetric grid deformation ---------------------; Performing the deformation of the volumetric grid. # FGMRES residual history. # Residual tolerance target = 4.14044e-11. # Initial residual norm = 15.8102. ```; 0 1; 50 2.17385e-06; 100 1.08998e-10; ```. # FGMRES final (true) residual:. # Iteration = 105: |res|/|res0| = 3.50764e-11. Non-linear iter.: 1/",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/187#issuecomment-132065067:725,config,config,725,https://su2code.github.io,https://github.com/su2code/SU2/pull/187#issuecomment-132065067,3,"['config', 'variab']","['config', 'variables']"
Modifiability,"Thanks for the clarification!. Best,; Francisco. > On Apr 22, 2017, at 5:01 PM, Heather Kline <notifications@github.com> wrote:; > ; > Thanks; > The discrete adjoint can also be used with combined objectives, and uses the same config specifications. It may not be clear from this pull request since this functionality was added in a previously - when multiple objectives (limited to objectives defined inside the CFD solver) are specified, they are added together (with specified weights) in the CFD solver into the 'COMBO' output to history. This variable is registered for the discrete adjoint solver.; > An example of this can be seen in the serial_regression_AD.py, test name 'discadj_multi_py'.; > ; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/pull/385#issuecomment-296409557>, or mute the thread <https://github.com/notifications/unsubscribe-auth/AEpklrJ5WQ8CoWJNAy_FVZ0bbYN000s2ks5rypTpgaJpZM4MgM_e>.; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/385#issuecomment-296409876:227,config,config,227,https://su2code.github.io,https://github.com/su2code/SU2/pull/385#issuecomment-296409876,2,"['config', 'variab']","['config', 'variable']"
Modifiability,"Thanks for the explanation @suargi . I would personally advocate for that the testcases should converge to some reasonable solution people might use it as a starting point (copy the cfg and doing mild adaptions) for their own stuff. And the Testcases show off the capabilities to some degree, to do so, convergence is beneficial. But as we have a bunch of working 2D airfoils in regression already I recon that adding a clear explanation and warning to the cfg as suggested by Pedro is fine. Otherwise you might try to bisect the AoA ... maybe there is a value that triggers negative SA and does not diverge :thinking: . Knowingly adding a diverging test without a clear warning is not good imo :)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1559#issuecomment-1067977083:201,adapt,adaptions,201,https://su2code.github.io,https://github.com/su2code/SU2/pull/1559#issuecomment-1067977083,1,['adapt'],['adaptions']
Modifiability,"Thanks for the feedback @pcarruscag. @jayantmukho and I discussed this when we implemented the objective function. The main motivation was that since our implementation of the separation sensor is computed using the skin friction coefficient, we only defined the variables Buffet_Sensor, Buffet_Metric, etc. for the NSSolver class. Since the NSSolver needs to be able to evaluate all the same objectives as the EulerSolver, but the buffet objective is exclusive to the NSSolver, I copy pasted the function and added the new objective. Let me know if you have any suggestions for a cleaner implementation. We were basically choosing between defining all the Buffet_* variables in EulerSolver which would just add unnecessary variables to the constantly growing list of variables, or copying EvaluateObj_Func to allow for NS-specific objectives.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/614#issuecomment-441300657:263,variab,variables,263,https://su2code.github.io,https://github.com/su2code/SU2/pull/614#issuecomment-441300657,4,['variab'],['variables']
Modifiability,"Thanks for the fixes, Francisco. The continuous adjoint tests are now failing, but I am guessing that it is something simple with the changes to the config option. Can you please take a look when you have a moment?. Couldn't agree more about keeping an eye on the Python scripts. We'll chat about it this week at the developer meeting (we need regressions for the Python scripts). More on that to come.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/244#issuecomment-191571633:149,config,config,149,https://su2code.github.io,https://github.com/su2code/SU2/pull/244#issuecomment-191571633,1,['config'],['config']
Modifiability,"Thanks for the hint, just uploaded a screenshot of the mesh adaption!; Now I'm trying to run a simple 3D case, but unfortunately the amg.out fails during the first try (in the adap/ini folder):; ```; ## 16739 TRIANGLE(S) DISCARDED ; fefloa_Python2Mesh : 3d mesh on input ; fefloa_Python2Mesh : msh->NbrVer 14368 ; fefloa_Python2Mesh : msh->NbrTet 58189 ; fefloa_Python2Mesh : leaving with 14368 ver. 16740 tri. 0 edg. ; -- Maximal memory ; Maximum number of Points 53800000 ; Maximun number of Bnd Points 10760000; Maximum number of Triangles 21520000 ; Maximum number of Tetrahedra 295900000 ; Allocated Memory 50.105 Gb ; Physical Memory 62.729 Gb; bounding box x: -100 200 y: -150 150 z: -150 150 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; 14368 Vertex ; 3 Boundary Vertices ; 58189 Tetrahedra ; 1 Triangles ; 0 Edges ; 1 Surface(s) ; % Output subdom.meshb Mesh ndimn=3, mpoin=14368, melem=58189, mface=1; Corners 0 Required 0 ; ## ERROR : TETRAHEDRON 2 BOUNDARY FACE 1 2; 9 IS MISSING ; ## ERROR : TETRAHEDRON 4 BOUNDARY FACE 3 7; 2324 IS MISSING ; ···; ## ERROR: FEFLO.A: 16740 BOUNDARY FACES ARE MISSING ; CHECK YOUR MESH . ## FATAL ERROR: FEFLOA: INITIAL OR CURRENT MESH HAS AN IN",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/948#issuecomment-623572280:60,adapt,adaption,60,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-623572280,1,['adapt'],['adaption']
Modifiability,"Thanks for your comments! Except for mixing plane and frozen rotor, sliding plane is also pretty common in turbomachinery simulation, it is indeed implemented in some, if not all, in-house codes. ; MRF is quite useful in turbomachinery simulation, expecially when we deal with transient simulation. Actually it is really rare to move the rotor mesh like in reality. One reason is that MRF is more efficient and accurate. Otherwise, you introduce new disturbance into the transient flow field every physical time step, which is not good. Because when you rotate the mesh, the velocity direction of each grid point inherited from last time step is not rotated. To make it more clear, you will have a flow going towards casing instead of parallel to, at the start of next physical time step. So you need more pseudo time steps to get a proper velocity variable. As a result, you get a zig-zag shape in the residual history.; I'm not actually moving the interface. The rotor mesh is not rotated, so as the interface at rotor zone. I'm just virtually rotating the rotor interface to find the new matching points between rotor and stator for each physical time step, so that the variable could be passed across the interface. In other words, only the passing variables are actually rotated. If I understand it correctly, there is no additional moving mesh restriction introduced here.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/2173#issuecomment-1953783506:613,inherit,inherited,613,https://su2code.github.io,https://github.com/su2code/SU2/pull/2173#issuecomment-1953783506,4,"['inherit', 'variab']","['inherited', 'variable', 'variables']"
Modifiability,"Thanks for your feedback! I agree, `OMP_NUM_THREADS` is better than having the number of threads in the constructor. I adapted `disc_adj_flow` and `disc_adj_fea` for MPI and added both to parallel AD and hybrid AD tests.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1966#issuecomment-1472198978:119,adapt,adapted,119,https://su2code.github.io,https://github.com/su2code/SU2/pull/1966#issuecomment-1472198978,1,['adapt'],['adapted']
Modifiability,"Thanks, Edwin. I had originally toyed around with this too, but I thought using the system-specific versions would be most portable at first. However, for something this simple, I agree that we should just do it ourselves. I have reused your implementation with some minor modifications. Could you please just confirm that the code posted above is yours, you are ok with me adapting it, and that I can name you as an author at the top of the file (I have added you there)?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/562#issuecomment-414092502:123,portab,portable,123,https://su2code.github.io,https://github.com/su2code/SU2/pull/562#issuecomment-414092502,2,"['adapt', 'portab']","['adapting', 'portable']"
Modifiability,"Thanks, I’ll take a look at that before the weekend,. Best,; Francisco. > On Mar 2, 2016, at 8:03 PM, Thomas D. Economon notifications@github.com wrote:; > ; > Thanks for the fixes, Francisco. The continuous adjoint tests are now failing, but I am guessing that it is something simple with the changes to the config option. Can you please take a look when you have a moment?; > ; > Couldn't agree more about keeping an eye on the Python scripts. We'll chat about it this week at the developer meeting (we need regressions for the Python scripts). More on that to come.; > ; > —; > Reply to this email directly or view it on GitHub https://github.com/su2code/SU2/pull/244#issuecomment-191571633.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/244#issuecomment-191590831:309,config,config,309,https://su2code.github.io,https://github.com/su2code/SU2/pull/244#issuecomment-191590831,1,['config'],['config']
Modifiability,"Thanks, Tim. Adding flexibility to the FFD is a great contribution. I was just going through the changes and I have a couple of questions:; 1. I noticed that you have added AD as an option for computing the geometric sensitivity component (change in the surface location due to a delta change in the design variable) that multiplies the adjoint sensitivity. Is there a way to make this usable for the continuous adjoint too rather than using finite differencing? This assumes that the user has built the AD version, even though they use the continuous adjoint.; 2. On a related note (I think), is the finite differencing that is currently used for computing the geometric sensitivity the only roadblock to arbitrary FFD movements for the continuous adjoint?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/239#issuecomment-183462794:307,variab,variable,307,https://su2code.github.io,https://github.com/su2code/SU2/pull/239#issuecomment-183462794,1,['variab'],['variable']
Modifiability,"Thanks; The discrete adjoint can also be used with combined objectives, and uses the same config specifications. It may not be clear from this pull request since this functionality was added in a previously - when multiple objectives (limited to objectives defined inside the CFD solver) are specified, they are added together (with specified weights) in the CFD solver into the 'COMBO' output to history. This variable is registered for the discrete adjoint solver. ; An example of this can be seen in the serial_regression_AD.py, test name 'discadj_multi_py'.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/385#issuecomment-296409557:90,config,config,90,https://su2code.github.io,https://github.com/su2code/SU2/pull/385#issuecomment-296409557,2,"['config', 'variab']","['config', 'variable']"
Modifiability,"The _amgio extension should be built by default. I haven't had any issues on any of the machines I've built on, so I appreciate the feedback. Just curious, are you running with python >=3.7? The shebang in all the SU2 python scripts; ```; #!/usr/bin/env python; ```; uses whatever python is set to in your environment variables, but pyamg/_amgio will only build/run with python >=3.7. Could you also check if the _amgio extension was installed in your site-packages (probably located in ~/.local/lib/python3.x/site-packages)?. If it didn't build/install, you could go into extensions/AMGIO/su2io and run; ```; python3 setup.py build_ext && python3 setup.py install; ```; If it did build/install, try the command; ```; python3 $SU2_RUN/mesh_adaptation_amg.py -f invCyl.cfg -n 6; ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/948#issuecomment-619334494:318,variab,variables,318,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-619334494,1,['variab'],['variables']
Modifiability,"The answer to that is very simple. Look in the data set that is present in the szplt file. The z-coordinate is not in there anymore and consequently Tecplot takes the next variable, the density in this case, as the z-coordinate. Consequently you git a picture like you showed. The same is true for the field solution. Also there the z-coordinate is not present in the szplt file and hence you get a rather funny picture when you attempt to visualize this in 3D. But 2D visualization works just fine. In contrast the z-coordinate is stored in the vtu files, because the standard requires that. Hence you can still visualize this in 3D. Could you try a truly 3D test case to see if that visualizes fine? If so, please let us know such that we can close this issue.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1182#issuecomment-771407798:172,variab,variable,172,https://su2code.github.io,https://github.com/su2code/SU2/issues/1182#issuecomment-771407798,1,['variab'],['variable']
Modifiability,"The dimensional inconsistency comes from the multiplicity of the normal velocity eigenvalue and the manipulation Hirsch does with the corresponding eigenvectors in order to obtain a formulation that is valid for any normal vector. When you use the P matrix to form the characteristic variables, the dimensional inconsistency disappears again, as it should. Never looked at it this way. Thanks for clearing this up Francisco.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/423#issuecomment-322124810:284,variab,variables,284,https://su2code.github.io,https://github.com/su2code/SU2/issues/423#issuecomment-322124810,1,['variab'],['variables']
Modifiability,The dummy layer is what we used before version 7 and moved away from it for simplicity.; Two layers doesn't sound possible for unstructured meshes.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/2038#issuecomment-1557818415:93,layers,layers,93,https://su2code.github.io,https://github.com/su2code/SU2/pull/2038#issuecomment-1557818415,1,['layers'],['layers']
Modifiability,"The fix is not as simple, using the strategy from #1631 makes it worse.; Intersection with symmetry/euler look ok, so the best is to extend the domain...",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1639#issuecomment-1132302976:133,extend,extend,133,https://su2code.github.io,https://github.com/su2code/SU2/issues/1639#issuecomment-1132302976,1,['extend'],['extend']
Modifiability,"The motivation of having it as the default was to make the code as user-friendly as possible (fewer knobs exposed in the config), but options are good of course. I would propose then that we add an option for the reconstruction gradient, something like:; ```; NUM_METHOD_GRAD_RECON= LEAST_SQUARES; ```; to let users decide if they want a separate option for the reconstruction gradients. If it does not appear, then the default is to use the same method as defined by NUM_METHOD_GRAD without a second gradient computation (basically what we have now). The nice thing about that is we can even try out other combos such as WLS+GG for the two different gradients. I will throw an error if users try to use LSQ for the viscous/source gradients, to avoid accuracy issues. What do you think?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/790#issuecomment-533259202:121,config,config,121,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-533259202,1,['config'],['config']
Modifiability,"The solver with the closest functionality to what you are trying to do is the elasticity solver, it may be worth having a look there. But in a nutshell there the variables we want to differentiate are held by (members of) the discrete adjoint solver, they are reset before being registered as inputs to clear the derivative information, and it is important that they are left alone during the recording phase.; You will see that the adjoint iteration class for this solver then needs to update the numerics classes (in SetDependencies), at least for the source term the SA coefficients are set in the constructor of the corresponding numerics so maybe this step is missing?; The key point is that whenever a coefficient is used you need to be able to trace its value back to the original variable you registered.; Also the derivatives should be extracted in the same order they were registered, and you cannot access them multiple times by calling ""GetDerivative"" on them repeatedly (not 100% sure if this restriction still exists after the update of CoDi).; If none of this makes sense point me to branch you are working on.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/679#issuecomment-491910935:162,variab,variables,162,https://su2code.github.io,https://github.com/su2code/SU2/issues/679#issuecomment-491910935,2,['variab'],"['variable', 'variables']"
Modifiability,"There is only one efficient way to move data between memory and registers, via `load` and `store` instructions (they do come in multiple flavors). That is, pointing to a memory location and reading or writing N elements of contiguous data.; It is not the only way, it is also possible to `gather` and `scatter` data. That is populating the register from non-contiguous locations and vice versa. This is about one order of magnitude slower, to the point where if the computations are very simple it may not pay-off to vectorize. **Relation with algorithms**; Some form of `gather` and `scatter` is required in unstructured CFD, which means SIMD has a price of admission. Some thought needs to go into designing algorithms that amortize that cost by maximizing the so called FLOP/Byte ratio, and mask the latency of those operations by being able to start computing as soon as the first element of data is available. **What elements should we try to process simultaneously?**; The choice is between multiple geometric primitives (edges/points) or multiple solution primitives (variables). The latter sounds like a sensible idea until we get to areas of the code where different primitives require different treatment, that and the fact that the number of variables might not fit evenly in the number of lanes can lead to very tricky and non-generic code. Nevertheless if the same code were to be applied to e.g. 4 solution variables, this strategy would likely perform better as it avoids the pesky gather/scatter operations.; Processing multiple geometric primitives can make full utilization of whatever register size (important on GPU's), the code is just as readable (as I hope to show), but gather/scatter cannot be avoided. ### Intro to SPMD; This one is simpler, in a nutshell multiple threads operate on the sub domain of an MPI rank.; The typical implementation has each thread executing a chunk of an edge or cell loop. **Why should we care about SPMD?**; Reduce the communication overhead re",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-529662724:2204,variab,variables,2204,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-529662724,1,['variab'],['variables']
Modifiability,"There was a lot of talk about refactoring the shape optimization framework to be able to work completely in memory.; I think the idea was not to have more drivers but simply to have more granularity such that you could manipulate the geometry from python (without writing it to files).; We also wanted introspection, i.e. you could probe SU2 via python for what variables and functions are available.; We also talked about having the projection step (DOT) included in CFD_AD so that you only need to worry about surface sensitivities, note that DEF is already part of CFD for forward mode AD.; (talking does not go very far). If you want to lead this work, we can help you understand the inner workings. We meet every Wednesday at 4pm CET https://meet.jit.si/SU2_DevMeeting to discuss this type of issue.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1262#issuecomment-818786416:30,refactor,refactoring,30,https://su2code.github.io,https://github.com/su2code/SU2/issues/1262#issuecomment-818786416,2,"['refactor', 'variab']","['refactoring', 'variables']"
Modifiability,"This bug pops up because the periodic mesh reconstruction (in `SU2_MSH`) doesn't always create a valid mesh in 3D. Some points disappear, and some points are duplicated. When `SU2_CFD` (specifically, `CPhysicalGeometry`) tries to get the number of points in the domain, it calculates the wrong number because some of those points are duplicated. That leads to segfaults, because the output routine thinks the extra (missing) points belong to another processor. I've got a little toy problem with a simple periodic cube. It's easy to see on the simple 4x4x4 (+ periodic) problem that 3 nodes disappear, and 3 nodes are duplicated. I've never observed this problem in any of the 2D test cases I ran. As to why `SU2_MSH` is missing some points and duplicating others, I'm not sure. I tried running Valgrind to check for uninitialized variables or illegal memory access, but nothing there. I'll have to look more into the problem. The `su2_periodic.f90` script mentioned in #416 seems to be a workaround. I don't run into any problems when I use that script.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/431#issuecomment-337056131:831,variab,variables,831,https://su2code.github.io,https://github.com/su2code/SU2/issues/431#issuecomment-337056131,1,['variab'],['variables']
Modifiability,"This is obviously very good work and should make it much simpler to add new outputs etc. My main concern when first reviewing was performance (something no one seems to care about) but from the limited testing I did while merging this and CVariable there seems to be no big impact, I did not time anything though, if you have numbers to share please do.; Nevertheless if you can get away with using unordered_map instead of map it would be better. Possibly part of the reason everyone puts of reviewing this is that it is a major refactoring and yet there are no accompanying notes about the architecture the implementation choices etc. I absolutely guarantee you that is not how professional software is developed.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/724#issuecomment-534651933:530,refactor,refactoring,530,https://su2code.github.io,https://github.com/su2code/SU2/pull/724#issuecomment-534651933,1,['refactor'],['refactoring']
Modifiability,"This is simply the way how the cmd.exe shell works on Windows - file and folder names containing spaces or special characters must be quoted into `""` to be handled correctly.; The title says it all - *to make them [executables] run*. The patch prepends one `""` and appends one `""` to the command name. This could be refactored further to reduce repetition much more by putting the different executable file names into a map and have a single place to combine quote + executable + quote.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/332#issuecomment-321264218:316,refactor,refactored,316,https://su2code.github.io,https://github.com/su2code/SU2/pull/332#issuecomment-321264218,1,['refactor'],['refactored']
Modifiability,"This may be relevant, and it may not be. Is there a reason that the molecular and turbulent diffusion of turbulent kinetic energy is not included in the total energy terms? I'm talking about terms like:. ![molecular and turbulent diffusion of tke](https://latex.codecogs.com/gif.latex?\left(&space;\mu&space;&plus;&space;\frac{\mu_t}{\sigma_k}\right)\frac{\partial&space;k}{\partial&space;x_j}). This term is listed both in Wilcox's ""Turbulence Modeling for CFD"" book and the [NASA TMR website](https://turbmodels.larc.nasa.gov/implementrans.html). NASA's page basically just copies what Wilcox states, and then says ""This expression in the energy equation is also sometimes neglected."". Rumsey clarified his position in a [2009 report](https://ntrs.nasa.gov/archive/nasa/casi.ntrs.nasa.gov/20090015399.pdf), saying that ""when considering high Mach number compressible boundary layer flows using k-omega models, the conservation of total energy should be configured to include the contribution of the turbulent kinetic energy k... It is sometimes common practice to ignore these effects, which is certainly justified when k is signficantly smaller than the square of the mean velocity."" . But he also states: ""Note that in CFL3D, the turbulence models are decoupled from the mean flow equations, k is *not* included in the definition of the total energy, and the diffusion of k does not appear in the mean flow energy equation for its models tested here."" He also omitted the 2/3 \rho k term in both the production and the turbulent stress tensor, and found that it made little difference even for M=10 wall-bounded flows. SU2's version of SST is in a weird spot right now, where it's using the turbulent kinetic energy in some places but not others. It's using it here:. + Total energy definition; + Production of turbulent kinetic energy; + RANS evolution equations; + Eddy viscosity definition. But not here:. + Molecular and turbulent diffusion of turbulent kinetic energy in the total energy cons",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/797#issuecomment-548886007:955,config,configured,955,https://su2code.github.io,https://github.com/su2code/SU2/issues/797#issuecomment-548886007,1,['config'],['configured']
Modifiability,"This one is all set after a little more cleanup. I left some low-level changes to the EoS models for later. @CatarinaGarbacz @MarcoFossati : we can use a simple directory name, as you suggest. Let's just go with fluid/ since we also treat liquids with the incompressible solver. Bonus: adds a rotating frame calculation test and some extra error checks on CFL adapt params that should help avoid unreported problems with old configs.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1010#issuecomment-640170715:360,adapt,adapt,360,https://su2code.github.io,https://github.com/su2code/SU2/pull/1010#issuecomment-640170715,2,"['adapt', 'config']","['adapt', 'configs']"
Modifiability,"Those two cases are not part of the regression suite, and so they were probably not updated as some of the options were renamed.; You can have a look at the other turbomachinery examples (at least two of them are part of the regressions) it should be simple to adapt those options.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1086#issuecomment-706417999:261,adapt,adapt,261,https://su2code.github.io,https://github.com/su2code/SU2/issues/1086#issuecomment-706417999,1,['adapt'],['adapt']
Modifiability,"To be clear: I like the solver/, variable/, output/, etc. layout a lot, and I am simply suggesting that we move entirely to that layout (with cpp and hpp merged together in each of those folders) and merging the code in Common, SU2_CFD, and other modules into that structure too (in their own folders still, like geometry/ for example). To keep it organized you can simply make each of those directories a library in meson which all later get linked into the various binaries. The mains could live in the top level src/ directory if we keep it or a separate directory (open for me). Something like. ```; SU2/; src/; solver/; meson.build; solver_\*.cpp; solver_\*.hpp; variable/; meson.build; variable_\*.cpp; variable_\*.hpp; ...; ```. with or without the src/ directory in the root (could go either way). Might want to keep it or even name it cpp/ to differentiate from the python framework(s).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/583#issuecomment-630918578:33,variab,variable,33,https://su2code.github.io,https://github.com/su2code/SU2/issues/583#issuecomment-630918578,2,['variab'],['variable']
Modifiability,"Todo list:; - [x] Make sure the code can handle arbitrary many species equtions. Especially the output has to be adapted. Note the MAXNVAR of the ScalarSolver has to adapted to that need as well. Make a suitable Testcase for that.; - [x] Implement weak inlet and outlet BC. The weak approach is used in the turb and mean flow and is most likely conservative opposed to the strong one. Here a simple switch will be put in place to compare both versions.; - [x] Consolidate nVar, nSpecies, ... variable to only use 1 consistently (The choice was `nSpecies` which was already introduced for NEMO and it just makes sense to use the same container); - [x] Make the numerous reviewers happy; - [x] Check inlet profiles for Species solver (have a testcase for that) See #1427 ; - [x] Create Objective functions of Surface avg quantities (Area and Massflow? prob. And a variance-style output to capture mixing); - [x] Avoid redundant operations (pre/post processings) during solver restarts. 156d0c5. What will be done in follow-up PR's:; - Viscous contributions for BC_inlet and outlet which are currently not used (also then for Turb-solver) https://github.com/su2code/SU2/pull/1388#discussion_r752384956; - Axissymmetric source term addtion and testing; - multi-component mixing from #1332 ; - gradient validation between DA and FD",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1388#issuecomment-935901996:113,adapt,adapted,113,https://su2code.github.io,https://github.com/su2code/SU2/pull/1388#issuecomment-935901996,3,"['adapt', 'variab']","['adapted', 'variable']"
Modifiability,"Tom, I would love to address both of these. Give me some time. I feel even in the current form, it is good. Do you have plans to merge this into master, so that people can use this to setup dev environment quickly. They can also create a basic config file quickly. . I will consider both of your ideas to make user experience better. Thanks for your support. ; Krishna",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/172#issuecomment-126133647:244,config,config,244,https://su2code.github.io,https://github.com/su2code/SU2/pull/172#issuecomment-126133647,1,['config'],['config']
Modifiability,Tools/PointwiseSU2plugin/PluginSDK.suo (0) ; - D MeshTools/PointwiseSU2plugin/depend.sh (28) ; - D MeshTools/PointwiseSU2plugin/mkplugin (10) ; - D MeshTools/PointwiseSU2plugin/mkplugin.bat (82) ; - D MeshTools/PointwiseSU2plugin/mkplugin.tcl (422) ; - D MeshTools/PointwiseSU2plugin/src/Pointwise/Win32Target.props (28) ; - D MeshTools/PointwiseSU2plugin/src/Pointwise/Win32Target.vsprops (24) ; - D MeshTools/PointwiseSU2plugin/src/Pointwise/Win64Target.props (28) ; - D MeshTools/PointwiseSU2plugin/src/Pointwise/Win64Target.vsprops (24) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/CaeStrXML.vcproj (511) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/CaeStrXML.vcproj.PWI.dgarlisch.user (121) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/CaeStrXML.vcxproj (307) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/CaeStrXML.vcxproj.filters (78) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/CaeStrXML.vcxproj.user (3) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/module.mk (239) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/modulelocal-sample.mk (84) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtCaepInitItems.h (98) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtCaepInstanceData.h (135) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtCaepSupportData.h (89) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtPwpInitItems.h (68) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtPwpPluginInfo.h (75) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtPwpVersions.h (62) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/runtimeWrite.c (443) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.sdf (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.sln (26) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.suo (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcproj (511) ; - ,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:14284,plugin,plugins,14284,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['plugin'],['plugins']
Modifiability,Tools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/module.mk (240) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/modulelocal-sample.mk (84) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtCaepInitItems.h (142) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtCaepInstanceData.h (135) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtCaepSupportData.h (83) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtPwpInitItems.h (68) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtPwpPluginInfo.h (75) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtPwpVersions.h (64) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/runtimeWrite.c (439) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/runtimeWrite_orig.txt (60) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcproj (511) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcproj.PWI.dgarlisch.user (121) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcxproj (307) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcxproj.filters (78) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcxproj.user (3) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/module.mk (239) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/modulelocal-sample.mk (84) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtCaepInitItems.h (98) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtCaepInstanceData.h (135) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtCaepSupportData.h (89) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtPwpInitItems.h (68) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtPwpPluginInfo.h (75) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtPwpVersions.h (62) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/runtimeWrite.c (347) ; - D MeshTools/PointwiseSU2plugin/src/plugins/README.txt,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:17036,plugin,plugins,17036,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['plugin'],['plugins']
Modifiability,Tools/PointwiseSU2plugin/src/plugins/CaeUnsXML/module.mk (239) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/modulelocal-sample.mk (84) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtCaepInitItems.h (98) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtCaepInstanceData.h (135) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtCaepSupportData.h (89) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtPwpInitItems.h (68) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtPwpPluginInfo.h (75) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtPwpVersions.h (62) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/runtimeWrite.c (347) ; - D MeshTools/PointwiseSU2plugin/src/plugins/README.txt (272) ; - D MeshTools/PointwiseSU2plugin/src/plugins/module.mk (309) ; - D MeshTools/PointwiseSU2plugin/src/plugins/modulelocal.mk (8) ; - D MeshTools/PointwiseSU2plugin/src/plugins/pluginRegistry.h (29) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEP.c (228) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEP.h (550) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEPUtils.c (290) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEPUtils.h (725) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/runtimeWrite.h (57) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWGM/apiGridModel.c (492) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWGM/apiGridModel.h (1808) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWP.c (132) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWP.h (707) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWPUtils.c (789) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWPUtils.h (1030) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiUtils.h (174) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/pwpPlatform.c (0) ; - D MeshTools/PointwiseS,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:18269,plugin,plugins,18269,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['plugin'],['plugins']
Modifiability,Tools/PointwiseSU2plugin/src/plugins/templates/CAEP/CaeTemplate.suo (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/CaeTemplate.vcproj (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/module.mk (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/modulelocal-sample.mk (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/rtCaepInitItems.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/rtCaepInstanceData.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/rtCaepSupportData.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/runtimeWrite.c (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/PWP/rtPwpInitItems.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/PWP/rtPwpPluginInfo.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/PWP/rtPwpVersions.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/unstructured.props (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/unstructured.vsprops (0) ; - D MeshTools/PointwiseSU2plugin_Instructions.txt (0) ; - I QuickStart/inv_NACA0012.cfg (0) ; - I README (0) ; - I SU2_CFD/include/SU2_CFD.hpp (0) ; - I SU2_CFD/include/definition_structure.hpp (0) ; - I SU2_CFD/include/fluid_model.hpp (0) ; - I SU2_CFD/include/fluid_model.inl (0) ; - I SU2_CFD/include/integration_structure.hpp (0) ; - I SU2_CFD/include/integration_structure.inl (0) ; - I SU2_CFD/include/iteration_structure.hpp (0) ; - I SU2_CFD/include/numerics_machine_learning.hpp (0) ; - I SU2_CFD/include/numerics_machine_learning.inl (0) ; - I SU2_CFD/include/numerics_machine_learning_turbulent.hpp (0) ; - I SU2_CFD/include/numerics_structure.hpp (0) ; - I SU2_CFD/include/numerics_structure.inl (0) ; - I SU2_CFD/include/output_structure.hpp (0) ; - I SU2_CFD/include/solver_structure.hpp (0) ; - I SU2_CFD/include/solver_structure.inl (0) ; - I SU2_CFD/include/transport_model.hpp (0) ; - I SU2_CFD/include/transport_model.inl (0) ; - I ,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:20530,plugin,plugins,20530,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['plugin'],['plugins']
Modifiability,U2plugin/src/plugins/CaeStrXML/CaeStrXML.vcproj (511) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/CaeStrXML.vcproj.PWI.dgarlisch.user (121) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/CaeStrXML.vcxproj (307) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/CaeStrXML.vcxproj.filters (78) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/CaeStrXML.vcxproj.user (3) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/module.mk (239) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/modulelocal-sample.mk (84) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtCaepInitItems.h (98) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtCaepInstanceData.h (135) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtCaepSupportData.h (89) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtPwpInitItems.h (68) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtPwpPluginInfo.h (75) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtPwpVersions.h (62) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/runtimeWrite.c (443) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.sdf (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.sln (26) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.suo (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcproj (511) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcxproj (307) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcxproj.filters (78) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcxproj.user (3) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/UpgradeLog.XML (47) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport.css (207) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport.xslt (232) ; - D MeshTools/PointwiseSU2plugin/,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:14846,plugin,plugins,14846,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['plugin'],['plugins']
Modifiability,U2plugin/src/plugins/CaeUnsSU2/rtPwpVersions.h (64) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/runtimeWrite.c (439) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/runtimeWrite_orig.txt (60) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcproj (511) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcproj.PWI.dgarlisch.user (121) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcxproj (307) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcxproj.filters (78) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcxproj.user (3) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/module.mk (239) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/modulelocal-sample.mk (84) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtCaepInitItems.h (98) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtCaepInstanceData.h (135) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtCaepSupportData.h (89) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtPwpInitItems.h (68) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtPwpPluginInfo.h (75) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtPwpVersions.h (62) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/runtimeWrite.c (347) ; - D MeshTools/PointwiseSU2plugin/src/plugins/README.txt (272) ; - D MeshTools/PointwiseSU2plugin/src/plugins/module.mk (309) ; - D MeshTools/PointwiseSU2plugin/src/plugins/modulelocal.mk (8) ; - D MeshTools/PointwiseSU2plugin/src/plugins/pluginRegistry.h (29) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEP.c (228) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEP.h (550) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEPUtils.c (290) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEPUtils.h (725) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/runtim,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:17610,plugin,plugins,17610,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['plugin'],['plugins']
Modifiability,U2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcproj (511) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcproj.PWI.dgarlisch.user (121) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcxproj (307) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcxproj.filters (78) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcxproj.user (3) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/module.mk (239) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/modulelocal-sample.mk (84) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtCaepInitItems.h (98) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtCaepInstanceData.h (135) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtCaepSupportData.h (89) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtPwpInitItems.h (68) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtPwpPluginInfo.h (75) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtPwpVersions.h (62) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/runtimeWrite.c (347) ; - D MeshTools/PointwiseSU2plugin/src/plugins/README.txt (272) ; - D MeshTools/PointwiseSU2plugin/src/plugins/module.mk (309) ; - D MeshTools/PointwiseSU2plugin/src/plugins/modulelocal.mk (8) ; - D MeshTools/PointwiseSU2plugin/src/plugins/pluginRegistry.h (29) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEP.c (228) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEP.h (550) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEPUtils.c (290) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEPUtils.h (725) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/runtimeWrite.h (57) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWGM/apiGridModel.c (492) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWGM/apiGridModel.h (1808) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWP,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:17851,plugin,plugins,17851,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['plugin'],['plugins']
Modifiability,"Vec(data_,offsets_); }. STRONGINLINE FltVec operator++(int) {; auto ret = (*this)(); offsets_ += Incr; return ret;; }; };; ```; so silly in fact, it only moves forward, we use it in our loop like so; ```c++; ...; auto gradI = grad.getColIterator(iPoint);; auto gradJ = grad.getColIterator(jPoint);. for(size_t iVar=0; iVar<nVar; ++iVar); {; FltVec phiL = 0.0;; FltVec phiR = 0.0;. for(size_t iDim=0; iDim<nDim; ++iDim); {; phiL += (gradI++)*d_ij[iDim];; phiR -= (gradJ++)*d_ij[iDim];; }; ...; ```; to get better assembly; ```asm; .L7:; vmovapd ymm3, ymm13; vmovapd ymm2, YMMWORD PTR [rbp-400]; add rax, 32; vgatherqpd ymm0, QWORD PTR [rcx+ymm1*8], ymm3; vpaddq ymm1, ymm1, ymm11; vmovapd YMMWORD PTR [rbp-272], ymm0; vmovapd YMMWORD PTR [rbp-240], ymm0; vfmadd132pd ymm0, ymm2, YMMWORD PTR [rax-32]; vmovdqa YMMWORD PTR [rbp-208], ymm1; vmovapd YMMWORD PTR [rbp-400], ymm0; cmp rax, rbx; jne .L7; ```; which makes the vectorized code perform just as well as the scalar code, iterators could also be used for the other variables but that would start to hurt readability without improving the performance much. _Note: There is also a chance the compiler (gcc) is not doing this kind of optimization because of the way I wrote the code..._. **So we need AoS to avoid losing performance in lightweight numerics classes.**. Before we look into the impact of not using SoA in the gradient and limiters routines let me tell you there is a way to have the best of both worlds, enter the *_array of structures of arrays_* or as I like to call it zig zag storage, aka a right mess.; Imagine an AoS of short arrays of SIMD length, e.g. `{ {u0 u1 u2 u3} {v0 ... v3} {w0 ... w3} {u4 u5 u6 u7} ... }` with that it is possible to fully vectorize point loops as the first index (iPoint) is contiguous in groups of SIMD length and when looping along variables and dimensions in edge loops the stride is small enough (equal to SIMD length) to trigger hardware prefetching.; The catch is that we need even more integer a",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-535977206:12416,variab,variables,12416,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206,1,['variab'],['variables']
Modifiability,"Was playing around with the turbomachinery cases with the new multi-zone config. I like the new changes, makes it much clearer!. Just a remark, don't know if this is on purpose, but for the configuration parameter TURBOMACHINERY_KIND, you still need to supply them in the general configuration file for both zones (so in case of a two zone problem: TURBOMACHINERY_KIND = CENTRIFUGAL CENTRIFUGAL). Wouldnt it make more sense to have this per zone specified in the respective configuration file?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/715#issuecomment-514208185:73,config,config,73,https://su2code.github.io,https://github.com/su2code/SU2/pull/715#issuecomment-514208185,4,['config'],"['config', 'configuration']"
Modifiability,"We will merge this PR next in order to have enough time for testing and for you to solve conflicts (if you need any help to solve those, please contact me). Even if this PR is merged, please continue to give feedback on the usability. We will still continue to work on that. Refer to the user documentation in order to learn how to adapt your config files. Let me know if you have any questions.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/724#issuecomment-534522241:332,adapt,adapt,332,https://su2code.github.io,https://github.com/su2code/SU2/pull/724#issuecomment-534522241,2,"['adapt', 'config']","['adapt', 'config']"
Modifiability,"What advantages does meson provide over Cmake? I have experience with CMake, but not with meson. @talbring I'm not sure what you mean by ""the syntax is also not very comfortable and it has too many features which we actually don't need."". I recently did a survey of the some of the most popular open-source C++ libraries, both inside and outside and outside of scientific computing. The most popular build system was CMake (60% of the 15 open source libraries). If ""everyone else"" is using CMake, then why should we use meson? I'm not trying to be adversarial. I'm curious about why meson is better. Is the syntax simpler? Is meson more flexible? Is it more robust during changes? Is it faster?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/685#issuecomment-498827230:637,flexible,flexible,637,https://su2code.github.io,https://github.com/su2code/SU2/issues/685#issuecomment-498827230,1,['flexible'],['flexible']
Modifiability,"When I enter the ""shape_optimization.py -f unsteady_naca0012_opt.cfg"" in the commend the error is:; ```; Traceback (most recent call last):; File ""C:\Users\74351\Desktop\SU2\SU2\bin\test2\shape_optimization.py"", line 116, in <module>; main(); File ""C:\Users\74351\Desktop\SU2\SU2\bin\test2\shape_optimization.py"", line 34, in main; shape_optimization( options.filename ,; File ""C:\Users\74351\Desktop\SU2\SU2\bin\test2\shape_optimization.py"", line 51, in shape_optimization; config = SU2.io.Config(filename); File ""C:\Users\74351\Desktop\SU2\SU2\bin\SU2\io\config.py"", line 88, in __init__; super(Config,self).__init__(*args,**kwarg); File ""C:\Users\74351\Desktop\SU2\SU2\bin\SU2\util\ordered_bunch.py"", line 83, in __init__; super(OrderedBunch,self).__init__(*args,**kwarg); File ""C:\Users\74351\Desktop\SU2\SU2\bin\SU2\util\ordered_dict.py"", line 48, in __init__; self.__update(*args, **kwds); File ""C:\Users\74351\Desktop\SU2\SU2\bin\SU2\util\ordered_dict.py"", line 174, in update; for key, value in other:; TypeError: 'NoneType' object is not iterable; ```; When I enter the ""parallel_computation.py -f turb_naca0012.cfg -n NP in the commend the error is:; ```; Traceback (most recent call last):; File ""C:\Users\74351\Desktop\SU2\SU2\bin\parallel_computation.py"", line 110, in <module>; main(); File ""C:\Users\74351\Desktop\SU2\SU2\bin\parallel_computation.py"", line 53, in main; raise Exception(""No config file provided. Use -f flag""); Exception: No config file provided. Use -f flag; ```; Any solvers related to "".py"" cannot be executed, but I can run any cases with SU2_CFD. So I wonder if this situation is a problem with the Python Wrapper? . I will be very appreciated if I could get some feedback on this issue.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1567#issuecomment-1074910200:475,config,config,475,https://su2code.github.io,https://github.com/su2code/SU2/issues/1567#issuecomment-1074910200,4,['config'],['config']
Modifiability,"Wonderful contribution. Thanks for doing all that. Streamlining the dev process is very helpful and cmake is definitely becoming a standard. Best,. Juan. On Nov 10, 2019, at 11:24 AM, Daumantas Kavolis <notifications@github.com> wrote:. ﻿; Proposed Changes. Added CMake build support for SU2. With this, many popular IDEs will be able to use SU2 as a project with minimal setup. CMake also enables to add dependencies more easily since most libraries have CMake support. vcpkg is great for the libraries available there. SU2 CMake has the same build options as autotools but uses CMake to find system libraries and compilers (MKL, Mutationpp, MPI and Python currently). No longer need to specify paths to compilers/libraries if they are in standard locations. In addition, compile flags can be modified from CMake. There is no need to use preconfigure.py anymore since downloading/unpacking is handled by CMake and is system-agnostic. At the moment, all library targets are static but that could be easily changed to be configurable from CMake. The installation directory is ${CMAKE_PREFIX_PATH}/bin. Similarly to autotools, some build options are disabled if built with Codi forward/reverse datatypes or without MPI. Note that SWIG fails to compile pySU2ad with Nothing known about namespace 'medi' in Common/include/mpi_structure.hpp:57 without -includeall SWIG option but then it takes forever to generate the wrapper (more than 15 minutes on my machine, stopped early). I suggest removing using namespace declarations and either importing used symbols explicitly with using or prepending namespace name, clang-tidy warns against them by default and it makes the code clearer. SU2 CMake options are:. * Build modules:; * SU2_BUILD_CFD: ON|OFF; * SU2_BUILD_DEF: ON|OFF, disabled when building with Codi; * SU2_BUILD_DOT: ON|OFF, disabled when building with Codi forward; * SU2_BUILD_GEO: ON|OFF, disabled when building with Codi; * SU2_BUILD_MSH: ON|OFF, disabled when building with Codi; * SU2_BUIL",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/814#issuecomment-552242380:1020,config,configurable,1020,https://su2code.github.io,https://github.com/su2code/SU2/pull/814#issuecomment-552242380,1,['config'],['configurable']
Modifiability,"YES! I am excited to try this out. I can probably test it on some of the other TMR cases (airfoils, flatplates). Will post the results when I get those done. . Side note, there was one issue that @bmunguia and I encountered when performing optimizations with adaptive CFL. Say the DIRECT simulation is run with adaptive CFL and is well converged (6 to 8 orders of residual reduction). When the discrete adjoint performs the one direct iteration to store the computational graph, it uses the initial CFL value, not the CFL that the adaptive CFL routine ended at. This results in the residuals being very high for that one iteration, which then affects the convergence of the discrete adjoint. . I will try to run an adjoint on one of these cases as well to see if the problem persists. Perhaps could be overcome with a simple additional field for CFL in the restart meta-data",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/790#issuecomment-531520526:259,adapt,adaptive,259,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-531520526,3,['adapt'],['adaptive']
Modifiability,"Yep, things seem to be passing just fine now, and it looks like things are coming along nicely for the turbomachinery features. Before we merge this in... I am a little concerned with the number of additions to solver_direct_mean.cpp related to the different switch statements and subroutines needed for the Riemann and non-reflecting BCs. Is there anything we can do to simplify things?. In addition, could you please clean up the spacing/style in those methods to match up with the other BCs (more comments are needed, indentation, variable declarations, etc.)? It would also be great to have a little more detail on how to use the new BCs in the descriptions in config_template.cfg. Thanks!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/207#issuecomment-152406337:534,variab,variable,534,https://su2code.github.io,https://github.com/su2code/SU2/pull/207#issuecomment-152406337,1,['variab'],['variable']
Modifiability,"Yes for MARKER_ROUGH, or MARKER_ROUGH_WALL to be clearer.; Or just WALL_ROUGHNESS as you have right now, since it would not really a marker, just the properties of markers (and I've seen some people on CFD online confused with similar naming e.g. MARKER_SHROUD). Regarding the MPI stuff, I had the following idea over lunch:; In CPhysicalGeometry::SetWallDistance we compute the closest distance, and in so doing we also get the mpi rank and markerID associated with the closest vertex.; So, before computing the wall distances you communicate the local marker ids and wall roughness's (via Allgather as you are doing now), with this info you can build a `unordered_map<pair<int,int>, su2double>` to map pairs of <rank,markerID> to the values of roughness.; Now when you loop over the points to compute the distances you can retrieve the roughness from this map instead of from config.; It's almost exactly the same as you have, but avoids using the config as a messenger between routines, and using a stl map should also make the code simpler. In the boundary conditions you can still get the marker roughness via the marker tag as you are doing now, and I guess the wall type (smooth / rough) can be inferred from having 0 (default) roughness (?); With the string+double list specification you also avoid having to specify 0 roughness and SMOOTH wall type for markers where you don't want to use this feature.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/877#issuecomment-630861158:878,config,config,878,https://su2code.github.io,https://github.com/su2code/SU2/pull/877#issuecomment-630861158,2,['config'],['config']
Modifiability,"You're right about that bug with vel_i_corr. Thanks for finding it, I'll submit a correction. Yes, it's possible to modify the config file so that your implementation works. But is this simply masking the problem of reduced stability? Do you expect the direct formulation to be less stable? And do the benefits of the direct formulation make the loss of stability worthwhile? If so, then I think you should change the config file. I hope this answers your question, I'm not sure if I understood it correctly. Regards,; Daniel",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/232#issuecomment-182655391:127,config,config,127,https://su2code.github.io,https://github.com/su2code/SU2/pull/232#issuecomment-182655391,2,['config'],['config']
Modifiability,"ZEOF_DOUBLE 8; | #define SIZEOF_VOID_P 8; | /* end confdefs.h. */; | #include <X11/Intrinsic.h>; configure:5409: result: no; configure:5409: checking for X11/Intrinsic.h; configure:5409: result: no; configure:5721: checking for /gshare/soft/code_saturne/4.0.0/prod/cgnslib_3.2.1/lib/libcgns.a; configure:5735: result: yes; configure:5755: checking for /gshare/soft/code_saturne/4.0.0/prod/cgnslib_3.2.1/include/cgnslib.h; configure:5769: result: yes; configure:6815: checking that generated files are newer than configure; configure:6821: result: done; configure:6952: creating ./config.status. ## ---------------------- ##; ## Running config.status. ##; ## ---------------------- ##. This file was extended by SU2 config.status 4.1.0, which was; generated by GNU Autoconf 2.69. Invocation command line was. CONFIG_FILES = ; CONFIG_HEADERS = ; CONFIG_LINKS = ; CONFIG_COMMANDS = ; $ ./config.status . on master. config.status:875: creating externals/tecio/Makefile; config.status:875: creating externals/metis/Makefile; config.status:875: creating externals/parmetis/Makefile; config.status:875: creating Makefile; config.status:875: creating externals/Makefile; config.status:875: creating Common/lib/Makefile; config.status:875: creating SU2_CFD/obj/Makefile; config.status:875: creating SU2_DOT/obj/Makefile; config.status:875: creating SU2_MSH/obj/Makefile; config.status:875: creating SU2_DEF/obj/Makefile; config.status:875: creating SU2_SOL/obj/Makefile; config.status:875: creating SU2_GEO/obj/Makefile; config.status:875: creating SU2_PY/Makefile; config.status:1047: executing depfiles commands; configure:8181: result:. -------------------------------------------------------------------------; | ___ _ _ ___ |; | / __| | | |_ ) Release 4.1.0 'Cardinal' |; | \__ \ |_| |/ / |; | |___/\___//___| Suite |; | |; -------------------------------------------------------------------------; | SU2 Lead Dev.: Dr. Francisco Palacios, Francisco.D.Palacios@boeing.com|; | Dr. Thomas D. Economon, econ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:16090,config,config,16090,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,1,['config'],['config']
Modifiability,"ZEOF_INT 4; | #define SIZEOF_UNSIGNED_INT 4; | #define SIZEOF_LONG_INT 8; | #define SIZEOF_FLOAT 4; | #define SIZEOF_DOUBLE 8; | #define SIZEOF_VOID_P 8; | /* end confdefs.h. */; | #include <X11/Intrinsic.h>; configure:5409: result: no; configure:5409: checking for X11/Intrinsic.h; configure:5409: result: no; configure:5721: checking for /gshare/soft/code_saturne/4.0.0/prod/cgnslib_3.2.1/lib/libcgns.a; configure:5735: result: yes; configure:5755: checking for /gshare/soft/code_saturne/4.0.0/prod/cgnslib_3.2.1/include/cgnslib.h; configure:5769: result: yes; configure:6815: checking that generated files are newer than configure; configure:6821: result: done; configure:6952: creating ./config.status. ## ---------------------- ##; ## Running config.status. ##; ## ---------------------- ##. This file was extended by SU2 config.status 4.1.0, which was; generated by GNU Autoconf 2.69. Invocation command line was. CONFIG_FILES = ; CONFIG_HEADERS = ; CONFIG_LINKS = ; CONFIG_COMMANDS = ; $ ./config.status . on master. config.status:875: creating externals/tecio/Makefile; config.status:875: creating externals/metis/Makefile; config.status:875: creating externals/parmetis/Makefile; config.status:875: creating Makefile; config.status:875: creating externals/Makefile; config.status:875: creating Common/lib/Makefile; config.status:875: creating SU2_CFD/obj/Makefile; config.status:875: creating SU2_DOT/obj/Makefile; config.status:875: creating SU2_MSH/obj/Makefile; config.status:875: creating SU2_DEF/obj/Makefile; config.status:875: creating SU2_SOL/obj/Makefile; config.status:875: creating SU2_GEO/obj/Makefile; config.status:875: creating SU2_PY/Makefile; config.status:1047: executing depfiles commands; configure:8181: result:. -------------------------------------------------------------------------; | ___ _ _ ___ |; | / __| | | |_ ) Release 4.1.0 'Cardinal' |; | \__ \ |_| |/ / |; | |___/\___//___| Suite |; | |; --------------------------------------------------------------------",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:15955,config,config,15955,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,1,['config'],['config']
Modifiability,"[iVar] = vmax(phiMax[iVar], phi.getVec(jPoint,iVar));; phiMin[iVar] = vmin(phiMin[iVar], phi.getVec(jPoint,iVar));; }; }. for(size_t iVar=0; iVar<nVar; ++iVar); {; FltVec lim = vmin(FltVec(2.0), vmin(; (phiMax[iVar]-phi.getVec(iPoint,iVar))/prjMax[iVar],; (phiMin[iVar]-phi.getVec(iPoint,iVar))/prjMin[iVar]));. limiter.setVec(iPoint,iVar, lim*(lim+2.0)/(lim*lim+lim+2.0));; }; }; }; ```; In terms of algorithm, for each point we find the min and max neighbor values and the min (negative) and max (positive) projections, those are then combined in a final `min(2, max/max, min/min)` to which the limiter function is applied (this would also be applicable to Venkatakrishnan-[Wang] limiters).; This is equivalent to the edge-loop, if statements are not required as due to cells being closed, if the positive projection is not zero, the negative one will also not be zero, therefore it is correct to always evaluate both ratios.; This algorithm only needs min and max neighbors as small local variables instead of large global ones due to the way those values are determined. This is where the memory from the extra adjacency information is recovered. Like @economon said, fusing the gradient kernel with the limiter kernel is trivial with these point loops, and I do not think it affects readability much since one can clearly tell ""what is what"" (I will not put it here but it really is a matter of copy paste), including the boundaries could be a bit more challenging, but I will give performance number nevertheless. **Performance summary**. | Code | Edge | Edge, SIMD on vars | Point | Point, SIMD on points |; | ---- | ---- | ---- | ---- | ---- |; | **Speed 1 core** | 1.0 | 1.75 | 1.25 | 2.0 |; | **Speed 4 cores** | 2.45 | 2.7 | 4.5 | 7.0 |. The basic point version does not lose to edge based because, contrary to gradients, it does not require duplication of computations while benefiting from sequential access to gradients.; Again the point-based implementation does really well in parallel",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-530593912:9687,variab,variables,9687,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530593912,1,['variab'],['variables']
Modifiability,"_HEADERS 1; | #define HAVE_SYS_TYPES_H 1; | #define HAVE_SYS_STAT_H 1; | #define HAVE_STDLIB_H 1; | #define HAVE_STRING_H 1; | #define HAVE_MEMORY_H 1; | #define HAVE_STRINGS_H 1; | #define HAVE_INTTYPES_H 1; | #define HAVE_STDINT_H 1; | #define HAVE_UNISTD_H 1; | #define SIZEOF_SHORT_INT 2; | #define SIZEOF_INT 4; | #define SIZEOF_UNSIGNED_INT 4; | #define SIZEOF_LONG_INT 8; | #define SIZEOF_FLOAT 4; | #define SIZEOF_DOUBLE 8; | #define SIZEOF_VOID_P 8; | /* end confdefs.h. */; | #include <X11/Intrinsic.h>; configure:5409: result: no; configure:5409: checking for X11/Intrinsic.h; configure:5409: result: no; configure:5721: checking for /gshare/soft/code_saturne/4.0.0/prod/cgnslib_3.2.1/lib/libcgns.a; configure:5735: result: yes; configure:5755: checking for /gshare/soft/code_saturne/4.0.0/prod/cgnslib_3.2.1/include/cgnslib.h; configure:5769: result: yes; configure:6815: checking that generated files are newer than configure; configure:6821: result: done; configure:6952: creating ./config.status. ## ---------------------- ##; ## Running config.status. ##; ## ---------------------- ##. This file was extended by SU2 config.status 4.1.0, which was; generated by GNU Autoconf 2.69. Invocation command line was. CONFIG_FILES = ; CONFIG_HEADERS = ; CONFIG_LINKS = ; CONFIG_COMMANDS = ; $ ./config.status . on master. config.status:875: creating externals/tecio/Makefile; config.status:875: creating externals/metis/Makefile; config.status:875: creating externals/parmetis/Makefile; config.status:875: creating Makefile; config.status:875: creating externals/Makefile; config.status:875: creating Common/lib/Makefile; config.status:875: creating SU2_CFD/obj/Makefile; config.status:875: creating SU2_DOT/obj/Makefile; config.status:875: creating SU2_MSH/obj/Makefile; config.status:875: creating SU2_DEF/obj/Makefile; config.status:875: creating SU2_SOL/obj/Makefile; config.status:875: creating SU2_GEO/obj/Makefile; config.status:875: creating SU2_PY/Makefile; config.status:1047: execut",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:15650,config,config,15650,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,1,['config'],['config']
Modifiability,"```diff; $ git --no-pager diff --cached ; diff --git a/meson.build b/meson.build; index ca86992ea..b68a03c52 100644; --- a/meson.build; +++ b/meson.build; @@ -1,15 +1,12 @@; project('SU2', 'c', 'cpp',; version: '7.5.1 ""Blackbird""',; + meson_version: '0.61.1',; license: 'LGPL2',; default_options: ['buildtype=release',; 'warning_level=0',; 'c_std=c99',; 'cpp_std=c++11']); ; -if meson.version() != '0.61.1'; - error('SU2 must be configured with the extended Meson script (./meson.py) in the SU2 root directory.'); -endif; -; pymod = import('python'); python = pymod.find_installation(); ; ```. I used this patch, and then ran the following:. ```; $ meson setup builddir --wipe; The Meson build system; Version: 1.0.1; Source dir: /tmp/SU2; Build dir: /tmp/SU2/builddir; Build type: native build. meson.build:1:0: ERROR: Meson version is 1.0.1 but project requires 0.61.1; ```. Using the >= comparison, it configures fine, and downloads a git submodule for mutationpp/coolprop on demand. From a hasty look around, it seems like the other git submodules are used as externals/ directories, not meson subprojects. Another project I know uses e.g. ```; if not fs.exists('submoduledir/README.md'); error('Missing the `submoduledir` submodule! Run `git submodule update --init` to fix this.'); endif; ```. for each submodule before it gets processed by meson. This is less automatic than wrapping it in meson.py, but does provide pretty clear directions... the sticking point is if people download tarballs. You currently point people to github's autogenerated archives, which is NOT sufficient as it doesn't have submodules included. I would actually suggest using `meson dist --include-subprojects --no-tests` to produce your own tarballs and attach them as additional releases artifacts. Meson *does* include submodules (whether or not they are subprojects) automatically to the tarball it creates.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1945#issuecomment-1451057434:429,config,configured,429,https://su2code.github.io,https://github.com/su2code/SU2/issues/1945#issuecomment-1451057434,3,"['config', 'extend']","['configured', 'configures', 'extended']"
Modifiability,"ails. |; | |; | You should have received a copy of the GNU Lesser General Public |; | License along with SU2. If not, see <http://www.gnu.org/licenses/>. |; -------------------------------------------------------------------------. Build Configuration Summary:. Source code location: /home/antodech/SU2-4.1.0; Install location: /gshare/work/hpascalj/CodeSU2-master; Version: 4.1.0; C++ Compiler: g++; C Compiler: gcc; Preprocessor flags: ; Compiler flags: -g -O2; Linker flags: ; MPI support: no; Metis support: no; Parmetis support: no; TecIO support: no; CGNS support: yes; HDF5 support: no; SZIP support: no; ZLIB support: no; Mutation++ support: no; Jsoncpp support: no; LAPACK support: no; Datatype support:; double yes; complex no; codi_reverse no; codi_forward no. External includes: ; External libs: . Build SU2_CFD: yes; Build SU2_DOT: yes; Build SU2_MSH: yes; Build SU2_DEF: yes; Build SU2_SOL: yes; Build SU2_GEO: yes. Please be sure to add the $SU2_HOME and $SU2_RUN environment variables,; and update your $PATH (and $PYTHONPATH if applicable) with $SU2_RUN. Based on the input to this configuration, add these lines to your .bashrc file:. export SU2_RUN=""/gshare/work/hpascalj/CodeSU2-master/bin""; export SU2_HOME=""/home/antodech/SU2-4.1.0""; export PATH=$PATH:$SU2_RUN; export PYTHONPATH=$PYTHONPATH:$SU2_RUN. ## ---------------- ##; ## Cache variables. ##; ## ---------------- ##. ac_cv_build=x86_64-unknown-linux-gnu; ac_cv_c_compiler_gnu=yes; ac_cv_cxx_compiler_gnu=yes; ac_cv_env_CCC_set=; ac_cv_env_CCC_value=; ac_cv_env_CC_set=; ac_cv_env_CC_value=; ac_cv_env_CFLAGS_set=; ac_cv_env_CFLAGS_value=; ac_cv_env_CPPFLAGS_set=; ac_cv_env_CPPFLAGS_value=; ac_cv_env_CPP_set=; ac_cv_env_CPP_value=; ac_cv_env_CXXFLAGS_set=; ac_cv_env_CXXFLAGS_value=; ac_cv_env_CXX_set=; ac_cv_env_CXX_value=; ac_cv_env_LDFLAGS_set=; ac_cv_env_LDFLAGS_value=; ac_cv_env_LIBS_set=; ac_cv_env_LIBS_value=; ac_cv_env_build_alias_set=; ac_cv_env_build_alias_value=; ac_cv_env_host_alias_set=; ac_cv_env_host_",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:19168,variab,variables,19168,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,1,['variab'],['variables']
Modifiability,"ance.; The git add, git commit and git push commands worked as expected.; The only problem I had was when I tried to upload the mesh file to https://github.com/su2code/TestCases/tree/develop/disc_adj_euler: <https://github.com/su2code/TestCases/tree/develop/disc_adj_euler:> I wanted to upload a folder “arina2k”, whose contents is the mesh file (.su2). I could not just upload the folder name: the system appears to be waiting for an actual file name. When I choose the file name inside that folder , it appears that the system would upload the file within the repository, but 'discarding’ its folder name, so I would have an ‘orphaned’ file there. I tried also to create a file (which would be my folder name), but again, I am prompted with an editor in order to write an actual file, using directly the browser. I believe that there is a simple way to upload a sub-directory/filename, but i could not realize it. With kind regards,. Jairo. > On Dec 14, 2018, at 01:26, Thomas D. Economon <notifications@github.com> wrote:; > ; > @jaspe55 <https://github.com/jaspe55> : I see that you have added the residual check for the python regression script, but I do not see the config file, target file, or mesh. The config file and target file should be placed in SU2/TestCases/disc_adj_euler/arina2k/ (according to your path in the regression script), and the mesh placed in the TestCases/disc_adj_euler/arina2k/ directory in the TestCases repository here (develop): https://github.com/su2code/TestCases/tree/develop <https://github.com/su2code/TestCases/tree/develop>. Don't forget to 'git add' the files to make sure they are included on push. We can help diagnose any segfaults with the files.; > ; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/pull/600#issuecomment-447209397>, or mute the thread <https://github.com/notifications/unsubscribe-auth/Ac180hTDpbM_TXuwfdIJnHpDEpp295gqks5u4yh5gaJpZM4X34F2>.; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/600#issuecomment-447475363:1221,config,config,1221,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-447475363,2,['config'],['config']
Modifiability,"are mentioning is the same. I simply united the TIP, LOWER_SIDE and UPPER_SIDE under the marker tag WING. > The initial transient through the domain based on the initial values is unphysical to some extend and if e.g. 'steady state' results are the same for both code versions .... the problem is not that big. Although it differs quite a bit in the temporal evolution tbh; In the results (also in the mail) it looks a bit like it approaches a steady state for Cl and CD. So maybe 1000 timesteps will tell us a bit more 🤔. I guess they converge eventually to the same values. I tried to compare the same case but steady (I attach the summary). Results in this case are fairly similar and (in my opinion) raise no warnings.; [Summary_steady_6_0_1.txt](https://github.com/su2code/SU2/files/3906039/Summary_steady_6_0_1.txt); [Summary_steady_6_2_0.txt](https://github.com/su2code/SU2/files/3906010/Summary_steady_6_2_0.txt). Regarding the unsteady case, I'm aware that this test may have little physics behind (especially if comparing the first timesteps) but I wanted to investigate the reason :). Results are too different and I think these might be one of the reasons behind some discrepancies I'm encountering in my FSI framework. ; My framework for FSI features a restart from a steady solution at t=0 and an unsteady simulation with imposed boundary of the wing marker. The discrepancies in that case are huge and are clearly wrong. I went back to the root and found this weird behaviour comparing the two versions so I thought this might be one cause. > Another thing: There is no tag 6.0.2 😕 ... 6.0.1 and then 6.1.0.. Yep you are right, the version is definitely 6.0.1 as it can be seen from the Summaries: **I'm updating the issue.**. > And both versions are/were on the develop branches -> what exactly do you refer to here: config-files, code, mesh. Didn't quite understand you here. Let me know if you need any other info regarding the topic. Looking forward to hear from you!. Best,; Rocco",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/828#issuecomment-559850074:2163,config,config-files,2163,https://su2code.github.io,https://github.com/su2code/SU2/issues/828#issuecomment-559850074,1,['config'],['config-files']
Modifiability,"ared --enable-threads=posix --enable-checking=release --with-system-zlib --enable-__cxa_atexit --disable-libunwind-exceptions --enable-gnu-unique-object --enable-languages=c,c++,objc,obj-c++,java,fortran,ada --enable-java-awt=gtk --disable-dssi --with-java-home=/usr/lib/jvm/java-1.5.0-gcj-1.5.0.0/jre --enable-libgcj-multifile --enable-java-maintainer-mode --with-ecj-jar=/usr/share/java/eclipse-ecj.jar --disable-libjava-multilib --with-ppl --with-cloog --with-tune=generic --with-arch_32=i686 --build=x86_64-redhat-linux; Thread model: posix; gcc version 4.4.6 20120305 (Red Hat 4.4.6-4) (GCC) ; configure:3999: $? = 0; configure:3988: gcc -V >&5; gcc: '-V' option must have argument; configure:3999: $? = 1; configure:3988: gcc -qversion >&5; gcc: unrecognized option '-qversion'; gcc: no input files; configure:3999: $? = 1; configure:4003: checking whether we are using the GNU C compiler; configure:4022: gcc -c conftest.c >&5; configure:4022: $? = 0; configure:4031: result: yes; configure:4040: checking whether gcc accepts -g; configure:4060: gcc -c -g conftest.c >&5; configure:4060: $? = 0; configure:4101: result: yes; configure:4118: checking for gcc option to accept ISO C89; configure:4181: gcc -c -g -O2 conftest.c >&5; configure:4181: $? = 0; configure:4194: result: none needed; configure:4216: checking dependency style of gcc; configure:4327: result: gcc3; configure:4345: checking whether gcc and cc understand -c and -o together; configure:4376: gcc -c conftest.c -o conftest2.o >&5; configure:4380: $? = 0; configure:4386: gcc -c conftest.c -o conftest2.o >&5; configure:4390: $? = 0; configure:4401: cc -c conftest.c >&5; configure:4405: $? = 0; configure:4413: cc -c conftest.c -o conftest2.o >&5; configure:4417: $? = 0; configure:4423: cc -c conftest.c -o conftest2.o >&5; configure:4427: $? = 0; configure:4445: result: yes; configure:4513: checking for ranlib; configure:4529: found /usr/bin/ranlib; configure:4540: result: ranlib; configure:4574: checking how to run th",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:6905,config,configure,6905,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,4,['config'],['configure']
Modifiability,"ble-shared --enable-threads=posix --enable-checking=release --with-system-zlib --enable-__cxa_atexit --disable-libunwind-exceptions --enable-gnu-unique-object --enable-languages=c,c++,objc,obj-c++,java,fortran,ada --enable-java-awt=gtk --disable-dssi --with-java-home=/usr/lib/jvm/java-1.5.0-gcj-1.5.0.0/jre --enable-libgcj-multifile --enable-java-maintainer-mode --with-ecj-jar=/usr/share/java/eclipse-ecj.jar --disable-libjava-multilib --with-ppl --with-cloog --with-tune=generic --with-arch_32=i686 --build=x86_64-redhat-linux; Thread model: posix; gcc version 4.4.6 20120305 (Red Hat 4.4.6-4) (GCC) ; configure:3343: $? = 0; configure:3332: g++ -V >&5; g++: '-V' option must have argument; configure:3343: $? = 1; configure:3332: g++ -qversion >&5; g++: unrecognized option '-qversion'; g++: no input files; configure:3343: $? = 1; configure:3363: checking whether the C++ compiler works; configure:3385: g++ conftest.cpp >&5; configure:3389: $? = 0; configure:3437: result: yes; configure:3440: checking for C++ compiler default output file name; configure:3442: result: a.out; configure:3448: checking for suffix of executables; configure:3455: g++ -o conftest conftest.cpp >&5; configure:3459: $? = 0; configure:3481: result: ; configure:3503: checking whether we are cross compiling; configure:3511: g++ -o conftest conftest.cpp >&5; configure:3515: $? = 0; configure:3522: ./conftest; configure:3526: $? = 0; configure:3541: result: no; configure:3546: checking for suffix of object files; configure:3568: g++ -c conftest.cpp >&5; configure:3572: $? = 0; configure:3593: result: o; configure:3597: checking whether we are using the GNU C++ compiler; configure:3616: g++ -c conftest.cpp >&5; configure:3616: $? = 0; configure:3625: result: yes; configure:3634: checking whether g++ accepts -g; configure:3654: g++ -c -g conftest.cpp >&5; configure:3654: $? = 0; configure:3695: result: yes; configure:3720: checking dependency style of g++; configure:3831: result: gcc3; configure:3921: check",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:4215,config,configure,4215,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,4,['config'],['configure']
Modifiability,"bsonic engine intake option; - Small output change; - Added output_su2.cpp; - Updated Engine BC; - Working on Engine BCs; - Added Supersonic Outlet BC; - Minor change; - Merge remote-tracking branch 'upstream/develop' into develop; - adjoints, solid boundary, doxygen in config; - continued fixing; - re-added adjoint bc mods; - re-adding avg outlet pressure (static pressure adjoint); - re-adding avg outlet pressure (static pressure adjoint); - Merge branch 'temp' of https://github.com/hlkline/SU2 into temp; - continued fixing; - average total pressure and fixes to avg outlet pressure; - adding stagnation pressure output to SU2_DOT; - Merge pull request #146 from hlkline/temp; - Updated Entropy fix (now it is active).; - Another change in BC_Engine_Exhaust; - Updated CGNS in parallel; - Added runtime file; - Small typo; - Adjustment of the Entropy fix coefficient; - Bug in SU2_GEO; - Debug version with print statements.; - Updated release 3.2.7.1; - Small change; - Updated config file; - Code update; - MPI Status and Request fix.; - Another MPI Status/Request fix.; - Actuator disk update.; - Small update; - Initial implementation of pyramids and prisms for Tecplot binary.; - Small fix for Tecplot binaries. Closes #56. Closes #57.; - Removed extra allocation related to markers during partitioning.; - Non-working version; - Small update; - Updated memory deallocation.; - Merge branch 'feature_MarkerMax' into develop; - Time and date in the header.; - Small fix to the latest commit.; - Simplification of entropy correction; - Critical stability improvement.; - Minor release 3.2.7.2; - Fixing issues to run with the latest intel compiler; - Fix for Tecplot binary solutions for unsteady flows. Fixes #150.; - Now SU2 should work with the latest version of the Intel compiler.; - Merge branch 'develop' of https://github.com/su2code/SU2 into develop; - Working on the O3 stuff; - Small change.; - Add another check to improve stability.; - Collection of improvements.; - Updated ac",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:4106,config,config,4106,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['config'],['config']
Modifiability,"calj/CodeSU2-master; Version: 4.1.0; C++ Compiler: g++; C Compiler: gcc; Preprocessor flags: ; Compiler flags: -g -O2; Linker flags: ; MPI support: no; Metis support: no; Parmetis support: no; TecIO support: no; CGNS support: yes; HDF5 support: no; SZIP support: no; ZLIB support: no; Mutation++ support: no; Jsoncpp support: no; LAPACK support: no; Datatype support:; double yes; complex no; codi_reverse no; codi_forward no. External includes: ; External libs: . Build SU2_CFD: yes; Build SU2_DOT: yes; Build SU2_MSH: yes; Build SU2_DEF: yes; Build SU2_SOL: yes; Build SU2_GEO: yes. Please be sure to add the $SU2_HOME and $SU2_RUN environment variables,; and update your $PATH (and $PYTHONPATH if applicable) with $SU2_RUN. Based on the input to this configuration, add these lines to your .bashrc file:. export SU2_RUN=""/gshare/work/hpascalj/CodeSU2-master/bin""; export SU2_HOME=""/home/antodech/SU2-4.1.0""; export PATH=$PATH:$SU2_RUN; export PYTHONPATH=$PYTHONPATH:$SU2_RUN. ## ---------------- ##; ## Cache variables. ##; ## ---------------- ##. ac_cv_build=x86_64-unknown-linux-gnu; ac_cv_c_compiler_gnu=yes; ac_cv_cxx_compiler_gnu=yes; ac_cv_env_CCC_set=; ac_cv_env_CCC_value=; ac_cv_env_CC_set=; ac_cv_env_CC_value=; ac_cv_env_CFLAGS_set=; ac_cv_env_CFLAGS_value=; ac_cv_env_CPPFLAGS_set=; ac_cv_env_CPPFLAGS_value=; ac_cv_env_CPP_set=; ac_cv_env_CPP_value=; ac_cv_env_CXXFLAGS_set=; ac_cv_env_CXXFLAGS_value=; ac_cv_env_CXX_set=; ac_cv_env_CXX_value=; ac_cv_env_LDFLAGS_set=; ac_cv_env_LDFLAGS_value=; ac_cv_env_LIBS_set=; ac_cv_env_LIBS_value=; ac_cv_env_build_alias_set=; ac_cv_env_build_alias_value=; ac_cv_env_host_alias_set=; ac_cv_env_host_alias_value=; ac_cv_env_target_alias_set=; ac_cv_env_target_alias_value=; ac_cv_file__gshare_soft_code_saturne_4_0_0_prod_cgnslib_3_2_1_include_cgnslib_h=yes; ac_cv_file__gshare_soft_code_saturne_4_0_0_prod_cgnslib_3_2_1_lib_libcgns_a=yes; ac_cv_header_X11_Intrinsic_h=no; ac_cv_header_inttypes_h=yes; ac_cv_header_memory_h=yes; ac_cv_header_std",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:19534,variab,variables,19534,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,1,['variab'],['variables']
Modifiability,"cc: unrecognized option '-qversion'; gcc: no input files; configure:3999: $? = 1; configure:4003: checking whether we are using the GNU C compiler; configure:4022: gcc -c conftest.c >&5; configure:4022: $? = 0; configure:4031: result: yes; configure:4040: checking whether gcc accepts -g; configure:4060: gcc -c -g conftest.c >&5; configure:4060: $? = 0; configure:4101: result: yes; configure:4118: checking for gcc option to accept ISO C89; configure:4181: gcc -c -g -O2 conftest.c >&5; configure:4181: $? = 0; configure:4194: result: none needed; configure:4216: checking dependency style of gcc; configure:4327: result: gcc3; configure:4345: checking whether gcc and cc understand -c and -o together; configure:4376: gcc -c conftest.c -o conftest2.o >&5; configure:4380: $? = 0; configure:4386: gcc -c conftest.c -o conftest2.o >&5; configure:4390: $? = 0; configure:4401: cc -c conftest.c >&5; configure:4405: $? = 0; configure:4413: cc -c conftest.c -o conftest2.o >&5; configure:4417: $? = 0; configure:4423: cc -c conftest.c -o conftest2.o >&5; configure:4427: $? = 0; configure:4445: result: yes; configure:4513: checking for ranlib; configure:4529: found /usr/bin/ranlib; configure:4540: result: ranlib; configure:4574: checking how to run the C preprocessor; configure:4605: gcc -E conftest.c; configure:4605: $? = 0; configure:4619: gcc -E conftest.c; conftest.c:11:28: error: ac_nonexistent.h: No such file or directory; configure:4619: $? = 1; configure: failed program was:; | /* confdefs.h */; | #define PACKAGE_NAME ""SU2""; | #define PACKAGE_TARNAME ""SU2""; | #define PACKAGE_VERSION ""4.1.0""; | #define PACKAGE_STRING ""SU2 4.1.0""; | #define PACKAGE_BUGREPORT ""su2code-dev@lists.stanford.edu""; | #define PACKAGE_URL ""https://github.com/su2code""; | #define PACKAGE ""SU2""; | #define VERSION ""4.1.0""; | /* end confdefs.h. */; | #include <ac_nonexistent.h>; configure:4644: result: gcc -E; configure:4664: gcc -E conftest.c; configure:4664: $? = 0; configure:4678: gcc -E conftest.c; confte",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:7694,config,configure,7694,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,2,['config'],['configure']
Modifiability,ceData.h (135) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtCaepSupportData.h (89) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtPwpInitItems.h (68) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtPwpPluginInfo.h (75) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtPwpVersions.h (62) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/runtimeWrite.c (443) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.sdf (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.sln (26) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.suo (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcproj (511) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcxproj (307) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcxproj.filters (78) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcxproj.user (3) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/UpgradeLog.XML (47) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport.css (207) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport.xslt (232) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport_Minus.gif (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport_Plus.gif (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/module.mk (240) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/modulelocal-sample.mk (84) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtCaepInitItems.h (142) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtCaepInstanceData.h (135) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtCaepSupportData.h (83) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtPwpInitItems.h (68) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsS,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:15561,plugin,plugins,15561,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['plugin'],['plugins']
Modifiability,"ce_adjoint files and in contrary as what Ole expected; the compressible gives a more wavy result. However the deviation of the sens_adjoint of incompressible is huge compare to the compressible case. ![image](https://user-images.githubusercontent.com/21182966/28306613-4425789c-6ba0-11e7-8337-41a99e15ebd2.png). So if I am understanding correctly, in order to determine the sensitivity an initial deviation of the control points has to be set to determine the (dx/dC)-term. In which 'x' indicates discrete points and 'C' control points. . ![image](https://latex.codecogs.com/gif.latex?%5Cfrac%7B%5Cpartial%20J%7D%7B%5Cpartial%20%5Cvec%7BC%7D%7D%20%3D%20%5Cfrac%7B%5Cpartial%20%5Cvec%7Bx%7D%7D%7B%5Cpartial%20%5Cvec%7BC%7D%7D%5Ccdot%20%5Cfrac%7B%5Cpartial%20J%7D%7B%5Cpartial%20%5Cvec%7Bx%7D%7D). Tim do you mean with the current step size the step of dC ? Because the step of the discrete point is set on 0.001 (of_grad_cd.vtk). If you mean the control point step, then there should be a parameterization step in between as well in order to know the influence of dC to dx. This should give a difference in sensitivity results, however the sensitivities of the case of scale = 0.01 and of the case scale =1 are exactly the same (for the compressible and incompressible case). The values below are gradients of the file of_grad_cd.vtk from the compressible case. ![image](https://user-images.githubusercontent.com/21182966/28307680-f01c9240-6ba3-11e7-8ada-4ddf9e4ae0a9.png). The final thing which I still have to check is the residuals of the direct and adjoint solution. As can be seen there is a difference in convergence and result, which I think is due to the difference in regime. The convergence of the direct solution is: ; ![image](https://user-images.githubusercontent.com/21182966/28309520-e967cbc6-6ba9-11e7-9233-9c9f69db126b.png). The convergence of the adjoint solution is:; ![image](https://user-images.githubusercontent.com/21182966/28308831-b937bf76-6ba7-11e7-9108-e8a2ab959b74.png). Th",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/409#issuecomment-316018103:1592,parameteriz,parameterization,1592,https://su2code.github.io,https://github.com/su2code/SU2/issues/409#issuecomment-316018103,1,['parameteriz'],['parameterization']
Modifiability,"composed via an inheritance chain, to do this; // we allow each building block to inherit from any class. These classes should; // be function objects that have no member variables, all data used in the; // resulting Compute method will be on the stack.; template<typename Base>; class ComputeArea : Base; {; protected:; // Different template instantiations will be made for; // 2D/3D to allow perfect loop unrolling.; enum : int {nDim = Base::nDim};. // To share variables between building blocks we will pass; // down a struct which is also composed by inheritance; struct WorkVarsType : Base::WorkVarsType; {; double area; // add ""area"" to the variables of Base; };; ; // The final implementation of Compute will be a call down the chain.; // The final constructed WorkVarsType is not known at this stage,; // hence we also template the method.; template<typename WV>; void Compute(WV& wv, const SolutionContainer& sol) const; {; // Boilerplate, call base first. This is akin to the decorator design pattern; // without polymorphism. The working variables resemble Python's ""self"" which; // makes this solution reasonably idiomatic.; Base::Compute(wv, sol);. // Then do our specific job.; wv.area = 0.0;; for(int i=0; i<nDim; ++i); wv.area += pow(sol.areaVector[i],2);; wv.area = sqrt(wv.area);; }; };. // Same mechanics as above; template<typename Base>; class ComputeFlux : Base; {; protected:; enum : int {nDim = Base::nDim};. struct WorkVarsType : Base::WorkVarsType ; {; double flux; // ...add new member; };. template<typename WV>; void Compute(WV& wv, const SolutionContainer& sol) const; {; // ...call base; Base::Compute(wv,sol);. // ...do aditional work; wv.flux = 0.0;; for(int i=0; i<nDim; ++i); wv.flux += sol.velocity[i]*sol.areaVector[i];; }; };. // This class is used to terminate the chain, it makes the link; // with the interface and it is used to specify any fixed sizes.; template<int NDIM>; class Terminator : private VirtualInterface; {; protected:; enum : int {nDim = NDIM};",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-622941617:3564,polymorphi,polymorphism,3564,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-622941617,1,['polymorphi'],['polymorphism']
Modifiability,"computations are very simple it may not pay-off to vectorize. **Relation with algorithms**; Some form of `gather` and `scatter` is required in unstructured CFD, which means SIMD has a price of admission. Some thought needs to go into designing algorithms that amortize that cost by maximizing the so called FLOP/Byte ratio, and mask the latency of those operations by being able to start computing as soon as the first element of data is available. **What elements should we try to process simultaneously?**; The choice is between multiple geometric primitives (edges/points) or multiple solution primitives (variables). The latter sounds like a sensible idea until we get to areas of the code where different primitives require different treatment, that and the fact that the number of variables might not fit evenly in the number of lanes can lead to very tricky and non-generic code. Nevertheless if the same code were to be applied to e.g. 4 solution variables, this strategy would likely perform better as it avoids the pesky gather/scatter operations.; Processing multiple geometric primitives can make full utilization of whatever register size (important on GPU's), the code is just as readable (as I hope to show), but gather/scatter cannot be avoided. ### Intro to SPMD; This one is simpler, in a nutshell multiple threads operate on the sub domain of an MPI rank.; The typical implementation has each thread executing a chunk of an edge or cell loop. **Why should we care about SPMD?**; Reduce the communication overhead resulting from domain decomposition and improve load balancing, important for strong scaling.; Some algorithms are more efficient that way, e.g. the ADT (as mentioned by Edwin), the current MG also seems to work better on fewer partitions, and additive versions of preconditioners like the ILU or LU-SGS lose effectiveness with number of partitions.; Optimum hardware utilization, for routines that are bandwidth-bound it may be beneficial to use all threads available",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-529662724:2550,variab,variables,2550,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-529662724,1,['variab'],['variables']
Modifiability,"configure:4060: $? = 0; configure:4101: result: yes; configure:4118: checking for gcc option to accept ISO C89; configure:4181: gcc -c -g -O2 conftest.c >&5; configure:4181: $? = 0; configure:4194: result: none needed; configure:4216: checking dependency style of gcc; configure:4327: result: gcc3; configure:4345: checking whether gcc and cc understand -c and -o together; configure:4376: gcc -c conftest.c -o conftest2.o >&5; configure:4380: $? = 0; configure:4386: gcc -c conftest.c -o conftest2.o >&5; configure:4390: $? = 0; configure:4401: cc -c conftest.c >&5; configure:4405: $? = 0; configure:4413: cc -c conftest.c -o conftest2.o >&5; configure:4417: $? = 0; configure:4423: cc -c conftest.c -o conftest2.o >&5; configure:4427: $? = 0; configure:4445: result: yes; configure:4513: checking for ranlib; configure:4529: found /usr/bin/ranlib; configure:4540: result: ranlib; configure:4574: checking how to run the C preprocessor; configure:4605: gcc -E conftest.c; configure:4605: $? = 0; configure:4619: gcc -E conftest.c; conftest.c:11:28: error: ac_nonexistent.h: No such file or directory; configure:4619: $? = 1; configure: failed program was:; | /* confdefs.h */; | #define PACKAGE_NAME ""SU2""; | #define PACKAGE_TARNAME ""SU2""; | #define PACKAGE_VERSION ""4.1.0""; | #define PACKAGE_STRING ""SU2 4.1.0""; | #define PACKAGE_BUGREPORT ""su2code-dev@lists.stanford.edu""; | #define PACKAGE_URL ""https://github.com/su2code""; | #define PACKAGE ""SU2""; | #define VERSION ""4.1.0""; | /* end confdefs.h. */; | #include <ac_nonexistent.h>; configure:4644: result: gcc -E; configure:4664: gcc -E conftest.c; configure:4664: $? = 0; configure:4678: gcc -E conftest.c; conftest.c:11:28: error: ac_nonexistent.h: No such file or directory; configure:4678: $? = 1; configure: failed program was:; | /* confdefs.h */; | #define PACKAGE_NAME ""SU2""; | #define PACKAGE_TARNAME ""SU2""; | #define PACKAGE_VERSION ""4.1.0""; | #define PACKAGE_STRING ""SU2 4.1.0""; | #define PACKAGE_BUGREPORT ""su2code-dev@lists.stanford.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:8023,config,configure,8023,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,2,['config'],['configure']
Modifiability,configure:4707: checking for grep that handles long lines and -e; configure:4765: result: /bin/grep; configure:4770: checking for egrep; configure:4832: result: /bin/grep -E; configure:4837: checking for ANSI C header files; configure:4857: gcc -c -g -O2 conftest.c >&5; configure:4857: $? = 0; configure:4930: gcc -o conftest -g -O2 conftest.c >&5; configure:4930: $? = 0; configure:4930: ./conftest; configure:4930: $? = 0; configure:4941: result: yes; configure:4954: checking for sys/types.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for sys/stat.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for stdlib.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for string.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for memory.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for strings.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for inttypes.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for stdint.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for unistd.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4970: checking size of short int; configure:4975: gcc -o conftest -g -O2 conftest.c >&5; configure:4975: $? = 0; configure:4975: ./conftest; configure:4975: $? = 0; configure:4989: result: 2; configure:5003: checking size of int; configure:5008: gcc -o conftest -g -O2 conftest.c >&5; ,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:10175,config,configure,10175,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,3,['config'],['configure']
Modifiability,configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for string.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for memory.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for strings.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for inttypes.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for stdint.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for unistd.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4970: checking size of short int; configure:4975: gcc -o conftest -g -O2 conftest.c >&5; configure:4975: $? = 0; configure:4975: ./conftest; configure:4975: $? = 0; configure:4989: result: 2; configure:5003: checking size of int; configure:5008: gcc -o conftest -g -O2 conftest.c >&5; configure:5008: $? = 0; configure:5008: ./conftest; configure:5008: $? = 0; configure:5022: result: 4; configure:5036: checking size of unsigned int; configure:5041: gcc -o conftest -g -O2 conftest.c >&5; configure:5041: $? = 0; configure:5041: ./conftest; configure:5041: $? = 0; configure:5055: result: 4; configure:5069: checking size of long int; configure:5074: gcc -o conftest -g -O2 conftest.c >&5; configure:5074: $? = 0; configure:5074: ./conftest; configure:5074: $? = 0; configure:5088: result: 8; configure:5102: checking size of float; configure:5107: gcc -o conftest -g -O2 conftest.c >&5; configure:5107: $? = 0; configure:5107: ./conftest; configure:5107: $? = 0; configure:5121: result: 4; configure:5135: checking size of double; configure:5140: gcc -o conftest -g -O2 conftest.c >&5; configure:5140: $?,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:11020,config,configure,11020,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,2,['config'],['configure']
Modifiability,"configure:5735: result: yes; configure:5755: checking for /gshare/soft/code_saturne/4.0.0/prod/cgnslib_3.2.1/include/cgnslib.h; configure:5769: result: yes; configure:6815: checking that generated files are newer than configure; configure:6821: result: done; configure:6952: creating ./config.status. ## ---------------------- ##; ## Running config.status. ##; ## ---------------------- ##. This file was extended by SU2 config.status 4.1.0, which was; generated by GNU Autoconf 2.69. Invocation command line was. CONFIG_FILES = ; CONFIG_HEADERS = ; CONFIG_LINKS = ; CONFIG_COMMANDS = ; $ ./config.status . on master. config.status:875: creating externals/tecio/Makefile; config.status:875: creating externals/metis/Makefile; config.status:875: creating externals/parmetis/Makefile; config.status:875: creating Makefile; config.status:875: creating externals/Makefile; config.status:875: creating Common/lib/Makefile; config.status:875: creating SU2_CFD/obj/Makefile; config.status:875: creating SU2_DOT/obj/Makefile; config.status:875: creating SU2_MSH/obj/Makefile; config.status:875: creating SU2_DEF/obj/Makefile; config.status:875: creating SU2_SOL/obj/Makefile; config.status:875: creating SU2_GEO/obj/Makefile; config.status:875: creating SU2_PY/Makefile; config.status:1047: executing depfiles commands; configure:8181: result:. -------------------------------------------------------------------------; | ___ _ _ ___ |; | / __| | | |_ ) Release 4.1.0 'Cardinal' |; | \__ \ |_| |/ / |; | |___/\___//___| Suite |; | |; -------------------------------------------------------------------------; | SU2 Lead Dev.: Dr. Francisco Palacios, Francisco.D.Palacios@boeing.com|; | Dr. Thomas D. Economon, economon@stanford.edu |; -------------------------------------------------------------------------; | SU2 Developers: |; | - Prof. Juan J. Alonso's group at Stanford University. |; | - Prof. Piero Colonna's group at Delft University of Technology. |; | - Prof. Nicolas R. Gauger's group at Kaisersl",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:16382,config,config,16382,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,1,['config'],['config']
Modifiability,d/PWP/pwpPlatform.c (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/pwpPlatform.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/site.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/structured.props (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/structured.vsprops (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/CaeTemplate.suo (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/CaeTemplate.vcproj (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/module.mk (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/modulelocal-sample.mk (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/rtCaepInitItems.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/rtCaepInstanceData.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/rtCaepSupportData.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/runtimeWrite.c (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/PWP/rtPwpInitItems.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/PWP/rtPwpPluginInfo.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/PWP/rtPwpVersions.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/unstructured.props (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/unstructured.vsprops (0) ; - D MeshTools/PointwiseSU2plugin_Instructions.txt (0) ; - I QuickStart/inv_NACA0012.cfg (0) ; - I README (0) ; - I SU2_CFD/include/SU2_CFD.hpp (0) ; - I SU2_CFD/include/definition_structure.hpp (0) ; - I SU2_CFD/include/fluid_model.hpp (0) ; - I SU2_CFD/include/fluid_model.inl (0) ; - I SU2_CFD/include/integration_structure.hpp (0) ; - I SU2_CFD/include/integration_structure.inl (0) ; - I SU2_CFD/include/iteration_structure.hpp (0) ; - I SU2_CFD/include/numerics_machine_learning.hpp (0) ; - I SU2_CFD/include/numerics_machine_learning.inl (0) ; - I SU2_CFD/include/numerics_machine_learning_turbulent.hpp (0) ; - I SU2_CFD/include/numerics_,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:20214,plugin,plugins,20214,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['plugin'],['plugins']
Modifiability,"defs.h. */; | #include <X11/Intrinsic.h>; configure:5409: result: no; configure:5409: checking for X11/Intrinsic.h; configure:5409: result: no; configure:5721: checking for /gshare/soft/code_saturne/4.0.0/prod/cgnslib_3.2.1/lib/libcgns.a; configure:5735: result: yes; configure:5755: checking for /gshare/soft/code_saturne/4.0.0/prod/cgnslib_3.2.1/include/cgnslib.h; configure:5769: result: yes; configure:6815: checking that generated files are newer than configure; configure:6821: result: done; configure:6952: creating ./config.status. ## ---------------------- ##; ## Running config.status. ##; ## ---------------------- ##. This file was extended by SU2 config.status 4.1.0, which was; generated by GNU Autoconf 2.69. Invocation command line was. CONFIG_FILES = ; CONFIG_HEADERS = ; CONFIG_LINKS = ; CONFIG_COMMANDS = ; $ ./config.status . on master. config.status:875: creating externals/tecio/Makefile; config.status:875: creating externals/metis/Makefile; config.status:875: creating externals/parmetis/Makefile; config.status:875: creating Makefile; config.status:875: creating externals/Makefile; config.status:875: creating Common/lib/Makefile; config.status:875: creating SU2_CFD/obj/Makefile; config.status:875: creating SU2_DOT/obj/Makefile; config.status:875: creating SU2_MSH/obj/Makefile; config.status:875: creating SU2_DEF/obj/Makefile; config.status:875: creating SU2_SOL/obj/Makefile; config.status:875: creating SU2_GEO/obj/Makefile; config.status:875: creating SU2_PY/Makefile; config.status:1047: executing depfiles commands; configure:8181: result:. -------------------------------------------------------------------------; | ___ _ _ ___ |; | / __| | | |_ ) Release 4.1.0 'Cardinal' |; | \__ \ |_| |/ / |; | |___/\___//___| Suite |; | |; -------------------------------------------------------------------------; | SU2 Lead Dev.: Dr. Francisco Palacios, Francisco.D.Palacios@boeing.com|; | Dr. Thomas D. Economon, economon@stanford.edu |; -----------------------------------",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:16147,config,config,16147,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,1,['config'],['config']
Modifiability,"e more granularity such that you could manipulate the geometry from python (without writing it to files).; > We also wanted introspection, i.e. you could probe SU2 via python for what variables and functions are available.; > We also talked about having the projection step (DOT) included in CFD_AD so that you only need to worry about surface sensitivities, note that DEF is already part of CFD for forward mode AD.; > (talking does not go very far); > ; > If you want to lead this work, we can help you understand the inner workings. We meet every Wednesday at 4pm CET https://meet.jit.si/SU2_DevMeeting to discuss this type of issue. Thank you for the quick reply. The discussions you mention sound very promising, I would be glad to join tomorrow afternoon and learn more, so that I might contribute. One quick remark: I am aware that it is indeed possible to deform the mesh within `SU2_CFD`, I use this extensively for static aero-elastic analysis. However, I have not been able to have the deformed mesh be written to file at output (in SU2 or CGNS format). This is fine for aero-elastic updates (movement of the surface due to _structural displacements_), where it is sufficient to see the deformed mesh in the post-processing files. It becomes impractical though, for design updates (movement of the surface to due to _design displacements_, i.e. representing changes in the design variables) where the new mesh is a useful intermediate result. Even if this is just an issue in my configuration file, I think that a stand-alone driver or equivalent of `SU2_DEF` would remain useful. For each new set of updated design variables during shape optimisation, a single mesh deformation is sufficient to provide the new, updated jig geometry which all of the aerodynamic or aero-elastic analyses (one for each operating point) have in common. There would be no need to initialise the entire `SU2_CFD` machinery for this step, or to apply the design update separately for each of the SU2 instances.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1262#issuecomment-818839696:1575,variab,variables,1575,https://su2code.github.io,https://github.com/su2code/SU2/issues/1262#issuecomment-818839696,3,"['config', 'variab']","['configuration', 'variables']"
Modifiability,e.; - Add another check to improve stability.; - Collection of improvements.; - Updated actuator disk; - Merge branch 'develop' of https://github.com/su2code/SU2 into develop; - Preliminary implementation of the Neg SA; - Minor updates; - Preliminary implementation of the Negative SA; - Bug fixing; - Fixed memory issued for very large meshes with ParMETIS.; - Clear evaluation of Vorticity and StrainMag; - Viscous limiter; - Updated RELAXATION_FACTOR; - RANS MG; - Partial fix to no MPI output; - Updated I/O; - Updated Adapt CFL; - Updated Adaptive CFL number; - Release 3.2.8; - Updated SetCFL_Number; - Small update; - Small change; - Small adjustments; - Minor changes; - Updated release 3.2.8; - MPI disabled by default in build. Added --enable-mpi flag to configure.; - Merged the ParMETIS implementation. Updated the build files.; - bootstrap; - Started parallel CGNS reader.; - Memory fix.; - Minor change; - Merge branch 'develop' of https://github.com/su2code/SU2 into develop; - Updated binaries; - Small change to configure.ac. Bootstrap.; - Small change; - Cleaning the code; - Updated grid deformation subroutine; - Fixing the mesh deformation; - Updated SU2_MSH; - Bug fixing; - Initial implementation of parallel CGNS reader. Works on 1 rank.; - Merged in recent changes to geometry_structure.cpp.; - Periodic BC working in serial; - Update option_structure.hpp; - Merge pull request #154 from su2code/fixCOptionEnumList; - Bug fixing (periodic bc); - Merge branch 'develop' of https://github.com/su2code/SU2 into develop; - Another important updated to BC in parallel; - More implementation and clean up of the parallel CGNS reader.; - Merge branch 'develop' of https://github.com/su2code/SU2 into develop; - CGNS reader bug fix.; - Updated adj. NS solver with primitive variables and farfield bc including viscous contribution.; - Merge branch 'develop' of https://github.com/su2code/SU2 into develop; - Small change; - Back to the previous version; - Fixed some loop variables.;,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:6059,config,configure,6059,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['config'],['configure']
Modifiability,e.m (60) ; - D MeshTools/Matlab/plotMarkers.m (64) ; - D MeshTools/PointwiseSU2plugin/FLAGS.linux (33) ; - D MeshTools/PointwiseSU2plugin/FLAGS.linux_x86_64 (33) ; - D MeshTools/PointwiseSU2plugin/FLAGS.macosx (112) ; - D MeshTools/PointwiseSU2plugin/FLAGS.win (14) ; - D MeshTools/PointwiseSU2plugin/FLAGS.win32 (33) ; - D MeshTools/PointwiseSU2plugin/Makefile (304) ; - D MeshTools/PointwiseSU2plugin/PluginSDK.sln (64) ; - D MeshTools/PointwiseSU2plugin/PluginSDK.suo (0) ; - D MeshTools/PointwiseSU2plugin/depend.sh (28) ; - D MeshTools/PointwiseSU2plugin/mkplugin (10) ; - D MeshTools/PointwiseSU2plugin/mkplugin.bat (82) ; - D MeshTools/PointwiseSU2plugin/mkplugin.tcl (422) ; - D MeshTools/PointwiseSU2plugin/src/Pointwise/Win32Target.props (28) ; - D MeshTools/PointwiseSU2plugin/src/Pointwise/Win32Target.vsprops (24) ; - D MeshTools/PointwiseSU2plugin/src/Pointwise/Win64Target.props (28) ; - D MeshTools/PointwiseSU2plugin/src/Pointwise/Win64Target.vsprops (24) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/CaeStrXML.vcproj (511) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/CaeStrXML.vcproj.PWI.dgarlisch.user (121) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/CaeStrXML.vcxproj (307) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/CaeStrXML.vcxproj.filters (78) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/CaeStrXML.vcxproj.user (3) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/module.mk (239) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/modulelocal-sample.mk (84) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtCaepInitItems.h (98) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtCaepInstanceData.h (135) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtCaepSupportData.h (89) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtPwpInitItems.h (68) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtPwpPluginInfo.h (75) ; - D MeshTools/PointwiseSU2plugi,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:13852,plugin,plugins,13852,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['plugin'],['plugins']
Modifiability,"e:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for unistd.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4970: checking size of short int; configure:4975: gcc -o conftest -g -O2 conftest.c >&5; configure:4975: $? = 0; configure:4975: ./conftest; configure:4975: $? = 0; configure:4989: result: 2; configure:5003: checking size of int; configure:5008: gcc -o conftest -g -O2 conftest.c >&5; configure:5008: $? = 0; configure:5008: ./conftest; configure:5008: $? = 0; configure:5022: result: 4; configure:5036: checking size of unsigned int; configure:5041: gcc -o conftest -g -O2 conftest.c >&5; configure:5041: $? = 0; configure:5041: ./conftest; configure:5041: $? = 0; configure:5055: result: 4; configure:5069: checking size of long int; configure:5074: gcc -o conftest -g -O2 conftest.c >&5; configure:5074: $? = 0; configure:5074: ./conftest; configure:5074: $? = 0; configure:5088: result: 8; configure:5102: checking size of float; configure:5107: gcc -o conftest -g -O2 conftest.c >&5; configure:5107: $? = 0; configure:5107: ./conftest; configure:5107: $? = 0; configure:5121: result: 4; configure:5135: checking size of double; configure:5140: gcc -o conftest -g -O2 conftest.c >&5; configure:5140: $? = 0; configure:5140: ./conftest; configure:5140: $? = 0; configure:5154: result: 8; configure:5168: checking size of void *; configure:5173: gcc -o conftest -g -O2 conftest.c >&5; configure:5173: $? = 0; configure:5173: ./conftest; configure:5173: $? = 0; configure:5187: result: 8; configure:5409: checking X11/Intrinsic.h usability; configure:5409: gcc -c -g -O2 conftest.c >&5; conftest.c:61:27: error: X11/Intrinsic.h: No such file or directory; configure:5409: $? = 1; configure: failed program was:; | /* confdefs.h */; | #define PACKAGE_NAME ""SU2""; | #define PACKAGE_TARNAME ""SU2""; | #define PACKAGE_VERSION ""4.1.0""; | #define PACKAGE_STRING ""SU2 4.1.0""; | #define PACKAGE_BUGREPORT ""su2code-d",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:11674,config,configure,11674,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,4,['config'],['configure']
Modifiability,eSU2plugin/src/plugins/CaeUnsSU2/rtCaepInstanceData.h (135) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtCaepSupportData.h (83) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtPwpInitItems.h (68) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtPwpPluginInfo.h (75) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtPwpVersions.h (64) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/runtimeWrite.c (439) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/runtimeWrite_orig.txt (60) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcproj (511) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcproj.PWI.dgarlisch.user (121) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcxproj (307) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcxproj.filters (78) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcxproj.user (3) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/module.mk (239) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/modulelocal-sample.mk (84) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtCaepInitItems.h (98) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtCaepInstanceData.h (135) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtCaepSupportData.h (89) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtPwpInitItems.h (68) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtPwpPluginInfo.h (75) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtPwpVersions.h (62) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/runtimeWrite.c (347) ; - D MeshTools/PointwiseSU2plugin/src/plugins/README.txt (272) ; - D MeshTools/PointwiseSU2plugin/src/plugins/module.mk (309) ; - D MeshTools/PointwiseSU2plugin/src/plugins/modulelocal.mk (8) ; - D MeshTools/PointwiseSU2plugin/src/plugins/pluginRegistry.h (29) ; - D MeshTools/PointwiseSU2plugin/src/plugins/s,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:17289,plugin,plugins,17289,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['plugin'],['plugins']
Modifiability,"e_saturne/4.0.0/prod/cgnslib_3.2.1/lib/libcgns.a; configure:5735: result: yes; configure:5755: checking for /gshare/soft/code_saturne/4.0.0/prod/cgnslib_3.2.1/include/cgnslib.h; configure:5769: result: yes; configure:6815: checking that generated files are newer than configure; configure:6821: result: done; configure:6952: creating ./config.status. ## ---------------------- ##; ## Running config.status. ##; ## ---------------------- ##. This file was extended by SU2 config.status 4.1.0, which was; generated by GNU Autoconf 2.69. Invocation command line was. CONFIG_FILES = ; CONFIG_HEADERS = ; CONFIG_LINKS = ; CONFIG_COMMANDS = ; $ ./config.status . on master. config.status:875: creating externals/tecio/Makefile; config.status:875: creating externals/metis/Makefile; config.status:875: creating externals/parmetis/Makefile; config.status:875: creating Makefile; config.status:875: creating externals/Makefile; config.status:875: creating Common/lib/Makefile; config.status:875: creating SU2_CFD/obj/Makefile; config.status:875: creating SU2_DOT/obj/Makefile; config.status:875: creating SU2_MSH/obj/Makefile; config.status:875: creating SU2_DEF/obj/Makefile; config.status:875: creating SU2_SOL/obj/Makefile; config.status:875: creating SU2_GEO/obj/Makefile; config.status:875: creating SU2_PY/Makefile; config.status:1047: executing depfiles commands; configure:8181: result:. -------------------------------------------------------------------------; | ___ _ _ ___ |; | / __| | | |_ ) Release 4.1.0 'Cardinal' |; | \__ \ |_| |/ / |; | |___/\___//___| Suite |; | |; -------------------------------------------------------------------------; | SU2 Lead Dev.: Dr. Francisco Palacios, Francisco.D.Palacios@boeing.com|; | Dr. Thomas D. Economon, economon@stanford.edu |; -------------------------------------------------------------------------; | SU2 Developers: |; | - Prof. Juan J. Alonso's group at Stanford University. |; | - Prof. Piero Colonna's group at Delft University of Technology. ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:16332,config,config,16332,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,1,['config'],['config']
Modifiability,"ead_id * MAX_TERMS`.; I think someone mentioned this (maybe Tim) that we could revisit the ownership relations of the numerics classes, i.e. allocate them as members of their respective solvers, which if we do, we can think of having a purpose built container that automates the per-thread creation and access. > Why are they redefined each time inside the loop?; > Is this for efficiency reasons?. Referring to variables being declared inside loops. One stylist reason is that declaring everything at the top of a function is the C way of doing things, the C++ people whose books/blogs I've read and talks I've watched, recommend keeping namespaces (the inside of the loop being one) as clean as possible.; The only reason not to do this is if you explicitly want re-use, in the case of trivial types this does not improve efficiency, and in the context of OpenMP code it can create issues. Just like we need one numerics per thread, if we declare variables outside a parallel loop the default OpenMP behaviour is to consider them shared, and concurrent writes to shared locations = gdb and many bad words xD.; **EDIT:** I should mention here that if the parallel region is started before the variable declarations they become local and all is well, with the exception of class members, those will be shared most of the time (this is where const correctness can give some peace of mind). > Also, just an additional (hopefully constructive) comment: I find all of these developments great, and I honestly think that you are doing an amazing job on performance and overall code improvement. However, as a non-C++-master myself, I'm just a little concerned of whether some advanced programming may become an entrance barrier to new additions to the community. As I wrote in the preamble of #789:; ""But please participate even if you never heard of these topics, your opinion about readability and ""developability"" of the code is important! I think the code-style should be accessible to people starting ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/843#issuecomment-577684728:2870,variab,variables,2870,https://su2code.github.io,https://github.com/su2code/SU2/pull/843#issuecomment-577684728,1,['variab'],['variables']
Modifiability,"eature_adapt branch`. 2. downloaded the Adaptive 2D NACA 0012 example (https://pyamg.saclay.inria.fr/pyamgexamples.html#2dnaca): `adap_NACA0012.cfg`, `mesh_NACA0012_inv.su2`, `NACA0012_ini.dat`. 3. added the following lines to the config:; ```; % Type of sensor used for adaptation; % Options include GOAL (adjoint-based), MACH, PRES; PYADAP_SENSOR= GOAL; % Objective function used for goal-oriented adaptation; OBJECTIVE_FUNCTION= LIFT; % Maximum cell size for adaptation; PYADAP_HMAX= 500.0; % Minimum cell size for adaptation; PYADAP_HMIN= 1e-9; % Gradation factor (typically 1.2-1.8); PYADAP_HGRAD= 1.8; % Norm used for adaptation; % 1.0 or 2.0 recommended for inviscid flows; % 4.0 recommeneded for viscid; ADAP_NORM= 4.0; % Approximate mesh size (NPOI) at each level; PYADAP_COMPLEXITY= (30000, 60000, 120000); % Number of adaptations performed at each level; PYADAP_SUBITE= (3, 3, 3); ```. 4. run the following command: `$ python3 SU2_RUN/mesh_adaptation_amg.py -f adap_ONERAM6.cfg -n 8`. The response I have obtained is the following:; ```; SU2-AMG Anisotropic Mesh Adaptation. Mesh adaptation options:; PYADAP_COMPLEXITY : (30000, 60000, 120000); PYADAP_SUBITE : (2, 2, 2); PYADAP_SENSOR : MACH; PYADAP_HMAX : 500.0; PYADAP_HMIN : 1e-9; PYADAP_HGRAD : 1.8; PYADAP_FLOW_ITER : (2999, 4999, 6999); PYADAP_ADJ_ITER : (2999, 4999, 6999); PYADAP_CFL : (10.0, 15.0, 20.0); PYADAP_RDG : NO. The ./adap folder was deleted. Generating GMF background surface mesh.; ## WARNING: MISSING SU2 MESH FILE KEYWORD: NCORNERS=.; Initial CFD solution is provided.; ```. As expected, a `./ADAP` folder was created, containing these docs: `amg_back_meshb`, `config_CFD.cfd`, `log.err`, `log.out` (sizes 0 byte), `mesh_NACA0012_inv.su2` (link to the mesh), `NACA0012_ini.dat` (link to the file.dat). Did I perform the procedure correctly? Or did I miss something?; If it is correct and complete, which file contains the adaptive mesh? How can I use it since there is no new .su2 file? . Thank you for the big help",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/948#issuecomment-737134105:1256,adapt,adaptation,1256,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-737134105,2,['adapt'],"['adaptation', 'adaptive']"
Modifiability,epend.sh (28) ; - D MeshTools/PointwiseSU2plugin/mkplugin (10) ; - D MeshTools/PointwiseSU2plugin/mkplugin.bat (82) ; - D MeshTools/PointwiseSU2plugin/mkplugin.tcl (422) ; - D MeshTools/PointwiseSU2plugin/src/Pointwise/Win32Target.props (28) ; - D MeshTools/PointwiseSU2plugin/src/Pointwise/Win32Target.vsprops (24) ; - D MeshTools/PointwiseSU2plugin/src/Pointwise/Win64Target.props (28) ; - D MeshTools/PointwiseSU2plugin/src/Pointwise/Win64Target.vsprops (24) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/CaeStrXML.vcproj (511) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/CaeStrXML.vcproj.PWI.dgarlisch.user (121) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/CaeStrXML.vcxproj (307) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/CaeStrXML.vcxproj.filters (78) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/CaeStrXML.vcxproj.user (3) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/module.mk (239) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/modulelocal-sample.mk (84) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtCaepInitItems.h (98) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtCaepInstanceData.h (135) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtCaepSupportData.h (89) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtPwpInitItems.h (68) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtPwpPluginInfo.h (75) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtPwpVersions.h (62) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/runtimeWrite.c (443) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.sdf (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.sln (26) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.suo (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcproj (511) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcxproj (307) ; ,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:14357,plugin,plugins,14357,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['plugin'],['plugins']
Modifiability,eport_Files/UpgradeReport.xslt (232) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport_Minus.gif (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport_Plus.gif (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/module.mk (240) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/modulelocal-sample.mk (84) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtCaepInitItems.h (142) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtCaepInstanceData.h (135) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtCaepSupportData.h (83) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtPwpInitItems.h (68) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtPwpPluginInfo.h (75) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtPwpVersions.h (64) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/runtimeWrite.c (439) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/runtimeWrite_orig.txt (60) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcproj (511) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcproj.PWI.dgarlisch.user (121) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcxproj (307) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcxproj.filters (78) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcxproj.user (3) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/module.mk (239) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/modulelocal-sample.mk (84) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtCaepInitItems.h (98) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtCaepInstanceData.h (135) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtCaepSupportData.h (89) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtPwpInitItems.h (68) ; - D MeshTools/PointwiseSU2plugin/s,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:16773,plugin,plugins,16773,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['plugin'],['plugins']
Modifiability,"er the communication to make sure the correct values are passed and _seen_ by all threads.; We can test other alternatives in the future but at the moment this does not seem to be a significant bottleneck.; _Worksharing_ constructs have implicit barriers at completion, for CSysVector routines I used `nowait` modifiers, it is safe to call those routines in sequence since the loop sizes, and static work scheduling specifications are identical.; However, routines that access a CSysVector in a different way, should have an explicit barrier before using the vector (or risk having undefined behaviour). You will see these barriers on entry to matrix-vector product, and every `ComputeXXXPreconditioner` (if you don't, let me know xD). I think those routines are large enough to amortise the cost of this. ### Performance; Disclaimer:; - We are talking about linear solvers only, **you will not see a global improvement yet**.; - The large global improvements from ""hybridization"" will come from the multigrid behaving better on less decomposed domains, and from the ability to independently tune the number of cores used in the linear preconditioners. For now the objective is ""just"" not to loose performance while gaining flexibility.; - The performance of MPI+threads with 1 thread per rank will be worse than just MPI (no free lunches). With this [small case](https://github.com/su2code/SU2/files/3933059/small_case.zip) using 8 cores off a machine with two 2650v4 CPU, Intel MPI 2018 + GCC 8.2, the hybrid (2 ranks of 4 threads) approach is about 5% faster thank the MPI-only (8 ranks), I expect larger cases to have identical performance. ### How To; - Compile: Add -fopenmp to the compiler and linker arguments.; - Run: Set number of threads with env variable `OMP_NUM_THREADS` (eventually I will make that a command line parameter), for best performance set `OMP_WAIT_POLICY=ACTIVE` and beware of thread binding settings, use `mpirun --bind-to socket` or `mpirun --bind-to numa` never `core`.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/830#issuecomment-562646766:3593,variab,variable,3593,https://su2code.github.io,https://github.com/su2code/SU2/pull/830#issuecomment-562646766,1,['variab'],['variable']
Modifiability,"erator= (const Array& rhs); {; #pragma omp simd; FOREACH vals_[k] = rhs.vals_[k];; return *this;; }. STRONGINLINE Array& operator+= (const Array& rhs); {; #pragma omp simd; FOREACH vals_[k] += rhs.vals_[k];; return *this;; }; STRONGINLINE Array operator+ (const Array& rhs) const { return Array(*this)+=rhs; }; ; /*; * Many other operators go here.; */; };. // Common math function overloads; template<class T>; STRONGINLINE T vmax(const T& a, const T& b); {; T res;; #pragma omp simd; for(size_t k=0; k<T::Size; ++k); res[k] = (a[k]>b[k])? a[k] : b[k];; return res;; }. #undef FOREACH; ```; There are other (better) ways to do this, for example using [x86 intrinsics](https://software.intel.com/sites/landingpage/IntrinsicsGuide/#expand=2273,2273,2436,2943,2436,2943,610,1788,2942) (in header `<x86intrin.h>`), register types instead of arrays, and a boat load of template meta-programming (I'm guessing) there are professional libraries for this.; This quickly-hacked-together code is compatible with custom types, portable, and seems to do the trick. To pull this off we do not need to have `Vector` or `Matrix` of this class, the underlying type for those data structures is still `double`, only the `getVec` type methods need to convert on the fly to the SIMD type, for example:; ```C++; // use the ""pointer ctor"" to return an array starting at ""row0""; Array<double,4> Matrix<double>::getVec(size_t row0, size_t col) const {; return Array<double,4>(&data_[row0+col*rows_]);; }. // use the ""gather ctor"" to return an array with the indices in ""rows""; template<class U>; Array<double,4> Matrix<double>::getVec(const U& rows, size_t col) const {; return Array<double,4>(&data_[col*rows_], rows);; }; ```; After inlining those copies get optimized away.; Although the stored type, and ""scalar interface"" of the containers do not need to change, the storage order of the data does. Notice that in the above data is stored by columns instead of rows (something that @vdweide mentioned in #716) this has",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-530328194:9050,portab,portable,9050,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530328194,1,['portab'],['portable']
Modifiability,"erency) or it needs to acquire a *lock* for the point it is writing to, if it fails to acquire the *lock* (because another thread has it) it needs to wait. None of these is without drawbacks.; - **Coloring** reduces temporal locality, edges are sorted in increasing order of the point indices to reduce cache misses, this means small groups of contiguous edges will share the same ""iPoint"", coloring single edges destroys this. Furthermore coloring either requires edges to be re-sorted by color, or if the edge indices of each color are instead kept in arrays, performance will suffer due to increased indirection which confounds the hardware pre-fetcher.; This can be mitigated to some extent by coloring groups of edges, groups of edges of the same color can be processed simultaneously, but within each group edges need to be processed serially. However grouping will reduce how much parallelism can be exploited within each color.; - **Gather to scatter** will in general use more memory due to the intermediate variables and extra adjacency information needed. If the entire algorithm is transformed performance may suffer as some computations may have to be repeated.; However, some reductions are possible without intermediate variables, for example when assembling the system matrix for implicit schemes only the diagonal entries can result in race conditions, now it just so happens that each diagonal entry is equal to the negated corresponding column sum.; - **Atomics** are terrible for the performance of code that writes frequently to memory (i.e. bandwidth-bound code), they do not increase the memory footprint and so make sense for compute-bound code.; Bugs due to a missing atomic can be very hard to debug (but any race condition is). Coloring is what one sees most in the literature, and yet I lean towards gather-to-scatter. Fewer things can go wrong with it as it is easy to understand, one gets the maximum amount of parallelism. I will now take two familiar routines, computin",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-529662724:5878,variab,variables,5878,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-529662724,1,['variab'],['variables']
Modifiability,"erit from any class. These classes should; // be function objects that have no member variables, all data used in the; // resulting Compute method will be on the stack.; template<typename Base>; class ComputeArea : Base; {; protected:; // Different template instantiations will be made for; // 2D/3D to allow perfect loop unrolling.; enum : int {nDim = Base::nDim};. // To share variables between building blocks we will pass; // down a struct which is also composed by inheritance; struct WorkVarsType : Base::WorkVarsType; {; double area; // add ""area"" to the variables of Base; };; ; // The final implementation of Compute will be a call down the chain.; // The final constructed WorkVarsType is not known at this stage,; // hence we also template the method.; template<typename WV>; void Compute(WV& wv, const SolutionContainer& sol) const; {; // Boilerplate, call base first. This is akin to the decorator design pattern; // without polymorphism. The working variables resemble Python's ""self"" which; // makes this solution reasonably idiomatic.; Base::Compute(wv, sol);. // Then do our specific job.; wv.area = 0.0;; for(int i=0; i<nDim; ++i); wv.area += pow(sol.areaVector[i],2);; wv.area = sqrt(wv.area);; }; };. // Same mechanics as above; template<typename Base>; class ComputeFlux : Base; {; protected:; enum : int {nDim = Base::nDim};. struct WorkVarsType : Base::WorkVarsType ; {; double flux; // ...add new member; };. template<typename WV>; void Compute(WV& wv, const SolutionContainer& sol) const; {; // ...call base; Base::Compute(wv,sol);. // ...do aditional work; wv.flux = 0.0;; for(int i=0; i<nDim; ++i); wv.flux += sol.velocity[i]*sol.areaVector[i];; }; };. // This class is used to terminate the chain, it makes the link; // with the interface and it is used to specify any fixed sizes.; template<int NDIM>; class Terminator : private VirtualInterface; {; protected:; enum : int {nDim = NDIM};. struct WorkVarsType {};. template<typename... Ts>; void Compute(Ts&...) const {}; }",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-622941617:3590,variab,variables,3590,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-622941617,1,['variab'],['variables']
Modifiability,"es are newer than configure; configure:6821: result: done; configure:6952: creating ./config.status. ## ---------------------- ##; ## Running config.status. ##; ## ---------------------- ##. This file was extended by SU2 config.status 4.1.0, which was; generated by GNU Autoconf 2.69. Invocation command line was. CONFIG_FILES = ; CONFIG_HEADERS = ; CONFIG_LINKS = ; CONFIG_COMMANDS = ; $ ./config.status . on master. config.status:875: creating externals/tecio/Makefile; config.status:875: creating externals/metis/Makefile; config.status:875: creating externals/parmetis/Makefile; config.status:875: creating Makefile; config.status:875: creating externals/Makefile; config.status:875: creating Common/lib/Makefile; config.status:875: creating SU2_CFD/obj/Makefile; config.status:875: creating SU2_DOT/obj/Makefile; config.status:875: creating SU2_MSH/obj/Makefile; config.status:875: creating SU2_DEF/obj/Makefile; config.status:875: creating SU2_SOL/obj/Makefile; config.status:875: creating SU2_GEO/obj/Makefile; config.status:875: creating SU2_PY/Makefile; config.status:1047: executing depfiles commands; configure:8181: result:. -------------------------------------------------------------------------; | ___ _ _ ___ |; | / __| | | |_ ) Release 4.1.0 'Cardinal' |; | \__ \ |_| |/ / |; | |___/\___//___| Suite |; | |; -------------------------------------------------------------------------; | SU2 Lead Dev.: Dr. Francisco Palacios, Francisco.D.Palacios@boeing.com|; | Dr. Thomas D. Economon, economon@stanford.edu |; -------------------------------------------------------------------------; | SU2 Developers: |; | - Prof. Juan J. Alonso's group at Stanford University. |; | - Prof. Piero Colonna's group at Delft University of Technology. |; | - Prof. Nicolas R. Gauger's group at Kaiserslautern U. of Technology. |; | - Prof. Alberto Guardone's group at Polytechnic University of Milan. |; | - Prof. Rafael Palacios' group at Imperial College London. |; ----------------------------------",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:16582,config,config,16582,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,1,['config'],['config']
Modifiability,eshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.suo (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcproj (511) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcxproj (307) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcxproj.filters (78) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcxproj.user (3) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/UpgradeLog.XML (47) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport.css (207) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport.xslt (232) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport_Minus.gif (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport_Plus.gif (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/module.mk (240) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/modulelocal-sample.mk (84) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtCaepInitItems.h (142) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtCaepInstanceData.h (135) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtCaepSupportData.h (83) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtPwpInitItems.h (68) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtPwpPluginInfo.h (75) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtPwpVersions.h (64) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/runtimeWrite.c (439) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/runtimeWrite_orig.txt (60) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcproj (511) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcproj.PWI.dgarlisch.user (121) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcxproj (307) ; - D MeshTools/PointwiseSU2plugin/src/plugi,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:16127,plugin,plugins,16127,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['plugin'],['plugins']
Modifiability,"esult: 4; configure:5036: checking size of unsigned int; configure:5041: gcc -o conftest -g -O2 conftest.c >&5; configure:5041: $? = 0; configure:5041: ./conftest; configure:5041: $? = 0; configure:5055: result: 4; configure:5069: checking size of long int; configure:5074: gcc -o conftest -g -O2 conftest.c >&5; configure:5074: $? = 0; configure:5074: ./conftest; configure:5074: $? = 0; configure:5088: result: 8; configure:5102: checking size of float; configure:5107: gcc -o conftest -g -O2 conftest.c >&5; configure:5107: $? = 0; configure:5107: ./conftest; configure:5107: $? = 0; configure:5121: result: 4; configure:5135: checking size of double; configure:5140: gcc -o conftest -g -O2 conftest.c >&5; configure:5140: $? = 0; configure:5140: ./conftest; configure:5140: $? = 0; configure:5154: result: 8; configure:5168: checking size of void *; configure:5173: gcc -o conftest -g -O2 conftest.c >&5; configure:5173: $? = 0; configure:5173: ./conftest; configure:5173: $? = 0; configure:5187: result: 8; configure:5409: checking X11/Intrinsic.h usability; configure:5409: gcc -c -g -O2 conftest.c >&5; conftest.c:61:27: error: X11/Intrinsic.h: No such file or directory; configure:5409: $? = 1; configure: failed program was:; | /* confdefs.h */; | #define PACKAGE_NAME ""SU2""; | #define PACKAGE_TARNAME ""SU2""; | #define PACKAGE_VERSION ""4.1.0""; | #define PACKAGE_STRING ""SU2 4.1.0""; | #define PACKAGE_BUGREPORT ""su2code-dev@lists.stanford.edu""; | #define PACKAGE_URL ""https://github.com/su2code""; | #define PACKAGE ""SU2""; | #define VERSION ""4.1.0""; | #define STDC_HEADERS 1; | #define HAVE_SYS_TYPES_H 1; | #define HAVE_SYS_STAT_H 1; | #define HAVE_STDLIB_H 1; | #define HAVE_STRING_H 1; | #define HAVE_MEMORY_H 1; | #define HAVE_STRINGS_H 1; | #define HAVE_INTTYPES_H 1; | #define HAVE_STDINT_H 1; | #define HAVE_UNISTD_H 1; | #define SIZEOF_SHORT_INT 2; | #define SIZEOF_INT 4; | #define SIZEOF_UNSIGNED_INT 4; | #define SIZEOF_LONG_INT 8; | #define SIZEOF_FLOAT 4; | #define SIZEOF_DOUBLE 8",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:12270,config,configure,12270,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,3,['config'],['configure']
Modifiability,figure:4765: result: /bin/grep; configure:4770: checking for egrep; configure:4832: result: /bin/grep -E; configure:4837: checking for ANSI C header files; configure:4857: gcc -c -g -O2 conftest.c >&5; configure:4857: $? = 0; configure:4930: gcc -o conftest -g -O2 conftest.c >&5; configure:4930: $? = 0; configure:4930: ./conftest; configure:4930: $? = 0; configure:4941: result: yes; configure:4954: checking for sys/types.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for sys/stat.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for stdlib.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for string.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for memory.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for strings.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for inttypes.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for stdint.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for unistd.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4970: checking size of short int; configure:4975: gcc -o conftest -g -O2 conftest.c >&5; configure:4975: $? = 0; configure:4975: ./conftest; configure:4975: $? = 0; configure:4989: result: 2; configure:5003: checking size of int; configure:5008: gcc -o conftest -g -O2 conftest.c >&5; configure:5008: $? = 0; configure:5008: ./conftest; configure:5008: $,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:10267,config,configure,10267,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,1,['config'],['configure']
Modifiability,"fine PACKAGE_VERSION ""4.1.0""; | #define PACKAGE_STRING ""SU2 4.1.0""; | #define PACKAGE_BUGREPORT ""su2code-dev@lists.stanford.edu""; | #define PACKAGE_URL ""https://github.com/su2code""; | #define PACKAGE ""SU2""; | #define VERSION ""4.1.0""; | #define STDC_HEADERS 1; | #define HAVE_SYS_TYPES_H 1; | #define HAVE_SYS_STAT_H 1; | #define HAVE_STDLIB_H 1; | #define HAVE_STRING_H 1; | #define HAVE_MEMORY_H 1; | #define HAVE_STRINGS_H 1; | #define HAVE_INTTYPES_H 1; | #define HAVE_STDINT_H 1; | #define HAVE_UNISTD_H 1; | #define SIZEOF_SHORT_INT 2; | #define SIZEOF_INT 4; | #define SIZEOF_UNSIGNED_INT 4; | #define SIZEOF_LONG_INT 8; | #define SIZEOF_FLOAT 4; | #define SIZEOF_DOUBLE 8; | #define SIZEOF_VOID_P 8; | /* end confdefs.h. */; | #include <X11/Intrinsic.h>; configure:5409: result: no; configure:5409: checking for X11/Intrinsic.h; configure:5409: result: no; configure:5721: checking for /gshare/soft/code_saturne/4.0.0/prod/cgnslib_3.2.1/lib/libcgns.a; configure:5735: result: yes; configure:5755: checking for /gshare/soft/code_saturne/4.0.0/prod/cgnslib_3.2.1/include/cgnslib.h; configure:5769: result: yes; configure:6815: checking that generated files are newer than configure; configure:6821: result: done; configure:6952: creating ./config.status. ## ---------------------- ##; ## Running config.status. ##; ## ---------------------- ##. This file was extended by SU2 config.status 4.1.0, which was; generated by GNU Autoconf 2.69. Invocation command line was. CONFIG_FILES = ; CONFIG_HEADERS = ; CONFIG_LINKS = ; CONFIG_COMMANDS = ; $ ./config.status . on master. config.status:875: creating externals/tecio/Makefile; config.status:875: creating externals/metis/Makefile; config.status:875: creating externals/parmetis/Makefile; config.status:875: creating Makefile; config.status:875: creating externals/Makefile; config.status:875: creating Common/lib/Makefile; config.status:875: creating SU2_CFD/obj/Makefile; config.status:875: creating SU2_DOT/obj/Makefile; config.status:875: creat",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:15364,config,configure,15364,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,2,['config'],['configure']
Modifiability,"firmed by opening a python terminal and running `import mpi4py`. #### The easiest workaround. Switch to a [virtualenv](https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/). This will ensure that all of your python packages are stored in single location. #### Alternate workaround. In this method, you change the hardcoded includes to match mpi4py's package location. First I figure out where my mpi4py is installed. I start a terminal session of python using the python environment I want to use (in this case, it's python 3.6), and then run:; ```; from mpi4py import MPI; MPI; ```. Since I have mpi4py installed on your system and it's on my python path, I see something like:; ```; <module 'mpi4py.MPI' from '/home/clarkpede/.local/lib/python3.6/site-packages/mpi4py/MPI.cpython-34m.so'>; ```. The `/home/clarkpede/.local/lib/python3.6/` directory is where my mpi4py package is installed. But the swig compile command includes `/home/clarkpede/.local/lib/python2.7/`. That's not the right directory! So first I find the hardcoded paths of the makefile by running (on a bash terminal):; ```; grep -rn python2\.7 SU2_PY/ ; ```; On my system, this prints out four lines. I don't care about the `Makefile.in` files, because those are generated automatically and will be overwritten every time I run ""configure"" or ""preconfigure.py."" The `NUMPY_INCLUDE` line is also commented out, so I ignore that too. That leaves me with one line, line 51 of `SU2_PY/pySU2/Makefile.am`:. ```; SU2_PY/pySU2/Makefile.am:51:MPI4PY_INCLUDE = ${HOME}/.local/lib/python2.7/site-packages/mpi4py/include \; ```. I now modify line 51 of Makefile.am to read:. ```; MPI4PY_INCLUDE = ${HOME}/.local/lib/python3.6/site-packages/mpi4py/include \; ```. Then run configure or preconfigure.py again, and then run make again. You should be good to go!. #### tl;dr. If you're having this error, modify the `MPI4PY_INCLUDE` line of `SU2_PY/pySU2/Makefile.am` to include the location of your mpi4py package.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/722#issuecomment-515693590:2286,config,configure,2286,https://su2code.github.io,https://github.com/su2code/SU2/issues/722#issuecomment-515693590,2,['config'],['configure']
Modifiability,"ftest.c >&5; configure:4022: $? = 0; configure:4031: result: yes; configure:4040: checking whether gcc accepts -g; configure:4060: gcc -c -g conftest.c >&5; configure:4060: $? = 0; configure:4101: result: yes; configure:4118: checking for gcc option to accept ISO C89; configure:4181: gcc -c -g -O2 conftest.c >&5; configure:4181: $? = 0; configure:4194: result: none needed; configure:4216: checking dependency style of gcc; configure:4327: result: gcc3; configure:4345: checking whether gcc and cc understand -c and -o together; configure:4376: gcc -c conftest.c -o conftest2.o >&5; configure:4380: $? = 0; configure:4386: gcc -c conftest.c -o conftest2.o >&5; configure:4390: $? = 0; configure:4401: cc -c conftest.c >&5; configure:4405: $? = 0; configure:4413: cc -c conftest.c -o conftest2.o >&5; configure:4417: $? = 0; configure:4423: cc -c conftest.c -o conftest2.o >&5; configure:4427: $? = 0; configure:4445: result: yes; configure:4513: checking for ranlib; configure:4529: found /usr/bin/ranlib; configure:4540: result: ranlib; configure:4574: checking how to run the C preprocessor; configure:4605: gcc -E conftest.c; configure:4605: $? = 0; configure:4619: gcc -E conftest.c; conftest.c:11:28: error: ac_nonexistent.h: No such file or directory; configure:4619: $? = 1; configure: failed program was:; | /* confdefs.h */; | #define PACKAGE_NAME ""SU2""; | #define PACKAGE_TARNAME ""SU2""; | #define PACKAGE_VERSION ""4.1.0""; | #define PACKAGE_STRING ""SU2 4.1.0""; | #define PACKAGE_BUGREPORT ""su2code-dev@lists.stanford.edu""; | #define PACKAGE_URL ""https://github.com/su2code""; | #define PACKAGE ""SU2""; | #define VERSION ""4.1.0""; | /* end confdefs.h. */; | #include <ac_nonexistent.h>; configure:4644: result: gcc -E; configure:4664: gcc -E conftest.c; configure:4664: $? = 0; configure:4678: gcc -E conftest.c; conftest.c:11:28: error: ac_nonexistent.h: No such file or directory; configure:4678: $? = 1; configure: failed program was:; | /* confdefs.h */; | #define PACKAGE_NAME ""SU2""; | #d",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:7771,config,configure,7771,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,7,['config'],['configure']
Modifiability,gin/src/plugins/CaeUnsSU2/runtimeWrite_orig.txt (60) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcproj (511) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcproj.PWI.dgarlisch.user (121) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcxproj (307) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcxproj.filters (78) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcxproj.user (3) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/module.mk (239) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/modulelocal-sample.mk (84) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtCaepInitItems.h (98) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtCaepInstanceData.h (135) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtCaepSupportData.h (89) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtPwpInitItems.h (68) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtPwpPluginInfo.h (75) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtPwpVersions.h (62) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/runtimeWrite.c (347) ; - D MeshTools/PointwiseSU2plugin/src/plugins/README.txt (272) ; - D MeshTools/PointwiseSU2plugin/src/plugins/module.mk (309) ; - D MeshTools/PointwiseSU2plugin/src/plugins/modulelocal.mk (8) ; - D MeshTools/PointwiseSU2plugin/src/plugins/pluginRegistry.h (29) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEP.c (228) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEP.h (550) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEPUtils.c (290) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEPUtils.h (725) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/runtimeWrite.h (57) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWGM/apiGridModel.c (492) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWGM/apiGrid,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:17771,plugin,plugins,17771,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['plugin'],['plugins']
Modifiability,gins/CaeUnsXML/CaeUnsXML.vcxproj.filters (78) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcxproj.user (3) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/module.mk (239) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/modulelocal-sample.mk (84) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtCaepInitItems.h (98) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtCaepInstanceData.h (135) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtCaepSupportData.h (89) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtPwpInitItems.h (68) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtPwpPluginInfo.h (75) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtPwpVersions.h (62) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/runtimeWrite.c (347) ; - D MeshTools/PointwiseSU2plugin/src/plugins/README.txt (272) ; - D MeshTools/PointwiseSU2plugin/src/plugins/module.mk (309) ; - D MeshTools/PointwiseSU2plugin/src/plugins/modulelocal.mk (8) ; - D MeshTools/PointwiseSU2plugin/src/plugins/pluginRegistry.h (29) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEP.c (228) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEP.h (550) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEPUtils.c (290) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEPUtils.h (725) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/runtimeWrite.h (57) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWGM/apiGridModel.c (492) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWGM/apiGridModel.h (1808) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWP.c (132) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWP.h (707) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWPUtils.c (789) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWPUtils.h (1030) ; - D MeshTools/PointwiseSU2plugin/sr,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:18134,plugin,plugins,18134,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['plugin'],['plugins']
Modifiability,"github.com/su2code/SU2/commit/ac8b3bf7636cc66ca7f47e15935942a6598e1a9f), the `SetRoe_Dissipation` function checked to see if the sensor values were valid regardless of the type of blending selected. Commit [ac8b3bf](https://github.com/su2code/SU2/commit/ac8b3bf7636cc66ca7f47e15935942a6598e1a9f) changed the behavior to only check the sensor values if they will be used. The unit test sets the convective blending to `NTS`, feeds invalid sensor values into `SetRoe_Dissipation` and checks the output. ```cpp; // Used to set the Roe-low-dissipation option; void WriteCfgFile(unsigned short nDim, const char* filename,; std::string blending) {; std::ofstream cfg_file;. cfg_file.open(filename, ios::out);; cfg_file << ""PHYSICAL_PROBLEM= NAVIER_STOKES"" << std::endl;; cfg_file << ""ROE_LOW_DISSIPATION= "" << blending << std::endl;. cfg_file.close();; }. BOOST_AUTO_TEST_CASE(BadSensorsAllowedForNTS) {. /*--- Setup ---*/. const unsigned short nDim = 3;. /*--- Set up the config class for the test ---*/; char cfg_filename[100] = ""convective_blending_test.cfg"";; WriteCfgFile(nDim, cfg_filename, ""NTS"");; CConfig* config = new CConfig(cfg_filename, SU2_CFD, 0, 1, 2, VERB_NONE);; std::remove(cfg_filename);. /*--- Inputs ---*/; const su2double dissipation_i = 0.4;; const su2double dissipation_j = 0.6;; const su2double sensor_i = NAN; // Intentionally unphysical:; const su2double sensor_j = NAN; // Intentionally unphysical:. /*--- Outputs ---*/; su2double dissipation;. /*--- Test ---*/. CNumerics numerics;; numerics.SetRoe_Dissipation(dissipation_i, dissipation_j,; sensor_i, sensor_j,; dissipation, config);. const su2double tolerance = std::numeric_limits<su2double>::epsilon();; BOOST_CHECK_CLOSE_FRACTION(dissipation, 0.5, tolerance);. /*--- Teardown ---*/; delete config;; }; ```. There's a couple problems I would fix if I had more time. Ideally, I would be writing the cfg file to an in-memory stream and not to a file. And realistically, I shouldn't need to use a config file at all for a sim",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499999225:1267,config,config,1267,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499999225,1,['config'],['config']
Modifiability,"gnized option '-qversion'; g++: no input files; configure:3343: $? = 1; configure:3363: checking whether the C++ compiler works; configure:3385: g++ conftest.cpp >&5; configure:3389: $? = 0; configure:3437: result: yes; configure:3440: checking for C++ compiler default output file name; configure:3442: result: a.out; configure:3448: checking for suffix of executables; configure:3455: g++ -o conftest conftest.cpp >&5; configure:3459: $? = 0; configure:3481: result: ; configure:3503: checking whether we are cross compiling; configure:3511: g++ -o conftest conftest.cpp >&5; configure:3515: $? = 0; configure:3522: ./conftest; configure:3526: $? = 0; configure:3541: result: no; configure:3546: checking for suffix of object files; configure:3568: g++ -c conftest.cpp >&5; configure:3572: $? = 0; configure:3593: result: o; configure:3597: checking whether we are using the GNU C++ compiler; configure:3616: g++ -c conftest.cpp >&5; configure:3616: $? = 0; configure:3625: result: yes; configure:3634: checking whether g++ accepts -g; configure:3654: g++ -c -g conftest.cpp >&5; configure:3654: $? = 0; configure:3695: result: yes; configure:3720: checking dependency style of g++; configure:3831: result: gcc3; configure:3921: checking for gcc; configure:3937: found /usr/bin/gcc; configure:3948: result: gcc; configure:3979: checking for C compiler version; configure:3988: gcc --version >&5; gcc (GCC) 4.4.6 20120305 (Red Hat 4.4.6-4); Copyright (C) 2010 Free Software Foundation, Inc.; This is free software; see the source for copying conditions. There is NO; warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. configure:3999: $? = 0; configure:3988: gcc -v >&5; Using built-in specs.; Target: x86_64-redhat-linux; Configured with: ../configure --prefix=/usr --mandir=/usr/share/man --infodir=/usr/share/info --with-bugurl=http://bugzilla.redhat.com/bugzilla --enable-bootstrap --enable-shared --enable-threads=posix --enable-checking=release --with-system-zlib --ena",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:4984,config,configure,4984,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,4,['config'],['configure']
Modifiability,"gure:3332: g++ -v >&5; Using built-in specs.; Target: x86_64-redhat-linux; Configured with: ../configure --prefix=/usr --mandir=/usr/share/man --infodir=/usr/share/info --with-bugurl=http://bugzilla.redhat.com/bugzilla --enable-bootstrap --enable-shared --enable-threads=posix --enable-checking=release --with-system-zlib --enable-__cxa_atexit --disable-libunwind-exceptions --enable-gnu-unique-object --enable-languages=c,c++,objc,obj-c++,java,fortran,ada --enable-java-awt=gtk --disable-dssi --with-java-home=/usr/lib/jvm/java-1.5.0-gcj-1.5.0.0/jre --enable-libgcj-multifile --enable-java-maintainer-mode --with-ecj-jar=/usr/share/java/eclipse-ecj.jar --disable-libjava-multilib --with-ppl --with-cloog --with-tune=generic --with-arch_32=i686 --build=x86_64-redhat-linux; Thread model: posix; gcc version 4.4.6 20120305 (Red Hat 4.4.6-4) (GCC) ; configure:3343: $? = 0; configure:3332: g++ -V >&5; g++: '-V' option must have argument; configure:3343: $? = 1; configure:3332: g++ -qversion >&5; g++: unrecognized option '-qversion'; g++: no input files; configure:3343: $? = 1; configure:3363: checking whether the C++ compiler works; configure:3385: g++ conftest.cpp >&5; configure:3389: $? = 0; configure:3437: result: yes; configure:3440: checking for C++ compiler default output file name; configure:3442: result: a.out; configure:3448: checking for suffix of executables; configure:3455: g++ -o conftest conftest.cpp >&5; configure:3459: $? = 0; configure:3481: result: ; configure:3503: checking whether we are cross compiling; configure:3511: g++ -o conftest conftest.cpp >&5; configure:3515: $? = 0; configure:3522: ./conftest; configure:3526: $? = 0; configure:3541: result: no; configure:3546: checking for suffix of object files; configure:3568: g++ -c conftest.cpp >&5; configure:3572: $? = 0; configure:3593: result: o; configure:3597: checking whether we are using the GNU C++ compiler; configure:3616: g++ -c conftest.cpp >&5; configure:3616: $? = 0; configure:3625: result: yes; conf",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:3889,config,configure,3889,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,7,['config'],['configure']
Modifiability,"gure:4664: $? = 0; configure:4678: gcc -E conftest.c; conftest.c:11:28: error: ac_nonexistent.h: No such file or directory; configure:4678: $? = 1; configure: failed program was:; | /* confdefs.h */; | #define PACKAGE_NAME ""SU2""; | #define PACKAGE_TARNAME ""SU2""; | #define PACKAGE_VERSION ""4.1.0""; | #define PACKAGE_STRING ""SU2 4.1.0""; | #define PACKAGE_BUGREPORT ""su2code-dev@lists.stanford.edu""; | #define PACKAGE_URL ""https://github.com/su2code""; | #define PACKAGE ""SU2""; | #define VERSION ""4.1.0""; | /* end confdefs.h. */; | #include <ac_nonexistent.h>; configure:4707: checking for grep that handles long lines and -e; configure:4765: result: /bin/grep; configure:4770: checking for egrep; configure:4832: result: /bin/grep -E; configure:4837: checking for ANSI C header files; configure:4857: gcc -c -g -O2 conftest.c >&5; configure:4857: $? = 0; configure:4930: gcc -o conftest -g -O2 conftest.c >&5; configure:4930: $? = 0; configure:4930: ./conftest; configure:4930: $? = 0; configure:4941: result: yes; configure:4954: checking for sys/types.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for sys/stat.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for stdlib.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for string.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for memory.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for strings.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for inttypes.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:9618,config,configure,9618,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,3,['config'],['configure']
Modifiability,gure:4954: checking for memory.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for strings.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for inttypes.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for stdint.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for unistd.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4970: checking size of short int; configure:4975: gcc -o conftest -g -O2 conftest.c >&5; configure:4975: $? = 0; configure:4975: ./conftest; configure:4975: $? = 0; configure:4989: result: 2; configure:5003: checking size of int; configure:5008: gcc -o conftest -g -O2 conftest.c >&5; configure:5008: $? = 0; configure:5008: ./conftest; configure:5008: $? = 0; configure:5022: result: 4; configure:5036: checking size of unsigned int; configure:5041: gcc -o conftest -g -O2 conftest.c >&5; configure:5041: $? = 0; configure:5041: ./conftest; configure:5041: $? = 0; configure:5055: result: 4; configure:5069: checking size of long int; configure:5074: gcc -o conftest -g -O2 conftest.c >&5; configure:5074: $? = 0; configure:5074: ./conftest; configure:5074: $? = 0; configure:5088: result: 8; configure:5102: checking size of float; configure:5107: gcc -o conftest -g -O2 conftest.c >&5; configure:5107: $? = 0; configure:5107: ./conftest; configure:5107: $? = 0; configure:5121: result: 4; configure:5135: checking size of double; configure:5140: gcc -o conftest -g -O2 conftest.c >&5; configure:5140: $? = 0; configure:5140: ./conftest; configure:5140: $? = 0; configure:5154: result: 8; configure:5168: checking size of void *; configure:5173: gcc -o conftest -g -O2 conftest.c >&5; configure:5173:,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:11216,config,configure,11216,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,2,['config'],['configure']
Modifiability,"h>. // An example type to use instead of the container that stores solution data for all vertices.; struct SolutionContainer; {; std::array<double,3> velocity;; std::array<double,3> areaVector;; };. using ResultType = double;. // We want classes with this interface.; class VirtualInterface; {; public:; virtual ResultType Compute(const SolutionContainer&) const = 0;; };. // The Compute method is to be composed via an inheritance chain, to do this; // we allow each building block to inherit from any class. These classes should; // be function objects that have no member variables, all data used in the; // resulting Compute method will be on the stack.; template<typename Base>; class ComputeArea : Base; {; protected:; // Different template instantiations will be made for; // 2D/3D to allow perfect loop unrolling.; enum : int {nDim = Base::nDim};. // To share variables between building blocks we will pass; // down a struct which is also composed by inheritance; struct WorkVarsType : Base::WorkVarsType; {; double area; // add ""area"" to the variables of Base; };; ; // The final implementation of Compute will be a call down the chain.; // The final constructed WorkVarsType is not known at this stage,; // hence we also template the method.; template<typename WV>; void Compute(WV& wv, const SolutionContainer& sol) const; {; // Boilerplate, call base first. This is akin to the decorator design pattern; // without polymorphism. The working variables resemble Python's ""self"" which; // makes this solution reasonably idiomatic.; Base::Compute(wv, sol);. // Then do our specific job.; wv.area = 0.0;; for(int i=0; i<nDim; ++i); wv.area += pow(sol.areaVector[i],2);; wv.area = sqrt(wv.area);; }; };. // Same mechanics as above; template<typename Base>; class ComputeFlux : Base; {; protected:; enum : int {nDim = Base::nDim};. struct WorkVarsType : Base::WorkVarsType ; {; double flux; // ...add new member; };. template<typename WV>; void Compute(WV& wv, const SolutionContainer& sol) cons",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-622941617:3005,variab,variables,3005,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-622941617,3,"['inherit', 'variab']","['inheritance', 'variables']"
Modifiability,hTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/UpgradeLog.XML (47) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport.css (207) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport.xslt (232) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport_Minus.gif (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport_Plus.gif (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/module.mk (240) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/modulelocal-sample.mk (84) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtCaepInitItems.h (142) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtCaepInstanceData.h (135) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtCaepSupportData.h (83) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtPwpInitItems.h (68) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtPwpPluginInfo.h (75) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtPwpVersions.h (64) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/runtimeWrite.c (439) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/runtimeWrite_orig.txt (60) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcproj (511) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcproj.PWI.dgarlisch.user (121) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcxproj (307) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcxproj.filters (78) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcxproj.user (3) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/module.mk (239) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/modulelocal-sample.mk (84) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtCaepInitItems.h (98) ; - D MeshTools/PointwiseSU2plugin/src/plugi,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:16537,plugin,plugins,16537,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['plugin'],['plugins']
Modifiability,header_stdc=yes; ac_cv_header_stdint_h=yes; ac_cv_header_stdlib_h=yes; ac_cv_header_string_h=yes; ac_cv_header_strings_h=yes; ac_cv_header_sys_stat_h=yes; ac_cv_header_sys_types_h=yes; ac_cv_header_unistd_h=yes; ac_cv_host=x86_64-unknown-linux-gnu; ac_cv_objext=o; ac_cv_path_EGREP='/bin/grep -E'; ac_cv_path_GREP=/bin/grep; ac_cv_path_install='/usr/bin/install -c'; ac_cv_path_mkdir=/bin/mkdir; ac_cv_prog_AWK=gawk; ac_cv_prog_CPP='gcc -E'; ac_cv_prog_ac_ct_CC=gcc; ac_cv_prog_ac_ct_CXX=g++; ac_cv_prog_ac_ct_RANLIB=ranlib; ac_cv_prog_cc_c89=; ac_cv_prog_cc_g=yes; ac_cv_prog_cc_gcc_c_o=yes; ac_cv_prog_cxx_g=yes; ac_cv_prog_make_make_set=yes; ac_cv_sizeof_double=8; ac_cv_sizeof_float=4; ac_cv_sizeof_int=4; ac_cv_sizeof_long_int=8; ac_cv_sizeof_short_int=2; ac_cv_sizeof_unsigned_int=4; ac_cv_sizeof_void_p=8; ac_cv_target=x86_64-unknown-linux-gnu; am_cv_CC_dependencies_compiler_type=gcc3; am_cv_CXX_dependencies_compiler_type=gcc3; am_cv_make_support_nested_variables=yes. ## ----------------- ##; ## Output variables. ##; ## ----------------- ##. ACLOCAL='${SHELL} /home/antodech/SU2-4.1.0/missing --run aclocal-1.12'; AMDEPBACKSLASH='\'; AMDEP_FALSE='#'; AMDEP_TRUE=''; AMTAR='$${TAR-tar}'; AM_BACKSLASH='\'; AM_DEFAULT_V='$(AM_DEFAULT_VERBOSITY)'; AM_DEFAULT_VERBOSITY='0'; AM_V='$(V)'; AUTOCONF='${SHELL} /home/antodech/SU2-4.1.0/missing --run autoconf'; AUTOHEADER='${SHELL} /home/antodech/SU2-4.1.0/missing --run autoheader'; AUTOMAKE='${SHELL} /home/antodech/SU2-4.1.0/missing --run automake-1.12'; AWK='gawk'; BUILD_CFD_FALSE='#'; BUILD_CFD_TRUE=''; BUILD_CGNS_FALSE='#'; BUILD_CGNS_TRUE=''; BUILD_DEF_FALSE='#'; BUILD_DEF_TRUE=''; BUILD_DIRECTDIFF_FALSE=''; BUILD_DIRECTDIFF_TRUE='#'; BUILD_DOT_FALSE='#'; BUILD_DOT_TRUE=''; BUILD_GEO_FALSE='#'; BUILD_GEO_TRUE=''; BUILD_HDF5_FALSE=''; BUILD_HDF5_TRUE='#'; BUILD_JSONCPP_FALSE=''; BUILD_JSONCPP_TRUE='#'; BUILD_LAPACK_FALSE=''; BUILD_LAPACK_TRUE='#'; BUILD_METIS_FALSE=''; BUILD_METIS_TRUE='#'; BUILD_MSH_FALSE='#'; BUILD_MSH_TRUE=''; B,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:21525,variab,variables,21525,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,1,['variab'],['variables']
Modifiability,"hort array of matrices, the result of that is code like the above that explicitly manipulates the lanes of our SIMD type, such code can be completely hidden inside CSysMatrix which is good because a 4x4 vectorized transpose and matrix update looks like this; ```c++; // block j, subs from jj and goes to ij; T0 = blk_j[ k ].unpackLo(blk_j[k+1]); T1 = blk_j[ k ].unpackHi(blk_j[k+1]);; T2 = blk_j[k+2].unpackLo(blk_j[k+3]); T3 = blk_j[k+2].unpackHi(blk_j[k+3]);. C0 = T0.widePermuteLo(T2); C1 = T1.widePermuteLo(T3);; C2 = T0.widePermuteHi(T2); C3 = T1.widePermuteHi(T3);. (Array4d(&bjj[0][k])-C0).store(&bjj[0][k]);; (Array4d(&bjj[1][k])-C1).store(&bjj[1][k]);; (Array4d(&bjj[2][k])-C2).store(&bjj[2][k]);; (Array4d(&bjj[3][k])-C3).store(&bjj[3][k]);. C0.store(&bij[0][k]); C1.store(&bij[1][k]);; C2.store(&bij[2][k]); C3.store(&bij[3][k]);; ```; I am showing this because it represents a readability worst case in terms of manipulating SIMD types, we might end up with one or two of these to get the best performance possible but they will always be encapsulated and deep in kernel-type areas of SU2 that are almost never touched. ## Conclusions; - Over 45% faster CSysMatrix updates by mapping off-diagonal blocks to edges and diagonal blocks to points.; - Colouring is the best strategy for hybrid parallelism of compute-heavy edge loops and matrix updates as it interleaves compute and memory operations.; - AoS storage should be kept to avoid significant loss of performance in compute-light edge loops due to poor locality of SoA storage.; - Major implication of AoS is on point loops where some data needs to be fetched (transposed) into local variables for effective vectorization.; - An intermediate storage scheme, AoSoA, can provide both good locality and vectorization of point loops, however it requires that data be accessed via special iterators and scalar code based on it would have poor performance. Next I will try to estimate how much we can gain for a ""realistic"" numerics class.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-535977206:17193,variab,variables,17193,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206,1,['variab'],['variables']
Modifiability,https://github.com/su2code/SU2 into develop; - Updated binaries; - Small change to configure.ac. Bootstrap.; - Small change; - Cleaning the code; - Updated grid deformation subroutine; - Fixing the mesh deformation; - Updated SU2_MSH; - Bug fixing; - Initial implementation of parallel CGNS reader. Works on 1 rank.; - Merged in recent changes to geometry_structure.cpp.; - Periodic BC working in serial; - Update option_structure.hpp; - Merge pull request #154 from su2code/fixCOptionEnumList; - Bug fixing (periodic bc); - Merge branch 'develop' of https://github.com/su2code/SU2 into develop; - Another important updated to BC in parallel; - More implementation and clean up of the parallel CGNS reader.; - Merge branch 'develop' of https://github.com/su2code/SU2 into develop; - CGNS reader bug fix.; - Updated adj. NS solver with primitive variables and farfield bc including viscous contribution.; - Merge branch 'develop' of https://github.com/su2code/SU2 into develop; - Small change; - Back to the previous version; - Fixed some loop variables.; - Merge branch 'develop' of https://github.com/su2code/SU2 into develop; - Bug fixes for CGNS.; - New slope limiter based on the wall distance; - Merge branch 'develop' of https://github.com/su2code/SU2 into develop; - Bug fixing; - Non-dimensional adjoint bc; - CGNS bug.; - Mixed-element support in new CGNS reader.; - Memory fix for mixed-element CGNS in parallel.; - Activated the parallel CGNS reader.; - New FFD input; - Adjacency building for Parmetis improve to account for VTK structure; - added if viscous steps to some adjeuler bcs; - Minor changes; - Back to previous version of ParMetis; - Small change; - Final update.; - Minor bug fixed.; - Updated SU2_DEF (cgns); - CGNS global element ID bug fix.; - Heat flux bug fix.; - Small fix.; - Merge branch 'master' into develop; - changed history output to match # of residuals printed in header and body; - further correction to history output; - history file fix; - fixed history out,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:7019,variab,variables,7019,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['variab'],['variables']
Modifiability,"hub.com/su2code""; | #define PACKAGE ""SU2""; | #define VERSION ""4.1.0""; | #define STDC_HEADERS 1; | #define HAVE_SYS_TYPES_H 1; | #define HAVE_SYS_STAT_H 1; | #define HAVE_STDLIB_H 1; | #define HAVE_STRING_H 1; | #define HAVE_MEMORY_H 1; | #define HAVE_STRINGS_H 1; | #define HAVE_INTTYPES_H 1; | #define HAVE_STDINT_H 1; | #define HAVE_UNISTD_H 1; | #define SIZEOF_SHORT_INT 2; | #define SIZEOF_INT 4; | #define SIZEOF_UNSIGNED_INT 4; | #define SIZEOF_LONG_INT 8; | #define SIZEOF_FLOAT 4; | #define SIZEOF_DOUBLE 8; | #define SIZEOF_VOID_P 8; | /* end confdefs.h. */; | #include <X11/Intrinsic.h>; configure:5409: result: no; configure:5409: checking for X11/Intrinsic.h; configure:5409: result: no; configure:5721: checking for /gshare/soft/code_saturne/4.0.0/prod/cgnslib_3.2.1/lib/libcgns.a; configure:5735: result: yes; configure:5755: checking for /gshare/soft/code_saturne/4.0.0/prod/cgnslib_3.2.1/include/cgnslib.h; configure:5769: result: yes; configure:6815: checking that generated files are newer than configure; configure:6821: result: done; configure:6952: creating ./config.status. ## ---------------------- ##; ## Running config.status. ##; ## ---------------------- ##. This file was extended by SU2 config.status 4.1.0, which was; generated by GNU Autoconf 2.69. Invocation command line was. CONFIG_FILES = ; CONFIG_HEADERS = ; CONFIG_LINKS = ; CONFIG_COMMANDS = ; $ ./config.status . on master. config.status:875: creating externals/tecio/Makefile; config.status:875: creating externals/metis/Makefile; config.status:875: creating externals/parmetis/Makefile; config.status:875: creating Makefile; config.status:875: creating externals/Makefile; config.status:875: creating Common/lib/Makefile; config.status:875: creating SU2_CFD/obj/Makefile; config.status:875: creating SU2_DOT/obj/Makefile; config.status:875: creating SU2_MSH/obj/Makefile; config.status:875: creating SU2_DEF/obj/Makefile; config.status:875: creating SU2_SOL/obj/Makefile; config.status:875: creating SU2_GEO/o",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:15492,config,configure,15492,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,5,['config'],['configure']
Modifiability,"iVar); {; lim_i[iVar] = (lim_i[iVar]-phi(iPoint,iVar))/proj_i[iVar];; limiter(iPoint,iVar) = min(limiter(iPoint,iVar), lim_i[iVar]);. lim_j[iVar] = (lim_j[iVar]-phi(jPoint,iVar))/proj_j[iVar];; limiter(jPoint,iVar) = min(limiter(jPoint,iVar), lim_j[iVar]);; }; }. #pragma omp parallel for schedule(dynamic,TARGET_CHUNK_SIZE); for(size_t iPoint=0; iPoint<nPoint; ++iPoint); {; #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); {; double lim = limiter(iPoint,iVar);; limiter(iPoint,iVar) = lim*(lim+2)/(lim*lim+lim+2);; }; }; }; ```; Again to keep things short here is the parallel and SIMD point-loop version (like for gradients it is very similar to the scalar and sequential version).; ```C++; void computeLimiters(size_t nPoint,; size_t nVar,; size_t nDim,; const Adjacency<4>& adj,; const Matrix& coords,; const Matrix& phi,; const VectorOfMatrix& grad,; Matrix& limiter); {; const size_t SIMDLEN = 4;; using FltVec = Array<double,SIMDLEN>;. // working variables; FltVec phiMax[MAXNVAR], phiMin[MAXNVAR], prjMax[MAXNVAR], prjMin[MAXNVAR];. const double eps = numeric_limits<double>::epsilon();. #pragma omp parallel for schedule(dynamic,128) private(phiMax,phiMin,prjMax,prjMin); for(size_t iPoint=0; iPoint<nPoint; iPoint+=SIMDLEN); {; for(size_t iVar=0; iVar<nVar; ++iVar); {; phiMin[iVar] = phiMax[iVar] = phi.getVec(iPoint,iVar);; prjMax[iVar] = eps;; prjMin[iVar] = -eps;; }. for(size_t iNeigh=0; iNeigh<adj.nNeighbor(iPoint); ++iNeigh); {; auto jPoint = adj.jPoint_vec(iPoint,iNeigh);. FltVec d_ij[3] = {FltVec(0.0), FltVec(0.0), FltVec(0.0)};. for(size_t iDim=0; iDim<nDim; ++iDim); d_ij[iDim] = (coords.getVec(jPoint,iDim)-; coords.getVec(iPoint,iDim))*0.5;. for(size_t iVar=0; iVar<nVar; ++iVar); {; FltVec prj = 0.0;. for(size_t iDim=0; iDim<nDim; ++iDim); prj += d_ij[iDim]*grad.getVec(iPoint,iVar,iDim);. prjMax[iVar] = vmax(prjMax[iVar], prj);; prjMin[iVar] = vmin(prjMin[iVar], prj);. phiMax[iVar] = vmax(phiMax[iVar], phi.getVec(jPoint,iVar));; phiMin[iVar] = vmin(phiMin[iVa",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-530593912:7743,variab,variables,7743,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530593912,1,['variab'],['variables']
Modifiability,"ib_3.2.1/include/cgnslib.h; configure:5769: result: yes; configure:6815: checking that generated files are newer than configure; configure:6821: result: done; configure:6952: creating ./config.status. ## ---------------------- ##; ## Running config.status. ##; ## ---------------------- ##. This file was extended by SU2 config.status 4.1.0, which was; generated by GNU Autoconf 2.69. Invocation command line was. CONFIG_FILES = ; CONFIG_HEADERS = ; CONFIG_LINKS = ; CONFIG_COMMANDS = ; $ ./config.status . on master. config.status:875: creating externals/tecio/Makefile; config.status:875: creating externals/metis/Makefile; config.status:875: creating externals/parmetis/Makefile; config.status:875: creating Makefile; config.status:875: creating externals/Makefile; config.status:875: creating Common/lib/Makefile; config.status:875: creating SU2_CFD/obj/Makefile; config.status:875: creating SU2_DOT/obj/Makefile; config.status:875: creating SU2_MSH/obj/Makefile; config.status:875: creating SU2_DEF/obj/Makefile; config.status:875: creating SU2_SOL/obj/Makefile; config.status:875: creating SU2_GEO/obj/Makefile; config.status:875: creating SU2_PY/Makefile; config.status:1047: executing depfiles commands; configure:8181: result:. -------------------------------------------------------------------------; | ___ _ _ ___ |; | / __| | | |_ ) Release 4.1.0 'Cardinal' |; | \__ \ |_| |/ / |; | |___/\___//___| Suite |; | |; -------------------------------------------------------------------------; | SU2 Lead Dev.: Dr. Francisco Palacios, Francisco.D.Palacios@boeing.com|; | Dr. Thomas D. Economon, economon@stanford.edu |; -------------------------------------------------------------------------; | SU2 Developers: |; | - Prof. Juan J. Alonso's group at Stanford University. |; | - Prof. Piero Colonna's group at Delft University of Technology. |; | - Prof. Nicolas R. Gauger's group at Kaiserslautern U. of Technology. |; | - Prof. Alberto Guardone's group at Polytechnic University of Milan. |",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:16482,config,config,16482,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,1,['config'],['config']
Modifiability,"implified / optimized by adopting a dense matrix format, for example:; - This snipped from the viscous numerics refactoring`for (iDim = 0; iDim < nDim; iDim++) {; TauElem[iDim] = 0.0;; for (jDim = 0; jDim < nDim; jDim++); TauElem[iDim] += tau[iDim][jDim]*UnitNormal[jDim];; }` would simply become `TauElem=tau*UnitNormal`; - Cumbersome allocations like `tau_jacobian_i = new su2double* [nDim];; for (iDim = 0; iDim < nDim; iDim++) {; tau_jacobian_i[iDim] = new su2double [nVar];; }` become `Matrix tau_jacobian_i(nDim,nVar);` and the cleanup is dealt with by the destructor of the object automatically. Now to answer some questions.; @juanjosealonso @erangit LAPACK and BLAS are indeed the standard, so much so that most (all?) newer libraries will call their routines behind the scenes.; However they considerably simplify the user interface by encapsulating the aforementioned construction/destruction and by exposing natural ways of manipulating the matrices, e.g. access entire rows, columns, blocks, etc.; Another issue with using BLAS routines is that we then need to provide a portable version that can be differentiated with CoDi or to implement the exact differentiation (similar to what is done in the ""solve_b"" routines). @vdweide that is not an issue with Eigen because everything is templated and therefore compatible with any type or class that overloads the appropriate arithmetic operators.; I have used it for over 2 years and I can attest to its compatibility with AD tools (I've tried 3), and speed when linked with a BLAS library, their native implementations are also very good, peeking inside their code... you can tell they know what they are doing. P.S. I feel this post needs a disclaimer, I am not affiliated in any way to Eigen, my motivation is not to promote their work (but I obviously think they deserve it). I genuinely think adopting an algebra library (that is compatible with AD) would greatly simplify our work and further drop the entry barrier to new developers.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/643#issuecomment-459653772:2229,portab,portable,2229,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459653772,1,['portab'],['portable']
Modifiability,"in essence both are performing similar duties, but people should express their opinions. With that said, how about a boolean such as USE_WALL_FUNCTIONS / USE_WALL_MODEL (YES or NO) with an optional argument WALL_FUNCTION_TYPE / WALL_MODEL_TYPE that can taken one of many pre-specified values that can be added as these options are developed and tested? Certainly options like STANDARD_WALL_FUNCTION, ADAPTIVE_WALL_FUNCTION, SCALABLE_WALL_FUNCTION, compressible and incompressible versions, and even EQUILIBRIUM_WALL_MODEL and NONEQUILIBRIUM_WALL_MODEL are things that are likely to be in the code in the near future. Thoughts?. Juan. On Sep 5, 2017, at 2:27 PM, Thomas D. Economon <notifications@github.com<mailto:notifications@github.com>> wrote:. @petebachant<https://github.com/petebachant>: the paper that I linked earlier on this thread had some fairly simple examples similar to the one you propose.. different flat plates and so on with varying y^+. You can likely reuse the grid(s) in the TestCases repo. @vdweide<https://github.com/vdweide>: it was very simple in this first implementation. It checks for a single boolean for whether or not to apply wall functions (WALL_FUNCTIONS= YES or NO, https://github.com/su2code/SU2/blob/43b8a4015c4b09b01d78e4243d32011c663c2b70/SU2_CFD/src/solver_direct_mean.cpp#L15339), and then assumes they should be applied to all no-slip walls (heat flux or isothermal, https://github.com/su2code/SU2/blob/43b8a4015c4b09b01d78e4243d32011c663c2b70/SU2_CFD/src/solver_direct_mean.cpp#L16653). This could of course be made more specific for individual markers using a config structure like MARKER_MONITORING to list them, or by making a dedicated BC type for it potentially. —; You are receiving this because you commented.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/399#issuecomment-327308587>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADpSxJUhyEBSuSzHV1a7BZM_Frxbtb5sks5sfbzUgaJpZM4NvG6w>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/399#issuecomment-327313634:1950,config,config,1950,https://su2code.github.io,https://github.com/su2code/SU2/issues/399#issuecomment-327313634,1,['config'],['config']
Modifiability,in/src/plugins/shared/PWP/apiPWPUtils.c (789) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWPUtils.h (1030) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiUtils.h (174) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/pwpPlatform.c (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/pwpPlatform.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/site.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/structured.props (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/structured.vsprops (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/CaeTemplate.suo (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/CaeTemplate.vcproj (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/module.mk (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/modulelocal-sample.mk (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/rtCaepInitItems.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/rtCaepInstanceData.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/rtCaepSupportData.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/runtimeWrite.c (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/PWP/rtPwpInitItems.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/PWP/rtPwpPluginInfo.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/PWP/rtPwpVersions.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/unstructured.props (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/unstructured.vsprops (0) ; - D MeshTools/PointwiseSU2plugin_Instructions.txt (0) ; - I QuickStart/inv_NACA0012.cfg (0) ; - I README (0) ; - I SU2_CFD/include/SU2_CFD.hpp (0) ; - I SU2_CFD/include/definition_structure.hpp (0) ; - I SU2_CFD/include/fluid_model.hpp (0) ; - I SU2_CFD/include/fluid_model.inl (0) ; - I SU2_CFD/include/integration_structure.hpp (0) ; - I SU2_CFD/include/integration_structure.inl (0) ; - I SU,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:19960,plugin,plugins,19960,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['plugin'],['plugins']
Modifiability,"ing MAX_NUMBER_MARKER; - Working version with ParMETIS. Fixed bug in global index. Now clean up and testing...; - Cleaned version of ParMETIS routines with better console output during partitioning.; - Small bug in initial element division.; - Made arrays in ParMETIS call dynamic.; - Fixed compiler warnings and added MPI directives so that the pure serial code works with the ParMETIS routines.; - Bootstrap on zion.; - Added some typecasts. Still tracking down a memory problem...; - Critical bug fix for vtxdist array.; - Partial fix; - More MPI improvements.; - Fixing a bug in SU2_DEF; - Updated BC_ActDisk_Boundary (MPI); - Merge remote-tracking branch 'upstream/develop' into develop; - changing solidboundary setting to be heatflux OR euler etc instead of AND, also working on doxygen documentation; - Dynamic allocation for some marker-related arrays.; - visualize part taken out to match upstream/dev; - Collection of improvements; - Release 3.2.7; - Fixing LOW_MEMORY_OUTPUT; - Updated LOW_MEMORY_OUTPUT option; - Updated configure.ac; - After autoconf; - Updated MPI; - Updated BC_Engine_Exhaust and BC_Engine_Bleed; - Small change; - Fixing subsonic engine intake option; - Small output change; - Added output_su2.cpp; - Updated Engine BC; - Working on Engine BCs; - Added Supersonic Outlet BC; - Minor change; - Merge remote-tracking branch 'upstream/develop' into develop; - adjoints, solid boundary, doxygen in config; - continued fixing; - re-added adjoint bc mods; - re-adding avg outlet pressure (static pressure adjoint); - re-adding avg outlet pressure (static pressure adjoint); - Merge branch 'temp' of https://github.com/hlkline/SU2 into temp; - continued fixing; - average total pressure and fixes to avg outlet pressure; - adding stagnation pressure output to SU2_DOT; - Merge pull request #146 from hlkline/temp; - Updated Entropy fix (now it is active).; - Another change in BC_Engine_Exhaust; - Updated CGNS in parallel; - Added runtime file; - Small typo; - Adjustment o",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:2997,config,configure,2997,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['config'],['configure']
Modifiability,"ing for /gshare/soft/code_saturne/4.0.0/prod/cgnslib_3.2.1/include/cgnslib.h; configure:5769: result: yes; configure:6815: checking that generated files are newer than configure; configure:6821: result: done; configure:6952: creating ./config.status. ## ---------------------- ##; ## Running config.status. ##; ## ---------------------- ##. This file was extended by SU2 config.status 4.1.0, which was; generated by GNU Autoconf 2.69. Invocation command line was. CONFIG_FILES = ; CONFIG_HEADERS = ; CONFIG_LINKS = ; CONFIG_COMMANDS = ; $ ./config.status . on master. config.status:875: creating externals/tecio/Makefile; config.status:875: creating externals/metis/Makefile; config.status:875: creating externals/parmetis/Makefile; config.status:875: creating Makefile; config.status:875: creating externals/Makefile; config.status:875: creating Common/lib/Makefile; config.status:875: creating SU2_CFD/obj/Makefile; config.status:875: creating SU2_DOT/obj/Makefile; config.status:875: creating SU2_MSH/obj/Makefile; config.status:875: creating SU2_DEF/obj/Makefile; config.status:875: creating SU2_SOL/obj/Makefile; config.status:875: creating SU2_GEO/obj/Makefile; config.status:875: creating SU2_PY/Makefile; config.status:1047: executing depfiles commands; configure:8181: result:. -------------------------------------------------------------------------; | ___ _ _ ___ |; | / __| | | |_ ) Release 4.1.0 'Cardinal' |; | \__ \ |_| |/ / |; | |___/\___//___| Suite |; | |; -------------------------------------------------------------------------; | SU2 Lead Dev.: Dr. Francisco Palacios, Francisco.D.Palacios@boeing.com|; | Dr. Thomas D. Economon, economon@stanford.edu |; -------------------------------------------------------------------------; | SU2 Developers: |; | - Prof. Juan J. Alonso's group at Stanford University. |; | - Prof. Piero Colonna's group at Delft University of Technology. |; | - Prof. Nicolas R. Gauger's group at Kaiserslautern U. of Technology. |; | - Prof. Alberto Guar",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:16432,config,config,16432,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,1,['config'],['config']
Modifiability,"ing for C++ compiler default output file name; configure:3442: result: a.out; configure:3448: checking for suffix of executables; configure:3455: g++ -o conftest conftest.cpp >&5; configure:3459: $? = 0; configure:3481: result: ; configure:3503: checking whether we are cross compiling; configure:3511: g++ -o conftest conftest.cpp >&5; configure:3515: $? = 0; configure:3522: ./conftest; configure:3526: $? = 0; configure:3541: result: no; configure:3546: checking for suffix of object files; configure:3568: g++ -c conftest.cpp >&5; configure:3572: $? = 0; configure:3593: result: o; configure:3597: checking whether we are using the GNU C++ compiler; configure:3616: g++ -c conftest.cpp >&5; configure:3616: $? = 0; configure:3625: result: yes; configure:3634: checking whether g++ accepts -g; configure:3654: g++ -c -g conftest.cpp >&5; configure:3654: $? = 0; configure:3695: result: yes; configure:3720: checking dependency style of g++; configure:3831: result: gcc3; configure:3921: checking for gcc; configure:3937: found /usr/bin/gcc; configure:3948: result: gcc; configure:3979: checking for C compiler version; configure:3988: gcc --version >&5; gcc (GCC) 4.4.6 20120305 (Red Hat 4.4.6-4); Copyright (C) 2010 Free Software Foundation, Inc.; This is free software; see the source for copying conditions. There is NO; warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. configure:3999: $? = 0; configure:3988: gcc -v >&5; Using built-in specs.; Target: x86_64-redhat-linux; Configured with: ../configure --prefix=/usr --mandir=/usr/share/man --infodir=/usr/share/info --with-bugurl=http://bugzilla.redhat.com/bugzilla --enable-bootstrap --enable-shared --enable-threads=posix --enable-checking=release --with-system-zlib --enable-__cxa_atexit --disable-libunwind-exceptions --enable-gnu-unique-object --enable-languages=c,c++,objc,obj-c++,java,fortran,ada --enable-java-awt=gtk --disable-dssi --with-java-home=/usr/lib/jvm/java-1.5.0-gcj-1.5.0.0/jre --enable-libgcj-mu",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:5130,config,configure,5130,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,9,['config'],['configure']
Modifiability,"ing for X11/Intrinsic.h; configure:5409: result: no; configure:5721: checking for /gshare/soft/code_saturne/4.0.0/prod/cgnslib_3.2.1/lib/libcgns.a; configure:5735: result: yes; configure:5755: checking for /gshare/soft/code_saturne/4.0.0/prod/cgnslib_3.2.1/include/cgnslib.h; configure:5769: result: yes; configure:6815: checking that generated files are newer than configure; configure:6821: result: done; configure:6952: creating ./config.status. ## ---------------------- ##; ## Running config.status. ##; ## ---------------------- ##. This file was extended by SU2 config.status 4.1.0, which was; generated by GNU Autoconf 2.69. Invocation command line was. CONFIG_FILES = ; CONFIG_HEADERS = ; CONFIG_LINKS = ; CONFIG_COMMANDS = ; $ ./config.status . on master. config.status:875: creating externals/tecio/Makefile; config.status:875: creating externals/metis/Makefile; config.status:875: creating externals/parmetis/Makefile; config.status:875: creating Makefile; config.status:875: creating externals/Makefile; config.status:875: creating Common/lib/Makefile; config.status:875: creating SU2_CFD/obj/Makefile; config.status:875: creating SU2_DOT/obj/Makefile; config.status:875: creating SU2_MSH/obj/Makefile; config.status:875: creating SU2_DEF/obj/Makefile; config.status:875: creating SU2_SOL/obj/Makefile; config.status:875: creating SU2_GEO/obj/Makefile; config.status:875: creating SU2_PY/Makefile; config.status:1047: executing depfiles commands; configure:8181: result:. -------------------------------------------------------------------------; | ___ _ _ ___ |; | / __| | | |_ ) Release 4.1.0 'Cardinal' |; | \__ \ |_| |/ / |; | |___/\___//___| Suite |; | |; -------------------------------------------------------------------------; | SU2 Lead Dev.: Dr. Francisco Palacios, Francisco.D.Palacios@boeing.com|; | Dr. Thomas D. Economon, economon@stanford.edu |; -------------------------------------------------------------------------; | SU2 Developers: |; | - Prof. Juan J. Alonso's gr",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:16233,config,config,16233,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,1,['config'],['config']
Modifiability,"ing the installation (the exact same steps that @chesiv presented), I encountered a problem when running the mesh_adaptation_amg.py script. The command used was:. ```; python3 $SU2_RUN/mesh_adaptation_amg.py -f adapt_Mesh.cfg -n 4; ```; The script initiates the mesh adaptation process as expected, with the following output:. ```; SU2-AMG Anisotropic Mesh Adaptation. Mesh adaptation options:; PYADAP_COMPLEXITY : (30000, 60000, 120000); PYADAP_SUBITE : (2, 2, 2); PYADAP_SENSOR : GOAL; PYADAP_HMAX : 500.0; PYADAP_HMIN : 1e-9; PYADAP_HGRAD : 1.8. ./adap exists. Removing old mesh adaptation in 10s.; The ./adap folder was deleted. Generating GMF background surface mesh.; Initial CFD solution is provided.; ```; However, no _adap\ite0_ folder gets created. ; The log.err file in the _adap/ini_ directory provides this traceback:. ```; Traceback (most recent call last):; File "".../mesh_adaptation_amg.py"", line 111, in <module>; ...; RuntimeError: ...; Error in TokenizeString(): two or more options before an ""="" sign in the configuration file.; terminate called after throwing an instance of 'int'; ...; *** Process received signal ***; Signal: Aborted (6); Signal code: (-6); ...; ```. The critical part of this error seems to be the Error in TokenizeString() message, suggesting an issue with parsing the configuration file. This error typically indicates a syntax problem, such as having multiple options on a single line without proper separation by an equal sign (=). However, upon reviewing _adap/ini/config_CFD.cfg_, was unable to find any lines that clearly violated this syntax rule. Could this error be indicative of a more subtle issue within the configuration file, or might it be related to specific aspects of the feature_adap branch? Any insights, suggestions, or guidance on how to troubleshoot this error would be greatly appreciated. If anyone has a working adapt_mesh.cfg file for a similar setup or for the feature_adap branch, I would be very interested in seeing it. Underst",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/948#issuecomment-1847333809:1237,config,configuration,1237,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-1847333809,1,['config'],['configuration']
Modifiability,"ing them, multiple threads cannot write to the same location (i.e. the internal structures of CNumerics) therefore one per thread is required. > ...Also, I think I missed the point where the numerics container is extended beyond MAX_TERMS. The allocation of space for one numerics per thread is done above in line 1995 of my 21 Dec 2019 comment: `...MAX_TERMS*omp_get_max_threads()...`.; The instantiation of one numerics per thread is then done by executing the rest of the preprocessing in parallel and instead of using `XYZ_TERM` using `XYZ_TERM+offset` where `offset = thread_id * MAX_TERMS`.; I think someone mentioned this (maybe Tim) that we could revisit the ownership relations of the numerics classes, i.e. allocate them as members of their respective solvers, which if we do, we can think of having a purpose built container that automates the per-thread creation and access. > Why are they redefined each time inside the loop?; > Is this for efficiency reasons?. Referring to variables being declared inside loops. One stylist reason is that declaring everything at the top of a function is the C way of doing things, the C++ people whose books/blogs I've read and talks I've watched, recommend keeping namespaces (the inside of the loop being one) as clean as possible.; The only reason not to do this is if you explicitly want re-use, in the case of trivial types this does not improve efficiency, and in the context of OpenMP code it can create issues. Just like we need one numerics per thread, if we declare variables outside a parallel loop the default OpenMP behaviour is to consider them shared, and concurrent writes to shared locations = gdb and many bad words xD.; **EDIT:** I should mention here that if the parallel region is started before the variable declarations they become local and all is well, with the exception of class members, those will be shared most of the time (this is where const correctness can give some peace of mind). > Also, just an additional (hopeful",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/843#issuecomment-577684728:2333,variab,variables,2333,https://su2code.github.io,https://github.com/su2code/SU2/pull/843#issuecomment-577684728,1,['variab'],['variables']
Modifiability,ins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport_Minus.gif (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport_Plus.gif (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/module.mk (240) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/modulelocal-sample.mk (84) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtCaepInitItems.h (142) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtCaepInstanceData.h (135) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtCaepSupportData.h (83) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtPwpInitItems.h (68) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtPwpPluginInfo.h (75) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtPwpVersions.h (64) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/runtimeWrite.c (439) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/runtimeWrite_orig.txt (60) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcproj (511) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcproj.PWI.dgarlisch.user (121) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcxproj (307) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcxproj.filters (78) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcxproj.user (3) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/module.mk (239) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/modulelocal-sample.mk (84) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtCaepInitItems.h (98) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtCaepInstanceData.h (135) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtCaepSupportData.h (89) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtPwpInitItems.h (68) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtPwpPluginInfo.h (75) ; - D MeshTools/PointwiseSU2plugin/,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:16857,plugin,plugins,16857,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['plugin'],['plugins']
Modifiability,intwiseSU2plugin/FLAGS.macosx (112) ; - D MeshTools/PointwiseSU2plugin/FLAGS.win (14) ; - D MeshTools/PointwiseSU2plugin/FLAGS.win32 (33) ; - D MeshTools/PointwiseSU2plugin/Makefile (304) ; - D MeshTools/PointwiseSU2plugin/PluginSDK.sln (64) ; - D MeshTools/PointwiseSU2plugin/PluginSDK.suo (0) ; - D MeshTools/PointwiseSU2plugin/depend.sh (28) ; - D MeshTools/PointwiseSU2plugin/mkplugin (10) ; - D MeshTools/PointwiseSU2plugin/mkplugin.bat (82) ; - D MeshTools/PointwiseSU2plugin/mkplugin.tcl (422) ; - D MeshTools/PointwiseSU2plugin/src/Pointwise/Win32Target.props (28) ; - D MeshTools/PointwiseSU2plugin/src/Pointwise/Win32Target.vsprops (24) ; - D MeshTools/PointwiseSU2plugin/src/Pointwise/Win64Target.props (28) ; - D MeshTools/PointwiseSU2plugin/src/Pointwise/Win64Target.vsprops (24) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/CaeStrXML.vcproj (511) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/CaeStrXML.vcproj.PWI.dgarlisch.user (121) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/CaeStrXML.vcxproj (307) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/CaeStrXML.vcxproj.filters (78) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/CaeStrXML.vcxproj.user (3) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/module.mk (239) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/modulelocal-sample.mk (84) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtCaepInitItems.h (98) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtCaepInstanceData.h (135) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtCaepSupportData.h (89) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtPwpInitItems.h (68) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtPwpPluginInfo.h (75) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtPwpVersions.h (62) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/runtimeWrite.c (443) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:14031,plugin,plugins,14031,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['plugin'],['plugins']
Modifiability,intwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcxproj (307) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcxproj.filters (78) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcxproj.user (3) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/UpgradeLog.XML (47) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport.css (207) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport.xslt (232) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport_Minus.gif (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport_Plus.gif (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/module.mk (240) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/modulelocal-sample.mk (84) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtCaepInitItems.h (142) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtCaepInstanceData.h (135) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtCaepSupportData.h (83) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtPwpInitItems.h (68) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtPwpPluginInfo.h (75) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtPwpVersions.h (64) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/runtimeWrite.c (439) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/runtimeWrite_orig.txt (60) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcproj (511) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcproj.PWI.dgarlisch.user (121) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcxproj (307) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcxproj.filters (78) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcxproj.user (3) ; - D MeshTools/PointwiseSU2plugin/sr,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:16292,plugin,plugins,16292,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['plugin'],['plugins']
Modifiability,"ion, the polymorphic overhead will be reduced to a single call (ComputeResidual), all auxiliary functions (like the ones that live in CNumerics) will be forcefully inlined, no useless copies of data (no more numerics->SetBlaBla).; - Compile time nDim/nVar, which will: a) avoid heap allocations; b) allow effective loop-unrolling (also during the writes to CSysMatrix).; - Allow low-overhead composition, e.g. have one CRoe for Euler and one CRoeVisc for NS to fuse convective and viscous residuals (without copy pasting code).; - A lot more readable, those cryptic V_i[iDim+1] need to go (somehow...). To achieve all this, the ""CNewNumerics"" will work as a template (obvs) decorator/visitor.; A visitor in the sense that the solver calls the numerics and gives it (read-only) access to all its data, the object pulls whatever it needs directly and there is no need for numerics->SetBlaBla.; A template decorator in the sense that the class can be augmented simply by inheriting from another, along the lines of `class CRoeVisc : public CRoe, public CVisc` (to allow fusing residual and Jacobian contributions).; All this needs to be done with templates for the ""minimal indirection"" requirement. Which means for each numerical method we will have 4 explicit template instantiations (Euler2D, Euler3D, (RA)NS2D, (RA)NS3D) but in the end these are still polymorphic objects that will be instantiated by some factory function (i.e. it will look clean, especially because I will not port all methods in one go xD). The template machinery to support this is actually not too crazy:; ```c++; #include <array>; #include <cmath>. // An example type to use instead of the container that stores solution data for all vertices.; struct SolutionContainer; {; std::array<double,3> velocity;; std::array<double,3> areaVector;; };. using ResultType = double;. // We want classes with this interface.; class VirtualInterface; {; public:; virtual ResultType Compute(const SolutionContainer&) const = 0;; };. // The Co",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-622941617:1486,inherit,inheriting,1486,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-622941617,1,['inherit'],['inheriting']
Modifiability,"ions --enable-gnu-unique-object --enable-languages=c,c++,objc,obj-c++,java,fortran,ada --enable-java-awt=gtk --disable-dssi --with-java-home=/usr/lib/jvm/java-1.5.0-gcj-1.5.0.0/jre --enable-libgcj-multifile --enable-java-maintainer-mode --with-ecj-jar=/usr/share/java/eclipse-ecj.jar --disable-libjava-multilib --with-ppl --with-cloog --with-tune=generic --with-arch_32=i686 --build=x86_64-redhat-linux; Thread model: posix; gcc version 4.4.6 20120305 (Red Hat 4.4.6-4) (GCC) ; configure:3343: $? = 0; configure:3332: g++ -V >&5; g++: '-V' option must have argument; configure:3343: $? = 1; configure:3332: g++ -qversion >&5; g++: unrecognized option '-qversion'; g++: no input files; configure:3343: $? = 1; configure:3363: checking whether the C++ compiler works; configure:3385: g++ conftest.cpp >&5; configure:3389: $? = 0; configure:3437: result: yes; configure:3440: checking for C++ compiler default output file name; configure:3442: result: a.out; configure:3448: checking for suffix of executables; configure:3455: g++ -o conftest conftest.cpp >&5; configure:3459: $? = 0; configure:3481: result: ; configure:3503: checking whether we are cross compiling; configure:3511: g++ -o conftest conftest.cpp >&5; configure:3515: $? = 0; configure:3522: ./conftest; configure:3526: $? = 0; configure:3541: result: no; configure:3546: checking for suffix of object files; configure:3568: g++ -c conftest.cpp >&5; configure:3572: $? = 0; configure:3593: result: o; configure:3597: checking whether we are using the GNU C++ compiler; configure:3616: g++ -c conftest.cpp >&5; configure:3616: $? = 0; configure:3625: result: yes; configure:3634: checking whether g++ accepts -g; configure:3654: g++ -c -g conftest.cpp >&5; configure:3654: $? = 0; configure:3695: result: yes; configure:3720: checking dependency style of g++; configure:3831: result: gcc3; configure:3921: checking for gcc; configure:3937: found /usr/bin/gcc; configure:3948: result: gcc; configure:3979: checking for C compiler version; ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:4367,config,configure,4367,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,2,['config'],['configure']
Modifiability,iseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcxproj.user (3) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/module.mk (239) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/modulelocal-sample.mk (84) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtCaepInitItems.h (98) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtCaepInstanceData.h (135) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtCaepSupportData.h (89) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtPwpInitItems.h (68) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtPwpPluginInfo.h (75) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtPwpVersions.h (62) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/runtimeWrite.c (347) ; - D MeshTools/PointwiseSU2plugin/src/plugins/README.txt (272) ; - D MeshTools/PointwiseSU2plugin/src/plugins/module.mk (309) ; - D MeshTools/PointwiseSU2plugin/src/plugins/modulelocal.mk (8) ; - D MeshTools/PointwiseSU2plugin/src/plugins/pluginRegistry.h (29) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEP.c (228) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEP.h (550) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEPUtils.c (290) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEPUtils.h (725) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/runtimeWrite.h (57) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWGM/apiGridModel.c (492) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWGM/apiGridModel.h (1808) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWP.c (132) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWP.h (707) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWPUtils.c (789) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWPUtils.h (1030) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiUtils.h (174) ; - D MeshTools/PointwiseSU2plu,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:18200,plugin,plugins,18200,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,2,['plugin'],"['pluginRegistry', 'plugins']"
Modifiability,"ith-java-home=/usr/lib/jvm/java-1.5.0-gcj-1.5.0.0/jre --enable-libgcj-multifile --enable-java-maintainer-mode --with-ecj-jar=/usr/share/java/eclipse-ecj.jar --disable-libjava-multilib --with-ppl --with-cloog --with-tune=generic --with-arch_32=i686 --build=x86_64-redhat-linux; Thread model: posix; gcc version 4.4.6 20120305 (Red Hat 4.4.6-4) (GCC) ; configure:3343: $? = 0; configure:3332: g++ -V >&5; g++: '-V' option must have argument; configure:3343: $? = 1; configure:3332: g++ -qversion >&5; g++: unrecognized option '-qversion'; g++: no input files; configure:3343: $? = 1; configure:3363: checking whether the C++ compiler works; configure:3385: g++ conftest.cpp >&5; configure:3389: $? = 0; configure:3437: result: yes; configure:3440: checking for C++ compiler default output file name; configure:3442: result: a.out; configure:3448: checking for suffix of executables; configure:3455: g++ -o conftest conftest.cpp >&5; configure:3459: $? = 0; configure:3481: result: ; configure:3503: checking whether we are cross compiling; configure:3511: g++ -o conftest conftest.cpp >&5; configure:3515: $? = 0; configure:3522: ./conftest; configure:3526: $? = 0; configure:3541: result: no; configure:3546: checking for suffix of object files; configure:3568: g++ -c conftest.cpp >&5; configure:3572: $? = 0; configure:3593: result: o; configure:3597: checking whether we are using the GNU C++ compiler; configure:3616: g++ -c conftest.cpp >&5; configure:3616: $? = 0; configure:3625: result: yes; configure:3634: checking whether g++ accepts -g; configure:3654: g++ -c -g conftest.cpp >&5; configure:3654: $? = 0; configure:3695: result: yes; configure:3720: checking dependency style of g++; configure:3831: result: gcc3; configure:3921: checking for gcc; configure:3937: found /usr/bin/gcc; configure:3948: result: gcc; configure:3979: checking for C compiler version; configure:3988: gcc --version >&5; gcc (GCC) 4.4.6 20120305 (Red Hat 4.4.6-4); Copyright (C) 2010 Free Software Foundation, Inc.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:4469,config,configure,4469,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,4,['config'],['configure']
Modifiability,"ive loop-unrolling (also during the writes to CSysMatrix).; - Allow low-overhead composition, e.g. have one CRoe for Euler and one CRoeVisc for NS to fuse convective and viscous residuals (without copy pasting code).; - A lot more readable, those cryptic V_i[iDim+1] need to go (somehow...). To achieve all this, the ""CNewNumerics"" will work as a template (obvs) decorator/visitor.; A visitor in the sense that the solver calls the numerics and gives it (read-only) access to all its data, the object pulls whatever it needs directly and there is no need for numerics->SetBlaBla.; A template decorator in the sense that the class can be augmented simply by inheriting from another, along the lines of `class CRoeVisc : public CRoe, public CVisc` (to allow fusing residual and Jacobian contributions).; All this needs to be done with templates for the ""minimal indirection"" requirement. Which means for each numerical method we will have 4 explicit template instantiations (Euler2D, Euler3D, (RA)NS2D, (RA)NS3D) but in the end these are still polymorphic objects that will be instantiated by some factory function (i.e. it will look clean, especially because I will not port all methods in one go xD). The template machinery to support this is actually not too crazy:; ```c++; #include <array>; #include <cmath>. // An example type to use instead of the container that stores solution data for all vertices.; struct SolutionContainer; {; std::array<double,3> velocity;; std::array<double,3> areaVector;; };. using ResultType = double;. // We want classes with this interface.; class VirtualInterface; {; public:; virtual ResultType Compute(const SolutionContainer&) const = 0;; };. // The Compute method is to be composed via an inheritance chain, to do this; // we allow each building block to inherit from any class. These classes should; // be function objects that have no member variables, all data used in the; // resulting Compute method will be on the stack.; template<typename Base>; class Com",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-622941617:1871,polymorphi,polymorphic,1871,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-622941617,1,['polymorphi'],['polymorphic']
Modifiability,"l Strategy; The strategy now is to start a parallel section in CSysSolve::Solve that covers building the preconditioner and solving the linear system.; Linear algebra routines called within this section have _worksharing_ constructs instead of _parallel_ ones, i.e. the work is distributed by however many threads arrive to that routine. This also makes the routines safe to call in serial.; The only ""dangerous"" things to do in parallel are to: manage memory for a shared object (multiple threads call `new` but there is only one shared pointer on which to call `delete`); writing to the same memory locations concurrently.; I tried to make the first issue debugable by asserting that the initialization routines of CSysMatrix and CSysVector are only called by the master thread.; For the second issue I made the associated classes as const-correct as possible, that should at least make someone think twice before changing a member variable of those classes. The risk is still there for input variables as an algorithm development aspect... For example `MatrixVectorProductTransposed` cannot be made thread-parallel as simply/naively as its normal counterpart. ### Communication Model; The MPI + Threads communication model is very simple, currently only the master thread calls MPI routines (including `Error`), this requires thread barriers before and after the communication to make sure the correct values are passed and _seen_ by all threads.; We can test other alternatives in the future but at the moment this does not seem to be a significant bottleneck.; _Worksharing_ constructs have implicit barriers at completion, for CSysVector routines I used `nowait` modifiers, it is safe to call those routines in sequence since the loop sizes, and static work scheduling specifications are identical.; However, routines that access a CSysVector in a different way, should have an explicit barrier before using the vector (or risk having undefined behaviour). You will see these barriers on entry ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/830#issuecomment-562646766:1471,variab,variables,1471,https://su2code.github.io,https://github.com/su2code/SU2/pull/830#issuecomment-562646766,1,['variab'],['variables']
Modifiability,"loog --with-tune=generic --with-arch_32=i686 --build=x86_64-redhat-linux; Thread model: posix; gcc version 4.4.6 20120305 (Red Hat 4.4.6-4) (GCC) ; configure:3343: $? = 0; configure:3332: g++ -V >&5; g++: '-V' option must have argument; configure:3343: $? = 1; configure:3332: g++ -qversion >&5; g++: unrecognized option '-qversion'; g++: no input files; configure:3343: $? = 1; configure:3363: checking whether the C++ compiler works; configure:3385: g++ conftest.cpp >&5; configure:3389: $? = 0; configure:3437: result: yes; configure:3440: checking for C++ compiler default output file name; configure:3442: result: a.out; configure:3448: checking for suffix of executables; configure:3455: g++ -o conftest conftest.cpp >&5; configure:3459: $? = 0; configure:3481: result: ; configure:3503: checking whether we are cross compiling; configure:3511: g++ -o conftest conftest.cpp >&5; configure:3515: $? = 0; configure:3522: ./conftest; configure:3526: $? = 0; configure:3541: result: no; configure:3546: checking for suffix of object files; configure:3568: g++ -c conftest.cpp >&5; configure:3572: $? = 0; configure:3593: result: o; configure:3597: checking whether we are using the GNU C++ compiler; configure:3616: g++ -c conftest.cpp >&5; configure:3616: $? = 0; configure:3625: result: yes; configure:3634: checking whether g++ accepts -g; configure:3654: g++ -c -g conftest.cpp >&5; configure:3654: $? = 0; configure:3695: result: yes; configure:3720: checking dependency style of g++; configure:3831: result: gcc3; configure:3921: checking for gcc; configure:3937: found /usr/bin/gcc; configure:3948: result: gcc; configure:3979: checking for C compiler version; configure:3988: gcc --version >&5; gcc (GCC) 4.4.6 20120305 (Red Hat 4.4.6-4); Copyright (C) 2010 Free Software Foundation, Inc.; This is free software; see the source for copying conditions. There is NO; warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. configure:3999: $? = 0; configure:3988: gcc -v >&",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:4678,config,configure,4678,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,4,['config'],['configure']
Modifiability,"look, I used a conservative number based on:; For the Roe scheme 4 matrices are generated (Jacobian i, Jacobian j, P tensor, P^-1 tensor), each coefficient of those matrices requires a reasonable number of floating point ops, and two of those matrices are indeed multiplied by each other.; So lets say 5 matrix-matrix multiplications are representative, this should be a conservative estimate as I am not considering the eventual fusion of convective and diffusive discretizations. **The vectorized code is 1.5 times faster.**; This is a fair 1.5 as the code is running on 4 fast cores (parallel via colouring for the reasons I explained previously) and 2 memory channels (scalar code can eventually saturate the memory bandwidth too, but it would take an unreasonable ratio of cores to channels to do so).; Furthermore the scalar code I am considering is writing to CSysMatrix with all the mapping and vectorized writes I mentioned before, before you get all compound interest and take this 1.5 with the 1.47 from CSysMatrix, the speedup relative to code without mapping and vector writes is 1.85.; I restate that this does not require changes to the data layout, again for reasons previously mentioned. ## SpMv - Sparse matrix-vector multiplication; With all these speedups the linear solvers will start taking well over 50% of the time, and so it is desirable to make some improvements there too.; Sadly SpMv is as bandwidth bound as it gets, 1 FMA per 8 bytes, nonetheless I implemented some number-of-variable-specific kernels (for nVar=4 and nVar=5) and I can get about **1.12** speedup (same realistic core to channel conditions). I am not going to dump that code here because it is not too nice to look at (it uses intrinsics) but again that would be something hidden away in CSysMatrix that most people would not need to look at, and there would be a safe generic fall-back for arbitrary number of variables. I think I will do the estimated global speedup together with the summary/proposal.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-539177957:3924,variab,variable-specific,3924,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-539177957,2,['variab'],"['variable-specific', 'variables']"
Modifiability,"ls a unique role. Unit testing increases time spent in development, but decreases the amount of time spent in bug-fixing and maintaining. For more information, see this relevant Stack Exchange question.<https://scicomp.stackexchange.com/questions/206/is-it-worthwhile-to-write-unit-tests-for-scientific-research-codes>. What do I propose?. My research group at UT Austing has implemented a unit testing framework on our branch, which we're happy with. Some choices were arbitrary, and some choices were made based on our development environment. Those choices may be different for other groups. Here's what we have done:. The unit testing framework is compiled and run using autotools. For more information on autotool's setup, see their documentation<https://www.gnu.org/software/automake/manual/html_node/Tests.html>. Since autotools is the build system for SU2, this involves minimal changes. Using automake, the build process for building unit tests becomes:. '''; ./bootstrap; ./configure; make; make check; '''. We use Boost's unit testing framework<https://www.boost.org/doc/libs/1_70_0/libs/test/doc/html/index.html>. This provides a convenient set of macros for instatiating tests, grouping tests into suites, and running checks. This choice was based on what is available in our development setup. We have integrated our unit tests into our Travis CI regression testing. Every time we push commits or submit a pull request, the unit tests are run and checked. What is my vision for unit testing in SU2?. I am not proposing that we start trying to get 100% code coverage with pre-existing code. That would not provide a good return on investment. Instead, I see people adding unit tests as they write new code and as they find bugs. For each new behavior added to SU2, tests are first added to document the related existing behavior. These tests serve to check that the existing behavior isn't damaged by the new code. Then new tests are added to prove that the new behavior is working corre",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499250240:3056,config,configure,3056,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240,1,['config'],['configure']
Modifiability,ls/PointwiseSU2plugin/src/Pointwise/Win64Target.props (28) ; - D MeshTools/PointwiseSU2plugin/src/Pointwise/Win64Target.vsprops (24) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/CaeStrXML.vcproj (511) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/CaeStrXML.vcproj.PWI.dgarlisch.user (121) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/CaeStrXML.vcxproj (307) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/CaeStrXML.vcxproj.filters (78) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/CaeStrXML.vcxproj.user (3) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/module.mk (239) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/modulelocal-sample.mk (84) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtCaepInitItems.h (98) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtCaepInstanceData.h (135) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtCaepSupportData.h (89) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtPwpInitItems.h (68) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtPwpPluginInfo.h (75) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtPwpVersions.h (62) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/runtimeWrite.c (443) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.sdf (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.sln (26) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.suo (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcproj (511) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcxproj (307) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcxproj.filters (78) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcxproj.user (3) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/UpgradeLog.XML (47) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/Upgr,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:14687,plugin,plugins,14687,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['plugin'],['plugins']
Modifiability,ls/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcxproj.user (3) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/UpgradeLog.XML (47) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport.css (207) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport.xslt (232) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport_Minus.gif (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport_Plus.gif (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/module.mk (240) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/modulelocal-sample.mk (84) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtCaepInitItems.h (142) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtCaepInstanceData.h (135) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtCaepSupportData.h (83) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtPwpInitItems.h (68) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtPwpPluginInfo.h (75) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtPwpVersions.h (64) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/runtimeWrite.c (439) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/runtimeWrite_orig.txt (60) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcproj (511) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcproj.PWI.dgarlisch.user (121) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcxproj (307) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcxproj.filters (78) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcxproj.user (3) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/module.mk (239) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/modulelocal-sample.mk (84) ; - D MeshTools/PointwiseSU2plugin/src/plugin,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:16458,plugin,plugins,16458,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['plugin'],['plugins']
Modifiability,lugin/FLAGS.linux (33) ; - D MeshTools/PointwiseSU2plugin/FLAGS.linux_x86_64 (33) ; - D MeshTools/PointwiseSU2plugin/FLAGS.macosx (112) ; - D MeshTools/PointwiseSU2plugin/FLAGS.win (14) ; - D MeshTools/PointwiseSU2plugin/FLAGS.win32 (33) ; - D MeshTools/PointwiseSU2plugin/Makefile (304) ; - D MeshTools/PointwiseSU2plugin/PluginSDK.sln (64) ; - D MeshTools/PointwiseSU2plugin/PluginSDK.suo (0) ; - D MeshTools/PointwiseSU2plugin/depend.sh (28) ; - D MeshTools/PointwiseSU2plugin/mkplugin (10) ; - D MeshTools/PointwiseSU2plugin/mkplugin.bat (82) ; - D MeshTools/PointwiseSU2plugin/mkplugin.tcl (422) ; - D MeshTools/PointwiseSU2plugin/src/Pointwise/Win32Target.props (28) ; - D MeshTools/PointwiseSU2plugin/src/Pointwise/Win32Target.vsprops (24) ; - D MeshTools/PointwiseSU2plugin/src/Pointwise/Win64Target.props (28) ; - D MeshTools/PointwiseSU2plugin/src/Pointwise/Win64Target.vsprops (24) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/CaeStrXML.vcproj (511) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/CaeStrXML.vcproj.PWI.dgarlisch.user (121) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/CaeStrXML.vcxproj (307) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/CaeStrXML.vcxproj.filters (78) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/CaeStrXML.vcxproj.user (3) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/module.mk (239) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/modulelocal-sample.mk (84) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtCaepInitItems.h (98) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtCaepInstanceData.h (135) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtCaepSupportData.h (89) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtPwpInitItems.h (68) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtPwpPluginInfo.h (75) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtPwpVersions.h (62) ; - D MeshTools/PointwiseSU2plugin/,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:13932,plugin,plugins,13932,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['plugin'],['plugins']
Modifiability,lugin/src/plugins/CaeUnsSU2/runtimeWrite.c (439) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/runtimeWrite_orig.txt (60) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcproj (511) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcproj.PWI.dgarlisch.user (121) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcxproj (307) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcxproj.filters (78) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcxproj.user (3) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/module.mk (239) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/modulelocal-sample.mk (84) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtCaepInitItems.h (98) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtCaepInstanceData.h (135) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtCaepSupportData.h (89) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtPwpInitItems.h (68) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtPwpPluginInfo.h (75) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtPwpVersions.h (62) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/runtimeWrite.c (347) ; - D MeshTools/PointwiseSU2plugin/src/plugins/README.txt (272) ; - D MeshTools/PointwiseSU2plugin/src/plugins/module.mk (309) ; - D MeshTools/PointwiseSU2plugin/src/plugins/modulelocal.mk (8) ; - D MeshTools/PointwiseSU2plugin/src/plugins/pluginRegistry.h (29) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEP.c (228) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEP.h (550) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEPUtils.c (290) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEPUtils.h (725) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/runtimeWrite.h (57) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWGM/apiGridM,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:17692,plugin,plugins,17692,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['plugin'],['plugins']
Modifiability,lugins/CaeStrXML/rtPwpVersions.h (62) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/runtimeWrite.c (443) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.sdf (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.sln (26) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.suo (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcproj (511) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcxproj (307) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcxproj.filters (78) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcxproj.user (3) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/UpgradeLog.XML (47) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport.css (207) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport.xslt (232) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport_Minus.gif (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport_Plus.gif (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/module.mk (240) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/modulelocal-sample.mk (84) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtCaepInitItems.h (142) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtCaepInstanceData.h (135) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtCaepSupportData.h (83) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtPwpInitItems.h (68) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtPwpPluginInfo.h (75) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtPwpVersions.h (64) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/runtimeWrite.c (439) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/runtimeWrite_orig.txt (60) ; - D MeshTools/PointwiseSU2pl,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:15843,plugin,plugins,15843,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['plugin'],['plugins']
Modifiability,n (14) ; - D MeshTools/PointwiseSU2plugin/FLAGS.win32 (33) ; - D MeshTools/PointwiseSU2plugin/Makefile (304) ; - D MeshTools/PointwiseSU2plugin/PluginSDK.sln (64) ; - D MeshTools/PointwiseSU2plugin/PluginSDK.suo (0) ; - D MeshTools/PointwiseSU2plugin/depend.sh (28) ; - D MeshTools/PointwiseSU2plugin/mkplugin (10) ; - D MeshTools/PointwiseSU2plugin/mkplugin.bat (82) ; - D MeshTools/PointwiseSU2plugin/mkplugin.tcl (422) ; - D MeshTools/PointwiseSU2plugin/src/Pointwise/Win32Target.props (28) ; - D MeshTools/PointwiseSU2plugin/src/Pointwise/Win32Target.vsprops (24) ; - D MeshTools/PointwiseSU2plugin/src/Pointwise/Win64Target.props (28) ; - D MeshTools/PointwiseSU2plugin/src/Pointwise/Win64Target.vsprops (24) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/CaeStrXML.vcproj (511) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/CaeStrXML.vcproj.PWI.dgarlisch.user (121) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/CaeStrXML.vcxproj (307) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/CaeStrXML.vcxproj.filters (78) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/CaeStrXML.vcxproj.user (3) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/module.mk (239) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/modulelocal-sample.mk (84) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtCaepInitItems.h (98) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtCaepInstanceData.h (135) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtCaepSupportData.h (89) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtPwpInitItems.h (68) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtPwpPluginInfo.h (75) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtPwpVersions.h (62) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/runtimeWrite.c (443) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.sdf (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUn,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:14112,plugin,plugins,14112,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['plugin'],['plugins']
Modifiability,"n on the library we choose, but he seems to be in favor of [PETSc](https://www.mcs.anl.gov/petsc/) from ANL, which has a 2-clause BSD license and is used by ADflow (formerly SUmb), among other solvers. Eduardo could probably provide more details.; > ; > Another one that's come up in our discussions is [HYPRE](https://computation.llnl.gov/projects/hypre-scalable-linear-solvers-multigrid-methods) from LLNL which has a GNU LGPL. >@juanjosealonso ; >(...) While PETSc is a wonderful library (and parallel), I would hesitate to use it as the solution for the problem that we are trying to solve: it is not the easiest thing to compile and it is most definitely not lightweight. If one also wanted to replace Krylov-space solvers and preconditioners in SU2 the PETSc might make more sense….but it still forces the developer to conform to their view of the world (including matrix setup and decomposition). (...). >@erangit; >I also support external libraries usage (no need to repeat the many advantages as it is well described above) but I think we should be very wary of portability issues. For instance in SUMB, PETSc was used for the Krylov solvers and more. While indeed it worked well and in parallel mode, each new implementation was a nightmare. LAPACK/BLAS package, on the other hand, provides a much easier implementation experience. Certainly, this is not the only consideration but it should be taken into account. Currently, resulting from the significant contributions of the members of this developers group, SU2 implementation works like a charm. I think we should strive to conserve this feature, especially if we aim at attracting more users and developers into the community. (...). >@vdweide; >(...) @bmunguia and @EduardoMolina, what type of application did you have in mind for PETSc? The only thing I can think of is a full Newton solver. And no matter how much I like PETSc, @juanjosealonso and @erangit have a point here. Looks like I start to belong to the group of old conser",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/648#issuecomment-460853218:1231,portab,portability,1231,https://su2code.github.io,https://github.com/su2code/SU2/issues/648#issuecomment-460853218,1,['portab'],['portability']
Modifiability,nftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for inttypes.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for stdint.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for unistd.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4970: checking size of short int; configure:4975: gcc -o conftest -g -O2 conftest.c >&5; configure:4975: $? = 0; configure:4975: ./conftest; configure:4975: $? = 0; configure:4989: result: 2; configure:5003: checking size of int; configure:5008: gcc -o conftest -g -O2 conftest.c >&5; configure:5008: $? = 0; configure:5008: ./conftest; configure:5008: $? = 0; configure:5022: result: 4; configure:5036: checking size of unsigned int; configure:5041: gcc -o conftest -g -O2 conftest.c >&5; configure:5041: $? = 0; configure:5041: ./conftest; configure:5041: $? = 0; configure:5055: result: 4; configure:5069: checking size of long int; configure:5074: gcc -o conftest -g -O2 conftest.c >&5; configure:5074: $? = 0; configure:5074: ./conftest; configure:5074: $? = 0; configure:5088: result: 8; configure:5102: checking size of float; configure:5107: gcc -o conftest -g -O2 conftest.c >&5; configure:5107: $? = 0; configure:5107: ./conftest; configure:5107: $? = 0; configure:5121: result: 4; configure:5135: checking size of double; configure:5140: gcc -o conftest -g -O2 conftest.c >&5; configure:5140: $? = 0; configure:5140: ./conftest; configure:5140: $? = 0; configure:5154: result: 8; configure:5168: checking size of void *; configure:5173: gcc -o conftest -g -O2 conftest.c >&5; configure:5173: $? = 0; configure:5173: ./conftest; configure:5173: $? = 0; configure:5187: result: 8; configure:5409: checking X11/Intrinsic.h usability; configure:5409: gcc -c -g -O2 conftest.c >&5; conftest.c:61:27: e,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:11421,config,configure,11421,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,2,['config'],['configure']
Modifiability,"nftest2.o >&5; configure:4417: $? = 0; configure:4423: cc -c conftest.c -o conftest2.o >&5; configure:4427: $? = 0; configure:4445: result: yes; configure:4513: checking for ranlib; configure:4529: found /usr/bin/ranlib; configure:4540: result: ranlib; configure:4574: checking how to run the C preprocessor; configure:4605: gcc -E conftest.c; configure:4605: $? = 0; configure:4619: gcc -E conftest.c; conftest.c:11:28: error: ac_nonexistent.h: No such file or directory; configure:4619: $? = 1; configure: failed program was:; | /* confdefs.h */; | #define PACKAGE_NAME ""SU2""; | #define PACKAGE_TARNAME ""SU2""; | #define PACKAGE_VERSION ""4.1.0""; | #define PACKAGE_STRING ""SU2 4.1.0""; | #define PACKAGE_BUGREPORT ""su2code-dev@lists.stanford.edu""; | #define PACKAGE_URL ""https://github.com/su2code""; | #define PACKAGE ""SU2""; | #define VERSION ""4.1.0""; | /* end confdefs.h. */; | #include <ac_nonexistent.h>; configure:4644: result: gcc -E; configure:4664: gcc -E conftest.c; configure:4664: $? = 0; configure:4678: gcc -E conftest.c; conftest.c:11:28: error: ac_nonexistent.h: No such file or directory; configure:4678: $? = 1; configure: failed program was:; | /* confdefs.h */; | #define PACKAGE_NAME ""SU2""; | #define PACKAGE_TARNAME ""SU2""; | #define PACKAGE_VERSION ""4.1.0""; | #define PACKAGE_STRING ""SU2 4.1.0""; | #define PACKAGE_BUGREPORT ""su2code-dev@lists.stanford.edu""; | #define PACKAGE_URL ""https://github.com/su2code""; | #define PACKAGE ""SU2""; | #define VERSION ""4.1.0""; | /* end confdefs.h. */; | #include <ac_nonexistent.h>; configure:4707: checking for grep that handles long lines and -e; configure:4765: result: /bin/grep; configure:4770: checking for egrep; configure:4832: result: /bin/grep -E; configure:4837: checking for ANSI C header files; configure:4857: gcc -c -g -O2 conftest.c >&5; configure:4857: $? = 0; configure:4930: gcc -o conftest -g -O2 conftest.c >&5; configure:4930: $? = 0; configure:4930: ./conftest; configure:4930: $? = 0; configure:4941: result: yes; configure",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:8653,config,configure,8653,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,2,['config'],['configure']
Modifiability,"ng type for those data structures is still `double`, only the `getVec` type methods need to convert on the fly to the SIMD type, for example:; ```C++; // use the ""pointer ctor"" to return an array starting at ""row0""; Array<double,4> Matrix<double>::getVec(size_t row0, size_t col) const {; return Array<double,4>(&data_[row0+col*rows_]);; }. // use the ""gather ctor"" to return an array with the indices in ""rows""; template<class U>; Array<double,4> Matrix<double>::getVec(const U& rows, size_t col) const {; return Array<double,4>(&data_[col*rows_], rows);; }; ```; After inlining those copies get optimized away.; Although the stored type, and ""scalar interface"" of the containers do not need to change, the storage order of the data does. Notice that in the above data is stored by columns instead of rows (something that @vdweide mentioned in #716) this has greater implications for gradients as instead of the familiar ""vector of matrices"" we would need a ""matrix of vectors"", i.e. the derivative of variable i w.r.t. coordinate j stored as a vector for all points. The `Adjacency` also needs to be stored in a funny way. For the scalar version of the code it was stored as a CSR sparse matrix (one array of indices into the arrays of data for each point, the rows).; For the vectorized version we want to load (small) arrays of jPoint's, arrays of iEdge's, and arrays of directions, and as we know either those are contiguous or we take a huge performance hit.; If all points had the same number of neighbors we could store the adjacency in LIL (list of lists) format, essentially a column-major matrix, but that is not true for hybrid meshes and so we would possibly waste a lot of memory.; The solution is to use a Block-CSR format (like in CSysMatrix) where the blocks are the vectors we want and instead of one row per point we have one row per SIMD group. But even within a SIMD-sized group points can have different number of neighbors...; The solution for that is padding, within each grou",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-530328194:10178,variab,variable,10178,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530328194,1,['variab'],['variable']
Modifiability,"nly in finite_differences.py.; >; > The step size is scaled with the reference length because from the; > practical point of view, I have found that the size of the aircraft, wing,; > airfoil, is important to determine a meaningful step size. e.g. should we; > use the same step for an aircraft with a MAC of ~150in than for an airfoil; > with a chord of 1in.; >; > Remember that most of the times we are using FD when the adjoint is not; > converging… so we have bad convergence of the direct problem (including; > some level of unsteadiness that we want to filter with the selection of the; > step size). In other words, with the right choice of the FD step size you; > can obtain, at least, an useful gradient… and that number is somehow linked; > to the size of the aircraft, wing, or airfoil.; >; > The best solution would be to add the step size to the; > finite_differences.py and also to the shape_optimization.py (creating a new; > option in the config file)… not a top priority, but I’ll do it soon; >; > Best,; > Francisco; >; >; > > On Mar 1, 2017, at 3:25 PM, Thomas D. Economon <notifications@github.com; > <mailto:notifications@github.com>> wrote:; > >; > > Bumping this issue. This has come up several times now for different; > people/projects. Is there a reason to keep it based on the reference moment; > length, or can we revert to specifying this through the command line; > options?; > >; > > —; > > You are receiving this because you were assigned.; > > Reply to this email directly, view it on GitHub <; > https://github.com/su2code/SU2/issues/367#issuecomment-283505108>, or; > mute the thread <https://github.com/notifications/unsubscribe-; > auth/AEpkllp8PXmLDDQLJNq-2yRLBoDAfXE-ks5rhf5pgaJpZM4Lq5F->.; > >; >; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub<https://github.com/; > su2code/SU2/issues/367#issuecomment-284288637>, or mute the thread<; > https://github.com/notifications/unsubscri",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/367#issuecomment-284314148:2381,config,config,2381,https://su2code.github.io,https://github.com/su2code/SU2/issues/367#issuecomment-284314148,1,['config'],['config']
Modifiability,ntation. Updated the build files.; - bootstrap; - Started parallel CGNS reader.; - Memory fix.; - Minor change; - Merge branch 'develop' of https://github.com/su2code/SU2 into develop; - Updated binaries; - Small change to configure.ac. Bootstrap.; - Small change; - Cleaning the code; - Updated grid deformation subroutine; - Fixing the mesh deformation; - Updated SU2_MSH; - Bug fixing; - Initial implementation of parallel CGNS reader. Works on 1 rank.; - Merged in recent changes to geometry_structure.cpp.; - Periodic BC working in serial; - Update option_structure.hpp; - Merge pull request #154 from su2code/fixCOptionEnumList; - Bug fixing (periodic bc); - Merge branch 'develop' of https://github.com/su2code/SU2 into develop; - Another important updated to BC in parallel; - More implementation and clean up of the parallel CGNS reader.; - Merge branch 'develop' of https://github.com/su2code/SU2 into develop; - CGNS reader bug fix.; - Updated adj. NS solver with primitive variables and farfield bc including viscous contribution.; - Merge branch 'develop' of https://github.com/su2code/SU2 into develop; - Small change; - Back to the previous version; - Fixed some loop variables.; - Merge branch 'develop' of https://github.com/su2code/SU2 into develop; - Bug fixes for CGNS.; - New slope limiter based on the wall distance; - Merge branch 'develop' of https://github.com/su2code/SU2 into develop; - Bug fixing; - Non-dimensional adjoint bc; - CGNS bug.; - Mixed-element support in new CGNS reader.; - Memory fix for mixed-element CGNS in parallel.; - Activated the parallel CGNS reader.; - New FFD input; - Adjacency building for Parmetis improve to account for VTK structure; - added if viscous steps to some adjeuler bcs; - Minor changes; - Back to previous version of ParMetis; - Small change; - Final update.; - Minor bug fixed.; - Updated SU2_DEF (cgns); - CGNS global element ID bug fix.; - Heat flux bug fix.; - Small fix.; - Merge branch 'master' into develop; - changed history,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:6821,variab,variables,6821,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['variab'],['variables']
Modifiability,ntwiseSU2plugin/src/plugins/CaeUnsSU2/rtCaepSupportData.h (83) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtPwpInitItems.h (68) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtPwpPluginInfo.h (75) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtPwpVersions.h (64) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/runtimeWrite.c (439) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/runtimeWrite_orig.txt (60) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcproj (511) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcproj.PWI.dgarlisch.user (121) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcxproj (307) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcxproj.filters (78) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcxproj.user (3) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/module.mk (239) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/modulelocal-sample.mk (84) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtCaepInitItems.h (98) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtCaepInstanceData.h (135) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtCaepSupportData.h (89) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtPwpInitItems.h (68) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtPwpPluginInfo.h (75) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtPwpVersions.h (62) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/runtimeWrite.c (347) ; - D MeshTools/PointwiseSU2plugin/src/plugins/README.txt (272) ; - D MeshTools/PointwiseSU2plugin/src/plugins/module.mk (309) ; - D MeshTools/PointwiseSU2plugin/src/plugins/modulelocal.mk (8) ; - D MeshTools/PointwiseSU2plugin/src/plugins/pluginRegistry.h (29) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEP.c (228) ; - D MeshTools/PointwiseSU2plugin/src/plugins/share,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:17362,plugin,plugins,17362,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['plugin'],['plugins']
Modifiability,ntwiseSU2plugin/src/plugins/shared/PWP/apiPWP.h (707) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWPUtils.c (789) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWPUtils.h (1030) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiUtils.h (174) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/pwpPlatform.c (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/pwpPlatform.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/site.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/structured.props (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/structured.vsprops (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/CaeTemplate.suo (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/CaeTemplate.vcproj (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/module.mk (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/modulelocal-sample.mk (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/rtCaepInitItems.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/rtCaepInstanceData.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/rtCaepSupportData.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/runtimeWrite.c (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/PWP/rtPwpInitItems.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/PWP/rtPwpPluginInfo.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/PWP/rtPwpVersions.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/unstructured.props (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/unstructured.vsprops (0) ; - D MeshTools/PointwiseSU2plugin_Instructions.txt (0) ; - I QuickStart/inv_NACA0012.cfg (0) ; - I README (0) ; - I SU2_CFD/include/SU2_CFD.hpp (0) ; - I SU2_CFD/include/definition_structure.hpp (0) ; - I SU2_CFD/include/fluid_model.hpp (0) ; - I SU2_CFD/include/fluid_model.inl (0) ; - I SU2_CFD/include/inte,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:19876,plugin,plugins,19876,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['plugin'],['plugins']
Modifiability,"o allow fusing residual and Jacobian contributions).; All this needs to be done with templates for the ""minimal indirection"" requirement. Which means for each numerical method we will have 4 explicit template instantiations (Euler2D, Euler3D, (RA)NS2D, (RA)NS3D) but in the end these are still polymorphic objects that will be instantiated by some factory function (i.e. it will look clean, especially because I will not port all methods in one go xD). The template machinery to support this is actually not too crazy:; ```c++; #include <array>; #include <cmath>. // An example type to use instead of the container that stores solution data for all vertices.; struct SolutionContainer; {; std::array<double,3> velocity;; std::array<double,3> areaVector;; };. using ResultType = double;. // We want classes with this interface.; class VirtualInterface; {; public:; virtual ResultType Compute(const SolutionContainer&) const = 0;; };. // The Compute method is to be composed via an inheritance chain, to do this; // we allow each building block to inherit from any class. These classes should; // be function objects that have no member variables, all data used in the; // resulting Compute method will be on the stack.; template<typename Base>; class ComputeArea : Base; {; protected:; // Different template instantiations will be made for; // 2D/3D to allow perfect loop unrolling.; enum : int {nDim = Base::nDim};. // To share variables between building blocks we will pass; // down a struct which is also composed by inheritance; struct WorkVarsType : Base::WorkVarsType; {; double area; // add ""area"" to the variables of Base; };; ; // The final implementation of Compute will be a call down the chain.; // The final constructed WorkVarsType is not known at this stage,; // hence we also template the method.; template<typename WV>; void Compute(WV& wv, const SolutionContainer& sol) const; {; // Boilerplate, call base first. This is akin to the decorator design pattern; // without polymorphism. ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-622941617:2557,inherit,inheritance,2557,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-622941617,2,['inherit'],"['inherit', 'inheritance']"
Modifiability,odulelocal-sample.mk (84) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtCaepInitItems.h (98) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtCaepInstanceData.h (135) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtCaepSupportData.h (89) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtPwpInitItems.h (68) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtPwpPluginInfo.h (75) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtPwpVersions.h (62) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/runtimeWrite.c (443) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.sdf (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.sln (26) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.suo (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcproj (511) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcxproj (307) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcxproj.filters (78) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcxproj.user (3) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/UpgradeLog.XML (47) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport.css (207) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport.xslt (232) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport_Minus.gif (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport_Plus.gif (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/module.mk (240) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/modulelocal-sample.mk (84) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtCaepInitItems.h (142) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtCaepInstanceData.h (135) ; - D MeshTools/PointwiseSU2plugin/src/p,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:15389,plugin,plugins,15389,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['plugin'],['plugins']
Modifiability,"ogramming may become an entrance barrier to new additions to the community. As I wrote in the preamble of #789:; ""But please participate even if you never heard of these topics, your opinion about readability and ""developability"" of the code is important! I think the code-style should be accessible to people starting a PhD (after they read a bit about C++...).""; I try to encapsulate and hide the tricky bits as much as possible to make the code as readable as possible, whether I am succeeding or not is for the community to decide, in all these PR's I've been pointing to the areas I think are trickier, if someone, anyone, feels they are absolutely incomprehensible please say something... either here, or trough slack, or by email (I think it shows in the commits) (I understand not everyone is keen on github exposure). > I'm aware that you have been doing very well at documenting the code and the various PRs, but I'd say we should try to find an strategy to ease the learning curve on potential new developers (maybe some developer tutorials? a collection of the comments/discussions on the PRs moved to the wiki? a list of links/useful resources?). I agree with documentation of broad design decisions, that is the intent of #789, and developer tutorials (how to implement a new X) once we are content with the restructurings, otherwise they will quickly go outdated... or actually...; We should probably first think about the answers to ""how to implement a new X"" and restructure/refactor as a function of that.; Based on previous efforts of maintaining wiki's updated while code is being developed, I much prefer this github style where you can clearly tell what version of the code the comments refer to. A collection of comments/discussions organized by topic and linked to a feature is somewhat what I had in mind when I opened a ""big PR"" (#824) with little branches such as this one, I can try to complete that with a list of links/useful resources, references as it were, good idea!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/843#issuecomment-577684728:5095,refactor,refactor,5095,https://su2code.github.io,https://github.com/su2code/SU2/pull/843#issuecomment-577684728,1,['refactor'],['refactor']
Modifiability,"oint,iVar));. for(size_t iDim=0; iDim<nDim; ++iDim); gradI[iVar][iDim] += a_ij[iDim]*flux;; }; }. for(size_t iVar=0; iVar<nVar; ++iVar); for(size_t iDim=0; iDim<nDim; ++iDim); for(size_t k=0; k<SIMDLEN; ++k); grad(iPoint+k,iVar,iDim) = gradI[iVar][iDim][k];; ...; ```; Similarly when computing the gradient we need to first fetch/transpose it to be able to vectorize subsequent computations; ```c++; FltVec gradI[MAXNVAR][MAXNDIM];. for(size_t iVar=0; iVar<nVar; ++iVar); for(size_t iDim=0; iDim<nDim; ++iDim); for(size_t k=0; k<SIMDLEN; ++k); gradI[iVar][iDim][k] = grad(iPoint+k,iVar,iDim);; ...; ```; Performance wise this is actually better than the SoA version (4% on gradients, 35% on limiters) as it also benefits from better locality, and it is only slightly (3%) worse than zig zag storage, especially when fusing limiters and gradients as the transposition of the gradient into storage is greatly amortised.; Regarding readability, the 3 nested loops can be moved to methods of the container, but we cannot get rid off the local variable (if we want vectorization that is). **We lose the ability to vectorize primitive variable updates efficiently with AoS** but currently that only accounts for 3% of the runtime and it is a memory bound operation therefore it would not gain much from vectorization anyway. On the subject of de-swizzling data remember I said the writes into CSysMatrix would be a bit weird, that is because each Jacobian contribution will be a ""matrix of short arrays"" that needs to be transformed into a short array of matrices, the result of that is code like the above that explicitly manipulates the lanes of our SIMD type, such code can be completely hidden inside CSysMatrix which is good because a 4x4 vectorized transpose and matrix update looks like this; ```c++; // block j, subs from jj and goes to ij; T0 = blk_j[ k ].unpackLo(blk_j[k+1]); T1 = blk_j[ k ].unpackHi(blk_j[k+1]);; T2 = blk_j[k+2].unpackLo(blk_j[k+3]); T3 = blk_j[k+2].unpackHi(blk_j[k+3]);. C0 ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-535977206:15046,variab,variable,15046,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206,1,['variab'],['variable']
Modifiability,ointwiseSU2plugin/src/plugins/modulelocal.mk (8) ; - D MeshTools/PointwiseSU2plugin/src/plugins/pluginRegistry.h (29) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEP.c (228) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEP.h (550) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEPUtils.c (290) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEPUtils.h (725) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/runtimeWrite.h (57) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWGM/apiGridModel.c (492) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWGM/apiGridModel.h (1808) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWP.c (132) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWP.h (707) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWPUtils.c (789) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWPUtils.h (1030) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiUtils.h (174) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/pwpPlatform.c (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/pwpPlatform.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/site.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/structured.props (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/structured.vsprops (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/CaeTemplate.suo (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/CaeTemplate.vcproj (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/module.mk (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/modulelocal-sample.mk (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/rtCaepInitItems.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/rtCaepInstanceData.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/rtCaepSupportData.h (0) ; - D MeshTools/Po,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:19122,plugin,plugins,19122,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['plugin'],['plugins']
Modifiability,ols/PointwiseSU2plugin/src/plugins/structured.vsprops (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/CaeTemplate.suo (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/CaeTemplate.vcproj (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/module.mk (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/modulelocal-sample.mk (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/rtCaepInitItems.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/rtCaepInstanceData.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/rtCaepSupportData.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/runtimeWrite.c (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/PWP/rtPwpInitItems.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/PWP/rtPwpPluginInfo.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/PWP/rtPwpVersions.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/unstructured.props (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/unstructured.vsprops (0) ; - D MeshTools/PointwiseSU2plugin_Instructions.txt (0) ; - I QuickStart/inv_NACA0012.cfg (0) ; - I README (0) ; - I SU2_CFD/include/SU2_CFD.hpp (0) ; - I SU2_CFD/include/definition_structure.hpp (0) ; - I SU2_CFD/include/fluid_model.hpp (0) ; - I SU2_CFD/include/fluid_model.inl (0) ; - I SU2_CFD/include/integration_structure.hpp (0) ; - I SU2_CFD/include/integration_structure.inl (0) ; - I SU2_CFD/include/iteration_structure.hpp (0) ; - I SU2_CFD/include/numerics_machine_learning.hpp (0) ; - I SU2_CFD/include/numerics_machine_learning.inl (0) ; - I SU2_CFD/include/numerics_machine_learning_turbulent.hpp (0) ; - I SU2_CFD/include/numerics_structure.hpp (0) ; - I SU2_CFD/include/numerics_structure.inl (0) ; - I SU2_CFD/include/output_structure.hpp (0) ; - I SU2_CFD/include/solver_structure.hpp (0) ; - I SU2_CFD/include/solver_structure.inl (0) ; - I SU2_CFD/include/transpor,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:20460,plugin,plugins,20460,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['plugin'],['plugins']
Modifiability,onfigure:4832: result: /bin/grep -E; configure:4837: checking for ANSI C header files; configure:4857: gcc -c -g -O2 conftest.c >&5; configure:4857: $? = 0; configure:4930: gcc -o conftest -g -O2 conftest.c >&5; configure:4930: $? = 0; configure:4930: ./conftest; configure:4930: $? = 0; configure:4941: result: yes; configure:4954: checking for sys/types.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for sys/stat.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for stdlib.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for string.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for memory.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for strings.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for inttypes.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for stdint.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for unistd.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4970: checking size of short int; configure:4975: gcc -o conftest -g -O2 conftest.c >&5; configure:4975: $? = 0; configure:4975: ./conftest; configure:4975: $? = 0; configure:4989: result: 2; configure:5003: checking size of int; configure:5008: gcc -o conftest -g -O2 conftest.c >&5; configure:5008: $? = 0; configure:5008: ./conftest; configure:5008: $? = 0; configure:5022: result: 4; configure:5036: checking size of uns,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:10313,config,configure,10313,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,3,['config'],['configure']
Modifiability,ools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport.css (207) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport.xslt (232) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport_Minus.gif (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport_Plus.gif (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/module.mk (240) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/modulelocal-sample.mk (84) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtCaepInitItems.h (142) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtCaepInstanceData.h (135) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtCaepSupportData.h (83) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtPwpInitItems.h (68) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtPwpPluginInfo.h (75) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtPwpVersions.h (64) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/runtimeWrite.c (439) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/runtimeWrite_orig.txt (60) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcproj (511) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcproj.PWI.dgarlisch.user (121) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcxproj (307) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcxproj.filters (78) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcxproj.user (3) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/module.mk (239) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/modulelocal-sample.mk (84) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtCaepInitItems.h (98) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtCaepInstanceData.h (135) ; - D MeshTools/PointwiseSU2plugin/src/,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:16617,plugin,plugins,16617,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['plugin'],['plugins']
Modifiability,ools/PointwiseSU2plugin/src/plugins/CaeUnsXML/modulelocal-sample.mk (84) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtCaepInitItems.h (98) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtCaepInstanceData.h (135) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtCaepSupportData.h (89) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtPwpInitItems.h (68) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtPwpPluginInfo.h (75) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtPwpVersions.h (62) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/runtimeWrite.c (347) ; - D MeshTools/PointwiseSU2plugin/src/plugins/README.txt (272) ; - D MeshTools/PointwiseSU2plugin/src/plugins/module.mk (309) ; - D MeshTools/PointwiseSU2plugin/src/plugins/modulelocal.mk (8) ; - D MeshTools/PointwiseSU2plugin/src/plugins/pluginRegistry.h (29) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEP.c (228) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEP.h (550) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEPUtils.c (290) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEPUtils.h (725) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/runtimeWrite.h (57) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWGM/apiGridModel.c (492) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWGM/apiGridModel.h (1808) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWP.c (132) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWP.h (707) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWPUtils.c (789) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWPUtils.h (1030) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiUtils.h (174) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/pwpPlatform.c (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/pwpPlatform.h (0) ; - D MeshTools/Pointwise,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:18344,plugin,plugins,18344,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['plugin'],['plugins']
Modifiability,"opt/xcat/sbin; PATH: /usr/lib64/qt-3.3/bin; PATH: /opt/pbs/default/bin; PATH: /opt/pbs/tools/bin; PATH: /usr/lpp/mmfs/bin/; PATH: /usr/local/bin; PATH: /bin; PATH: /usr/bin; PATH: /usr/local/sbin; PATH: /usr/sbin; PATH: /sbin; PATH: /gshare/soft/init; PATH: /gshare/soft/scripts; PATH: .; PATH: /gshare/soft/init; PATH: /gshare/soft/scripts; PATH: . ## ----------- ##; ## Core tests. ##; ## ----------- ##. configure:2465: checking build system type; configure:2479: result: x86_64-unknown-linux-gnu; configure:2499: checking host system type; configure:2512: result: x86_64-unknown-linux-gnu; configure:2532: checking target system type; configure:2545: result: x86_64-unknown-linux-gnu; configure:2587: checking for a BSD-compatible install; configure:2655: result: /usr/bin/install -c; configure:2666: checking whether build environment is sane; configure:2721: result: yes; configure:2872: checking for a thread-safe mkdir -p; configure:2911: result: /bin/mkdir -p; configure:2918: checking for gawk; configure:2934: found /bin/gawk; configure:2945: result: gawk; configure:2956: checking whether make sets $(MAKE); configure:2978: result: yes; configure:3075: checking whether make supports nested variables; configure:3092: result: yes; configure:3117: checking for style of include used by make; configure:3145: result: GNU; configure:3196: result: >>> MPI support disabled by default <<<; configure:3269: checking for g++; configure:3285: found /usr/bin/g++; configure:3296: result: g++; configure:3323: checking for C++ compiler version; configure:3332: g++ --version >&5; g++ (GCC) 4.4.6 20120305 (Red Hat 4.4.6-4); Copyright (C) 2010 Free Software Foundation, Inc.; This is free software; see the source for copying conditions. There is NO; warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. configure:3343: $? = 0; configure:3332: g++ -v >&5; Using built-in specs.; Target: x86_64-redhat-linux; Configured with: ../configure --prefix=/usr --mandir=/usr/share/man ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:1591,config,configure,1591,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,28,"['config', 'variab']","['configure', 'variables']"
Modifiability,or Tecplot binary solutions for unsteady flows. Fixes #150.; - Now SU2 should work with the latest version of the Intel compiler.; - Merge branch 'develop' of https://github.com/su2code/SU2 into develop; - Working on the O3 stuff; - Small change.; - Add another check to improve stability.; - Collection of improvements.; - Updated actuator disk; - Merge branch 'develop' of https://github.com/su2code/SU2 into develop; - Preliminary implementation of the Neg SA; - Minor updates; - Preliminary implementation of the Negative SA; - Bug fixing; - Fixed memory issued for very large meshes with ParMETIS.; - Clear evaluation of Vorticity and StrainMag; - Viscous limiter; - Updated RELAXATION_FACTOR; - RANS MG; - Partial fix to no MPI output; - Updated I/O; - Updated Adapt CFL; - Updated Adaptive CFL number; - Release 3.2.8; - Updated SetCFL_Number; - Small update; - Small change; - Small adjustments; - Minor changes; - Updated release 3.2.8; - MPI disabled by default in build. Added --enable-mpi flag to configure.; - Merged the ParMETIS implementation. Updated the build files.; - bootstrap; - Started parallel CGNS reader.; - Memory fix.; - Minor change; - Merge branch 'develop' of https://github.com/su2code/SU2 into develop; - Updated binaries; - Small change to configure.ac. Bootstrap.; - Small change; - Cleaning the code; - Updated grid deformation subroutine; - Fixing the mesh deformation; - Updated SU2_MSH; - Bug fixing; - Initial implementation of parallel CGNS reader. Works on 1 rank.; - Merged in recent changes to geometry_structure.cpp.; - Periodic BC working in serial; - Update option_structure.hpp; - Merge pull request #154 from su2code/fixCOptionEnumList; - Bug fixing (periodic bc); - Merge branch 'develop' of https://github.com/su2code/SU2 into develop; - Another important updated to BC in parallel; - More implementation and clean up of the parallel CGNS reader.; - Merge branch 'develop' of https://github.com/su2code/SU2 into develop; - CGNS reader bug fix.; - Upd,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:5795,config,configure,5795,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['config'],['configure']
Modifiability,ort.css (207) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport.xslt (232) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport_Minus.gif (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport_Plus.gif (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/module.mk (240) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/modulelocal-sample.mk (84) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtCaepInitItems.h (142) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtCaepInstanceData.h (135) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtCaepSupportData.h (83) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtPwpInitItems.h (68) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtPwpPluginInfo.h (75) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtPwpVersions.h (64) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/runtimeWrite.c (439) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/runtimeWrite_orig.txt (60) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcproj (511) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcproj.PWI.dgarlisch.user (121) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcxproj (307) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcxproj.filters (78) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcxproj.user (3) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/module.mk (239) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/modulelocal-sample.mk (84) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtCaepInitItems.h (98) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtCaepInstanceData.h (135) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtCaepSupportData.h (89) ; - D MeshTools/PointwiseSU2plugin/,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:16695,plugin,plugins,16695,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['plugin'],['plugins']
Modifiability,"orted in increasing order of the point indices to reduce cache misses, this means small groups of contiguous edges will share the same ""iPoint"", coloring single edges destroys this. Furthermore coloring either requires edges to be re-sorted by color, or if the edge indices of each color are instead kept in arrays, performance will suffer due to increased indirection which confounds the hardware pre-fetcher.; This can be mitigated to some extent by coloring groups of edges, groups of edges of the same color can be processed simultaneously, but within each group edges need to be processed serially. However grouping will reduce how much parallelism can be exploited within each color.; - **Gather to scatter** will in general use more memory due to the intermediate variables and extra adjacency information needed. If the entire algorithm is transformed performance may suffer as some computations may have to be repeated.; However, some reductions are possible without intermediate variables, for example when assembling the system matrix for implicit schemes only the diagonal entries can result in race conditions, now it just so happens that each diagonal entry is equal to the negated corresponding column sum.; - **Atomics** are terrible for the performance of code that writes frequently to memory (i.e. bandwidth-bound code), they do not increase the memory footprint and so make sense for compute-bound code.; Bugs due to a missing atomic can be very hard to debug (but any race condition is). Coloring is what one sees most in the literature, and yet I lean towards gather-to-scatter. Fewer things can go wrong with it as it is easy to understand, one gets the maximum amount of parallelism. I will now take two familiar routines, computing gradients (Green-Gauss) and limiters, vectorize / parallelize them in different ways, and measure relative performance to illustrate some of these key points introduced here. There will be C++ snipets and there will be some x86 assembly too :)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-529662724:6096,variab,variables,6096,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-529662724,1,['variab'],['variables']
Modifiability,"ow with a few pragmas we get gcc to vectorize:; ```C++; template<size_t nVar>; void computeGradients_impl(size_t nEdge,; size_t nPoint,; size_t nDim,; const vector<pair<size_t,size_t> >& connectivity,; const Matrix& area,; const vector<double>& volume,; const Matrix& phi,; VectorOfMatrix& grad); {; grad.setZero();. for(size_t iEdge=0; iEdge<nEdge; ++iEdge); {; size_t iPoint = connectivity[iEdge].first;; size_t jPoint = connectivity[iEdge].second;. double phi_ave[nVar];. #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); phi_ave[iVar] = 0.5*(phi(iPoint,iVar)+phi(jPoint,iVar));. for(size_t iDim=0; iDim<nDim; ++iDim); {; #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); {; double flux = phi_ave[iVar]*area(iEdge,iDim);. grad(iPoint,iVar,iDim) += flux;; grad(jPoint,iVar,iDim) -= flux;; }; }; }. for(size_t iPoint=0; iPoint<nPoint; ++iPoint); for(size_t iDim=0; iDim<nDim; ++iDim); #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); grad(iPoint,iVar,iDim) /= volume[iPoint];; }; ```; Well it is not just a few pragmas, we need to make the number of variables known at compile time (via a template parameter) and we need to transpose how the gradient is stored, i.e. instead of {xyz, xyz, xyz, xyz} we need {xxxx, yyyy, zzzz}. This code gets a speed-up of **2.2**. This code is generic but the template needs to be instantiated for every possible number of variables and we need a `switch` to call the right version at runtime, not very friendly.; Processing multiple edges at the same time is not worth the effort, for one we need `gather/scatter` on a very light routine, and on top of that we need to sort the edges such that we do not attempt to `scatter` to the same point when updating the gradient (a problem similar to the race condition described for SPMD). We can switch to a point-based loop and process multiple points in a SIMD way, that avoids the `scatter` problem but `gathers` will still be required. Here is what the scalar version of the point-based loop loo",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-530328194:2817,variab,variables,2817,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530328194,1,['variab'],['variables']
Modifiability,"pecasts. Still tracking down a memory problem...; - Critical bug fix for vtxdist array.; - Partial fix; - More MPI improvements.; - Fixing a bug in SU2_DEF; - Updated BC_ActDisk_Boundary (MPI); - Merge remote-tracking branch 'upstream/develop' into develop; - changing solidboundary setting to be heatflux OR euler etc instead of AND, also working on doxygen documentation; - Dynamic allocation for some marker-related arrays.; - visualize part taken out to match upstream/dev; - Collection of improvements; - Release 3.2.7; - Fixing LOW_MEMORY_OUTPUT; - Updated LOW_MEMORY_OUTPUT option; - Updated configure.ac; - After autoconf; - Updated MPI; - Updated BC_Engine_Exhaust and BC_Engine_Bleed; - Small change; - Fixing subsonic engine intake option; - Small output change; - Added output_su2.cpp; - Updated Engine BC; - Working on Engine BCs; - Added Supersonic Outlet BC; - Minor change; - Merge remote-tracking branch 'upstream/develop' into develop; - adjoints, solid boundary, doxygen in config; - continued fixing; - re-added adjoint bc mods; - re-adding avg outlet pressure (static pressure adjoint); - re-adding avg outlet pressure (static pressure adjoint); - Merge branch 'temp' of https://github.com/hlkline/SU2 into temp; - continued fixing; - average total pressure and fixes to avg outlet pressure; - adding stagnation pressure output to SU2_DOT; - Merge pull request #146 from hlkline/temp; - Updated Entropy fix (now it is active).; - Another change in BC_Engine_Exhaust; - Updated CGNS in parallel; - Added runtime file; - Small typo; - Adjustment of the Entropy fix coefficient; - Bug in SU2_GEO; - Debug version with print statements.; - Updated release 3.2.7.1; - Small change; - Updated config file; - Code update; - MPI Status and Request fix.; - Another MPI Status/Request fix.; - Actuator disk update.; - Small update; - Initial implementation of pyramids and prisms for Tecplot binary.; - Small fix for Tecplot binaries. Closes #56. Closes #57.; - Removed extra allocation re",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:3391,config,config,3391,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['config'],['config']
Modifiability,plugin/src/plugins/pluginRegistry.h (29) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEP.c (228) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEP.h (550) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEPUtils.c (290) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEPUtils.h (725) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/runtimeWrite.h (57) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWGM/apiGridModel.c (492) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWGM/apiGridModel.h (1808) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWP.c (132) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWP.h (707) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWPUtils.c (789) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWPUtils.h (1030) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiUtils.h (174) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/pwpPlatform.c (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/pwpPlatform.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/site.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/structured.props (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/structured.vsprops (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/CaeTemplate.suo (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/CaeTemplate.vcproj (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/module.mk (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/modulelocal-sample.mk (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/rtCaepInitItems.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/rtCaepInstanceData.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/rtCaepSupportData.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/runtimeWrite.c (0) ; - D MeshTool,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:19197,plugin,plugins,19197,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['plugin'],['plugins']
Modifiability,plugin/src/plugins/shared/CAEP/apiCAEP.h (550) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEPUtils.c (290) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEPUtils.h (725) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/runtimeWrite.h (57) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWGM/apiGridModel.c (492) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWGM/apiGridModel.h (1808) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWP.c (132) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWP.h (707) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWPUtils.c (789) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWPUtils.h (1030) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiUtils.h (174) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/pwpPlatform.c (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/pwpPlatform.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/site.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/structured.props (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/structured.vsprops (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/CaeTemplate.suo (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/CaeTemplate.vcproj (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/module.mk (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/modulelocal-sample.mk (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/rtCaepInitItems.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/rtCaepInstanceData.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/rtCaepSupportData.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/runtimeWrite.c (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/PWP/rtPwpInitItems.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/PWP/rtPwpPluginInfo,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:19349,plugin,plugins,19349,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['plugin'],['plugins']
Modifiability,proj.filters (78) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/CaeStrXML.vcxproj.user (3) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/module.mk (239) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/modulelocal-sample.mk (84) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtCaepInitItems.h (98) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtCaepInstanceData.h (135) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtCaepSupportData.h (89) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtPwpInitItems.h (68) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtPwpPluginInfo.h (75) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtPwpVersions.h (62) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/runtimeWrite.c (443) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.sdf (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.sln (26) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.suo (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcproj (511) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcxproj (307) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcxproj.filters (78) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcxproj.user (3) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/UpgradeLog.XML (47) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport.css (207) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport.xslt (232) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport_Minus.gif (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport_Plus.gif (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/module.mk (240) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:15153,plugin,plugins,15153,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['plugin'],['plugins']
Modifiability,"proj_j;; limiter(jPoint,iVar) = min(limiter(jPoint,iVar), lim_j);; }; }. for(size_t iPoint=0; iPoint<nPoint; ++iPoint); {; for(size_t iVar=0; iVar<nVar; ++iVar); {; double lim = limiter(iPoint,iVar);; limiter(iPoint,iVar) = lim*(lim+2)/(lim*lim+lim+2);; }; }; }; ```; Something in the code above is a bit different from the implementation in SU2, namely:; ```C++; double lim_i = phiMax(iPoint,iVar);; if(proj_i <= 0.0) {; lim_i = phiMin(iPoint,iVar);; proj_i = min(proj_i, -eps);; }; ```; This is the bit of code that selects the right delta based on the sign of the projection and avoids division by zero, this less readable version does the same with one branch instead of three, simplifying ""if"" statements is essential for vectorization, so to make the comparison fair I used the same strategy in the scalar code. To make this post shorter I will show the SIMD and parallel version of the code right away. Trying to process multiple edges instead of multiple variables has all the problems I mentioned for the gradients, so again we use the trick of templating on the number of variables.; ```C++; template<size_t nVar>; void computeLimiters_impl(size_t nPoint,; size_t nDim,; const vector<size_t>& colorStart,; const vector<size_t>& edgeIdx,; const vector<pair<size_t,size_t> >& connectivity,; const Matrix& coords,; const Matrix& phi,; const VectorOfMatrix& grad,; Matrix& phiMax,; Matrix& phiMin,; Matrix& limiter); {; // initialize; #pragma omp parallel for schedule(dynamic,TARGET_CHUNK_SIZE); for(size_t iPoint=0; iPoint<nPoint; ++iPoint); {; #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); {; phiMax(iPoint,iVar) = phi(iPoint,iVar);; phiMin(iPoint,iVar) = phi(iPoint,iVar);; limiter(iPoint,iVar) = 2.0;; }; }. // find min and max neighbor; for(size_t color=0; color<colorStart.size()-1; ++color); #pragma omp parallel for schedule(dynamic,CHUNK_SIZE); for(size_t k=colorStart[color]; k<colorStart[color+1]; ++k); {; #if SORT_BY_COLOR==1; size_t iEdge = k;; #else; size_t iEdge = ed",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-530593912:3389,variab,variables,3389,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530593912,2,['variab'],['variables']
Modifiability,pwpPlatform.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/site.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/structured.props (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/structured.vsprops (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/CaeTemplate.suo (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/CaeTemplate.vcproj (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/module.mk (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/modulelocal-sample.mk (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/rtCaepInitItems.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/rtCaepInstanceData.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/rtCaepSupportData.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/runtimeWrite.c (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/PWP/rtPwpInitItems.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/PWP/rtPwpPluginInfo.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/PWP/rtPwpVersions.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/unstructured.props (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/unstructured.vsprops (0) ; - D MeshTools/PointwiseSU2plugin_Instructions.txt (0) ; - I QuickStart/inv_NACA0012.cfg (0) ; - I README (0) ; - I SU2_CFD/include/SU2_CFD.hpp (0) ; - I SU2_CFD/include/definition_structure.hpp (0) ; - I SU2_CFD/include/fluid_model.hpp (0) ; - I SU2_CFD/include/fluid_model.inl (0) ; - I SU2_CFD/include/integration_structure.hpp (0) ; - I SU2_CFD/include/integration_structure.inl (0) ; - I SU2_CFD/include/iteration_structure.hpp (0) ; - I SU2_CFD/include/numerics_machine_learning.hpp (0) ; - I SU2_CFD/include/numerics_machine_learning.inl (0) ; - I SU2_CFD/include/numerics_machine_learning_turbulent.hpp (0) ; - I SU2_CFD/include/numerics_structure.hpp (0) ; - I SU2_CFD/include/numerics_structure.inl (0) ; - I SU2_CFD/in,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:20296,plugin,plugins,20296,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['plugin'],['plugins']
Modifiability,"r""'; am__untar='$${TAR-tar} xf -'; bindir='${exec_prefix}/bin'; build='x86_64-unknown-linux-gnu'; build_alias=''; build_cpu='x86_64'; build_os='linux-gnu'; build_vendor='unknown'; datadir='${datarootdir}'; datarootdir='${prefix}/share'; docdir='${datarootdir}/doc/${PACKAGE_TARNAME}'; dvidir='${docdir}'; exec_prefix='${prefix}'; host='x86_64-unknown-linux-gnu'; host_alias=''; host_cpu='x86_64'; host_os='linux-gnu'; host_vendor='unknown'; htmldir='${docdir}'; includedir='${prefix}/include'; infodir='${datarootdir}/info'; install_sh='${SHELL} /home/antodech/SU2-4.1.0/install-sh'; libdir='${exec_prefix}/lib'; libexecdir='${exec_prefix}/libexec'; localedir='${datarootdir}/locale'; localstatedir='${prefix}/var'; mandir='${datarootdir}/man'; mkdir_p='$(MKDIR_P)'; oldincludedir='/usr/include'; pdfdir='${docdir}'; prefix='/gshare/work/hpascalj/CodeSU2-master'; program_transform_name='s,x,x,'; psdir='${docdir}'; sbindir='${exec_prefix}/sbin'; sharedstatedir='${prefix}/com'; su2_externals_INCLUDES=''; su2_externals_LIBS=''; sysconfdir='${prefix}/etc'; target='x86_64-unknown-linux-gnu'; target_alias=''; target_cpu='x86_64'; target_os='linux-gnu'; target_vendor='unknown'. ## ----------- ##; ## confdefs.h. ##; ## ----------- ##. /* confdefs.h */; #define PACKAGE_NAME ""SU2""; #define PACKAGE_TARNAME ""SU2""; #define PACKAGE_VERSION ""4.1.0""; #define PACKAGE_STRING ""SU2 4.1.0""; #define PACKAGE_BUGREPORT ""su2code-dev@lists.stanford.edu""; #define PACKAGE_URL ""https://github.com/su2code""; #define PACKAGE ""SU2""; #define VERSION ""4.1.0""; #define STDC_HEADERS 1; #define HAVE_SYS_TYPES_H 1; #define HAVE_SYS_STAT_H 1; #define HAVE_STDLIB_H 1; #define HAVE_STRING_H 1; #define HAVE_MEMORY_H 1; #define HAVE_STRINGS_H 1; #define HAVE_INTTYPES_H 1; #define HAVE_STDINT_H 1; #define HAVE_UNISTD_H 1; #define SIZEOF_SHORT_INT 2; #define SIZEOF_INT 4; #define SIZEOF_UNSIGNED_INT 4; #define SIZEOF_LONG_INT 8; #define SIZEOF_FLOAT 4; #define SIZEOF_DOUBLE 8; #define SIZEOF_VOID_P 8. configure: exit 0; ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:27135,config,configure,27135,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,1,['config'],['configure']
Modifiability,rc/plugins/shared/CAEP/apiCAEP.c (228) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEP.h (550) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEPUtils.c (290) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEPUtils.h (725) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/runtimeWrite.h (57) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWGM/apiGridModel.c (492) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWGM/apiGridModel.h (1808) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWP.c (132) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWP.h (707) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWPUtils.c (789) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWPUtils.h (1030) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiUtils.h (174) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/pwpPlatform.c (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/pwpPlatform.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/site.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/structured.props (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/structured.vsprops (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/CaeTemplate.suo (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/CaeTemplate.vcproj (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/module.mk (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/modulelocal-sample.mk (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/rtCaepInitItems.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/rtCaepInstanceData.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/rtCaepSupportData.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/runtimeWrite.c (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/PWP/rtPwpInitItems.h (0) ; - D Mes,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:19273,plugin,plugins,19273,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['plugin'],['plugins']
Modifiability,"re:4445: result: yes; configure:4513: checking for ranlib; configure:4529: found /usr/bin/ranlib; configure:4540: result: ranlib; configure:4574: checking how to run the C preprocessor; configure:4605: gcc -E conftest.c; configure:4605: $? = 0; configure:4619: gcc -E conftest.c; conftest.c:11:28: error: ac_nonexistent.h: No such file or directory; configure:4619: $? = 1; configure: failed program was:; | /* confdefs.h */; | #define PACKAGE_NAME ""SU2""; | #define PACKAGE_TARNAME ""SU2""; | #define PACKAGE_VERSION ""4.1.0""; | #define PACKAGE_STRING ""SU2 4.1.0""; | #define PACKAGE_BUGREPORT ""su2code-dev@lists.stanford.edu""; | #define PACKAGE_URL ""https://github.com/su2code""; | #define PACKAGE ""SU2""; | #define VERSION ""4.1.0""; | /* end confdefs.h. */; | #include <ac_nonexistent.h>; configure:4644: result: gcc -E; configure:4664: gcc -E conftest.c; configure:4664: $? = 0; configure:4678: gcc -E conftest.c; conftest.c:11:28: error: ac_nonexistent.h: No such file or directory; configure:4678: $? = 1; configure: failed program was:; | /* confdefs.h */; | #define PACKAGE_NAME ""SU2""; | #define PACKAGE_TARNAME ""SU2""; | #define PACKAGE_VERSION ""4.1.0""; | #define PACKAGE_STRING ""SU2 4.1.0""; | #define PACKAGE_BUGREPORT ""su2code-dev@lists.stanford.edu""; | #define PACKAGE_URL ""https://github.com/su2code""; | #define PACKAGE ""SU2""; | #define VERSION ""4.1.0""; | /* end confdefs.h. */; | #include <ac_nonexistent.h>; configure:4707: checking for grep that handles long lines and -e; configure:4765: result: /bin/grep; configure:4770: checking for egrep; configure:4832: result: /bin/grep -E; configure:4837: checking for ANSI C header files; configure:4857: gcc -c -g -O2 conftest.c >&5; configure:4857: $? = 0; configure:4930: gcc -o conftest -g -O2 conftest.c >&5; configure:4930: $? = 0; configure:4930: ./conftest; configure:4930: $? = 0; configure:4941: result: yes; configure:4954: checking for sys/types.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: res",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:8782,config,configure,8782,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,2,['config'],['configure']
Modifiability,re:4857: $? = 0; configure:4930: gcc -o conftest -g -O2 conftest.c >&5; configure:4930: $? = 0; configure:4930: ./conftest; configure:4930: $? = 0; configure:4941: result: yes; configure:4954: checking for sys/types.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for sys/stat.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for stdlib.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for string.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for memory.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for strings.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for inttypes.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for stdint.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for unistd.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4970: checking size of short int; configure:4975: gcc -o conftest -g -O2 conftest.c >&5; configure:4975: $? = 0; configure:4975: ./conftest; configure:4975: $? = 0; configure:4989: result: 2; configure:5003: checking size of int; configure:5008: gcc -o conftest -g -O2 conftest.c >&5; configure:5008: $? = 0; configure:5008: ./conftest; configure:5008: $? = 0; configure:5022: result: 4; configure:5036: checking size of unsigned int; configure:5041: gcc -o conftest -g -O2 conftest.c >&5; configure:5041: $? = 0; configure:5041: ./conftest; configure:5041: $? = ,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:10452,config,configure,10452,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,3,['config'],['configure']
Modifiability,"rror: ac_nonexistent.h: No such file or directory; configure:4678: $? = 1; configure: failed program was:; | /* confdefs.h */; | #define PACKAGE_NAME ""SU2""; | #define PACKAGE_TARNAME ""SU2""; | #define PACKAGE_VERSION ""4.1.0""; | #define PACKAGE_STRING ""SU2 4.1.0""; | #define PACKAGE_BUGREPORT ""su2code-dev@lists.stanford.edu""; | #define PACKAGE_URL ""https://github.com/su2code""; | #define PACKAGE ""SU2""; | #define VERSION ""4.1.0""; | /* end confdefs.h. */; | #include <ac_nonexistent.h>; configure:4707: checking for grep that handles long lines and -e; configure:4765: result: /bin/grep; configure:4770: checking for egrep; configure:4832: result: /bin/grep -E; configure:4837: checking for ANSI C header files; configure:4857: gcc -c -g -O2 conftest.c >&5; configure:4857: $? = 0; configure:4930: gcc -o conftest -g -O2 conftest.c >&5; configure:4930: $? = 0; configure:4930: ./conftest; configure:4930: $? = 0; configure:4941: result: yes; configure:4954: checking for sys/types.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for sys/stat.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for stdlib.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for string.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for memory.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for strings.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for inttypes.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for stdint.h; configure:4954: gcc -c -g -O2 conftest.c >&5; c",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:9713,config,configure,9713,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,1,['config'],['configure']
Modifiability,s.h (62) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/runtimeWrite.c (347) ; - D MeshTools/PointwiseSU2plugin/src/plugins/README.txt (272) ; - D MeshTools/PointwiseSU2plugin/src/plugins/module.mk (309) ; - D MeshTools/PointwiseSU2plugin/src/plugins/modulelocal.mk (8) ; - D MeshTools/PointwiseSU2plugin/src/plugins/pluginRegistry.h (29) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEP.c (228) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEP.h (550) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEPUtils.c (290) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEPUtils.h (725) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/runtimeWrite.h (57) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWGM/apiGridModel.c (492) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWGM/apiGridModel.h (1808) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWP.c (132) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWP.h (707) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWPUtils.c (789) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWPUtils.h (1030) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiUtils.h (174) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/pwpPlatform.c (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/pwpPlatform.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/site.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/structured.props (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/structured.vsprops (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/CaeTemplate.suo (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/CaeTemplate.vcproj (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/module.mk (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/modulelocal-sample.mk (0) ; - D MeshTools/PointwiseSU2plugin/src/plugin,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:18892,plugin,plugins,18892,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['plugin'],['plugins']
Modifiability,s/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEPUtils.c (290) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEPUtils.h (725) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/runtimeWrite.h (57) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWGM/apiGridModel.c (492) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWGM/apiGridModel.h (1808) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWP.c (132) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWP.h (707) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWPUtils.c (789) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWPUtils.h (1030) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiUtils.h (174) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/pwpPlatform.c (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/pwpPlatform.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/site.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/structured.props (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/structured.vsprops (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/CaeTemplate.suo (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/CaeTemplate.vcproj (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/module.mk (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/modulelocal-sample.mk (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/rtCaepInitItems.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/rtCaepInstanceData.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/rtCaepSupportData.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/runtimeWrite.c (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/PWP/rtPwpInitItems.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/PWP/rtPwpPluginInfo.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templat,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:19407,plugin,plugins,19407,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['plugin'],['plugins']
Modifiability,s/shared/PWP/apiUtils.h (174) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/pwpPlatform.c (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/pwpPlatform.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/site.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/structured.props (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/structured.vsprops (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/CaeTemplate.suo (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/CaeTemplate.vcproj (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/module.mk (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/modulelocal-sample.mk (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/rtCaepInitItems.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/rtCaepInstanceData.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/rtCaepSupportData.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/runtimeWrite.c (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/PWP/rtPwpInitItems.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/PWP/rtPwpPluginInfo.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/PWP/rtPwpVersions.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/unstructured.props (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/unstructured.vsprops (0) ; - D MeshTools/PointwiseSU2plugin_Instructions.txt (0) ; - I QuickStart/inv_NACA0012.cfg (0) ; - I README (0) ; - I SU2_CFD/include/SU2_CFD.hpp (0) ; - I SU2_CFD/include/definition_structure.hpp (0) ; - I SU2_CFD/include/fluid_model.hpp (0) ; - I SU2_CFD/include/fluid_model.inl (0) ; - I SU2_CFD/include/integration_structure.hpp (0) ; - I SU2_CFD/include/integration_structure.inl (0) ; - I SU2_CFD/include/iteration_structure.hpp (0) ; - I SU2_CFD/include/numerics_machine_learning.hpp (0) ; - I SU2_CFD/include/numerics_machine_learning.inl (0) ; - I SU2_CFD/in,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:20133,plugin,plugins,20133,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['plugin'],['plugins']
Modifiability,s/types.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for sys/stat.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for stdlib.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for string.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for memory.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for strings.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for inttypes.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for stdint.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for unistd.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4970: checking size of short int; configure:4975: gcc -o conftest -g -O2 conftest.c >&5; configure:4975: $? = 0; configure:4975: ./conftest; configure:4975: $? = 0; configure:4989: result: 2; configure:5003: checking size of int; configure:5008: gcc -o conftest -g -O2 conftest.c >&5; configure:5008: $? = 0; configure:5008: ./conftest; configure:5008: $? = 0; configure:5022: result: 4; configure:5036: checking size of unsigned int; configure:5041: gcc -o conftest -g -O2 conftest.c >&5; configure:5041: $? = 0; configure:5041: ./conftest; configure:5041: $? = 0; configure:5055: result: 4; configure:5069: checking size of long int; configure:5074: gcc -o conftest -g -O2 conftest.c >&5; configure:5074: $? = 0; configure:5074: ./conftest; configure:5074: $? = 0; conf,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:10684,config,configure,10684,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,1,['config'],['configure']
Modifiability,seSU2plugin/src/plugins/CaeStrXML/CaeStrXML.vcproj.PWI.dgarlisch.user (121) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/CaeStrXML.vcxproj (307) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/CaeStrXML.vcxproj.filters (78) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/CaeStrXML.vcxproj.user (3) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/module.mk (239) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/modulelocal-sample.mk (84) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtCaepInitItems.h (98) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtCaepInstanceData.h (135) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtCaepSupportData.h (89) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtPwpInitItems.h (68) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtPwpPluginInfo.h (75) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtPwpVersions.h (62) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/runtimeWrite.c (443) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.sdf (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.sln (26) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.suo (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcproj (511) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcxproj (307) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcxproj.filters (78) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcxproj.user (3) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/UpgradeLog.XML (47) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport.css (207) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport.xslt (232) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport_Minus.gif (0) ; - D M,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:14924,plugin,plugins,14924,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['plugin'],['plugins']
Modifiability,seSU2plugin/src/plugins/CaeUnsSU2/rtPwpPluginInfo.h (75) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtPwpVersions.h (64) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/runtimeWrite.c (439) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/runtimeWrite_orig.txt (60) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcproj (511) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcproj.PWI.dgarlisch.user (121) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcxproj (307) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcxproj.filters (78) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcxproj.user (3) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/module.mk (239) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/modulelocal-sample.mk (84) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtCaepInitItems.h (98) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtCaepInstanceData.h (135) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtCaepSupportData.h (89) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtPwpInitItems.h (68) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtPwpPluginInfo.h (75) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtPwpVersions.h (62) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/runtimeWrite.c (347) ; - D MeshTools/PointwiseSU2plugin/src/plugins/README.txt (272) ; - D MeshTools/PointwiseSU2plugin/src/plugins/module.mk (309) ; - D MeshTools/PointwiseSU2plugin/src/plugins/modulelocal.mk (8) ; - D MeshTools/PointwiseSU2plugin/src/plugins/pluginRegistry.h (29) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEP.c (228) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEP.h (550) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEPUtils.c (290) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/api,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:17526,plugin,plugins,17526,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['plugin'],['plugins']
Modifiability,seSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcproj.PWI.dgarlisch.user (121) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcxproj (307) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcxproj.filters (78) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcxproj.user (3) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/module.mk (239) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/modulelocal-sample.mk (84) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtCaepInitItems.h (98) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtCaepInstanceData.h (135) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtCaepSupportData.h (89) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtPwpInitItems.h (68) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtPwpPluginInfo.h (75) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtPwpVersions.h (62) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/runtimeWrite.c (347) ; - D MeshTools/PointwiseSU2plugin/src/plugins/README.txt (272) ; - D MeshTools/PointwiseSU2plugin/src/plugins/module.mk (309) ; - D MeshTools/PointwiseSU2plugin/src/plugins/modulelocal.mk (8) ; - D MeshTools/PointwiseSU2plugin/src/plugins/pluginRegistry.h (29) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEP.c (228) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEP.h (550) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEPUtils.c (290) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEPUtils.h (725) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/runtimeWrite.h (57) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWGM/apiGridModel.c (492) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWGM/apiGridModel.h (1808) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWP.c (132) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWP.h (7,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:17929,plugin,plugins,17929,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['plugin'],['plugins']
Modifiability,"setZero();. for(size_t iEdge=0; iEdge<nEdge; ++iEdge); {; size_t iPoint = connectivity[iEdge].first;; size_t jPoint = connectivity[iEdge].second;. for(size_t iVar=0; iVar<nVar; ++iVar); {; double phi_ave = 0.5*(phi(iPoint,iVar)+phi(jPoint,iVar));. for(size_t iDim=0; iDim<nDim; ++iDim); {; double flux = phi_ave*area(iEdge,iDim);. grad(iPoint,iVar,iDim) += flux;; grad(jPoint,iVar,iDim) -= flux;; }; }; }. for(size_t iPoint=0; iPoint<nPoint; ++iPoint); for(size_t iVar=0; iVar<nVar; ++iVar); for(size_t iDim=0; iDim<nDim; ++iDim); grad(iPoint,iVar,iDim) /= volume[iPoint];; }; ```; This is more or less what SU2 does with minor differences on how the edges (`connectivity`) and area are stored, there is no vectorization nor easy way to make the loop parallel, this will be the reference for execution times. Suppose now that due to a perfect storm the number of variables is 4, here is how with a few pragmas we get gcc to vectorize:; ```C++; template<size_t nVar>; void computeGradients_impl(size_t nEdge,; size_t nPoint,; size_t nDim,; const vector<pair<size_t,size_t> >& connectivity,; const Matrix& area,; const vector<double>& volume,; const Matrix& phi,; VectorOfMatrix& grad); {; grad.setZero();. for(size_t iEdge=0; iEdge<nEdge; ++iEdge); {; size_t iPoint = connectivity[iEdge].first;; size_t jPoint = connectivity[iEdge].second;. double phi_ave[nVar];. #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); phi_ave[iVar] = 0.5*(phi(iPoint,iVar)+phi(jPoint,iVar));. for(size_t iDim=0; iDim<nDim; ++iDim); {; #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); {; double flux = phi_ave[iVar]*area(iEdge,iDim);. grad(iPoint,iVar,iDim) += flux;; grad(jPoint,iVar,iDim) -= flux;; }; }; }. for(size_t iPoint=0; iPoint<nPoint; ++iPoint); for(size_t iDim=0; iDim<nDim; ++iDim); #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); grad(iPoint,iVar,iDim) /= volume[iPoint];; }; ```; Well it is not just a few pragmas, we need to make the number of variables known at compile time (via a t",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-530328194:1719,variab,variables,1719,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530328194,1,['variab'],['variables']
Modifiability,"sult: done; configure:6952: creating ./config.status. ## ---------------------- ##; ## Running config.status. ##; ## ---------------------- ##. This file was extended by SU2 config.status 4.1.0, which was; generated by GNU Autoconf 2.69. Invocation command line was. CONFIG_FILES = ; CONFIG_HEADERS = ; CONFIG_LINKS = ; CONFIG_COMMANDS = ; $ ./config.status . on master. config.status:875: creating externals/tecio/Makefile; config.status:875: creating externals/metis/Makefile; config.status:875: creating externals/parmetis/Makefile; config.status:875: creating Makefile; config.status:875: creating externals/Makefile; config.status:875: creating Common/lib/Makefile; config.status:875: creating SU2_CFD/obj/Makefile; config.status:875: creating SU2_DOT/obj/Makefile; config.status:875: creating SU2_MSH/obj/Makefile; config.status:875: creating SU2_DEF/obj/Makefile; config.status:875: creating SU2_SOL/obj/Makefile; config.status:875: creating SU2_GEO/obj/Makefile; config.status:875: creating SU2_PY/Makefile; config.status:1047: executing depfiles commands; configure:8181: result:. -------------------------------------------------------------------------; | ___ _ _ ___ |; | / __| | | |_ ) Release 4.1.0 'Cardinal' |; | \__ \ |_| |/ / |; | |___/\___//___| Suite |; | |; -------------------------------------------------------------------------; | SU2 Lead Dev.: Dr. Francisco Palacios, Francisco.D.Palacios@boeing.com|; | Dr. Thomas D. Economon, economon@stanford.edu |; -------------------------------------------------------------------------; | SU2 Developers: |; | - Prof. Juan J. Alonso's group at Stanford University. |; | - Prof. Piero Colonna's group at Delft University of Technology. |; | - Prof. Nicolas R. Gauger's group at Kaiserslautern U. of Technology. |; | - Prof. Alberto Guardone's group at Polytechnic University of Milan. |; | - Prof. Rafael Palacios' group at Imperial College London. |; -------------------------------------------------------------------------; | Copyr",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:16627,config,config,16627,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,1,['config'],['config']
Modifiability,"t --enable-languages=c,c++,objc,obj-c++,java,fortran,ada --enable-java-awt=gtk --disable-dssi --with-java-home=/usr/lib/jvm/java-1.5.0-gcj-1.5.0.0/jre --enable-libgcj-multifile --enable-java-maintainer-mode --with-ecj-jar=/usr/share/java/eclipse-ecj.jar --disable-libjava-multilib --with-ppl --with-cloog --with-tune=generic --with-arch_32=i686 --build=x86_64-redhat-linux; Thread model: posix; gcc version 4.4.6 20120305 (Red Hat 4.4.6-4) (GCC) ; configure:3999: $? = 0; configure:3988: gcc -V >&5; gcc: '-V' option must have argument; configure:3999: $? = 1; configure:3988: gcc -qversion >&5; gcc: unrecognized option '-qversion'; gcc: no input files; configure:3999: $? = 1; configure:4003: checking whether we are using the GNU C compiler; configure:4022: gcc -c conftest.c >&5; configure:4022: $? = 0; configure:4031: result: yes; configure:4040: checking whether gcc accepts -g; configure:4060: gcc -c -g conftest.c >&5; configure:4060: $? = 0; configure:4101: result: yes; configure:4118: checking for gcc option to accept ISO C89; configure:4181: gcc -c -g -O2 conftest.c >&5; configure:4181: $? = 0; configure:4194: result: none needed; configure:4216: checking dependency style of gcc; configure:4327: result: gcc3; configure:4345: checking whether gcc and cc understand -c and -o together; configure:4376: gcc -c conftest.c -o conftest2.o >&5; configure:4380: $? = 0; configure:4386: gcc -c conftest.c -o conftest2.o >&5; configure:4390: $? = 0; configure:4401: cc -c conftest.c >&5; configure:4405: $? = 0; configure:4413: cc -c conftest.c -o conftest2.o >&5; configure:4417: $? = 0; configure:4423: cc -c conftest.c -o conftest2.o >&5; configure:4427: $? = 0; configure:4445: result: yes; configure:4513: checking for ranlib; configure:4529: found /usr/bin/ranlib; configure:4540: result: ranlib; configure:4574: checking how to run the C preprocessor; configure:4605: gcc -E conftest.c; configure:4605: $? = 0; configure:4619: gcc -E conftest.c; conftest.c:11:28: error: ac_nonexistent",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:7049,config,configure,7049,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,4,['config'],['configure']
Modifiability,"t have argument; configure:3999: $? = 1; configure:3988: gcc -qversion >&5; gcc: unrecognized option '-qversion'; gcc: no input files; configure:3999: $? = 1; configure:4003: checking whether we are using the GNU C compiler; configure:4022: gcc -c conftest.c >&5; configure:4022: $? = 0; configure:4031: result: yes; configure:4040: checking whether gcc accepts -g; configure:4060: gcc -c -g conftest.c >&5; configure:4060: $? = 0; configure:4101: result: yes; configure:4118: checking for gcc option to accept ISO C89; configure:4181: gcc -c -g -O2 conftest.c >&5; configure:4181: $? = 0; configure:4194: result: none needed; configure:4216: checking dependency style of gcc; configure:4327: result: gcc3; configure:4345: checking whether gcc and cc understand -c and -o together; configure:4376: gcc -c conftest.c -o conftest2.o >&5; configure:4380: $? = 0; configure:4386: gcc -c conftest.c -o conftest2.o >&5; configure:4390: $? = 0; configure:4401: cc -c conftest.c >&5; configure:4405: $? = 0; configure:4413: cc -c conftest.c -o conftest2.o >&5; configure:4417: $? = 0; configure:4423: cc -c conftest.c -o conftest2.o >&5; configure:4427: $? = 0; configure:4445: result: yes; configure:4513: checking for ranlib; configure:4529: found /usr/bin/ranlib; configure:4540: result: ranlib; configure:4574: checking how to run the C preprocessor; configure:4605: gcc -E conftest.c; configure:4605: $? = 0; configure:4619: gcc -E conftest.c; conftest.c:11:28: error: ac_nonexistent.h: No such file or directory; configure:4619: $? = 1; configure: failed program was:; | /* confdefs.h */; | #define PACKAGE_NAME ""SU2""; | #define PACKAGE_TARNAME ""SU2""; | #define PACKAGE_VERSION ""4.1.0""; | #define PACKAGE_STRING ""SU2 4.1.0""; | #define PACKAGE_BUGREPORT ""su2code-dev@lists.stanford.edu""; | #define PACKAGE_URL ""https://github.com/su2code""; | #define PACKAGE ""SU2""; | #define VERSION ""4.1.0""; | /* end confdefs.h. */; | #include <ac_nonexistent.h>; configure:4644: result: gcc -E; configure:4664: gcc -E ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:7617,config,configure,7617,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,2,['config'],['configure']
Modifiability,te.c (347) ; - D MeshTools/PointwiseSU2plugin/src/plugins/README.txt (272) ; - D MeshTools/PointwiseSU2plugin/src/plugins/module.mk (309) ; - D MeshTools/PointwiseSU2plugin/src/plugins/modulelocal.mk (8) ; - D MeshTools/PointwiseSU2plugin/src/plugins/pluginRegistry.h (29) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEP.c (228) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEP.h (550) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEPUtils.c (290) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEPUtils.h (725) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/runtimeWrite.h (57) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWGM/apiGridModel.c (492) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWGM/apiGridModel.h (1808) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWP.c (132) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWP.h (707) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWPUtils.c (789) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiPWPUtils.h (1030) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiUtils.h (174) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/pwpPlatform.c (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/pwpPlatform.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/site.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/structured.props (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/structured.vsprops (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/CaeTemplate.suo (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/CaeTemplate.vcproj (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/module.mk (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/modulelocal-sample.mk (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/rtCaepInitItems.h (0) ; - D MeshTools/PointwiseSU2plugin/s,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:18965,plugin,plugins,18965,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['plugin'],['plugins']
Modifiability,"testcase suite. > * Should this just run ""out of the box"" with a working installation of OpenMP in any machine, or is there anything else _fancy_ needed?. I would leave it to the community to decide what the defaults should be, probably for a lot of new users that don't run on clusters just calling SU2_CFD and not having to worry about mpi would be nice (a lot of the issues on CFD online are mpi related). > * Is the previous behaviour exactly kept, or are there any modifications in the basic, non OpenMP version of code? (Not that I mind, just curious). Other than the algorithmic changes (but mathematically equivalent) introduced to limiters and gradients in #834, yes. > What's the advantage of having one numerics term per thread?. It is a requirement, we need to write data into numerics before using them, multiple threads cannot write to the same location (i.e. the internal structures of CNumerics) therefore one per thread is required. > ...Also, I think I missed the point where the numerics container is extended beyond MAX_TERMS. The allocation of space for one numerics per thread is done above in line 1995 of my 21 Dec 2019 comment: `...MAX_TERMS*omp_get_max_threads()...`.; The instantiation of one numerics per thread is then done by executing the rest of the preprocessing in parallel and instead of using `XYZ_TERM` using `XYZ_TERM+offset` where `offset = thread_id * MAX_TERMS`.; I think someone mentioned this (maybe Tim) that we could revisit the ownership relations of the numerics classes, i.e. allocate them as members of their respective solvers, which if we do, we can think of having a purpose built container that automates the per-thread creation and access. > Why are they redefined each time inside the loop?; > Is this for efficiency reasons?. Referring to variables being declared inside loops. One stylist reason is that declaring everything at the top of a function is the C way of doing things, the C++ people whose books/blogs I've read and talks I've watche",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/843#issuecomment-577684728:1558,extend,extended,1558,https://su2code.github.io,https://github.com/su2code/SU2/pull/843#issuecomment-577684728,1,['extend'],['extended']
Modifiability,"thing to do. So let’s indeed do something like what Tom suggests (in the spirit of MARKER_MONITORING) so that one can control which markers get wall functions applied. If a list of markers is not specified in the config file, the default behavior should be that all no-slip walls get wall function BCs. If a list of markers is specified, then those and only those markers listed get wall function Bfs (with the others getting integration to the wall treatment). Now, what you point out in the second half of your message is the ultimate in flexibility: not only specifying wall functions in a subset of the no-slip wall markers, but also allowing for different kinds of wall functions to be used in those markers. I imagine that this would be a seldom used capability…but someone out there might have the need. I guess it does not seem to me that the coding of the most flexible logic is that much more complicated, so we may as well do that. If you guys think it is too complicated, the advertised options in the config file can allow some simpler behavior. My two cents,. Juan. On Sep 5, 2017, at 9:58 PM, Edwin van der Weide <notifications@github.com<mailto:notifications@github.com>> wrote:. Juan,. I think that having the flexibility to apply wall functions on only a subset of the viscous wall boundaries would be useful. E.g., if you are interested in a wing, you can apply integration to the wall there, but apply wall functions on the fuselage. My preference would be to have a dedicated BC type for that, i.e. Tom's second suggestion. Apart from this, we can have the different wall model types as a single input parameter, i.e. you apply the same wall model type for all viscous boundaries. Or would you like to have the flexibility to specify this as well per individual marker?. Edwin. —; You are receiving this because you commented.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/399#issuecomment-327374728>, or mute the thread<https://github.co",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/399#issuecomment-327377108:1344,config,config,1344,https://su2code.github.io,https://github.com/su2code/SU2/issues/399#issuecomment-327377108,1,['config'],['config']
Modifiability,trXML/module.mk (239) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/modulelocal-sample.mk (84) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtCaepInitItems.h (98) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtCaepInstanceData.h (135) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtCaepSupportData.h (89) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtPwpInitItems.h (68) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtPwpPluginInfo.h (75) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtPwpVersions.h (62) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/runtimeWrite.c (443) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.sdf (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.sln (26) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.suo (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcproj (511) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcxproj (307) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcxproj.filters (78) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcxproj.user (3) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/UpgradeLog.XML (47) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport.css (207) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport.xslt (232) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport_Minus.gif (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport_Plus.gif (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/module.mk (240) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/modulelocal-sample.mk (84) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtCaepInitItems.h (142) ; - D MeshTools/PointwiseSU2plugin/src/plug,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:15308,plugin,plugins,15308,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['plugin'],['plugins']
Modifiability,"ts in config_structure to make doxygen pretty; - Bug fixing; - Merge branch 'develop'; - EA in ft^2; - further update to config; - Merge remote-tracking branch 'upstream/develop' into upstream_dev; - Minor changes; - Updated NF BC; - More adjustments; - Small update; - Final update Nearfield BC; - added massflowrate as option for cauchy criteria, more config file comments; - Merge remote-tracking branch 'upstream/develop' into upstream_dev; - paraview output modified/added back in for current version for SU2_DEF; - Merge branch 'develop' into feature_dualoutput; - Removed deprecated options from quicstart config.; - Working version of the compressible actuator disk; - Updated fixed CL mode.; - Very minor change; - Merge branch 'develop' into feature_dualoutput; - Final push to 3.2.9; - Merge branch 'develop'; - Minor change; - Minor change; - Small change; - Minor change; - Bug fixing: unsigned short val_vertex --> unsigned long val_vertex; - CFL adapt now works for adjoint problems; - Merge branch 'develop' into feature_dualoutput; - Fixing a typo; - Fix in the Euler BC for grid movement cases; - merging and fixing conflicts bwtn feature_dealloc and develop; - dealloc; - Time spectral fix.; - Merging some recent bug fixes from master into the develop branch to keep nsync.; - Merge branch 'feature_gridvel_fix' into develop; - Merge remote-tracking branch 'upstream/develop' into feature_Deallocation; - correcting issues, adding more deallocation; - fixed uninitialized pointers in CConfig; - further deallocation; - some corrections needed to pass reg tests; - fixed some dealloc issues that caused errors in euler adj; - modifications needed to (mostly) pass reg tests; all run w/o segfault. File Changes; - D Articles/AIAA_2013-0287.pdf (0) ; - D Articles/AIAA_2014-0243.pdf (0) ; - M Common/doc/docmain.hpp (46) ; - M Common/include/config_structure.hpp (1038) ; - M Common/include/config_structure.inl (191) ; - M Common/include/dual_grid_structure.hpp (43) ; - M Common/inc",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:9856,adapt,adapt,9856,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['adapt'],['adapt']
Modifiability,twiseSU2plugin/mkplugin.bat (82) ; - D MeshTools/PointwiseSU2plugin/mkplugin.tcl (422) ; - D MeshTools/PointwiseSU2plugin/src/Pointwise/Win32Target.props (28) ; - D MeshTools/PointwiseSU2plugin/src/Pointwise/Win32Target.vsprops (24) ; - D MeshTools/PointwiseSU2plugin/src/Pointwise/Win64Target.props (28) ; - D MeshTools/PointwiseSU2plugin/src/Pointwise/Win64Target.vsprops (24) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/CaeStrXML.vcproj (511) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/CaeStrXML.vcproj.PWI.dgarlisch.user (121) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/CaeStrXML.vcxproj (307) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/CaeStrXML.vcxproj.filters (78) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/CaeStrXML.vcxproj.user (3) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/module.mk (239) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/modulelocal-sample.mk (84) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtCaepInitItems.h (98) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtCaepInstanceData.h (135) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtCaepSupportData.h (89) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtPwpInitItems.h (68) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtPwpPluginInfo.h (75) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtPwpVersions.h (62) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/runtimeWrite.c (443) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.sdf (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.sln (26) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.suo (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcproj (511) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcxproj (307) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcxproj.filters (7,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:14441,plugin,plugins,14441,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['plugin'],['plugins']
Modifiability,twiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcxproj.filters (78) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcxproj.user (3) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/UpgradeLog.XML (47) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport.css (207) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport.xslt (232) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport_Minus.gif (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport_Plus.gif (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/module.mk (240) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/modulelocal-sample.mk (84) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtCaepInitItems.h (142) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtCaepInstanceData.h (135) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtCaepSupportData.h (83) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtPwpInitItems.h (68) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtPwpPluginInfo.h (75) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtPwpVersions.h (64) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/runtimeWrite.c (439) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/runtimeWrite_orig.txt (60) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcproj (511) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcproj.PWI.dgarlisch.user (121) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcxproj (307) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcxproj.filters (78) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcxproj.user (3) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/module.mk (239) ; - D MeshTools/PointwiseSU2plugin/src/plugins/C,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:16376,plugin,plugins,16376,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['plugin'],['plugins']
Modifiability,twiseSU2plugin/src/plugins/CaeUnsSU2/rtPwpInitItems.h (68) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtPwpPluginInfo.h (75) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtPwpVersions.h (64) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/runtimeWrite.c (439) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/runtimeWrite_orig.txt (60) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcproj (511) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcproj.PWI.dgarlisch.user (121) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcxproj (307) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcxproj.filters (78) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcxproj.user (3) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/module.mk (239) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/modulelocal-sample.mk (84) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtCaepInitItems.h (98) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtCaepInstanceData.h (135) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtCaepSupportData.h (89) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtPwpInitItems.h (68) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtPwpPluginInfo.h (75) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtPwpVersions.h (62) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/runtimeWrite.c (347) ; - D MeshTools/PointwiseSU2plugin/src/plugins/README.txt (272) ; - D MeshTools/PointwiseSU2plugin/src/plugins/module.mk (309) ; - D MeshTools/PointwiseSU2plugin/src/plugins/modulelocal.mk (8) ; - D MeshTools/PointwiseSU2plugin/src/plugins/pluginRegistry.h (29) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEP.c (228) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/apiCAEP.h (550) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/CAEP/a,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:17446,plugin,plugins,17446,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['plugin'],['plugins']
Modifiability,ugin/Makefile (304) ; - D MeshTools/PointwiseSU2plugin/PluginSDK.sln (64) ; - D MeshTools/PointwiseSU2plugin/PluginSDK.suo (0) ; - D MeshTools/PointwiseSU2plugin/depend.sh (28) ; - D MeshTools/PointwiseSU2plugin/mkplugin (10) ; - D MeshTools/PointwiseSU2plugin/mkplugin.bat (82) ; - D MeshTools/PointwiseSU2plugin/mkplugin.tcl (422) ; - D MeshTools/PointwiseSU2plugin/src/Pointwise/Win32Target.props (28) ; - D MeshTools/PointwiseSU2plugin/src/Pointwise/Win32Target.vsprops (24) ; - D MeshTools/PointwiseSU2plugin/src/Pointwise/Win64Target.props (28) ; - D MeshTools/PointwiseSU2plugin/src/Pointwise/Win64Target.vsprops (24) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/CaeStrXML.vcproj (511) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/CaeStrXML.vcproj.PWI.dgarlisch.user (121) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/CaeStrXML.vcxproj (307) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/CaeStrXML.vcxproj.filters (78) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/CaeStrXML.vcxproj.user (3) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/module.mk (239) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/modulelocal-sample.mk (84) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtCaepInitItems.h (98) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtCaepInstanceData.h (135) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtCaepSupportData.h (89) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtPwpInitItems.h (68) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtPwpPluginInfo.h (75) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtPwpVersions.h (62) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/runtimeWrite.c (443) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.sdf (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.sln (26) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.suo (0),MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:14200,plugin,plugins,14200,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['plugin'],['plugins']
Modifiability,ugins/shared/PWP/apiPWPUtils.h (1030) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/apiUtils.h (174) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/pwpPlatform.c (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/shared/PWP/pwpPlatform.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/site.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/structured.props (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/structured.vsprops (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/CaeTemplate.suo (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/CaeTemplate.vcproj (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/module.mk (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/modulelocal-sample.mk (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/rtCaepInitItems.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/rtCaepInstanceData.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/rtCaepSupportData.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/CAEP/runtimeWrite.c (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/PWP/rtPwpInitItems.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/PWP/rtPwpPluginInfo.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/templates/PWP/rtPwpVersions.h (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/unstructured.props (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/unstructured.vsprops (0) ; - D MeshTools/PointwiseSU2plugin_Instructions.txt (0) ; - I QuickStart/inv_NACA0012.cfg (0) ; - I README (0) ; - I SU2_CFD/include/SU2_CFD.hpp (0) ; - I SU2_CFD/include/definition_structure.hpp (0) ; - I SU2_CFD/include/fluid_model.hpp (0) ; - I SU2_CFD/include/fluid_model.inl (0) ; - I SU2_CFD/include/integration_structure.hpp (0) ; - I SU2_CFD/include/integration_structure.inl (0) ; - I SU2_CFD/include/iteration_structure.hpp (0) ; - I SU2_CFD/include/numerics_machine_learn,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:20047,plugin,plugins,20047,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['plugin'],['plugins']
Modifiability,"ult: o; configure:3597: checking whether we are using the GNU C++ compiler; configure:3616: g++ -c conftest.cpp >&5; configure:3616: $? = 0; configure:3625: result: yes; configure:3634: checking whether g++ accepts -g; configure:3654: g++ -c -g conftest.cpp >&5; configure:3654: $? = 0; configure:3695: result: yes; configure:3720: checking dependency style of g++; configure:3831: result: gcc3; configure:3921: checking for gcc; configure:3937: found /usr/bin/gcc; configure:3948: result: gcc; configure:3979: checking for C compiler version; configure:3988: gcc --version >&5; gcc (GCC) 4.4.6 20120305 (Red Hat 4.4.6-4); Copyright (C) 2010 Free Software Foundation, Inc.; This is free software; see the source for copying conditions. There is NO; warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. configure:3999: $? = 0; configure:3988: gcc -v >&5; Using built-in specs.; Target: x86_64-redhat-linux; Configured with: ../configure --prefix=/usr --mandir=/usr/share/man --infodir=/usr/share/info --with-bugurl=http://bugzilla.redhat.com/bugzilla --enable-bootstrap --enable-shared --enable-threads=posix --enable-checking=release --with-system-zlib --enable-__cxa_atexit --disable-libunwind-exceptions --enable-gnu-unique-object --enable-languages=c,c++,objc,obj-c++,java,fortran,ada --enable-java-awt=gtk --disable-dssi --with-java-home=/usr/lib/jvm/java-1.5.0-gcj-1.5.0.0/jre --enable-libgcj-multifile --enable-java-maintainer-mode --with-ecj-jar=/usr/share/java/eclipse-ecj.jar --disable-libjava-multilib --with-ppl --with-cloog --with-tune=generic --with-arch_32=i686 --build=x86_64-redhat-linux; Thread model: posix; gcc version 4.4.6 20120305 (Red Hat 4.4.6-4) (GCC) ; configure:3999: $? = 0; configure:3988: gcc -V >&5; gcc: '-V' option must have argument; configure:3999: $? = 1; configure:3988: gcc -qversion >&5; gcc: unrecognized option '-qversion'; gcc: no input files; configure:3999: $? = 1; configure:4003: checking whether we are using the GNU C compiler; co",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:5816,config,configure,5816,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,1,['config'],['configure']
Modifiability,"ure:3343: $? = 0; configure:3332: g++ -V >&5; g++: '-V' option must have argument; configure:3343: $? = 1; configure:3332: g++ -qversion >&5; g++: unrecognized option '-qversion'; g++: no input files; configure:3343: $? = 1; configure:3363: checking whether the C++ compiler works; configure:3385: g++ conftest.cpp >&5; configure:3389: $? = 0; configure:3437: result: yes; configure:3440: checking for C++ compiler default output file name; configure:3442: result: a.out; configure:3448: checking for suffix of executables; configure:3455: g++ -o conftest conftest.cpp >&5; configure:3459: $? = 0; configure:3481: result: ; configure:3503: checking whether we are cross compiling; configure:3511: g++ -o conftest conftest.cpp >&5; configure:3515: $? = 0; configure:3522: ./conftest; configure:3526: $? = 0; configure:3541: result: no; configure:3546: checking for suffix of object files; configure:3568: g++ -c conftest.cpp >&5; configure:3572: $? = 0; configure:3593: result: o; configure:3597: checking whether we are using the GNU C++ compiler; configure:3616: g++ -c conftest.cpp >&5; configure:3616: $? = 0; configure:3625: result: yes; configure:3634: checking whether g++ accepts -g; configure:3654: g++ -c -g conftest.cpp >&5; configure:3654: $? = 0; configure:3695: result: yes; configure:3720: checking dependency style of g++; configure:3831: result: gcc3; configure:3921: checking for gcc; configure:3937: found /usr/bin/gcc; configure:3948: result: gcc; configure:3979: checking for C compiler version; configure:3988: gcc --version >&5; gcc (GCC) 4.4.6 20120305 (Red Hat 4.4.6-4); Copyright (C) 2010 Free Software Foundation, Inc.; This is free software; see the source for copying conditions. There is NO; warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. configure:3999: $? = 0; configure:3988: gcc -v >&5; Using built-in specs.; Target: x86_64-redhat-linux; Configured with: ../configure --prefix=/usr --mandir=/usr/share/man --infodir=/usr/share/info --wit",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:4824,config,configure,4824,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,4,['config'],['configure']
Modifiability,ure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for memory.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for strings.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for inttypes.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for stdint.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for unistd.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4970: checking size of short int; configure:4975: gcc -o conftest -g -O2 conftest.c >&5; configure:4975: $? = 0; configure:4975: ./conftest; configure:4975: $? = 0; configure:4989: result: 2; configure:5003: checking size of int; configure:5008: gcc -o conftest -g -O2 conftest.c >&5; configure:5008: $? = 0; configure:5008: ./conftest; configure:5008: $? = 0; configure:5022: result: 4; configure:5036: checking size of unsigned int; configure:5041: gcc -o conftest -g -O2 conftest.c >&5; configure:5041: $? = 0; configure:5041: ./conftest; configure:5041: $? = 0; configure:5055: result: 4; configure:5069: checking size of long int; configure:5074: gcc -o conftest -g -O2 conftest.c >&5; configure:5074: $? = 0; configure:5074: ./conftest; configure:5074: $? = 0; configure:5088: result: 8; configure:5102: checking size of float; configure:5107: gcc -o conftest -g -O2 conftest.c >&5; configure:5107: $? = 0; configure:5107: ./conftest; configure:5107: $? = 0; configure:5121: result: 4; configure:5135: checking size of double; configure:5140: gcc -o conftest -g -O2 conftest.c >&5; configure:5140: $? = 0; configure:5140: ./conftest; configure:5140: $? = 0; configure:5154: result: 8; configure:516,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:11072,config,configure,11072,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,4,['config'],['configure']
Modifiability,"ure:5409: result: no; configure:5409: checking for X11/Intrinsic.h; configure:5409: result: no; configure:5721: checking for /gshare/soft/code_saturne/4.0.0/prod/cgnslib_3.2.1/lib/libcgns.a; configure:5735: result: yes; configure:5755: checking for /gshare/soft/code_saturne/4.0.0/prod/cgnslib_3.2.1/include/cgnslib.h; configure:5769: result: yes; configure:6815: checking that generated files are newer than configure; configure:6821: result: done; configure:6952: creating ./config.status. ## ---------------------- ##; ## Running config.status. ##; ## ---------------------- ##. This file was extended by SU2 config.status 4.1.0, which was; generated by GNU Autoconf 2.69. Invocation command line was. CONFIG_FILES = ; CONFIG_HEADERS = ; CONFIG_LINKS = ; CONFIG_COMMANDS = ; $ ./config.status . on master. config.status:875: creating externals/tecio/Makefile; config.status:875: creating externals/metis/Makefile; config.status:875: creating externals/parmetis/Makefile; config.status:875: creating Makefile; config.status:875: creating externals/Makefile; config.status:875: creating Common/lib/Makefile; config.status:875: creating SU2_CFD/obj/Makefile; config.status:875: creating SU2_DOT/obj/Makefile; config.status:875: creating SU2_MSH/obj/Makefile; config.status:875: creating SU2_DEF/obj/Makefile; config.status:875: creating SU2_SOL/obj/Makefile; config.status:875: creating SU2_GEO/obj/Makefile; config.status:875: creating SU2_PY/Makefile; config.status:1047: executing depfiles commands; configure:8181: result:. -------------------------------------------------------------------------; | ___ _ _ ___ |; | / __| | | |_ ) Release 4.1.0 'Cardinal' |; | \__ \ |_| |/ / |; | |___/\___//___| Suite |; | |; -------------------------------------------------------------------------; | SU2 Lead Dev.: Dr. Francisco Palacios, Francisco.D.Palacios@boeing.com|; | Dr. Thomas D. Economon, economon@stanford.edu |; -------------------------------------------------------------------------; | SU2 D",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:16185,config,config,16185,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,1,['config'],['config']
Modifiability,"using SoA in the gradient and limiters routines let me tell you there is a way to have the best of both worlds, enter the *_array of structures of arrays_* or as I like to call it zig zag storage, aka a right mess.; Imagine an AoS of short arrays of SIMD length, e.g. `{ {u0 u1 u2 u3} {v0 ... v3} {w0 ... w3} {u4 u5 u6 u7} ... }` with that it is possible to fully vectorize point loops as the first index (iPoint) is contiguous in groups of SIMD length and when looping along variables and dimensions in edge loops the stride is small enough (equal to SIMD length) to trigger hardware prefetching.; The catch is that we need even more integer arithmetic and so we really need iterators to amortise that cost, there is also the drawback that scalar usage of such a container would be terrible. **For these reasons I think we should sacrifice ultimate performance and keep node data in AoS storage.**. The major impact on gradients and limiters is the way the code is written, to vectorize the computation we need to compute the gradient into a local variable and then ""transpose"" it when storing it, i.e.; ```c++; FltVec phiI[MAXNVAR], gradI[MAXNVAR][MAXNDIM];; ...; for(size_t iVar=0; iVar<nVar; ++iVar); {; auto flux = weight*(phiI[iVar]+phi.getVec(jPoint,iVar));. for(size_t iDim=0; iDim<nDim; ++iDim); gradI[iVar][iDim] += a_ij[iDim]*flux;; }; }. for(size_t iVar=0; iVar<nVar; ++iVar); for(size_t iDim=0; iDim<nDim; ++iDim); for(size_t k=0; k<SIMDLEN; ++k); grad(iPoint+k,iVar,iDim) = gradI[iVar][iDim][k];; ...; ```; Similarly when computing the gradient we need to first fetch/transpose it to be able to vectorize subsequent computations; ```c++; FltVec gradI[MAXNVAR][MAXNDIM];. for(size_t iVar=0; iVar<nVar; ++iVar); for(size_t iDim=0; iDim<nDim; ++iDim); for(size_t k=0; k<SIMDLEN; ++k); gradI[iVar][iDim][k] = grad(iPoint+k,iVar,iDim);; ...; ```; Performance wise this is actually better than the SoA version (4% on gradients, 35% on limiters) as it also benefits from better locality, and i",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-535977206:13804,variab,variable,13804,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206,1,['variab'],['variable']
Modifiability,wiseSU2plugin/src/Pointwise/Win64Target.vsprops (24) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/CaeStrXML.vcproj (511) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/CaeStrXML.vcproj.PWI.dgarlisch.user (121) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/CaeStrXML.vcxproj (307) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/CaeStrXML.vcxproj.filters (78) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/CaeStrXML.vcxproj.user (3) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/module.mk (239) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/modulelocal-sample.mk (84) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtCaepInitItems.h (98) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtCaepInstanceData.h (135) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtCaepSupportData.h (89) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtPwpInitItems.h (68) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtPwpPluginInfo.h (75) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/rtPwpVersions.h (62) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeStrXML/runtimeWrite.c (443) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.sdf (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.sln (26) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.suo (0) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcproj (511) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcxproj (307) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcxproj.filters (78) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/CaeUnsSU2.vcxproj.user (3) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/UpgradeLog.XML (47) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_UpgradeReport_Files/UpgradeReport.css (207) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/_U,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:14766,plugin,plugins,14766,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['plugin'],['plugins']
Modifiability,wiseSU2plugin/src/plugins/CaeUnsSU2/rtCaepInitItems.h (142) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtCaepInstanceData.h (135) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtCaepSupportData.h (83) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtPwpInitItems.h (68) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtPwpPluginInfo.h (75) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/rtPwpVersions.h (64) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/runtimeWrite.c (439) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsSU2/runtimeWrite_orig.txt (60) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcproj (511) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcproj.PWI.dgarlisch.user (121) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcxproj (307) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcxproj.filters (78) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/CaeUnsXML.vcxproj.user (3) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/module.mk (239) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/modulelocal-sample.mk (84) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtCaepInitItems.h (98) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtCaepInstanceData.h (135) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtCaepSupportData.h (89) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtPwpInitItems.h (68) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtPwpPluginInfo.h (75) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/rtPwpVersions.h (62) ; - D MeshTools/PointwiseSU2plugin/src/plugins/CaeUnsXML/runtimeWrite.c (347) ; - D MeshTools/PointwiseSU2plugin/src/plugins/README.txt (272) ; - D MeshTools/PointwiseSU2plugin/src/plugins/module.mk (309) ; - D MeshTools/PointwiseSU2plugin/src/plugins/modulelocal.mk (8) ; - D MeshTools/PointwiseSU2plug,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:17205,plugin,plugins,17205,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['plugin'],['plugins']
Modifiability,xcbkptlist (0) ; - I SU2_IDE/Xcode/SU2_CFD.xcodeproj/xcuserdata/fpalacios.xcuserdatad/xcschemes/SU2_CFD.xcscheme (0) ; - I SU2_IDE/Xcode/SU2_DEF.xcodeproj/project.pbxproj (0) ; - I SU2_IDE/Xcode/SU2_DOT.xcodeproj/project.xcworkspace/xcshareddata/SU2_DOT.xccheckout (0) ; - I SU2_IDE/Xcode/SU2_GEO.xcodeproj/project.xcworkspace/xcshareddata/SU2_GEO.xccheckout (0) ; - I SU2_IDE/Xcode/SU2_MSH.xcodeproj/project.pbxproj (0) ; - D SU2_IDE/Xcode/SU2_PRT.xcodeproj/fpalacios.mode1v3 (0) ; - D SU2_IDE/Xcode/SU2_PRT.xcodeproj/fpalacios.pbxuser (0) ; - D SU2_IDE/Xcode/SU2_PRT.xcodeproj/project.pbxproj (0) ; - D SU2_IDE/Xcode/SU2_PRT.xcodeproj/project.xcworkspace/contents.xcworkspacedata (0) ; - D SU2_IDE/Xcode/SU2_PRT.xcodeproj/project.xcworkspace/xcshareddata/SU2_DDC.xccheckout (0) ; - I SU2_IDE/Xcode/SU2_SOL.xcodeproj/project.pbxproj (0) ; - I SU2_IDE/Xcode/SU2_SOL.xcodeproj/xcuserdata/fpalacios.xcuserdatad/xcschemes/SU2_SOL.xcscheme (0) ; - I SU2_MSH/include/SU2_MSH.hpp (0) ; - I SU2_MSH/obj/Makefile.am (0) ; - I SU2_MSH/obj/Makefile.in (0) ; - I SU2_MSH/src/SU2_MSH.cpp (0) ; - D SU2_PRT/bin/.gitignore (0) ; - D SU2_PRT/include/SU2_PRT.hpp (0) ; - D SU2_PRT/obj/Makefile.am (0) ; - I SU2_PRT/obj/Makefile.in (0) ; - D SU2_PRT/src/SU2_PRT.cpp (0) ; - D SU2_PY/2DChannel.py (0) ; - D SU2_PY/3DChannel.py (0) ; - I SU2_PY/Makefile.am (0) ; - I SU2_PY/Makefile.in (0) ; - I SU2_PY/SU2/**init**.py (0) ; - I SU2_PY/SU2/eval/design.py (0) ; - I SU2_PY/SU2/eval/functions.py (0) ; - I SU2_PY/SU2/eval/gradients.py (0) ; - I SU2_PY/SU2/io/config.py (0) ; - I SU2_PY/SU2/io/config_options.py (0) ; - I SU2_PY/SU2/io/data.py (0) ; - I SU2_PY/SU2/io/filelock.py (0) ; - I SU2_PY/SU2/io/redirect.py (0) ; - I SU2_PY/SU2/io/state.py (0) ; - I SU2_PY/SU2/io/tools.py (0) ; - I SU2_PY/SU2/mesh/adapt.py (0) ; - I SU2_PY/SU2/mesh/tools.py (0) . Patch Links:; - https://github.com/su2code/SU2/pull/174.patch; - https://github.com/su2code/SU2/pull/174.diff; —; Reply to this email directly or view it on GitHub.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:27379,config,config,27379,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,2,"['adapt', 'config']","['adapt', 'config']"
Modifiability,ypes.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for stdint.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4954: checking for unistd.h; configure:4954: gcc -c -g -O2 conftest.c >&5; configure:4954: $? = 0; configure:4954: result: yes; configure:4970: checking size of short int; configure:4975: gcc -o conftest -g -O2 conftest.c >&5; configure:4975: $? = 0; configure:4975: ./conftest; configure:4975: $? = 0; configure:4989: result: 2; configure:5003: checking size of int; configure:5008: gcc -o conftest -g -O2 conftest.c >&5; configure:5008: $? = 0; configure:5008: ./conftest; configure:5008: $? = 0; configure:5022: result: 4; configure:5036: checking size of unsigned int; configure:5041: gcc -o conftest -g -O2 conftest.c >&5; configure:5041: $? = 0; configure:5041: ./conftest; configure:5041: $? = 0; configure:5055: result: 4; configure:5069: checking size of long int; configure:5074: gcc -o conftest -g -O2 conftest.c >&5; configure:5074: $? = 0; configure:5074: ./conftest; configure:5074: $? = 0; configure:5088: result: 8; configure:5102: checking size of float; configure:5107: gcc -o conftest -g -O2 conftest.c >&5; configure:5107: $? = 0; configure:5107: ./conftest; configure:5107: $? = 0; configure:5121: result: 4; configure:5135: checking size of double; configure:5140: gcc -o conftest -g -O2 conftest.c >&5; configure:5140: $? = 0; configure:5140: ./conftest; configure:5140: $? = 0; configure:5154: result: 8; configure:5168: checking size of void *; configure:5173: gcc -o conftest -g -O2 conftest.c >&5; configure:5173: $? = 0; configure:5173: ./conftest; configure:5173: $? = 0; configure:5187: result: 8; configure:5409: checking X11/Intrinsic.h usability; configure:5409: gcc -c -g -O2 conftest.c >&5; conftest.c:61:27: error: X11/Intrinsic.h: No such file or directory; configure:5409: $? = 1; configure: failed program w,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:11473,config,configure,11473,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,4,['config'],['configure']
Performance," be transformed into a short array of matrices, the result of that is code like the above that explicitly manipulates the lanes of our SIMD type, such code can be completely hidden inside CSysMatrix which is good because a 4x4 vectorized transpose and matrix update looks like this; ```c++; // block j, subs from jj and goes to ij; T0 = blk_j[ k ].unpackLo(blk_j[k+1]); T1 = blk_j[ k ].unpackHi(blk_j[k+1]);; T2 = blk_j[k+2].unpackLo(blk_j[k+3]); T3 = blk_j[k+2].unpackHi(blk_j[k+3]);. C0 = T0.widePermuteLo(T2); C1 = T1.widePermuteLo(T3);; C2 = T0.widePermuteHi(T2); C3 = T1.widePermuteHi(T3);. (Array4d(&bjj[0][k])-C0).store(&bjj[0][k]);; (Array4d(&bjj[1][k])-C1).store(&bjj[1][k]);; (Array4d(&bjj[2][k])-C2).store(&bjj[2][k]);; (Array4d(&bjj[3][k])-C3).store(&bjj[3][k]);. C0.store(&bij[0][k]); C1.store(&bij[1][k]);; C2.store(&bij[2][k]); C3.store(&bij[3][k]);; ```; I am showing this because it represents a readability worst case in terms of manipulating SIMD types, we might end up with one or two of these to get the best performance possible but they will always be encapsulated and deep in kernel-type areas of SU2 that are almost never touched. ## Conclusions; - Over 45% faster CSysMatrix updates by mapping off-diagonal blocks to edges and diagonal blocks to points.; - Colouring is the best strategy for hybrid parallelism of compute-heavy edge loops and matrix updates as it interleaves compute and memory operations.; - AoS storage should be kept to avoid significant loss of performance in compute-light edge loops due to poor locality of SoA storage.; - Major implication of AoS is on point loops where some data needs to be fetched (transposed) into local variables for effective vectorization.; - An intermediate storage scheme, AoSoA, can provide both good locality and vectorization of point loops, however it requires that data be accessed via special iterators and scalar code based on it would have poor performance. Next I will try to estimate how much we can gain for a ""rea",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-535977206:16548,perform,performance,16548,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206,1,['perform'],['performance']
Performance," case, we would have something along the lines of: . a) NACA0012; i) 113 x 33; ii) 225 x 65 ; iii) 449 x 129; iv) ... This way we have a family of meshes and configuration files that are specifically built for the purpose of validating the code and comparing with other solvers. I might be useful to compress meshes that are larger than a certain size (say 10MB). We should also put a limit on the size of a single mesh that the repository can handle (say 50MB?). . Within the home directory, the README file should list all the cases in the repository, who the custodian of the test case is (person with meshes in case the meshes are too large), and which version it was last run on. . I thought about splitting it up into Verification cases and Validation cases, but I thought it would be more informative and intuitive to split up according to the physics of the simulations. My thinking might be limited because that's how I have seen the TestCases folder organized, so any other suggestions are welcome. I think it is imperative that this is accompanied with a section on the SU2 website that showcases just the results of the validation test cases (grid convergence studies, residual reductions etc) and links to the v&v repo appropriately. This way, if people are just inquisitive about SU2's performance, they can get a quick snapshot of the results, without the need to run the cases themselves. . I also wanted to broach the topic of convergence here. Would it be a good idea to standardize the termination criteria wherever possible? For example, in the NACA0012 case we can ensure that residuals are reduced by 8 orders of magnitude for all meshes. Or for the ONERAM6, we use Cauchy convergence and make sure the C_L is converged to 6 orders of magnitude. This would have to be flexible since the same level of convergence might not apply to all the cases in the repository. But for within a test case, I think it would be good to use the same convergence criteria for a family of meshes.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/581#issuecomment-426026053:1925,perform,performance,1925,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-426026053,1,['perform'],['performance']
Performance," per rank participates in the message passing, I have no experience here though so this might be a bad strategy, idk. **Back to business:**; I went silent for a bit because in prototyping a typical residual computation and matrix update loop I made some realisations that made me go back to the drawing board regarding data structures, and eventually back to square 0. . ## Parallel strategy for flux computation; Because significant computation is required to obtain each edge's flux, it does not make sense to attempt a ""point-loop"" strategy (which would double the effort).; However, one can either use colouring to avoid the race conditions that would result from updating the residual of cells i and j, or store the edge fluxes and then, on a second point-loop perform the summation of fluxes for each cell, with the direction being accounted by the same adjacency information used in the point-loop GG gradient computation.; If we consider only the update of residuals the two strategies are fairly equivalent performance wise, the tie breaker is the matrix updates. ## Matrix Updates; By this I mean the `addBlock`, `subBlock` we do (two times each) to update diagonal and off-diagonal blocks for each edge.; Here is a dummy numerics loop that does nothing else but setting blocks in the matrix (with colouring).; ```c++; void testLoop1(const vector<size_t>& colorStart,; const vector<size_t>& edgeIdx,; const vector<pair<size_t,size_t> >& connectivity,; double** blk_i, double** blk_j,; SparseMatrix& matrix); {; matrix.setZero();. for(size_t color=0; color<colorStart.size()-1; ++color); #pragma omp parallel for schedule(dynamic,CHUNK_SIZE); for(size_t k=colorStart[color]; k<colorStart[color+1]; ++k); {; size_t iEdge = edgeIdx[k];; size_t iPoint = connectivity[iEdge].first;; size_t jPoint = connectivity[iEdge].second;. matrix.addBlock(iPoint, iPoint, blk_i);; matrix.addBlock(iPoint, jPoint, blk_j);. matrix.subBlock(jPoint, jPoint, blk_j);; matrix.subBlock(jPoint, iPoint, blk_i);; }; }",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-535977206:1221,perform,performance,1221,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206,1,['perform'],['performance']
Performance," simd-loops in sight, in good C++ fashion that trickery has been encapsulated in a ""simd-friendly"" class.; Such a class can look something like this:; ```C++; template<class T, size_t N>; class Array; {; #define FOREACH for(size_t k=0; k<N; ++k); public:; enum : size_t {Size = N};; enum : size_t {Align = N*sizeof(T)};; private:; // fixed size and aligned array of internal data, naturally maps to a SIMD register; alignas(Align) T vals_[N];; /*; * Some helper methods go here; */; public:; // **** CONSTRUCTORS **** //; // We want to be able to construct this type from single scalars,; // a memory location from which we LOAD data,; // or a memory location and some offsets from which we GATHER data.; // In addition to the ""normal"" constructors. // scalar broadcasting ctor; STRONGINLINE Array(T x) {bcast(x);}. // loading ctor; STRONGINLINE Array(const T* ptr); {; #pragma omp simd aligned(ptr:Align); FOREACH vals_[k] = ptr[k];; }; // gathering ctor; template<class U>; STRONGINLINE Array(const T* base_ptr, const U& offsets); {; #pragma omp simd; FOREACH vals_[k] = base_ptr[offsets[k]];; }; /*; * Other traditional constructors (default, copy-ctor, move-ctor, etc) go here; */. // **** ACCESSORS **** //; STRONGINLINE T& operator[] (size_t k) {return vals_[k];}; STRONGINLINE T operator[] (size_t k) const {return vals_[k];}. // **** MATH OPERATORS **** //; STRONGINLINE Array& operator= (const Array& rhs); {; #pragma omp simd; FOREACH vals_[k] = rhs.vals_[k];; return *this;; }. STRONGINLINE Array& operator+= (const Array& rhs); {; #pragma omp simd; FOREACH vals_[k] += rhs.vals_[k];; return *this;; }; STRONGINLINE Array operator+ (const Array& rhs) const { return Array(*this)+=rhs; }; ; /*; * Many other operators go here.; */; };. // Common math function overloads; template<class T>; STRONGINLINE T vmax(const T& a, const T& b); {; T res;; #pragma omp simd; for(size_t k=0; k<T::Size; ++k); res[k] = (a[k]>b[k])? a[k] : b[k];; return res;; }. #undef FOREACH; ```; There are other (bet",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-530328194:7464,load,loading,7464,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530328194,1,['load'],['loading']
Performance," the instructions) processing multiple edges at the same time can therefore result in race conditions where multiple threads try to update the data of the same point.; There are 3 ways to address this:; - **Coloring**: Edges are colored (grouped) such that edges of the same color have no risk of race conditions, i.e. each endpoint is referenced only once per color (this definition gives you the basis of a greedy algorithm to color edges).; - **Scatter to gather transformations**: Edge quantities (e.g. fluxes) are computed and stored on one pass (i.e. we read from 2 locations and write to 1), on a second pass, over points, we reduce (e.g. sum) the edge quantities for each point, again a gather access pattern. It may also be possible to convert the entire algorithm to a loop over points instead of edges.; - **Atomic operations or locks**: Here when a thread wants to write to a memory location it either needs to do so atomically (this is essentially an operations that always goes through main memory and forces cache coherency) or it needs to acquire a *lock* for the point it is writing to, if it fails to acquire the *lock* (because another thread has it) it needs to wait. None of these is without drawbacks.; - **Coloring** reduces temporal locality, edges are sorted in increasing order of the point indices to reduce cache misses, this means small groups of contiguous edges will share the same ""iPoint"", coloring single edges destroys this. Furthermore coloring either requires edges to be re-sorted by color, or if the edge indices of each color are instead kept in arrays, performance will suffer due to increased indirection which confounds the hardware pre-fetcher.; This can be mitigated to some extent by coloring groups of edges, groups of edges of the same color can be processed simultaneously, but within each group edges need to be processed serially. However grouping will reduce how much parallelism can be exploited within each color.; - **Gather to scatter** will in",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-529662724:4852,cache,cache,4852,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-529662724,1,['cache'],['cache']
Performance," to SU2 in one of our branches. >@pcarruscag; >(...) being able to use PETSc or HYPRE would be interesting as it would give us access to AMG, and @talbring 's branch feature_template_linear_solver would make such an integration compatible with AD. (...). >@EduardoMolina; >(...) When Brian (@bmunguia ) and I mentioned PETSc, it was an idea to try a different Newton-Krylov (with preconditioner) library in order to improve the convergence of SU2.; Since the slow convergence of the SU2-FV is the main feedback that I received from other users from industry and academia, I think it worth try an external library and evaluate the performance. (...). >@pcarruscag ; >(...) That is something I am also interested in as for some of my structural cases the current linear solvers simply do not converge. (...). >@economon ; >I would add one practical comment for consideration: it is worth checking whether the main restriction we have is related to approximations in the Jacobian that limit the effective CFL we can use or whether the convergence of the linear solver itself is a problem (speed or complete lack of convergence). A quick test without resorting to another library is to increase the fill-in for ILU-preconditioned GMRES, which is very expensive/slow but should converge difficult problems, and to check how high we can take the CFL when allowing each nonlinear iteration to converge to a tight tolerance in the linear solver, say 1e-14 (you can output the linear solver residuals to verify convergence). If we can take the CFL higher with a more performant linear solver, then it could be worth the effort to try other options.; >If the CFL must remain low for stability, then perhaps we should look at the quality of the Jacobians we construct to see if we can improve, or even try exact Jacobians with AD if we can afford it. A more advanced CFL ramping strategy could also be helpful here to get us closer to a solution before trying to aggressively converge. I think that is everyone.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/648#issuecomment-460853218:3877,perform,performant,3877,https://su2code.github.io,https://github.com/su2code/SU2/issues/648#issuecomment-460853218,1,['perform'],['performant']
Performance,"# Import issues. In Python 3, relative import behaviour changes.; In Python 2, ""import module"" loads first local module, then system module. In Python 3, it is the opposite. ## Import patterns in SU2 code. If we consider, to simplify, these generic packages:; `package1/p1m1.py`; `package1/p1m2.py`; `package1/__init__.py`. `package2/p2m1.py`; `package2/__init__.py`. In SU2 code we find these patterns:. **Pattern 1**; `package1/__init__.py`; contains. ``` python; import p1m1; import p1m2; ```. These instructions are useless as it is the common behaviour of package.; If a `__init__.py` is defined, I can do from package1 import p1m1 or import package1.p1m1. Do you know why this happens ? Is there an historical reason or other ?; For example, in [`SU2_PY/SU2/__init__.py`](https://github.com/su2code/SU2/blob/master/SU2_PY/SU2/__init__.py) or [`SU2_PY/SU2/mesh/__init__.py`](https://github.com/su2code/SU2/blob/master/SU2_PY/SU2/mesh/__init__.py). **Pattern 2**; `package1/__init__.py`; contains. ``` python; from p1m1 import f; ```. **Pattern 3**; `package1/p1m1.py`; contains. ``` python; from ..p1m2 import f; ```. **Pattern 4**. ``` python; import cPickle as pickle; ```. ## Solution. I suggest these solutions:. **Pattern 1**; delete imports. **Pattern 2**; replace `from p1m1 import f` with `from .p1m1 import f` . See also next solution. **Pattern 3**. This is OK. Another approach is to always use absolute imports, for example. ``` python; from ..p1m2 import f; ```. becomes. ``` python; from package1.p1m2 import f; ```. Result is the same except that it is recommended in [PEP8](https://www.python.org/dev/peps/pep-0008/#id20) but first approach is ok too.; I can do it if you want. **Pattern 4**; Py3 pickle now manage both accelerated cPickle and pure python pickle; See https://docs.python.org/3/whatsnew/3.0.html#library-changes, 4th item.; So replace it with. ``` python; if sys.version_info.major > 2:; # Py3 pickle now manage both accelerated cPickle and pure python pickle; # S",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/246#issuecomment-197397273:95,load,loads,95,https://su2code.github.io,https://github.com/su2code/SU2/issues/246#issuecomment-197397273,1,['load'],['loads']
Performance,"### Intro to SIMD; The ALU of modern CPU are capable of processing multiple elements of built-in types simultaneously by applying one instruction (e.g. add) to a register of those elements. Registers are at the very top of the memory hierarchy, for any computation to be performed data needs to be in registers.; An AVX register is 256 bits wide, that means 4 lanes of doubles or 8 of floats, AVX-512 (available in Xeon-Phi and SkylakeX processors) doubles the size. By GPU standards these are rookie numbers. **Why should we care about SIMD?**; Because it is the only way to use the whole silicon, by and large vector instructions have the same latency and throughput of their scalar versions, therefore speedups proportional to the number of SIMD lanes are possible in compute-bound code.; As we saw in #716 there is some of that in the numerics, do not expect 4x speed-ups though, low order unstructured FVM is known to be bandwidth-bound, vectorization helps a bit there too (instructions are also data that needs to travel to the CPU) (maybe for explicit schemes and 8 SIMD lanes, maybe). **Relation with data structures**; There is only one efficient way to move data between memory and registers, via `load` and `store` instructions (they do come in multiple flavors). That is, pointing to a memory location and reading or writing N elements of contiguous data.; It is not the only way, it is also possible to `gather` and `scatter` data. That is populating the register from non-contiguous locations and vice versa. This is about one order of magnitude slower, to the point where if the computations are very simple it may not pay-off to vectorize. **Relation with algorithms**; Some form of `gather` and `scatter` is required in unstructured CFD, which means SIMD has a price of admission. Some thought needs to go into designing algorithms that amortize that cost by maximizing the so called FLOP/Byte ratio, and mask the latency of those operations by being able to start computing as soon ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-529662724:271,perform,performed,271,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-529662724,3,"['latency', 'perform', 'throughput']","['latency', 'performed', 'throughput']"
Performance,"(GCC) 4.4.6 20120305 (Red Hat 4.4.6-4); Copyright (C) 2010 Free Software Foundation, Inc.; This is free software; see the source for copying conditions. There is NO; warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. configure:3343: $? = 0; configure:3332: g++ -v >&5; Using built-in specs.; Target: x86_64-redhat-linux; Configured with: ../configure --prefix=/usr --mandir=/usr/share/man --infodir=/usr/share/info --with-bugurl=http://bugzilla.redhat.com/bugzilla --enable-bootstrap --enable-shared --enable-threads=posix --enable-checking=release --with-system-zlib --enable-__cxa_atexit --disable-libunwind-exceptions --enable-gnu-unique-object --enable-languages=c,c++,objc,obj-c++,java,fortran,ada --enable-java-awt=gtk --disable-dssi --with-java-home=/usr/lib/jvm/java-1.5.0-gcj-1.5.0.0/jre --enable-libgcj-multifile --enable-java-maintainer-mode --with-ecj-jar=/usr/share/java/eclipse-ecj.jar --disable-libjava-multilib --with-ppl --with-cloog --with-tune=generic --with-arch_32=i686 --build=x86_64-redhat-linux; Thread model: posix; gcc version 4.4.6 20120305 (Red Hat 4.4.6-4) (GCC) ; configure:3343: $? = 0; configure:3332: g++ -V >&5; g++: '-V' option must have argument; configure:3343: $? = 1; configure:3332: g++ -qversion >&5; g++: unrecognized option '-qversion'; g++: no input files; configure:3343: $? = 1; configure:3363: checking whether the C++ compiler works; configure:3385: g++ conftest.cpp >&5; configure:3389: $? = 0; configure:3437: result: yes; configure:3440: checking for C++ compiler default output file name; configure:3442: result: a.out; configure:3448: checking for suffix of executables; configure:3455: g++ -o conftest conftest.cpp >&5; configure:3459: $? = 0; configure:3481: result: ; configure:3503: checking whether we are cross compiling; configure:3511: g++ -o conftest conftest.cpp >&5; configure:3515: $? = 0; configure:3522: ./conftest; configure:3526: $? = 0; configure:3541: result: no; configure:3546: checking for suffix of ob",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:3753,tune,tune,3753,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,1,['tune'],['tune']
Performance,"(GCC) 4.4.6 20120305 (Red Hat 4.4.6-4); Copyright (C) 2010 Free Software Foundation, Inc.; This is free software; see the source for copying conditions. There is NO; warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. configure:3999: $? = 0; configure:3988: gcc -v >&5; Using built-in specs.; Target: x86_64-redhat-linux; Configured with: ../configure --prefix=/usr --mandir=/usr/share/man --infodir=/usr/share/info --with-bugurl=http://bugzilla.redhat.com/bugzilla --enable-bootstrap --enable-shared --enable-threads=posix --enable-checking=release --with-system-zlib --enable-__cxa_atexit --disable-libunwind-exceptions --enable-gnu-unique-object --enable-languages=c,c++,objc,obj-c++,java,fortran,ada --enable-java-awt=gtk --disable-dssi --with-java-home=/usr/lib/jvm/java-1.5.0-gcj-1.5.0.0/jre --enable-libgcj-multifile --enable-java-maintainer-mode --with-ecj-jar=/usr/share/java/eclipse-ecj.jar --disable-libjava-multilib --with-ppl --with-cloog --with-tune=generic --with-arch_32=i686 --build=x86_64-redhat-linux; Thread model: posix; gcc version 4.4.6 20120305 (Red Hat 4.4.6-4) (GCC) ; configure:3999: $? = 0; configure:3988: gcc -V >&5; gcc: '-V' option must have argument; configure:3999: $? = 1; configure:3988: gcc -qversion >&5; gcc: unrecognized option '-qversion'; gcc: no input files; configure:3999: $? = 1; configure:4003: checking whether we are using the GNU C compiler; configure:4022: gcc -c conftest.c >&5; configure:4022: $? = 0; configure:4031: result: yes; configure:4040: checking whether gcc accepts -g; configure:4060: gcc -c -g conftest.c >&5; configure:4060: $? = 0; configure:4101: result: yes; configure:4118: checking for gcc option to accept ISO C89; configure:4181: gcc -c -g -O2 conftest.c >&5; configure:4181: $? = 0; configure:4194: result: none needed; configure:4216: checking dependency style of gcc; configure:4327: result: gcc3; configure:4345: checking whether gcc and cc understand -c and -o together; configure:4376: gcc -c conft",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:6433,tune,tune,6433,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,1,['tune'],['tune']
Performance,"(Krylov solvers, sparse approximate factorizations, etc.) is relatively independent from what I have in mind.; Nevertheless being able to use PETSc or HYPRE would be interesting as it would give us access to AMG, and @talbring 's branch feature_template_linear_solver would make such an integration compatible with AD.; What I would like is to have a ""CMatrixDense"" class, to give concrete examples:; - For RBF interpolation the guy who worked on it before me implemented his own Cholesky and LU factorizations, matrix-matrix, matrix-vector routines, etc.; - @jayantmukho recently needed some eigenvector decomposition's for the uncertainty quantification feature.; - I imagine in some other places of the code similar routines were needed, for example small matrix inversion when computing gradients by weighted least squares (indeed what I need now is a QR decomposition). And, as an added bonus, I think some other areas of the code could be simplified / optimized by adopting a dense matrix format, for example:; - This snipped from the viscous numerics refactoring`for (iDim = 0; iDim < nDim; iDim++) {; TauElem[iDim] = 0.0;; for (jDim = 0; jDim < nDim; jDim++); TauElem[iDim] += tau[iDim][jDim]*UnitNormal[jDim];; }` would simply become `TauElem=tau*UnitNormal`; - Cumbersome allocations like `tau_jacobian_i = new su2double* [nDim];; for (iDim = 0; iDim < nDim; iDim++) {; tau_jacobian_i[iDim] = new su2double [nVar];; }` become `Matrix tau_jacobian_i(nDim,nVar);` and the cleanup is dealt with by the destructor of the object automatically. Now to answer some questions.; @juanjosealonso @erangit LAPACK and BLAS are indeed the standard, so much so that most (all?) newer libraries will call their routines behind the scenes.; However they considerably simplify the user interface by encapsulating the aforementioned construction/destruction and by exposing natural ways of manipulating the matrices, e.g. access entire rows, columns, blocks, etc.; Another issue with using BLAS routines is th",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/643#issuecomment-459653772:1157,optimiz,optimized,1157,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459653772,1,['optimiz'],['optimized']
Performance,"**Disclaimer**; The performance numbers that follow are based on simple implementations of the methods, I do not claim any of my implementations or choice of methods to be optimal. If you know better speak up.; The data is from the case used to benchmark #753 (see #716), it is by no means an extensive collection of different grid types. I will share code and data with anyone who wants to repeat the tests on the condition they post detailed results. With that out of the way :) ... ### Green-Gauss Gradients. This is the plain edge-loop version of the code with boundary contributions omitted for simplicity:; ```C++; void computeGradients(size_t nEdge,; size_t nPoint,; size_t nVar,; size_t nDim,; const vector<pair<size_t,size_t> >& connectivity,; const Matrix& area,; const vector<double>& volume,; const Matrix& phi,; VectorOfMatrix& grad); {; grad.setZero();. for(size_t iEdge=0; iEdge<nEdge; ++iEdge); {; size_t iPoint = connectivity[iEdge].first;; size_t jPoint = connectivity[iEdge].second;. for(size_t iVar=0; iVar<nVar; ++iVar); {; double phi_ave = 0.5*(phi(iPoint,iVar)+phi(jPoint,iVar));. for(size_t iDim=0; iDim<nDim; ++iDim); {; double flux = phi_ave*area(iEdge,iDim);. grad(iPoint,iVar,iDim) += flux;; grad(jPoint,iVar,iDim) -= flux;; }; }; }. for(size_t iPoint=0; iPoint<nPoint; ++iPoint); for(size_t iVar=0; iVar<nVar; ++iVar); for(size_t iDim=0; iDim<nDim; ++iDim); grad(iPoint,iVar,iDim) /= volume[iPoint];; }; ```; This is more or less what SU2 does with minor differences on how the edges (`connectivity`) and area are stored, there is no vectorization nor easy way to make the loop parallel, this will be the reference for execution times. Suppose now that due to a perfect storm the number of variables is 4, here is how with a few pragmas we get gcc to vectorize:; ```C++; template<size_t nVar>; void computeGradients_impl(size_t nEdge,; size_t nPoint,; size_t nDim,; const vector<pair<size_t,size_t> >& connectivity,; const Matrix& area,; const vector<double>& volume,; con",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-530328194:20,perform,performance,20,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530328194,1,['perform'],['performance']
Performance,"**SOLVED** see edit. Hello! I seem to remember that it used to be possible to get angle of attack in the history file? Is this still possible? I would like to be able to just pull the angle of attack out of the history file, along with the aero coeffs.; Context:; I have looked through the custom output document and the reference config file, and (perhaps I am secretly blind), but there does not seem to be a simple output group for it.; Reason I need it: performing analysis for fixed Cl, so angle of attack is useful information. At the moment I am getting probed data:; ```; CUSTOM_OUTPUTS='m_vel_x : Macro{VELOCITY_X};\; m_vel_y : Macro{VELOCITY_Y};\; vel_x1: Probe{$m_vel_x}[-15, -15];\; vel_y1: Probe{$m_vel_y}[-15, -15]'; ```; And just getting the tan(y/x) of the probed values for angle. This works well enough.; The other option I have is stripping the angle of attack out of the forced breakdown file, would prefer to not do, but can. EDIT:. **It can be pulled out of line 2 of flow.meta**",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/2138#issuecomment-1780159397:458,perform,performing,458,https://su2code.github.io,https://github.com/su2code/SU2/issues/2138#issuecomment-1780159397,1,['perform'],['performing']
Performance,"-images.githubusercontent.com/21182966/28308831-b937bf76-6ba7-11e7-9108-e8a2ab959b74.png). Then I noticed a difference in SENS_GEO (which is the second term of the upper equation, right?) between compressible and incompressible. . ![image](https://user-images.githubusercontent.com/21182966/28310143-bb28c42a-6bab-11e7-8c14-8409b6b12027.png). So if the scale is adjusting current step size the step of dC and SENS_GEO represents the second term, then the SENS_GEO would change when the scale is changed. But this is not the case for incompressible and compressible. . In short, the only noticeable change, due to scaling, occurs in deformation folder of DSN_002. But this is after the optimization step, which is really confusing. Scaling adjusts the current step size and because it can not find a sufficient decrease it is halving the dv_value. But then one should expect different values in the adjoint folder for different scale factors, right?. I hope you can use this information and can tell me whether it is a correct behavior of the optimizer. I should also note that I did not make use of constraints, just as in the test case. I read that the optimizer will switch from optimization procedure. I think this should not matter because of the test case. . I attached also the configure files (compressible (working, scale= 0.01) and incompressible (not working, scale =0.01)) and the mesh file, which is in both cases the same file. [compressible_cfg.txt](https://github.com/su2code/SU2/files/1155421/compressible_cfg.txt); [incompressible_cfg.txt](https://github.com/su2code/SU2/files/1155427/incompressible_cfg.txt); [mesh_300_su2.txt](https://github.com/su2code/SU2/files/1155430/mesh_300_su2.txt). I hope I provide enough information so that one can clarify the behavior of the optimizer. I also appreciate if one can tell me which variables have to be kept in mind. I really want to learn from this and if more information is needed, I really do not mind to provide it. Many thanks in adv",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/409#issuecomment-316018103:3553,optimiz,optimizer,3553,https://su2code.github.io,https://github.com/su2code/SU2/issues/409#issuecomment-316018103,1,['optimiz'],['optimizer']
Performance,"/21182966/28308831-b937bf76-6ba7-11e7-9108-e8a2ab959b74.png). Then I noticed a difference in SENS_GEO (which is the second term of the upper equation, right?) between compressible and incompressible. . ![image](https://user-images.githubusercontent.com/21182966/28310143-bb28c42a-6bab-11e7-8c14-8409b6b12027.png). So if the scale is adjusting current step size the step of dC and SENS_GEO represents the second term, then the SENS_GEO would change when the scale is changed. But this is not the case for incompressible and compressible. . In short, the only noticeable change, due to scaling, occurs in deformation folder of DSN_002. But this is after the optimization step, which is really confusing. Scaling adjusts the current step size and because it can not find a sufficient decrease it is halving the dv_value. But then one should expect different values in the adjoint folder for different scale factors, right?. I hope you can use this information and can tell me whether it is a correct behavior of the optimizer. I should also note that I did not make use of constraints, just as in the test case. I read that the optimizer will switch from optimization procedure. I think this should not matter because of the test case. . I attached also the configure files (compressible (working, scale= 0.01) and incompressible (not working, scale =0.01)) and the mesh file, which is in both cases the same file. [compressible_cfg.txt](https://github.com/su2code/SU2/files/1155421/compressible_cfg.txt); [incompressible_cfg.txt](https://github.com/su2code/SU2/files/1155427/incompressible_cfg.txt); [mesh_300_su2.txt](https://github.com/su2code/SU2/files/1155430/mesh_300_su2.txt). I hope I provide enough information so that one can clarify the behavior of the optimizer. I also appreciate if one can tell me which variables have to be kept in mind. I really want to learn from this and if more information is needed, I really do not mind to provide it. Many thanks in advance!. Floris van der Schuur",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/409#issuecomment-316018103:3665,optimiz,optimizer,3665,https://su2code.github.io,https://github.com/su2code/SU2/issues/409#issuecomment-316018103,3,['optimiz'],"['optimization', 'optimizer']"
Performance,"; phiR = phi.getVec(jPoint,iVar) + limiter.getVec(jPoint,iVar)*phiR;. FltVec flux = (phiL+phiR)*0.5;. for(size_t k=0; k<SIMDLEN; ++k) {; residual(iPoint[k],iVar) += flux[k];; residual(jPoint[k],iVar) -= flux[k];; }; }; ```; Note that at the end of the loop we need to de-swizzle the flux to update the multiple indexes references by iPoint and jPoint, which are now short arrays of integers (this operation can be moved to the container, akin to `getVec` but I show it here for clarity). **With SoA (aka column major storage) this code is 1.5 times slower than the scalar version.**. The reason for that is poor locality (of the spacial variety), as we loop through the number of variables and dimensions we are accessing the data in strides of nPoint, as the contiguous index is the first one so that we can perform vector read/writes when computing gradients and limiters.; With the scalar version the data for each point is contiguous which means on the first access we get whatever extra data is on the same cache line for free and subsequent accesses will be hardware prefetched since the stride is small (1 in this case). We lose all this with SoA storage. If we go back to arrays of structures (AoS, aka row major storage, basically what we have in #753) performance is only 9% worse (the code is identical). Those 9% are mostly due to increased integer arithmetic in the accesses to the data, on each call to `getVec` we resolve 4/8 row/column pairs into 1D indexes, while this calculation is vectorized, it seems to be less optimizable by compilers, for example this; ```c++; for(size_t iDim=0; iDim<nDim; ++iDim); phiL += grad.getVec(iPoint,iVar,iDim)*d_ij[iDim];; ```; gets compiled into this monstrosity; ```asm; .L13:; vpmuludq ymm0, ymm4, ymm1; vmovq xmm15, rax; vmovapd ymm6, ymm11; mov rdx, rax; vpbroadcastq ymm15, xmm15; sal rdx, 5; add rax, 1; vpaddq ymm0, ymm0, ymm2; vpsllq ymm0, ymm0, 32; vpaddq ymm0, ymm5, ymm0; vmovdqa YMMWORD PTR [rbp-240], ymm0; vpaddq ymm0, ymm3, ymm0; vmo",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-535977206:8727,cache,cache,8727,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206,1,['cache'],['cache']
Performance,";. #pragma omp simd; for(size_t k=0; k<blkSz; ++k); {; coeffs[bii+k] += blk_i[k]; coeffs[bij+k] = +blk_j[k];; coeffs[bji+k] = -blk_i[k]; coeffs[bjj+k] -= blk_j[k];; }; }; ```; This is **47% faster**, which for a memory bound task is massive!; Yes, this does increase the memory footprint a bit (makes CSysMatrix 4% larger for a 3D problem) but I can get that back by sharing sparsity patterns and maps across turbulence and bulk flow (I think @talbring was already working on this in the template linear solver branch he had started). We could also parallelize the matrix updates without colouring by setting only the off-diagonal coefficients and then setting the diagonal entries to the column sum.; It turns out that this is worse (by about 10%), maybe if the matrix were symmetric (row sum) but a column sum accesses blocks very far apart. Also we want to interleave compute and load/stores as much as possible to allow the CPU pipelining magic to mask the latency of the latter (even if it looks like you can only write the block after it is computed, CPU's have all kinds of buffers that allow the next loop iteration to begin while data is in flight). **Therefore colouring is the way to go.**. _Note: With vectorized numerics we insert blocks for 4 or 8 edges into the matrix at a time, the data for those inserts will be in a slightly weird format, which will make `SparseMatrix::updateBlocks` a bit harder on the eye, more on that later._. ## MUSCL Reconstruction; The MUSCL reconstruction, characteristic of upwind schemes, is the simplest building block to show the (negative) implications of storing the data as structures of arrays (SoA) on the performance of some operations.; Here is the most basic numerics you can think of, reconstruct and average (the dummy matrix loop was to benchmark the writes this is to benchmark the reads); ```c++; void computeResidual(size_t nVar,; size_t nDim,; const vector<size_t>& colorStart,; const vector<size_t>& edgeIdx,; const vector<pair<size_t,si",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-535977206:5021,load,load,5021,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206,2,"['latency', 'load']","['latency', 'load']"
Performance,"<nVar; ++iVar); {; FltVec phiL = 0.0;; FltVec phiR = 0.0;. for(size_t iDim=0; iDim<nDim; ++iDim); {; phiL += grad.getVec(iPoint,iVar,iDim)*d_ij[iDim];; phiR -= grad.getVec(jPoint,iVar,iDim)*d_ij[iDim];; }. phiL = phi.getVec(iPoint,iVar) + limiter.getVec(iPoint,iVar)*phiL;; phiR = phi.getVec(jPoint,iVar) + limiter.getVec(jPoint,iVar)*phiR;. FltVec flux = (phiL+phiR)*0.5;. for(size_t k=0; k<SIMDLEN; ++k) {; residual(iPoint[k],iVar) += flux[k];; residual(jPoint[k],iVar) -= flux[k];; }; }; ```; Note that at the end of the loop we need to de-swizzle the flux to update the multiple indexes references by iPoint and jPoint, which are now short arrays of integers (this operation can be moved to the container, akin to `getVec` but I show it here for clarity). **With SoA (aka column major storage) this code is 1.5 times slower than the scalar version.**. The reason for that is poor locality (of the spacial variety), as we loop through the number of variables and dimensions we are accessing the data in strides of nPoint, as the contiguous index is the first one so that we can perform vector read/writes when computing gradients and limiters.; With the scalar version the data for each point is contiguous which means on the first access we get whatever extra data is on the same cache line for free and subsequent accesses will be hardware prefetched since the stride is small (1 in this case). We lose all this with SoA storage. If we go back to arrays of structures (AoS, aka row major storage, basically what we have in #753) performance is only 9% worse (the code is identical). Those 9% are mostly due to increased integer arithmetic in the accesses to the data, on each call to `getVec` we resolve 4/8 row/column pairs into 1D indexes, while this calculation is vectorized, it seems to be less optimizable by compilers, for example this; ```c++; for(size_t iDim=0; iDim<nDim; ++iDim); phiL += grad.getVec(iPoint,iVar,iDim)*d_ij[iDim];; ```; gets compiled into this monstrosity; ```asm; .L13",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-535977206:8524,perform,perform,8524,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206,1,['perform'],['perform']
Performance,> @EvertBunschoten even if the performance isn't great this is a pretty small change so I think we can merge it. Do you have time to wrap it up and add a simple regression test?. I just added a test case and tutorial under the TestCases and Tutorials repo under the same branch name. I'm also writing a short tutorial on the SU2 website repo.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/2152#issuecomment-2271237145:31,perform,performance,31,https://su2code.github.io,https://github.com/su2code/SU2/pull/2152#issuecomment-2271237145,1,['perform'],['performance']
Performance,"> @kursatyurt Hello, thank you so much for the lead.; > ; > Our initial scope mostly involved writing our own kernels and I did explore some libraries at the start - I was planning on using CUSP as well but my main concern was its lack of being updated to the newly compatible versions of the toolkit. cuSolver and cuBLAS do exist, but I chose to go ahead with a ""simple"" kernel implementation to have more control. I also felt that if I could keep the block size of the grid in optimal territory then they could be just as fast as those options (please do correct me if my reading of the literature or the situation was incorrect). To learn the basics, it's a good idea, but for large-scale projects, I prefer using existing libraries if possible.; Those libraries generally exploit state-of-the-art solution like mixed-precision computing. A gaming GPU is not way faster than a good CPU in double precision, but way faster in single precision, most of them have 64:1 ratio, however server class GPU have 2:1 ratio. Also when available they use vendor libraries like cuBLAS or hipBLAS. It is always nice to have you only care about connection and somebody else handle the solver as performant as possible. In future probably they will provide more and more solvers and it will be automagically works. It is kind of light-weight too, not a huge dependency like Trilinos or PETSc. ; > ; > I was not aware of Ginkgo and I will surely give it a go and try to produce some comparative results. I am currently super busy for this month and will get to working on the code with some delay.; > ; > Again, thank you for the lead!. I can test on various GPUs (P100/V100/A100 and 4070Mobile) on single node multi-gpu etc.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/2346#issuecomment-2397803409:1183,perform,performant,1183,https://su2code.github.io,https://github.com/su2code/SU2/pull/2346#issuecomment-2397803409,1,['perform'],['performant']
Performance,"> Do I understand correctly that two gradients are always computed per iteration?; > Is there any downside to using the unweighted LS for viscous flux correction? Is the statement that this type of gradient is better for reconstruction based on your observations or is it one of those well known things?. Yes - the gradient for now is computed twice and stored separately for viscous flows with 2nd-order upwind. Could be combined into one loop eventually. It is known that weighted LSQ / GG is more accurate (see Mavriplis, ""Revisiting the Least-Squares Procedure for Gradient Reconstruction on Unstructured Meshes"" for instance). However, unweighted LSQ is known to be more robust.. so a good compromise is to use it only for the reconstruction step (which is more susceptible to robustness issues than the viscous term) and then use WLSQ or GG for all other gradients in the viscous flux/sources for accuracy. > Sometimes high CFL leads to limit-cycle oscillations of the residuals and the solution is to reduce it, is this something this controller can pick up?; > High CFL also makes the linear systems harder to solve and as Edwin pointed out _somewhere_ there is not much point going above reasonable values with weakly coupled turbulence. Do you think it would be reasonable to build in some feedback from the linear solver (e.g. it is taking too much time or did not converge -> drop the CFL)?. Yes, I would also like to couple it to the linear solver so that we can remove the need to tune that as well. Ideally the user will not need to adjust parameters. There are some things I am going to try for that..",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/790#issuecomment-531890295:1495,tune,tune,1495,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-531890295,1,['tune'],['tune']
Performance,"> Thanks for pointing that out. I dont think it is intentional. Maybe we can use this PR also to fix this ?. That depends on how atomic we want these PRs to be. This PR is largely a refactoring PR, and shouldn't change any underlying performance. But adding extra calculations on source terms and wall conditions might change the performance of the code. The two changes are completely compatible, so combining them wouldn't be hard. Nevertheless, I propose we keep these changes separate, so that the purpose of each PR is clear and easy to see. In my mind, two small PRs are easier to check and review than one large PR. @talbring @economon What do you think? One big PR or two small PRs?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/626#issuecomment-458177675:234,perform,performance,234,https://su2code.github.io,https://github.com/su2code/SU2/pull/626#issuecomment-458177675,2,['perform'],['performance']
Performance,"> There was a lot of talk about refactoring the shape optimization framework to be able to work completely in memory.; > I think the idea was not to have more drivers but simply to have more granularity such that you could manipulate the geometry from python (without writing it to files).; > We also wanted introspection, i.e. you could probe SU2 via python for what variables and functions are available.; > We also talked about having the projection step (DOT) included in CFD_AD so that you only need to worry about surface sensitivities, note that DEF is already part of CFD for forward mode AD.; > (talking does not go very far); > ; > If you want to lead this work, we can help you understand the inner workings. We meet every Wednesday at 4pm CET https://meet.jit.si/SU2_DevMeeting to discuss this type of issue. Thank you for the quick reply. The discussions you mention sound very promising, I would be glad to join tomorrow afternoon and learn more, so that I might contribute. One quick remark: I am aware that it is indeed possible to deform the mesh within `SU2_CFD`, I use this extensively for static aero-elastic analysis. However, I have not been able to have the deformed mesh be written to file at output (in SU2 or CGNS format). This is fine for aero-elastic updates (movement of the surface due to _structural displacements_), where it is sufficient to see the deformed mesh in the post-processing files. It becomes impractical though, for design updates (movement of the surface to due to _design displacements_, i.e. representing changes in the design variables) where the new mesh is a useful intermediate result. Even if this is just an issue in my configuration file, I think that a stand-alone driver or equivalent of `SU2_DEF` would remain useful. For each new set of updated design variables during shape optimisation, a single mesh deformation is sufficient to provide the new, updated jig geometry which all of the aerodynamic or aero-elastic analyses (one for each oper",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1262#issuecomment-818839696:54,optimiz,optimization,54,https://su2code.github.io,https://github.com/su2code/SU2/issues/1262#issuecomment-818839696,1,['optimiz'],['optimization']
Performance,"> You may want to remove the string based interface since it's known to be inneficient. When replacing the string-based with index-based look-up methods, the performance improves substantially. The figure below shows the average measured evaluation time (measured with chrono library) vs the number of output variables. It's clear that using index-based look-up methods results in reduced query time, as well as improved scaling. ![scaling_nVars](https://github.com/su2code/SU2/assets/38651601/31252439-ac6e-4f1b-82d4-e13a55d54c98)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/2214#issuecomment-1952521226:158,perform,performance,158,https://su2code.github.io,https://github.com/su2code/SU2/pull/2214#issuecomment-1952521226,1,['perform'],['performance']
Performance,">@bmunguia ; > @EduardoMolina and I have discussed this over the past few weeks and are also in favor of using an external library. I don't have a strong opinion on the library we choose, but he seems to be in favor of [PETSc](https://www.mcs.anl.gov/petsc/) from ANL, which has a 2-clause BSD license and is used by ADflow (formerly SUmb), among other solvers. Eduardo could probably provide more details.; > ; > Another one that's come up in our discussions is [HYPRE](https://computation.llnl.gov/projects/hypre-scalable-linear-solvers-multigrid-methods) from LLNL which has a GNU LGPL. >@juanjosealonso ; >(...) While PETSc is a wonderful library (and parallel), I would hesitate to use it as the solution for the problem that we are trying to solve: it is not the easiest thing to compile and it is most definitely not lightweight. If one also wanted to replace Krylov-space solvers and preconditioners in SU2 the PETSc might make more sense….but it still forces the developer to conform to their view of the world (including matrix setup and decomposition). (...). >@erangit; >I also support external libraries usage (no need to repeat the many advantages as it is well described above) but I think we should be very wary of portability issues. For instance in SUMB, PETSc was used for the Krylov solvers and more. While indeed it worked well and in parallel mode, each new implementation was a nightmare. LAPACK/BLAS package, on the other hand, provides a much easier implementation experience. Certainly, this is not the only consideration but it should be taken into account. Currently, resulting from the significant contributions of the members of this developers group, SU2 implementation works like a charm. I think we should strive to conserve this feature, especially if we aim at attracting more users and developers into the community. (...). >@vdweide; >(...) @bmunguia and @EduardoMolina, what type of application did you have in mind for PETSc? The only thing I can think of is a f",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/648#issuecomment-460853218:515,scalab,scalable-linear-solvers-multigrid-methods,515,https://su2code.github.io,https://github.com/su2code/SU2/issues/648#issuecomment-460853218,1,['scalab'],['scalable-linear-solvers-multigrid-methods']
Performance,@EvertBunschoten even if the performance isn't great this is a pretty small change so I think we can merge it.; Do you have time to wrap it up and add a simple regression test?,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/2152#issuecomment-2269672071:29,perform,performance,29,https://su2code.github.io,https://github.com/su2code/SU2/pull/2152#issuecomment-2269672071,1,['perform'],['performance']
Performance,"@bigfooted @economon and @pcarruscag . I created separate repo to demonstrate what I'm after in the simplest way possible: [FoamScience/AutoRegistering-Cpp-Classes](https://github.com/FoamScience/AutoRegistering-Cpp-Classes/commits/master). > If you're going to check the code, check CSolver first, then CEulerSolver ... - Commit FoamScience/AutoRegistering-Cpp-Classes@20ca601 implements the concept for a single Factory.; - (Make-believe) Standard solver classes are compiled to a library; - A (Make-beleive) Custom solver class is compiled to its own shared library; - By default, the make program knows only about CEulerSolver (from standard solvers lib); - But if you pass in a library name (eg. libCCustomSolvers.so), it gets loaded, symbols pulled and the registration map for CSolver gets updated with the new Solver automatically. - But it would bloat the code if things went this way, so commit FoamScience/AutoRegistering-Cpp-Classes@380c052 isolates self-registration code into 3 macros to:; - Declare the registration map and associated members; - Define and initialize registration-related members on the base class; - Register a class. If you only care about the interface and not how the thing is implemented, commit 380c052 is your target.; I took care to document the important parts of the code, so, please, dig in and let me know what you think. At this point, integrating this with SU2 (and at what parts, and when) is your call but If you decide to do so, l will help.; > And yes, I wrote my own build script so I can have direct control over the compiler and the linker. **One last note: I used ""dlopen"", so you will have to compile the code on Linux I suppose.**",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1058#issuecomment-680962672:732,load,loaded,732,https://su2code.github.io,https://github.com/su2code/SU2/issues/1058#issuecomment-680962672,1,['load'],['loaded']
Performance,"@economon I was envisioning something similar to the TestCases folder. With v&v cases grouped according to what they are testing. Something along the lines of: . 1) Inviscid Simulations: ; a) 2D Inviscid bump; b) 2D oblique shocks interaction; c) ...; 2) RANS simulations: ; a) Flatplate; b) NACA0012; c) ...; 3) Unsteady simulations:; a) Square Cylinder; b) ...; 4) Turbomachinary: ; a) ... And so on. Each of the directories would have sub-directories for different mesh sizes, with configuration files for each mesh level that have optimized parameters for best results. So for example if we are talking about the NACA0012 case, we would have something along the lines of: . a) NACA0012; i) 113 x 33; ii) 225 x 65 ; iii) 449 x 129; iv) ... This way we have a family of meshes and configuration files that are specifically built for the purpose of validating the code and comparing with other solvers. I might be useful to compress meshes that are larger than a certain size (say 10MB). We should also put a limit on the size of a single mesh that the repository can handle (say 50MB?). . Within the home directory, the README file should list all the cases in the repository, who the custodian of the test case is (person with meshes in case the meshes are too large), and which version it was last run on. . I thought about splitting it up into Verification cases and Validation cases, but I thought it would be more informative and intuitive to split up according to the physics of the simulations. My thinking might be limited because that's how I have seen the TestCases folder organized, so any other suggestions are welcome. I think it is imperative that this is accompanied with a section on the SU2 website that showcases just the results of the validation test cases (grid convergence studies, residual reductions etc) and links to the v&v repo appropriately. This way, if people are just inquisitive about SU2's performance, they can get a quick snapshot of the results, without the need ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/581#issuecomment-426026053:535,optimiz,optimized,535,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-426026053,1,['optimiz'],['optimized']
Performance,"All,. I looked a bit more through Eigen and, indeed, the performance is pretty impressive and generally better than MKL and Atlas (the self-tuned implementation of LAPACK) ant most/all matrix sizes. I agree with comments made by @pcarruscg that having a standard for matrix operations throughout the source would clean up /simplify the code considerably and, since it does not seem to impact the AD approach, it should be pursued. It sounds like a quick test branch like @vdweide is suggesting makes sense. A quick driver code to test the performance of the Eigen routines vs MKL makes sense too. The only thing that @vdweide should comment on is how much work it would be to change the LAPACK/BLAS based implementation in the DG-FEM solver to the interface that Eigen exposes. Best,. Juan. On Feb 1, 2019, at 4:19 AM, Edwin van der Weide <notifications@github.com<mailto:notifications@github.com>> wrote:. Would it be an idea to create a branch to test things out and make a decision based on the results? It would be interesting to see the performance for e.g. the dense matrix multiplications in the DG-solver compared to Intel's MKL. —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/643#issuecomment-459705131>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADpSxM1gm0iy_FeGBMFzxVQnYFFzEHt4ks5vJDDlgaJpZM4adbAo>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/643#issuecomment-459845576:57,perform,performance,57,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459845576,4,"['perform', 'tune']","['performance', 'tuned']"
Performance,"All,. Of course, another approach to verifying which sign is correct is to do an analytic differentiation (using CoDi?) or simply using complex-step on the residual calculation routine to get exact Jacobians (for a particular state) and confirm the correct sign. This does require some code extraction / refactoring to perform the test, but it has the benefit that you would know exactly what the correct answer is for the specific residual implementation. Best,. Juan. On Nov 16, 2018, at 11:03 AM, Thomas D. Economon <notifications@github.com<mailto:notifications@github.com>> wrote:. As Jacobians affect convergence rate and not accuracy, you could do a quick test of the same problem with the current version and the sign flipped to see if there is measurable difference in the convergence rate. If yes, then it should give you a hint about which direction. If no, then we should still correct it, but prob don't need to put in too much effort. @clarkpede<https://github.com/clarkpede> : I'm interested in your unit testing set up... —; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/609#issuecomment-439493827>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADpSxInSS3cmLF8iFkD22AoYAp0G3G2yks5uvwvxgaJpZM4YeD9V>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/609#issuecomment-439500791:319,perform,perform,319,https://su2code.github.io,https://github.com/su2code/SU2/issues/609#issuecomment-439500791,1,['perform'],['perform']
Performance,"All,. Regarding the wall function specification, if we are going to settle on a standard way that could work for both the FV and DG-FEM solvers, it might be good to think about some modifiers that can later allow for a generality of approaches. We can make a distinction between wall functions and wall models, but this is subject to discussion…in essence both are performing similar duties, but people should express their opinions. With that said, how about a boolean such as USE_WALL_FUNCTIONS / USE_WALL_MODEL (YES or NO) with an optional argument WALL_FUNCTION_TYPE / WALL_MODEL_TYPE that can taken one of many pre-specified values that can be added as these options are developed and tested? Certainly options like STANDARD_WALL_FUNCTION, ADAPTIVE_WALL_FUNCTION, SCALABLE_WALL_FUNCTION, compressible and incompressible versions, and even EQUILIBRIUM_WALL_MODEL and NONEQUILIBRIUM_WALL_MODEL are things that are likely to be in the code in the near future. Thoughts?. Juan. On Sep 5, 2017, at 2:27 PM, Thomas D. Economon <notifications@github.com<mailto:notifications@github.com>> wrote:. @petebachant<https://github.com/petebachant>: the paper that I linked earlier on this thread had some fairly simple examples similar to the one you propose.. different flat plates and so on with varying y^+. You can likely reuse the grid(s) in the TestCases repo. @vdweide<https://github.com/vdweide>: it was very simple in this first implementation. It checks for a single boolean for whether or not to apply wall functions (WALL_FUNCTIONS= YES or NO, https://github.com/su2code/SU2/blob/43b8a4015c4b09b01d78e4243d32011c663c2b70/SU2_CFD/src/solver_direct_mean.cpp#L15339), and then assumes they should be applied to all no-slip walls (heat flux or isothermal, https://github.com/su2code/SU2/blob/43b8a4015c4b09b01d78e4243d32011c663c2b70/SU2_CFD/src/solver_direct_mean.cpp#L16653). This could of course be made more specific for individual markers using a config structure like MARKER_MONITORING to list the",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/399#issuecomment-327313634:365,perform,performing,365,https://su2code.github.io,https://github.com/su2code/SU2/issues/399#issuecomment-327313634,1,['perform'],['performing']
Performance,"All,. The following page has performance comparisons between eigen and mkl (and others):. http://eigen.tuxfamily.org/index.php?title=Benchmark. They are dated 2011, so they are a bit old, but if the quoted performance is real, I would say it is a no-brainer to switch to eigen. If the performance tests (for at least simple things like daxpy and gemm) could be repeated to verify the numbers, that would help us make a final decision. Best,. Juan. On Feb 2, 2019, at 1:58 AM, Edwin van der Weide <notifications@github.com<mailto:notifications@github.com>> wrote:. @pcarruscag<https://github.com/pcarruscag>, I agree with you it will be hard to beat the MKL (running at 60 percent peak for most of the gemm calls for the DG-solver), but if you don't have any performance loss, that would already be nice, as it improves readability. Furthermore, the performance of the DG solver in combination with the discrete adjoint is horrible, because it relies on my very naive implementation of the matrix products. So it would already be something if we can get an improvement there, although we do not use the DG adjoint solver (yet). For me the easiest way to test things out for the DG-solver would actually be in SU2 itself. @economon<https://github.com/economon> put some nice profiling routines in there for the gemm calls, which can be used without any additional work to test eigen. @pcarruscag<https://github.com/pcarruscag> (or somebody else), could you create a branch in which eigen is downloaded in the external directory? I think I can manage from there. Thanks,. Edwin. —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/643#issuecomment-459952137>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADpSxCgydwy1nS3qPJvyCMJXLXWNMSFsks5vJWEkgaJpZM4adbAo>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/643#issuecomment-459986613:29,perform,performance,29,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459986613,5,['perform'],['performance']
Performance,"At some point the marker starts being partitioned, some of it is in one rank, some in other(s).; Your print function truncates the file when it opens it, and so you only get the output from the last rank that opened the file.; You could make the file a member of the class, so that you can guarantee it is only opened once (other ranks would need to open in append mode), but then you still have a race condition when multiple ranks try to write simultaneously to the file (the result might be mixed lines, especially when `endl` is used to terminate lines because it forces a flush, maybe with ""\n"" and some luck it would be ok, but the order of the lines is still unpredictable).; To my knowledge mpi does not have simple ways to guarantee ordered execution of certain code regions. So unless you want to get knee deep in mpi, I recommend you keep this file output as a debug feature (that works on a single core) and use the normal surface output files (paraview, tecplot, etc.) for visualization.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/944#issuecomment-616367257:398,race condition,race condition,398,https://su2code.github.io,https://github.com/su2code/SU2/issues/944#issuecomment-616367257,1,['race condition'],['race condition']
Performance,"Dear Heather,; I am analyzing a propeller of an UAV. I have static thrust measurements such that when I used Euler results I got 3.5 lbf thrust as compared to the measured 6 lbs. My next step was to perform an NS equation with SA turb model. I got 7 times over predicted results such that the mesh has a Y+ of less than 1. Then I thought of doing an SST but was not long enough that it gave me error with divergence. I have been setting up my SST case as per the tutorial example of NACA0012. However, I do not happen to see any entry with regards to eddy frequency etc. (usually required by SST) in the config file. Any guidance will be great.; Thanks; Jehan; From: Heather Kline notifications@github.com; To: su2code/SU2 SU2@noreply.github.com ; Sent: Tuesday, May 12, 2015 11:43 AM; Subject: [SU2] Feature deallocation (#174). Bringing this branch up to date with current develop branch. ; Various deallocation changes; Some regression tests fail but all run. (previously was not the case); You can view, comment on, or merge this pull request online at:;   https://github.com/su2code/SU2/pull/174; Commit Summary; - Updated GetEngine_Properties; - Fix to the last commit; - Small bug; - Merge branch 'develop' into feature_MPI; - merging; - SU2_SOL and SU2_CFD are working; - Preliminary, but complete, implementation of SU2_DEF; - More updates; - Working version; - Complete implementation (validate); - Working version of SU2_DEF; - Final push before moving to the develop branch; - New MPI (removing SU2_PRT); - Merged in Ben's ParMETIS integration and fixed some conflicts.; - Merge branch 'benkirk-parmetis_integration' into feature_MPI; - ParMETIS geometry routines have been copied over but are not activated yet.; - Small change to ParMETIS include.; - ParMETIS can now be activated for testing (PARMETIS=YES in config).; - Updated MG; - Updated EA subrotuine; - Small fix; - Fixing memory leak; - Fixing memory leaks; - Dev release v.3.2.6; - Increasing MAX_NUMBER_MARKER; - Working versi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:199,perform,perform,199,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['perform'],['perform']
Performance,"Folks,. Perhaps we can split this issue to a separate thread. But it is indeed a critical one. Improving performance of the solver (or trying other preconditioned solvers) would be a significant improvement amortized over a very large number of users. Add it as a topic of discussion for the Annual Meeting in May?. Juan. On Feb 5, 2019, at 6:54 AM, pcarruscag <notifications@github.com<mailto:notifications@github.com>> wrote:. Hi @EduardoMolina<https://github.com/EduardoMolina>,. That is something I am also interested in as for some of my structural cases the current linear solvers simply do not converge. However Eigen is not the tool for that as the sparse linear solvers it has are similar and are not distributed parallel.; When I opened this issue I was thinking exclusively about how we handle small-medium dense matrices that live on a single rank, and associated algorithms (the kind used for RBF interpolation for example).; I think the two issues are fairly orthogonal, so we can open another to discuss large solvers, for which related work has already been started. Cheers,; Pedro. —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/643#issuecomment-460666656>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADpSxClv7-iTk5lFN9sK4fkqM7lk0FZEks5vKZsPgaJpZM4adbAo>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/643#issuecomment-460714752:105,perform,performance,105,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-460714752,1,['perform'],['performance']
Performance,"Hello @pcarruscag @TobiKattmann and SU2 developers,. We have been busy making several code updates, performing cleanup, etc. for this PR. Can you please review and provide feedback when you get the chance? Thank you in advance!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1300#issuecomment-1061224541:100,perform,performing,100,https://su2code.github.io,https://github.com/su2code/SU2/pull/1300#issuecomment-1061224541,1,['perform'],['performing']
Performance,"Hi @Nicola-Fonzi,. I'm not 100% sure of the reasons behind the GetFSI_Simulation criteria. I'd imagine that the nMarker_Fluid_Load might have been included there to make sure that a problem is treated as FSI only if there is transfer of load from the fluid to the structural domain, even if both zones existed independently in the config. But since the GetFSI_Simulation check is set up as an ""or"" rather than ""and"", as long as one of them is satisfied, the logic will be true for an FSI simulation, which might be sufficient for your application?. For the velocity transfer, I agree with Rafa that it would be better if you could also transfer the velocity from the external structural solver. If an external structural solver is used for dynamic analysis, it probably can output the structural velocities as well as the structural displacements? I left the methods for the recalculation of the grid velocity using finite differences in the code to support fluid-only problems with dynamic grid motion, I wouldn't suggest this as the method for FSI problems. For primal analysis, results from both methods agree with FSI benchmark cases but if you are interested in adjoint analysis at any point, transferring the velocity information from the structural domain directly to the fluid domain gives a significant simplification and improvement to the gradients.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1174#issuecomment-778368854:237,load,load,237,https://su2code.github.io,https://github.com/su2code/SU2/pull/1174#issuecomment-778368854,1,['load'],['load']
Performance,"Hi @pcarruscag and @vdweide ,. Thanks for creating a test branch and for bringing this discussion. When Brian (@bmunguia ) and I mentioned PETSc, it was an idea to try a different Newton-Krylov (with preconditioner) library in order to improve the convergence of SU2. ; Since the slow convergence of the SU2-FV is the main feedback that I received from other users from industry and academia, I think it worth try an external library and evaluate the performance. ; I will be happy to help test Eigen and see if it is a good candidate. Best,; Eduardo",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/643#issuecomment-460479862:451,perform,performance,451,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-460479862,1,['perform'],['performance']
Performance,"Hi @pcarruscag, just a small follow-up to my comment in the code section concerning the new adjoint implementation that might also help here (either by using it directly or just for getting some ideas). What I would like to change is in fact not the `CDiscAdjSolver` (which I find is very good) - but I'd like to propose some changes for the *interface* to the AD tool. And some subsequent stuff.; It will allow for a more direct control of derivatives which is favourable in case one deals with multiple zones, multiple sets of conservative variables, geometry coordinates in case of FSI, and so on. And of course in terms of performance as one needs only one tape that one can keep during all iterations, regardless of what their variables might be. In case you are interested, take a look at the implementation in [su2code:sc_develop](https://github.com/su2code/SU2/tree/sc_develop). I'll open the PR as soon as @talbring opened his one for his great rework on input/ouput. As for this PR, let me wait a second if we can clear up the issue concerning the registration and I'll leave a small review afterwards.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/615#issuecomment-457582842:627,perform,performance,627,https://su2code.github.io,https://github.com/su2code/SU2/pull/615#issuecomment-457582842,1,['perform'],['performance']
Performance,"Hi @pcarruscag,; thank you very much for the insight and the well thought proposed solution. I wasn't aware that there was such a loss in performance, it seems clear that something needs to be done. The only question I have is regarding the following comment . > There are no free lunches and this performance improvement would come at the cost of losing the ability to have different types of variables in different parts of the domain. I'm using this feature more and more, I was planning to extend it in the structural solver to remove the `if fsi` statements, and I also used it in the rework of the mesh solver, as defining variables at the interface only reduces greatly the memory footprint (sort of like the node-vertex structures in geometry). You mention there are options to keep this versatility, how difficult do you think would be to implement them?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/716#issuecomment-507998889:138,perform,performance,138,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-507998889,2,['perform'],['performance']
Performance,"Hi Economon,. I encountered an issue very similar to what Auzbaig reported: the error message ""OBJECTIVE_FUNCTION: invalid option value EntropyGeneration"" during optimization with SU2. (I am using SU2 version 8.0.1 ""Harrier.""). After thoroughly examining the existing Python optimization framework, I found that one of the steps in the optimization chain is generating different config.cfg files, with a focus on DV_VALUE and OBJECTIVE_FUNCTION. DV_VALUE controls the geometry deformation;; OBJECTIVE_FUNCTION determines the type of objective/constraints.; Then the framework calls SU2_CFD and SU2_DOT to obtain performance metrics or gradient information.; As you mentioned, ""You might need to run updateHistoryMap.py to register new outputs with Python."" Initially, I thought it meant simply providing a new input for OBJECTIVE_FUNCTION in the Python optimization framework. However, it seems that this may not work at the C++ level. To verify this, I ran $ SU2_CFD your_config.cfg -d and observed all available history outputs. However, I suspect that OBJECTIVE_FUNCTION cannot use every history output, meaning that the adjoint solver might not recognize some objective functions. Does this imply that additional modifications in the C++ code are required?. Additionally, I would appreciate more information regarding CUSTOM_OBJFUNC. From TestCases/user_defined_functions/lam_flatplate.cfg, I understand that CUSTOM_OBJFUNC allows combinations of existing OBJECTIVE_FUNCTIONs and can also utilize CUSTOM_OUTPUTS. The flexibility of CUSTOM_OUTPUTS seems to enable the construction of various desired variables. However, I am unsure whether using OBJECTIVE_FUNCTION= CUSTOM_OBJFUNC along with CUSTOM_OUTPUTS can entirely replace the need for additional modifications in the C++ code. Since I’m not very proficient in C++, I would greatly appreciate your guidance. Sincerely,; Tongtong",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/889#issuecomment-2324575133:162,optimiz,optimization,162,https://su2code.github.io,https://github.com/su2code/SU2/issues/889#issuecomment-2324575133,5,"['optimiz', 'perform']","['optimization', 'performance']"
Performance,"Hi Pedro, ; As discussed last week, I now translate and rotate the whole aircraft in the elastic mesh in combination with a farfield onflow. Implementing and doing the coordinate transformations right took me a few hours, but now everything seems to work properly and fast :). 1. Currently, activating the gust resets/overwrites the grid velocities due to the deformed mesh, but I haven't found the place yet. Any ideas?. 2. Should I clean up / remove the split velocity approach as described in the first post or would you like to keep it?. 4. How to handle the new approach, should I close this pull request and open a new one? There are a few commits which I needed to undo. 5. Generally, I still need the rotating frame approach for steady maneuver load cases, e.g. to calculate the pitching, rolling or yawing aircraft in a steady simulation. The acceleration terms are zero in this case, but I understood that the Coriolis-Term with omega x velocity is missing. Is that correct? I guess they are probably important for objects like a propeller which spins at a couple of thousand RPMs but maybe it is justified to neglect them for slow objects?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1954#issuecomment-1505397240:753,load,load,753,https://su2code.github.io,https://github.com/su2code/SU2/pull/1954#issuecomment-1505397240,1,['load'],['load']
Performance,"Hi everyone,; I was tring to use the mesh adaptation feature but the whole procedure is not clear to me.; Following the previous indications I:. 1. downloaded the `feature_adapt branch`. 2. downloaded the Adaptive 2D NACA 0012 example (https://pyamg.saclay.inria.fr/pyamgexamples.html#2dnaca): `adap_NACA0012.cfg`, `mesh_NACA0012_inv.su2`, `NACA0012_ini.dat`. 3. added the following lines to the config:; ```; % Type of sensor used for adaptation; % Options include GOAL (adjoint-based), MACH, PRES; PYADAP_SENSOR= GOAL; % Objective function used for goal-oriented adaptation; OBJECTIVE_FUNCTION= LIFT; % Maximum cell size for adaptation; PYADAP_HMAX= 500.0; % Minimum cell size for adaptation; PYADAP_HMIN= 1e-9; % Gradation factor (typically 1.2-1.8); PYADAP_HGRAD= 1.8; % Norm used for adaptation; % 1.0 or 2.0 recommended for inviscid flows; % 4.0 recommeneded for viscid; ADAP_NORM= 4.0; % Approximate mesh size (NPOI) at each level; PYADAP_COMPLEXITY= (30000, 60000, 120000); % Number of adaptations performed at each level; PYADAP_SUBITE= (3, 3, 3); ```. 4. run the following command: `$ python3 SU2_RUN/mesh_adaptation_amg.py -f adap_ONERAM6.cfg -n 8`. The response I have obtained is the following:; ```; SU2-AMG Anisotropic Mesh Adaptation. Mesh adaptation options:; PYADAP_COMPLEXITY : (30000, 60000, 120000); PYADAP_SUBITE : (2, 2, 2); PYADAP_SENSOR : MACH; PYADAP_HMAX : 500.0; PYADAP_HMIN : 1e-9; PYADAP_HGRAD : 1.8; PYADAP_FLOW_ITER : (2999, 4999, 6999); PYADAP_ADJ_ITER : (2999, 4999, 6999); PYADAP_CFL : (10.0, 15.0, 20.0); PYADAP_RDG : NO. The ./adap folder was deleted. Generating GMF background surface mesh.; ## WARNING: MISSING SU2 MESH FILE KEYWORD: NCORNERS=.; Initial CFD solution is provided.; ```. As expected, a `./ADAP` folder was created, containing these docs: `amg_back_meshb`, `config_CFD.cfd`, `log.err`, `log.out` (sizes 0 byte), `mesh_NACA0012_inv.su2` (link to the mesh), `NACA0012_ini.dat` (link to the file.dat). Did I perform the procedure correctly? Or did I m",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/948#issuecomment-737134105:1006,perform,performed,1006,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-737134105,1,['perform'],['performed']
Performance,"I agree with the final conclusion here... thanks for discussing this and working toward a solution. . We have found in some of our performance optimization work that continuously allocating/deallocating memory is a performance killer, and I am in favor of uniform behavior across the code for readability/usability. Let's merge this in.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/200#issuecomment-149771091:131,perform,performance,131,https://su2code.github.io,https://github.com/su2code/SU2/pull/200#issuecomment-149771091,3,"['optimiz', 'perform']","['optimization', 'performance']"
Performance,"I am a little partial because I wrote it, but this https://github.com/su2code/FADO should do any kind of optimization you want.; Multiple operating points, manipulations of variables, running everything simultaneously... But I guess for something simple it is a little more work to setup.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1279#issuecomment-833754354:105,optimiz,optimization,105,https://su2code.github.io,https://github.com/su2code/SU2/issues/1279#issuecomment-833754354,1,['optimiz'],['optimization']
Performance,"I am not sure about why periodic boundaries are allowed to deform. It doesn't seem to be a good idea unless there is a way to deform its periodic pair in the same way. As for @auzbaig's question about why SLSQP converges in one step: There is a huge difference in the magnitude of the objective function, O(1) and the gradient O(-11). I am guessing the optimizer doesn't think it can reduce the function value any further since the gradient with respect to the DVs is so small. . To change the relative magnitudes of the objective and gradient, you need to change the DV scaling. This isn't intuitive and is one of the things we are hoping to address in #922 . Check out the `obj_df` function in `SU2_PY/SU2/eval/design.py` (line 386 in the develop branch). There you see how the gradient is scaled: . `grad[k] = grad[k] * sign * scale * global_factor / dv_scl` . Here `scale` is the objective function scaling factor, `global_factor` is what you specify for the `OPT_GRADIENT_FACTOR`, the `dv_scl` is the design variable scaling. . So if you wanted to bring the gradient norm to O(1), you'd have to specify a DV scaling of 1e-11. Usually a gradient norm of O(-6) is what seems to work best with SLSQP.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/976#issuecomment-628724163:353,optimiz,optimizer,353,https://su2code.github.io,https://github.com/su2code/SU2/issues/976#issuecomment-628724163,1,['optimiz'],['optimizer']
Performance,"I could create a ""safe Allgatherv"" function, e.g. in [`mpi_structure.hpp`](https://github.com/su2code/SU2/blob/1b085062547ec5b066a28ddeeacf4907588f4f5a/Common/include/parallelization/mpi_structure.hpp) or in [`ndflattener.hpp`](https://github.com/su2code/SU2/blob/1b085062547ec5b066a28ddeeacf4907588f4f5a/Common/include/toolboxes/ndflattener.hpp). This function should check the number of processes, perform a simple copy if it is 1, and otherwise calls the regular Allgatherv. It would then be used [here](https://github.com/su2code/SU2/blob/1b085062547ec5b066a28ddeeacf4907588f4f5a/Common/include/toolboxes/ndflattener.hpp#L235) instead of `SU2_MPI::Allgatherv`.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1893#issuecomment-1397491031:400,perform,perform,400,https://su2code.github.io,https://github.com/su2code/SU2/issues/1893#issuecomment-1397491031,1,['perform'],['perform']
Performance,"I have covered all operations used in non adjoint use, the non ideal part of the implementation I mentioned above is that the parallelization is ""local"", i.e. we get to the operation we want to make parallel and launch the threads there, for simple vector-vector operations the overhead may be significant.; Ideally we would have a parallel construct at a higher level, say CSysSolve::Solve, so that the threads are already in flight when we get to those small operations.; In principle it is not too hard to do that, but it needs to be done carefully especially when the execution gets to an MPI part of the code (which thread(s) communicate, etc.).; I will try to benchmark this to put numbers on the performance / simplicity trade-off.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/830#issuecomment-560572616:703,perform,performance,703,https://su2code.github.io,https://github.com/su2code/SU2/pull/830#issuecomment-560572616,1,['perform'],['performance']
Performance,"I know that it can be frustrating sometimes operating within the constraints of an open-source project such as ours. However, I can assure you that folks do indeed care about performance, and sometimes I have the impression that we stress over relatively small performance issues (remember to keep the total pie chart of where the major work of the solver resides in mind). . The option WRT_PERFORMANCE= YES is available to get timings for runs broken down by preprocessing, compute, and output phases, and I think we should focus our performance concerns first on issues within the compute phase, unless a major bottleneck appears in the other two phases that completely prohibits us from running larger cases (we have been clearing many of those out lately). We do not have the resources of a professional software company, but what we do have is a great community of folks who are putting in lots of effort on a volunteer basis. @pcarruscag: your reviews have been very helpful for improving contributions - thank you for that effort. Let's keep supporting each other, but let's also make sure we stay positive and foster a welcoming environment to encourage more participation.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/724#issuecomment-534682406:175,perform,performance,175,https://su2code.github.io,https://github.com/su2code/SU2/pull/724#issuecomment-534682406,4,"['bottleneck', 'perform']","['bottleneck', 'performance']"
Performance,"I think I implemented all the modifications you suggested. I am sorry you see all the commits in between, unfortunately due to Covid I work outside of office and I actually use Github to push the modified code to the office PC. I was actually working on a separate branch but, for reason that I do not understand, all the commits have been moved in the merging process... sorry about that. I am still learning git. In particular the modifications are:. - The functions related to static mesh deformation have been removed. I only included some new lines in the python wrapper ; that overwrite the initial velocities to zero and push back the solution.; - I now use the BC_Sym_Plane of the FEA solver for the deformation at the symmetry plane. I had to add a flag that avoids ; accessing LinSysReact in case of mesh deformation, as this is not initialised in that context.; - GetnMarker_Match_Deform_Mesh is not present anymore; - The marker has been renamed from MATCH_DEFORM_MESH to DEFORM_MESH_SYM_PLANE. All the functions have also ; been renamed accordingly; - I included the SU2 header in all the new files, changing the version number to 7.0.8. I did not modify the version number of ; the files that were already present in SU2 prior to this PR. I think the merging process should take care of that, am I wrong?; - The python functions that were separated in x,y,z component now give back an array and are merged into one function only; - The descriptions for the methods have been added; - The test case has been removed. I actually prepared a tutorial and all the appropriate files will be placed in the tutorial and ; website repos. I will now perform a PR for those repos so that you can see the material. Again thank you very much and sorry for the mess with the ""internal"" commits. . Please let me know if you think I missed something",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1124#issuecomment-742471972:1654,perform,perform,1654,https://su2code.github.io,https://github.com/su2code/SU2/pull/1124#issuecomment-742471972,1,['perform'],['perform']
Performance,"I think its a good idea to separate the weight from the objective function. This makes it more clear and flexible. However, what bothers me a little bit is that the OBJECTIVE_FUNCTION option is now used for two things. Namely for the optimization and for the individual adjoint runs. Maybe it would be good to still have another option for specifying the obj. function for the adjoint run itself (with a completely different name, so that there won't be any confusions). . Maybe it's less of a problem then I think, though.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/241#issuecomment-185126081:234,optimiz,optimization,234,https://su2code.github.io,https://github.com/su2code/SU2/pull/241#issuecomment-185126081,1,['optimiz'],['optimization']
Performance,"I was running some tests using a simple geometry but for the refinement seems to be chewing up the geometry. Has anyone who has worked on 3D geometries experienced this or figured out a way to avoid this?. I was using the following settings:; ```; % ------------- MESH ADAPTATION PARAMETER ------------%; %; % Type of sensor used for adaptation; % Options include GOAL (adjoint-based), MACH, PRES; PYADAP_SENSOR= MACH; % Maximum cell size for adaptation; PYADAP_HMAX= 500.0; % Minimum cell size for adaptation; PYADAP_HMIN= 1e-9; % Gradation factor (typically 1.2-1.8); PYADAP_HGRAD= 1.8; % Norm used for adaptation; % 1.0 or 2.0 recommended for inviscid flows; % 4.0 recommeneded for viscid; ADAP_NORM= 2.0; % Approximate mesh size (NPOI) at each level; PYADAP_COMPLEXITY= (1000000, 1300000, 1500000); % Number of adaptations performed at each level; PYADAP_SUBITE= (2, 2, 2); ```. ![refine](https://user-images.githubusercontent.com/16842258/104834786-0b94fa80-58e5-11eb-9018-687ffc5aaa9d.png). I noticed a few comments up, there is the `PYADAP_BACK` setting, which sounds like it might solve this, but how should one use this? Should the geometry alone be re-meshed to a high resolution and the whole volume exported as a SU2 block? Or should it be just a surface mesh? (It seems that Pointwise is not able to output only the surface mesh in SU2 format.)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/948#issuecomment-761751741:827,perform,performed,827,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-761751741,1,['perform'],['performed']
Performance,"I've run into some headaches getting the optimization to run efficiently on my end, which is why I ask. Playing with a toy problem, SLSQP actually does a great job on its own (with all tuning parameters set to 1.0) if the following conditions are met:. + The constraints and bounds effectively bound ""reasonable"" solutions, so you don't have to worry about unrealistic deformations.; + The optimization function is (relatively) convex. If those conditions are met, then playing with any of the tuning parameters makes SLSQP converge more slowly, sometimes with 10x the iterations. So its not clear to me when the tuning parameters are necessary, and how those tuning parameters affect the convergence in those cases. I'm not arguing that the tuning parameters aren't necessary, just that their effects aren't clear. And I agree, the proper way to nondimensionalize and regularize these problems is not clear from a brief search of the literature.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/733#issuecomment-616825497:41,optimiz,optimization,41,https://su2code.github.io,https://github.com/su2code/SU2/issues/733#issuecomment-616825497,2,['optimiz'],['optimization']
Performance,"In the lab we are also writing/rewriting another largish solver with eigen (https://ic-sharpy.rtfd.io/). A major advantage (and, I think, critical for open source) was code readability to ease the learning curve for newcomers, with no reported penalty on performance. I second all the other nice things about it written by @pcarruscag.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/643#issuecomment-459943384:255,perform,performance,255,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459943384,1,['perform'],['performance']
Performance,"Indeed, this helps, but it could be more general, since you only get to see this in the console output. I was thinking that a simple tag in the optimization history file for the evaluations that are 'major' would make this much simpler (and easier to post-process).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/108#issuecomment-102168908:144,optimiz,optimization,144,https://su2code.github.io,https://github.com/su2code/SU2/issues/108#issuecomment-102168908,1,['optimiz'],['optimization']
Performance,"It's not always the case that using a restart file is continuing from a simulation. For example, if one has a simulation that has a similar solution as a seed. An example would be doing optimization and using a nearby flow solution. Here, having the iteration count start from zero is useful, because it's the more accurate measure. We would also have to this about how this interfaces with MAX_ITER. Right now it's really clear, but which does it mean when iterations don't start from zero?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/99#issuecomment-103239930:186,optimiz,optimization,186,https://su2code.github.io,https://github.com/su2code/SU2/issues/99#issuecomment-103239930,1,['optimiz'],['optimization']
Performance,"Nice progress @pcarruscag!. I like the concept of your SIMD-friendly class that will take care of the data structure under the hood coupled with a standard type of loop statement (w/ +SIMDLEN). This should make it pretty easy for folks to still modify the kernels without having to worry about the data alignment, and they can reuse the same simple 'for' construct repeatedly. . Another reason to have our own lightweight class for this is that you can avoid dependence on OpenMP for SIMD (although that feature looks to have potential and wasn't available until somewhat recently) as well as the intrinsics. In my experience, the latter is especially bad for portability and readability (part of why we left the CaF work in a separate repo). It starts to become so specialized that compiling and modifying become difficult. W.r.t. OpenMP, another roadblock there a few years ago was making sure it is interoperable with CoDi for the adjoint, but I know this has been worked on and may be available by now. Might keep an open mind about point vs. edge. In some places, we may be able to pump up the compute in our loops by fusing kernels, as previously discussed (and I am guessing you are working on this already with gradients/limiters). Could change the final performance numbers significantly. Lastly, I know you are not there yet, but it is worth considering whether you can reuse anything you are developing in the kernels here for the linear solver routines. At some point, you will successfully reduce the cost of the residual kernels (RHS) to the bandwidth limit, and the majority of the iteration cost will be in the linear solver (it is already about 50% of the iteration cost before optimization, if I recall). Before making final decisions on strategy, you should consider if it will help in any of the linear solver routines too.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-530440072:1263,perform,performance,1263,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530440072,2,"['optimiz', 'perform']","['optimization', 'performance']"
Performance,"No need for Intel buddies, I know what's up. Take [this code:](https://gcc.godbolt.org/z/siQamn); ```; class Base {; public:; inline virtual double get() const {return 0.0;}; };. class Derived : public Base {; double val;; public:; Derived(double a) : val(a) {}. inline double get() const final {return val;}; };. double fun1(Base* obj) {; return obj->get();; }. double fun2(Base* obj) {; return static_cast<Derived*>(obj)->get();; }; ```. `get` of derived has been marked `final` so in `fun2` polymorphism should be optimized away. Here is the assembly for gcc 5.4:. ```; fun1(Base*):; mov rax, QWORD PTR [rdi]; jmp [QWORD PTR [rax]]; fun2(Base*):; movsd xmm0, QWORD PTR [rdi+8]; ret; ```; `fun1` needs a jump, `fun2` knows what to return right away. Here is the assembly for icc 17:; ```; fun1(Base*):; mov rax, QWORD PTR [rdi] #16.12; mov rdx, QWORD PTR [rax] #16.12; jmp rdx #16.12; fun2(Base*):; mov rax, QWORD PTR [rdi] #20.34; mov rdx, QWORD PTR [rax] #20.34; jmp rdx #20.34; ```. @vdweide please tell me you did not use icc 19, because it performs this optimization just fine on this simple example. By the way @talbring (since you asked in #753), take away the `final` keyword and nothing gets optimized by the `static_cast`.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/716#issuecomment-523952473:517,optimiz,optimized,517,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-523952473,4,"['optimiz', 'perform']","['optimization', 'optimized', 'performs']"
Performance,"Ok the ""simple"" version of ""going parallel"" whenever we get to a linear algebra operation did not make the cut.; On an older architecture there was a 10% slowdown of the linear solvers at ~10k nodes per core and about the same on a newer architecture but only at ~1k node per core.; Since hybrid parallel is supposed to be good for strong scaling, this was not good enough... With the new strategy it is ok (see ""performance"" below), hence this is ready for review. ### Overall Strategy; The strategy now is to start a parallel section in CSysSolve::Solve that covers building the preconditioner and solving the linear system.; Linear algebra routines called within this section have _worksharing_ constructs instead of _parallel_ ones, i.e. the work is distributed by however many threads arrive to that routine. This also makes the routines safe to call in serial.; The only ""dangerous"" things to do in parallel are to: manage memory for a shared object (multiple threads call `new` but there is only one shared pointer on which to call `delete`); writing to the same memory locations concurrently.; I tried to make the first issue debugable by asserting that the initialization routines of CSysMatrix and CSysVector are only called by the master thread.; For the second issue I made the associated classes as const-correct as possible, that should at least make someone think twice before changing a member variable of those classes. The risk is still there for input variables as an algorithm development aspect... For example `MatrixVectorProductTransposed` cannot be made thread-parallel as simply/naively as its normal counterpart. ### Communication Model; The MPI + Threads communication model is very simple, currently only the master thread calls MPI routines (including `Error`), this requires thread barriers before and after the communication to make sure the correct values are passed and _seen_ by all threads.; We can test other alternatives in the future but at the moment this does n",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/830#issuecomment-562646766:413,perform,performance,413,https://su2code.github.io,https://github.com/su2code/SU2/pull/830#issuecomment-562646766,2,"['concurren', 'perform']","['concurrently', 'performance']"
Performance,"Ok time to share some results after #753.; I deviated a bit from the original plan in that I skipped the contrived strategy of using a wrapper container with a special [] operator (as it had a slight whiff of hackery), and went straight to adding ""iNode"" to the methods of CVariable instead (me and a few lines of python...). The first rule of performance is **""measure it before changing code""**, I broke that rule because as my first post illustrated non contiguous storage at the scale we had is a real killer. With that out of the way, to some extent at least (the layout may not be optimum still) measuring is essential to decide what to do next. This is the case I am using:; ![case](https://user-images.githubusercontent.com/38071223/63288257-27d9d580-c2b4-11e9-9899-8b44b230b8bb.png); It is a bad wing design (NACA0012) with some sweep and taper and a home-brew mesh whose quality rivals that of the design (it converges and the flow does not separate...).; The mesh is just over 500k vertices (so it ""fits"" comfortably in my pc) the y+ is not great (obvs) but the aspect ratios are 200 and 2000 in the chordwise and spanwise directions respectively, so not exactly linear solver friendly either. Some settings which are kinda optimal:; - Mach 0.6, AoA 2 degrees;; - SST (1st order);; - CFL 20 (higher and residuals would limit-cycle (regardless of linear solver settings); - Roe;; - MUSCL - Green-Gauss and Venkat-Wang;; - FGMRES + LU_SGS to 0.05 residual (about 3 iters on avg.);; - 2 levels of MG (1,1,2 iterations, all zeros for other stuff and 0.7 damping both ways);. The case is light on the linear solver and therefore stands to benefit the most from better data layout. Conversely, applications that can take higher CFL / or use central schemes will not benefit as much. **Running this from scratch to residual of 10^-8 on a couple of Xeon E5-2650v4 (24c total) shows a speedup of 1.4 and just over 10% lower memory usage.**; Those numbers will be better for an equivalent 2D case sin",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/716#issuecomment-522730951:344,perform,performance,344,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-522730951,1,['perform'],['performance']
Performance,"On the subject of virtual functions I would like to put another idea forward.; After moving things around in #725 I noticed that we have tons of `inline virtual` methods.; The keyword `inline` has two meanings to the compiler:; - ""Dear merciful compiler please copy paste the body of this function and then do all your wonderful optimizations, if that pleases your excellency.""; - ""Dear forgiving compiler, you will find this method defined in multiple units, please don't be mad"" (i.e. ignore the one-definition-rule). `virtual` means determine what version of the method to call at runtime. This is not compatible with the first (and often the intended one) meaning of inline, therefore the compiler will in general not inline those methods.; They will only be inlined if they are being called on a pointer to the derived class that does not declare the method to be virtual anymore. CSolver knows what variables it creates and so in hot areas of the code it could do a static downcast to allow inlining (e.g. `static_cast<CEulerVariable*>(node[iNode])->DoStuff()`).; Where is this important? For example when computing gradients, where simple additions and subtractions are hidden behind virtual functions.; If you are worried about maintenance each solver can typedef its most safe downcast level or better yet (or just more modern), methods that could benefit from this can be templated for the type of downcast.; Those in favour say Yea those against say Nay.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/716#issuecomment-509273008:329,optimiz,optimizations,329,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-509273008,1,['optimiz'],['optimizations']
Performance,"One of the interesting paper -. "" Comparison of numerical and Analytical Jacobians"", Kirk J. Vanden, Paul D. Orkwis; AIAA, Vol 34, No. 6, June 1996. They computed the exact analytical Jacobian with symbolic manipulation. In conclusion they are showing that both analytical and numerical Jacobians showed similar performance and suggesting that for simpler numerical fluxes, analytical Jacobians should be the best way to go and for complex numerical fluxes, numerical Jacobian can be preferable choice (but if one can work out analytical, that should be good as well, I guess (one time effort) ). Best; Amit",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/691#issuecomment-505615012:312,perform,performance,312,https://su2code.github.io,https://github.com/su2code/SU2/pull/691#issuecomment-505615012,1,['perform'],['performance']
Performance,"Regarding periodic boundaries: You have two options. You can hack the code to not allow grid deformation on periodic boundaries. That's a simple code edit, since the code already prevents most boundaries from being deformed. Let me know if you want to use this option, and I can point you to those lines. Second, you can use the `HOLD_GRID_FIXED` and `HOLD_GRID_FIXED_COORD` options to prevent grid deformation outside a specific box. I have found this option to be better overall, since it also makes the linear system easier to solve in `SU2_DEF`. The `DV_VALUE` and `FINDIFF_STEP` are different. I've only seen `FINDIFF_STEP` used for the finite-differencing python script, though it may have other uses I am not aware of. The `DV_VALUE` depends on the context. When using `SU2_DOT`, `DV_VALUE` is set to its default value. But when performing shape optimization using SU2's framework, the `DV_VALUE` parameters will be set based on the output of SLSQP (or whatever optimization framework you're using).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/976#issuecomment-626799862:836,perform,performing,836,https://su2code.github.io,https://github.com/su2code/SU2/issues/976#issuecomment-626799862,3,"['optimiz', 'perform']","['optimization', 'performing']"
Performance,"Sounds like a reasonable optimization, the only other place that handles averages is `COutput::Postprocess_HistoryData`, so this should be a very local change and thus a good first issue. Do you want to give it a go at creating a pull request for this? We can give you some pointers. But it should be simple to modify the `addValue` function to take the window type as argument and only `push_back` for non trivial windows.; Even those could be optimized by caching the sum over n-1 elements, this would avoid traversing the entire history of values when only the last entry is modified during inner iterations.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1545#issuecomment-1037249095:25,optimiz,optimization,25,https://su2code.github.io,https://github.com/su2code/SU2/issues/1545#issuecomment-1037249095,2,['optimiz'],"['optimization', 'optimized']"
Performance,"Thank you for the feedbacks, I am working on the modifications you suggested. I will perform a couple of tests to be sure I did not break anything. Hope to commit the new code soon!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1124#issuecomment-740209039:85,perform,perform,85,https://su2code.github.io,https://github.com/su2code/SU2/pull/1124#issuecomment-740209039,1,['perform'],['perform']
Performance,"Thanks @MicK7 I will have a look, my initial thought was to have a simple strategy where within each MPI rank parallelism is extracted via colouring or scatter-to-gather transformations and only one thread per rank participates in the message passing, I have no experience here though so this might be a bad strategy, idk. **Back to business:**; I went silent for a bit because in prototyping a typical residual computation and matrix update loop I made some realisations that made me go back to the drawing board regarding data structures, and eventually back to square 0. . ## Parallel strategy for flux computation; Because significant computation is required to obtain each edge's flux, it does not make sense to attempt a ""point-loop"" strategy (which would double the effort).; However, one can either use colouring to avoid the race conditions that would result from updating the residual of cells i and j, or store the edge fluxes and then, on a second point-loop perform the summation of fluxes for each cell, with the direction being accounted by the same adjacency information used in the point-loop GG gradient computation.; If we consider only the update of residuals the two strategies are fairly equivalent performance wise, the tie breaker is the matrix updates. ## Matrix Updates; By this I mean the `addBlock`, `subBlock` we do (two times each) to update diagonal and off-diagonal blocks for each edge.; Here is a dummy numerics loop that does nothing else but setting blocks in the matrix (with colouring).; ```c++; void testLoop1(const vector<size_t>& colorStart,; const vector<size_t>& edgeIdx,; const vector<pair<size_t,size_t> >& connectivity,; double** blk_i, double** blk_j,; SparseMatrix& matrix); {; matrix.setZero();. for(size_t color=0; color<colorStart.size()-1; ++color); #pragma omp parallel for schedule(dynamic,CHUNK_SIZE); for(size_t k=colorStart[color]; k<colorStart[color+1]; ++k); {; size_t iEdge = edgeIdx[k];; size_t iPoint = connectivity[iEdge].first;; size_t j",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-535977206:834,race condition,race conditions,834,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206,2,"['perform', 'race condition']","['perform', 'race conditions']"
Performance,"Thanks @economon!; I don't know what is the current situation with OpenMP and CoDi but any eventual change will have to be compatible with CoDi. The worst case would be disabling OpenMP for the discrete adjoint, the parallel clause supports an ""if"" modifier so that would not be too hard. But I hope to at least be able to lower the memory footprint by fusing some loops or make pre-accumulation more effective by using point loops.; The linear solvers will indeed become the bottleneck, they already are for JST, the good thing is matrix multiplication is easier to vectorize, not sure the best strategy will be similar though. ### Limiters. Scalar (reference) version of the code:; ```C++; void computeLimiters(size_t nPoint,; size_t nVar,; size_t nDim,; const vector<pair<size_t,size_t> >& connectivity,; const Matrix& coords,; const Matrix& phi,; const VectorOfMatrix& grad,; Matrix& phiMax,; Matrix& phiMin,; Matrix& limiter); {; for(size_t iPoint=0; iPoint<nPoint; ++iPoint); {; for(size_t iVar=0; iVar<nVar; ++iVar); {; phiMax(iPoint,iVar) = phi(iPoint,iVar);; phiMin(iPoint,iVar) = phi(iPoint,iVar);; limiter(iPoint,iVar) = 2.0;; }; }. for(auto edge : connectivity); {; size_t iPoint = edge.first;; size_t jPoint = edge.second;. for(size_t iVar=0; iVar<nVar; ++iVar); {; phiMax(iPoint,iVar) = max(phiMax(iPoint,iVar), phi(jPoint,iVar));; phiMin(iPoint,iVar) = min(phiMin(iPoint,iVar), phi(jPoint,iVar));. phiMax(jPoint,iVar) = max(phiMax(jPoint,iVar), phi(iPoint,iVar));; phiMin(jPoint,iVar) = min(phiMin(jPoint,iVar), phi(iPoint,iVar));; }; }. for(auto edge : connectivity); {; size_t iPoint = edge.first;; size_t jPoint = edge.second;. double d_ij[3] = {0.0, 0.0, 0.0};. for(size_t iDim=0; iDim<nDim; ++iDim); d_ij[iDim] = 0.5*(coords(jPoint,iDim)-coords(iPoint,iDim));. for(size_t iVar=0; iVar<nVar; ++iVar); {; double proj_i = 0.0, proj_j = 0.0;. for(size_t iDim=0; iDim<nDim; ++iDim); {; proj_i += d_ij[iDim]*grad(iPoint,iVar,iDim);; proj_j -= d_ij[iDim]*grad(jPoint,iVar,iDim);; }. doubl",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-530593912:476,bottleneck,bottleneck,476,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530593912,1,['bottleneck'],['bottleneck']
Performance,"Thanks Edwin, the vectorized loops in the code are probably very simple array copies, hence the low efficiency? I would put money on not a single vector instruction being generated for the important stuff. I was surprised by the 1.25 to 1.3 factor you are seeing, for the exact same case I measured 1.39 (to be more precise). Initially I thought it had something to do with running single core, thus leaving vast amounts of L3 for only that core to use, so on the same 24c platform I ran 2 processes (30MB of cache for each) (very uncivilised) and the factor went down to 1.37, so cache was not the reason.; So then I thought maybe the Intel compilers are very good at optimizing polymorphism away, but the development branch compiled with icc 17 runs at exactly the same speed as when compiled with gcc 5.4. Then I compiled feature_contiguous_cvariable with icc 17 and it runs 9% slower than the gcc binaries, and so with icc 17 the speedup for this case was 1.27 errrrr... Anyone got a buddy at Intel?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/716#issuecomment-523930905:509,cache,cache,509,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-523930905,3,"['cache', 'optimiz']","['cache', 'optimizing']"
Performance,"Thanks for the quick review @pcarruscag. I have cleaned up a little bit. Also added a nicer table of the output. l prefer that we always compute the min/max values, at least for the FVM CFD solvers, for a few reasons. The most important reason is that we should start to build up some intuition about the correlation between mesh quality metrics and accuracy + convergence in the solvers. This can be especially important during optimization when the mesh is deforming. I think the metrics are valuable to print every time for this reason, which might help users diagnose problems eventually. Additionally, the cost is relatively small (on par with the other pre-processing routines, it is only executed once and it is parallelized, and the memory is released if we don't write).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/778#issuecomment-526456264:429,optimiz,optimization,429,https://su2code.github.io,https://github.com/su2code/SU2/pull/778#issuecomment-526456264,1,['optimiz'],['optimization']
Performance,"There was a lot of talk about refactoring the shape optimization framework to be able to work completely in memory.; I think the idea was not to have more drivers but simply to have more granularity such that you could manipulate the geometry from python (without writing it to files).; We also wanted introspection, i.e. you could probe SU2 via python for what variables and functions are available.; We also talked about having the projection step (DOT) included in CFD_AD so that you only need to worry about surface sensitivities, note that DEF is already part of CFD for forward mode AD.; (talking does not go very far). If you want to lead this work, we can help you understand the inner workings. We meet every Wednesday at 4pm CET https://meet.jit.si/SU2_DevMeeting to discuss this type of issue.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1262#issuecomment-818786416:52,optimiz,optimization,52,https://su2code.github.io,https://github.com/su2code/SU2/issues/1262#issuecomment-818786416,1,['optimiz'],['optimization']
Performance,"These timings were all run this morning on the same cluster. . Using qperf, I'm seeing 80 microsecond latency. I'm also seeing the expected bandwidth using qperf as well. I would think that mpi would behave similarly but 100% sure. . I'm quite sure that the jobs are being launched correctly. I've checked that a bunch of times since that was my first instinct. I've both logged into all the machines and watched top and everything looked normal. And I've tried running SU2 v6 before and after v7, launching them the same way, and I keep getting the same numbers. I'm not sure how to check whether there is any reason non blocking comm would be ineffective. If you have any ideas I can certainly try something. I tried to download vampirtrace which seemingly can profile mpi, but it failed to compile against my version of mpi. When I get the chance I can try a different version of openmpi and see if I can get it running. The networking setup is pretty simple with all 4 machines plugged into the same switch and they share their own vlan as part of a bigger network. As I said, I ordered some faster networking equipment to see if it makes a difference (though I'm honestly not 100% sure that what I ordered will work with my comps but we'll see.)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/894#issuecomment-593144776:102,latency,latency,102,https://su2code.github.io,https://github.com/su2code/SU2/issues/894#issuecomment-593144776,1,['latency'],['latency']
Performance,"This is obviously very good work and should make it much simpler to add new outputs etc. My main concern when first reviewing was performance (something no one seems to care about) but from the limited testing I did while merging this and CVariable there seems to be no big impact, I did not time anything though, if you have numbers to share please do.; Nevertheless if you can get away with using unordered_map instead of map it would be better. Possibly part of the reason everyone puts of reviewing this is that it is a major refactoring and yet there are no accompanying notes about the architecture the implementation choices etc. I absolutely guarantee you that is not how professional software is developed.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/724#issuecomment-534651933:130,perform,performance,130,https://su2code.github.io,https://github.com/su2code/SU2/pull/724#issuecomment-534651933,1,['perform'],['performance']
Performance,"Vec(data_,offsets_); }. STRONGINLINE FltVec operator++(int) {; auto ret = (*this)(); offsets_ += Incr; return ret;; }; };; ```; so silly in fact, it only moves forward, we use it in our loop like so; ```c++; ...; auto gradI = grad.getColIterator(iPoint);; auto gradJ = grad.getColIterator(jPoint);. for(size_t iVar=0; iVar<nVar; ++iVar); {; FltVec phiL = 0.0;; FltVec phiR = 0.0;. for(size_t iDim=0; iDim<nDim; ++iDim); {; phiL += (gradI++)*d_ij[iDim];; phiR -= (gradJ++)*d_ij[iDim];; }; ...; ```; to get better assembly; ```asm; .L7:; vmovapd ymm3, ymm13; vmovapd ymm2, YMMWORD PTR [rbp-400]; add rax, 32; vgatherqpd ymm0, QWORD PTR [rcx+ymm1*8], ymm3; vpaddq ymm1, ymm1, ymm11; vmovapd YMMWORD PTR [rbp-272], ymm0; vmovapd YMMWORD PTR [rbp-240], ymm0; vfmadd132pd ymm0, ymm2, YMMWORD PTR [rax-32]; vmovdqa YMMWORD PTR [rbp-208], ymm1; vmovapd YMMWORD PTR [rbp-400], ymm0; cmp rax, rbx; jne .L7; ```; which makes the vectorized code perform just as well as the scalar code, iterators could also be used for the other variables but that would start to hurt readability without improving the performance much. _Note: There is also a chance the compiler (gcc) is not doing this kind of optimization because of the way I wrote the code..._. **So we need AoS to avoid losing performance in lightweight numerics classes.**. Before we look into the impact of not using SoA in the gradient and limiters routines let me tell you there is a way to have the best of both worlds, enter the *_array of structures of arrays_* or as I like to call it zig zag storage, aka a right mess.; Imagine an AoS of short arrays of SIMD length, e.g. `{ {u0 u1 u2 u3} {v0 ... v3} {w0 ... w3} {u4 u5 u6 u7} ... }` with that it is possible to fully vectorize point loops as the first index (iPoint) is contiguous in groups of SIMD length and when looping along variables and dimensions in edge loops the stride is small enough (equal to SIMD length) to trigger hardware prefetching.; The catch is that we need even more integer a",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-535977206:12332,perform,perform,12332,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206,2,['perform'],"['perform', 'performance']"
Performance,"YES! I am excited to try this out. I can probably test it on some of the other TMR cases (airfoils, flatplates). Will post the results when I get those done. . Side note, there was one issue that @bmunguia and I encountered when performing optimizations with adaptive CFL. Say the DIRECT simulation is run with adaptive CFL and is well converged (6 to 8 orders of residual reduction). When the discrete adjoint performs the one direct iteration to store the computational graph, it uses the initial CFL value, not the CFL that the adaptive CFL routine ended at. This results in the residuals being very high for that one iteration, which then affects the convergence of the discrete adjoint. . I will try to run an adjoint on one of these cases as well to see if the problem persists. Perhaps could be overcome with a simple additional field for CFL in the restart meta-data",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/790#issuecomment-531520526:229,perform,performing,229,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-531520526,3,"['optimiz', 'perform']","['optimizations', 'performing', 'performs']"
Performance,"```diff; $ git --no-pager diff --cached ; diff --git a/meson.build b/meson.build; index ca86992ea..b68a03c52 100644; --- a/meson.build; +++ b/meson.build; @@ -1,15 +1,12 @@; project('SU2', 'c', 'cpp',; version: '7.5.1 ""Blackbird""',; + meson_version: '0.61.1',; license: 'LGPL2',; default_options: ['buildtype=release',; 'warning_level=0',; 'c_std=c99',; 'cpp_std=c++11']); ; -if meson.version() != '0.61.1'; - error('SU2 must be configured with the extended Meson script (./meson.py) in the SU2 root directory.'); -endif; -; pymod = import('python'); python = pymod.find_installation(); ; ```. I used this patch, and then ran the following:. ```; $ meson setup builddir --wipe; The Meson build system; Version: 1.0.1; Source dir: /tmp/SU2; Build dir: /tmp/SU2/builddir; Build type: native build. meson.build:1:0: ERROR: Meson version is 1.0.1 but project requires 0.61.1; ```. Using the >= comparison, it configures fine, and downloads a git submodule for mutationpp/coolprop on demand. From a hasty look around, it seems like the other git submodules are used as externals/ directories, not meson subprojects. Another project I know uses e.g. ```; if not fs.exists('submoduledir/README.md'); error('Missing the `submoduledir` submodule! Run `git submodule update --init` to fix this.'); endif; ```. for each submodule before it gets processed by meson. This is less automatic than wrapping it in meson.py, but does provide pretty clear directions... the sticking point is if people download tarballs. You currently point people to github's autogenerated archives, which is NOT sufficient as it doesn't have submodules included. I would actually suggest using `meson dist --include-subprojects --no-tests` to produce your own tarballs and attach them as additional releases artifacts. Meson *does* include submodules (whether or not they are subprojects) automatically to the tarball it creates.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1945#issuecomment-1451057434:33,cache,cached,33,https://su2code.github.io,https://github.com/su2code/SU2/issues/1945#issuecomment-1451057434,1,['cache'],['cached']
Performance,"ays to do this, for example using [x86 intrinsics](https://software.intel.com/sites/landingpage/IntrinsicsGuide/#expand=2273,2273,2436,2943,2436,2943,610,1788,2942) (in header `<x86intrin.h>`), register types instead of arrays, and a boat load of template meta-programming (I'm guessing) there are professional libraries for this.; This quickly-hacked-together code is compatible with custom types, portable, and seems to do the trick. To pull this off we do not need to have `Vector` or `Matrix` of this class, the underlying type for those data structures is still `double`, only the `getVec` type methods need to convert on the fly to the SIMD type, for example:; ```C++; // use the ""pointer ctor"" to return an array starting at ""row0""; Array<double,4> Matrix<double>::getVec(size_t row0, size_t col) const {; return Array<double,4>(&data_[row0+col*rows_]);; }. // use the ""gather ctor"" to return an array with the indices in ""rows""; template<class U>; Array<double,4> Matrix<double>::getVec(const U& rows, size_t col) const {; return Array<double,4>(&data_[col*rows_], rows);; }; ```; After inlining those copies get optimized away.; Although the stored type, and ""scalar interface"" of the containers do not need to change, the storage order of the data does. Notice that in the above data is stored by columns instead of rows (something that @vdweide mentioned in #716) this has greater implications for gradients as instead of the familiar ""vector of matrices"" we would need a ""matrix of vectors"", i.e. the derivative of variable i w.r.t. coordinate j stored as a vector for all points. The `Adjacency` also needs to be stored in a funny way. For the scalar version of the code it was stored as a CSR sparse matrix (one array of indices into the arrays of data for each point, the rows).; For the vectorized version we want to load (small) arrays of jPoint's, arrays of iEdge's, and arrays of directions, and as we know either those are contiguous or we take a huge performance hit.; If all poi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-530328194:9772,optimiz,optimized,9772,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530328194,1,['optimiz'],['optimized']
Performance,"centages only, normalized by that of CFluidIteration::Iterate (to exclude pre-processing time) and multiplied the results from the total ""iteration time"" from the history file. Doing that for before and after results allowed computing individual speedup factors for each important routine (in terms of time, otherwise they are all special and important in their own way) e.g. gradients, limiters, upwind/viscous residuals, etc.; ![image](https://user-images.githubusercontent.com/38071223/63292708-30cfa480-c2be-11e9-8d4a-5feb3dc61abf.png). Here is the data by the way: [results.xlsx](https://github.com/su2code/SU2/files/3517492/results.xlsx). As predicted the linear solvers stay the same and routines that are light see more speedup than their arithmetic-intensive friends.; What is surprising to me is how intensive the convective residuals appear to be with only a 7% improvement, so surprising in fact, I do not think the above paints the full picture. Maybe the outlet bandwidth bottleneck (into the Jacobian matrix) is more important.; To put that do the test I switched to Euler-explicit time marching and repeated the measurements:; ![image](https://user-images.githubusercontent.com/38071223/63293351-d8010b80-c2bf-11e9-8135-2502eac1128e.png); Better, but not by much, which means upwind and viscous residuals computations might gain a lot from vectorization (SIMD). And like @economon mentioned even more if they are somehow fused together.; It also means the writes to CSysMatrix are relatively expensive, I think there are two-three reasons for it.; - We do a linear search on each Add/SubtractBlock - This could be replaced by a map.; - The Jacobian contributions are first written into a temporary block - Interleaving the writes with the computation could help mask latency.; - That temporary is not stored contiguously - Which makes it hard to vectorize the writes to CSysMatrix. **So what do I think should be tackled next?**; Hybrid parallelism (wait what?!) from messing about wi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/716#issuecomment-522730951:4284,bottleneck,bottleneck,4284,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-522730951,1,['bottleneck'],['bottleneck']
Performance,"computations are very simple it may not pay-off to vectorize. **Relation with algorithms**; Some form of `gather` and `scatter` is required in unstructured CFD, which means SIMD has a price of admission. Some thought needs to go into designing algorithms that amortize that cost by maximizing the so called FLOP/Byte ratio, and mask the latency of those operations by being able to start computing as soon as the first element of data is available. **What elements should we try to process simultaneously?**; The choice is between multiple geometric primitives (edges/points) or multiple solution primitives (variables). The latter sounds like a sensible idea until we get to areas of the code where different primitives require different treatment, that and the fact that the number of variables might not fit evenly in the number of lanes can lead to very tricky and non-generic code. Nevertheless if the same code were to be applied to e.g. 4 solution variables, this strategy would likely perform better as it avoids the pesky gather/scatter operations.; Processing multiple geometric primitives can make full utilization of whatever register size (important on GPU's), the code is just as readable (as I hope to show), but gather/scatter cannot be avoided. ### Intro to SPMD; This one is simpler, in a nutshell multiple threads operate on the sub domain of an MPI rank.; The typical implementation has each thread executing a chunk of an edge or cell loop. **Why should we care about SPMD?**; Reduce the communication overhead resulting from domain decomposition and improve load balancing, important for strong scaling.; Some algorithms are more efficient that way, e.g. the ADT (as mentioned by Edwin), the current MG also seems to work better on fewer partitions, and additive versions of preconditioners like the ILU or LU-SGS lose effectiveness with number of partitions.; Optimum hardware utilization, for routines that are bandwidth-bound it may be beneficial to use all threads available",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-529662724:2588,perform,perform,2588,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-529662724,1,['perform'],['perform']
Performance,"dweide; >(...) @bmunguia and @EduardoMolina, what type of application did you have in mind for PETSc? The only thing I can think of is a full Newton solver. And no matter how much I like PETSc, @juanjosealonso and @erangit have a point here. Looks like I start to belong to the group of old conservatives as well.... >@economon ; >(...) If you really would like to give PETSc a shot, I recommend talking with @anilvar who had an interface for connecting it to SU2 in one of our branches. >@pcarruscag; >(...) being able to use PETSc or HYPRE would be interesting as it would give us access to AMG, and @talbring 's branch feature_template_linear_solver would make such an integration compatible with AD. (...). >@EduardoMolina; >(...) When Brian (@bmunguia ) and I mentioned PETSc, it was an idea to try a different Newton-Krylov (with preconditioner) library in order to improve the convergence of SU2.; Since the slow convergence of the SU2-FV is the main feedback that I received from other users from industry and academia, I think it worth try an external library and evaluate the performance. (...). >@pcarruscag ; >(...) That is something I am also interested in as for some of my structural cases the current linear solvers simply do not converge. (...). >@economon ; >I would add one practical comment for consideration: it is worth checking whether the main restriction we have is related to approximations in the Jacobian that limit the effective CFL we can use or whether the convergence of the linear solver itself is a problem (speed or complete lack of convergence). A quick test without resorting to another library is to increase the fill-in for ILU-preconditioned GMRES, which is very expensive/slow but should converge difficult problems, and to check how high we can take the CFL when allowing each nonlinear iteration to converge to a tight tolerance in the linear solver, say 1e-14 (you can output the linear solver residuals to verify convergence). If we can take the CFL higher",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/648#issuecomment-460853218:2949,perform,performance,2949,https://su2code.github.io,https://github.com/su2code/SU2/issues/648#issuecomment-460853218,1,['perform'],['performance']
Performance,"e use it in our loop like so; ```c++; ...; auto gradI = grad.getColIterator(iPoint);; auto gradJ = grad.getColIterator(jPoint);. for(size_t iVar=0; iVar<nVar; ++iVar); {; FltVec phiL = 0.0;; FltVec phiR = 0.0;. for(size_t iDim=0; iDim<nDim; ++iDim); {; phiL += (gradI++)*d_ij[iDim];; phiR -= (gradJ++)*d_ij[iDim];; }; ...; ```; to get better assembly; ```asm; .L7:; vmovapd ymm3, ymm13; vmovapd ymm2, YMMWORD PTR [rbp-400]; add rax, 32; vgatherqpd ymm0, QWORD PTR [rcx+ymm1*8], ymm3; vpaddq ymm1, ymm1, ymm11; vmovapd YMMWORD PTR [rbp-272], ymm0; vmovapd YMMWORD PTR [rbp-240], ymm0; vfmadd132pd ymm0, ymm2, YMMWORD PTR [rax-32]; vmovdqa YMMWORD PTR [rbp-208], ymm1; vmovapd YMMWORD PTR [rbp-400], ymm0; cmp rax, rbx; jne .L7; ```; which makes the vectorized code perform just as well as the scalar code, iterators could also be used for the other variables but that would start to hurt readability without improving the performance much. _Note: There is also a chance the compiler (gcc) is not doing this kind of optimization because of the way I wrote the code..._. **So we need AoS to avoid losing performance in lightweight numerics classes.**. Before we look into the impact of not using SoA in the gradient and limiters routines let me tell you there is a way to have the best of both worlds, enter the *_array of structures of arrays_* or as I like to call it zig zag storage, aka a right mess.; Imagine an AoS of short arrays of SIMD length, e.g. `{ {u0 u1 u2 u3} {v0 ... v3} {w0 ... w3} {u4 u5 u6 u7} ... }` with that it is possible to fully vectorize point loops as the first index (iPoint) is contiguous in groups of SIMD length and when looping along variables and dimensions in edge loops the stride is small enough (equal to SIMD length) to trigger hardware prefetching.; The catch is that we need even more integer arithmetic and so we really need iterators to amortise that cost, there is also the drawback that scalar usage of such a container would be terrible. **For these reasons I",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-535977206:12582,optimiz,optimization,12582,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206,1,['optimiz'],['optimization']
Performance,"ead_id * MAX_TERMS`.; I think someone mentioned this (maybe Tim) that we could revisit the ownership relations of the numerics classes, i.e. allocate them as members of their respective solvers, which if we do, we can think of having a purpose built container that automates the per-thread creation and access. > Why are they redefined each time inside the loop?; > Is this for efficiency reasons?. Referring to variables being declared inside loops. One stylist reason is that declaring everything at the top of a function is the C way of doing things, the C++ people whose books/blogs I've read and talks I've watched, recommend keeping namespaces (the inside of the loop being one) as clean as possible.; The only reason not to do this is if you explicitly want re-use, in the case of trivial types this does not improve efficiency, and in the context of OpenMP code it can create issues. Just like we need one numerics per thread, if we declare variables outside a parallel loop the default OpenMP behaviour is to consider them shared, and concurrent writes to shared locations = gdb and many bad words xD.; **EDIT:** I should mention here that if the parallel region is started before the variable declarations they become local and all is well, with the exception of class members, those will be shared most of the time (this is where const correctness can give some peace of mind). > Also, just an additional (hopefully constructive) comment: I find all of these developments great, and I honestly think that you are doing an amazing job on performance and overall code improvement. However, as a non-C++-master myself, I'm just a little concerned of whether some advanced programming may become an entrance barrier to new additions to the community. As I wrote in the preamble of #789:; ""But please participate even if you never heard of these topics, your opinion about readability and ""developability"" of the code is important! I think the code-style should be accessible to people starting ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/843#issuecomment-577684728:2965,concurren,concurrent,2965,https://su2code.github.io,https://github.com/su2code/SU2/pull/843#issuecomment-577684728,1,['concurren'],['concurrent']
Performance,"eature_adapt branch`. 2. downloaded the Adaptive 2D NACA 0012 example (https://pyamg.saclay.inria.fr/pyamgexamples.html#2dnaca): `adap_NACA0012.cfg`, `mesh_NACA0012_inv.su2`, `NACA0012_ini.dat`. 3. added the following lines to the config:; ```; % Type of sensor used for adaptation; % Options include GOAL (adjoint-based), MACH, PRES; PYADAP_SENSOR= GOAL; % Objective function used for goal-oriented adaptation; OBJECTIVE_FUNCTION= LIFT; % Maximum cell size for adaptation; PYADAP_HMAX= 500.0; % Minimum cell size for adaptation; PYADAP_HMIN= 1e-9; % Gradation factor (typically 1.2-1.8); PYADAP_HGRAD= 1.8; % Norm used for adaptation; % 1.0 or 2.0 recommended for inviscid flows; % 4.0 recommeneded for viscid; ADAP_NORM= 4.0; % Approximate mesh size (NPOI) at each level; PYADAP_COMPLEXITY= (30000, 60000, 120000); % Number of adaptations performed at each level; PYADAP_SUBITE= (3, 3, 3); ```. 4. run the following command: `$ python3 SU2_RUN/mesh_adaptation_amg.py -f adap_ONERAM6.cfg -n 8`. The response I have obtained is the following:; ```; SU2-AMG Anisotropic Mesh Adaptation. Mesh adaptation options:; PYADAP_COMPLEXITY : (30000, 60000, 120000); PYADAP_SUBITE : (2, 2, 2); PYADAP_SENSOR : MACH; PYADAP_HMAX : 500.0; PYADAP_HMIN : 1e-9; PYADAP_HGRAD : 1.8; PYADAP_FLOW_ITER : (2999, 4999, 6999); PYADAP_ADJ_ITER : (2999, 4999, 6999); PYADAP_CFL : (10.0, 15.0, 20.0); PYADAP_RDG : NO. The ./adap folder was deleted. Generating GMF background surface mesh.; ## WARNING: MISSING SU2 MESH FILE KEYWORD: NCORNERS=.; Initial CFD solution is provided.; ```. As expected, a `./ADAP` folder was created, containing these docs: `amg_back_meshb`, `config_CFD.cfd`, `log.err`, `log.out` (sizes 0 byte), `mesh_NACA0012_inv.su2` (link to the mesh), `NACA0012_ini.dat` (link to the file.dat). Did I perform the procedure correctly? Or did I miss something?; If it is correct and complete, which file contains the adaptive mesh? How can I use it since there is no new .su2 file? . Thank you for the big help",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/948#issuecomment-737134105:1958,perform,perform,1958,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-737134105,1,['perform'],['perform']
Performance,"ed the linear solvers stay the same and routines that are light see more speedup than their arithmetic-intensive friends.; What is surprising to me is how intensive the convective residuals appear to be with only a 7% improvement, so surprising in fact, I do not think the above paints the full picture. Maybe the outlet bandwidth bottleneck (into the Jacobian matrix) is more important.; To put that do the test I switched to Euler-explicit time marching and repeated the measurements:; ![image](https://user-images.githubusercontent.com/38071223/63293351-d8010b80-c2bf-11e9-8135-2502eac1128e.png); Better, but not by much, which means upwind and viscous residuals computations might gain a lot from vectorization (SIMD). And like @economon mentioned even more if they are somehow fused together.; It also means the writes to CSysMatrix are relatively expensive, I think there are two-three reasons for it.; - We do a linear search on each Add/SubtractBlock - This could be replaced by a map.; - The Jacobian contributions are first written into a temporary block - Interleaving the writes with the computation could help mask latency.; - That temporary is not stored contiguously - Which makes it hard to vectorize the writes to CSysMatrix. **So what do I think should be tackled next?**; Hybrid parallelism (wait what?!) from messing about with this case (and more refined versions) it is clear the MG puts some limits on how many cores can be used before it stops being able to produce coarse grids, both in number and quality. Going to an MPI+Threads strategy would move that limit by one order of magnitude, giving us some robustness and performance for folks hoping to rely on strong scaling. I think I'll break it off here and keep my thoughts about SIMD and hybrid parallel for a later occasion (I have to do some ""real"" PhD work for a while) but please, if anyone has ideias, comments, corrections, suggestions, similar ongoing developments (specially)... I am all ears/eyes. Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/716#issuecomment-522730951:5081,latency,latency,5081,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-522730951,2,"['latency', 'perform']","['latency', 'performance']"
Performance,"enced only once per color (this definition gives you the basis of a greedy algorithm to color edges).; - **Scatter to gather transformations**: Edge quantities (e.g. fluxes) are computed and stored on one pass (i.e. we read from 2 locations and write to 1), on a second pass, over points, we reduce (e.g. sum) the edge quantities for each point, again a gather access pattern. It may also be possible to convert the entire algorithm to a loop over points instead of edges.; - **Atomic operations or locks**: Here when a thread wants to write to a memory location it either needs to do so atomically (this is essentially an operations that always goes through main memory and forces cache coherency) or it needs to acquire a *lock* for the point it is writing to, if it fails to acquire the *lock* (because another thread has it) it needs to wait. None of these is without drawbacks.; - **Coloring** reduces temporal locality, edges are sorted in increasing order of the point indices to reduce cache misses, this means small groups of contiguous edges will share the same ""iPoint"", coloring single edges destroys this. Furthermore coloring either requires edges to be re-sorted by color, or if the edge indices of each color are instead kept in arrays, performance will suffer due to increased indirection which confounds the hardware pre-fetcher.; This can be mitigated to some extent by coloring groups of edges, groups of edges of the same color can be processed simultaneously, but within each group edges need to be processed serially. However grouping will reduce how much parallelism can be exploited within each color.; - **Gather to scatter** will in general use more memory due to the intermediate variables and extra adjacency information needed. If the entire algorithm is transformed performance may suffer as some computations may have to be repeated.; However, some reductions are possible without intermediate variables, for example when assembling the system matrix for implicit sche",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-529662724:5164,cache,cache,5164,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-529662724,1,['cache'],['cache']
Performance,"ents. Registers are at the very top of the memory hierarchy, for any computation to be performed data needs to be in registers.; An AVX register is 256 bits wide, that means 4 lanes of doubles or 8 of floats, AVX-512 (available in Xeon-Phi and SkylakeX processors) doubles the size. By GPU standards these are rookie numbers. **Why should we care about SIMD?**; Because it is the only way to use the whole silicon, by and large vector instructions have the same latency and throughput of their scalar versions, therefore speedups proportional to the number of SIMD lanes are possible in compute-bound code.; As we saw in #716 there is some of that in the numerics, do not expect 4x speed-ups though, low order unstructured FVM is known to be bandwidth-bound, vectorization helps a bit there too (instructions are also data that needs to travel to the CPU) (maybe for explicit schemes and 8 SIMD lanes, maybe). **Relation with data structures**; There is only one efficient way to move data between memory and registers, via `load` and `store` instructions (they do come in multiple flavors). That is, pointing to a memory location and reading or writing N elements of contiguous data.; It is not the only way, it is also possible to `gather` and `scatter` data. That is populating the register from non-contiguous locations and vice versa. This is about one order of magnitude slower, to the point where if the computations are very simple it may not pay-off to vectorize. **Relation with algorithms**; Some form of `gather` and `scatter` is required in unstructured CFD, which means SIMD has a price of admission. Some thought needs to go into designing algorithms that amortize that cost by maximizing the so called FLOP/Byte ratio, and mask the latency of those operations by being able to start computing as soon as the first element of data is available. **What elements should we try to process simultaneously?**; The choice is between multiple geometric primitives (edges/points) or multiple s",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-529662724:1209,load,load,1209,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-529662724,1,['load'],['load']
Performance,"er the communication to make sure the correct values are passed and _seen_ by all threads.; We can test other alternatives in the future but at the moment this does not seem to be a significant bottleneck.; _Worksharing_ constructs have implicit barriers at completion, for CSysVector routines I used `nowait` modifiers, it is safe to call those routines in sequence since the loop sizes, and static work scheduling specifications are identical.; However, routines that access a CSysVector in a different way, should have an explicit barrier before using the vector (or risk having undefined behaviour). You will see these barriers on entry to matrix-vector product, and every `ComputeXXXPreconditioner` (if you don't, let me know xD). I think those routines are large enough to amortise the cost of this. ### Performance; Disclaimer:; - We are talking about linear solvers only, **you will not see a global improvement yet**.; - The large global improvements from ""hybridization"" will come from the multigrid behaving better on less decomposed domains, and from the ability to independently tune the number of cores used in the linear preconditioners. For now the objective is ""just"" not to loose performance while gaining flexibility.; - The performance of MPI+threads with 1 thread per rank will be worse than just MPI (no free lunches). With this [small case](https://github.com/su2code/SU2/files/3933059/small_case.zip) using 8 cores off a machine with two 2650v4 CPU, Intel MPI 2018 + GCC 8.2, the hybrid (2 ranks of 4 threads) approach is about 5% faster thank the MPI-only (8 ranks), I expect larger cases to have identical performance. ### How To; - Compile: Add -fopenmp to the compiler and linker arguments.; - Run: Set number of threads with env variable `OMP_NUM_THREADS` (eventually I will make that a command line parameter), for best performance set `OMP_WAIT_POLICY=ACTIVE` and beware of thread binding settings, use `mpirun --bind-to socket` or `mpirun --bind-to numa` never `core`.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/830#issuecomment-562646766:2927,tune,tune,2927,https://su2code.github.io,https://github.com/su2code/SU2/pull/830#issuecomment-562646766,5,"['perform', 'tune']","['performance', 'tune']"
Performance,"er thread has it) it needs to wait. None of these is without drawbacks.; - **Coloring** reduces temporal locality, edges are sorted in increasing order of the point indices to reduce cache misses, this means small groups of contiguous edges will share the same ""iPoint"", coloring single edges destroys this. Furthermore coloring either requires edges to be re-sorted by color, or if the edge indices of each color are instead kept in arrays, performance will suffer due to increased indirection which confounds the hardware pre-fetcher.; This can be mitigated to some extent by coloring groups of edges, groups of edges of the same color can be processed simultaneously, but within each group edges need to be processed serially. However grouping will reduce how much parallelism can be exploited within each color.; - **Gather to scatter** will in general use more memory due to the intermediate variables and extra adjacency information needed. If the entire algorithm is transformed performance may suffer as some computations may have to be repeated.; However, some reductions are possible without intermediate variables, for example when assembling the system matrix for implicit schemes only the diagonal entries can result in race conditions, now it just so happens that each diagonal entry is equal to the negated corresponding column sum.; - **Atomics** are terrible for the performance of code that writes frequently to memory (i.e. bandwidth-bound code), they do not increase the memory footprint and so make sense for compute-bound code.; Bugs due to a missing atomic can be very hard to debug (but any race condition is). Coloring is what one sees most in the literature, and yet I lean towards gather-to-scatter. Fewer things can go wrong with it as it is easy to understand, one gets the maximum amount of parallelism. I will now take two familiar routines, computing gradients (Green-Gauss) and limiters, vectorize / parallelize them in different ways, and measure relative performanc",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-529662724:5967,perform,performance,5967,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-529662724,1,['perform'],['performance']
Performance,"everything at the top of a function is the C way of doing things, the C++ people whose books/blogs I've read and talks I've watched, recommend keeping namespaces (the inside of the loop being one) as clean as possible.; The only reason not to do this is if you explicitly want re-use, in the case of trivial types this does not improve efficiency, and in the context of OpenMP code it can create issues. Just like we need one numerics per thread, if we declare variables outside a parallel loop the default OpenMP behaviour is to consider them shared, and concurrent writes to shared locations = gdb and many bad words xD.; **EDIT:** I should mention here that if the parallel region is started before the variable declarations they become local and all is well, with the exception of class members, those will be shared most of the time (this is where const correctness can give some peace of mind). > Also, just an additional (hopefully constructive) comment: I find all of these developments great, and I honestly think that you are doing an amazing job on performance and overall code improvement. However, as a non-C++-master myself, I'm just a little concerned of whether some advanced programming may become an entrance barrier to new additions to the community. As I wrote in the preamble of #789:; ""But please participate even if you never heard of these topics, your opinion about readability and ""developability"" of the code is important! I think the code-style should be accessible to people starting a PhD (after they read a bit about C++...).""; I try to encapsulate and hide the tricky bits as much as possible to make the code as readable as possible, whether I am succeeding or not is for the community to decide, in all these PR's I've been pointing to the areas I think are trickier, if someone, anyone, feels they are absolutely incomprehensible please say something... either here, or trough slack, or by email (I think it shows in the commits) (I understand not everyone is keen o",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/843#issuecomment-577684728:3469,perform,performance,3469,https://su2code.github.io,https://github.com/su2code/SU2/pull/843#issuecomment-577684728,1,['perform'],['performance']
Performance,"he end of the loop we need to de-swizzle the flux to update the multiple indexes references by iPoint and jPoint, which are now short arrays of integers (this operation can be moved to the container, akin to `getVec` but I show it here for clarity). **With SoA (aka column major storage) this code is 1.5 times slower than the scalar version.**. The reason for that is poor locality (of the spacial variety), as we loop through the number of variables and dimensions we are accessing the data in strides of nPoint, as the contiguous index is the first one so that we can perform vector read/writes when computing gradients and limiters.; With the scalar version the data for each point is contiguous which means on the first access we get whatever extra data is on the same cache line for free and subsequent accesses will be hardware prefetched since the stride is small (1 in this case). We lose all this with SoA storage. If we go back to arrays of structures (AoS, aka row major storage, basically what we have in #753) performance is only 9% worse (the code is identical). Those 9% are mostly due to increased integer arithmetic in the accesses to the data, on each call to `getVec` we resolve 4/8 row/column pairs into 1D indexes, while this calculation is vectorized, it seems to be less optimizable by compilers, for example this; ```c++; for(size_t iDim=0; iDim<nDim; ++iDim); phiL += grad.getVec(iPoint,iVar,iDim)*d_ij[iDim];; ```; gets compiled into this monstrosity; ```asm; .L13:; vpmuludq ymm0, ymm4, ymm1; vmovq xmm15, rax; vmovapd ymm6, ymm11; mov rdx, rax; vpbroadcastq ymm15, xmm15; sal rdx, 5; add rax, 1; vpaddq ymm0, ymm0, ymm2; vpsllq ymm0, ymm0, 32; vpaddq ymm0, ymm5, ymm0; vmovdqa YMMWORD PTR [rbp-240], ymm0; vpaddq ymm0, ymm3, ymm0; vmovdqa YMMWORD PTR [rbp-208], ymm0; vpaddq ymm0, ymm15, ymm0; vmovdqa YMMWORD PTR [rbp-176], ymm0; vgatherqpd ymm15, QWORD PTR [rdi+ymm0*8], ymm6; vmovapd ymm0, YMMWORD PTR [rsi+rdx]; vfmadd213pd ymm0, ymm15, YMMWORD PTR [rbp-336]; vmovapd ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-535977206:8977,perform,performance,8977,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206,1,['perform'],['performance']
Performance,"hort array of matrices, the result of that is code like the above that explicitly manipulates the lanes of our SIMD type, such code can be completely hidden inside CSysMatrix which is good because a 4x4 vectorized transpose and matrix update looks like this; ```c++; // block j, subs from jj and goes to ij; T0 = blk_j[ k ].unpackLo(blk_j[k+1]); T1 = blk_j[ k ].unpackHi(blk_j[k+1]);; T2 = blk_j[k+2].unpackLo(blk_j[k+3]); T3 = blk_j[k+2].unpackHi(blk_j[k+3]);. C0 = T0.widePermuteLo(T2); C1 = T1.widePermuteLo(T3);; C2 = T0.widePermuteHi(T2); C3 = T1.widePermuteHi(T3);. (Array4d(&bjj[0][k])-C0).store(&bjj[0][k]);; (Array4d(&bjj[1][k])-C1).store(&bjj[1][k]);; (Array4d(&bjj[2][k])-C2).store(&bjj[2][k]);; (Array4d(&bjj[3][k])-C3).store(&bjj[3][k]);. C0.store(&bij[0][k]); C1.store(&bij[1][k]);; C2.store(&bij[2][k]); C3.store(&bij[3][k]);; ```; I am showing this because it represents a readability worst case in terms of manipulating SIMD types, we might end up with one or two of these to get the best performance possible but they will always be encapsulated and deep in kernel-type areas of SU2 that are almost never touched. ## Conclusions; - Over 45% faster CSysMatrix updates by mapping off-diagonal blocks to edges and diagonal blocks to points.; - Colouring is the best strategy for hybrid parallelism of compute-heavy edge loops and matrix updates as it interleaves compute and memory operations.; - AoS storage should be kept to avoid significant loss of performance in compute-light edge loops due to poor locality of SoA storage.; - Major implication of AoS is on point loops where some data needs to be fetched (transposed) into local variables for effective vectorization.; - An intermediate storage scheme, AoSoA, can provide both good locality and vectorization of point loops, however it requires that data be accessed via special iterators and scalar code based on it would have poor performance. Next I will try to estimate how much we can gain for a ""realistic"" numerics class.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-535977206:17010,perform,performance,17010,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206,2,['perform'],['performance']
Performance,"iVar, lim*(lim+2.0)/(lim*lim+lim+2.0));; }; }; }; ```; In terms of algorithm, for each point we find the min and max neighbor values and the min (negative) and max (positive) projections, those are then combined in a final `min(2, max/max, min/min)` to which the limiter function is applied (this would also be applicable to Venkatakrishnan-[Wang] limiters).; This is equivalent to the edge-loop, if statements are not required as due to cells being closed, if the positive projection is not zero, the negative one will also not be zero, therefore it is correct to always evaluate both ratios.; This algorithm only needs min and max neighbors as small local variables instead of large global ones due to the way those values are determined. This is where the memory from the extra adjacency information is recovered. Like @economon said, fusing the gradient kernel with the limiter kernel is trivial with these point loops, and I do not think it affects readability much since one can clearly tell ""what is what"" (I will not put it here but it really is a matter of copy paste), including the boundaries could be a bit more challenging, but I will give performance number nevertheless. **Performance summary**. | Code | Edge | Edge, SIMD on vars | Point | Point, SIMD on points |; | ---- | ---- | ---- | ---- | ---- |; | **Speed 1 core** | 1.0 | 1.75 | 1.25 | 2.0 |; | **Speed 4 cores** | 2.45 | 2.7 | 4.5 | 7.0 |. The basic point version does not lose to edge based because, contrary to gradients, it does not require duplication of computations while benefiting from sequential access to gradients.; Again the point-based implementation does really well in parallel, limiters are more compute intensive and so the scaling is almost perfect.; For reference, limiters are 1.9 times more expensive to compute than gradients with the reference edge version. With point loops, SIMD, and in parallel, gradients and limiters cost the same. If we consider the combined cost of gradients and limiters, and co",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-530593912:10182,perform,performance,10182,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530593912,1,['perform'],['performance']
Performance,"irst;; size_t jPoint = connectivity[iEdge].second;; ```; Apologies for the macro but it is just to illustrate that if we re-sort edge data after coloring the edge index is the loop index, otherwise the edge indices for each color need to be stored in a separate array.; Note that for each edge loop we first loop over colors, then over same-color edges, it is this inner loop that can run in parallel in chunk sizes that are multiple of the group size considered during coloring. There is some runtime cost on entry to every #omp parallel section, with coloring we enter one such section once by color. I mentioned in the introduction coloring reduces locality and therefore performance, here is the effect of color group size on the execution time of the scalar code on one thread:; ![image](https://user-images.githubusercontent.com/38071223/64686801-2e0d3d00-d481-11e9-82a0-c56e5554cd83.png); The hassle-free option of not sorting by color ""never"" recovers the performance of the base algorithm, things are even worse for the SIMD version where even at group size of 8192 with re-sorting the slowdown is 14%. Running the edge-loop version on 4 cores (8192 group + sorting) we get speedups (relative to reference) of **1.98** and **2.04** for the scalar and SIMD versions respectively (yes I quadruple checked).; If you are keeping track of the number two things should surprise you, the first is that there is no difference between scalar and SIMD now (the vector instruction are still there though), the second is that 4 cores give only a 2x speedup. The reason for both is: the implementation is very memory-bound, and so throwing more compute at it, either in the form of more cores or more lanes, does not help much. This is the 4 core summary:. | Code | Edge | Edge, SIMD on vars | Point | Point, SIMD on points |; | ---- | ---- | ---- | ---- | ---- |; | **Speed** | 2.0 | 2.0 | 3.8 | 2.8 |. I think the point-based versions scale better because they are a bit less memory-bound as they write ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-530328194:14089,perform,performance,14089,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530328194,1,['perform'],['performance']
Performance,"ix updates without colouring by setting only the off-diagonal coefficients and then setting the diagonal entries to the column sum.; It turns out that this is worse (by about 10%), maybe if the matrix were symmetric (row sum) but a column sum accesses blocks very far apart. Also we want to interleave compute and load/stores as much as possible to allow the CPU pipelining magic to mask the latency of the latter (even if it looks like you can only write the block after it is computed, CPU's have all kinds of buffers that allow the next loop iteration to begin while data is in flight). **Therefore colouring is the way to go.**. _Note: With vectorized numerics we insert blocks for 4 or 8 edges into the matrix at a time, the data for those inserts will be in a slightly weird format, which will make `SparseMatrix::updateBlocks` a bit harder on the eye, more on that later._. ## MUSCL Reconstruction; The MUSCL reconstruction, characteristic of upwind schemes, is the simplest building block to show the (negative) implications of storing the data as structures of arrays (SoA) on the performance of some operations.; Here is the most basic numerics you can think of, reconstruct and average (the dummy matrix loop was to benchmark the writes this is to benchmark the reads); ```c++; void computeResidual(size_t nVar,; size_t nDim,; const vector<size_t>& colorStart,; const vector<size_t>& edgeIdx,; const vector<pair<size_t,size_t> >& connectivity,; const Matrix& coords,; const Matrix& phi,; const VectorOfMatrix& grad,; const Matrix& limiter,; Matrix& residual); {; residual.setZero();. for(size_t color=0; color<colorStart.size()-1; ++color); #pragma omp parallel for schedule(dynamic,CHUNK_SIZE); for(size_t k=colorStart[color]; k<colorStart[color+1]; ++k); {; size_t iEdge = edgeIdx[k];; size_t iPoint = connectivity[iEdge].first;; size_t jPoint = connectivity[iEdge].second;. double d_ij[MAXNDIM];; for(size_t iDim=0; iDim<nDim; ++iDim); d_ij[iDim] = 0.5*(coords(jPoint,iDim)-coords(iPoint",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-535977206:5797,perform,performance,5797,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206,1,['perform'],['performance']
Performance,"k];}; STRONGINLINE T operator[] (size_t k) const {return vals_[k];}. // **** MATH OPERATORS **** //; STRONGINLINE Array& operator= (const Array& rhs); {; #pragma omp simd; FOREACH vals_[k] = rhs.vals_[k];; return *this;; }. STRONGINLINE Array& operator+= (const Array& rhs); {; #pragma omp simd; FOREACH vals_[k] += rhs.vals_[k];; return *this;; }; STRONGINLINE Array operator+ (const Array& rhs) const { return Array(*this)+=rhs; }; ; /*; * Many other operators go here.; */; };. // Common math function overloads; template<class T>; STRONGINLINE T vmax(const T& a, const T& b); {; T res;; #pragma omp simd; for(size_t k=0; k<T::Size; ++k); res[k] = (a[k]>b[k])? a[k] : b[k];; return res;; }. #undef FOREACH; ```; There are other (better) ways to do this, for example using [x86 intrinsics](https://software.intel.com/sites/landingpage/IntrinsicsGuide/#expand=2273,2273,2436,2943,2436,2943,610,1788,2942) (in header `<x86intrin.h>`), register types instead of arrays, and a boat load of template meta-programming (I'm guessing) there are professional libraries for this.; This quickly-hacked-together code is compatible with custom types, portable, and seems to do the trick. To pull this off we do not need to have `Vector` or `Matrix` of this class, the underlying type for those data structures is still `double`, only the `getVec` type methods need to convert on the fly to the SIMD type, for example:; ```C++; // use the ""pointer ctor"" to return an array starting at ""row0""; Array<double,4> Matrix<double>::getVec(size_t row0, size_t col) const {; return Array<double,4>(&data_[row0+col*rows_]);; }. // use the ""gather ctor"" to return an array with the indices in ""rows""; template<class U>; Array<double,4> Matrix<double>::getVec(const U& rows, size_t col) const {; return Array<double,4>(&data_[col*rows_], rows);; }; ```; After inlining those copies get optimized away.; Although the stored type, and ""scalar interface"" of the containers do not need to change, the storage order of the data d",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-530328194:8890,load,load,8890,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530328194,1,['load'],['load']
Performance,"metric primitives (edges/points) or multiple solution primitives (variables). The latter sounds like a sensible idea until we get to areas of the code where different primitives require different treatment, that and the fact that the number of variables might not fit evenly in the number of lanes can lead to very tricky and non-generic code. Nevertheless if the same code were to be applied to e.g. 4 solution variables, this strategy would likely perform better as it avoids the pesky gather/scatter operations.; Processing multiple geometric primitives can make full utilization of whatever register size (important on GPU's), the code is just as readable (as I hope to show), but gather/scatter cannot be avoided. ### Intro to SPMD; This one is simpler, in a nutshell multiple threads operate on the sub domain of an MPI rank.; The typical implementation has each thread executing a chunk of an edge or cell loop. **Why should we care about SPMD?**; Reduce the communication overhead resulting from domain decomposition and improve load balancing, important for strong scaling.; Some algorithms are more efficient that way, e.g. the ADT (as mentioned by Edwin), the current MG also seems to work better on fewer partitions, and additive versions of preconditioners like the ILU or LU-SGS lose effectiveness with number of partitions.; Optimum hardware utilization, for routines that are bandwidth-bound it may be beneficial to use all threads available, while for compute-bound or ""algorithm-bound"" ones this may not be the case. **Relation with algorithms**; A typical edge loop reads from 2 locations and writes to 2 locations (gather / scatter access pattern, not to be confused with the instructions) processing multiple edges at the same time can therefore result in race conditions where multiple threads try to update the data of the same point.; There are 3 ways to address this:; - **Coloring**: Edges are colored (grouped) such that edges of the same color have no risk of race conditi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-529662724:3175,load,load,3175,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-529662724,1,['load'],['load']
Performance,"nce in convergence and result, which I think is due to the difference in regime. The convergence of the direct solution is: ; ![image](https://user-images.githubusercontent.com/21182966/28309520-e967cbc6-6ba9-11e7-9233-9c9f69db126b.png). The convergence of the adjoint solution is:; ![image](https://user-images.githubusercontent.com/21182966/28308831-b937bf76-6ba7-11e7-9108-e8a2ab959b74.png). Then I noticed a difference in SENS_GEO (which is the second term of the upper equation, right?) between compressible and incompressible. . ![image](https://user-images.githubusercontent.com/21182966/28310143-bb28c42a-6bab-11e7-8c14-8409b6b12027.png). So if the scale is adjusting current step size the step of dC and SENS_GEO represents the second term, then the SENS_GEO would change when the scale is changed. But this is not the case for incompressible and compressible. . In short, the only noticeable change, due to scaling, occurs in deformation folder of DSN_002. But this is after the optimization step, which is really confusing. Scaling adjusts the current step size and because it can not find a sufficient decrease it is halving the dv_value. But then one should expect different values in the adjoint folder for different scale factors, right?. I hope you can use this information and can tell me whether it is a correct behavior of the optimizer. I should also note that I did not make use of constraints, just as in the test case. I read that the optimizer will switch from optimization procedure. I think this should not matter because of the test case. . I attached also the configure files (compressible (working, scale= 0.01) and incompressible (not working, scale =0.01)) and the mesh file, which is in both cases the same file. [compressible_cfg.txt](https://github.com/su2code/SU2/files/1155421/compressible_cfg.txt); [incompressible_cfg.txt](https://github.com/su2code/SU2/files/1155427/incompressible_cfg.txt); [mesh_300_su2.txt](https://github.com/su2code/SU2/files/1155430/mesh_",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/409#issuecomment-316018103:3196,optimiz,optimization,3196,https://su2code.github.io,https://github.com/su2code/SU2/issues/409#issuecomment-316018103,1,['optimiz'],['optimization']
Performance,"nd off-diagonal blocks for each edge.; Here is a dummy numerics loop that does nothing else but setting blocks in the matrix (with colouring).; ```c++; void testLoop1(const vector<size_t>& colorStart,; const vector<size_t>& edgeIdx,; const vector<pair<size_t,size_t> >& connectivity,; double** blk_i, double** blk_j,; SparseMatrix& matrix); {; matrix.setZero();. for(size_t color=0; color<colorStart.size()-1; ++color); #pragma omp parallel for schedule(dynamic,CHUNK_SIZE); for(size_t k=colorStart[color]; k<colorStart[color+1]; ++k); {; size_t iEdge = edgeIdx[k];; size_t iPoint = connectivity[iEdge].first;; size_t jPoint = connectivity[iEdge].second;. matrix.addBlock(iPoint, iPoint, blk_i);; matrix.addBlock(iPoint, jPoint, blk_j);. matrix.subBlock(jPoint, jPoint, blk_j);; matrix.subBlock(jPoint, iPoint, blk_i);; }; }; ```; This and a few more memory reads is why we can't have nice things, i.e. massive speedups with vectorization. Believe it or not this loop sets ~75% of the maximum speed at which the residual edge loop can run (bandwidth bottleneck).; Don't be sad though, we can make a few things about it better:; - We can store the blocks we insert contiguously so the writes can be vectorized (this would be done using a container so that we still have `(i,j)` access syntax);; - On each insertion we have to first look for the block by traversing the `colInd` (column index) array, we can instead map the diagonal blocks to the corresponding points and the off-diagonal blocks to the edge (remember we insert ""by the edge"").; - We can fuse numerics (possibly using the [decorator](https://en.wikipedia.org/wiki/Decorator_pattern) pattern) so that we write to the matrix only once per iteration, which means we only need to clear the diagonal blocks and not the entire matrix because we can **set** the off-diagonals instead of **updating** them. Assuming these modification our dummy loop becomes; ```c++; void testLoop2(const vector<size_t>& colorStart,; const vector<size_t>& edgeId",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-535977206:2432,bottleneck,bottleneck,2432,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206,1,['bottleneck'],['bottleneck']
Performance,"ocations and write to 1), on a second pass, over points, we reduce (e.g. sum) the edge quantities for each point, again a gather access pattern. It may also be possible to convert the entire algorithm to a loop over points instead of edges.; - **Atomic operations or locks**: Here when a thread wants to write to a memory location it either needs to do so atomically (this is essentially an operations that always goes through main memory and forces cache coherency) or it needs to acquire a *lock* for the point it is writing to, if it fails to acquire the *lock* (because another thread has it) it needs to wait. None of these is without drawbacks.; - **Coloring** reduces temporal locality, edges are sorted in increasing order of the point indices to reduce cache misses, this means small groups of contiguous edges will share the same ""iPoint"", coloring single edges destroys this. Furthermore coloring either requires edges to be re-sorted by color, or if the edge indices of each color are instead kept in arrays, performance will suffer due to increased indirection which confounds the hardware pre-fetcher.; This can be mitigated to some extent by coloring groups of edges, groups of edges of the same color can be processed simultaneously, but within each group edges need to be processed serially. However grouping will reduce how much parallelism can be exploited within each color.; - **Gather to scatter** will in general use more memory due to the intermediate variables and extra adjacency information needed. If the entire algorithm is transformed performance may suffer as some computations may have to be repeated.; However, some reductions are possible without intermediate variables, for example when assembling the system matrix for implicit schemes only the diagonal entries can result in race conditions, now it just so happens that each diagonal entry is equal to the negated corresponding column sum.; - **Atomics** are terrible for the performance of code that writes freque",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-529662724:5423,perform,performance,5423,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-529662724,1,['perform'],['performance']
Performance,"orted in increasing order of the point indices to reduce cache misses, this means small groups of contiguous edges will share the same ""iPoint"", coloring single edges destroys this. Furthermore coloring either requires edges to be re-sorted by color, or if the edge indices of each color are instead kept in arrays, performance will suffer due to increased indirection which confounds the hardware pre-fetcher.; This can be mitigated to some extent by coloring groups of edges, groups of edges of the same color can be processed simultaneously, but within each group edges need to be processed serially. However grouping will reduce how much parallelism can be exploited within each color.; - **Gather to scatter** will in general use more memory due to the intermediate variables and extra adjacency information needed. If the entire algorithm is transformed performance may suffer as some computations may have to be repeated.; However, some reductions are possible without intermediate variables, for example when assembling the system matrix for implicit schemes only the diagonal entries can result in race conditions, now it just so happens that each diagonal entry is equal to the negated corresponding column sum.; - **Atomics** are terrible for the performance of code that writes frequently to memory (i.e. bandwidth-bound code), they do not increase the memory footprint and so make sense for compute-bound code.; Bugs due to a missing atomic can be very hard to debug (but any race condition is). Coloring is what one sees most in the literature, and yet I lean towards gather-to-scatter. Fewer things can go wrong with it as it is easy to understand, one gets the maximum amount of parallelism. I will now take two familiar routines, computing gradients (Green-Gauss) and limiters, vectorize / parallelize them in different ways, and measure relative performance to illustrate some of these key points introduced here. There will be C++ snipets and there will be some x86 assembly too :)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-529662724:6214,race condition,race conditions,6214,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-529662724,4,"['perform', 'race condition']","['performance', 'race condition', 'race conditions']"
Performance,"p team developing the SU2. I think moving the main tutorials to the main repository is a good idea. We; declared to contribute some validation cases and written tutorials and; having this in main repository will ease the process of adding/modifying; the docs to a simple pull request. I also have a suggestion regarding the Test Cases and Tutorial files. I; apologize if this is the wrong place or this has been discussed already,; but still will give it a try:; - Test cases folder from SU2/su2code repository shall be moved to the; SU2/TestCases repository. Rationale: this makes one repository to store the; test case *.cfg files and mesh files.; - There shall be a TestCases/Mesh folder to store all the meshes needed for; Test Cases files, without subdivisions for RANS, Euler etc subfolders.; Considering that multiple test cases use the same mesh and all the mesh; files are distinct, this solution generates one place to store all the mesh; files. Should a user perform a test case, he/she will find the mesh by name; referenced in the *.cfg file instead searching thru multiple folders. This; will also help avoiding unnecessary copies of mesh files.; - The same should be done for Tutorial files: Tutorial/Mesh folder for; storing meshes (duplicating these few files from TestCases/Mesh should not; be a problem IMO, but will really help a new user to get up to speed with; SU2); - I have no clear opinion on where the Tutorial files folder should be; stored. But considering moving written tutorials to main repository i think; that tutorial files should also be stored in main SU2/su2code repository. Best regards and Happy New Year; Jędrzej. 2017-12-30 23:45 GMT+01:00 Tim Albring <notifications@github.com>:. > What do you think of moving the written tutorials also to the main; > repository ? Then we can have links in the wiki to the markdown files like; > this (the link will be much shorter if the files are in the master branch):; > https://github.com/su2code/SU2/blob/0e36facc031aa",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/485#issuecomment-354736415:1159,perform,perform,1159,https://su2code.github.io,https://github.com/su2code/SU2/pull/485#issuecomment-354736415,1,['perform'],['perform']
Performance,"r clarity). **With SoA (aka column major storage) this code is 1.5 times slower than the scalar version.**. The reason for that is poor locality (of the spacial variety), as we loop through the number of variables and dimensions we are accessing the data in strides of nPoint, as the contiguous index is the first one so that we can perform vector read/writes when computing gradients and limiters.; With the scalar version the data for each point is contiguous which means on the first access we get whatever extra data is on the same cache line for free and subsequent accesses will be hardware prefetched since the stride is small (1 in this case). We lose all this with SoA storage. If we go back to arrays of structures (AoS, aka row major storage, basically what we have in #753) performance is only 9% worse (the code is identical). Those 9% are mostly due to increased integer arithmetic in the accesses to the data, on each call to `getVec` we resolve 4/8 row/column pairs into 1D indexes, while this calculation is vectorized, it seems to be less optimizable by compilers, for example this; ```c++; for(size_t iDim=0; iDim<nDim; ++iDim); phiL += grad.getVec(iPoint,iVar,iDim)*d_ij[iDim];; ```; gets compiled into this monstrosity; ```asm; .L13:; vpmuludq ymm0, ymm4, ymm1; vmovq xmm15, rax; vmovapd ymm6, ymm11; mov rdx, rax; vpbroadcastq ymm15, xmm15; sal rdx, 5; add rax, 1; vpaddq ymm0, ymm0, ymm2; vpsllq ymm0, ymm0, 32; vpaddq ymm0, ymm5, ymm0; vmovdqa YMMWORD PTR [rbp-240], ymm0; vpaddq ymm0, ymm3, ymm0; vmovdqa YMMWORD PTR [rbp-208], ymm0; vpaddq ymm0, ymm15, ymm0; vmovdqa YMMWORD PTR [rbp-176], ymm0; vgatherqpd ymm15, QWORD PTR [rdi+ymm0*8], ymm6; vmovapd ymm0, YMMWORD PTR [rsi+rdx]; vfmadd213pd ymm0, ymm15, YMMWORD PTR [rbp-336]; vmovapd YMMWORD PTR [rbp-336], ymm0; cmp rbx, rax; jne .L13; ```; the meat of which is `vgatherqpd` (`getVec`) and `vfmadd213pd` fused-multiply-add to update `phiL`, everything else is integer arithmetic which in the scalar version gets factored",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-535977206:9248,optimiz,optimizable,9248,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206,1,['optimiz'],['optimizable']
Performance,"size_t color=0; color<colorStart.size()-1; ++color); #pragma omp parallel for schedule(dynamic,CHUNK_SIZE); for(size_t k=colorStart[color]; k<colorStart[color+1]; ++k); {; #if SORT_BY_COLOR==1; size_t iEdge = k;; #else; size_t iEdge = edgeIdx[k];; #endif. size_t iPoint = connectivity[iEdge].first;; size_t jPoint = connectivity[iEdge].second;; ```; Apologies for the macro but it is just to illustrate that if we re-sort edge data after coloring the edge index is the loop index, otherwise the edge indices for each color need to be stored in a separate array.; Note that for each edge loop we first loop over colors, then over same-color edges, it is this inner loop that can run in parallel in chunk sizes that are multiple of the group size considered during coloring. There is some runtime cost on entry to every #omp parallel section, with coloring we enter one such section once by color. I mentioned in the introduction coloring reduces locality and therefore performance, here is the effect of color group size on the execution time of the scalar code on one thread:; ![image](https://user-images.githubusercontent.com/38071223/64686801-2e0d3d00-d481-11e9-82a0-c56e5554cd83.png); The hassle-free option of not sorting by color ""never"" recovers the performance of the base algorithm, things are even worse for the SIMD version where even at group size of 8192 with re-sorting the slowdown is 14%. Running the edge-loop version on 4 cores (8192 group + sorting) we get speedups (relative to reference) of **1.98** and **2.04** for the scalar and SIMD versions respectively (yes I quadruple checked).; If you are keeping track of the number two things should surprise you, the first is that there is no difference between scalar and SIMD now (the vector instruction are still there though), the second is that 4 cores give only a 2x speedup. The reason for both is: the implementation is very memory-bound, and so throwing more compute at it, either in the form of more cores or more lanes, does",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-530328194:13800,perform,performance,13800,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530328194,1,['perform'],['performance']
Performance,"tColIterator(jPoint);. for(size_t iVar=0; iVar<nVar; ++iVar); {; FltVec phiL = 0.0;; FltVec phiR = 0.0;. for(size_t iDim=0; iDim<nDim; ++iDim); {; phiL += (gradI++)*d_ij[iDim];; phiR -= (gradJ++)*d_ij[iDim];; }; ...; ```; to get better assembly; ```asm; .L7:; vmovapd ymm3, ymm13; vmovapd ymm2, YMMWORD PTR [rbp-400]; add rax, 32; vgatherqpd ymm0, QWORD PTR [rcx+ymm1*8], ymm3; vpaddq ymm1, ymm1, ymm11; vmovapd YMMWORD PTR [rbp-272], ymm0; vmovapd YMMWORD PTR [rbp-240], ymm0; vfmadd132pd ymm0, ymm2, YMMWORD PTR [rax-32]; vmovdqa YMMWORD PTR [rbp-208], ymm1; vmovapd YMMWORD PTR [rbp-400], ymm0; cmp rax, rbx; jne .L7; ```; which makes the vectorized code perform just as well as the scalar code, iterators could also be used for the other variables but that would start to hurt readability without improving the performance much. _Note: There is also a chance the compiler (gcc) is not doing this kind of optimization because of the way I wrote the code..._. **So we need AoS to avoid losing performance in lightweight numerics classes.**. Before we look into the impact of not using SoA in the gradient and limiters routines let me tell you there is a way to have the best of both worlds, enter the *_array of structures of arrays_* or as I like to call it zig zag storage, aka a right mess.; Imagine an AoS of short arrays of SIMD length, e.g. `{ {u0 u1 u2 u3} {v0 ... v3} {w0 ... w3} {u4 u5 u6 u7} ... }` with that it is possible to fully vectorize point loops as the first index (iPoint) is contiguous in groups of SIMD length and when looping along variables and dimensions in edge loops the stride is small enough (equal to SIMD length) to trigger hardware prefetching.; The catch is that we need even more integer arithmetic and so we really need iterators to amortise that cost, there is also the drawback that scalar usage of such a container would be terrible. **For these reasons I think we should sacrifice ultimate performance and keep node data in AoS storage.**. The major impact on",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-535977206:12669,perform,performance,12669,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206,1,['perform'],['performance']
Performance,"to be bandwidth-bound, vectorization helps a bit there too (instructions are also data that needs to travel to the CPU) (maybe for explicit schemes and 8 SIMD lanes, maybe). **Relation with data structures**; There is only one efficient way to move data between memory and registers, via `load` and `store` instructions (they do come in multiple flavors). That is, pointing to a memory location and reading or writing N elements of contiguous data.; It is not the only way, it is also possible to `gather` and `scatter` data. That is populating the register from non-contiguous locations and vice versa. This is about one order of magnitude slower, to the point where if the computations are very simple it may not pay-off to vectorize. **Relation with algorithms**; Some form of `gather` and `scatter` is required in unstructured CFD, which means SIMD has a price of admission. Some thought needs to go into designing algorithms that amortize that cost by maximizing the so called FLOP/Byte ratio, and mask the latency of those operations by being able to start computing as soon as the first element of data is available. **What elements should we try to process simultaneously?**; The choice is between multiple geometric primitives (edges/points) or multiple solution primitives (variables). The latter sounds like a sensible idea until we get to areas of the code where different primitives require different treatment, that and the fact that the number of variables might not fit evenly in the number of lanes can lead to very tricky and non-generic code. Nevertheless if the same code were to be applied to e.g. 4 solution variables, this strategy would likely perform better as it avoids the pesky gather/scatter operations.; Processing multiple geometric primitives can make full utilization of whatever register size (important on GPU's), the code is just as readable (as I hope to show), but gather/scatter cannot be avoided. ### Intro to SPMD; This one is simpler, in a nutshell multiple t",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-529662724:1932,latency,latency,1932,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-529662724,1,['latency'],['latency']
Performance,"to return an array with the indices in ""rows""; template<class U>; Array<double,4> Matrix<double>::getVec(const U& rows, size_t col) const {; return Array<double,4>(&data_[col*rows_], rows);; }; ```; After inlining those copies get optimized away.; Although the stored type, and ""scalar interface"" of the containers do not need to change, the storage order of the data does. Notice that in the above data is stored by columns instead of rows (something that @vdweide mentioned in #716) this has greater implications for gradients as instead of the familiar ""vector of matrices"" we would need a ""matrix of vectors"", i.e. the derivative of variable i w.r.t. coordinate j stored as a vector for all points. The `Adjacency` also needs to be stored in a funny way. For the scalar version of the code it was stored as a CSR sparse matrix (one array of indices into the arrays of data for each point, the rows).; For the vectorized version we want to load (small) arrays of jPoint's, arrays of iEdge's, and arrays of directions, and as we know either those are contiguous or we take a huge performance hit.; If all points had the same number of neighbors we could store the adjacency in LIL (list of lists) format, essentially a column-major matrix, but that is not true for hybrid meshes and so we would possibly waste a lot of memory.; The solution is to use a Block-CSR format (like in CSysMatrix) where the blocks are the vectors we want and instead of one row per point we have one row per SIMD group. But even within a SIMD-sized group points can have different number of neighbors...; The solution for that is padding, within each group the number of neighbors is rounded up, shorter rows are then padded with valid data, e.g. jPoint=iPoint, direction=0, and iEdge repeated. This concept of padding is important for something else, you may have noticed that the SIMD point-loops I showed make no provisions for values of nPoint that are not multiples of SIMDLEN, that is because the containers already ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-530328194:10484,load,load,10484,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530328194,2,"['load', 'perform']","['load', 'performance']"
Performance,"tter cannot be avoided. ### Intro to SPMD; This one is simpler, in a nutshell multiple threads operate on the sub domain of an MPI rank.; The typical implementation has each thread executing a chunk of an edge or cell loop. **Why should we care about SPMD?**; Reduce the communication overhead resulting from domain decomposition and improve load balancing, important for strong scaling.; Some algorithms are more efficient that way, e.g. the ADT (as mentioned by Edwin), the current MG also seems to work better on fewer partitions, and additive versions of preconditioners like the ILU or LU-SGS lose effectiveness with number of partitions.; Optimum hardware utilization, for routines that are bandwidth-bound it may be beneficial to use all threads available, while for compute-bound or ""algorithm-bound"" ones this may not be the case. **Relation with algorithms**; A typical edge loop reads from 2 locations and writes to 2 locations (gather / scatter access pattern, not to be confused with the instructions) processing multiple edges at the same time can therefore result in race conditions where multiple threads try to update the data of the same point.; There are 3 ways to address this:; - **Coloring**: Edges are colored (grouped) such that edges of the same color have no risk of race conditions, i.e. each endpoint is referenced only once per color (this definition gives you the basis of a greedy algorithm to color edges).; - **Scatter to gather transformations**: Edge quantities (e.g. fluxes) are computed and stored on one pass (i.e. we read from 2 locations and write to 1), on a second pass, over points, we reduce (e.g. sum) the edge quantities for each point, again a gather access pattern. It may also be possible to convert the entire algorithm to a loop over points instead of edges.; - **Atomic operations or locks**: Here when a thread wants to write to a memory location it either needs to do so atomically (this is essentially an operations that always goes through main ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-529662724:3915,race condition,race conditions,3915,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-529662724,1,['race condition'],['race conditions']
Performance,"use of the way I wrote the code..._. **So we need AoS to avoid losing performance in lightweight numerics classes.**. Before we look into the impact of not using SoA in the gradient and limiters routines let me tell you there is a way to have the best of both worlds, enter the *_array of structures of arrays_* or as I like to call it zig zag storage, aka a right mess.; Imagine an AoS of short arrays of SIMD length, e.g. `{ {u0 u1 u2 u3} {v0 ... v3} {w0 ... w3} {u4 u5 u6 u7} ... }` with that it is possible to fully vectorize point loops as the first index (iPoint) is contiguous in groups of SIMD length and when looping along variables and dimensions in edge loops the stride is small enough (equal to SIMD length) to trigger hardware prefetching.; The catch is that we need even more integer arithmetic and so we really need iterators to amortise that cost, there is also the drawback that scalar usage of such a container would be terrible. **For these reasons I think we should sacrifice ultimate performance and keep node data in AoS storage.**. The major impact on gradients and limiters is the way the code is written, to vectorize the computation we need to compute the gradient into a local variable and then ""transpose"" it when storing it, i.e.; ```c++; FltVec phiI[MAXNVAR], gradI[MAXNVAR][MAXNDIM];; ...; for(size_t iVar=0; iVar<nVar; ++iVar); {; auto flux = weight*(phiI[iVar]+phi.getVec(jPoint,iVar));. for(size_t iDim=0; iDim<nDim; ++iDim); gradI[iVar][iDim] += a_ij[iDim]*flux;; }; }. for(size_t iVar=0; iVar<nVar; ++iVar); for(size_t iDim=0; iDim<nDim; ++iDim); for(size_t k=0; k<SIMDLEN; ++k); grad(iPoint+k,iVar,iDim) = gradI[iVar][iDim][k];; ...; ```; Similarly when computing the gradient we need to first fetch/transpose it to be able to vectorize subsequent computations; ```c++; FltVec gradI[MAXNVAR][MAXNDIM];. for(size_t iVar=0; iVar<nVar; ++iVar); for(size_t iDim=0; iDim<nDim; ++iDim); for(size_t k=0; k<SIMDLEN; ++k); gradI[iVar][iDim][k] = grad(iPoint+k,iVar,iDim);",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-535977206:13605,perform,performance,13605,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206,1,['perform'],['performance']
Performance,"w` but there is only one shared pointer on which to call `delete`); writing to the same memory locations concurrently.; I tried to make the first issue debugable by asserting that the initialization routines of CSysMatrix and CSysVector are only called by the master thread.; For the second issue I made the associated classes as const-correct as possible, that should at least make someone think twice before changing a member variable of those classes. The risk is still there for input variables as an algorithm development aspect... For example `MatrixVectorProductTransposed` cannot be made thread-parallel as simply/naively as its normal counterpart. ### Communication Model; The MPI + Threads communication model is very simple, currently only the master thread calls MPI routines (including `Error`), this requires thread barriers before and after the communication to make sure the correct values are passed and _seen_ by all threads.; We can test other alternatives in the future but at the moment this does not seem to be a significant bottleneck.; _Worksharing_ constructs have implicit barriers at completion, for CSysVector routines I used `nowait` modifiers, it is safe to call those routines in sequence since the loop sizes, and static work scheduling specifications are identical.; However, routines that access a CSysVector in a different way, should have an explicit barrier before using the vector (or risk having undefined behaviour). You will see these barriers on entry to matrix-vector product, and every `ComputeXXXPreconditioner` (if you don't, let me know xD). I think those routines are large enough to amortise the cost of this. ### Performance; Disclaimer:; - We are talking about linear solvers only, **you will not see a global improvement yet**.; - The large global improvements from ""hybridization"" will come from the multigrid behaving better on less decomposed domains, and from the ability to independently tune the number of cores used in the linear precondition",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/830#issuecomment-562646766:2029,bottleneck,bottleneck,2029,https://su2code.github.io,https://github.com/su2code/SU2/pull/830#issuecomment-562646766,1,['bottleneck'],['bottleneck']
Performance,"we care about SPMD?**; Reduce the communication overhead resulting from domain decomposition and improve load balancing, important for strong scaling.; Some algorithms are more efficient that way, e.g. the ADT (as mentioned by Edwin), the current MG also seems to work better on fewer partitions, and additive versions of preconditioners like the ILU or LU-SGS lose effectiveness with number of partitions.; Optimum hardware utilization, for routines that are bandwidth-bound it may be beneficial to use all threads available, while for compute-bound or ""algorithm-bound"" ones this may not be the case. **Relation with algorithms**; A typical edge loop reads from 2 locations and writes to 2 locations (gather / scatter access pattern, not to be confused with the instructions) processing multiple edges at the same time can therefore result in race conditions where multiple threads try to update the data of the same point.; There are 3 ways to address this:; - **Coloring**: Edges are colored (grouped) such that edges of the same color have no risk of race conditions, i.e. each endpoint is referenced only once per color (this definition gives you the basis of a greedy algorithm to color edges).; - **Scatter to gather transformations**: Edge quantities (e.g. fluxes) are computed and stored on one pass (i.e. we read from 2 locations and write to 1), on a second pass, over points, we reduce (e.g. sum) the edge quantities for each point, again a gather access pattern. It may also be possible to convert the entire algorithm to a loop over points instead of edges.; - **Atomic operations or locks**: Here when a thread wants to write to a memory location it either needs to do so atomically (this is essentially an operations that always goes through main memory and forces cache coherency) or it needs to acquire a *lock* for the point it is writing to, if it fails to acquire the *lock* (because another thread has it) it needs to wait. None of these is without drawbacks.; - **Coloring** r",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-529662724:4126,race condition,race conditions,4126,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-529662724,1,['race condition'],['race conditions']
Performance,"y waste a lot of memory.; The solution is to use a Block-CSR format (like in CSysMatrix) where the blocks are the vectors we want and instead of one row per point we have one row per SIMD group. But even within a SIMD-sized group points can have different number of neighbors...; The solution for that is padding, within each group the number of neighbors is rounded up, shorter rows are then padded with valid data, e.g. jPoint=iPoint, direction=0, and iEdge repeated. This concept of padding is important for something else, you may have noticed that the SIMD point-loops I showed make no provisions for values of nPoint that are not multiples of SIMDLEN, that is because the containers already took care of that by rounding up the number of columns, and so that seemingly out-of-bounds access is safe (ain't encapsulation great). Padding also aligns the start of each column, thus it is a generally good thing to have (on large dimensions) whether used or not. Here is a relative performance recap before we talk bout parallelization. | Code | Edge | Edge, SIMD on vars | Point | Point, SIMD on points |; | ---- | ---- | ---- | ---- | ---- |; | **Speed** | 1.0 | 2.2 | 0.83 | 1.35 |. **Parallel execution**. I will start at the end for this, all it takes to parallellize the points loops with OpenMP is to take this:; ```C++; for(size_t iPoint=0; iPoint<nPoint; iPoint+=SIMDLEN); ```; And add some pixie dust; ```C++; #pragma omp parallel for schedule(dynamic,128); for(size_t iPoint=0; iPoint<nPoint; iPoint+=SIMDLEN); ```; This means each thread gets chunks of 128 loop iterations (512 points) to work on, assigned in a dynamic way, the 4 core speedup (still relative to our reference) is **3.8** for the SIMD code and **2.8** for the scalar code. Parallelizing the edge loops is a bit more intricate, as this:; ```C++; for(size_t iEdge=0; iEdge<nEdge; ++iEdge); {; size_t iPoint = connectivity[iEdge].first;; size_t jPoint = connectivity[iEdge].second;; ```; Becomes:; ```C++; for(size_t color=",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-530328194:11828,perform,performance,11828,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530328194,1,['perform'],['performance']
Performance,"{; #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); {; double flux = phi_ave[iVar]*area(iEdge,iDim);. grad(iPoint,iVar,iDim) += flux;; grad(jPoint,iVar,iDim) -= flux;; }; }; }. for(size_t iPoint=0; iPoint<nPoint; ++iPoint); for(size_t iDim=0; iDim<nDim; ++iDim); #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); grad(iPoint,iVar,iDim) /= volume[iPoint];; }; ```; Well it is not just a few pragmas, we need to make the number of variables known at compile time (via a template parameter) and we need to transpose how the gradient is stored, i.e. instead of {xyz, xyz, xyz, xyz} we need {xxxx, yyyy, zzzz}. This code gets a speed-up of **2.2**. This code is generic but the template needs to be instantiated for every possible number of variables and we need a `switch` to call the right version at runtime, not very friendly.; Processing multiple edges at the same time is not worth the effort, for one we need `gather/scatter` on a very light routine, and on top of that we need to sort the edges such that we do not attempt to `scatter` to the same point when updating the gradient (a problem similar to the race condition described for SPMD). We can switch to a point-based loop and process multiple points in a SIMD way, that avoids the `scatter` problem but `gathers` will still be required. Here is what the scalar version of the point-based loop looks like:; ```C++; void computeGradients(size_t nPoint,; size_t nVar,; size_t nDim,; const Adjacency& adj,; const Matrix& area,; const vector<double>& volume,; const Matrix& phi,; VectorOfMatrix& grad); {; for(size_t iPoint=0; iPoint<nPoint; ++iPoint); {; for(size_t iVar=0; iVar<nVar; ++iVar); for(size_t iDim=0; iDim<nDim; ++iDim); grad(iPoint,iVar,iDim) = 0.0;. for(size_t iNeigh=0; iNeigh<adj.nNeighbor(iPoint); ++iNeigh); {; size_t jPoint = adj.jPoint(iPoint,iNeigh);; size_t iEdge = adj.iEdge(iPoint,iNeigh);; double dir = adj.dir(iPoint,iNeigh);. for(size_t iVar=0; iVar<nVar; ++iVar); {; double phi_ave = 0.5*(phi(iPoint,i",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-530328194:3498,race condition,race condition,3498,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530328194,1,['race condition'],['race condition']
Safety," make someone think twice before changing a member variable of those classes. The risk is still there for input variables as an algorithm development aspect... For example `MatrixVectorProductTransposed` cannot be made thread-parallel as simply/naively as its normal counterpart. ### Communication Model; The MPI + Threads communication model is very simple, currently only the master thread calls MPI routines (including `Error`), this requires thread barriers before and after the communication to make sure the correct values are passed and _seen_ by all threads.; We can test other alternatives in the future but at the moment this does not seem to be a significant bottleneck.; _Worksharing_ constructs have implicit barriers at completion, for CSysVector routines I used `nowait` modifiers, it is safe to call those routines in sequence since the loop sizes, and static work scheduling specifications are identical.; However, routines that access a CSysVector in a different way, should have an explicit barrier before using the vector (or risk having undefined behaviour). You will see these barriers on entry to matrix-vector product, and every `ComputeXXXPreconditioner` (if you don't, let me know xD). I think those routines are large enough to amortise the cost of this. ### Performance; Disclaimer:; - We are talking about linear solvers only, **you will not see a global improvement yet**.; - The large global improvements from ""hybridization"" will come from the multigrid behaving better on less decomposed domains, and from the ability to independently tune the number of cores used in the linear preconditioners. For now the objective is ""just"" not to loose performance while gaining flexibility.; - The performance of MPI+threads with 1 thread per rank will be worse than just MPI (no free lunches). With this [small case](https://github.com/su2code/SU2/files/3933059/small_case.zip) using 8 cores off a machine with two 2650v4 CPU, Intel MPI 2018 + GCC 8.2, the hybrid (2 ranks of 4",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/830#issuecomment-562646766:2405,risk,risk,2405,https://su2code.github.io,https://github.com/su2code/SU2/pull/830#issuecomment-562646766,1,['risk'],['risk']
Safety,"(size_t iDim=0; iDim<nDim; ++iDim); #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); grad(iPoint,iVar,iDim) /= volume[iPoint];; }; ```; Well it is not just a few pragmas, we need to make the number of variables known at compile time (via a template parameter) and we need to transpose how the gradient is stored, i.e. instead of {xyz, xyz, xyz, xyz} we need {xxxx, yyyy, zzzz}. This code gets a speed-up of **2.2**. This code is generic but the template needs to be instantiated for every possible number of variables and we need a `switch` to call the right version at runtime, not very friendly.; Processing multiple edges at the same time is not worth the effort, for one we need `gather/scatter` on a very light routine, and on top of that we need to sort the edges such that we do not attempt to `scatter` to the same point when updating the gradient (a problem similar to the race condition described for SPMD). We can switch to a point-based loop and process multiple points in a SIMD way, that avoids the `scatter` problem but `gathers` will still be required. Here is what the scalar version of the point-based loop looks like:; ```C++; void computeGradients(size_t nPoint,; size_t nVar,; size_t nDim,; const Adjacency& adj,; const Matrix& area,; const vector<double>& volume,; const Matrix& phi,; VectorOfMatrix& grad); {; for(size_t iPoint=0; iPoint<nPoint; ++iPoint); {; for(size_t iVar=0; iVar<nVar; ++iVar); for(size_t iDim=0; iDim<nDim; ++iDim); grad(iPoint,iVar,iDim) = 0.0;. for(size_t iNeigh=0; iNeigh<adj.nNeighbor(iPoint); ++iNeigh); {; size_t jPoint = adj.jPoint(iPoint,iNeigh);; size_t iEdge = adj.iEdge(iPoint,iNeigh);; double dir = adj.dir(iPoint,iNeigh);. for(size_t iVar=0; iVar<nVar; ++iVar); {; double phi_ave = 0.5*(phi(iPoint,iVar)+phi(jPoint,iVar));. for(size_t iDim=0; iDim<nDim; ++iDim); grad(iPoint,iVar,iDim) += phi_ave*dir*area(iEdge,iDim);; }; }. for(size_t iVar=0; iVar<nVar; ++iVar); for(size_t iDim=0; iDim<nDim; ++iDim); grad(iPoint,iVar,iDim) /= volum",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-530328194:3618,avoid,avoids,3618,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530328194,1,['avoid'],['avoids']
Safety,") arrays of jPoint's, arrays of iEdge's, and arrays of directions, and as we know either those are contiguous or we take a huge performance hit.; If all points had the same number of neighbors we could store the adjacency in LIL (list of lists) format, essentially a column-major matrix, but that is not true for hybrid meshes and so we would possibly waste a lot of memory.; The solution is to use a Block-CSR format (like in CSysMatrix) where the blocks are the vectors we want and instead of one row per point we have one row per SIMD group. But even within a SIMD-sized group points can have different number of neighbors...; The solution for that is padding, within each group the number of neighbors is rounded up, shorter rows are then padded with valid data, e.g. jPoint=iPoint, direction=0, and iEdge repeated. This concept of padding is important for something else, you may have noticed that the SIMD point-loops I showed make no provisions for values of nPoint that are not multiples of SIMDLEN, that is because the containers already took care of that by rounding up the number of columns, and so that seemingly out-of-bounds access is safe (ain't encapsulation great). Padding also aligns the start of each column, thus it is a generally good thing to have (on large dimensions) whether used or not. Here is a relative performance recap before we talk bout parallelization. | Code | Edge | Edge, SIMD on vars | Point | Point, SIMD on points |; | ---- | ---- | ---- | ---- | ---- |; | **Speed** | 1.0 | 2.2 | 0.83 | 1.35 |. **Parallel execution**. I will start at the end for this, all it takes to parallellize the points loops with OpenMP is to take this:; ```C++; for(size_t iPoint=0; iPoint<nPoint; iPoint+=SIMDLEN); ```; And add some pixie dust; ```C++; #pragma omp parallel for schedule(dynamic,128); for(size_t iPoint=0; iPoint<nPoint; iPoint+=SIMDLEN); ```; This means each thread gets chunks of 128 loop iterations (512 points) to work on, assigned in a dynamic way, the 4 core sp",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-530328194:11644,safe,safe,11644,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530328194,1,['safe'],['safe']
Safety,");; }; }. for(size_t iVar=0; iVar<nVar; ++iVar); {; FltVec lim = vmin(FltVec(2.0), vmin(; (phiMax[iVar]-phi.getVec(iPoint,iVar))/prjMax[iVar],; (phiMin[iVar]-phi.getVec(iPoint,iVar))/prjMin[iVar]));. limiter.setVec(iPoint,iVar, lim*(lim+2.0)/(lim*lim+lim+2.0));; }; }; }; ```; In terms of algorithm, for each point we find the min and max neighbor values and the min (negative) and max (positive) projections, those are then combined in a final `min(2, max/max, min/min)` to which the limiter function is applied (this would also be applicable to Venkatakrishnan-[Wang] limiters).; This is equivalent to the edge-loop, if statements are not required as due to cells being closed, if the positive projection is not zero, the negative one will also not be zero, therefore it is correct to always evaluate both ratios.; This algorithm only needs min and max neighbors as small local variables instead of large global ones due to the way those values are determined. This is where the memory from the extra adjacency information is recovered. Like @economon said, fusing the gradient kernel with the limiter kernel is trivial with these point loops, and I do not think it affects readability much since one can clearly tell ""what is what"" (I will not put it here but it really is a matter of copy paste), including the boundaries could be a bit more challenging, but I will give performance number nevertheless. **Performance summary**. | Code | Edge | Edge, SIMD on vars | Point | Point, SIMD on points |; | ---- | ---- | ---- | ---- | ---- |; | **Speed 1 core** | 1.0 | 1.75 | 1.25 | 2.0 |; | **Speed 4 cores** | 2.45 | 2.7 | 4.5 | 7.0 |. The basic point version does not lose to edge based because, contrary to gradients, it does not require duplication of computations while benefiting from sequential access to gradients.; Again the point-based implementation does really well in parallel, limiters are more compute intensive and so the scaling is almost perfect.; For reference, limiters are 1.9 ti",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-530593912:9835,recover,recovered,9835,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530593912,1,['recover'],['recovered']
Safety,", which means SIMD has a price of admission. Some thought needs to go into designing algorithms that amortize that cost by maximizing the so called FLOP/Byte ratio, and mask the latency of those operations by being able to start computing as soon as the first element of data is available. **What elements should we try to process simultaneously?**; The choice is between multiple geometric primitives (edges/points) or multiple solution primitives (variables). The latter sounds like a sensible idea until we get to areas of the code where different primitives require different treatment, that and the fact that the number of variables might not fit evenly in the number of lanes can lead to very tricky and non-generic code. Nevertheless if the same code were to be applied to e.g. 4 solution variables, this strategy would likely perform better as it avoids the pesky gather/scatter operations.; Processing multiple geometric primitives can make full utilization of whatever register size (important on GPU's), the code is just as readable (as I hope to show), but gather/scatter cannot be avoided. ### Intro to SPMD; This one is simpler, in a nutshell multiple threads operate on the sub domain of an MPI rank.; The typical implementation has each thread executing a chunk of an edge or cell loop. **Why should we care about SPMD?**; Reduce the communication overhead resulting from domain decomposition and improve load balancing, important for strong scaling.; Some algorithms are more efficient that way, e.g. the ADT (as mentioned by Edwin), the current MG also seems to work better on fewer partitions, and additive versions of preconditioners like the ILU or LU-SGS lose effectiveness with number of partitions.; Optimum hardware utilization, for routines that are bandwidth-bound it may be beneficial to use all threads available, while for compute-bound or ""algorithm-bound"" ones this may not be the case. **Relation with algorithms**; A typical edge loop reads from 2 locations and writ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-529662724:2848,avoid,avoided,2848,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-529662724,1,['avoid'],['avoided']
Safety,"> I don't known how the process to find the alpha that gives you a given CL works, but could the derivative not be obtained from this process? i.e. you could avoid the FD step entirely. It is a simple proportional controller that will change the angle of attack after a number of iterations depending on the difference between the current CL and the target CL. . So if the the option `ITER_DCL_DALPHA = 0` then it will do exactly what you suggest. It calculates the derivative based on the last update. The only problem with that is, there is no guarantee that the simulation at the previous update was converged, so the derivative might be incorrect. . But you are correct, I could just do a really tiny update (order of delta AoA ~10^-6) at the end and calculate the finite difference using that value. Let me try that and see if the gradients it calculates are reasonable, or if the update is too small and it gets clouded by numerical errors.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/780#issuecomment-539606698:158,avoid,avoid,158,https://su2code.github.io,https://github.com/su2code/SU2/pull/780#issuecomment-539606698,1,['avoid'],['avoid']
Safety,"> Nice! By the way, did you use some scripts for going through all the files and returning 'bad' naming conventions?. No, now I am just going through it by hand probably some linters are available to at least detect them. Actually, I am a bit confused as it is not so clear in the guide. It looks like the beginning of the project was just abbreviated from the Google style guide and was not enforced. Enforcing function names in UpperCamelCase and leaving variable names to the developer seems reasonable. > Can you explain the snake/camel terminology? :). Let's say we have a variable we want to name as `number of nodes per mesh` there are 2 common choices as . ```cpp; number_of_nodes_per_mesh = 42;; numberOfNodesPerMesh = 42;; ```; The first case is called the [snake case](https://en.wikipedia.org/wiki/Snake_case) and the second one is the [camel case ](https://en.wikipedia.org/wiki/Camel_case). Snake case is generally used in Python as [PEP8](https://peps.python.org/pep-0008/) suggests. . > Please revert the python accessor changes. I merged develop many of them vanished, should I revert the remaining ones?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1981#issuecomment-1482062542:209,detect,detect,209,https://su2code.github.io,https://github.com/su2code/SU2/pull/1981#issuecomment-1482062542,1,['detect'],['detect']
Safety,"> Note that you need to checkout this branch `fix_2d_periodic_rotation` (it is not in `develop` yet). Hi Pedro,; I checked the files you sent but building SU2 from source provided some errors:. - _MinGW64_ files provided from SU2 official website are corrupted and the installation crashes; however, it is possible to install the software but the .exe file mentioned in the installation guide won't be present. ; - After building _meson.py_ , the ninja installation command was line typed and the following alert message appeared "" **ninja: fatal: chdir to 'build' - No such file or directory** "". On a different laptop (with different user, to avoid the same mistakes) the following ERROR came up after the mason.py command line:; "" **'meson.py' is not recognized as an internal or external command, operable program or batch file** "". I don't know if any other user might have experienced the same errors. ; Anyway, are the bugfix files you published already available in the pre-compiled version? ; In the meanwhile, I'll try to figure out this inconvenient. Thank you in advance.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1562#issuecomment-1069325722:645,avoid,avoid,645,https://su2code.github.io,https://github.com/su2code/SU2/issues/1562#issuecomment-1069325722,1,['avoid'],['avoid']
Safety,"> You are proposing the exact opposite of the conclusion of the paper:; > ; > ""From the above findings, it is **recommended that all three of these terms be included** when running hypersonic, or even supersonic, turbulent flow simulations, especially for flows with shock wave-induced separations.""; > ; > And they clearly say this: ""While the full inclusion of these terms does not always result in predictions that agree better with DNS/experimental data, this is likely caused by the fact that their exclusion cancels out effects of other flaws in the RANS models employed.""; > ; > If your strategy is to get a better match with experiments by neglecting physics terms, then you should rethink your strategy. Thank you for your comment @bigfooted . The above paper is not presented to improve the current k-w SST model. . As you can see in the first post, there is a problem with the high Mach number and freestream turbulence intensity case. If high turbulence kinetic energy(TKE) and Mach number condition, the boundary condition cannot be maintained the imposed value. (I think there seems to be a bug in the temperature calculation using total energy when including the TKE). The introduction of C1 was intended to provide a 'temporary' solution at the level of first aid (simply commenting out conditional statements in code).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1851#issuecomment-1521383702:401,predict,predictions,401,https://su2code.github.io,https://github.com/su2code/SU2/issues/1851#issuecomment-1521383702,1,['predict'],['predictions']
Safety,">Therefore, we try to avoid templates when possible …. I find this view strange. I would appreciate if current C++ software techniques can be applied. How much can they help to make the source code a bit simpler?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/400#issuecomment-360055094:22,avoid,avoid,22,https://su2code.github.io,https://github.com/su2code/SU2/issues/400#issuecomment-360055094,1,['avoid'],['avoid']
Safety,"@JedrzejMosiezny . The reason why the mesh and config files are split into separate repos is the following: ideally we want to have the test cases being closely coupled to the current version of the code as config options change quite frequently. However, the mesh files are simply too big to have them in the main repo (it takes too much time to check them out etc.). So a compromise was to still leave the config files in the main repo in order for them to stay up-to-date. We thought that the information [here](https://github.com/su2code/SU2/wiki/Test-Cases) would be quite clear for the user on how to merge config and mesh files. Following this instructions should avoid having to search for the mesh files manually. Let us know if you think different. @economon could you add Jędrzej to the dev team here on github ? Thanks!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/485#issuecomment-355152833:671,avoid,avoid,671,https://su2code.github.io,https://github.com/su2code/SU2/pull/485#issuecomment-355152833,1,['avoid'],['avoid']
Safety,"@elfring: thank you very much for the suggestion, but for the time being, our philosophy is to keep the code as simple as possible to keep a low barrier to entry for new users/developers. Therefore, we try to avoid templates when possible (there are a few isolated places where they are necessary). This may change in the future, but we'll close this for now.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/400#issuecomment-360053938:209,avoid,avoid,209,https://su2code.github.io,https://github.com/su2code/SU2/issues/400#issuecomment-360053938,1,['avoid'],['avoid']
Safety,"@marcovanderbijl : thanks for the question. The original limit there is simply to impose an upper bound for memory considerations, since the first instantiation of the array of FFD boxes (before the number of FFD boxes embedded in the mesh is detected) needs a default value. We can of course change this to automatically detect the number to avoid the requirement or make it an input option in the config, but we have not run into this issue yet. For now, you should be able to increase that to a reasonable number without any issue. Please give it a try.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/684#issuecomment-495078497:243,detect,detected,243,https://su2code.github.io,https://github.com/su2code/SU2/issues/684#issuecomment-495078497,3,"['avoid', 'detect']","['avoid', 'detect', 'detected']"
Safety,"Dear Heather,; I am analyzing a propeller of an UAV. I have static thrust measurements such that when I used Euler results I got 3.5 lbf thrust as compared to the measured 6 lbs. My next step was to perform an NS equation with SA turb model. I got 7 times over predicted results such that the mesh has a Y+ of less than 1. Then I thought of doing an SST but was not long enough that it gave me error with divergence. I have been setting up my SST case as per the tutorial example of NACA0012. However, I do not happen to see any entry with regards to eddy frequency etc. (usually required by SST) in the config file. Any guidance will be great.; Thanks; Jehan; From: Heather Kline notifications@github.com; To: su2code/SU2 SU2@noreply.github.com ; Sent: Tuesday, May 12, 2015 11:43 AM; Subject: [SU2] Feature deallocation (#174). Bringing this branch up to date with current develop branch. ; Various deallocation changes; Some regression tests fail but all run. (previously was not the case); You can view, comment on, or merge this pull request online at:;   https://github.com/su2code/SU2/pull/174; Commit Summary; - Updated GetEngine_Properties; - Fix to the last commit; - Small bug; - Merge branch 'develop' into feature_MPI; - merging; - SU2_SOL and SU2_CFD are working; - Preliminary, but complete, implementation of SU2_DEF; - More updates; - Working version; - Complete implementation (validate); - Working version of SU2_DEF; - Final push before moving to the develop branch; - New MPI (removing SU2_PRT); - Merged in Ben's ParMETIS integration and fixed some conflicts.; - Merge branch 'benkirk-parmetis_integration' into feature_MPI; - ParMETIS geometry routines have been copied over but are not activated yet.; - Small change to ParMETIS include.; - ParMETIS can now be activated for testing (PARMETIS=YES in config).; - Updated MG; - Updated EA subrotuine; - Small fix; - Fixing memory leak; - Fixing memory leaks; - Dev release v.3.2.6; - Increasing MAX_NUMBER_MARKER; - Working versi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:261,predict,predicted,261,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['predict'],['predicted']
Safety,"Hey Rocco,. > And both versions are/were on the develop branches -> what exactly do you refer to here: config-files, code, mesh. The code tags 6.0.1 and 6.2.0 refer to specific master-commits of the code. So I want to know what is exactly of the develop branch, can't be the code if you understand the tags as I do. Maybe you refer to the develop code at the time where these tags were introduced. But maybe sth different. > I guess they converge eventually to the same values. I tried to compare the same case but steady (I attach the summary). Results in this case are fairly similar and (in my opinion) raise no warnings. That is good to hear. ; Luckily @cvencro (Thanks for that 👍 ) ran some tests and found that #740 (which rewrites Euler Wall boundaries for compressible and incompressible flows ... which was me btw) introduces the changes you see. The Euler wall for compressible is changed a bit in the way the boundary condition is enforced. Upon convergence both version should recover (close to) the same value. If the results in a steady state are the same/very-similar and if an unsteady simulation at low enough Reynolds-number converges to the same steady result (or oscillate in the same bounds) -> I would say it is simply some purely numerical effect based on the unphysical initialization and different treatment of the euler wall boundary. . 1 thing one could test additionally is to force a very high convergence in each physical timestep, i.e. usually one converges ~3 orders of magnitude in each ts -> now try converging until residual stalling in each ts. If the code versions get the same/closer results in the temporal evolution my euler wall boundary explanation would be quite reasonable.; Together with the long running unsteady simulation proposed above, I would feel more comfortable to judge. @cvencro (bringing the conversation to this place 😉 ) concerning the pitching case: the `if (dynamic_grid)` statements in the 'old' version are not necessary as that is handle",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/828#issuecomment-562621057:989,recover,recover,989,https://su2code.github.io,https://github.com/su2code/SU2/issues/828#issuecomment-562621057,1,['recover'],['recover']
Safety,"Hey,. @cvencro and I were discussing this issue quite a bit this morning and here an attempt of a summary:. We are looking at the following cases:; 1. 3D Onera m6, compressible euler, including euler_wall and sym_plane ; a. steady state; b. unsteady (no pitching, deforming); 2. 2D NACA64A010, compressible euler, including euler_wall; a. unsteady (no pitching/ deformation); b. pitching (with rigid and with deforming mesh -> used for the gradient validation of @cvencro 's post ). We are rather certain that the differences between the code-versions are due to the new euler_wall boundary which was introduced in #740 (by me :) ). @cvencro did a test where the old euler_wall was simply pasted into the newer function body (which currently directly calls the sym_plane boundary) -> that recovered the results obtained with the 'older' version. The steady state results (onera m6) show that both codes deliver the same results (of course with some minor differences). So far so good. Unsteady cases are a bit trickier: the latest 2D results of @RoccoBombardieri show pretty much no difference including the first timesteps. The onera m6 case in contrast converges to the same (steady-state) results for both code version eventually but their initial transient phase differs quite significantly. . A possible explanation for the different initial transient phase: In both implementations a ""reflected state"" is constructed where the normal component of the velocity is subtracted [once in the older code version & twice in the newer version]. I.e. subtracting the normal component of velocity twice means mirroring the velocity along the symmetry plane. The newer code version is a bit ""stronger"" in enforcing the boundary conditions which could lead to the reduced oscillation in CD and CL. If we agree that both code versions produce physically correct results for steady cases and unsteady cases that were integrated long enough in time to get rid of the influence of the initial condition ... then",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/828#issuecomment-563314747:789,recover,recovered,789,https://su2code.github.io,https://github.com/su2code/SU2/issues/828#issuecomment-563314747,1,['recover'],['recovered']
Safety,"Hi Pedro, thanks for looking into this more. I had run into inconsistencies for FSI problems with relaxation which was the reason for the domain specific calls coming into the multizone driver Update function. With the changes I introduced, the velocity at the interface was being transferred correctly with and without relaxation, so I left it there but it is a bit messy. I'll test with the modified calls for the Relaxation as you suggest. I completely agree that if we can simplify the velocity transfer by just using the velocity directly, then we should. Especially since the predicted velocity is only zero order anyway.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1174#issuecomment-774993325:582,predict,predicted,582,https://su2code.github.io,https://github.com/su2code/SU2/pull/1174#issuecomment-774993325,1,['predict'],['predicted']
Safety,"Hi Ruben,. Thank you for your feedback !. It is hard to tell what to do you to avoid conflicts. Anyway, the most significant part of the changes concerns the parent CDriver class, especially the constructor and some new functions that are pieces of code coming from the main function (like Output and Monitor). So if the contributions are focused on one particular driver (single, multi, ...) and if they are more or less compatible with the main ""driver->run"" then ""driver->update"" structure, it should be straightforward to solve the potential confilcts. Best,. David",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/295#issuecomment-237702911:79,avoid,avoid,79,https://su2code.github.io,https://github.com/su2code/SU2/pull/295#issuecomment-237702911,1,['avoid'],['avoid']
Safety,"Hi everyone, glad this subject is of interest. I will try to make that test case. I edit my earlier comment to avoid a mess. So I changed the terms. Still not sure but the derivation is simple. source term viscous = (0, tau_xy, tau_yy - tau_thetatheta, u* tau_yx + v* tau_yy - q)/y, right?. then from Bird:. ![IMG_20201027_115003](https://user-images.githubusercontent.com/55834287/97291927-d9767e00-184a-11eb-9418-a3ace3e3a077.jpg). bulk viscosity = 0, any derivative wrt theta = 0. For the generalised inviscid part I am pretty sure it is all correct including the jacobian. You can compare with very similar terms in any generalised flux jacobian like in Glaister's paper https://www.sciencedirect.com/science/article/pii/002199918890174X",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1095#issuecomment-713564781:111,avoid,avoid,111,https://su2code.github.io,https://github.com/su2code/SU2/pull/1095#issuecomment-713564781,1,['avoid'],['avoid']
Safety,"Hi, ; thanks for this contribution, I will get a more detailed feedback soon. A first comment about the CSymmetricMatrix class came up to my mind, from a first brief review.; There is already a CSysMatrix class and a few routines added in this pull request look redundant (matvect product for instance).; On the other hand, many of those routines (cholesky decomposition and so on) could turn out to be very useful also for other future code developments.; That said, perhaps it would be nice to collect all the matrix-related routines into the CSymmetricMatrix class (removing redundancies) to make them available at an higher level. Cheers,; Giulio",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/555#issuecomment-406370798:262,redund,redundant,262,https://su2code.github.io,https://github.com/su2code/SU2/pull/555#issuecomment-406370798,2,['redund'],"['redundancies', 'redundant']"
Safety,"I also like the idea of renaming to ""SOLVER"" but I would also say to avoid as much churn as possible in the conditionals throughout the code... looks like a wash when reading through the PR changes (almost as many +'s as -'s). Unless the changes are going to make something much more flexible or clear, I would say just keep Kind_Regime and set it in config postprocessing.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/756#issuecomment-520705829:69,avoid,avoid,69,https://su2code.github.io,https://github.com/su2code/SU2/pull/756#issuecomment-520705829,1,['avoid'],['avoid']
Safety,"I could create a ""safe Allgatherv"" function, e.g. in [`mpi_structure.hpp`](https://github.com/su2code/SU2/blob/1b085062547ec5b066a28ddeeacf4907588f4f5a/Common/include/parallelization/mpi_structure.hpp) or in [`ndflattener.hpp`](https://github.com/su2code/SU2/blob/1b085062547ec5b066a28ddeeacf4907588f4f5a/Common/include/toolboxes/ndflattener.hpp). This function should check the number of processes, perform a simple copy if it is 1, and otherwise calls the regular Allgatherv. It would then be used [here](https://github.com/su2code/SU2/blob/1b085062547ec5b066a28ddeeacf4907588f4f5a/Common/include/toolboxes/ndflattener.hpp#L235) instead of `SU2_MPI::Allgatherv`.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1893#issuecomment-1397491031:18,safe,safe,18,https://su2code.github.io,https://github.com/su2code/SU2/issues/1893#issuecomment-1397491031,1,['safe'],['safe']
Safety,"I expect that epsilon to be a simple measure to avoid division by 0, if that lower bound had physical meaning it would have to be multiplied by some reference factors to make its dimensions appropriate, otherwise SST would not give the same results for the same Reynolds obtained with different rho and mu.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/2329#issuecomment-2284506205:48,avoid,avoid,48,https://su2code.github.io,https://github.com/su2code/SU2/pull/2329#issuecomment-2284506205,1,['avoid'],['avoid']
Safety,"I have a few updates. I found out that most of my FGMRES problems in this branch where related to the fact that I was using single precision for the linear system. You can see it in this graphs for the residuals of Rho. ![RMSRho_Mesh_3](https://github.com/user-attachments/assets/185b8195-e415-4dff-9332-cff573c069cc). The first two curves are in mixed-precision and they stop long before reaching the minimum residual required due to divergence of the linear solver. Moreover, it seems that the 2003 model here implemented (which, simply put, considers the full reynolds stress tensor for the computation of the production of k and always considers k in the stress tensor and in the thermodynamic variables) has faster convergence and increases the recirculating zone (maybe due to the reduction of turbulence kinetic energy) which is a feature that has also been seen in [DOI:10.1017/aer.2020.93]. . ![SFC_Mesh_3](https://github.com/user-attachments/assets/81a50021-6b58-4a84-9057-a18b5bab023c). There are some differences between the use of the TMR boundary conditions and the ones used before. The results improve with respect to the develop in the prediction of the SFC distribution, which has results completely off from the V&V page of SU2. ![SFC_Mesh_3_Old](https://github.com/user-attachments/assets/0f4d634b-df31-4f86-a324-d9f67947f1ff). ![RMSRho_Mesh_3_Old](https://github.com/user-attachments/assets/24d5c2f5-93fe-432f-82d9-c050a90f7339). I may keep on checking if the implementation of the v2003 model is correct or not by searching for other test cases (probably coming from DOI:10.1017/aer.2020.93).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/2329#issuecomment-2393433487:1153,predict,prediction,1153,https://su2code.github.io,https://github.com/su2code/SU2/pull/2329#issuecomment-2393433487,1,['predict'],['prediction']
Safety,"I think I implemented all the modifications you suggested. I am sorry you see all the commits in between, unfortunately due to Covid I work outside of office and I actually use Github to push the modified code to the office PC. I was actually working on a separate branch but, for reason that I do not understand, all the commits have been moved in the merging process... sorry about that. I am still learning git. In particular the modifications are:. - The functions related to static mesh deformation have been removed. I only included some new lines in the python wrapper ; that overwrite the initial velocities to zero and push back the solution.; - I now use the BC_Sym_Plane of the FEA solver for the deformation at the symmetry plane. I had to add a flag that avoids ; accessing LinSysReact in case of mesh deformation, as this is not initialised in that context.; - GetnMarker_Match_Deform_Mesh is not present anymore; - The marker has been renamed from MATCH_DEFORM_MESH to DEFORM_MESH_SYM_PLANE. All the functions have also ; been renamed accordingly; - I included the SU2 header in all the new files, changing the version number to 7.0.8. I did not modify the version number of ; the files that were already present in SU2 prior to this PR. I think the merging process should take care of that, am I wrong?; - The python functions that were separated in x,y,z component now give back an array and are merged into one function only; - The descriptions for the methods have been added; - The test case has been removed. I actually prepared a tutorial and all the appropriate files will be placed in the tutorial and ; website repos. I will now perform a PR for those repos so that you can see the material. Again thank you very much and sorry for the mess with the ""internal"" commits. . Please let me know if you think I missed something",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1124#issuecomment-742471972:768,avoid,avoids,768,https://su2code.github.io,https://github.com/su2code/SU2/pull/1124#issuecomment-742471972,1,['avoid'],['avoids']
Safety,"I was running some tests using a simple geometry but for the refinement seems to be chewing up the geometry. Has anyone who has worked on 3D geometries experienced this or figured out a way to avoid this?. I was using the following settings:; ```; % ------------- MESH ADAPTATION PARAMETER ------------%; %; % Type of sensor used for adaptation; % Options include GOAL (adjoint-based), MACH, PRES; PYADAP_SENSOR= MACH; % Maximum cell size for adaptation; PYADAP_HMAX= 500.0; % Minimum cell size for adaptation; PYADAP_HMIN= 1e-9; % Gradation factor (typically 1.2-1.8); PYADAP_HGRAD= 1.8; % Norm used for adaptation; % 1.0 or 2.0 recommended for inviscid flows; % 4.0 recommeneded for viscid; ADAP_NORM= 2.0; % Approximate mesh size (NPOI) at each level; PYADAP_COMPLEXITY= (1000000, 1300000, 1500000); % Number of adaptations performed at each level; PYADAP_SUBITE= (2, 2, 2); ```. ![refine](https://user-images.githubusercontent.com/16842258/104834786-0b94fa80-58e5-11eb-9018-687ffc5aaa9d.png). I noticed a few comments up, there is the `PYADAP_BACK` setting, which sounds like it might solve this, but how should one use this? Should the geometry alone be re-meshed to a high resolution and the whole volume exported as a SU2 block? Or should it be just a surface mesh? (It seems that Pointwise is not able to output only the surface mesh in SU2 format.)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/948#issuecomment-761751741:193,avoid,avoid,193,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-761751741,1,['avoid'],['avoid']
Safety,"It seems like your situation may have been resolved, but for archival purposes, I'll list my workaround here. This problem occurs when you've installed python packages in two different locations. This could be due to installing some python packages in a system directory (e.g. `/usr/lib/`) and some in a user directory (e.g. `~/.local/`). SU2's build process is set to automatically detect the default package location, but it's not equipped to handle multiple package locations. There are some hardcoded includes, but these only work for python 2.7. I don't consider this a bug *per se* because multiple python package directories is not a standard use case. #### The symptoms. When building SU2 with the python wrapper you'll see the following error during the swig build:; ```; <install directory>/../SU2_PY/pySU2/pySU2.i:64: Error: Unable to find 'mpi4py/mpi4py.i'; ```; But mpi4py is indeed installed on your system and it's on your python path, as confirmed by opening a python terminal and running `import mpi4py`. #### The easiest workaround. Switch to a [virtualenv](https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/). This will ensure that all of your python packages are stored in single location. #### Alternate workaround. In this method, you change the hardcoded includes to match mpi4py's package location. First I figure out where my mpi4py is installed. I start a terminal session of python using the python environment I want to use (in this case, it's python 3.6), and then run:; ```; from mpi4py import MPI; MPI; ```. Since I have mpi4py installed on your system and it's on my python path, I see something like:; ```; <module 'mpi4py.MPI' from '/home/clarkpede/.local/lib/python3.6/site-packages/mpi4py/MPI.cpython-34m.so'>; ```. The `/home/clarkpede/.local/lib/python3.6/` directory is where my mpi4py package is installed. But the swig compile command includes `/home/clarkpede/.local/lib/python2.7/`. That's not the right directory! So first I ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/722#issuecomment-515693590:383,detect,detect,383,https://su2code.github.io,https://github.com/su2code/SU2/issues/722#issuecomment-515693590,1,['detect'],['detect']
Safety,"Juan,. Indeed, it is desirable that at the highest level the details of the time integration scheme and number of zones per discipline should not be visible. The question is whether that is achievable for all combinations you can think of. This is especially the case for the time integration schemes. E.g. suppose you would like to use a multi-stage time integration scheme for a multi-physics problem. To obtain the design accuracy in time, this implies that the loop over the number of time stages is outside the loop over the number of physical disciplines. Hence at a very high level in the hierarchy, the details of the time integration should then be known. The situation becomes even more complicated when one would like to employ time integration schemes that allow for time accurate local time stepping, e.g. the ones we are currently working on for the DG solver. I won't bore you with all the details here, but those schemes basically require the loop over the multiple disciplines to be between the predictor and corrector step, while both these steps consist of multiple stages. Although it is probably possible to come up with a data structure that supports all this, the question is whether this is desirable. Apart from the fact that it would require a major overhaul in the high level design of SU2, the implementation will be less readable, especially for people that will be starting with the code. Also the parallelization may become significantly more complicated. The alternative is that for unsteady multi-physics problems, we put the restriction that only single stage time integration schemes can be used, e.g. DT_STEPPING_1ST and DT_STEPPING_2ND. In that case, the details of the time integration scheme can be hidden at the driver level, where we then simply have a loop over the number of physical disciplines. The consequence of course is that more advanced time integration schemes will not be available for multi-physics problems. In the above I just tried to picture w",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/437#issuecomment-328441926:1012,predict,predictor,1012,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328441926,1,['predict'],['predictor']
Safety,"Maybe CNumerics is not the perfect place, but it is good enough for government work (there are much more misplaced things in there). The ""everything is class"" OO approach applied to the lowest level of abstraction is... well I think it is terrible -- and it has taken me a mighty long time to get rid of it in CPoint and CVariable and to design alternative Numerics -- because:; - Boilerplate: Set this, get that, constructor, destructor;; - Thread safety: Those classes always end up having some mutable state that renders them thread-unsafe;; - Correctness: Many of the classes we have follow this paradigm of ""pass by member variable"" - I like to know what are the inputs and outputs of something just by looking at the signature;; - Slowww: Too much virtual;; - Unnecessary complexity: A case of using a canon to kill the mosquito, good code should be as simple as possible, if a function does the job then that is the level of abstraction we should use. My introduction to C++ was also the ""everything is class"", then one day I read ""From Mathematics to Generic Programming"" and well, I started liking C++ a whole lot more.; The standard template library is incredibly successful, and it ""just"" provides some containers and generic algorithms which are functions. That is what we need in SU2, some decent containers and generic algorithms to operate on them. OO and its patterns are very good high level tools to achieve encapsulation and to isolate code, which are very important for projects with millions of lines of code, but for low level things they are overkill. Sorry for the rant, I guess I have strong feelings about tiny classes.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1127#issuecomment-742629412:449,safe,safety,449,https://su2code.github.io,https://github.com/su2code/SU2/pull/1127#issuecomment-742629412,2,"['safe', 'unsafe']","['safety', 'unsafe']"
Safety,"Nice analysis @clarkpede. It is true that we simplify the Jacobians at the periodic boundaries, mostly to avoid issues with adding entries to the Jacobian from the neighbors that potentially do not live on our rank and to keep communication costs low (those neighbors are treated explicitly). This could be changed to communicate the full Jacobian.. but I am not sure it is worth the effort/cost. The approximation that is made should still be consistent though, because we only allow one of the repeated periodic nodes to participate in the linear solve with each nonlinear iteration, and then we communicate its update to its periodic pair. In short, the value of the solution should always be the same on periodic points with each iteration update, and if the problem converges to a steady-state (even in time stepping mode), the Jacobian should only affect convergence (the RHS should be the same). You could try the time stepping option with one of the RK methods to see if going fully explicit helps further isolate the issue. It could also be something related to the time step that is communicated. In the SetTime_Step() routine in the flow solver class, we do some special checks for time stepping mode to make sure that the minimum global time step is used in all cells. Might want to print out the dT communicated in the periodic comms or write the dT to the solution file to make sure everything is ok there too. Honestly, I don't think a ton of folks use the time stepping option in general with the FVM solver, so double-checking that it behaves well for a non-periodic problem could shed some light too, unless you have already done that.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/763#issuecomment-524007345:106,avoid,avoid,106,https://su2code.github.io,https://github.com/su2code/SU2/issues/763#issuecomment-524007345,1,['avoid'],['avoid']
Safety,"Nice progress @pcarruscag!. I like the concept of your SIMD-friendly class that will take care of the data structure under the hood coupled with a standard type of loop statement (w/ +SIMDLEN). This should make it pretty easy for folks to still modify the kernels without having to worry about the data alignment, and they can reuse the same simple 'for' construct repeatedly. . Another reason to have our own lightweight class for this is that you can avoid dependence on OpenMP for SIMD (although that feature looks to have potential and wasn't available until somewhat recently) as well as the intrinsics. In my experience, the latter is especially bad for portability and readability (part of why we left the CaF work in a separate repo). It starts to become so specialized that compiling and modifying become difficult. W.r.t. OpenMP, another roadblock there a few years ago was making sure it is interoperable with CoDi for the adjoint, but I know this has been worked on and may be available by now. Might keep an open mind about point vs. edge. In some places, we may be able to pump up the compute in our loops by fusing kernels, as previously discussed (and I am guessing you are working on this already with gradients/limiters). Could change the final performance numbers significantly. Lastly, I know you are not there yet, but it is worth considering whether you can reuse anything you are developing in the kernels here for the linear solver routines. At some point, you will successfully reduce the cost of the residual kernels (RHS) to the bandwidth limit, and the majority of the iteration cost will be in the linear solver (it is already about 50% of the iteration cost before optimization, if I recall). Before making final decisions on strategy, you should consider if it will help in any of the linear solver routines too.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-530440072:453,avoid,avoid,453,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530440072,1,['avoid'],['avoid']
Safety,"Ok the ""simple"" version of ""going parallel"" whenever we get to a linear algebra operation did not make the cut.; On an older architecture there was a 10% slowdown of the linear solvers at ~10k nodes per core and about the same on a newer architecture but only at ~1k node per core.; Since hybrid parallel is supposed to be good for strong scaling, this was not good enough... With the new strategy it is ok (see ""performance"" below), hence this is ready for review. ### Overall Strategy; The strategy now is to start a parallel section in CSysSolve::Solve that covers building the preconditioner and solving the linear system.; Linear algebra routines called within this section have _worksharing_ constructs instead of _parallel_ ones, i.e. the work is distributed by however many threads arrive to that routine. This also makes the routines safe to call in serial.; The only ""dangerous"" things to do in parallel are to: manage memory for a shared object (multiple threads call `new` but there is only one shared pointer on which to call `delete`); writing to the same memory locations concurrently.; I tried to make the first issue debugable by asserting that the initialization routines of CSysMatrix and CSysVector are only called by the master thread.; For the second issue I made the associated classes as const-correct as possible, that should at least make someone think twice before changing a member variable of those classes. The risk is still there for input variables as an algorithm development aspect... For example `MatrixVectorProductTransposed` cannot be made thread-parallel as simply/naively as its normal counterpart. ### Communication Model; The MPI + Threads communication model is very simple, currently only the master thread calls MPI routines (including `Error`), this requires thread barriers before and after the communication to make sure the correct values are passed and _seen_ by all threads.; We can test other alternatives in the future but at the moment this does n",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/830#issuecomment-562646766:843,safe,safe,843,https://su2code.github.io,https://github.com/su2code/SU2/pull/830#issuecomment-562646766,1,['safe'],['safe']
Safety,"Ok, SIMD update, with #753, #959, and #966 we now have a unified storage type for the data we need in CNumerics. This means that we (I) only need to implement ""SIMD accessor methods"" (i.e. that return a SIMD type instead of a su2double) for one class (C2DContainer and co.). I think to do SIMD right we need a new way of going about CNumerics, these are my design requirements for ""CNewNumerics"":; - Thread-safe (consequently const-correct), a single object must be safe to use by multiple threads.; - Minimal indirection, the polymorphic overhead will be reduced to a single call (ComputeResidual), all auxiliary functions (like the ones that live in CNumerics) will be forcefully inlined, no useless copies of data (no more numerics->SetBlaBla).; - Compile time nDim/nVar, which will: a) avoid heap allocations; b) allow effective loop-unrolling (also during the writes to CSysMatrix).; - Allow low-overhead composition, e.g. have one CRoe for Euler and one CRoeVisc for NS to fuse convective and viscous residuals (without copy pasting code).; - A lot more readable, those cryptic V_i[iDim+1] need to go (somehow...). To achieve all this, the ""CNewNumerics"" will work as a template (obvs) decorator/visitor.; A visitor in the sense that the solver calls the numerics and gives it (read-only) access to all its data, the object pulls whatever it needs directly and there is no need for numerics->SetBlaBla.; A template decorator in the sense that the class can be augmented simply by inheriting from another, along the lines of `class CRoeVisc : public CRoe, public CVisc` (to allow fusing residual and Jacobian contributions).; All this needs to be done with templates for the ""minimal indirection"" requirement. Which means for each numerical method we will have 4 explicit template instantiations (Euler2D, Euler3D, (RA)NS2D, (RA)NS3D) but in the end these are still polymorphic objects that will be instantiated by some factory function (i.e. it will look clean, especially because I will not por",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-622941617:407,safe,safe,407,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-622941617,3,"['avoid', 'safe']","['avoid', 'safe']"
Safety,"On the subject of virtual functions I would like to put another idea forward.; After moving things around in #725 I noticed that we have tons of `inline virtual` methods.; The keyword `inline` has two meanings to the compiler:; - ""Dear merciful compiler please copy paste the body of this function and then do all your wonderful optimizations, if that pleases your excellency.""; - ""Dear forgiving compiler, you will find this method defined in multiple units, please don't be mad"" (i.e. ignore the one-definition-rule). `virtual` means determine what version of the method to call at runtime. This is not compatible with the first (and often the intended one) meaning of inline, therefore the compiler will in general not inline those methods.; They will only be inlined if they are being called on a pointer to the derived class that does not declare the method to be virtual anymore. CSolver knows what variables it creates and so in hot areas of the code it could do a static downcast to allow inlining (e.g. `static_cast<CEulerVariable*>(node[iNode])->DoStuff()`).; Where is this important? For example when computing gradients, where simple additions and subtractions are hidden behind virtual functions.; If you are worried about maintenance each solver can typedef its most safe downcast level or better yet (or just more modern), methods that could benefit from this can be templated for the type of downcast.; Those in favour say Yea those against say Nay.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/716#issuecomment-509273008:1281,safe,safe,1281,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-509273008,1,['safe'],['safe']
Safety,"Sounds like a reasonable optimization, the only other place that handles averages is `COutput::Postprocess_HistoryData`, so this should be a very local change and thus a good first issue. Do you want to give it a go at creating a pull request for this? We can give you some pointers. But it should be simple to modify the `addValue` function to take the window type as argument and only `push_back` for non trivial windows.; Even those could be optimized by caching the sum over n-1 elements, this would avoid traversing the entire history of values when only the last entry is modified during inner iterations.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1545#issuecomment-1037249095:504,avoid,avoid,504,https://su2code.github.io,https://github.com/su2code/SU2/issues/1545#issuecomment-1037249095,1,['avoid'],['avoid']
Safety,"Thank you for the thorough review @rsanfer! I'll reply to your main questions and some of the smaller ones here to centralize things. > Just a request, if it's possible that you add one or two test cases so the implementation is safe onwards (and, of course, so I can play around with the new features a little bit ). The testcases are the same, no changes there other than the one optional option introduced above. When the hybrid stuff covers most of the code I would add an entire build configuration e.g. BaseMPIOMP and corresponding testcase suite. > * Should this just run ""out of the box"" with a working installation of OpenMP in any machine, or is there anything else _fancy_ needed?. I would leave it to the community to decide what the defaults should be, probably for a lot of new users that don't run on clusters just calling SU2_CFD and not having to worry about mpi would be nice (a lot of the issues on CFD online are mpi related). > * Is the previous behaviour exactly kept, or are there any modifications in the basic, non OpenMP version of code? (Not that I mind, just curious). Other than the algorithmic changes (but mathematically equivalent) introduced to limiters and gradients in #834, yes. > What's the advantage of having one numerics term per thread?. It is a requirement, we need to write data into numerics before using them, multiple threads cannot write to the same location (i.e. the internal structures of CNumerics) therefore one per thread is required. > ...Also, I think I missed the point where the numerics container is extended beyond MAX_TERMS. The allocation of space for one numerics per thread is done above in line 1995 of my 21 Dec 2019 comment: `...MAX_TERMS*omp_get_max_threads()...`.; The instantiation of one numerics per thread is then done by executing the rest of the preprocessing in parallel and instead of using `XYZ_TERM` using `XYZ_TERM+offset` where `offset = thread_id * MAX_TERMS`.; I think someone mentioned this (maybe Tim) that we could r",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/843#issuecomment-577684728:229,safe,safe,229,https://su2code.github.io,https://github.com/su2code/SU2/pull/843#issuecomment-577684728,1,['safe'],['safe']
Safety,"Thanks @MicK7 I will have a look, my initial thought was to have a simple strategy where within each MPI rank parallelism is extracted via colouring or scatter-to-gather transformations and only one thread per rank participates in the message passing, I have no experience here though so this might be a bad strategy, idk. **Back to business:**; I went silent for a bit because in prototyping a typical residual computation and matrix update loop I made some realisations that made me go back to the drawing board regarding data structures, and eventually back to square 0. . ## Parallel strategy for flux computation; Because significant computation is required to obtain each edge's flux, it does not make sense to attempt a ""point-loop"" strategy (which would double the effort).; However, one can either use colouring to avoid the race conditions that would result from updating the residual of cells i and j, or store the edge fluxes and then, on a second point-loop perform the summation of fluxes for each cell, with the direction being accounted by the same adjacency information used in the point-loop GG gradient computation.; If we consider only the update of residuals the two strategies are fairly equivalent performance wise, the tie breaker is the matrix updates. ## Matrix Updates; By this I mean the `addBlock`, `subBlock` we do (two times each) to update diagonal and off-diagonal blocks for each edge.; Here is a dummy numerics loop that does nothing else but setting blocks in the matrix (with colouring).; ```c++; void testLoop1(const vector<size_t>& colorStart,; const vector<size_t>& edgeIdx,; const vector<pair<size_t,size_t> >& connectivity,; double** blk_i, double** blk_j,; SparseMatrix& matrix); {; matrix.setZero();. for(size_t color=0; color<colorStart.size()-1; ++color); #pragma omp parallel for schedule(dynamic,CHUNK_SIZE); for(size_t k=colorStart[color]; k<colorStart[color+1]; ++k); {; size_t iEdge = edgeIdx[k];; size_t iPoint = connectivity[iEdge].first;; size_t j",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-535977206:824,avoid,avoid,824,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206,1,['avoid'],['avoid']
Safety,"The motivation of having it as the default was to make the code as user-friendly as possible (fewer knobs exposed in the config), but options are good of course. I would propose then that we add an option for the reconstruction gradient, something like:; ```; NUM_METHOD_GRAD_RECON= LEAST_SQUARES; ```; to let users decide if they want a separate option for the reconstruction gradients. If it does not appear, then the default is to use the same method as defined by NUM_METHOD_GRAD without a second gradient computation (basically what we have now). The nice thing about that is we can even try out other combos such as WLS+GG for the two different gradients. I will throw an error if users try to use LSQ for the viscous/source gradients, to avoid accuracy issues. What do you think?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/790#issuecomment-533259202:745,avoid,avoid,745,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-533259202,1,['avoid'],['avoid']
Safety,"This one is all set after a little more cleanup. I left some low-level changes to the EoS models for later. @CatarinaGarbacz @MarcoFossati : we can use a simple directory name, as you suggest. Let's just go with fluid/ since we also treat liquids with the incompressible solver. Bonus: adds a rotating frame calculation test and some extra error checks on CFL adapt params that should help avoid unreported problems with old configs.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1010#issuecomment-640170715:390,avoid,avoid,390,https://su2code.github.io,https://github.com/su2code/SU2/pull/1010#issuecomment-640170715,1,['avoid'],['avoid']
Safety,"Todo list:; - [x] Make sure the code can handle arbitrary many species equtions. Especially the output has to be adapted. Note the MAXNVAR of the ScalarSolver has to adapted to that need as well. Make a suitable Testcase for that.; - [x] Implement weak inlet and outlet BC. The weak approach is used in the turb and mean flow and is most likely conservative opposed to the strong one. Here a simple switch will be put in place to compare both versions.; - [x] Consolidate nVar, nSpecies, ... variable to only use 1 consistently (The choice was `nSpecies` which was already introduced for NEMO and it just makes sense to use the same container); - [x] Make the numerous reviewers happy; - [x] Check inlet profiles for Species solver (have a testcase for that) See #1427 ; - [x] Create Objective functions of Surface avg quantities (Area and Massflow? prob. And a variance-style output to capture mixing); - [x] Avoid redundant operations (pre/post processings) during solver restarts. 156d0c5. What will be done in follow-up PR's:; - Viscous contributions for BC_inlet and outlet which are currently not used (also then for Turb-solver) https://github.com/su2code/SU2/pull/1388#discussion_r752384956; - Axissymmetric source term addtion and testing; - multi-component mixing from #1332 ; - gradient validation between DA and FD",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1388#issuecomment-935901996:916,redund,redundant,916,https://su2code.github.io,https://github.com/su2code/SU2/pull/1388#issuecomment-935901996,1,['redund'],['redundant']
Safety,"Unfortunately, I wasn't able to get all of them. I fixed a majority of the calls but couldn't find workarounds all of them. There are 8 left in the following files: . `SU2_PY/change_version_number.py`: There's 2 in here. One is a complicated command with `grep` and pipes and the other is a simple `rm -rf`, but it isn't a security risk since there is no user input into that string. `SU2_PY/SU2/util/pyCppTap.py`: This is in the diff_routine and uses `tapenade`. I have no idea what this does so I didn't touch this one. `SU2/opt/server.py`: There are 4 `scp` calls that I didn't know how to replace. `SU2_PY/compute_polar.py`: There's one left in here which is a complicated `cat` call that I couldn't figure a workaround for. . If you have any suggestions for any of these, I can try and implement them. . Otherwise, once these tests pass, its good to merge.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/781#issuecomment-533590086:332,risk,risk,332,https://su2code.github.io,https://github.com/su2code/SU2/pull/781#issuecomment-533590086,1,['risk'],['risk']
Safety,"Yes for MARKER_ROUGH, or MARKER_ROUGH_WALL to be clearer.; Or just WALL_ROUGHNESS as you have right now, since it would not really a marker, just the properties of markers (and I've seen some people on CFD online confused with similar naming e.g. MARKER_SHROUD). Regarding the MPI stuff, I had the following idea over lunch:; In CPhysicalGeometry::SetWallDistance we compute the closest distance, and in so doing we also get the mpi rank and markerID associated with the closest vertex.; So, before computing the wall distances you communicate the local marker ids and wall roughness's (via Allgather as you are doing now), with this info you can build a `unordered_map<pair<int,int>, su2double>` to map pairs of <rank,markerID> to the values of roughness.; Now when you loop over the points to compute the distances you can retrieve the roughness from this map instead of from config.; It's almost exactly the same as you have, but avoids using the config as a messenger between routines, and using a stl map should also make the code simpler. In the boundary conditions you can still get the marker roughness via the marker tag as you are doing now, and I guess the wall type (smooth / rough) can be inferred from having 0 (default) roughness (?); With the string+double list specification you also avoid having to specify 0 roughness and SMOOTH wall type for markers where you don't want to use this feature.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/877#issuecomment-630861158:933,avoid,avoids,933,https://su2code.github.io,https://github.com/su2code/SU2/pull/877#issuecomment-630861158,2,['avoid'],"['avoid', 'avoids']"
Safety,"You are proposing the exact opposite of the conclusion of the paper:. ""From the above findings, it is **recommended that all three of these terms be included** when; running hypersonic, or even supersonic, turbulent flow simulations, especially for flows with; shock wave-induced separations."". And they clearly say this:; ""While the full inclusion of these terms does not always result in predictions that agree better; with DNS/experimental data, this is likely caused by the fact that their exclusion cancels out; effects of other flaws in the RANS models employed."". If your strategy is to get a better match with experiments by neglecting physics terms, then you should rethink your strategy.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1851#issuecomment-1520849562:390,predict,predictions,390,https://su2code.github.io,https://github.com/su2code/SU2/issues/1851#issuecomment-1520849562,1,['predict'],['predictions']
Safety,"You could modify `CWindowedAverage::addValue` to only ""push back"" more values if it detects a change in current time iteration, otherwise it simple overwrites the last value in the history.; Then you could get rid of the entire logic in `SetUpdate_Averages` simply making it true or false (less logic is the way for less bugs).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1259#issuecomment-817952886:84,detect,detects,84,https://su2code.github.io,https://github.com/su2code/SU2/pull/1259#issuecomment-817952886,1,['detect'],['detects']
Safety,"computations are very simple it may not pay-off to vectorize. **Relation with algorithms**; Some form of `gather` and `scatter` is required in unstructured CFD, which means SIMD has a price of admission. Some thought needs to go into designing algorithms that amortize that cost by maximizing the so called FLOP/Byte ratio, and mask the latency of those operations by being able to start computing as soon as the first element of data is available. **What elements should we try to process simultaneously?**; The choice is between multiple geometric primitives (edges/points) or multiple solution primitives (variables). The latter sounds like a sensible idea until we get to areas of the code where different primitives require different treatment, that and the fact that the number of variables might not fit evenly in the number of lanes can lead to very tricky and non-generic code. Nevertheless if the same code were to be applied to e.g. 4 solution variables, this strategy would likely perform better as it avoids the pesky gather/scatter operations.; Processing multiple geometric primitives can make full utilization of whatever register size (important on GPU's), the code is just as readable (as I hope to show), but gather/scatter cannot be avoided. ### Intro to SPMD; This one is simpler, in a nutshell multiple threads operate on the sub domain of an MPI rank.; The typical implementation has each thread executing a chunk of an edge or cell loop. **Why should we care about SPMD?**; Reduce the communication overhead resulting from domain decomposition and improve load balancing, important for strong scaling.; Some algorithms are more efficient that way, e.g. the ADT (as mentioned by Edwin), the current MG also seems to work better on fewer partitions, and additive versions of preconditioners like the ILU or LU-SGS lose effectiveness with number of partitions.; Optimum hardware utilization, for routines that are bandwidth-bound it may be beneficial to use all threads available",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-529662724:2609,avoid,avoids,2609,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-529662724,1,['avoid'],['avoids']
Safety,"formance, here is the effect of color group size on the execution time of the scalar code on one thread:; ![image](https://user-images.githubusercontent.com/38071223/64686801-2e0d3d00-d481-11e9-82a0-c56e5554cd83.png); The hassle-free option of not sorting by color ""never"" recovers the performance of the base algorithm, things are even worse for the SIMD version where even at group size of 8192 with re-sorting the slowdown is 14%. Running the edge-loop version on 4 cores (8192 group + sorting) we get speedups (relative to reference) of **1.98** and **2.04** for the scalar and SIMD versions respectively (yes I quadruple checked).; If you are keeping track of the number two things should surprise you, the first is that there is no difference between scalar and SIMD now (the vector instruction are still there though), the second is that 4 cores give only a 2x speedup. The reason for both is: the implementation is very memory-bound, and so throwing more compute at it, either in the form of more cores or more lanes, does not help much. This is the 4 core summary:. | Code | Edge | Edge, SIMD on vars | Point | Point, SIMD on points |; | ---- | ---- | ---- | ---- | ---- |; | **Speed** | 2.0 | 2.0 | 3.8 | 2.8 |. I think the point-based versions scale better because they are a bit less memory-bound as they write to the gradient sequentially and they have a bit more compute due to the duplicated computations. **Conclusion**; Computing gradients via point-loops allows simpler and more generic SIMD and SPMD strategies, the resulting implementation seems to do better in the bandwidth-starved conditions typical of modern hardware (3 or more cores per memory channel). However, additional adjacency information is required to support point-based loops. Next I will talk about limiters, almost all concepts are introduced so it will be shorter (promise). As a little appetizer let me tell you we can recover the extra memory and we could be looking at a 2.7x speedup for gradients+limiters.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-530328194:15713,recover,recover,15713,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530328194,1,['recover'],['recover']
Safety,"hort array of matrices, the result of that is code like the above that explicitly manipulates the lanes of our SIMD type, such code can be completely hidden inside CSysMatrix which is good because a 4x4 vectorized transpose and matrix update looks like this; ```c++; // block j, subs from jj and goes to ij; T0 = blk_j[ k ].unpackLo(blk_j[k+1]); T1 = blk_j[ k ].unpackHi(blk_j[k+1]);; T2 = blk_j[k+2].unpackLo(blk_j[k+3]); T3 = blk_j[k+2].unpackHi(blk_j[k+3]);. C0 = T0.widePermuteLo(T2); C1 = T1.widePermuteLo(T3);; C2 = T0.widePermuteHi(T2); C3 = T1.widePermuteHi(T3);. (Array4d(&bjj[0][k])-C0).store(&bjj[0][k]);; (Array4d(&bjj[1][k])-C1).store(&bjj[1][k]);; (Array4d(&bjj[2][k])-C2).store(&bjj[2][k]);; (Array4d(&bjj[3][k])-C3).store(&bjj[3][k]);. C0.store(&bij[0][k]); C1.store(&bij[1][k]);; C2.store(&bij[2][k]); C3.store(&bij[3][k]);; ```; I am showing this because it represents a readability worst case in terms of manipulating SIMD types, we might end up with one or two of these to get the best performance possible but they will always be encapsulated and deep in kernel-type areas of SU2 that are almost never touched. ## Conclusions; - Over 45% faster CSysMatrix updates by mapping off-diagonal blocks to edges and diagonal blocks to points.; - Colouring is the best strategy for hybrid parallelism of compute-heavy edge loops and matrix updates as it interleaves compute and memory operations.; - AoS storage should be kept to avoid significant loss of performance in compute-light edge loops due to poor locality of SoA storage.; - Major implication of AoS is on point loops where some data needs to be fetched (transposed) into local variables for effective vectorization.; - An intermediate storage scheme, AoSoA, can provide both good locality and vectorization of point loops, however it requires that data be accessed via special iterators and scalar code based on it would have poor performance. Next I will try to estimate how much we can gain for a ""realistic"" numerics class.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-535977206:16984,avoid,avoid,16984,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206,1,['avoid'],['avoid']
Safety,"i_i[iVar]);; phiMin(jPoint,iVar) = min(phiMin(jPoint,iVar), phi_i[iVar]);; }; }. for(size_t color=0; color<colorStart.size()-1; ++color); #pragma omp parallel for schedule(dynamic,CHUNK_SIZE); for(size_t k=colorStart[color]; k<colorStart[color+1]; ++k); {; #if SORT_BY_COLOR==1; size_t iEdge = k;; #else; size_t iEdge = edgeIdx[k];; #endif. size_t iPoint = connectivity[iEdge].first;; size_t jPoint = connectivity[iEdge].second;. // i to j vector; double d_ij[3] = {0.0, 0.0, 0.0};. for(size_t iDim=0; iDim<nDim; ++iDim); d_ij[iDim] = 0.5*(coords(jPoint,iDim)-coords(iPoint,iDim));. // projections; double proj_i[nVar], proj_j[nVar];. #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); proj_i[iVar] = proj_j[iVar] = 0.0;. for(size_t iDim=0; iDim<nDim; ++iDim); {; #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); {; proj_i[iVar] += d_ij[iDim]*grad(iPoint,iVar,iDim);; proj_j[iVar] -= d_ij[iDim]*grad(jPoint,iVar,iDim);; }; }. // choose the ""right"" delta based on sign of projection; // and avoid division by zero; double lim_i[nVar], lim_j[nVar];. #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); {; lim_i[iVar] = phiMax(iPoint,iVar);; lim_j[iVar] = phiMax(jPoint,iVar);; }. const double eps = numeric_limits<double>::epsilon();. // very simple if's are required to get vectorization; // trough vector comparisons and masked blends; #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); {; if(proj_i[iVar] <= 0.0); {; lim_i[iVar] = phiMin(iPoint,iVar);; proj_i[iVar] = min(proj_i[iVar], -eps);; }. if(proj_j[iVar] <= 0.0); {; lim_j[iVar] = phiMin(jPoint,iVar);; proj_j[iVar] = min(proj_j[iVar], -eps);; }; }. #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); {; lim_i[iVar] = (lim_i[iVar]-phi(iPoint,iVar))/proj_i[iVar];; limiter(iPoint,iVar) = min(limiter(iPoint,iVar), lim_i[iVar]);. lim_j[iVar] = (lim_j[iVar]-phi(jPoint,iVar))/proj_j[iVar];; limiter(jPoint,iVar) = min(limiter(jPoint,iVar), lim_j[iVar]);; }; }. #pragma omp parallel for schedule(dynamic,TARGET_CHU",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-530593912:6100,avoid,avoid,6100,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530593912,1,['avoid'],['avoid']
Safety,"irst;; size_t jPoint = connectivity[iEdge].second;; ```; Apologies for the macro but it is just to illustrate that if we re-sort edge data after coloring the edge index is the loop index, otherwise the edge indices for each color need to be stored in a separate array.; Note that for each edge loop we first loop over colors, then over same-color edges, it is this inner loop that can run in parallel in chunk sizes that are multiple of the group size considered during coloring. There is some runtime cost on entry to every #omp parallel section, with coloring we enter one such section once by color. I mentioned in the introduction coloring reduces locality and therefore performance, here is the effect of color group size on the execution time of the scalar code on one thread:; ![image](https://user-images.githubusercontent.com/38071223/64686801-2e0d3d00-d481-11e9-82a0-c56e5554cd83.png); The hassle-free option of not sorting by color ""never"" recovers the performance of the base algorithm, things are even worse for the SIMD version where even at group size of 8192 with re-sorting the slowdown is 14%. Running the edge-loop version on 4 cores (8192 group + sorting) we get speedups (relative to reference) of **1.98** and **2.04** for the scalar and SIMD versions respectively (yes I quadruple checked).; If you are keeping track of the number two things should surprise you, the first is that there is no difference between scalar and SIMD now (the vector instruction are still there though), the second is that 4 cores give only a 2x speedup. The reason for both is: the implementation is very memory-bound, and so throwing more compute at it, either in the form of more cores or more lanes, does not help much. This is the 4 core summary:. | Code | Edge | Edge, SIMD on vars | Point | Point, SIMD on points |; | ---- | ---- | ---- | ---- | ---- |; | **Speed** | 2.0 | 2.0 | 3.8 | 2.8 |. I think the point-based versions scale better because they are a bit less memory-bound as they write ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-530328194:14076,recover,recovers,14076,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530328194,1,['recover'],['recovers']
Safety,"it ""a"" to look at some assembly, honestly sliced bread has nothing on perf. NOTE: By and large Perf is not an intrusive tool, as such the accuracy of the measurements is limited i.e. it is probably not a good idea to draw conclusion about <1% variations. Moving on, I took the top level percentages only, normalized by that of CFluidIteration::Iterate (to exclude pre-processing time) and multiplied the results from the total ""iteration time"" from the history file. Doing that for before and after results allowed computing individual speedup factors for each important routine (in terms of time, otherwise they are all special and important in their own way) e.g. gradients, limiters, upwind/viscous residuals, etc.; ![image](https://user-images.githubusercontent.com/38071223/63292708-30cfa480-c2be-11e9-8d4a-5feb3dc61abf.png). Here is the data by the way: [results.xlsx](https://github.com/su2code/SU2/files/3517492/results.xlsx). As predicted the linear solvers stay the same and routines that are light see more speedup than their arithmetic-intensive friends.; What is surprising to me is how intensive the convective residuals appear to be with only a 7% improvement, so surprising in fact, I do not think the above paints the full picture. Maybe the outlet bandwidth bottleneck (into the Jacobian matrix) is more important.; To put that do the test I switched to Euler-explicit time marching and repeated the measurements:; ![image](https://user-images.githubusercontent.com/38071223/63293351-d8010b80-c2bf-11e9-8135-2502eac1128e.png); Better, but not by much, which means upwind and viscous residuals computations might gain a lot from vectorization (SIMD). And like @economon mentioned even more if they are somehow fused together.; It also means the writes to CSysMatrix are relatively expensive, I think there are two-three reasons for it.; - We do a linear search on each Add/SubtractBlock - This could be replaced by a map.; - The Jacobian contributions are first written into a tempor",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/716#issuecomment-522730951:3946,predict,predicted,3946,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-522730951,1,['predict'],['predicted']
Safety,"l Strategy; The strategy now is to start a parallel section in CSysSolve::Solve that covers building the preconditioner and solving the linear system.; Linear algebra routines called within this section have _worksharing_ constructs instead of _parallel_ ones, i.e. the work is distributed by however many threads arrive to that routine. This also makes the routines safe to call in serial.; The only ""dangerous"" things to do in parallel are to: manage memory for a shared object (multiple threads call `new` but there is only one shared pointer on which to call `delete`); writing to the same memory locations concurrently.; I tried to make the first issue debugable by asserting that the initialization routines of CSysMatrix and CSysVector are only called by the master thread.; For the second issue I made the associated classes as const-correct as possible, that should at least make someone think twice before changing a member variable of those classes. The risk is still there for input variables as an algorithm development aspect... For example `MatrixVectorProductTransposed` cannot be made thread-parallel as simply/naively as its normal counterpart. ### Communication Model; The MPI + Threads communication model is very simple, currently only the master thread calls MPI routines (including `Error`), this requires thread barriers before and after the communication to make sure the correct values are passed and _seen_ by all threads.; We can test other alternatives in the future but at the moment this does not seem to be a significant bottleneck.; _Worksharing_ constructs have implicit barriers at completion, for CSysVector routines I used `nowait` modifiers, it is safe to call those routines in sequence since the loop sizes, and static work scheduling specifications are identical.; However, routines that access a CSysVector in a different way, should have an explicit barrier before using the vector (or risk having undefined behaviour). You will see these barriers on entry ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/830#issuecomment-562646766:1441,risk,risk,1441,https://su2code.github.io,https://github.com/su2code/SU2/pull/830#issuecomment-562646766,1,['risk'],['risk']
Safety,"look, I used a conservative number based on:; For the Roe scheme 4 matrices are generated (Jacobian i, Jacobian j, P tensor, P^-1 tensor), each coefficient of those matrices requires a reasonable number of floating point ops, and two of those matrices are indeed multiplied by each other.; So lets say 5 matrix-matrix multiplications are representative, this should be a conservative estimate as I am not considering the eventual fusion of convective and diffusive discretizations. **The vectorized code is 1.5 times faster.**; This is a fair 1.5 as the code is running on 4 fast cores (parallel via colouring for the reasons I explained previously) and 2 memory channels (scalar code can eventually saturate the memory bandwidth too, but it would take an unreasonable ratio of cores to channels to do so).; Furthermore the scalar code I am considering is writing to CSysMatrix with all the mapping and vectorized writes I mentioned before, before you get all compound interest and take this 1.5 with the 1.47 from CSysMatrix, the speedup relative to code without mapping and vector writes is 1.85.; I restate that this does not require changes to the data layout, again for reasons previously mentioned. ## SpMv - Sparse matrix-vector multiplication; With all these speedups the linear solvers will start taking well over 50% of the time, and so it is desirable to make some improvements there too.; Sadly SpMv is as bandwidth bound as it gets, 1 FMA per 8 bytes, nonetheless I implemented some number-of-variable-specific kernels (for nVar=4 and nVar=5) and I can get about **1.12** speedup (same realistic core to channel conditions). I am not going to dump that code here because it is not too nice to look at (it uses intrinsics) but again that would be something hidden away in CSysMatrix that most people would not need to look at, and there would be a safe generic fall-back for arbitrary number of variables. I think I will do the estimated global speedup together with the summary/proposal.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-539177957:4278,safe,safe,4278,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-539177957,1,['safe'],['safe']
Safety,"m_j = phiMax(jPoint,iVar);. const double eps = numeric_limits<double>::epsilon();. if(proj_i <= 0.0); {; lim_i = phiMin(iPoint,iVar);; proj_i = min(proj_i, -eps);; }. if(proj_j <= 0.0); {; lim_j = phiMin(jPoint,iVar);; proj_j = min(proj_j, -eps);; }. lim_i = (lim_i-phi(iPoint,iVar))/proj_i;; limiter(iPoint,iVar) = min(limiter(iPoint,iVar), lim_i);. lim_j = (lim_j-phi(jPoint,iVar))/proj_j;; limiter(jPoint,iVar) = min(limiter(jPoint,iVar), lim_j);; }; }. for(size_t iPoint=0; iPoint<nPoint; ++iPoint); {; for(size_t iVar=0; iVar<nVar; ++iVar); {; double lim = limiter(iPoint,iVar);; limiter(iPoint,iVar) = lim*(lim+2)/(lim*lim+lim+2);; }; }; }; ```; Something in the code above is a bit different from the implementation in SU2, namely:; ```C++; double lim_i = phiMax(iPoint,iVar);; if(proj_i <= 0.0) {; lim_i = phiMin(iPoint,iVar);; proj_i = min(proj_i, -eps);; }; ```; This is the bit of code that selects the right delta based on the sign of the projection and avoids division by zero, this less readable version does the same with one branch instead of three, simplifying ""if"" statements is essential for vectorization, so to make the comparison fair I used the same strategy in the scalar code. To make this post shorter I will show the SIMD and parallel version of the code right away. Trying to process multiple edges instead of multiple variables has all the problems I mentioned for the gradients, so again we use the trick of templating on the number of variables.; ```C++; template<size_t nVar>; void computeLimiters_impl(size_t nPoint,; size_t nDim,; const vector<size_t>& colorStart,; const vector<size_t>& edgeIdx,; const vector<pair<size_t,size_t> >& connectivity,; const Matrix& coords,; const Matrix& phi,; const VectorOfMatrix& grad,; Matrix& phiMax,; Matrix& phiMin,; Matrix& limiter); {; // initialize; #pragma omp parallel for schedule(dynamic,TARGET_CHUNK_SIZE); for(size_t iPoint=0; iPoint<nPoint; ++iPoint); {; #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); {; phiM",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-530593912:3008,avoid,avoids,3008,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530593912,1,['avoid'],['avoids']
Safety,"opt/xcat/sbin; PATH: /usr/lib64/qt-3.3/bin; PATH: /opt/pbs/default/bin; PATH: /opt/pbs/tools/bin; PATH: /usr/lpp/mmfs/bin/; PATH: /usr/local/bin; PATH: /bin; PATH: /usr/bin; PATH: /usr/local/sbin; PATH: /usr/sbin; PATH: /sbin; PATH: /gshare/soft/init; PATH: /gshare/soft/scripts; PATH: .; PATH: /gshare/soft/init; PATH: /gshare/soft/scripts; PATH: . ## ----------- ##; ## Core tests. ##; ## ----------- ##. configure:2465: checking build system type; configure:2479: result: x86_64-unknown-linux-gnu; configure:2499: checking host system type; configure:2512: result: x86_64-unknown-linux-gnu; configure:2532: checking target system type; configure:2545: result: x86_64-unknown-linux-gnu; configure:2587: checking for a BSD-compatible install; configure:2655: result: /usr/bin/install -c; configure:2666: checking whether build environment is sane; configure:2721: result: yes; configure:2872: checking for a thread-safe mkdir -p; configure:2911: result: /bin/mkdir -p; configure:2918: checking for gawk; configure:2934: found /bin/gawk; configure:2945: result: gawk; configure:2956: checking whether make sets $(MAKE); configure:2978: result: yes; configure:3075: checking whether make supports nested variables; configure:3092: result: yes; configure:3117: checking for style of include used by make; configure:3145: result: GNU; configure:3196: result: >>> MPI support disabled by default <<<; configure:3269: checking for g++; configure:3285: found /usr/bin/g++; configure:3296: result: g++; configure:3323: checking for C++ compiler version; configure:3332: g++ --version >&5; g++ (GCC) 4.4.6 20120305 (Red Hat 4.4.6-4); Copyright (C) 2010 Free Software Foundation, Inc.; This is free software; see the source for copying conditions. There is NO; warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. configure:3343: $? = 0; configure:3332: g++ -v >&5; Using built-in specs.; Target: x86_64-redhat-linux; Configured with: ../configure --prefix=/usr --mandir=/usr/share/man ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:2100,safe,safe,2100,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,1,['safe'],['safe']
Safety,"some validation cases and written tutorials and; having this in main repository will ease the process of adding/modifying; the docs to a simple pull request. I also have a suggestion regarding the Test Cases and Tutorial files. I; apologize if this is the wrong place or this has been discussed already,; but still will give it a try:; - Test cases folder from SU2/su2code repository shall be moved to the; SU2/TestCases repository. Rationale: this makes one repository to store the; test case *.cfg files and mesh files.; - There shall be a TestCases/Mesh folder to store all the meshes needed for; Test Cases files, without subdivisions for RANS, Euler etc subfolders.; Considering that multiple test cases use the same mesh and all the mesh; files are distinct, this solution generates one place to store all the mesh; files. Should a user perform a test case, he/she will find the mesh by name; referenced in the *.cfg file instead searching thru multiple folders. This; will also help avoiding unnecessary copies of mesh files.; - The same should be done for Tutorial files: Tutorial/Mesh folder for; storing meshes (duplicating these few files from TestCases/Mesh should not; be a problem IMO, but will really help a new user to get up to speed with; SU2); - I have no clear opinion on where the Tutorial files folder should be; stored. But considering moving written tutorials to main repository i think; that tutorial files should also be stored in main SU2/su2code repository. Best regards and Happy New Year; Jędrzej. 2017-12-30 23:45 GMT+01:00 Tim Albring <notifications@github.com>:. > What do you think of moving the written tutorials also to the main; > repository ? Then we can have links in the wiki to the markdown files like; > this (the link will be much shorter if the files are in the master branch):; > https://github.com/su2code/SU2/blob/0e36facc031aaf6b411fd30a0aab80; > 29ebe325d8/Tutorials/Inviscid_Bump/Inviscid_Bump.md; >; > —; > You are receiving this because you are sub",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/485#issuecomment-354736415:1306,avoid,avoiding,1306,https://su2code.github.io,https://github.com/su2code/SU2/pull/485#issuecomment-354736415,1,['avoid'],['avoiding']
Safety,"t the initialization routines of CSysMatrix and CSysVector are only called by the master thread.; For the second issue I made the associated classes as const-correct as possible, that should at least make someone think twice before changing a member variable of those classes. The risk is still there for input variables as an algorithm development aspect... For example `MatrixVectorProductTransposed` cannot be made thread-parallel as simply/naively as its normal counterpart. ### Communication Model; The MPI + Threads communication model is very simple, currently only the master thread calls MPI routines (including `Error`), this requires thread barriers before and after the communication to make sure the correct values are passed and _seen_ by all threads.; We can test other alternatives in the future but at the moment this does not seem to be a significant bottleneck.; _Worksharing_ constructs have implicit barriers at completion, for CSysVector routines I used `nowait` modifiers, it is safe to call those routines in sequence since the loop sizes, and static work scheduling specifications are identical.; However, routines that access a CSysVector in a different way, should have an explicit barrier before using the vector (or risk having undefined behaviour). You will see these barriers on entry to matrix-vector product, and every `ComputeXXXPreconditioner` (if you don't, let me know xD). I think those routines are large enough to amortise the cost of this. ### Performance; Disclaimer:; - We are talking about linear solvers only, **you will not see a global improvement yet**.; - The large global improvements from ""hybridization"" will come from the multigrid behaving better on less decomposed domains, and from the ability to independently tune the number of cores used in the linear preconditioners. For now the objective is ""just"" not to loose performance while gaining flexibility.; - The performance of MPI+threads with 1 thread per rank will be worse than just MPI (no",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/830#issuecomment-562646766:2162,safe,safe,2162,https://su2code.github.io,https://github.com/su2code/SU2/pull/830#issuecomment-562646766,1,['safe'],['safe']
Safety,"tColIterator(jPoint);. for(size_t iVar=0; iVar<nVar; ++iVar); {; FltVec phiL = 0.0;; FltVec phiR = 0.0;. for(size_t iDim=0; iDim<nDim; ++iDim); {; phiL += (gradI++)*d_ij[iDim];; phiR -= (gradJ++)*d_ij[iDim];; }; ...; ```; to get better assembly; ```asm; .L7:; vmovapd ymm3, ymm13; vmovapd ymm2, YMMWORD PTR [rbp-400]; add rax, 32; vgatherqpd ymm0, QWORD PTR [rcx+ymm1*8], ymm3; vpaddq ymm1, ymm1, ymm11; vmovapd YMMWORD PTR [rbp-272], ymm0; vmovapd YMMWORD PTR [rbp-240], ymm0; vfmadd132pd ymm0, ymm2, YMMWORD PTR [rax-32]; vmovdqa YMMWORD PTR [rbp-208], ymm1; vmovapd YMMWORD PTR [rbp-400], ymm0; cmp rax, rbx; jne .L7; ```; which makes the vectorized code perform just as well as the scalar code, iterators could also be used for the other variables but that would start to hurt readability without improving the performance much. _Note: There is also a chance the compiler (gcc) is not doing this kind of optimization because of the way I wrote the code..._. **So we need AoS to avoid losing performance in lightweight numerics classes.**. Before we look into the impact of not using SoA in the gradient and limiters routines let me tell you there is a way to have the best of both worlds, enter the *_array of structures of arrays_* or as I like to call it zig zag storage, aka a right mess.; Imagine an AoS of short arrays of SIMD length, e.g. `{ {u0 u1 u2 u3} {v0 ... v3} {w0 ... w3} {u4 u5 u6 u7} ... }` with that it is possible to fully vectorize point loops as the first index (iPoint) is contiguous in groups of SIMD length and when looping along variables and dimensions in edge loops the stride is small enough (equal to SIMD length) to trigger hardware prefetching.; The catch is that we need even more integer arithmetic and so we really need iterators to amortise that cost, there is also the drawback that scalar usage of such a container would be terrible. **For these reasons I think we should sacrifice ultimate performance and keep node data in AoS storage.**. The major impact on",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-535977206:12656,avoid,avoid,12656,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206,1,['avoid'],['avoid']
Safety,"we care about SPMD?**; Reduce the communication overhead resulting from domain decomposition and improve load balancing, important for strong scaling.; Some algorithms are more efficient that way, e.g. the ADT (as mentioned by Edwin), the current MG also seems to work better on fewer partitions, and additive versions of preconditioners like the ILU or LU-SGS lose effectiveness with number of partitions.; Optimum hardware utilization, for routines that are bandwidth-bound it may be beneficial to use all threads available, while for compute-bound or ""algorithm-bound"" ones this may not be the case. **Relation with algorithms**; A typical edge loop reads from 2 locations and writes to 2 locations (gather / scatter access pattern, not to be confused with the instructions) processing multiple edges at the same time can therefore result in race conditions where multiple threads try to update the data of the same point.; There are 3 ways to address this:; - **Coloring**: Edges are colored (grouped) such that edges of the same color have no risk of race conditions, i.e. each endpoint is referenced only once per color (this definition gives you the basis of a greedy algorithm to color edges).; - **Scatter to gather transformations**: Edge quantities (e.g. fluxes) are computed and stored on one pass (i.e. we read from 2 locations and write to 1), on a second pass, over points, we reduce (e.g. sum) the edge quantities for each point, again a gather access pattern. It may also be possible to convert the entire algorithm to a loop over points instead of edges.; - **Atomic operations or locks**: Here when a thread wants to write to a memory location it either needs to do so atomically (this is essentially an operations that always goes through main memory and forces cache coherency) or it needs to acquire a *lock* for the point it is writing to, if it fails to acquire the *lock* (because another thread has it) it needs to wait. None of these is without drawbacks.; - **Coloring** r",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-529662724:4118,risk,risk,4118,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-529662724,1,['risk'],['risk']
Security," case, we would have something along the lines of: . a) NACA0012; i) 113 x 33; ii) 225 x 65 ; iii) 449 x 129; iv) ... This way we have a family of meshes and configuration files that are specifically built for the purpose of validating the code and comparing with other solvers. I might be useful to compress meshes that are larger than a certain size (say 10MB). We should also put a limit on the size of a single mesh that the repository can handle (say 50MB?). . Within the home directory, the README file should list all the cases in the repository, who the custodian of the test case is (person with meshes in case the meshes are too large), and which version it was last run on. . I thought about splitting it up into Verification cases and Validation cases, but I thought it would be more informative and intuitive to split up according to the physics of the simulations. My thinking might be limited because that's how I have seen the TestCases folder organized, so any other suggestions are welcome. I think it is imperative that this is accompanied with a section on the SU2 website that showcases just the results of the validation test cases (grid convergence studies, residual reductions etc) and links to the v&v repo appropriately. This way, if people are just inquisitive about SU2's performance, they can get a quick snapshot of the results, without the need to run the cases themselves. . I also wanted to broach the topic of convergence here. Would it be a good idea to standardize the termination criteria wherever possible? For example, in the NACA0012 case we can ensure that residuals are reduced by 8 orders of magnitude for all meshes. Or for the ONERAM6, we use Cauchy convergence and make sure the C_L is converged to 6 orders of magnitude. This would have to be flexible since the same level of convergence might not apply to all the cases in the repository. But for within a test case, I think it would be good to use the same convergence criteria for a family of meshes.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/581#issuecomment-426026053:1757,validat,validation,1757,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-426026053,1,['validat'],['validation']
Security," make someone think twice before changing a member variable of those classes. The risk is still there for input variables as an algorithm development aspect... For example `MatrixVectorProductTransposed` cannot be made thread-parallel as simply/naively as its normal counterpart. ### Communication Model; The MPI + Threads communication model is very simple, currently only the master thread calls MPI routines (including `Error`), this requires thread barriers before and after the communication to make sure the correct values are passed and _seen_ by all threads.; We can test other alternatives in the future but at the moment this does not seem to be a significant bottleneck.; _Worksharing_ constructs have implicit barriers at completion, for CSysVector routines I used `nowait` modifiers, it is safe to call those routines in sequence since the loop sizes, and static work scheduling specifications are identical.; However, routines that access a CSysVector in a different way, should have an explicit barrier before using the vector (or risk having undefined behaviour). You will see these barriers on entry to matrix-vector product, and every `ComputeXXXPreconditioner` (if you don't, let me know xD). I think those routines are large enough to amortise the cost of this. ### Performance; Disclaimer:; - We are talking about linear solvers only, **you will not see a global improvement yet**.; - The large global improvements from ""hybridization"" will come from the multigrid behaving better on less decomposed domains, and from the ability to independently tune the number of cores used in the linear preconditioners. For now the objective is ""just"" not to loose performance while gaining flexibility.; - The performance of MPI+threads with 1 thread per rank will be worse than just MPI (no free lunches). With this [small case](https://github.com/su2code/SU2/files/3933059/small_case.zip) using 8 cores off a machine with two 2650v4 CPU, Intel MPI 2018 + GCC 8.2, the hybrid (2 ranks of 4",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/830#issuecomment-562646766:2305,access,access,2305,https://su2code.github.io,https://github.com/su2code/SU2/pull/830#issuecomment-562646766,1,['access'],['access']
Security," new way of going about CNumerics, these are my design requirements for ""CNewNumerics"":; - Thread-safe (consequently const-correct), a single object must be safe to use by multiple threads.; - Minimal indirection, the polymorphic overhead will be reduced to a single call (ComputeResidual), all auxiliary functions (like the ones that live in CNumerics) will be forcefully inlined, no useless copies of data (no more numerics->SetBlaBla).; - Compile time nDim/nVar, which will: a) avoid heap allocations; b) allow effective loop-unrolling (also during the writes to CSysMatrix).; - Allow low-overhead composition, e.g. have one CRoe for Euler and one CRoeVisc for NS to fuse convective and viscous residuals (without copy pasting code).; - A lot more readable, those cryptic V_i[iDim+1] need to go (somehow...). To achieve all this, the ""CNewNumerics"" will work as a template (obvs) decorator/visitor.; A visitor in the sense that the solver calls the numerics and gives it (read-only) access to all its data, the object pulls whatever it needs directly and there is no need for numerics->SetBlaBla.; A template decorator in the sense that the class can be augmented simply by inheriting from another, along the lines of `class CRoeVisc : public CRoe, public CVisc` (to allow fusing residual and Jacobian contributions).; All this needs to be done with templates for the ""minimal indirection"" requirement. Which means for each numerical method we will have 4 explicit template instantiations (Euler2D, Euler3D, (RA)NS2D, (RA)NS3D) but in the end these are still polymorphic objects that will be instantiated by some factory function (i.e. it will look clean, especially because I will not port all methods in one go xD). The template machinery to support this is actually not too crazy:; ```c++; #include <array>; #include <cmath>. // An example type to use instead of the container that stores solution data for all vertices.; struct SolutionContainer; {; std::array<double,3> velocity;; std::array<",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-622941617:1295,access,access,1295,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-622941617,1,['access'],['access']
Security," where; > it makes sense (as described by Clark and in the Stack Exchange discussion); > I would advocate for using it moving forward. There may also be some; > issues that arise multiple times in existing code where a retroactive; > application of unit testing may also make sense. I am copying Pat Miller,; > formerly with DoE, who may have more experience on whether such unit; > testing approaches were useful/worth the investment in some major codes he; > worked on.; >; > Best,; >; > Juan; >; >; > On Jun 4, 2019, at 2:14 PM, Clark Pederson <notifications@github.com>; > wrote:; >; > I propose adding a unit-testing framework and unit-tests to SU2. After; > chatting with @economon <https://github.com/economon>, I've decided to; > move the discussion here to get additional input.; > What is unit testing?; >; > For those not familiar with unit testing, unit testing allows the testing; > of small bits of behavior, ideally using isolated bits of code. It is not; > intended to replace validation testing or formal verification tests.; > Instead, it serves a unique purpose. Consider the three following use cases:; >; > - You're developing a new feature, and you want to test it to see if; > it works. You could do a full simulation, but that takes a lot of time and; > computing power. You want to check if your new behavior behaves as you; > suspect before you throw a lot of resources at it.; > - You submit a PR and discover that one of the regression tests has; > failed. But...why? You know that something is broken, but its hard to track; > down what broke. You want more granular test coverage that can demonstrate; > what broke.; > - You are fixing a very small bug. You know that you should prove that; > your bug fix worked, but it doesn't seem logical to dedicate an entire; > validation case to one small bug fix. You want to write a small test for a; > small fix.; >; > In all of these cases, unit testing fills a unique role. Unit testing; > increases time spent in development",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499278427:2192,validat,validation,2192,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427,1,['validat'],['validation']
Security,"(I was not expecting this many comments so quickly, thanks guys!). First let me clarify the intent.; I do not propose replacing the routines that deal with CSysMatrix, or change its format, all that (Krylov solvers, sparse approximate factorizations, etc.) is relatively independent from what I have in mind.; Nevertheless being able to use PETSc or HYPRE would be interesting as it would give us access to AMG, and @talbring 's branch feature_template_linear_solver would make such an integration compatible with AD.; What I would like is to have a ""CMatrixDense"" class, to give concrete examples:; - For RBF interpolation the guy who worked on it before me implemented his own Cholesky and LU factorizations, matrix-matrix, matrix-vector routines, etc.; - @jayantmukho recently needed some eigenvector decomposition's for the uncertainty quantification feature.; - I imagine in some other places of the code similar routines were needed, for example small matrix inversion when computing gradients by weighted least squares (indeed what I need now is a QR decomposition). And, as an added bonus, I think some other areas of the code could be simplified / optimized by adopting a dense matrix format, for example:; - This snipped from the viscous numerics refactoring`for (iDim = 0; iDim < nDim; iDim++) {; TauElem[iDim] = 0.0;; for (jDim = 0; jDim < nDim; jDim++); TauElem[iDim] += tau[iDim][jDim]*UnitNormal[jDim];; }` would simply become `TauElem=tau*UnitNormal`; - Cumbersome allocations like `tau_jacobian_i = new su2double* [nDim];; for (iDim = 0; iDim < nDim; iDim++) {; tau_jacobian_i[iDim] = new su2double [nVar];; }` become `Matrix tau_jacobian_i(nDim,nVar);` and the cleanup is dealt with by the destructor of the object automatically. Now to answer some questions.; @juanjosealonso @erangit LAPACK and BLAS are indeed the standard, so much so that most (all?) newer libraries will call their routines behind the scenes.; However they considerably simplify the user interface by encapsulat",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/643#issuecomment-459653772:397,access,access,397,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459653772,1,['access'],['access']
Security,") arrays of jPoint's, arrays of iEdge's, and arrays of directions, and as we know either those are contiguous or we take a huge performance hit.; If all points had the same number of neighbors we could store the adjacency in LIL (list of lists) format, essentially a column-major matrix, but that is not true for hybrid meshes and so we would possibly waste a lot of memory.; The solution is to use a Block-CSR format (like in CSysMatrix) where the blocks are the vectors we want and instead of one row per point we have one row per SIMD group. But even within a SIMD-sized group points can have different number of neighbors...; The solution for that is padding, within each group the number of neighbors is rounded up, shorter rows are then padded with valid data, e.g. jPoint=iPoint, direction=0, and iEdge repeated. This concept of padding is important for something else, you may have noticed that the SIMD point-loops I showed make no provisions for values of nPoint that are not multiples of SIMDLEN, that is because the containers already took care of that by rounding up the number of columns, and so that seemingly out-of-bounds access is safe (ain't encapsulation great). Padding also aligns the start of each column, thus it is a generally good thing to have (on large dimensions) whether used or not. Here is a relative performance recap before we talk bout parallelization. | Code | Edge | Edge, SIMD on vars | Point | Point, SIMD on points |; | ---- | ---- | ---- | ---- | ---- |; | **Speed** | 1.0 | 2.2 | 0.83 | 1.35 |. **Parallel execution**. I will start at the end for this, all it takes to parallellize the points loops with OpenMP is to take this:; ```C++; for(size_t iPoint=0; iPoint<nPoint; iPoint+=SIMDLEN); ```; And add some pixie dust; ```C++; #pragma omp parallel for schedule(dynamic,128); for(size_t iPoint=0; iPoint<nPoint; iPoint+=SIMDLEN); ```; This means each thread gets chunks of 128 loop iterations (512 points) to work on, assigned in a dynamic way, the 4 core sp",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-530328194:11634,access,access,11634,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530328194,1,['access'],['access']
Security,"**SOLVED** see edit. Hello! I seem to remember that it used to be possible to get angle of attack in the history file? Is this still possible? I would like to be able to just pull the angle of attack out of the history file, along with the aero coeffs.; Context:; I have looked through the custom output document and the reference config file, and (perhaps I am secretly blind), but there does not seem to be a simple output group for it.; Reason I need it: performing analysis for fixed Cl, so angle of attack is useful information. At the moment I am getting probed data:; ```; CUSTOM_OUTPUTS='m_vel_x : Macro{VELOCITY_X};\; m_vel_y : Macro{VELOCITY_Y};\; vel_x1: Probe{$m_vel_x}[-15, -15];\; vel_y1: Probe{$m_vel_y}[-15, -15]'; ```; And just getting the tan(y/x) of the probed values for angle. This works well enough.; The other option I have is stripping the angle of attack out of the forced breakdown file, would prefer to not do, but can. EDIT:. **It can be pulled out of line 2 of flow.meta**",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/2138#issuecomment-1780159397:91,attack,attack,91,https://su2code.github.io,https://github.com/su2code/SU2/issues/2138#issuecomment-1780159397,4,['attack'],['attack']
Security,"; phiR = phi.getVec(jPoint,iVar) + limiter.getVec(jPoint,iVar)*phiR;. FltVec flux = (phiL+phiR)*0.5;. for(size_t k=0; k<SIMDLEN; ++k) {; residual(iPoint[k],iVar) += flux[k];; residual(jPoint[k],iVar) -= flux[k];; }; }; ```; Note that at the end of the loop we need to de-swizzle the flux to update the multiple indexes references by iPoint and jPoint, which are now short arrays of integers (this operation can be moved to the container, akin to `getVec` but I show it here for clarity). **With SoA (aka column major storage) this code is 1.5 times slower than the scalar version.**. The reason for that is poor locality (of the spacial variety), as we loop through the number of variables and dimensions we are accessing the data in strides of nPoint, as the contiguous index is the first one so that we can perform vector read/writes when computing gradients and limiters.; With the scalar version the data for each point is contiguous which means on the first access we get whatever extra data is on the same cache line for free and subsequent accesses will be hardware prefetched since the stride is small (1 in this case). We lose all this with SoA storage. If we go back to arrays of structures (AoS, aka row major storage, basically what we have in #753) performance is only 9% worse (the code is identical). Those 9% are mostly due to increased integer arithmetic in the accesses to the data, on each call to `getVec` we resolve 4/8 row/column pairs into 1D indexes, while this calculation is vectorized, it seems to be less optimizable by compilers, for example this; ```c++; for(size_t iDim=0; iDim<nDim; ++iDim); phiL += grad.getVec(iPoint,iVar,iDim)*d_ij[iDim];; ```; gets compiled into this monstrosity; ```asm; .L13:; vpmuludq ymm0, ymm4, ymm1; vmovq xmm15, rax; vmovapd ymm6, ymm11; mov rdx, rax; vpbroadcastq ymm15, xmm15; sal rdx, 5; add rax, 1; vpaddq ymm0, ymm0, ymm2; vpsllq ymm0, ymm0, 32; vpaddq ymm0, ymm5, ymm0; vmovdqa YMMWORD PTR [rbp-240], ymm0; vpaddq ymm0, ymm3, ymm0; vmo",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-535977206:8678,access,access,8678,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206,2,['access'],"['access', 'accesses']"
Security,"<nVar; ++iVar); {; FltVec phiL = 0.0;; FltVec phiR = 0.0;. for(size_t iDim=0; iDim<nDim; ++iDim); {; phiL += grad.getVec(iPoint,iVar,iDim)*d_ij[iDim];; phiR -= grad.getVec(jPoint,iVar,iDim)*d_ij[iDim];; }. phiL = phi.getVec(iPoint,iVar) + limiter.getVec(iPoint,iVar)*phiL;; phiR = phi.getVec(jPoint,iVar) + limiter.getVec(jPoint,iVar)*phiR;. FltVec flux = (phiL+phiR)*0.5;. for(size_t k=0; k<SIMDLEN; ++k) {; residual(iPoint[k],iVar) += flux[k];; residual(jPoint[k],iVar) -= flux[k];; }; }; ```; Note that at the end of the loop we need to de-swizzle the flux to update the multiple indexes references by iPoint and jPoint, which are now short arrays of integers (this operation can be moved to the container, akin to `getVec` but I show it here for clarity). **With SoA (aka column major storage) this code is 1.5 times slower than the scalar version.**. The reason for that is poor locality (of the spacial variety), as we loop through the number of variables and dimensions we are accessing the data in strides of nPoint, as the contiguous index is the first one so that we can perform vector read/writes when computing gradients and limiters.; With the scalar version the data for each point is contiguous which means on the first access we get whatever extra data is on the same cache line for free and subsequent accesses will be hardware prefetched since the stride is small (1 in this case). We lose all this with SoA storage. If we go back to arrays of structures (AoS, aka row major storage, basically what we have in #753) performance is only 9% worse (the code is identical). Those 9% are mostly due to increased integer arithmetic in the accesses to the data, on each call to `getVec` we resolve 4/8 row/column pairs into 1D indexes, while this calculation is vectorized, it seems to be less optimizable by compilers, for example this; ```c++; for(size_t iDim=0; iDim<nDim; ++iDim); phiL += grad.getVec(iPoint,iVar,iDim)*d_ij[iDim];; ```; gets compiled into this monstrosity; ```asm; .L13",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-535977206:8427,access,accessing,8427,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206,1,['access'],['accessing']
Security,"> > I find your work really interesting. I've been studying the internal flow field in compressors and have had good results using SU2's SA_EDDES for calculating the cantilevered stator with a tip clearance. If you need help with code verification, I'd be glad to assist.; > ; > Hi @Linnnnnn23, every help on the validation/verification is gladly accepted! Let me know if you need anything by my side.; Thank you for your response. Firstly, I would like to know what Verification and Validation (V&V) work has been conducted on the SST-based DDES (Delayed Detached Eddy Simulation) model to date. Secondly, we can provide a compressor cascade validation, with an inlet Mach number of 0.4, a Reynolds number of approximately 500,000, and a spanwise height of about 20% of the chord length, ensuring that the vortices resolved by DDES can develop in three dimensions. Thirdly, as I am a rookie to GitHub, I have not yet found out how to download your pull request code. For further communication, you can contact me via email at linnnnnn2308@gmail.com",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/2150#issuecomment-2072057976:313,validat,validation,313,https://su2code.github.io,https://github.com/su2code/SU2/pull/2150#issuecomment-2072057976,2,['validat'],['validation']
Security,"> I don't known how the process to find the alpha that gives you a given CL works, but could the derivative not be obtained from this process? i.e. you could avoid the FD step entirely. It is a simple proportional controller that will change the angle of attack after a number of iterations depending on the difference between the current CL and the target CL. . So if the the option `ITER_DCL_DALPHA = 0` then it will do exactly what you suggest. It calculates the derivative based on the last update. The only problem with that is, there is no guarantee that the simulation at the previous update was converged, so the derivative might be incorrect. . But you are correct, I could just do a really tiny update (order of delta AoA ~10^-6) at the end and calculate the finite difference using that value. Let me try that and see if the gradients it calculates are reasonable, or if the update is too small and it gets clouded by numerical errors.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/780#issuecomment-539606698:255,attack,attack,255,https://su2code.github.io,https://github.com/su2code/SU2/pull/780#issuecomment-539606698,1,['attack'],['attack']
Security,"> I find your work really interesting. I've been studying the internal flow field in compressors and have had good results using SU2's SA_EDDES for calculating the cantilevered stator with a tip clearance. If you need help with code verification, I'd be glad to assist. Hi @Linnnnnn23, every help on the validation/verification is gladly accepted! Let me know if you need anything by my side.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/2150#issuecomment-2071759773:304,validat,validation,304,https://su2code.github.io,https://github.com/su2code/SU2/pull/2150#issuecomment-2071759773,1,['validat'],['validation']
Security,"> Nice! By the way, did you use some scripts for going through all the files and returning 'bad' naming conventions?. No, now I am just going through it by hand probably some linters are available to at least detect them. Actually, I am a bit confused as it is not so clear in the guide. It looks like the beginning of the project was just abbreviated from the Google style guide and was not enforced. Enforcing function names in UpperCamelCase and leaving variable names to the developer seems reasonable. > Can you explain the snake/camel terminology? :). Let's say we have a variable we want to name as `number of nodes per mesh` there are 2 common choices as . ```cpp; number_of_nodes_per_mesh = 42;; numberOfNodesPerMesh = 42;; ```; The first case is called the [snake case](https://en.wikipedia.org/wiki/Snake_case) and the second one is the [camel case ](https://en.wikipedia.org/wiki/Camel_case). Snake case is generally used in Python as [PEP8](https://peps.python.org/pep-0008/) suggests. . > Please revert the python accessor changes. I merged develop many of them vanished, should I revert the remaining ones?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1981#issuecomment-1482062542:1028,access,accessor,1028,https://su2code.github.io,https://github.com/su2code/SU2/pull/1981#issuecomment-1482062542,1,['access'],['accessor']
Security,"> The ""int"" in ""intIndexBased"" is for internal then? Because its type is also int, easy mistake to make xD. Yes.. The name was the first one I gave that routine. It somehow made it through.. Now that I had to type it several times I'd love to have it changed. But anyway.. I'm a bit puzzled that it seems to be so easy but maybe it's just as simple as you said - new approach inside `CDiscAdjSolver` and old in `CDiscAdjFEASolver` (if I got that correctly?). That would come in handy for all further developments. Let's wait for the validation. I'll also do one with this branch for the CHT adjoints tomorrow, just to be sure.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/803#issuecomment-542360883:533,validat,validation,533,https://su2code.github.io,https://github.com/su2code/SU2/pull/803#issuecomment-542360883,1,['validat'],['validation']
Security,"> the off-PR comments can be integrated in this PR to clear that up a bit. If not that is OK as well. It's more than OK, the CHT implementation suffers a bit from being a single person's project.. you're very welcome to have a look over it! :-). > Can you add that option to the config_template.cfg together with that description, the valid inputs and the default. Actually I'm hesitating a bit adding it to the config template right now. I'd prefer to have `DIRECT_TEMPERATURE_ROBIN_HEATFLUX` as the default and ""hide"" the rest as developer's options for the moment.; The reason simply is that those different methods need to checked and validated against each other before we make them public.; E.g. I figured that for the incompressible CHT test case from the repo, there is a severe gap between the heatfluxes obtained from the ""averaged"" approach and the direct one, see below. ![heatflux_convergence](https://user-images.githubusercontent.com/22639394/72885197-bb9e4a80-3d07-11ea-9fad-a4d709dc511e.png). That needs to be cleared up first...",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/839#issuecomment-577108935:639,validat,validated,639,https://su2code.github.io,https://github.com/su2code/SU2/pull/839#issuecomment-577108935,1,['validat'],['validated']
Security,"@economon I was envisioning something similar to the TestCases folder. With v&v cases grouped according to what they are testing. Something along the lines of: . 1) Inviscid Simulations: ; a) 2D Inviscid bump; b) 2D oblique shocks interaction; c) ...; 2) RANS simulations: ; a) Flatplate; b) NACA0012; c) ...; 3) Unsteady simulations:; a) Square Cylinder; b) ...; 4) Turbomachinary: ; a) ... And so on. Each of the directories would have sub-directories for different mesh sizes, with configuration files for each mesh level that have optimized parameters for best results. So for example if we are talking about the NACA0012 case, we would have something along the lines of: . a) NACA0012; i) 113 x 33; ii) 225 x 65 ; iii) 449 x 129; iv) ... This way we have a family of meshes and configuration files that are specifically built for the purpose of validating the code and comparing with other solvers. I might be useful to compress meshes that are larger than a certain size (say 10MB). We should also put a limit on the size of a single mesh that the repository can handle (say 50MB?). . Within the home directory, the README file should list all the cases in the repository, who the custodian of the test case is (person with meshes in case the meshes are too large), and which version it was last run on. . I thought about splitting it up into Verification cases and Validation cases, but I thought it would be more informative and intuitive to split up according to the physics of the simulations. My thinking might be limited because that's how I have seen the TestCases folder organized, so any other suggestions are welcome. I think it is imperative that this is accompanied with a section on the SU2 website that showcases just the results of the validation test cases (grid convergence studies, residual reductions etc) and links to the v&v repo appropriately. This way, if people are just inquisitive about SU2's performance, they can get a quick snapshot of the results, without the need ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/581#issuecomment-426026053:850,validat,validating,850,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-426026053,1,['validat'],['validating']
Security,"@koodlyakshay I was looking at the ADT modifications that you mention.; Do I understand correctly that the roughness height does not influence the wall distance calculation itself? But that you simply need to know what is the roughness height associated with the closest wall point? If this is the case you can probably just use the markerId returned by the wall distance function?; As for mpi aspects, each rank sees the same ADT and I recall that we do have mechanisms to access global marker information.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/877#issuecomment-595197305:474,access,access,474,https://su2code.github.io,https://github.com/su2code/SU2/pull/877#issuecomment-595197305,1,['access'],['access']
Security,"@rsanfer I'm using a test case from Ref [1], which doesn't exactly match the test case matching the figure I gave from Ref [2]. In Ref [1], they ran a whole ensemble of tests at various resolutions, corrections, and inflow/initial conditions. Some of the tests involved laminar separation, while others involved turbulent separation. I did not pick one of the Re = 50,000 cases because those cases involve laminar separation. Travin *et. al.* used a special nonuniform initial condition to promote laminar separation, which I viewed as overly complicated for the purposes of these tests. Instead, I picked a turbulent separation case at Re = 1.4 x 10^5 (roughly matching TS1 from Ref [1]). If you want more details/grids/cfg files, I can certainly provide them. Yes, I used the unsteady compressible solver. But I'm unsure if the circular cylinder case provides a good test case for the unsteady incompressible solver. I did very little with this test case in terms of a proper validation. The references I listed went to great lengths to ensure that the numerical results were consistent with experiments. It seems like a challenging test case. There were a lot of improvements I should have made if I were also trying to get consistent results. For example, my spanwise length was too short, and I didn't look into the impact of the rotation correction for the SA model. I skipped these improvements in the interest of time, since I wasn't aiming for validation, but rather a simple acceptance test.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/552#issuecomment-403850762:978,validat,validation,978,https://su2code.github.io,https://github.com/su2code/SU2/pull/552#issuecomment-403850762,2,['validat'],['validation']
Security,"@talbring Yes, I do. I can't uninstall it since it breaks other packages. @pcarruscag Yeah same for me. You can see it here:; ```; slimshady@arch-linux-hp-probook-g3-450: ~$ mpicc -v; mpicc for MPICH version 3.3.2; Using built-in specs.; COLLECT_GCC=gcc; COLLECT_LTO_WRAPPER=/usr/lib/gcc/x86_64-pc-linux-gnu/9.2.1/lto-wrapper; Target: x86_64-pc-linux-gnu; Configured with: /build/gcc/src/gcc/configure --prefix=/usr --libdir=/usr/lib --libexecdir=/usr/lib --mandir=/usr/share/man --infodir=/usr/share/info --with-pkgversion='Arch Linux 9.2.1+20200130-2' --with-bugurl=https://bugs.archlinux.org/ --enable-languages=c,c++,ada,fortran,go,lto,objc,obj-c++,d --enable-shared --enable-threads=posix --with-system-zlib --with-isl --enable-__cxa_atexit --disable-libunwind-exceptions --enable-clocale=gnu --disable-libstdcxx-pch --disable-libssp --enable-gnu-unique-object --enable-linker-build-id --enable-lto --enable-plugin --enable-install-libiberty --with-linker-hash-style=gnu --enable-gnu-indirect-function --enable-multilib --disable-werror --enable-checking=release --enable-default-pie --enable-default-ssp --enable-cet=auto gdc_include_dir=/usr/include/dlang/gdc; Thread model: posix; gcc version 9.2.1 20200130 (Arch Linux 9.2.1+20200130-2) ; ```; I did what you suggested and here is how my meson.build file looks.; ```; # If custom mpi mode is enabled, include and library pathes for MPI have to be set manually to env variables; if get_option('custom-mpi'); mpi_dep = []; mpi = true; # Otherwise they are automatically determined; else; mpi_dep = [dependency('mpich', required : get_option('with-mpi'))]; # mpi_dep = [dependency('mpi', language:'c', required : get_option('with-mpi')),; # dependency('mpi', language:'cpp', required : get_option('with-mpi'))]; #if mpi_dep[0].found() or mpi_dep[1].found(); # mpi = true; #endif; endif; ```; My SU2 build was successful but there were a couple of warnings.; Also, instead of 870 there were only 772 files in total. Is that okay?; ```; slimshady@",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1000#issuecomment-633139474:961,hash,hash-style,961,https://su2code.github.io,https://github.com/su2code/SU2/issues/1000#issuecomment-633139474,1,['hash'],['hash-style']
Security,"All,. I looked a bit more through Eigen and, indeed, the performance is pretty impressive and generally better than MKL and Atlas (the self-tuned implementation of LAPACK) ant most/all matrix sizes. I agree with comments made by @pcarruscg that having a standard for matrix operations throughout the source would clean up /simplify the code considerably and, since it does not seem to impact the AD approach, it should be pursued. It sounds like a quick test branch like @vdweide is suggesting makes sense. A quick driver code to test the performance of the Eigen routines vs MKL makes sense too. The only thing that @vdweide should comment on is how much work it would be to change the LAPACK/BLAS based implementation in the DG-FEM solver to the interface that Eigen exposes. Best,. Juan. On Feb 1, 2019, at 4:19 AM, Edwin van der Weide <notifications@github.com<mailto:notifications@github.com>> wrote:. Would it be an idea to create a branch to test things out and make a decision based on the results? It would be interesting to see the performance for e.g. the dense matrix multiplications in the DG-solver compared to Intel's MKL. —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/643#issuecomment-459705131>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADpSxM1gm0iy_FeGBMFzxVQnYFFzEHt4ks5vJDDlgaJpZM4adbAo>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/643#issuecomment-459845576:769,expose,exposes,769,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459845576,1,['expose'],['exposes']
Security,"As we mentioned in the dev meeting where you exposed the problem, the implementation is not good for strongly coupled flows, and I would guess that it is worse for diffusion than convection (because diffusion is elliptic).; I suspect the main problem is that the linear system does not contain information from the other side of the interface, meaning the solution of the two domains is effectively decoupled.; You could try running the case at much lower CFL (below 1) even with an explicit method.; It is also possible that the current treatment could be improved, since it is an example of multiplicative Schwartz decomposition, maybe there is an ""optimal"" way of implementing that from a physics point of view. Just speculating here, but maybe it would help treating the interface as an outlet if flow is going out, and as an inlet if flow is coming in.; On the numerics side, you can also try hacking the MZ driver to use something more stable than block-Gauss-Seidel (e.g. some quasi-Newton thing for the interface). But those are all band-aids IMO, if you want a robust fluid-fluid interface you need the coupling to be present in the linear system. The simplest way to do that is to have an internal boundary and treat the problem as single zone.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1414#issuecomment-951848509:45,expose,exposed,45,https://su2code.github.io,https://github.com/su2code/SU2/issues/1414#issuecomment-951848509,1,['expose'],['exposed']
Security,"Dear all, ; I have added a pdf file here that includes some test case results obtained with our BC transition model. These zero pressure gradient and variable pressure gradient flat plate test cases are very popular for model validation. I have also included Eppler E387 airfoil results. I would appreciate if you have any 3-D test case and share it with me.; Looking forward to hear your feedback. ; Sincerely,; Samet. [BC_model_TestCaseResults.pdf](https://github.com/su2code/SU2/files/562425/BC_model_TestCaseResults.pdf)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/326#issuecomment-257360833:226,validat,validation,226,https://su2code.github.io,https://github.com/su2code/SU2/pull/326#issuecomment-257360833,1,['validat'],['validation']
Security,"From the SU2 paper, talking about ""guiding principles"":. <img width=""574"" alt=""Screen Shot 2019-10-09 at 3 26 46 PM"" src=""https://user-images.githubusercontent.com/19416354/66525312-edb5d480-eaa9-11e9-9c0f-158b3941b407.png"">. I particularly like. > Full documentation, including a comprehensive set of tutorials. (""including"" implying that the tutorials are a subset of the documentation), and . > expose the full set of options [...] to the practitioner. This conflicts with our ""operating principle"", laid out on the tutorials page:. > Rather than writing a long manual on all available (and constantly evolving) configuration options available in SU2[...]. The Guide to V7 is a good start, but I think at the bare minimum (since I agree that full documentation would be a huge task, though one that's apparently promised on a paper we link on our homepage), we should provide more information about the existing options beyond forcing the user to scroll through config_template.cfg or dig through the tutorials.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/775#issuecomment-540239931:398,expose,expose,398,https://su2code.github.io,https://github.com/su2code/SU2/issues/775#issuecomment-540239931,1,['expose'],['expose']
Security,"Good Morning,. I'm from Chair of Thermal Engineering of Poznań University of Technology.; In August 2017 my colleague and I attended SU2 Summer School in; Kaiserslautern and met the Sci-Comp team developing the SU2. I think moving the main tutorials to the main repository is a good idea. We; declared to contribute some validation cases and written tutorials and; having this in main repository will ease the process of adding/modifying; the docs to a simple pull request. I also have a suggestion regarding the Test Cases and Tutorial files. I; apologize if this is the wrong place or this has been discussed already,; but still will give it a try:; - Test cases folder from SU2/su2code repository shall be moved to the; SU2/TestCases repository. Rationale: this makes one repository to store the; test case *.cfg files and mesh files.; - There shall be a TestCases/Mesh folder to store all the meshes needed for; Test Cases files, without subdivisions for RANS, Euler etc subfolders.; Considering that multiple test cases use the same mesh and all the mesh; files are distinct, this solution generates one place to store all the mesh; files. Should a user perform a test case, he/she will find the mesh by name; referenced in the *.cfg file instead searching thru multiple folders. This; will also help avoiding unnecessary copies of mesh files.; - The same should be done for Tutorial files: Tutorial/Mesh folder for; storing meshes (duplicating these few files from TestCases/Mesh should not; be a problem IMO, but will really help a new user to get up to speed with; SU2); - I have no clear opinion on where the Tutorial files folder should be; stored. But considering moving written tutorials to main repository i think; that tutorial files should also be stored in main SU2/su2code repository. Best regards and Happy New Year; Jędrzej. 2017-12-30 23:45 GMT+01:00 Tim Albring <notifications@github.com>:. > What do you think of moving the written tutorials also to the main; > repository ? Then",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/485#issuecomment-354736415:321,validat,validation,321,https://su2code.github.io,https://github.com/su2code/SU2/pull/485#issuecomment-354736415,1,['validat'],['validation']
Security,"Good point about making the eigen-functions static. That makes it a lot more accessible in other parts of the code. Will include that in the changes along with the option name changes. . I like the idea about the static allocation, but I foresee a problem that you actually mention. If I convert the variables to be statically defined, I would have to make the eigen-functions accept statically defined arrays. Since most arrays in SU2 are dynamically allocated, this would cause some compatibility issues. . In general, I see the value in making a math library associated with matrix operations. Maybe you could pitch the idea in an issue and get feedback on it?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/570#issuecomment-433963723:77,access,accessible,77,https://su2code.github.io,https://github.com/su2code/SU2/pull/570#issuecomment-433963723,1,['access'],['accessible']
Security,"Guys, we cannot simply change defaults like that, update regressions, and call it a day... Even fixing #1551 is a major change that should warrant a major version update. We want SU2 users to be able to rely and trust the code we release...; That is why I suggested that this PR should be used only to change the way of specifying SST options, and introduce simple ones like the V and KL modifications. Then the validation work for SST 2003 (with and w/o modification) would be done in #1557.; But ok, let me look at this and propose a way forward that gets in develop ASAP, **please don't start updating regressions**.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1560#issuecomment-1084549672:412,validat,validation,412,https://su2code.github.io,https://github.com/su2code/SU2/pull/1560#issuecomment-1084549672,1,['validat'],['validation']
Security,"Hey,. @cvencro and I were discussing this issue quite a bit this morning and here an attempt of a summary:. We are looking at the following cases:; 1. 3D Onera m6, compressible euler, including euler_wall and sym_plane ; a. steady state; b. unsteady (no pitching, deforming); 2. 2D NACA64A010, compressible euler, including euler_wall; a. unsteady (no pitching/ deformation); b. pitching (with rigid and with deforming mesh -> used for the gradient validation of @cvencro 's post ). We are rather certain that the differences between the code-versions are due to the new euler_wall boundary which was introduced in #740 (by me :) ). @cvencro did a test where the old euler_wall was simply pasted into the newer function body (which currently directly calls the sym_plane boundary) -> that recovered the results obtained with the 'older' version. The steady state results (onera m6) show that both codes deliver the same results (of course with some minor differences). So far so good. Unsteady cases are a bit trickier: the latest 2D results of @RoccoBombardieri show pretty much no difference including the first timesteps. The onera m6 case in contrast converges to the same (steady-state) results for both code version eventually but their initial transient phase differs quite significantly. . A possible explanation for the different initial transient phase: In both implementations a ""reflected state"" is constructed where the normal component of the velocity is subtracted [once in the older code version & twice in the newer version]. I.e. subtracting the normal component of velocity twice means mirroring the velocity along the symmetry plane. The newer code version is a bit ""stronger"" in enforcing the boundary conditions which could lead to the reduced oscillation in CD and CL. If we agree that both code versions produce physically correct results for steady cases and unsteady cases that were integrated long enough in time to get rid of the influence of the initial condition ... then",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/828#issuecomment-563314747:449,validat,validation,449,https://su2code.github.io,https://github.com/su2code/SU2/issues/828#issuecomment-563314747,1,['validat'],['validation']
Security,"Hi @cvencro , I think it would be good to add that Testcase to the regression tests to 'guard' the code. ; I actually wanted to do that real quick but it guess that with `SINGLEZONE_DRIVER` one cannot access `TIME_ITER`, only `EXT_ITER` with the` .test_iter` variable of the python Testcase class. Not sure if that is addressed in #724 , maybe @rsanfer or @talbring can give a quick info as this is probably affecting all unsteady regression tests. . Concerning the Testcase repo: You can simply open a PR for the develop branch of the Testcase repo, and refer to the corresponding PR here (and vice versa). As far as I know the Testcase repo is not protected, i.e. you can merge without any check. And as it is just one added mesh and no other change you could do it right now from my point of view. Another point: What about the rotating_frame for incompressible flow? If it is untested I would like an error catch in place that this feature can't be used out of the box.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/767#issuecomment-527167827:201,access,access,201,https://su2code.github.io,https://github.com/su2code/SU2/pull/767#issuecomment-527167827,1,['access'],['access']
Security,"Hi @rois1995. The LM model code under the development clearly has some problems. I've not finished yet all validation cases for commonly used. So, I can't help with the E387 profile problem. but, I think I can give some helpful comments. . Check the numerical scheme which you used. like Roe and L2Roe, AUSM and SLAU. In my case, I didn't think to use the low dissipation scheme because I thought the code was wrong. I upload the configure file for the T3A flat plate case, which I used.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1592#issuecomment-1111261534:107,validat,validation,107,https://su2code.github.io,https://github.com/su2code/SU2/pull/1592#issuecomment-1111261534,1,['validat'],['validation']
Security,"Hi Tim,. Thanks!. I totally agree on the fact that Python-related functionalities could be in a separate file for code clarity. Anyway, considering only the C++ structure, those functionalities are still members of the CDriver (and all child classes). So if you are OK with the fact that having members of the same C++ class in different cpp files, I am OK too. . However, if you mean creating a new class for the Python wrapper (like CPyWrapper or whatever), and leave the CDriver ""clean"", this might be more tricky. Indeed, since the wrapper has to be a top-level class, it is better to have access to all the other main classes (config, geometry, solver, ...) and the CDriver was the perfect candidate (it instanciates all of them). So now if we create a new top-level class next to the CDriver, the direct link with all those classes is lost. Basically we will have to create accessors like CDriver::GetConfig(), CDriver::GetGeometry(), ... that will return the different containers to be used by the wrapper. Obviously this is possible but not in a short time, besides this might be a significant change in the top-level code structure. We could also think about exposing thoses CConfig, CGeometry, ... classes to Python in addition to just the driver, I already made some local tests and it worked great but this approach is less user-friendly. David",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/488#issuecomment-352045091:594,access,access,594,https://su2code.github.io,https://github.com/su2code/SU2/pull/488#issuecomment-352045091,2,['access'],"['access', 'accessors']"
Security,"I don't think the fix is as simple as it seems.; Indeed looking back at how we developed the CGNS reader, It was originally meant to read multiple zone in a single file. But during development, someone decided to restrict the reader to only one zone per file (and I don't know if it was validated). So now we are seating in the middle. If we replace line 169 of CGNSFVMMeshReader :; <pre>; if ( nzones > 1 ) {; SU2_MPI::Error(string(""CGNS reader currently expects only 1 zone per CGNS file."") +; string(""Multizone problems can be run with separate CGNS files for each zone.""), CURRENT_FUNCTION);; }; </pre>; by; <pre>; if ( cgnsZone > nzones) {; cgnsZone = 1;; }; </pre>. we can easily support multiple zone in one file. To support one CGNS zone per file, I guess that user should provide either the index in the cgns file of the zone we want to read or even better its name and not rely on SU2 numbering of zones. I think that supporting multiple mesh zones in the same file at the same time as one zone per mesh file should be possible as long as enough information is provided by the user. In this case, I am wondering how the option MULTIZONE_MESH and MULTIZONE option are interacting in the related issue. When MULTIZONE_MESH is set to NO do we expect one mesh file per zone ?; And in this case we can force CGNS Reader to read only the first Zone. In a more generic way something like this should be possible:; MULTIZONE=YES; CONFIG_LIST= (zone_1.cfg, zone_2.cfg, zone_3.cfg); CGNSZONENAMES = (""FluidRotor"", ""Solid"", ""FluidStator"") # To let CGNS pick the right zone in the file and if it not found the first zone can be used (current SU2 behavior). CGNSZONENAMES could also be set in each config file.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1566#issuecomment-1073204565:287,validat,validated,287,https://su2code.github.io,https://github.com/su2code/SU2/pull/1566#issuecomment-1073204565,1,['validat'],['validated']
Security,"I think I implemented all the modifications you suggested. I am sorry you see all the commits in between, unfortunately due to Covid I work outside of office and I actually use Github to push the modified code to the office PC. I was actually working on a separate branch but, for reason that I do not understand, all the commits have been moved in the merging process... sorry about that. I am still learning git. In particular the modifications are:. - The functions related to static mesh deformation have been removed. I only included some new lines in the python wrapper ; that overwrite the initial velocities to zero and push back the solution.; - I now use the BC_Sym_Plane of the FEA solver for the deformation at the symmetry plane. I had to add a flag that avoids ; accessing LinSysReact in case of mesh deformation, as this is not initialised in that context.; - GetnMarker_Match_Deform_Mesh is not present anymore; - The marker has been renamed from MATCH_DEFORM_MESH to DEFORM_MESH_SYM_PLANE. All the functions have also ; been renamed accordingly; - I included the SU2 header in all the new files, changing the version number to 7.0.8. I did not modify the version number of ; the files that were already present in SU2 prior to this PR. I think the merging process should take care of that, am I wrong?; - The python functions that were separated in x,y,z component now give back an array and are merged into one function only; - The descriptions for the methods have been added; - The test case has been removed. I actually prepared a tutorial and all the appropriate files will be placed in the tutorial and ; website repos. I will now perform a PR for those repos so that you can see the material. Again thank you very much and sorry for the mess with the ""internal"" commits. . Please let me know if you think I missed something",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1124#issuecomment-742471972:777,access,accessing,777,https://su2code.github.io,https://github.com/su2code/SU2/pull/1124#issuecomment-742471972,1,['access'],['accessing']
Security,"I thought of doing an SST but was not long enough that it gave me error with divergence. I have been setting up my SST case as per the tutorial example of NACA0012. However, I do not happen to see any entry with regards to eddy frequency etc. (usually required by SST) in the config file. Any guidance will be great.; Thanks; Jehan; From: Heather Kline notifications@github.com; To: su2code/SU2 SU2@noreply.github.com ; Sent: Tuesday, May 12, 2015 11:43 AM; Subject: [SU2] Feature deallocation (#174). Bringing this branch up to date with current develop branch. ; Various deallocation changes; Some regression tests fail but all run. (previously was not the case); You can view, comment on, or merge this pull request online at:;   https://github.com/su2code/SU2/pull/174; Commit Summary; - Updated GetEngine_Properties; - Fix to the last commit; - Small bug; - Merge branch 'develop' into feature_MPI; - merging; - SU2_SOL and SU2_CFD are working; - Preliminary, but complete, implementation of SU2_DEF; - More updates; - Working version; - Complete implementation (validate); - Working version of SU2_DEF; - Final push before moving to the develop branch; - New MPI (removing SU2_PRT); - Merged in Ben's ParMETIS integration and fixed some conflicts.; - Merge branch 'benkirk-parmetis_integration' into feature_MPI; - ParMETIS geometry routines have been copied over but are not activated yet.; - Small change to ParMETIS include.; - ParMETIS can now be activated for testing (PARMETIS=YES in config).; - Updated MG; - Updated EA subrotuine; - Small fix; - Fixing memory leak; - Fixing memory leaks; - Dev release v.3.2.6; - Increasing MAX_NUMBER_MARKER; - Working version with ParMETIS. Fixed bug in global index. Now clean up and testing...; - Cleaned version of ParMETIS routines with better console output during partitioning.; - Small bug in initial element division.; - Made arrays in ParMETIS call dynamic.; - Fixed compiler warnings and added MPI directives so that the pure serial code wor",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:1396,validat,validate,1396,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['validat'],['validate']
Security,"I'll try to break down each request to make it clearer. Request: Use nomenclature consistent with the C++ interface (point instead of node, etc.); Reason: People who know the C++ interface will know how to use the python wrapper straight away, people who learn how to use the python wrapper will be able to understand the C++ implementation (without needing a translation layer in their mind all the time). Request: Return connectivity/adjacency as local indices instead of global; Reason: This is the natural way of referencing data in an MPI code, local indices correspond directly to data stored in the partition thereby making it more efficient to access (without global-to-local conversions, which are much more expensive than local-to-global). Furthermore, the local ordering strategy improves the efficiency of loops (over edges, neighboring points, etc.). Request: Do not apply unnecessary ""transformations"" to the connectivity/adjacency as part of the API; Reason: Increases the maintenance burden and makes for a less versatile API. By returning the local indices that form a marker or element, it is trivial to retrieve any other data for those indices (the ""transformation""). For example, the solution at those points, the point coordinates, whether the points are halo or domain points, the global indices, etc.; This way, by adding a **single** function to the API e.g. get the global index of a point of element, the functionality of the API grows a lot more because the user can apply the function to **any** connectivity/adjacency function. Request: Do not offer too many overloads of the same function; Reason: Increases the maintenance burden and it's returning the data in structures that are not very efficient, namely vector of vectors. It is much easier to offer domain-wide data access on the python side, as a very small function that can be part of wrapper utilities (i.e. live only in python but not c++). It may even be more efficient since you make a numpy array/matrix in",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1300#issuecomment-1402197827:652,access,access,652,https://su2code.github.io,https://github.com/su2code/SU2/pull/1300#issuecomment-1402197827,1,['access'],['access']
Security,"I'll weigh in with a more in depth answer on a second email, but yes I've; found great value in being able to have a good set of unit tests. Particularly when you don't have good acceptance tests (hard in a fast; moving research code), it gives a developer confidence that new changes; aren't being fundamental assumptions in the code. It lets sub module; developers build ""armor"" around those assumptions. It is a bit of a cultural thing. People who want robust bits write more.; Some people wire less. At the bank I once worked at, unit tests were required for every module.; Some people wrote code that tested almost nothing. And it would get; through code review that way. Eventually, I added coverage analysis to the check in that exposed this; practice that gave a false assurance that things were ok. More when I can think a bit more on this and get to a real keyboard!. Pat. On Wed, Jun 5, 2019 at 1:50 PM Juan Jose Alonso <jjalonso@stanford.edu>; wrote:. > Clark,; >; > Thanks for putting this idea out there. In my experience, unit testing; > has been an intrinsic part of the the modus operandi in many multi-physics; > codes at DoE and has been well worth the additional effort. In cases where; > it makes sense (as described by Clark and in the Stack Exchange discussion); > I would advocate for using it moving forward. There may also be some; > issues that arise multiple times in existing code where a retroactive; > application of unit testing may also make sense. I am copying Pat Miller,; > formerly with DoE, who may have more experience on whether such unit; > testing approaches were useful/worth the investment in some major codes he; > worked on.; >; > Best,; >; > Juan; >; >; > On Jun 4, 2019, at 2:14 PM, Clark Pederson <notifications@github.com>; > wrote:; >; > I propose adding a unit-testing framework and unit-tests to SU2. After; > chatting with @economon <https://github.com/economon>, I've decided to; > move the discussion here to get additional input.; > What is uni",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499278427:736,expose,exposed,736,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427,1,['expose'],['exposed']
Security,"If you look at the testing history, commit 4f5f3ed doesn't pass the regression tests, while commit 8551cac does. Only two tests are failing on 4f5f3ed: `discadj_topol_optim` and `discadj_fsi_airfoil`. The difference between the two commits is a simple change. I changed the `SU2_MPI::Error` routine to give a return status of `EXIT_FAILURE` instead of `0`. Since `0` is conventionally defined as a successful program exit, returning `EXIT_FAILURE` makes more sense than returning `0` when `SU2_MPI::Error` is called. So why did that change cause the regression tests to fail? My suspicion is that these two tests have been exiting with an error for some time, but these regressions were not picked up by Travis since SU2 kept on returning `0` (i.e. success). Changing the exit code of `SU2_MPI::Error` doesn't cause any errors, but it will expose errors that are (sometimes silently) occurring. @pcarruscag I think you added these tests. Any idea why they're failing?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/649#issuecomment-462951152:840,expose,expose,840,https://su2code.github.io,https://github.com/su2code/SU2/pull/649#issuecomment-462951152,1,['expose'],['expose']
Security,"Ok, SIMD update, with #753, #959, and #966 we now have a unified storage type for the data we need in CNumerics. This means that we (I) only need to implement ""SIMD accessor methods"" (i.e. that return a SIMD type instead of a su2double) for one class (C2DContainer and co.). I think to do SIMD right we need a new way of going about CNumerics, these are my design requirements for ""CNewNumerics"":; - Thread-safe (consequently const-correct), a single object must be safe to use by multiple threads.; - Minimal indirection, the polymorphic overhead will be reduced to a single call (ComputeResidual), all auxiliary functions (like the ones that live in CNumerics) will be forcefully inlined, no useless copies of data (no more numerics->SetBlaBla).; - Compile time nDim/nVar, which will: a) avoid heap allocations; b) allow effective loop-unrolling (also during the writes to CSysMatrix).; - Allow low-overhead composition, e.g. have one CRoe for Euler and one CRoeVisc for NS to fuse convective and viscous residuals (without copy pasting code).; - A lot more readable, those cryptic V_i[iDim+1] need to go (somehow...). To achieve all this, the ""CNewNumerics"" will work as a template (obvs) decorator/visitor.; A visitor in the sense that the solver calls the numerics and gives it (read-only) access to all its data, the object pulls whatever it needs directly and there is no need for numerics->SetBlaBla.; A template decorator in the sense that the class can be augmented simply by inheriting from another, along the lines of `class CRoeVisc : public CRoe, public CVisc` (to allow fusing residual and Jacobian contributions).; All this needs to be done with templates for the ""minimal indirection"" requirement. Which means for each numerical method we will have 4 explicit template instantiations (Euler2D, Euler3D, (RA)NS2D, (RA)NS3D) but in the end these are still polymorphic objects that will be instantiated by some factory function (i.e. it will look clean, especially because I will not por",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-622941617:165,access,accessor,165,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-622941617,1,['access'],['accessor']
Security,"R [rsi+rdx]; vfmadd213pd ymm0, ymm15, YMMWORD PTR [rbp-336]; vmovapd YMMWORD PTR [rbp-336], ymm0; cmp rbx, rax; jne .L13; ```; the meat of which is `vgatherqpd` (`getVec`) and `vfmadd213pd` fused-multiply-add to update `phiL`, everything else is integer arithmetic which in the scalar version gets factored out of the inner loop so that the resulting assembly looks much simpler:; ```asm; .L15:; vmovsd xmm5, QWORD PTR [rsp-40+rax*8]; vfmadd231sd xmm0, xmm5, QWORD PTR [r15+rax*8]; add rax, 1; cmp rcx, rax; jne .L15; ```; I think the reason for this is that there are plenty of integer registers (64bit) to keep memory locations (rsp, rax, r15 in the above) but there are only 16 ymm registers (256bit). In any case we need to give the compiler a hand, the calculation we need is; `index = iPoint*nVar*nDim + iVar*nDim + iDim` where iPoint is an array of ints; Note that as we loop by nDim and then by nVar all we need is to compute `iPoint*nVar*nDim` outside the loops and then add 1 on each access (which is more or less what the compiler does for the scalar code), in other words we need an **iterator**, something silly like; ```c++; template<size_t VecLen, size_t Incr = VecLen>; class GatherIterator; {; private:; using IntVec = Array<size_t,VecLen>;; using FltVec = Array<double,VecLen>;. IntVec offsets_;; const double* data_;; public:; GatherIterator() = delete;; GatherIterator(const double* data, IntVec offsets) : offsets_(offsets), data_(data) {}. STRONGINLINE FltVec operator()() const { return FltVec(data_,offsets_); }. STRONGINLINE FltVec operator++(int) {; auto ret = (*this)(); offsets_ += Incr; return ret;; }; };; ```; so silly in fact, it only moves forward, we use it in our loop like so; ```c++; ...; auto gradI = grad.getColIterator(iPoint);; auto gradJ = grad.getColIterator(jPoint);. for(size_t iVar=0; iVar<nVar; ++iVar); {; FltVec phiL = 0.0;; FltVec phiR = 0.0;. for(size_t iDim=0; iDim<nDim; ++iDim); {; phiL += (gradI++)*d_ij[iDim];; phiR -= (gradJ++)*d_ij[iDim];; };",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-535977206:10879,access,access,10879,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206,1,['access'],['access']
Security,"TRONGINLINE void SparseMatrix::updateBlocks(size_t edge,; size_t row, size_t col, const double* blk_i, const double* blk_j); {; size_t bii = diagMap[row], bij = edgeMap[edge].first,; bjj = diagMap[col], bji = edgeMap[edge].second;. #pragma omp simd; for(size_t k=0; k<blkSz; ++k); {; coeffs[bii+k] += blk_i[k]; coeffs[bij+k] = +blk_j[k];; coeffs[bji+k] = -blk_i[k]; coeffs[bjj+k] -= blk_j[k];; }; }; ```; This is **47% faster**, which for a memory bound task is massive!; Yes, this does increase the memory footprint a bit (makes CSysMatrix 4% larger for a 3D problem) but I can get that back by sharing sparsity patterns and maps across turbulence and bulk flow (I think @talbring was already working on this in the template linear solver branch he had started). We could also parallelize the matrix updates without colouring by setting only the off-diagonal coefficients and then setting the diagonal entries to the column sum.; It turns out that this is worse (by about 10%), maybe if the matrix were symmetric (row sum) but a column sum accesses blocks very far apart. Also we want to interleave compute and load/stores as much as possible to allow the CPU pipelining magic to mask the latency of the latter (even if it looks like you can only write the block after it is computed, CPU's have all kinds of buffers that allow the next loop iteration to begin while data is in flight). **Therefore colouring is the way to go.**. _Note: With vectorized numerics we insert blocks for 4 or 8 edges into the matrix at a time, the data for those inserts will be in a slightly weird format, which will make `SparseMatrix::updateBlocks` a bit harder on the eye, more on that later._. ## MUSCL Reconstruction; The MUSCL reconstruction, characteristic of upwind schemes, is the simplest building block to show the (negative) implications of storing the data as structures of arrays (SoA) on the performance of some operations.; Here is the most basic numerics you can think of, reconstruct and average (the d",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-535977206:4950,access,accesses,4950,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206,1,['access'],['accesses']
Security,"Thank you @TobiKattmann for your feedback. The idea behind this new regression test config file is as follows:; We should have a test case that triggers the negative part of the SA model. Depending on the flow conditions, geometry and CFD parameters it might be triggered or not. With the previous config file, it was not. ; I think there is already a regression test in SU2 that triggers the negative SA, the `turb_oneram6_nk`. However, I decided to stick to rae2822 airfoil as it is a simpler (faster) case. In order to force the negative part of the SA for the rae2822 in a reasonable amount of iterations for a regression test, I increased the angle of attack. I have removed the multigrid as it might not be stable, but I have not tested though. Anyway, with the current configuration, e.g., convective scheme, CFL number, etc, the solution is not stable and diverges after some iterations, around 15. In that sense, I reduced the number of iterations from 20 to 10. In my opinion, a diverging regression test is not a problem at all as it might not be used as a tutorial, only to verify the integrity of the commit. ""The solution should always diverge to the same results"". If the regression test should converge, let me know and I will update the config file :)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1559#issuecomment-1067926363:657,attack,attack,657,https://su2code.github.io,https://github.com/su2code/SU2/pull/1559#issuecomment-1067926363,2,"['attack', 'integrity']","['attack', 'integrity']"
Security,"The motivation of having it as the default was to make the code as user-friendly as possible (fewer knobs exposed in the config), but options are good of course. I would propose then that we add an option for the reconstruction gradient, something like:; ```; NUM_METHOD_GRAD_RECON= LEAST_SQUARES; ```; to let users decide if they want a separate option for the reconstruction gradients. If it does not appear, then the default is to use the same method as defined by NUM_METHOD_GRAD without a second gradient computation (basically what we have now). The nice thing about that is we can even try out other combos such as WLS+GG for the two different gradients. I will throw an error if users try to use LSQ for the viscous/source gradients, to avoid accuracy issues. What do you think?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/790#issuecomment-533259202:106,expose,exposed,106,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-533259202,1,['expose'],['exposed']
Security,"The solver with the closest functionality to what you are trying to do is the elasticity solver, it may be worth having a look there. But in a nutshell there the variables we want to differentiate are held by (members of) the discrete adjoint solver, they are reset before being registered as inputs to clear the derivative information, and it is important that they are left alone during the recording phase.; You will see that the adjoint iteration class for this solver then needs to update the numerics classes (in SetDependencies), at least for the source term the SA coefficients are set in the constructor of the corresponding numerics so maybe this step is missing?; The key point is that whenever a coefficient is used you need to be able to trace its value back to the original variable you registered.; Also the derivatives should be extracted in the same order they were registered, and you cannot access them multiple times by calling ""GetDerivative"" on them repeatedly (not 100% sure if this restriction still exists after the update of CoDi).; If none of this makes sense point me to branch you are working on.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/679#issuecomment-491910935:910,access,access,910,https://su2code.github.io,https://github.com/su2code/SU2/issues/679#issuecomment-491910935,1,['access'],['access']
Security,"This bug pops up because the periodic mesh reconstruction (in `SU2_MSH`) doesn't always create a valid mesh in 3D. Some points disappear, and some points are duplicated. When `SU2_CFD` (specifically, `CPhysicalGeometry`) tries to get the number of points in the domain, it calculates the wrong number because some of those points are duplicated. That leads to segfaults, because the output routine thinks the extra (missing) points belong to another processor. I've got a little toy problem with a simple periodic cube. It's easy to see on the simple 4x4x4 (+ periodic) problem that 3 nodes disappear, and 3 nodes are duplicated. I've never observed this problem in any of the 2D test cases I ran. As to why `SU2_MSH` is missing some points and duplicating others, I'm not sure. I tried running Valgrind to check for uninitialized variables or illegal memory access, but nothing there. I'll have to look more into the problem. The `su2_periodic.f90` script mentioned in #416 seems to be a workaround. I don't run into any problems when I use that script.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/431#issuecomment-337056131:859,access,access,859,https://su2code.github.io,https://github.com/su2code/SU2/issues/431#issuecomment-337056131,1,['access'],['access']
Security,"Todo list:; - [x] Make sure the code can handle arbitrary many species equtions. Especially the output has to be adapted. Note the MAXNVAR of the ScalarSolver has to adapted to that need as well. Make a suitable Testcase for that.; - [x] Implement weak inlet and outlet BC. The weak approach is used in the turb and mean flow and is most likely conservative opposed to the strong one. Here a simple switch will be put in place to compare both versions.; - [x] Consolidate nVar, nSpecies, ... variable to only use 1 consistently (The choice was `nSpecies` which was already introduced for NEMO and it just makes sense to use the same container); - [x] Make the numerous reviewers happy; - [x] Check inlet profiles for Species solver (have a testcase for that) See #1427 ; - [x] Create Objective functions of Surface avg quantities (Area and Massflow? prob. And a variance-style output to capture mixing); - [x] Avoid redundant operations (pre/post processings) during solver restarts. 156d0c5. What will be done in follow-up PR's:; - Viscous contributions for BC_inlet and outlet which are currently not used (also then for Turb-solver) https://github.com/su2code/SU2/pull/1388#discussion_r752384956; - Axissymmetric source term addtion and testing; - multi-component mixing from #1332 ; - gradient validation between DA and FD",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1388#issuecomment-935901996:1298,validat,validation,1298,https://su2code.github.io,https://github.com/su2code/SU2/pull/1388#issuecomment-935901996,1,['validat'],['validation']
Security,"True. I was thinking more from the user point-of-view, to be sure people little little experience can use SU2 easier. Similar to something Tim has already started in the Docs page. The idea here is just to be sure new features are easily usable/accessible for people unfamiliar.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/799#issuecomment-541832531:245,access,accessible,245,https://su2code.github.io,https://github.com/su2code/SU2/pull/799#issuecomment-541832531,1,['access'],['accessible']
Security,"Unfortunately, I wasn't able to get all of them. I fixed a majority of the calls but couldn't find workarounds all of them. There are 8 left in the following files: . `SU2_PY/change_version_number.py`: There's 2 in here. One is a complicated command with `grep` and pipes and the other is a simple `rm -rf`, but it isn't a security risk since there is no user input into that string. `SU2_PY/SU2/util/pyCppTap.py`: This is in the diff_routine and uses `tapenade`. I have no idea what this does so I didn't touch this one. `SU2/opt/server.py`: There are 4 `scp` calls that I didn't know how to replace. `SU2_PY/compute_polar.py`: There's one left in here which is a complicated `cat` call that I couldn't figure a workaround for. . If you have any suggestions for any of these, I can try and implement them. . Otherwise, once these tests pass, its good to merge.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/781#issuecomment-533590086:323,secur,security,323,https://su2code.github.io,https://github.com/su2code/SU2/pull/781#issuecomment-533590086,1,['secur'],['security']
Security,"_t iPoint=0; iPoint<nPoint; ++iPoint); {; for(size_t iVar=0; iVar<nVar; ++iVar); for(size_t iDim=0; iDim<nDim; ++iDim); grad(iPoint,iVar,iDim) = 0.0;. for(size_t iNeigh=0; iNeigh<adj.nNeighbor(iPoint); ++iNeigh); {; size_t jPoint = adj.jPoint(iPoint,iNeigh);; size_t iEdge = adj.iEdge(iPoint,iNeigh);; double dir = adj.dir(iPoint,iNeigh);. for(size_t iVar=0; iVar<nVar; ++iVar); {; double phi_ave = 0.5*(phi(iPoint,iVar)+phi(jPoint,iVar));. for(size_t iDim=0; iDim<nDim; ++iDim); grad(iPoint,iVar,iDim) += phi_ave*dir*area(iEdge,iDim);; }; }. for(size_t iVar=0; iVar<nVar; ++iVar); for(size_t iDim=0; iDim<nDim; ++iDim); grad(iPoint,iVar,iDim) /= volume[iPoint];; }; }; ```; The `Adjacency` class stores for each point: the surrounding neighbor points (this is available in SU2), the neighbor edges, and the direction (in or out, -1 or 1) of the area vector relative to the point.; The speedup is **0.83** (i.e. not a speedup), that is actually not that bad considering the same computation is repeated for each edge, the reason it is not that bad is the sequential access to the gradient. Note that this loop is one #pragma away from parallelization. The SIMD version of this code is:; ```C++; void computeGradients(size_t nPoint,; size_t nVar,; size_t nDim,; const Adjacency<4>& adj,; const Matrix& area,; const Vector& volume,; const Matrix& phi,; VectorOfMatrix& grad); {; const size_t SIMDLEN = 4;. for(size_t iPoint=0; iPoint<nPoint; iPoint+=SIMDLEN); {; for(size_t iVar=0; iVar<nVar; ++iVar); for(size_t iDim=0; iDim<nDim; ++iDim); grad.setVec(iPoint,iVar,iDim,Array<double,SIMDLEN>(0.0));. for(size_t iNeigh=0; iNeigh<adj.nNeighbor_vec(iPoint); ++iNeigh); {; auto jPoint = adj.jPoint_vec(iPoint,iNeigh);; auto iEdge = adj.iEdge_vec(iPoint,iNeigh);; auto dir = adj.dir_vec(iPoint,iNeigh);. for(size_t iVar=0; iVar<nVar; ++iVar); {; auto phi_ave = (phi.getVec(iPoint,iVar)+; phi.getVec(jPoint,iVar))*0.5;. for(size_t iDim=0; iDim<nDim; ++iDim); grad.addVec(iPoint,iVar,iDim,; phi_ave*dir*area.g",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-530328194:5023,access,access,5023,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530328194,1,['access'],['access']
Security,"cally equivalent) introduced to limiters and gradients in #834, yes. > What's the advantage of having one numerics term per thread?. It is a requirement, we need to write data into numerics before using them, multiple threads cannot write to the same location (i.e. the internal structures of CNumerics) therefore one per thread is required. > ...Also, I think I missed the point where the numerics container is extended beyond MAX_TERMS. The allocation of space for one numerics per thread is done above in line 1995 of my 21 Dec 2019 comment: `...MAX_TERMS*omp_get_max_threads()...`.; The instantiation of one numerics per thread is then done by executing the rest of the preprocessing in parallel and instead of using `XYZ_TERM` using `XYZ_TERM+offset` where `offset = thread_id * MAX_TERMS`.; I think someone mentioned this (maybe Tim) that we could revisit the ownership relations of the numerics classes, i.e. allocate them as members of their respective solvers, which if we do, we can think of having a purpose built container that automates the per-thread creation and access. > Why are they redefined each time inside the loop?; > Is this for efficiency reasons?. Referring to variables being declared inside loops. One stylist reason is that declaring everything at the top of a function is the C way of doing things, the C++ people whose books/blogs I've read and talks I've watched, recommend keeping namespaces (the inside of the loop being one) as clean as possible.; The only reason not to do this is if you explicitly want re-use, in the case of trivial types this does not improve efficiency, and in the context of OpenMP code it can create issues. Just like we need one numerics per thread, if we declare variables outside a parallel loop the default OpenMP behaviour is to consider them shared, and concurrent writes to shared locations = gdb and many bad words xD.; **EDIT:** I should mention here that if the parallel region is started before the variable declarations they beco",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/843#issuecomment-577684728:2224,access,access,2224,https://su2code.github.io,https://github.com/su2code/SU2/pull/843#issuecomment-577684728,1,['access'],['access']
Security,"ch request to make it clearer. Request: Use nomenclature consistent with the C++ interface (point instead of node, etc.); Reason: People who know the C++ interface will know how to use the python wrapper straight away, people who learn how to use the python wrapper will be able to understand the C++ implementation (without needing a translation layer in their mind all the time). Request: Return connectivity/adjacency as local indices instead of global; Reason: This is the natural way of referencing data in an MPI code, local indices correspond directly to data stored in the partition thereby making it more efficient to access (without global-to-local conversions, which are much more expensive than local-to-global). Furthermore, the local ordering strategy improves the efficiency of loops (over edges, neighboring points, etc.). Request: Do not apply unnecessary ""transformations"" to the connectivity/adjacency as part of the API; Reason: Increases the maintenance burden and makes for a less versatile API. By returning the local indices that form a marker or element, it is trivial to retrieve any other data for those indices (the ""transformation""). For example, the solution at those points, the point coordinates, whether the points are halo or domain points, the global indices, etc.; This way, by adding a **single** function to the API e.g. get the global index of a point of element, the functionality of the API grows a lot more because the user can apply the function to **any** connectivity/adjacency function. Request: Do not offer too many overloads of the same function; Reason: Increases the maintenance burden and it's returning the data in structures that are not very efficient, namely vector of vectors. It is much easier to offer domain-wide data access on the python side, as a very small function that can be part of wrapper utilities (i.e. live only in python but not c++). It may even be more efficient since you make a numpy array/matrix instead of lists of lists.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1300#issuecomment-1402197827:1803,access,access,1803,https://su2code.github.io,https://github.com/su2code/SU2/pull/1300#issuecomment-1402197827,1,['access'],['access']
Security,"double** blk_j,; SparseMatrix& matrix); {; matrix.setZero();. for(size_t color=0; color<colorStart.size()-1; ++color); #pragma omp parallel for schedule(dynamic,CHUNK_SIZE); for(size_t k=colorStart[color]; k<colorStart[color+1]; ++k); {; size_t iEdge = edgeIdx[k];; size_t iPoint = connectivity[iEdge].first;; size_t jPoint = connectivity[iEdge].second;. matrix.addBlock(iPoint, iPoint, blk_i);; matrix.addBlock(iPoint, jPoint, blk_j);. matrix.subBlock(jPoint, jPoint, blk_j);; matrix.subBlock(jPoint, iPoint, blk_i);; }; }; ```; This and a few more memory reads is why we can't have nice things, i.e. massive speedups with vectorization. Believe it or not this loop sets ~75% of the maximum speed at which the residual edge loop can run (bandwidth bottleneck).; Don't be sad though, we can make a few things about it better:; - We can store the blocks we insert contiguously so the writes can be vectorized (this would be done using a container so that we still have `(i,j)` access syntax);; - On each insertion we have to first look for the block by traversing the `colInd` (column index) array, we can instead map the diagonal blocks to the corresponding points and the off-diagonal blocks to the edge (remember we insert ""by the edge"").; - We can fuse numerics (possibly using the [decorator](https://en.wikipedia.org/wiki/Decorator_pattern) pattern) so that we write to the matrix only once per iteration, which means we only need to clear the diagonal blocks and not the entire matrix because we can **set** the off-diagonals instead of **updating** them. Assuming these modification our dummy loop becomes; ```c++; void testLoop2(const vector<size_t>& colorStart,; const vector<size_t>& edgeIdx,; const vector<pair<size_t,size_t> >& connectivity,; const double* blk_i, const double* blk_j,; SparseMatrix& matrix); {; matrix.setDiagZero();. for(size_t color=0; color<colorStart.size()-1; ++color); #pragma omp parallel for schedule(dynamic,CHUNK_SIZE); for(size_t k=colorStart[color]; k<colorSta",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-535977206:2659,access,access,2659,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206,1,['access'],['access']
Security,"e could be simplified / optimized by adopting a dense matrix format, for example:; - This snipped from the viscous numerics refactoring`for (iDim = 0; iDim < nDim; iDim++) {; TauElem[iDim] = 0.0;; for (jDim = 0; jDim < nDim; jDim++); TauElem[iDim] += tau[iDim][jDim]*UnitNormal[jDim];; }` would simply become `TauElem=tau*UnitNormal`; - Cumbersome allocations like `tau_jacobian_i = new su2double* [nDim];; for (iDim = 0; iDim < nDim; iDim++) {; tau_jacobian_i[iDim] = new su2double [nVar];; }` become `Matrix tau_jacobian_i(nDim,nVar);` and the cleanup is dealt with by the destructor of the object automatically. Now to answer some questions.; @juanjosealonso @erangit LAPACK and BLAS are indeed the standard, so much so that most (all?) newer libraries will call their routines behind the scenes.; However they considerably simplify the user interface by encapsulating the aforementioned construction/destruction and by exposing natural ways of manipulating the matrices, e.g. access entire rows, columns, blocks, etc.; Another issue with using BLAS routines is that we then need to provide a portable version that can be differentiated with CoDi or to implement the exact differentiation (similar to what is done in the ""solve_b"" routines). @vdweide that is not an issue with Eigen because everything is templated and therefore compatible with any type or class that overloads the appropriate arithmetic operators.; I have used it for over 2 years and I can attest to its compatibility with AD tools (I've tried 3), and speed when linked with a BLAS library, their native implementations are also very good, peeking inside their code... you can tell they know what they are doing. P.S. I feel this post needs a disclaimer, I am not affiliated in any way to Eigen, my motivation is not to promote their work (but I obviously think they deserve it). I genuinely think adopting an algebra library (that is compatible with AD) would greatly simplify our work and further drop the entry barrier to new",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/643#issuecomment-459653772:2113,access,access,2113,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459653772,1,['access'],['access']
Security,"easier implementation experience. Certainly, this is not the only consideration but it should be taken into account. Currently, resulting from the significant contributions of the members of this developers group, SU2 implementation works like a charm. I think we should strive to conserve this feature, especially if we aim at attracting more users and developers into the community. (...). >@vdweide; >(...) @bmunguia and @EduardoMolina, what type of application did you have in mind for PETSc? The only thing I can think of is a full Newton solver. And no matter how much I like PETSc, @juanjosealonso and @erangit have a point here. Looks like I start to belong to the group of old conservatives as well.... >@economon ; >(...) If you really would like to give PETSc a shot, I recommend talking with @anilvar who had an interface for connecting it to SU2 in one of our branches. >@pcarruscag; >(...) being able to use PETSc or HYPRE would be interesting as it would give us access to AMG, and @talbring 's branch feature_template_linear_solver would make such an integration compatible with AD. (...). >@EduardoMolina; >(...) When Brian (@bmunguia ) and I mentioned PETSc, it was an idea to try a different Newton-Krylov (with preconditioner) library in order to improve the convergence of SU2.; Since the slow convergence of the SU2-FV is the main feedback that I received from other users from industry and academia, I think it worth try an external library and evaluate the performance. (...). >@pcarruscag ; >(...) That is something I am also interested in as for some of my structural cases the current linear solvers simply do not converge. (...). >@economon ; >I would add one practical comment for consideration: it is worth checking whether the main restriction we have is related to approximations in the Jacobian that limit the effective CFL we can use or whether the convergence of the linear solver itself is a problem (speed or complete lack of convergence). A quick test without re",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/648#issuecomment-460853218:2446,access,access,2446,https://su2code.github.io,https://github.com/su2code/SU2/issues/648#issuecomment-460853218,1,['access'],['access']
Security,"economon>, I've decided to move the discussion here to get additional input. What is unit testing?. For those not familiar with unit testing, unit testing allows the testing of small bits of behavior, ideally using isolated bits of code. It is not intended to replace validation testing or formal verification tests. Instead, it serves a unique purpose. Consider the three following use cases:. * You're developing a new feature, and you want to test it to see if it works. You could do a full simulation, but that takes a lot of time and computing power. You want to check if your new behavior behaves as you suspect before you throw a lot of resources at it.; * You submit a PR and discover that one of the regression tests has failed. But...why? You know that something is broken, but its hard to track down what broke. You want more granular test coverage that can demonstrate what broke.; * You are fixing a very small bug. You know that you should prove that your bug fix worked, but it doesn't seem logical to dedicate an entire validation case to one small bug fix. You want to write a small test for a small fix. In all of these cases, unit testing fills a unique role. Unit testing increases time spent in development, but decreases the amount of time spent in bug-fixing and maintaining. For more information, see this relevant Stack Exchange question.<https://scicomp.stackexchange.com/questions/206/is-it-worthwhile-to-write-unit-tests-for-scientific-research-codes>. What do I propose?. My research group at UT Austing has implemented a unit testing framework on our branch, which we're happy with. Some choices were arbitrary, and some choices were made based on our development environment. Those choices may be different for other groups. Here's what we have done:. The unit testing framework is compiled and run using autotools. For more information on autotool's setup, see their documentation<https://www.gnu.org/software/automake/manual/html_node/Tests.html>. Since autotools is t",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499250240:1947,validat,validation,1947,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240,1,['validat'],['validation']
Security,"here to get additional input.; > What is unit testing?; >; > For those not familiar with unit testing, unit testing allows the testing; > of small bits of behavior, ideally using isolated bits of code. It is not; > intended to replace validation testing or formal verification tests.; > Instead, it serves a unique purpose. Consider the three following use cases:; >; > - You're developing a new feature, and you want to test it to see if; > it works. You could do a full simulation, but that takes a lot of time and; > computing power. You want to check if your new behavior behaves as you; > suspect before you throw a lot of resources at it.; > - You submit a PR and discover that one of the regression tests has; > failed. But...why? You know that something is broken, but its hard to track; > down what broke. You want more granular test coverage that can demonstrate; > what broke.; > - You are fixing a very small bug. You know that you should prove that; > your bug fix worked, but it doesn't seem logical to dedicate an entire; > validation case to one small bug fix. You want to write a small test for a; > small fix.; >; > In all of these cases, unit testing fills a unique role. Unit testing; > increases time spent in development, but decreases the amount of time spent; > in bug-fixing and maintaining.; >; > For more information, see this relevant Stack Exchange question.; > <https://scicomp.stackexchange.com/questions/206/is-it-worthwhile-to-write-unit-tests-for-scientific-research-codes>; > What do I propose?; >; > My research group at UT Austing has implemented a unit testing framework; > on our branch, which we're happy with. Some choices were arbitrary, and; > some choices were made based on our development environment. Those choices; > may be different for other groups. Here's what we have done:; >; > The unit testing framework is compiled and run using autotools. For more; > information on autotool's setup, see their documentation; > <https://www.gnu.org/software/aut",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499278427:2996,validat,validation,2996,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427,1,['validat'],['validation']
Security,"hort array of matrices, the result of that is code like the above that explicitly manipulates the lanes of our SIMD type, such code can be completely hidden inside CSysMatrix which is good because a 4x4 vectorized transpose and matrix update looks like this; ```c++; // block j, subs from jj and goes to ij; T0 = blk_j[ k ].unpackLo(blk_j[k+1]); T1 = blk_j[ k ].unpackHi(blk_j[k+1]);; T2 = blk_j[k+2].unpackLo(blk_j[k+3]); T3 = blk_j[k+2].unpackHi(blk_j[k+3]);. C0 = T0.widePermuteLo(T2); C1 = T1.widePermuteLo(T3);; C2 = T0.widePermuteHi(T2); C3 = T1.widePermuteHi(T3);. (Array4d(&bjj[0][k])-C0).store(&bjj[0][k]);; (Array4d(&bjj[1][k])-C1).store(&bjj[1][k]);; (Array4d(&bjj[2][k])-C2).store(&bjj[2][k]);; (Array4d(&bjj[3][k])-C3).store(&bjj[3][k]);. C0.store(&bij[0][k]); C1.store(&bij[1][k]);; C2.store(&bij[2][k]); C3.store(&bij[3][k]);; ```; I am showing this because it represents a readability worst case in terms of manipulating SIMD types, we might end up with one or two of these to get the best performance possible but they will always be encapsulated and deep in kernel-type areas of SU2 that are almost never touched. ## Conclusions; - Over 45% faster CSysMatrix updates by mapping off-diagonal blocks to edges and diagonal blocks to points.; - Colouring is the best strategy for hybrid parallelism of compute-heavy edge loops and matrix updates as it interleaves compute and memory operations.; - AoS storage should be kept to avoid significant loss of performance in compute-light edge loops due to poor locality of SoA storage.; - Major implication of AoS is on point loops where some data needs to be fetched (transposed) into local variables for effective vectorization.; - An intermediate storage scheme, AoSoA, can provide both good locality and vectorization of point loops, however it requires that data be accessed via special iterators and scalar code based on it would have poor performance. Next I will try to estimate how much we can gain for a ""realistic"" numerics class.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-535977206:17372,access,accessed,17372,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206,1,['access'],['accessed']
Security,"ike we need one numerics per thread, if we declare variables outside a parallel loop the default OpenMP behaviour is to consider them shared, and concurrent writes to shared locations = gdb and many bad words xD.; **EDIT:** I should mention here that if the parallel region is started before the variable declarations they become local and all is well, with the exception of class members, those will be shared most of the time (this is where const correctness can give some peace of mind). > Also, just an additional (hopefully constructive) comment: I find all of these developments great, and I honestly think that you are doing an amazing job on performance and overall code improvement. However, as a non-C++-master myself, I'm just a little concerned of whether some advanced programming may become an entrance barrier to new additions to the community. As I wrote in the preamble of #789:; ""But please participate even if you never heard of these topics, your opinion about readability and ""developability"" of the code is important! I think the code-style should be accessible to people starting a PhD (after they read a bit about C++...).""; I try to encapsulate and hide the tricky bits as much as possible to make the code as readable as possible, whether I am succeeding or not is for the community to decide, in all these PR's I've been pointing to the areas I think are trickier, if someone, anyone, feels they are absolutely incomprehensible please say something... either here, or trough slack, or by email (I think it shows in the commits) (I understand not everyone is keen on github exposure). > I'm aware that you have been doing very well at documenting the code and the various PRs, but I'd say we should try to find an strategy to ease the learning curve on potential new developers (maybe some developer tutorials? a collection of the comments/discussions on the PRs moved to the wiki? a list of links/useful resources?). I agree with documentation of broad design decisions, tha",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/843#issuecomment-577684728:3892,access,accessible,3892,https://su2code.github.io,https://github.com/su2code/SU2/pull/843#issuecomment-577684728,1,['access'],['accessible']
Security,"ive one will also not be zero, therefore it is correct to always evaluate both ratios.; This algorithm only needs min and max neighbors as small local variables instead of large global ones due to the way those values are determined. This is where the memory from the extra adjacency information is recovered. Like @economon said, fusing the gradient kernel with the limiter kernel is trivial with these point loops, and I do not think it affects readability much since one can clearly tell ""what is what"" (I will not put it here but it really is a matter of copy paste), including the boundaries could be a bit more challenging, but I will give performance number nevertheless. **Performance summary**. | Code | Edge | Edge, SIMD on vars | Point | Point, SIMD on points |; | ---- | ---- | ---- | ---- | ---- |; | **Speed 1 core** | 1.0 | 1.75 | 1.25 | 2.0 |; | **Speed 4 cores** | 2.45 | 2.7 | 4.5 | 7.0 |. The basic point version does not lose to edge based because, contrary to gradients, it does not require duplication of computations while benefiting from sequential access to gradients.; Again the point-based implementation does really well in parallel, limiters are more compute intensive and so the scaling is almost perfect.; For reference, limiters are 1.9 times more expensive to compute than gradients with the reference edge version. With point loops, SIMD, and in parallel, gradients and limiters cost the same. If we consider the combined cost of gradients and limiters, and compare the scalar ""edge+edge"" with the SIMD ""point+point"" and ""fused point"" we get:. | G+L Approach | Edge+Edge | Point+Point | Fused Point |; | ---- | ---- | ---- | ---- |; | **Speed 1 core** | 1.0 | 1.75 | 1.85 |; | **Speed 4 cores** | 2.3 | 5.35 | 6.1 |. Fusing point loops only gives a 14% improvement vs separate loops due to the difference in gathered data, only one gather is amortized and the remaining memory accesses are very efficient.; Nevertheless if it can be done nicely while accounting for ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-530593912:10609,access,access,10609,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530593912,1,['access'],['access']
Security,"nd max neighbors as small local variables instead of large global ones due to the way those values are determined. This is where the memory from the extra adjacency information is recovered. Like @economon said, fusing the gradient kernel with the limiter kernel is trivial with these point loops, and I do not think it affects readability much since one can clearly tell ""what is what"" (I will not put it here but it really is a matter of copy paste), including the boundaries could be a bit more challenging, but I will give performance number nevertheless. **Performance summary**. | Code | Edge | Edge, SIMD on vars | Point | Point, SIMD on points |; | ---- | ---- | ---- | ---- | ---- |; | **Speed 1 core** | 1.0 | 1.75 | 1.25 | 2.0 |; | **Speed 4 cores** | 2.45 | 2.7 | 4.5 | 7.0 |. The basic point version does not lose to edge based because, contrary to gradients, it does not require duplication of computations while benefiting from sequential access to gradients.; Again the point-based implementation does really well in parallel, limiters are more compute intensive and so the scaling is almost perfect.; For reference, limiters are 1.9 times more expensive to compute than gradients with the reference edge version. With point loops, SIMD, and in parallel, gradients and limiters cost the same. If we consider the combined cost of gradients and limiters, and compare the scalar ""edge+edge"" with the SIMD ""point+point"" and ""fused point"" we get:. | G+L Approach | Edge+Edge | Point+Point | Fused Point |; | ---- | ---- | ---- | ---- |; | **Speed 1 core** | 1.0 | 1.75 | 1.85 |; | **Speed 4 cores** | 2.3 | 5.35 | 6.1 |. Fusing point loops only gives a 14% improvement vs separate loops due to the difference in gathered data, only one gather is amortized and the remaining memory accesses are very efficient.; Nevertheless if it can be done nicely while accounting for boundaries (which may have to be handled outside the loop) it could allow some memory savings for the discrete adjoint.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-530593912:11447,access,accesses,11447,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530593912,1,['access'],['accesses']
Security,"r clarity). **With SoA (aka column major storage) this code is 1.5 times slower than the scalar version.**. The reason for that is poor locality (of the spacial variety), as we loop through the number of variables and dimensions we are accessing the data in strides of nPoint, as the contiguous index is the first one so that we can perform vector read/writes when computing gradients and limiters.; With the scalar version the data for each point is contiguous which means on the first access we get whatever extra data is on the same cache line for free and subsequent accesses will be hardware prefetched since the stride is small (1 in this case). We lose all this with SoA storage. If we go back to arrays of structures (AoS, aka row major storage, basically what we have in #753) performance is only 9% worse (the code is identical). Those 9% are mostly due to increased integer arithmetic in the accesses to the data, on each call to `getVec` we resolve 4/8 row/column pairs into 1D indexes, while this calculation is vectorized, it seems to be less optimizable by compilers, for example this; ```c++; for(size_t iDim=0; iDim<nDim; ++iDim); phiL += grad.getVec(iPoint,iVar,iDim)*d_ij[iDim];; ```; gets compiled into this monstrosity; ```asm; .L13:; vpmuludq ymm0, ymm4, ymm1; vmovq xmm15, rax; vmovapd ymm6, ymm11; mov rdx, rax; vpbroadcastq ymm15, xmm15; sal rdx, 5; add rax, 1; vpaddq ymm0, ymm0, ymm2; vpsllq ymm0, ymm0, 32; vpaddq ymm0, ymm5, ymm0; vmovdqa YMMWORD PTR [rbp-240], ymm0; vpaddq ymm0, ymm3, ymm0; vmovdqa YMMWORD PTR [rbp-208], ymm0; vpaddq ymm0, ymm15, ymm0; vmovdqa YMMWORD PTR [rbp-176], ymm0; vgatherqpd ymm15, QWORD PTR [rdi+ymm0*8], ymm6; vmovapd ymm0, YMMWORD PTR [rsi+rdx]; vfmadd213pd ymm0, ymm15, YMMWORD PTR [rbp-336]; vmovapd YMMWORD PTR [rbp-336], ymm0; cmp rbx, rax; jne .L13; ```; the meat of which is `vgatherqpd` (`getVec`) and `vfmadd213pd` fused-multiply-add to update `phiL`, everything else is integer arithmetic which in the scalar version gets factored",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-535977206:9094,access,accesses,9094,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206,1,['access'],['accesses']
Security,"r routines that are bandwidth-bound it may be beneficial to use all threads available, while for compute-bound or ""algorithm-bound"" ones this may not be the case. **Relation with algorithms**; A typical edge loop reads from 2 locations and writes to 2 locations (gather / scatter access pattern, not to be confused with the instructions) processing multiple edges at the same time can therefore result in race conditions where multiple threads try to update the data of the same point.; There are 3 ways to address this:; - **Coloring**: Edges are colored (grouped) such that edges of the same color have no risk of race conditions, i.e. each endpoint is referenced only once per color (this definition gives you the basis of a greedy algorithm to color edges).; - **Scatter to gather transformations**: Edge quantities (e.g. fluxes) are computed and stored on one pass (i.e. we read from 2 locations and write to 1), on a second pass, over points, we reduce (e.g. sum) the edge quantities for each point, again a gather access pattern. It may also be possible to convert the entire algorithm to a loop over points instead of edges.; - **Atomic operations or locks**: Here when a thread wants to write to a memory location it either needs to do so atomically (this is essentially an operations that always goes through main memory and forces cache coherency) or it needs to acquire a *lock* for the point it is writing to, if it fails to acquire the *lock* (because another thread has it) it needs to wait. None of these is without drawbacks.; - **Coloring** reduces temporal locality, edges are sorted in increasing order of the point indices to reduce cache misses, this means small groups of contiguous edges will share the same ""iPoint"", coloring single edges destroys this. Furthermore coloring either requires edges to be re-sorted by color, or if the edge indices of each color are instead kept in arrays, performance will suffer due to increased indirection which confounds the hardware pre-f",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-529662724:4531,access,access,4531,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-529662724,1,['access'],['access']
Security,"rth the additional effort. In cases where it makes sense (as described by Clark and in the Stack Exchange discussion) I would advocate for using it moving forward. There may also be some issues that arise multiple times in existing code where a retroactive application of unit testing may also make sense. I am copying Pat Miller, formerly with DoE, who may have more experience on whether such unit testing approaches were useful/worth the investment in some major codes he worked on. Best,. Juan. On Jun 4, 2019, at 2:14 PM, Clark Pederson <notifications@github.com<mailto:notifications@github.com>> wrote:. I propose adding a unit-testing framework and unit-tests to SU2. After chatting with @economon<https://github.com/economon>, I've decided to move the discussion here to get additional input. What is unit testing?. For those not familiar with unit testing, unit testing allows the testing of small bits of behavior, ideally using isolated bits of code. It is not intended to replace validation testing or formal verification tests. Instead, it serves a unique purpose. Consider the three following use cases:. * You're developing a new feature, and you want to test it to see if it works. You could do a full simulation, but that takes a lot of time and computing power. You want to check if your new behavior behaves as you suspect before you throw a lot of resources at it.; * You submit a PR and discover that one of the regression tests has failed. But...why? You know that something is broken, but its hard to track down what broke. You want more granular test coverage that can demonstrate what broke.; * You are fixing a very small bug. You know that you should prove that your bug fix worked, but it doesn't seem logical to dedicate an entire validation case to one small bug fix. You want to write a small test for a small fix. In all of these cases, unit testing fills a unique role. Unit testing increases time spent in development, but decreases the amount of time spent in bug-fi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499250240:1179,validat,validation,1179,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240,1,['validat'],['validation']
Security,"shell = false doesn't seem to work in this particular case (symbolic linking) but it might in others. There seem more secure ways to run commands but they need case by case treatment. As in the solution for a `cp` command is different from a `ln -s` command. . We can also replace the `os.system` calls with other python functions (for example `os.symlink` for symbolic linking). . Either way, it wont be a simple search and replace. There seem to be about 25 `os.system` calls across the python scripts. Let me try and replace them.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/781#issuecomment-533410018:118,secur,secure,118,https://su2code.github.io,https://github.com/su2code/SU2/pull/781#issuecomment-533410018,1,['secur'],['secure']
Security,"tter cannot be avoided. ### Intro to SPMD; This one is simpler, in a nutshell multiple threads operate on the sub domain of an MPI rank.; The typical implementation has each thread executing a chunk of an edge or cell loop. **Why should we care about SPMD?**; Reduce the communication overhead resulting from domain decomposition and improve load balancing, important for strong scaling.; Some algorithms are more efficient that way, e.g. the ADT (as mentioned by Edwin), the current MG also seems to work better on fewer partitions, and additive versions of preconditioners like the ILU or LU-SGS lose effectiveness with number of partitions.; Optimum hardware utilization, for routines that are bandwidth-bound it may be beneficial to use all threads available, while for compute-bound or ""algorithm-bound"" ones this may not be the case. **Relation with algorithms**; A typical edge loop reads from 2 locations and writes to 2 locations (gather / scatter access pattern, not to be confused with the instructions) processing multiple edges at the same time can therefore result in race conditions where multiple threads try to update the data of the same point.; There are 3 ways to address this:; - **Coloring**: Edges are colored (grouped) such that edges of the same color have no risk of race conditions, i.e. each endpoint is referenced only once per color (this definition gives you the basis of a greedy algorithm to color edges).; - **Scatter to gather transformations**: Edge quantities (e.g. fluxes) are computed and stored on one pass (i.e. we read from 2 locations and write to 1), on a second pass, over points, we reduce (e.g. sum) the edge quantities for each point, again a gather access pattern. It may also be possible to convert the entire algorithm to a loop over points instead of edges.; - **Atomic operations or locks**: Here when a thread wants to write to a memory location it either needs to do so atomically (this is essentially an operations that always goes through main ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-529662724:3790,access,access,3790,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-529662724,1,['access'],['access']
Testability," You want to check if your new behavior behaves as you; > suspect before you throw a lot of resources at it.; > - You submit a PR and discover that one of the regression tests has; > failed. But...why? You know that something is broken, but its hard to track; > down what broke. You want more granular test coverage that can demonstrate; > what broke.; > - You are fixing a very small bug. You know that you should prove that; > your bug fix worked, but it doesn't seem logical to dedicate an entire; > validation case to one small bug fix. You want to write a small test for a; > small fix.; >; > In all of these cases, unit testing fills a unique role. Unit testing; > increases time spent in development, but decreases the amount of time spent; > in bug-fixing and maintaining.; >; > For more information, see this relevant Stack Exchange question.; > <https://scicomp.stackexchange.com/questions/206/is-it-worthwhile-to-write-unit-tests-for-scientific-research-codes>; > What do I propose?; >; > My research group at UT Austing has implemented a unit testing framework; > on our branch, which we're happy with. Some choices were arbitrary, and; > some choices were made based on our development environment. Those choices; > may be different for other groups. Here's what we have done:; >; > The unit testing framework is compiled and run using autotools. For more; > information on autotool's setup, see their documentation; > <https://www.gnu.org/software/automake/manual/html_node/Tests.html>.; > Since autotools is the build system for SU2, this involves minimal changes.; >; > Using automake, the build process for building unit tests becomes:; >; > '''; > ./bootstrap; > ./configure; > make; > make check; > '''; >; > We use Boost's unit testing framework; > <https://www.boost.org/doc/libs/1_70_0/libs/test/doc/html/index.html>.; > This provides a convenient set of macros for instatiating tests, grouping; > tests into suites, and running checks. This choice was based on what is; > avail",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499278427:3428,test,tests-for-scientific-research-codes,3428,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427,2,['test'],"['testing', 'tests-for-scientific-research-codes']"
Testability," are first added to; > document the related existing behavior. These tests serve to check that the; > existing behavior isn't damaged by the new code. Then new tests are added; > to prove that the new behavior is working correctly. For bug fixes, the; > process is simpler. A test is added to confirm that something is not; > behaving as expected. Then the code is fixed to make the test pass.; > What frameworks are available?; >; > For a unit testing framework, here are the most popular options, with the; > following pros and cons:; > Roll-your-own; >; > - Requires no external dependencies; > - The most flexible option; > - Involves the most work to setup; > - Will lack some of the more advances features of mature unit-testing; > frameworks.; >; > Boost Test; >; > - Can be header only, statically linked, or dynamically linked; > - If statically or dynamically linked, then Boost is not very; > lightweight; > - Easy to add if you're already using Boost; >; > Google Test; >; > - Most common unit-testing framework; > - Can be easily combined with Google's powerful GMock mocking library; > - Compiling and linking can be somewhat painful; >; > Catch2; >; > - Used by FEniCS; > - Makes unit tests easily readable with lots of syntactic sugar.; > - Has a very simple syntax; > - Is header-only; > - Requires C++11 compilation; > - Not as feature rich as Google Test or Boost Test; >; > Questions; >; > - How do developers feel about adding unit tests to SU2?; > - If a unit-testing framework were added to SU2, would you actually; > use it?; > - Do developers have a preference (or experience with) any of the unit; > testing frameworks?; > - Should unit tests be expected when submitting PRs?; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/issues/698?email_source=notifications&email_token=AA5FFRG5U3Z55N4W2XWQED3PY3LJ5A5CNFSM4HTDQXQKYY3PNVWWK3TUL52HS4DFUVEXG43VMWVGG33NNVSW4",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499278427:6039,test,testing,6039,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427,3,"['mock', 'test']","['mocking', 'testing', 'tests']"
Testability," case, we would have something along the lines of: . a) NACA0012; i) 113 x 33; ii) 225 x 65 ; iii) 449 x 129; iv) ... This way we have a family of meshes and configuration files that are specifically built for the purpose of validating the code and comparing with other solvers. I might be useful to compress meshes that are larger than a certain size (say 10MB). We should also put a limit on the size of a single mesh that the repository can handle (say 50MB?). . Within the home directory, the README file should list all the cases in the repository, who the custodian of the test case is (person with meshes in case the meshes are too large), and which version it was last run on. . I thought about splitting it up into Verification cases and Validation cases, but I thought it would be more informative and intuitive to split up according to the physics of the simulations. My thinking might be limited because that's how I have seen the TestCases folder organized, so any other suggestions are welcome. I think it is imperative that this is accompanied with a section on the SU2 website that showcases just the results of the validation test cases (grid convergence studies, residual reductions etc) and links to the v&v repo appropriately. This way, if people are just inquisitive about SU2's performance, they can get a quick snapshot of the results, without the need to run the cases themselves. . I also wanted to broach the topic of convergence here. Would it be a good idea to standardize the termination criteria wherever possible? For example, in the NACA0012 case we can ensure that residuals are reduced by 8 orders of magnitude for all meshes. Or for the ONERAM6, we use Cauchy convergence and make sure the C_L is converged to 6 orders of magnitude. This would have to be flexible since the same level of convergence might not apply to all the cases in the repository. But for within a test case, I think it would be good to use the same convergence criteria for a family of meshes.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/581#issuecomment-426026053:1768,test,test,1768,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-426026053,2,['test'],['test']
Testability," choice was based on what is available in our development setup. We have integrated our unit tests into our Travis CI regression testing. Every time we push commits or submit a pull request, the unit tests are run and checked. What is my vision for unit testing in SU2?. I am not proposing that we start trying to get 100% code coverage with pre-existing code. That would not provide a good return on investment. Instead, I see people adding unit tests as they write new code and as they find bugs. For each new behavior added to SU2, tests are first added to document the related existing behavior. These tests serve to check that the existing behavior isn't damaged by the new code. Then new tests are added to prove that the new behavior is working correctly. For bug fixes, the process is simpler. A test is added to confirm that something is not behaving as expected. Then the code is fixed to make the test pass. What frameworks are available?. For a unit testing framework, here are the most popular options, with the following pros and cons:. Roll-your-own. * Requires no external dependencies; * The most flexible option; * Involves the most work to setup; * Will lack some of the more advances features of mature unit-testing frameworks. Boost Test. * Can be header only, statically linked, or dynamically linked; * If statically or dynamically linked, then Boost is not very lightweight; * Easy to add if you're already using Boost. Google Test. * Most common unit-testing framework; * Can be easily combined with Google's powerful GMock mocking library; * Compiling and linking can be somewhat painful. Catch2. * Used by FEniCS; * Makes unit tests easily readable with lots of syntactic sugar.; * Has a very simple syntax; * Is header-only; * Requires C++11 compilation; * Not as feature rich as Google Test or Boost Test. Questions. * How do developers feel about adding unit tests to SU2?; * If a unit-testing framework were added to SU2, would you actually use it?; * Do developers hav",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499250240:4277,test,testing,4277,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240,1,['test'],['testing']
Testability," commits or submit a pull request, the unit tests are run and checked. What is my vision for unit testing in SU2?. I am not proposing that we start trying to get 100% code coverage with pre-existing code. That would not provide a good return on investment. Instead, I see people adding unit tests as they write new code and as they find bugs. For each new behavior added to SU2, tests are first added to document the related existing behavior. These tests serve to check that the existing behavior isn't damaged by the new code. Then new tests are added to prove that the new behavior is working correctly. For bug fixes, the process is simpler. A test is added to confirm that something is not behaving as expected. Then the code is fixed to make the test pass. What frameworks are available?. For a unit testing framework, here are the most popular options, with the following pros and cons:. Roll-your-own. * Requires no external dependencies; * The most flexible option; * Involves the most work to setup; * Will lack some of the more advances features of mature unit-testing frameworks. Boost Test. * Can be header only, statically linked, or dynamically linked; * If statically or dynamically linked, then Boost is not very lightweight; * Easy to add if you're already using Boost. Google Test. * Most common unit-testing framework; * Can be easily combined with Google's powerful GMock mocking library; * Compiling and linking can be somewhat painful. Catch2. * Used by FEniCS; * Makes unit tests easily readable with lots of syntactic sugar.; * Has a very simple syntax; * Is header-only; * Requires C++11 compilation; * Not as feature rich as Google Test or Boost Test. Questions. * How do developers feel about adding unit tests to SU2?; * If a unit-testing framework were added to SU2, would you actually use it?; * Do developers have a preference (or experience with) any of the unit testing frameworks?; * Should unit tests be expected when submitting PRs?. —; You are receiving this bec",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499250240:4543,test,testing,4543,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240,1,['test'],['testing']
Testability," first added to document the related existing behavior. These tests serve to check that the existing behavior isn't damaged by the new code. Then new tests are added to prove that the new behavior is working correctly. For bug fixes, the process is simpler. A test is added to confirm that something is not behaving as expected. Then the code is fixed to make the test pass. What frameworks are available?. For a unit testing framework, here are the most popular options, with the following pros and cons:. Roll-your-own. * Requires no external dependencies; * The most flexible option; * Involves the most work to setup; * Will lack some of the more advances features of mature unit-testing frameworks. Boost Test. * Can be header only, statically linked, or dynamically linked; * If statically or dynamically linked, then Boost is not very lightweight; * Easy to add if you're already using Boost. Google Test. * Most common unit-testing framework; * Can be easily combined with Google's powerful GMock mocking library; * Compiling and linking can be somewhat painful. Catch2. * Used by FEniCS; * Makes unit tests easily readable with lots of syntactic sugar.; * Has a very simple syntax; * Is header-only; * Requires C++11 compilation; * Not as feature rich as Google Test or Boost Test. Questions. * How do developers feel about adding unit tests to SU2?; * If a unit-testing framework were added to SU2, would you actually use it?; * Do developers have a preference (or experience with) any of the unit testing frameworks?; * Should unit tests be expected when submitting PRs?. —; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/698?email_source=notifications&email_token=AA5FFRG5U3Z55N4W2XWQED3PY3LJ5A5CNFSM4HTDQXQKYY3PNVWWK3TUL52HS4DFUVEXG43VMWVGG33NNVSW45C7NFSM4GXUGGLA>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AA5FFRHOPE2MUJ2Z5RRV4HTPY3LJ5ANCNFSM4HTDQXQA>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499250240:4969,test,tests,4969,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240,5,['test'],"['testing', 'tests']"
Testability," of time spent; > in bug-fixing and maintaining.; >; > For more information, see this relevant Stack Exchange question.; > <https://scicomp.stackexchange.com/questions/206/is-it-worthwhile-to-write-unit-tests-for-scientific-research-codes>; > What do I propose?; >; > My research group at UT Austing has implemented a unit testing framework; > on our branch, which we're happy with. Some choices were arbitrary, and; > some choices were made based on our development environment. Those choices; > may be different for other groups. Here's what we have done:; >; > The unit testing framework is compiled and run using autotools. For more; > information on autotool's setup, see their documentation; > <https://www.gnu.org/software/automake/manual/html_node/Tests.html>.; > Since autotools is the build system for SU2, this involves minimal changes.; >; > Using automake, the build process for building unit tests becomes:; >; > '''; > ./bootstrap; > ./configure; > make; > make check; > '''; >; > We use Boost's unit testing framework; > <https://www.boost.org/doc/libs/1_70_0/libs/test/doc/html/index.html>.; > This provides a convenient set of macros for instatiating tests, grouping; > tests into suites, and running checks. This choice was based on what is; > available in our development setup.; >; > We have integrated our unit tests into our Travis CI regression testing.; > Every time we push commits or submit a pull request, the unit tests are run; > and checked.; > What is my vision for unit testing in SU2?; >; > I am *not* proposing that we start trying to get 100% code coverage with; > pre-existing code. That would not provide a good return on investment.; >; > Instead, I see people adding unit tests as they write new code and as they; > find bugs. For each new behavior added to SU2, tests are first added to; > document the related existing behavior. These tests serve to check that the; > existing behavior isn't damaged by the new code. Then new tests are added; > to prove that",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499278427:4241,test,testing,4241,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427,1,['test'],['testing']
Testability," or formal verification tests.; > Instead, it serves a unique purpose. Consider the three following use cases:; >; > - You're developing a new feature, and you want to test it to see if; > it works. You could do a full simulation, but that takes a lot of time and; > computing power. You want to check if your new behavior behaves as you; > suspect before you throw a lot of resources at it.; > - You submit a PR and discover that one of the regression tests has; > failed. But...why? You know that something is broken, but its hard to track; > down what broke. You want more granular test coverage that can demonstrate; > what broke.; > - You are fixing a very small bug. You know that you should prove that; > your bug fix worked, but it doesn't seem logical to dedicate an entire; > validation case to one small bug fix. You want to write a small test for a; > small fix.; >; > In all of these cases, unit testing fills a unique role. Unit testing; > increases time spent in development, but decreases the amount of time spent; > in bug-fixing and maintaining.; >; > For more information, see this relevant Stack Exchange question.; > <https://scicomp.stackexchange.com/questions/206/is-it-worthwhile-to-write-unit-tests-for-scientific-research-codes>; > What do I propose?; >; > My research group at UT Austing has implemented a unit testing framework; > on our branch, which we're happy with. Some choices were arbitrary, and; > some choices were made based on our development environment. Those choices; > may be different for other groups. Here's what we have done:; >; > The unit testing framework is compiled and run using autotools. For more; > information on autotool's setup, see their documentation; > <https://www.gnu.org/software/automake/manual/html_node/Tests.html>.; > Since autotools is the build system for SU2, this involves minimal changes.; >; > Using automake, the build process for building unit tests becomes:; >; > '''; > ./bootstrap; > ./configure; > make; > make check; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499278427:3153,test,testing,3153,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427,1,['test'],['testing']
Testability," the solution at the inlet corner is completely wrong, while the outlet is ok most likely because characteristics are outgoing as it is supersonic. The artifacts disappear if we disable MUSCL everywhere (1st order solution) or disable it only on boundaries (not ideal solution, but disabling only on corners would still be good enough for now I believe). Using ```WEIGHTED_LEAST_SQUARES``` seems to not present the same issue, in this test case at least, as the stencil ""does not care"" about the boundary states. The boundary conditions are:; - ```MARKER_SYMMETRY``` at centerline; - ```MARKER_EULER``` at wall; - ```MARKER_RIEMANN= (INLET, TOTAL_CONDITIONS_PT, 904388, 542.13, 1.0, 0.0, 0.0)``` at inlet; - ```MARKER_RIEMANN= (OUTLET, STATIC_PRESSURE, 200000.0, 0.0, 0.0, 0.0, 0.0)``` at outlet. I tried both with and without a slope limiter as there are no discontinuities, but it makes no difference on the artifacts:. ```; SLOPE_LIMITER_FLOW= VENKATAKRISHNAN_WANG; VENKAT_LIMITER_COEFF= 0.1; ```. # Complete test case ZIP; [mdm_coolprop_nozzle.zip](https://github.com/su2code/SU2/files/15403732/mdm_coolprop_nozzle.zip). # Inlet pressure zoom; ![Screenshot from 2024-05-22 15-06-36](https://github.com/su2code/SU2/assets/79575547/9ba71127-cb12-4c5f-8e49-3ea9e839b1f4). # Notation: ; - ""1st order"" no MUSCL; - ""2nd order"" MUSCL as implemented in SU2; - ""2nd order (BC 1st order)"" I simply disabled MUSCL on ALL physical boundaries in the upwind residual computations, see code snippet below. # Proof of concept code modification for ""2nd order (BC 1st order)"":; To show that the error lies in MUSCL/gradients at boundaries I added these two lines of code in the upwind gradient computation; ![image](https://github.com/su2code/SU2/assets/79575547/27f2a79b-824d-4a32-a626-73cd87750c0c). # Residuals:; ![image](https://github.com/su2code/SU2/assets/79575547/3f0800fe-478e-433d-8495-cd4964d0f8ee). # Mesh:; ![image](https://github.com/su2code/SU2/assets/79575547/0ebaf86b-fbf9-40b1-aeb9-8764a90a1440)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/2285#issuecomment-2124781449:1320,test,test,1320,https://su2code.github.io,https://github.com/su2code/SU2/issues/2285#issuecomment-2124781449,1,['test'],['test']
Testability," to SU2 in one of our branches. >@pcarruscag; >(...) being able to use PETSc or HYPRE would be interesting as it would give us access to AMG, and @talbring 's branch feature_template_linear_solver would make such an integration compatible with AD. (...). >@EduardoMolina; >(...) When Brian (@bmunguia ) and I mentioned PETSc, it was an idea to try a different Newton-Krylov (with preconditioner) library in order to improve the convergence of SU2.; Since the slow convergence of the SU2-FV is the main feedback that I received from other users from industry and academia, I think it worth try an external library and evaluate the performance. (...). >@pcarruscag ; >(...) That is something I am also interested in as for some of my structural cases the current linear solvers simply do not converge. (...). >@economon ; >I would add one practical comment for consideration: it is worth checking whether the main restriction we have is related to approximations in the Jacobian that limit the effective CFL we can use or whether the convergence of the linear solver itself is a problem (speed or complete lack of convergence). A quick test without resorting to another library is to increase the fill-in for ILU-preconditioned GMRES, which is very expensive/slow but should converge difficult problems, and to check how high we can take the CFL when allowing each nonlinear iteration to converge to a tight tolerance in the linear solver, say 1e-14 (you can output the linear solver residuals to verify convergence). If we can take the CFL higher with a more performant linear solver, then it could be worth the effort to try other options.; >If the CFL must remain low for stability, then perhaps we should look at the quality of the Jacobians we construct to see if we can improve, or even try exact Jacobians with AD if we can afford it. A more advanced CFL ramping strategy could also be helpful here to get us closer to a solution before trying to aggressively converge. I think that is everyone.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/648#issuecomment-460853218:3453,test,test,3453,https://su2code.github.io,https://github.com/su2code/SU2/issues/648#issuecomment-460853218,1,['test'],['test']
Testability," unit-testing framework and unit-tests to SU2. After; > chatting with @economon <https://github.com/economon>, I've decided to; > move the discussion here to get additional input.; > What is unit testing?; >; > For those not familiar with unit testing, unit testing allows the testing; > of small bits of behavior, ideally using isolated bits of code. It is not; > intended to replace validation testing or formal verification tests.; > Instead, it serves a unique purpose. Consider the three following use cases:; >; > - You're developing a new feature, and you want to test it to see if; > it works. You could do a full simulation, but that takes a lot of time and; > computing power. You want to check if your new behavior behaves as you; > suspect before you throw a lot of resources at it.; > - You submit a PR and discover that one of the regression tests has; > failed. But...why? You know that something is broken, but its hard to track; > down what broke. You want more granular test coverage that can demonstrate; > what broke.; > - You are fixing a very small bug. You know that you should prove that; > your bug fix worked, but it doesn't seem logical to dedicate an entire; > validation case to one small bug fix. You want to write a small test for a; > small fix.; >; > In all of these cases, unit testing fills a unique role. Unit testing; > increases time spent in development, but decreases the amount of time spent; > in bug-fixing and maintaining.; >; > For more information, see this relevant Stack Exchange question.; > <https://scicomp.stackexchange.com/questions/206/is-it-worthwhile-to-write-unit-tests-for-scientific-research-codes>; > What do I propose?; >; > My research group at UT Austing has implemented a unit testing framework; > on our branch, which we're happy with. Some choices were arbitrary, and; > some choices were made based on our development environment. Those choices; > may be different for other groups. Here's what we have done:; >; > The unit testing fr",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499278427:2795,test,test,2795,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427,1,['test'],['test']
Testability," use Boost's unit testing framework; > <https://www.boost.org/doc/libs/1_70_0/libs/test/doc/html/index.html>.; > This provides a convenient set of macros for instatiating tests, grouping; > tests into suites, and running checks. This choice was based on what is; > available in our development setup.; >; > We have integrated our unit tests into our Travis CI regression testing.; > Every time we push commits or submit a pull request, the unit tests are run; > and checked.; > What is my vision for unit testing in SU2?; >; > I am *not* proposing that we start trying to get 100% code coverage with; > pre-existing code. That would not provide a good return on investment.; >; > Instead, I see people adding unit tests as they write new code and as they; > find bugs. For each new behavior added to SU2, tests are first added to; > document the related existing behavior. These tests serve to check that the; > existing behavior isn't damaged by the new code. Then new tests are added; > to prove that the new behavior is working correctly. For bug fixes, the; > process is simpler. A test is added to confirm that something is not; > behaving as expected. Then the code is fixed to make the test pass.; > What frameworks are available?; >; > For a unit testing framework, here are the most popular options, with the; > following pros and cons:; > Roll-your-own; >; > - Requires no external dependencies; > - The most flexible option; > - Involves the most work to setup; > - Will lack some of the more advances features of mature unit-testing; > frameworks.; >; > Boost Test; >; > - Can be header only, statically linked, or dynamically linked; > - If statically or dynamically linked, then Boost is not very; > lightweight; > - Easy to add if you're already using Boost; >; > Google Test; >; > - Most common unit-testing framework; > - Can be easily combined with Google's powerful GMock mocking library; > - Compiling and linking can be somewhat painful; >; > Catch2; >; > - Used by FEniCS; > - Ma",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499278427:5193,test,tests,5193,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427,1,['test'],['tests']
Testability," want to test it to see if it works. You could do a full simulation, but that takes a lot of time and computing power. You want to check if your new behavior behaves as you suspect before you throw a lot of resources at it.; * You submit a PR and discover that one of the regression tests has failed. But...why? You know that something is broken, but its hard to track down what broke. You want more granular test coverage that can demonstrate what broke.; * You are fixing a very small bug. You know that you should prove that your bug fix worked, but it doesn't seem logical to dedicate an entire validation case to one small bug fix. You want to write a small test for a small fix. In all of these cases, unit testing fills a unique role. Unit testing increases time spent in development, but decreases the amount of time spent in bug-fixing and maintaining. For more information, see this relevant Stack Exchange question.<https://scicomp.stackexchange.com/questions/206/is-it-worthwhile-to-write-unit-tests-for-scientific-research-codes>. What do I propose?. My research group at UT Austing has implemented a unit testing framework on our branch, which we're happy with. Some choices were arbitrary, and some choices were made based on our development environment. Those choices may be different for other groups. Here's what we have done:. The unit testing framework is compiled and run using autotools. For more information on autotool's setup, see their documentation<https://www.gnu.org/software/automake/manual/html_node/Tests.html>. Since autotools is the build system for SU2, this involves minimal changes. Using automake, the build process for building unit tests becomes:. '''; ./bootstrap; ./configure; make; make check; '''. We use Boost's unit testing framework<https://www.boost.org/doc/libs/1_70_0/libs/test/doc/html/index.html>. This provides a convenient set of macros for instatiating tests, grouping tests into suites, and running checks. This choice was based on what is avai",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499250240:2354,test,tests-for-scientific-research-codes,2354,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240,1,['test'],['tests-for-scientific-research-codes']
Testability," where integration to the wall makes sense and a fuselage marker where wall functions (or even an inviscid BC) is the right thing to do. So let’s indeed do something like what Tom suggests (in the spirit of MARKER_MONITORING) so that one can control which markers get wall functions applied. If a list of markers is not specified in the config file, the default behavior should be that all no-slip walls get wall function BCs. If a list of markers is specified, then those and only those markers listed get wall function Bfs (with the others getting integration to the wall treatment). Now, what you point out in the second half of your message is the ultimate in flexibility: not only specifying wall functions in a subset of the no-slip wall markers, but also allowing for different kinds of wall functions to be used in those markers. I imagine that this would be a seldom used capability…but someone out there might have the need. I guess it does not seem to me that the coding of the most flexible logic is that much more complicated, so we may as well do that. If you guys think it is too complicated, the advertised options in the config file can allow some simpler behavior. My two cents,. Juan. On Sep 5, 2017, at 9:58 PM, Edwin van der Weide <notifications@github.com<mailto:notifications@github.com>> wrote:. Juan,. I think that having the flexibility to apply wall functions on only a subset of the viscous wall boundaries would be useful. E.g., if you are interested in a wing, you can apply integration to the wall there, but apply wall functions on the fuselage. My preference would be to have a dedicated BC type for that, i.e. Tom's second suggestion. Apart from this, we can have the different wall model types as a single input parameter, i.e. you apply the same wall model type for all viscous boundaries. Or would you like to have the flexibility to specify this as well per individual marker?. Edwin. —; You are receiving this because you commented.; Reply to this email directl",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/399#issuecomment-327377108:1209,log,logic,1209,https://su2code.github.io,https://github.com/su2code/SU2/issues/399#issuecomment-327377108,1,['log'],['logic']
Testability," where; > it makes sense (as described by Clark and in the Stack Exchange discussion); > I would advocate for using it moving forward. There may also be some; > issues that arise multiple times in existing code where a retroactive; > application of unit testing may also make sense. I am copying Pat Miller,; > formerly with DoE, who may have more experience on whether such unit; > testing approaches were useful/worth the investment in some major codes he; > worked on.; >; > Best,; >; > Juan; >; >; > On Jun 4, 2019, at 2:14 PM, Clark Pederson <notifications@github.com>; > wrote:; >; > I propose adding a unit-testing framework and unit-tests to SU2. After; > chatting with @economon <https://github.com/economon>, I've decided to; > move the discussion here to get additional input.; > What is unit testing?; >; > For those not familiar with unit testing, unit testing allows the testing; > of small bits of behavior, ideally using isolated bits of code. It is not; > intended to replace validation testing or formal verification tests.; > Instead, it serves a unique purpose. Consider the three following use cases:; >; > - You're developing a new feature, and you want to test it to see if; > it works. You could do a full simulation, but that takes a lot of time and; > computing power. You want to check if your new behavior behaves as you; > suspect before you throw a lot of resources at it.; > - You submit a PR and discover that one of the regression tests has; > failed. But...why? You know that something is broken, but its hard to track; > down what broke. You want more granular test coverage that can demonstrate; > what broke.; > - You are fixing a very small bug. You know that you should prove that; > your bug fix worked, but it doesn't seem logical to dedicate an entire; > validation case to one small bug fix. You want to write a small test for a; > small fix.; >; > In all of these cases, unit testing fills a unique role. Unit testing; > increases time spent in development",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499278427:2203,test,testing,2203,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427,2,['test'],"['testing', 'tests']"
Testability,"   https://github.com/su2code/SU2/pull/174; Commit Summary; - Updated GetEngine_Properties; - Fix to the last commit; - Small bug; - Merge branch 'develop' into feature_MPI; - merging; - SU2_SOL and SU2_CFD are working; - Preliminary, but complete, implementation of SU2_DEF; - More updates; - Working version; - Complete implementation (validate); - Working version of SU2_DEF; - Final push before moving to the develop branch; - New MPI (removing SU2_PRT); - Merged in Ben's ParMETIS integration and fixed some conflicts.; - Merge branch 'benkirk-parmetis_integration' into feature_MPI; - ParMETIS geometry routines have been copied over but are not activated yet.; - Small change to ParMETIS include.; - ParMETIS can now be activated for testing (PARMETIS=YES in config).; - Updated MG; - Updated EA subrotuine; - Small fix; - Fixing memory leak; - Fixing memory leaks; - Dev release v.3.2.6; - Increasing MAX_NUMBER_MARKER; - Working version with ParMETIS. Fixed bug in global index. Now clean up and testing...; - Cleaned version of ParMETIS routines with better console output during partitioning.; - Small bug in initial element division.; - Made arrays in ParMETIS call dynamic.; - Fixed compiler warnings and added MPI directives so that the pure serial code works with the ParMETIS routines.; - Bootstrap on zion.; - Added some typecasts. Still tracking down a memory problem...; - Critical bug fix for vtxdist array.; - Partial fix; - More MPI improvements.; - Fixing a bug in SU2_DEF; - Updated BC_ActDisk_Boundary (MPI); - Merge remote-tracking branch 'upstream/develop' into develop; - changing solidboundary setting to be heatflux OR euler etc instead of AND, also working on doxygen documentation; - Dynamic allocation for some marker-related arrays.; - visualize part taken out to match upstream/dev; - Collection of improvements; - Release 3.2.7; - Fixing LOW_MEMORY_OUTPUT; - Updated LOW_MEMORY_OUTPUT option; - Updated configure.ac; - After autoconf; - Updated MPI; - Updated BC_E",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:2063,test,testing,2063,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['test'],['testing']
Testability,"'; ./bootstrap; ./configure; make; make check; '''. We use Boost's unit testing framework<https://www.boost.org/doc/libs/1_70_0/libs/test/doc/html/index.html>. This provides a convenient set of macros for instatiating tests, grouping tests into suites, and running checks. This choice was based on what is available in our development setup. We have integrated our unit tests into our Travis CI regression testing. Every time we push commits or submit a pull request, the unit tests are run and checked. What is my vision for unit testing in SU2?. I am not proposing that we start trying to get 100% code coverage with pre-existing code. That would not provide a good return on investment. Instead, I see people adding unit tests as they write new code and as they find bugs. For each new behavior added to SU2, tests are first added to document the related existing behavior. These tests serve to check that the existing behavior isn't damaged by the new code. Then new tests are added to prove that the new behavior is working correctly. For bug fixes, the process is simpler. A test is added to confirm that something is not behaving as expected. Then the code is fixed to make the test pass. What frameworks are available?. For a unit testing framework, here are the most popular options, with the following pros and cons:. Roll-your-own. * Requires no external dependencies; * The most flexible option; * Involves the most work to setup; * Will lack some of the more advances features of mature unit-testing frameworks. Boost Test. * Can be header only, statically linked, or dynamically linked; * If statically or dynamically linked, then Boost is not very lightweight; * Easy to add if you're already using Boost. Google Test. * Most common unit-testing framework; * Can be easily combined with Google's powerful GMock mocking library; * Compiling and linking can be somewhat painful. Catch2. * Used by FEniCS; * Makes unit tests easily readable with lots of syntactic sugar.; * Has a very sim",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499250240:4009,test,tests,4009,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240,1,['test'],['tests']
Testability,"**Disclaimer**; The performance numbers that follow are based on simple implementations of the methods, I do not claim any of my implementations or choice of methods to be optimal. If you know better speak up.; The data is from the case used to benchmark #753 (see #716), it is by no means an extensive collection of different grid types. I will share code and data with anyone who wants to repeat the tests on the condition they post detailed results. With that out of the way :) ... ### Green-Gauss Gradients. This is the plain edge-loop version of the code with boundary contributions omitted for simplicity:; ```C++; void computeGradients(size_t nEdge,; size_t nPoint,; size_t nVar,; size_t nDim,; const vector<pair<size_t,size_t> >& connectivity,; const Matrix& area,; const vector<double>& volume,; const Matrix& phi,; VectorOfMatrix& grad); {; grad.setZero();. for(size_t iEdge=0; iEdge<nEdge; ++iEdge); {; size_t iPoint = connectivity[iEdge].first;; size_t jPoint = connectivity[iEdge].second;. for(size_t iVar=0; iVar<nVar; ++iVar); {; double phi_ave = 0.5*(phi(iPoint,iVar)+phi(jPoint,iVar));. for(size_t iDim=0; iDim<nDim; ++iDim); {; double flux = phi_ave*area(iEdge,iDim);. grad(iPoint,iVar,iDim) += flux;; grad(jPoint,iVar,iDim) -= flux;; }; }; }. for(size_t iPoint=0; iPoint<nPoint; ++iPoint); for(size_t iVar=0; iVar<nVar; ++iVar); for(size_t iDim=0; iDim<nDim; ++iDim); grad(iPoint,iVar,iDim) /= volume[iPoint];; }; ```; This is more or less what SU2 does with minor differences on how the edges (`connectivity`) and area are stored, there is no vectorization nor easy way to make the loop parallel, this will be the reference for execution times. Suppose now that due to a perfect storm the number of variables is 4, here is how with a few pragmas we get gcc to vectorize:; ```C++; template<size_t nVar>; void computeGradients_impl(size_t nEdge,; size_t nPoint,; size_t nDim,; const vector<pair<size_t,size_t> >& connectivity,; const Matrix& area,; const vector<double>& volume,; con",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-530328194:245,benchmark,benchmark,245,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530328194,2,"['benchmark', 'test']","['benchmark', 'tests']"
Testability,", unit testing allows the testing; > of small bits of behavior, ideally using isolated bits of code. It is not; > intended to replace validation testing or formal verification tests.; > Instead, it serves a unique purpose. Consider the three following use cases:; >; > - You're developing a new feature, and you want to test it to see if; > it works. You could do a full simulation, but that takes a lot of time and; > computing power. You want to check if your new behavior behaves as you; > suspect before you throw a lot of resources at it.; > - You submit a PR and discover that one of the regression tests has; > failed. But...why? You know that something is broken, but its hard to track; > down what broke. You want more granular test coverage that can demonstrate; > what broke.; > - You are fixing a very small bug. You know that you should prove that; > your bug fix worked, but it doesn't seem logical to dedicate an entire; > validation case to one small bug fix. You want to write a small test for a; > small fix.; >; > In all of these cases, unit testing fills a unique role. Unit testing; > increases time spent in development, but decreases the amount of time spent; > in bug-fixing and maintaining.; >; > For more information, see this relevant Stack Exchange question.; > <https://scicomp.stackexchange.com/questions/206/is-it-worthwhile-to-write-unit-tests-for-scientific-research-codes>; > What do I propose?; >; > My research group at UT Austing has implemented a unit testing framework; > on our branch, which we're happy with. Some choices were arbitrary, and; > some choices were made based on our development environment. Those choices; > may be different for other groups. Here's what we have done:; >; > The unit testing framework is compiled and run using autotools. For more; > information on autotool's setup, see their documentation; > <https://www.gnu.org/software/automake/manual/html_node/Tests.html>.; > Since autotools is the build system for SU2, this involves min",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499278427:3060,test,test,3060,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427,1,['test'],['test']
Testability,"-------------------- Surface grid deformation ----------------------; Performing the deformation of the surface grid. ----------------------- Volumetric grid deformation ---------------------; Performing the deformation of the volumetric grid. # FGMRES residual history. # Residual tolerance target = 4.14044e-11. # Initial residual norm = 15.8102. ```; 0 1; 50 2.17385e-06; 100 1.08998e-10; ```. # FGMRES final (true) residual:. # Iteration = 105: |res|/|res0| = 3.50764e-11. Non-linear iter.: 1/1. Linear iter.: 105. Min. area: 4.1019e-08. Error: 5.54565e-10. ----------------------- Write deformed grid files -----------------------; Merging grid connectivity.; Merging grid coordinates.; Writing volume mesh file.; Writing surface mesh file.; Writing .su2 file.; Adding any FFD information to the SU2 file. Completed in 1.039217 seconds on 1 core. ------------------------- Exit Success (SU2_DEF) ------------------------. [image]https://cloud.githubusercontent.com/assets/5167760/9294056/7be9439a-440f-11e5-862f-742246ef1565.png; SU2_DEF: output when deforming with all markers included:. ------------------------- Surface grid deformation ----------------------; Performing the deformation of the surface grid.; No surface deformation (scaling, rotation, or translation). ----------------------- Volumetric grid deformation ---------------------; Performing a translation of the volumetric grid.; Translational displacement: (1, 0, 0). ----------------------- Write deformed grid files -----------------------; Merging grid connectivity.; Merging grid coordinates.; Writing volume mesh file.; Writing surface mesh file.; Writing .su2 file.; Adding any FFD information to the SU2 file. Completed in 0.716938 seconds on 1 core. as far as I can tell the regression test failure is the same as for the current develop branch; I'll update this pull request whenever that is resolved. —; Reply to this email directly or view it on GitHubhttps://github.com/su2code/SU2/pull/187#issuecomment-131578218.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/187#issuecomment-132065067:3272,test,test,3272,https://su2code.github.io,https://github.com/su2code/SU2/pull/187#issuecomment-132065067,1,['test'],['test']
Testability,".; Some people wrote code that tested almost nothing. And it would get; through code review that way. Eventually, I added coverage analysis to the check in that exposed this; practice that gave a false assurance that things were ok. More when I can think a bit more on this and get to a real keyboard!. Pat. On Wed, Jun 5, 2019 at 1:50 PM Juan Jose Alonso <jjalonso@stanford.edu>; wrote:. > Clark,; >; > Thanks for putting this idea out there. In my experience, unit testing; > has been an intrinsic part of the the modus operandi in many multi-physics; > codes at DoE and has been well worth the additional effort. In cases where; > it makes sense (as described by Clark and in the Stack Exchange discussion); > I would advocate for using it moving forward. There may also be some; > issues that arise multiple times in existing code where a retroactive; > application of unit testing may also make sense. I am copying Pat Miller,; > formerly with DoE, who may have more experience on whether such unit; > testing approaches were useful/worth the investment in some major codes he; > worked on.; >; > Best,; >; > Juan; >; >; > On Jun 4, 2019, at 2:14 PM, Clark Pederson <notifications@github.com>; > wrote:; >; > I propose adding a unit-testing framework and unit-tests to SU2. After; > chatting with @economon <https://github.com/economon>, I've decided to; > move the discussion here to get additional input.; > What is unit testing?; >; > For those not familiar with unit testing, unit testing allows the testing; > of small bits of behavior, ideally using isolated bits of code. It is not; > intended to replace validation testing or formal verification tests.; > Instead, it serves a unique purpose. Consider the three following use cases:; >; > - You're developing a new feature, and you want to test it to see if; > it works. You could do a full simulation, but that takes a lot of time and; > computing power. You want to check if your new behavior behaves as you; > suspect before you throw ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499278427:1582,test,testing,1582,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427,1,['test'],['testing']
Testability,"/21182966/28308831-b937bf76-6ba7-11e7-9108-e8a2ab959b74.png). Then I noticed a difference in SENS_GEO (which is the second term of the upper equation, right?) between compressible and incompressible. . ![image](https://user-images.githubusercontent.com/21182966/28310143-bb28c42a-6bab-11e7-8c14-8409b6b12027.png). So if the scale is adjusting current step size the step of dC and SENS_GEO represents the second term, then the SENS_GEO would change when the scale is changed. But this is not the case for incompressible and compressible. . In short, the only noticeable change, due to scaling, occurs in deformation folder of DSN_002. But this is after the optimization step, which is really confusing. Scaling adjusts the current step size and because it can not find a sufficient decrease it is halving the dv_value. But then one should expect different values in the adjoint folder for different scale factors, right?. I hope you can use this information and can tell me whether it is a correct behavior of the optimizer. I should also note that I did not make use of constraints, just as in the test case. I read that the optimizer will switch from optimization procedure. I think this should not matter because of the test case. . I attached also the configure files (compressible (working, scale= 0.01) and incompressible (not working, scale =0.01)) and the mesh file, which is in both cases the same file. [compressible_cfg.txt](https://github.com/su2code/SU2/files/1155421/compressible_cfg.txt); [incompressible_cfg.txt](https://github.com/su2code/SU2/files/1155427/incompressible_cfg.txt); [mesh_300_su2.txt](https://github.com/su2code/SU2/files/1155430/mesh_300_su2.txt). I hope I provide enough information so that one can clarify the behavior of the optimizer. I also appreciate if one can tell me which variables have to be kept in mind. I really want to learn from this and if more information is needed, I really do not mind to provide it. Many thanks in advance!. Floris van der Schuur",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/409#issuecomment-316018103:3638,test,test,3638,https://su2code.github.io,https://github.com/su2code/SU2/issues/409#issuecomment-316018103,2,['test'],['test']
Testability,"2357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; 14368 Vertex ; 3 Boundary Vertices ; 58189 Tetrahedra ; 1 Triangles ; 0 Edges ; 1 Surface(s) ; % Output subdom.meshb Mesh ndimn=3, mpoin=14368, melem=58189, mface=1; Corners 0 Required 0 ; ## ERROR : TETRAHEDRON 2 BOUNDARY FACE 1 2; 9 IS MISSING ; ## ERROR : TETRAHEDRON 4 BOUNDARY FACE 3 7; 2324 IS MISSING ; ···; ## ERROR: FEFLO.A: 16740 BOUNDARY FACES ARE MISSING ; CHECK YOUR MESH . ## FATAL ERROR: FEFLOA: INITIAL OR CURRENT MESH HAS AN INCONSISTANT TOPOLOGY . Thank you for using feflo.a . ```; Which in turn creates an invalid `amg.su2` mesh in the `adap/ite0 folder`, which triggers the fault.; I'm a bit puzzled as the domain is very simple, and the `log.out` is going well (with no complains of SU2 about any negative volume or trias with wrong normals). The mesh is only made of TRIAS and TETRAS, it should work in principle.; Am I missing something in the setup / mesh? I know you have little control on the `amg.out`, but maybe there some special hint that I'm missing. . Btw the final error in the terminal is but I think the problem arises before reaching `flo.csv` file:; ```; Traceback (most recent call last):; File ""/usr/local/bin/mesh_adaptation_amg.py"", line 111, in <module>; main(); File ""/usr/local/bin/mesh_adaptation_amg.py"", line 72, in main; options.save_all ); File ""/usr/local/bin/mesh_adaptation_amg.py"", line 101, in mesh_adaptation_amg; SU2.run.amg(config); File ""/usr/local/bin/SU2/run/amg.py"", line 464, in amg; os.rename(cur_solfil, cur_solfil_ini); FileNotFoundError: [Errno 2] No such file or directory: 'flo.csv' -> 'flo_ini.csv'. ```; Thanks!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/948#issuecomment-623572280:2217,log,log,2217,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-623572280,1,['log'],['log']
Testability,"> ; > ; > @CatarinaGarbacz thanks for pushing your changes! I have left some comments and questions.; > ; > A bigger question I have is if there is a more general way to deal with SU2_INTERP, making it usable for all of develop. Just answering @WallyMaier comment, this should be possible by changing the file **fem_interpolation_structure.cpp** and change the function call:. output = COutputFactory::CreateOutput(**NEMO_NAVIER_STOKES**, input_config_container[ZONE_0],nDim);. So we have to replace **NEMO_NAVIER_STOKES** to something like **config[val_iZone]->GetKind_Solver()**.; ; I have not tested this change, but I tested changing it for NAVIER_STOKES, and it was able to interpolate the baseline SU2.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1160#issuecomment-760110555:596,test,tested,596,https://su2code.github.io,https://github.com/su2code/SU2/pull/1160#issuecomment-760110555,2,['test'],['tested']
Testability,"> > I'm thinking about reusing the SST test case ([axisymmetric_rans/air_nozzle](https://github.com/su2code/SU2/tree/master/TestCases/axisymmetric_rans/air_nozzle)) so that the same mesh can be used. Would that be fine ?; > ; > That's a quite specific testcase. How did you test the implementation? Do you have some simple results for the turbulent axisymmetric jet? We know that the results for round jets are not super good for standard SA, but at least we know what the result should look like, here on p.32 - 35 they test SA for the round jet and compare to the Wygnanski & Fiedler measurements: https://www.researchgate.net/publication/24296213_Turbulence_Modeling_Validation_Testing_and_Development; > ; > The domain is just a rectangle so pretty simple to set up.; > ; > You could also use the V&V test that we have, but it is a variable density jet: https://su2code.github.io/vandv/SANDIA_jet/. I did some tests on a supersonic jet, since I already had the files, but it's a quite complex case so it's not that good to verify the implementation. I will look into the simpler cases you mentioned !",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/2197#issuecomment-1891046092:39,test,test,39,https://su2code.github.io,https://github.com/su2code/SU2/pull/2197#issuecomment-1891046092,6,['test'],"['test', 'testcase', 'tests']"
Testability,> @EvertBunschoten even if the performance isn't great this is a pretty small change so I think we can merge it. Do you have time to wrap it up and add a simple regression test?. I just added a test case and tutorial under the TestCases and Tutorials repo under the same branch name. I'm also writing a short tutorial on the SU2 website repo.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/2152#issuecomment-2271237145:172,test,test,172,https://su2code.github.io,https://github.com/su2code/SU2/pull/2152#issuecomment-2271237145,2,['test'],['test']
Testability,"> @kursatyurt Hello, thank you so much for the lead.; > ; > Our initial scope mostly involved writing our own kernels and I did explore some libraries at the start - I was planning on using CUSP as well but my main concern was its lack of being updated to the newly compatible versions of the toolkit. cuSolver and cuBLAS do exist, but I chose to go ahead with a ""simple"" kernel implementation to have more control. I also felt that if I could keep the block size of the grid in optimal territory then they could be just as fast as those options (please do correct me if my reading of the literature or the situation was incorrect). To learn the basics, it's a good idea, but for large-scale projects, I prefer using existing libraries if possible.; Those libraries generally exploit state-of-the-art solution like mixed-precision computing. A gaming GPU is not way faster than a good CPU in double precision, but way faster in single precision, most of them have 64:1 ratio, however server class GPU have 2:1 ratio. Also when available they use vendor libraries like cuBLAS or hipBLAS. It is always nice to have you only care about connection and somebody else handle the solver as performant as possible. In future probably they will provide more and more solvers and it will be automagically works. It is kind of light-weight too, not a huge dependency like Trilinos or PETSc. ; > ; > I was not aware of Ginkgo and I will surely give it a go and try to produce some comparative results. I am currently super busy for this month and will get to working on the code with some delay.; > ; > Again, thank you for the lead!. I can test on various GPUs (P100/V100/A100 and 4070Mobile) on single node multi-gpu etc.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/2346#issuecomment-2397803409:1629,test,test,1629,https://su2code.github.io,https://github.com/su2code/SU2/pull/2346#issuecomment-2397803409,1,['test'],['test']
Testability,"> Aside from my last two comments, and the possibility I broke the code :), this looks ready. Is this missing anything, or is it ready to merge?. Thank you so much @pcarruscag for your feedback. there is one thing left, it is about the residuals of the test case (species2_primitiveVenturi_mixingmodel.cfg) that I added in the previous pull request, they have changed exceeding in some outputs the tolerance 0.00001 with respect to the values stored in the parallel_regression.py, however the test case converges very well, so could it be possible to modify the values stored in that test case in order to not have this discrepancy between values stored and computed? Thank you so much in advance!!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1690#issuecomment-1194029520:253,test,test,253,https://su2code.github.io,https://github.com/su2code/SU2/pull/1690#issuecomment-1194029520,3,['test'],['test']
Testability,"> Below you can find a transitional test case using B-C model implemented in SU2:; > https://su2code.github.io/tutorials/Transitional_Flat_Plate/. Samet, nice to meet you! Thank you for your suggestion! I have learned this model in current SU2 version. B-C model can provide quite good results in many teatcases.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/502#issuecomment-446631804:36,test,test,36,https://su2code.github.io,https://github.com/su2code/SU2/issues/502#issuecomment-446631804,1,['test'],['test']
Testability,"> Every time we push commits or submit a pull request, the unit tests are run; > and checked.; > What is my vision for unit testing in SU2?; >; > I am *not* proposing that we start trying to get 100% code coverage with; > pre-existing code. That would not provide a good return on investment.; >; > Instead, I see people adding unit tests as they write new code and as they; > find bugs. For each new behavior added to SU2, tests are first added to; > document the related existing behavior. These tests serve to check that the; > existing behavior isn't damaged by the new code. Then new tests are added; > to prove that the new behavior is working correctly. For bug fixes, the; > process is simpler. A test is added to confirm that something is not; > behaving as expected. Then the code is fixed to make the test pass.; > What frameworks are available?; >; > For a unit testing framework, here are the most popular options, with the; > following pros and cons:; > Roll-your-own; >; > - Requires no external dependencies; > - The most flexible option; > - Involves the most work to setup; > - Will lack some of the more advances features of mature unit-testing; > frameworks.; >; > Boost Test; >; > - Can be header only, statically linked, or dynamically linked; > - If statically or dynamically linked, then Boost is not very; > lightweight; > - Easy to add if you're already using Boost; >; > Google Test; >; > - Most common unit-testing framework; > - Can be easily combined with Google's powerful GMock mocking library; > - Compiling and linking can be somewhat painful; >; > Catch2; >; > - Used by FEniCS; > - Makes unit tests easily readable with lots of syntactic sugar.; > - Has a very simple syntax; > - Is header-only; > - Requires C++11 compilation; > - Not as feature rich as Google Test or Boost Test; >; > Questions; >; > - How do developers feel about adding unit tests to SU2?; > - If a unit-testing framework were added to SU2, would you actually; > use it?; > - Do developers hav",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499278427:5478,test,testing,5478,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427,2,['test'],['testing']
Testability,"> I'm thinking about reusing the SST test case ([axisymmetric_rans/air_nozzle](https://github.com/su2code/SU2/tree/master/TestCases/axisymmetric_rans/air_nozzle)) so that the same mesh can be used. Would that be fine ?. That's a quite specific testcase. How did you test the implementation? Do you have some simple results for the turbulent axisymmetric jet? We know that the results for round jets are not super good for standard SA, but at least we know what the result should look like, here on p.32 - 35 they test SA for the round jet and compare to the Wygnanski & Fiedler measurements:; https://www.researchgate.net/publication/24296213_Turbulence_Modeling_Validation_Testing_and_Development. The domain is just a rectangle so pretty simple to set up. You could also use the V&V test that we have, but it is a variable density jet:; https://su2code.github.io/vandv/SANDIA_jet/",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/2197#issuecomment-1889612505:37,test,test,37,https://su2code.github.io,https://github.com/su2code/SU2/pull/2197#issuecomment-1889612505,5,['test'],"['test', 'testcase']"
Testability,"> If anyone as an elegant solution to simply check for EXIT_SUCCES in the regression test one could add some dry_run regression tests. This can be added to the meson tests simply enough. In other words, you could add it alongside the unit tests. You can read more about meson tests [here](https://mesonbuild.com/Unit-tests.html). If you add `SU2_CFD` as a test executable with the dry run option as a command line argument, then meson will do the dry run and mark it as failing if it does not receive `EXIT_SUCCESS`.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/858#issuecomment-581945210:85,test,test,85,https://su2code.github.io,https://github.com/su2code/SU2/pull/858#issuecomment-581945210,7,['test'],"['test', 'tests']"
Testability,> Mpi4 is not compatible with the version of pastix we support.; > And you have to compile scotch and pastix according to the instructions in TestCases/pastix_support/ before compiling SU2. Thanks for the clarification! I use Mpi4 for most of my programs so that's why I built it that way. I followed this guide for pastix: https://solverstack.gitlabpages.inria.fr/pastix/md_docs_doxygen_chapters_Pastix_Runtime.html. So I build pastix 6.X.X. I will check the test cases directory though for the instructions. Also how does changing openmpi change c++ command line option ? . Thanks 😊,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1349#issuecomment-894838291:460,test,test,460,https://su2code.github.io,https://github.com/su2code/SU2/issues/1349#issuecomment-894838291,1,['test'],['test']
Testability,"> Thank you for the feedback but for 99% of cases it is easier for users if we download the dependencies for them. The philosophy behind SU2 has always been to provide as much of a self contained package as possible. But this check will allow users to use external dependencies just fine, as long as they happen to use an external 0.61.1?. ... I am not entirely sure I understand the issue here. You want to make it *easier* for users by downloading the dependencies, so you make it harder if they went and got their own dependencies? If someone has gone to the effort of getting their own dependencies instead of using your documented meson.py, it would seem like that inherently means they are the 1% of use cases and you could probably just leave them to it. Is the issue rather that only Meson 0.61.1 has been tested to work?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1945#issuecomment-1450921338:814,test,tested,814,https://su2code.github.io,https://github.com/su2code/SU2/issues/1945#issuecomment-1450921338,1,['test'],['tested']
Testability,"> Thanks for the fast reply! I changed the hardcoded 2 (just as a remark: the hardcoded values also appear in the calculations), added myself as an author and inserted some lines for throwing an error if the issue in #1565 occurs. I did not know exactly where to put it best.; > ; > Concerning a regression test: I strongly support the idea of introducing an axisymmetric regression test. However, I was using a testcase from @bigfooted , and I never set up such a test case on my own. There do not seem to be any axisymmetric pipe setups in the Testcases folder so far. @bigfooted , could we maybe use your mesh for the jet flow test case and, if necessary, switch to a standard flow setup?. Yes, you can use that mesh. It can be used for pipe flow setup and jets with coflows, so we can reuse it in different testcases as well if needed. But any simple rectangular mesh is fine, so a mesh from the existing testcases as @pcarruscag mentions would also work.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1571#issuecomment-1075656956:307,test,test,307,https://su2code.github.io,https://github.com/su2code/SU2/pull/1571#issuecomment-1075656956,7,['test'],"['test', 'testcase', 'testcases']"
Testability,"> Thanks for the suggestion and I am preparing for a test. As far as I understand it, I just find that to get the absolute value of r_ij ( showed in the highest equation) in this part of code is unnecessary. The cross-product operation is to find the grid vector mostly parallel to the vorticity vector and the absolute value may cause a nonphysical recognition. @EduardoMolina, I don't know if I got it wrong and wish more guidance,.; > ; > ```; > for (auto iDim = 0u; iDim < nDim; iDim++){; > delta[iDim] = fabs(coord_j[iDim] - coord_i[iDim]);; > }; > ```. Hi Shihe,. I checked the implementation and I think it is correctly done. You do need the absolute value (i.e., delta has a unit of [m] or equivalent) to keep the correct dimension of nu_t based on a Smagorinsky-type SGS model. You may find the appendix of this paper useful for your understanding of delta_omg: [https://doi.org/10.1007/s00162-011-0240-z](https://doi.org/10.1007/s00162-011-0240-z). Also note that delta_omg does not always outperforms its peers - vorticity may not be aligned to the rotation axis of a local vortex (e.g., in rotating reference frame, in attached boundary layer, to name a few), in which case the physical meaning of delta_omg becomes vague. See also my work for a brief review of DES-type methods and some applications: [https://doi.org/10.1115/1.4052019](https://doi.org/10.1115/1.4052019)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1462#issuecomment-990220976:53,test,test,53,https://su2code.github.io,https://github.com/su2code/SU2/issues/1462#issuecomment-990220976,1,['test'],['test']
Testability,"> the off-PR comments can be integrated in this PR to clear that up a bit. If not that is OK as well. It's more than OK, the CHT implementation suffers a bit from being a single person's project.. you're very welcome to have a look over it! :-). > Can you add that option to the config_template.cfg together with that description, the valid inputs and the default. Actually I'm hesitating a bit adding it to the config template right now. I'd prefer to have `DIRECT_TEMPERATURE_ROBIN_HEATFLUX` as the default and ""hide"" the rest as developer's options for the moment.; The reason simply is that those different methods need to checked and validated against each other before we make them public.; E.g. I figured that for the incompressible CHT test case from the repo, there is a severe gap between the heatfluxes obtained from the ""averaged"" approach and the direct one, see below. ![heatflux_convergence](https://user-images.githubusercontent.com/22639394/72885197-bb9e4a80-3d07-11ea-9fad-a4d709dc511e.png). That needs to be cleared up first...",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/839#issuecomment-577108935:744,test,test,744,https://su2code.github.io,https://github.com/su2code/SU2/pull/839#issuecomment-577108935,1,['test'],['test']
Testability,"?. For those not familiar with unit testing, unit testing allows the testing of small bits of behavior, ideally using isolated bits of code. It is not intended to replace validation testing or formal verification tests. Instead, it serves a unique purpose. Consider the three following use cases:. * You're developing a new feature, and you want to test it to see if it works. You could do a full simulation, but that takes a lot of time and computing power. You want to check if your new behavior behaves as you suspect before you throw a lot of resources at it.; * You submit a PR and discover that one of the regression tests has failed. But...why? You know that something is broken, but its hard to track down what broke. You want more granular test coverage that can demonstrate what broke.; * You are fixing a very small bug. You know that you should prove that your bug fix worked, but it doesn't seem logical to dedicate an entire validation case to one small bug fix. You want to write a small test for a small fix. In all of these cases, unit testing fills a unique role. Unit testing increases time spent in development, but decreases the amount of time spent in bug-fixing and maintaining. For more information, see this relevant Stack Exchange question.<https://scicomp.stackexchange.com/questions/206/is-it-worthwhile-to-write-unit-tests-for-scientific-research-codes>. What do I propose?. My research group at UT Austing has implemented a unit testing framework on our branch, which we're happy with. Some choices were arbitrary, and some choices were made based on our development environment. Those choices may be different for other groups. Here's what we have done:. The unit testing framework is compiled and run using autotools. For more information on autotool's setup, see their documentation<https://www.gnu.org/software/automake/manual/html_node/Tests.html>. Since autotools is the build system for SU2, this involves minimal changes. Using automake, the build process for bu",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499250240:2011,test,test,2011,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240,1,['test'],['test']
Testability,"@AmauryBilocq Thanks for your post. Can you please check that you are actually not running out of memory, as that can also raise such errors? Second, if Giles BC is the issue I think you will still be able to run the case with Riemann which is a bit simpler than Giles. Can you also test that?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1429#issuecomment-1025177015:283,test,test,283,https://su2code.github.io,https://github.com/su2code/SU2/issues/1429#issuecomment-1025177015,1,['test'],['test']
Testability,@EvertBunschoten even if the performance isn't great this is a pretty small change so I think we can merge it.; Do you have time to wrap it up and add a simple regression test?,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/2152#issuecomment-2269672071:171,test,test,171,https://su2code.github.io,https://github.com/su2code/SU2/pull/2152#issuecomment-2269672071,1,['test'],['test']
Testability,"@JedrzejMosiezny . The reason why the mesh and config files are split into separate repos is the following: ideally we want to have the test cases being closely coupled to the current version of the code as config options change quite frequently. However, the mesh files are simply too big to have them in the main repo (it takes too much time to check them out etc.). So a compromise was to still leave the config files in the main repo in order for them to stay up-to-date. We thought that the information [here](https://github.com/su2code/SU2/wiki/Test-Cases) would be quite clear for the user on how to merge config and mesh files. Following this instructions should avoid having to search for the mesh files manually. Let us know if you think different. @economon could you add Jędrzej to the dev team here on github ? Thanks!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/485#issuecomment-355152833:136,test,test,136,https://su2code.github.io,https://github.com/su2code/SU2/pull/485#issuecomment-355152833,1,['test'],['test']
Testability,"@clarkpede @EduardoMolina : yep, the issue is that the periodic and MPI communications are tangled up together in the current implementation. The main issue occurs when there are periodic points that are also ghost nodes. . Ideally the periodic and MPI would be separated, and the periodic communications would happen first so that all periodic BCs are synchronized before trying to send across partitions. Right now, the comms are mixed, so sometimes, we send old data at periodic points to their matching pair, which then gets updated in a later MPI comm. Therefore, the second call you have added to the MPI resends the periodic update to with the correct data that was updated with MPI in the first call. I hope this is clear.. Anyway, please go with this change as you have it. All of the MPI and periodic comms will be replaced with a cleaner/separated version right after v6.2.0 (you can see what I am working on in feature_mpi_periodic). I will likely need some help testing that soon :).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/649#issuecomment-463711280:975,test,testing,975,https://su2code.github.io,https://github.com/su2code/SU2/pull/649#issuecomment-463711280,1,['test'],['testing']
Testability,"@clarkpede Great, thanks for the details. I see your point. In general, vortex shedding cases are indeed challenging to match with the experiments, but that's what makes them interesting at the end. For a start, I am aiming to obtain comparable behaviours with both the compressible and the incompressible unsteady solvers under similar settings, rather than matching with experiments; mostly as an acceptance test as well. I am now working with standard SST turbulence model, but if you could share some simple meshes/cfg files to have a first go with hybrid RANS/LES, I would really appreciate it. > Good catch. I just pushed a commit that adds SetMaxLength calculations in all the instances I could find where the geometry updates. Thanks for the fix!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/552#issuecomment-404097397:410,test,test,410,https://su2code.github.io,https://github.com/su2code/SU2/pull/552#issuecomment-404097397,1,['test'],['test']
Testability,"@economon I need to fix and test a few things before I push the branch to an internal branch. But I should be able to finish by the end of the next week. If you're looking to improve the C++ inlet profile specification I started, then I'd like to get some feedback on the overall design. There are several different ways to handle this, and I chose what I thought was most logical. I want to make sure that my design choices match your use cases and SU2's design. Should I post a summary here, or would you prefer that I email you?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/467#issuecomment-366493237:28,test,test,28,https://su2code.github.io,https://github.com/su2code/SU2/issues/467#issuecomment-366493237,2,"['log', 'test']","['logical', 'test']"
Testability,"@economon I tested a couple of simpler problems at subsonic speeds, including the ONERA M6 case at M=0.8395. There's occasionally a difference of one iteration out of about 20. Usually the current develop branch is the one that requires more iterations, but not always. I included a snapshot from my tests on the ONERA M6 case at CFL=30. ![convergence_comparison](https://user-images.githubusercontent.com/13340225/48648855-6c97af80-e9b6-11e8-863a-56dfdf0903c8.png). I don't have a good supersonic, viscous test problem, but I suspect the differences in convergence won't be huge there either. This sign change affects a single term out of many and a single component of a 4x4 or 5x5 Jacobian. My take is that the differences are there, but they are very small. I wouldn't have noticed the problem myself if I hadn't been refactoring the code to enable some changes on our end.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/609#issuecomment-439538677:12,test,tested,12,https://su2code.github.io,https://github.com/su2code/SU2/issues/609#issuecomment-439538677,3,['test'],"['test', 'tested', 'tests']"
Testability,"@economon I was envisioning something similar to the TestCases folder. With v&v cases grouped according to what they are testing. Something along the lines of: . 1) Inviscid Simulations: ; a) 2D Inviscid bump; b) 2D oblique shocks interaction; c) ...; 2) RANS simulations: ; a) Flatplate; b) NACA0012; c) ...; 3) Unsteady simulations:; a) Square Cylinder; b) ...; 4) Turbomachinary: ; a) ... And so on. Each of the directories would have sub-directories for different mesh sizes, with configuration files for each mesh level that have optimized parameters for best results. So for example if we are talking about the NACA0012 case, we would have something along the lines of: . a) NACA0012; i) 113 x 33; ii) 225 x 65 ; iii) 449 x 129; iv) ... This way we have a family of meshes and configuration files that are specifically built for the purpose of validating the code and comparing with other solvers. I might be useful to compress meshes that are larger than a certain size (say 10MB). We should also put a limit on the size of a single mesh that the repository can handle (say 50MB?). . Within the home directory, the README file should list all the cases in the repository, who the custodian of the test case is (person with meshes in case the meshes are too large), and which version it was last run on. . I thought about splitting it up into Verification cases and Validation cases, but I thought it would be more informative and intuitive to split up according to the physics of the simulations. My thinking might be limited because that's how I have seen the TestCases folder organized, so any other suggestions are welcome. I think it is imperative that this is accompanied with a section on the SU2 website that showcases just the results of the validation test cases (grid convergence studies, residual reductions etc) and links to the v&v repo appropriately. This way, if people are just inquisitive about SU2's performance, they can get a quick snapshot of the results, without the need ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/581#issuecomment-426026053:121,test,testing,121,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-426026053,1,['test'],['testing']
Testability,"@economon No, this looks good to me. It is merge-ready, from my perspective. I chatted with @talbring, and in a future PR we would like to add a simple set of classes to use with unit tests. For example, I've created a ""one-point geometry"" class for use in some of my tests. But I think that we should keep the PRs as incremental as possible. PSA: If anyone else wants to review this PR, they are welcome to. It is no longer a WIP.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/850#issuecomment-620382001:184,test,tests,184,https://su2code.github.io,https://github.com/su2code/SU2/pull/850#issuecomment-620382001,2,['test'],['tests']
Testability,"@fertinaz the problem is that the pkg_config name for MPICH is not ""mpi"" which is what meson is configured to look for...; It is ""mpich"", please see my reply from 23 of May, it is very simple to edit the meson.build script to look for ""mpich"" instead of ""mpi"".; I have used this on numerous machines and the code works fine...; Whatever you do, please do not follow the advice to use 6.2.0, we have all worked extremely hard to make v7.x much faster, fix bugs, and add nice features... Unfortunately we cannot test every combination of compiler, operating system, and libraries.; I'm sure that somewhere, someone has fixed similar problems, sadly not all fixes make it back into the code. Other alternatives, some of which folks have suggested on this thread.; - Use ""custom-mpi"" mode, you will need to set some environment variables (CC=mpicc CXX=mpicxx etc. see above); - Use the legacy build system (i.e. follow the instructions for 6.2.0 but with the 7.0.7 code) be sure to add ""-DNDEBUG"" to the CXXFLAGS environment variable.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1000#issuecomment-721322008:510,test,test,510,https://su2code.github.io,https://github.com/su2code/SU2/issues/1000#issuecomment-721322008,1,['test'],['test']
Testability,"@pcarruscag: I'm in the process of creating a test case for the 3D gust. To do so, I created a CFD mesh for a simple, rectangular 3m wing with a NACA0012 profile. The mesh has a size of 13.7 Mb and a restart solution is 16.3 Mb plus 5.5 Mb (.csv and .dat). Do you think that is acceptable?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1954#issuecomment-1545475126:46,test,test,46,https://su2code.github.io,https://github.com/su2code/SU2/pull/1954#issuecomment-1545475126,1,['test'],['test']
Testability,"@rsanfer I'm using a test case from Ref [1], which doesn't exactly match the test case matching the figure I gave from Ref [2]. In Ref [1], they ran a whole ensemble of tests at various resolutions, corrections, and inflow/initial conditions. Some of the tests involved laminar separation, while others involved turbulent separation. I did not pick one of the Re = 50,000 cases because those cases involve laminar separation. Travin *et. al.* used a special nonuniform initial condition to promote laminar separation, which I viewed as overly complicated for the purposes of these tests. Instead, I picked a turbulent separation case at Re = 1.4 x 10^5 (roughly matching TS1 from Ref [1]). If you want more details/grids/cfg files, I can certainly provide them. Yes, I used the unsteady compressible solver. But I'm unsure if the circular cylinder case provides a good test case for the unsteady incompressible solver. I did very little with this test case in terms of a proper validation. The references I listed went to great lengths to ensure that the numerical results were consistent with experiments. It seems like a challenging test case. There were a lot of improvements I should have made if I were also trying to get consistent results. For example, my spanwise length was too short, and I didn't look into the impact of the rotation correction for the SA model. I skipped these improvements in the interest of time, since I wasn't aiming for validation, but rather a simple acceptance test.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/552#issuecomment-403850762:21,test,test,21,https://su2code.github.io,https://github.com/su2code/SU2/pull/552#issuecomment-403850762,9,['test'],"['test', 'tests']"
Testability,"@talbring I agree with your assessment of Boost. I think it's a heavyweight solution to a lightweight use-case. We could always include just the unit-testing header (they offer a header-only version), but ""people may want to use more and more features of boost,"" as you point out. If we as developers want to add Boost as a formal dependency for SU2, then that seems like a fine route. But I have the feeling that many developers do not want to add a Boost dependency. Honestly, Boost UTF doesn't offer anything that we can't get from Google Test. Catch2 is definitely the simplest and easiest of the unit-testing frameworks I listed. The only sticking point is that it requires c++03, and that the full-feature version requires C++11.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-500393344:150,test,testing,150,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-500393344,2,['test'],['testing']
Testability,"@talbring: thanks for adding the regressions. One iteration is perfect just to check they're running, if they have the originals still being tested in the TestCases. I think the idea of having the written tutorials/documentation for the test cases in the main repository is a very good one, for several reasons. In particular, it will make it easier for people to add documentation, and we could eventually even test for its existence in Travis or make it a strict requirement for PRs in the future. My only concern at the moment is making sure that they look ""nice"" when viewed and that the links are easy to update/follow. We should probably add a title at the top of each tutorial markdown file now (above the first image), since the titles from the wiki page are missing. The image files should be moved from the website repo (su2code.github.io/github_wiki/) to these Tutorials folders. Another idea is to put a top-level ""Tutorials"" markdown file that will be linked from the wiki at the root Tutorials/ directory so that one only has to update the links to new tutorials in that file in the main repo, rather than always updating both the main repo and manually updating the wiki too. Any other ideas for making this seamless and user-friendly are most welcome! Let me know if you need any help.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/485#issuecomment-355216605:141,test,tested,141,https://su2code.github.io,https://github.com/su2code/SU2/pull/485#issuecomment-355216605,3,['test'],"['test', 'tested']"
Testability,"Agreed that the style needs some attention. I am open to ideas about this. You may have noticed that I integrated Codacy recently to test it out: https://www.codacy.com. We have the style guide, but honestly, it's not getting much attention. We should automate checks or have scripts that automatically enforce style constraints. Vera++ sounds interesting in this regard. A little while back, @rsanfer and I had been working on indentation issues with the uncrustify tool. Should we open this as an issue and get some input? Find volunteers to look into these things?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/426#issuecomment-323636235:133,test,test,133,https://su2code.github.io,https://github.com/su2code/SU2/pull/426#issuecomment-323636235,1,['test'],['test']
Testability,"Ah! Cool, sure open a new PR @maxaehle.; What adjoint stuff? file names and so on?; I think removing irrelevant options would be make the tests clearer, there are lots with Roe and JST options specified and vice versa which probably confuses new users.; I'm not so sure about removing all defaults thought... On one hand it would serve as regression for the default values set by CConfig, on the other it hides the tuning parameters of some methods... but then again those are more or less documented now.; :shrug:",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1236#issuecomment-804035589:138,test,tests,138,https://su2code.github.io,https://github.com/su2code/SU2/pull/1236#issuecomment-804035589,1,['test'],['tests']
Testability,"Ah, I wasn't aware of the corrected version. Thanks for pointing out my mistake. The corrected version does make more sense, and the main changes seem to be:. + Changing the location of the sqrt in the definition of `Lturb`; + Changing `ch3` from 0.5 to 2.0; + Clarifying that S and Omega should have a factor of sqrt(2). As for code verification, I would propose using one of the cases examined by Travin, Stretlets, Mockett, or Xiao for comparison. We know that they got a nice range of values for the blending constant on their tests with DDES. The cases I can see where they explicitly show the results of the blending function are:. + Circular cylinder at Re = 50,000 (Travin _et al._ 2002); + Tandem cylinders at Re = 166,000 (Xiao _et al._ 2012); + NACA0021 airfoil in deep stall (Mockett 2009). The tricky thing is that the value of the blending constant is determined by the flow solution, which is determined by the solver. So the values we obtain will be dependent both on the version of DDES used and the nature of the code. We can't expect to match any of these papers exactly. We could also use a simpler flow, such as fully developed channel flow or a flat plate boundary layer. The tradeoff would be simplicity for ease of comparison.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/532#issuecomment-388189377:531,test,tests,531,https://su2code.github.io,https://github.com/su2code/SU2/pull/532#issuecomment-388189377,1,['test'],['tests']
Testability,"Alex, Heather,. Thanks for commenting and straightening this out. Since this is a frequently asked question, I have added a new section in the documentation on how to use the test cases, which will hopefully clear things up more in the future: https://github.com/su2code/SU2/wiki/Test-Cases. Tom",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/222#issuecomment-171108493:175,test,test,175,https://su2code.github.io,https://github.com/su2code/SU2/issues/222#issuecomment-171108493,1,['test'],['test']
Testability,"All,. I looked a bit more through Eigen and, indeed, the performance is pretty impressive and generally better than MKL and Atlas (the self-tuned implementation of LAPACK) ant most/all matrix sizes. I agree with comments made by @pcarruscg that having a standard for matrix operations throughout the source would clean up /simplify the code considerably and, since it does not seem to impact the AD approach, it should be pursued. It sounds like a quick test branch like @vdweide is suggesting makes sense. A quick driver code to test the performance of the Eigen routines vs MKL makes sense too. The only thing that @vdweide should comment on is how much work it would be to change the LAPACK/BLAS based implementation in the DG-FEM solver to the interface that Eigen exposes. Best,. Juan. On Feb 1, 2019, at 4:19 AM, Edwin van der Weide <notifications@github.com<mailto:notifications@github.com>> wrote:. Would it be an idea to create a branch to test things out and make a decision based on the results? It would be interesting to see the performance for e.g. the dense matrix multiplications in the DG-solver compared to Intel's MKL. —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/643#issuecomment-459705131>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADpSxM1gm0iy_FeGBMFzxVQnYFFzEHt4ks5vJDDlgaJpZM4adbAo>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/643#issuecomment-459845576:454,test,test,454,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459845576,3,['test'],['test']
Testability,"All,. Of course, another approach to verifying which sign is correct is to do an analytic differentiation (using CoDi?) or simply using complex-step on the residual calculation routine to get exact Jacobians (for a particular state) and confirm the correct sign. This does require some code extraction / refactoring to perform the test, but it has the benefit that you would know exactly what the correct answer is for the specific residual implementation. Best,. Juan. On Nov 16, 2018, at 11:03 AM, Thomas D. Economon <notifications@github.com<mailto:notifications@github.com>> wrote:. As Jacobians affect convergence rate and not accuracy, you could do a quick test of the same problem with the current version and the sign flipped to see if there is measurable difference in the convergence rate. If yes, then it should give you a hint about which direction. If no, then we should still correct it, but prob don't need to put in too much effort. @clarkpede<https://github.com/clarkpede> : I'm interested in your unit testing set up... —; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/609#issuecomment-439493827>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADpSxInSS3cmLF8iFkD22AoYAp0G3G2yks5uvwvxgaJpZM4YeD9V>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/609#issuecomment-439500791:331,test,test,331,https://su2code.github.io,https://github.com/su2code/SU2/issues/609#issuecomment-439500791,3,['test'],"['test', 'testing']"
Testability,"All,. Regarding the wall function specification, if we are going to settle on a standard way that could work for both the FV and DG-FEM solvers, it might be good to think about some modifiers that can later allow for a generality of approaches. We can make a distinction between wall functions and wall models, but this is subject to discussion…in essence both are performing similar duties, but people should express their opinions. With that said, how about a boolean such as USE_WALL_FUNCTIONS / USE_WALL_MODEL (YES or NO) with an optional argument WALL_FUNCTION_TYPE / WALL_MODEL_TYPE that can taken one of many pre-specified values that can be added as these options are developed and tested? Certainly options like STANDARD_WALL_FUNCTION, ADAPTIVE_WALL_FUNCTION, SCALABLE_WALL_FUNCTION, compressible and incompressible versions, and even EQUILIBRIUM_WALL_MODEL and NONEQUILIBRIUM_WALL_MODEL are things that are likely to be in the code in the near future. Thoughts?. Juan. On Sep 5, 2017, at 2:27 PM, Thomas D. Economon <notifications@github.com<mailto:notifications@github.com>> wrote:. @petebachant<https://github.com/petebachant>: the paper that I linked earlier on this thread had some fairly simple examples similar to the one you propose.. different flat plates and so on with varying y^+. You can likely reuse the grid(s) in the TestCases repo. @vdweide<https://github.com/vdweide>: it was very simple in this first implementation. It checks for a single boolean for whether or not to apply wall functions (WALL_FUNCTIONS= YES or NO, https://github.com/su2code/SU2/blob/43b8a4015c4b09b01d78e4243d32011c663c2b70/SU2_CFD/src/solver_direct_mean.cpp#L15339), and then assumes they should be applied to all no-slip walls (heat flux or isothermal, https://github.com/su2code/SU2/blob/43b8a4015c4b09b01d78e4243d32011c663c2b70/SU2_CFD/src/solver_direct_mean.cpp#L16653). This could of course be made more specific for individual markers using a config structure like MARKER_MONITORING to list the",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/399#issuecomment-327313634:690,test,tested,690,https://su2code.github.io,https://github.com/su2code/SU2/issues/399#issuecomment-327313634,1,['test'],['tested']
Testability,"All,. The following page has performance comparisons between eigen and mkl (and others):. http://eigen.tuxfamily.org/index.php?title=Benchmark. They are dated 2011, so they are a bit old, but if the quoted performance is real, I would say it is a no-brainer to switch to eigen. If the performance tests (for at least simple things like daxpy and gemm) could be repeated to verify the numbers, that would help us make a final decision. Best,. Juan. On Feb 2, 2019, at 1:58 AM, Edwin van der Weide <notifications@github.com<mailto:notifications@github.com>> wrote:. @pcarruscag<https://github.com/pcarruscag>, I agree with you it will be hard to beat the MKL (running at 60 percent peak for most of the gemm calls for the DG-solver), but if you don't have any performance loss, that would already be nice, as it improves readability. Furthermore, the performance of the DG solver in combination with the discrete adjoint is horrible, because it relies on my very naive implementation of the matrix products. So it would already be something if we can get an improvement there, although we do not use the DG adjoint solver (yet). For me the easiest way to test things out for the DG-solver would actually be in SU2 itself. @economon<https://github.com/economon> put some nice profiling routines in there for the gemm calls, which can be used without any additional work to test eigen. @pcarruscag<https://github.com/pcarruscag> (or somebody else), could you create a branch in which eigen is downloaded in the external directory? I think I can manage from there. Thanks,. Edwin. —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/643#issuecomment-459952137>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADpSxCgydwy1nS3qPJvyCMJXLXWNMSFsks5vJWEkgaJpZM4adbAo>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/643#issuecomment-459986613:297,test,tests,297,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459986613,3,['test'],"['test', 'tests']"
Testability,"Also works for me now! Thanks for fixing this. ~~Travis failed due to reaching the maximum time for a job. The usual time the serial test take in other PRs is like 45 min, but this one was killed after 1h 9 min. Is there something that could go wrong in the non-mpi case ?~~. ~~I just restarted the tests to see whether it occurs again.~~ . Now it has passed. If it happens again, simply restart the job in Travis ...",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/328#issuecomment-264239270:133,test,test,133,https://su2code.github.io,https://github.com/su2code/SU2/pull/328#issuecomment-264239270,2,['test'],"['test', 'tests']"
Testability,"And here is a simple test case demonstrating potential use. A major benefit of the supersonic inlet is being able to model supersonic propulsion systems, such as a scramjet, where the propulsion system exit boundary is modeled as a supersonic inlet, with distinct properties from the farfield flow conditions. Here we have a two dimensional test case demonstrating the interaction of exhaust flow with free-stream flow at the exit plane of a 2D scramjet system. Flow conditions adapted from [A Design Method for Three-Dimensional Scramjet Nozzles with Shape Transition](https://arc-aiaa-org.stanford.idm.oclc.org/doi/abs/10.2514/1.B38293); Jens Kunze, Michael K. Smart, and Rowan Gollan; Journal of Propulsion and Power 2022 38:1, 3-17. <img width=""1262"" alt=""image"" src=""https://user-images.githubusercontent.com/44848904/211415971-b6122204-0d95-43ca-903b-d60fd6326c39.png"">",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1862#issuecomment-1375043856:21,test,test,21,https://su2code.github.io,https://github.com/su2code/SU2/pull/1862#issuecomment-1375043856,2,['test'],['test']
Testability,"As requested, here's an example of a unit test that I made. For context: There's a couple of different modes for the Roe-low-dissipation convective blending. If one of the ""DUCROS"" modes is selected, then the Ducros sensor values are used. Otherwise, they're ignored. Before commit [ac8b3bf](https://github.com/su2code/SU2/commit/ac8b3bf7636cc66ca7f47e15935942a6598e1a9f), the `SetRoe_Dissipation` function checked to see if the sensor values were valid regardless of the type of blending selected. Commit [ac8b3bf](https://github.com/su2code/SU2/commit/ac8b3bf7636cc66ca7f47e15935942a6598e1a9f) changed the behavior to only check the sensor values if they will be used. The unit test sets the convective blending to `NTS`, feeds invalid sensor values into `SetRoe_Dissipation` and checks the output. ```cpp; // Used to set the Roe-low-dissipation option; void WriteCfgFile(unsigned short nDim, const char* filename,; std::string blending) {; std::ofstream cfg_file;. cfg_file.open(filename, ios::out);; cfg_file << ""PHYSICAL_PROBLEM= NAVIER_STOKES"" << std::endl;; cfg_file << ""ROE_LOW_DISSIPATION= "" << blending << std::endl;. cfg_file.close();; }. BOOST_AUTO_TEST_CASE(BadSensorsAllowedForNTS) {. /*--- Setup ---*/. const unsigned short nDim = 3;. /*--- Set up the config class for the test ---*/; char cfg_filename[100] = ""convective_blending_test.cfg"";; WriteCfgFile(nDim, cfg_filename, ""NTS"");; CConfig* config = new CConfig(cfg_filename, SU2_CFD, 0, 1, 2, VERB_NONE);; std::remove(cfg_filename);. /*--- Inputs ---*/; const su2double dissipation_i = 0.4;; const su2double dissipation_j = 0.6;; const su2double sensor_i = NAN; // Intentionally unphysical:; const su2double sensor_j = NAN; // Intentionally unphysical:. /*--- Outputs ---*/; su2double dissipation;. /*--- Test ---*/. CNumerics numerics;; numerics.SetRoe_Dissipation(dissipation_i, dissipation_j,; sensor_i, sensor_j,; dissipation, config);. const su2double tolerance = std::numeric_limits<su2double>::epsilon();; BOOST_CHECK_CLOSE_F",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499999225:42,test,test,42,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499999225,2,['test'],['test']
Testability,"Bumping this thread... Files are now starting to be divided in several PRs, but we should set a clear policy for this. Seems that the consensus is to carry one class per file, move the inlines to the headers, and create subfolders where possible (i.e., have a more flat hierarchy in the src directory based on logical groups such as numerics, geometry, solvers, etc). We do not have a clear naming convention yet, but if it is one class per file, then an option is simply the class name. Am I capturing the current consensus correctly? Anything I am missing? Naming preferences?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/583#issuecomment-500945013:310,log,logical,310,https://su2code.github.io,https://github.com/su2code/SU2/issues/583#issuecomment-500945013,1,['log'],['logical']
Testability,"Charanya,. thanks for the detailed answer. Let me ask you some more info. Apparently, you where able to reproduce the results I had comparing the two code versions simply using different boundary conditions on the latest code version. Can you specify me how?. Tobi,. In the meanwhile, to narrow down the problem, I ran also a couple tests in 2D to seek confirmation. For the (Euler) **pitching_NACA64A010.cfg** test case in the repository I rerun the same test at AoA of 1 deg and removing the pitching (no mesh deforming). I attach config files and summaries relative to the test cases. [config_CFD_6_2_0.txt](https://github.com/su2code/SU2/files/3938858/config_CFD_6_2_0.txt); [Summary_6_2_0.txt](https://github.com/su2code/SU2/files/3938859/Summary_6_2_0.txt); [config_CFD_6_0_1.txt](https://github.com/su2code/SU2/files/3938863/config_CFD_6_0_1.txt); [Summary_6_0_1.txt](https://github.com/su2code/SU2/files/3938865/Summary_6_0_1.txt). In this case the situation is definitely better as the two solvers give the same results. It looks like it is an issue related to the 3D case. <img width=""1220"" alt=""Screenshot 2019-12-09 at 11 27 27"" src=""https://user-images.githubusercontent.com/23583209/70424365-f316a780-1a77-11ea-8f68-4fc83e188ed7.png"">. I also quote Charanya in saying that it is definitely good that convergence to same values is reached but the transient response is fundamental and holds physical/mathematical values (I think of Wagner et similia) :). I would also suggest to add a regression test in this sense. Best, ; Rocco",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/828#issuecomment-563150217:333,test,tests,333,https://su2code.github.io,https://github.com/su2code/SU2/issues/828#issuecomment-563150217,5,['test'],"['test', 'tests']"
Testability,"Check out the branch [fix_inlet_file_shape_opt](https://github.com/su2code/SU2/tree/fix_inlet_file_shape_opt). There's just one commit that differs from develop (921e85b9d7d9c152c131874a84f3534caf5705c2). I tested it on a simple case, and it seemed to work. But I don't have any more complex test cases to test it on. All my ""complex"" test cases involve other features not merged with develop. You can either merge that branch or (if your branch is not up to date with develop) cherry-pick the commit.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/970#issuecomment-627095055:207,test,tested,207,https://su2code.github.io,https://github.com/su2code/SU2/issues/970#issuecomment-627095055,4,['test'],"['test', 'tested']"
Testability,"Clark,. Thanks for putting this idea out there. In my experience, unit testing has been an intrinsic part of the the modus operandi in many multi-physics codes at DoE and has been well worth the additional effort. In cases where it makes sense (as described by Clark and in the Stack Exchange discussion) I would advocate for using it moving forward. There may also be some issues that arise multiple times in existing code where a retroactive application of unit testing may also make sense. I am copying Pat Miller, formerly with DoE, who may have more experience on whether such unit testing approaches were useful/worth the investment in some major codes he worked on. Best,. Juan. On Jun 4, 2019, at 2:14 PM, Clark Pederson <notifications@github.com<mailto:notifications@github.com>> wrote:. I propose adding a unit-testing framework and unit-tests to SU2. After chatting with @economon<https://github.com/economon>, I've decided to move the discussion here to get additional input. What is unit testing?. For those not familiar with unit testing, unit testing allows the testing of small bits of behavior, ideally using isolated bits of code. It is not intended to replace validation testing or formal verification tests. Instead, it serves a unique purpose. Consider the three following use cases:. * You're developing a new feature, and you want to test it to see if it works. You could do a full simulation, but that takes a lot of time and computing power. You want to check if your new behavior behaves as you suspect before you throw a lot of resources at it.; * You submit a PR and discover that one of the regression tests has failed. But...why? You know that something is broken, but its hard to track down what broke. You want more granular test coverage that can demonstrate what broke.; * You are fixing a very small bug. You know that you should prove that your bug fix worked, but it doesn't seem logical to dedicate an entire validation case to one small bug fix. You want to writ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499250240:71,test,testing,71,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240,6,['test'],"['testing', 'tests']"
Testability,"Dear Dr Albring,. I just followed the procedures and included the files to create a test case to SU2_CFD_AD [a coarse mesh, a TargetCp.dat and a config file for an Arina nozzle. The coarse mesh is a 2000 triangles one; which is enough to give us an idea of the shockwave location and the geometry modifications. The next mesh I have would be an ~85000 elements which gives us a good information on the 27th function call]. ; I had some segmentation faults during long jobs: Is there some recommended tuning I can do on OS/HW or SU2 in order to minimize them?. With kind regards,. Jairo. > On Dec 7, 2018, at 09:45, Jairo Paes Cavalcante Filho <jairo.pcfilho@gmail.com> wrote:; > ; > Hello Dr. Albring,; > ; > Yes! Sorry for the delay due some internal presentations and events here.; > I just finished a small model and successfully tested it on openSUSE. I expect to upload it today.; > ; > With kind regards,; > ; > Jairo; > ; >> On Dec 7, 2018, at 06:35, Tim Albring <notifications@github.com <mailto:notifications@github.com>> wrote:; >> ; >> Hi Jairo,; >> ; >> what is the status here ? Is it possible to provide a simpler (smaller) case ?; >> ; >> —; >> You are receiving this because you were mentioned.; >> Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/pull/600#issuecomment-445175541>, or mute the thread <https://github.com/notifications/unsubscribe-auth/Ac180u4PogeqhPW9rrfY4mW705IYKjvhks5u2jZpgaJpZM4X34F2>.; >> ; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/600#issuecomment-445429636:84,test,test,84,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-445429636,2,['test'],"['test', 'tested']"
Testability,"Dear Dr. Economon,. I just finished the run on AD with the files you have adjusted and it did; converge. I also have successfully run some simple inverse design tests; with a limit on the number of cycles.; Thank you very much for your guidance and help. With kind regards,. Jairo. On Wed, Jan 30, 2019 at 2:13 PM Thomas D. Economon <notifications@github.com>; wrote:. > *@economon* approved this pull request.; >; > LGMT. Thanks @jaspe55 <https://github.com/jaspe55>; >; > Just one request: I have adjusted the number of iterations for the; > regression test and updated the residual values in the python script. I; > also had to move around some files. Can you please run the case (to; > convergence) and verify that the results are what you expect? Note that the; > config file and target Cp are in the code repository and the mesh and; > solution file are in the testcases repository. If everything looks ok, then; > this is ready to be merged.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/pull/600#pullrequestreview-198200089>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/Ac180hqzVnSUPCnSBkQrTPfIv0kIltygks5vIdKrgaJpZM4X34F2>; > .; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/600#issuecomment-459568514:161,test,tests,161,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-459568514,3,['test'],"['test', 'testcases', 'tests']"
Testability,"Dear Heather,; I am analyzing a propeller of an UAV. I have static thrust measurements such that when I used Euler results I got 3.5 lbf thrust as compared to the measured 6 lbs. My next step was to perform an NS equation with SA turb model. I got 7 times over predicted results such that the mesh has a Y+ of less than 1. Then I thought of doing an SST but was not long enough that it gave me error with divergence. I have been setting up my SST case as per the tutorial example of NACA0012. However, I do not happen to see any entry with regards to eddy frequency etc. (usually required by SST) in the config file. Any guidance will be great.; Thanks; Jehan; From: Heather Kline notifications@github.com; To: su2code/SU2 SU2@noreply.github.com ; Sent: Tuesday, May 12, 2015 11:43 AM; Subject: [SU2] Feature deallocation (#174). Bringing this branch up to date with current develop branch. ; Various deallocation changes; Some regression tests fail but all run. (previously was not the case); You can view, comment on, or merge this pull request online at:;   https://github.com/su2code/SU2/pull/174; Commit Summary; - Updated GetEngine_Properties; - Fix to the last commit; - Small bug; - Merge branch 'develop' into feature_MPI; - merging; - SU2_SOL and SU2_CFD are working; - Preliminary, but complete, implementation of SU2_DEF; - More updates; - Working version; - Complete implementation (validate); - Working version of SU2_DEF; - Final push before moving to the develop branch; - New MPI (removing SU2_PRT); - Merged in Ben's ParMETIS integration and fixed some conflicts.; - Merge branch 'benkirk-parmetis_integration' into feature_MPI; - ParMETIS geometry routines have been copied over but are not activated yet.; - Small change to ParMETIS include.; - ParMETIS can now be activated for testing (PARMETIS=YES in config).; - Updated MG; - Updated EA subrotuine; - Small fix; - Fixing memory leak; - Fixing memory leaks; - Dev release v.3.2.6; - Increasing MAX_NUMBER_MARKER; - Working versi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:939,test,tests,939,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['test'],['tests']
Testability,"Dear all, ; I have added a pdf file here that includes some test case results obtained with our BC transition model. These zero pressure gradient and variable pressure gradient flat plate test cases are very popular for model validation. I have also included Eppler E387 airfoil results. I would appreciate if you have any 3-D test case and share it with me.; Looking forward to hear your feedback. ; Sincerely,; Samet. [BC_model_TestCaseResults.pdf](https://github.com/su2code/SU2/files/562425/BC_model_TestCaseResults.pdf)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/326#issuecomment-257360833:60,test,test,60,https://su2code.github.io,https://github.com/su2code/SU2/pull/326#issuecomment-257360833,3,['test'],['test']
Testability,"For the time being, lets use Gitter to communicate! Its free and you can simply log in with your github account. https://gitter.im/su2code/community",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/645#issuecomment-515048317:80,log,log,80,https://su2code.github.io,https://github.com/su2code/SU2/issues/645#issuecomment-515048317,1,['log'],['log']
Testability,"Good Morning,. I'm from Chair of Thermal Engineering of Poznań University of Technology.; In August 2017 my colleague and I attended SU2 Summer School in; Kaiserslautern and met the Sci-Comp team developing the SU2. I think moving the main tutorials to the main repository is a good idea. We; declared to contribute some validation cases and written tutorials and; having this in main repository will ease the process of adding/modifying; the docs to a simple pull request. I also have a suggestion regarding the Test Cases and Tutorial files. I; apologize if this is the wrong place or this has been discussed already,; but still will give it a try:; - Test cases folder from SU2/su2code repository shall be moved to the; SU2/TestCases repository. Rationale: this makes one repository to store the; test case *.cfg files and mesh files.; - There shall be a TestCases/Mesh folder to store all the meshes needed for; Test Cases files, without subdivisions for RANS, Euler etc subfolders.; Considering that multiple test cases use the same mesh and all the mesh; files are distinct, this solution generates one place to store all the mesh; files. Should a user perform a test case, he/she will find the mesh by name; referenced in the *.cfg file instead searching thru multiple folders. This; will also help avoiding unnecessary copies of mesh files.; - The same should be done for Tutorial files: Tutorial/Mesh folder for; storing meshes (duplicating these few files from TestCases/Mesh should not; be a problem IMO, but will really help a new user to get up to speed with; SU2); - I have no clear opinion on where the Tutorial files folder should be; stored. But considering moving written tutorials to main repository i think; that tutorial files should also be stored in main SU2/su2code repository. Best regards and Happy New Year; Jędrzej. 2017-12-30 23:45 GMT+01:00 Tim Albring <notifications@github.com>:. > What do you think of moving the written tutorials also to the main; > repository ? Then",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/485#issuecomment-354736415:800,test,test,800,https://su2code.github.io,https://github.com/su2code/SU2/pull/485#issuecomment-354736415,1,['test'],['test']
Testability,"Hello Dr. Albring,. Yes! Sorry for the delay due some internal presentations and events here.; I just finished a small model and successfully tested it on openSUSE. I expect to upload it today. With kind regards,. Jairo. > On Dec 7, 2018, at 06:35, Tim Albring <notifications@github.com> wrote:; > ; > Hi Jairo,; > ; > what is the status here ? Is it possible to provide a simpler (smaller) case ?; > ; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/pull/600#issuecomment-445175541>, or mute the thread <https://github.com/notifications/unsubscribe-auth/Ac180u4PogeqhPW9rrfY4mW705IYKjvhks5u2jZpgaJpZM4X34F2>.; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/600#issuecomment-445209093:142,test,tested,142,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-445209093,1,['test'],['tested']
Testability,"Hello Dr. Economon,; ; At this moment, I am running a case which is lighter but sill not very simple (I am running it on a Mac with four cores, and it will finish by Monday, I suspect). As soon as it successfully completes, I will work on a simpler sample case in order to include it in the test suite, willing God. With kind regards,. Jairo. > On Nov 16, 2018, at 16:12, Thomas D. Economon <notifications@github.com> wrote:; > ; > Thanks, @jaspe55 <https://github.com/jaspe55> ! LGTM. I don't think we have any tests for the inverse design capability. Do you have a very simple test case that we can put into the regressions for this capability? I think you are working on a nozzle design.; > ; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/pull/600#issuecomment-439496260>, or mute the thread <https://github.com/notifications/unsubscribe-auth/Ac180nOm5nOlpnYLID7YMRQeFOsAZQJYks5uvw4MgaJpZM4X34F2>.; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/600#issuecomment-439506935:291,test,test,291,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-439506935,3,['test'],"['test', 'tests']"
Testability,"Hello everyone. I am working with SU2 on the feature_adap branch and have come across an issue during the execution of the mesh adaptation script. After following the standard installation procedure and verifying the installation (the exact same steps that @chesiv presented), I encountered a problem when running the mesh_adaptation_amg.py script. The command used was:. ```; python3 $SU2_RUN/mesh_adaptation_amg.py -f adapt_Mesh.cfg -n 4; ```; The script initiates the mesh adaptation process as expected, with the following output:. ```; SU2-AMG Anisotropic Mesh Adaptation. Mesh adaptation options:; PYADAP_COMPLEXITY : (30000, 60000, 120000); PYADAP_SUBITE : (2, 2, 2); PYADAP_SENSOR : GOAL; PYADAP_HMAX : 500.0; PYADAP_HMIN : 1e-9; PYADAP_HGRAD : 1.8. ./adap exists. Removing old mesh adaptation in 10s.; The ./adap folder was deleted. Generating GMF background surface mesh.; Initial CFD solution is provided.; ```; However, no _adap\ite0_ folder gets created. ; The log.err file in the _adap/ini_ directory provides this traceback:. ```; Traceback (most recent call last):; File "".../mesh_adaptation_amg.py"", line 111, in <module>; ...; RuntimeError: ...; Error in TokenizeString(): two or more options before an ""="" sign in the configuration file.; terminate called after throwing an instance of 'int'; ...; *** Process received signal ***; Signal: Aborted (6); Signal code: (-6); ...; ```. The critical part of this error seems to be the Error in TokenizeString() message, suggesting an issue with parsing the configuration file. This error typically indicates a syntax problem, such as having multiple options on a single line without proper separation by an equal sign (=). However, upon reviewing _adap/ini/config_CFD.cfg_, was unable to find any lines that clearly violated this syntax rule. Could this error be indicative of a more subtle issue within the configuration file, or might it be related to specific aspects of the feature_adap branch? Any insights, suggestions, or guidance ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/948#issuecomment-1847333809:974,log,log,974,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-1847333809,1,['log'],['log']
Testability,"Hello,. I have been debugging the differences between the two versions. I found 5 differences that lead to slightly different results. Two of them have been verified to be an improvement of physical modelling. The other 3 I am still trying to figure out. Could you please run the same tests with MUSCL_FLOW=NO and see if you're still facing this issue?. I see that the MUSCL reconstruction is one of the 3 things that have been modified and not sure if could be the cause of the problem or not. I will keep working on understanding the impact of the other 2 things. When you do this - could you please save the simulation output log of both versions and send those back to me too (in this way I'll have a better feeling of what is happening to the residuals throughout the simulation)? We can just focus on the invbb case to make it simpler.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/2026#issuecomment-1562975684:285,test,tests,285,https://su2code.github.io,https://github.com/su2code/SU2/issues/2026#issuecomment-1562975684,2,"['log', 'test']","['log', 'tests']"
Testability,"Hello,. So, to clarify, there were two issues:. 1) With the old commit (382e82f), we were seeing the assertion failure at line 1881 of numerics_structure.cpp, but only with the very large mesh (180 million cells). 2) With the newer commit (c093a62), we were seeing the assertion failure at line 294 of C2DContainer.hpp, which was occurring even with smaller meshes (7 million cells). The solution to (2) appears to be to change `geometry->node[iPoint]->GetnNeighbor()` to `geometry->node[iPoint]->GetnPoint()` at line 3759 of CEulerSolver.cpp, in the `CEulerSolver::SetUpwind_Ducros_Sensor()` method. I made this change locally, and attempted to run on our large mesh. Issue (2) seems to be fixed, but we still run into issue (1). I have now gone through the read restart routines, and have found a potential issue:. For reference, the restart file for our large mesh with averaging data included consists of:; 39 fields * 75,107,967 points = 2,929,210,713 variable values (which is larger than `INT_MAX`). Beginning at line 3931 of CSolver.cpp, in method `CSolver::Read_SU2_Restart_Binary(...)`, we have the following:. ```; int *blocklen = new int[geometry->GetnPointDomain()];; int *displace = new int[geometry->GetnPointDomain()];; int counter = 0;; for (iPoint_Global = 0; iPoint_Global < geometry->GetGlobal_nPointDomain(); iPoint_Global++ ) {; if (geometry->GetGlobal_to_Local_Point(iPoint_Global) > -1) {; blocklen[counter] = nFields;; displace[counter] = iPoint_Global*nFields;; counter++;; }; }; MPI_Type_indexed(geometry->GetnPointDomain(), blocklen, displace, MPI_DOUBLE, &filetype);; ```; The problem here is that for our case, where `iPoint_Global` can get up to 75,107,967 and `nFields` = 39, the value assigned to `displace[counter]` in the loop can over-run `INT_MAX`. This would result in potential garbage / incorrect displace values being passed to `MPI_Type_indexed(...)`. Unfortunately, simply changing `displace` to a `long int *` won't work, as the expected argument type for `",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/949#issuecomment-622026420:101,assert,assertion,101,https://su2code.github.io,https://github.com/su2code/SU2/issues/949#issuecomment-622026420,2,['assert'],['assertion']
Testability,"Here is the patch from the develop branch. As I stated before, this adds the 'increment-progress' logic to the vertex export process; this causes the sub-progress bar to shows the progress of the vertex export for a more accurate experience. Thanks again,. Ethan Alan",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/72#issuecomment-56592650:98,log,logic,98,https://su2code.github.io,https://github.com/su2code/SU2/pull/72#issuecomment-56592650,1,['log'],['logic']
Testability,"Hey Rocco,. > And both versions are/were on the develop branches -> what exactly do you refer to here: config-files, code, mesh. The code tags 6.0.1 and 6.2.0 refer to specific master-commits of the code. So I want to know what is exactly of the develop branch, can't be the code if you understand the tags as I do. Maybe you refer to the develop code at the time where these tags were introduced. But maybe sth different. > I guess they converge eventually to the same values. I tried to compare the same case but steady (I attach the summary). Results in this case are fairly similar and (in my opinion) raise no warnings. That is good to hear. ; Luckily @cvencro (Thanks for that 👍 ) ran some tests and found that #740 (which rewrites Euler Wall boundaries for compressible and incompressible flows ... which was me btw) introduces the changes you see. The Euler wall for compressible is changed a bit in the way the boundary condition is enforced. Upon convergence both version should recover (close to) the same value. If the results in a steady state are the same/very-similar and if an unsteady simulation at low enough Reynolds-number converges to the same steady result (or oscillate in the same bounds) -> I would say it is simply some purely numerical effect based on the unphysical initialization and different treatment of the euler wall boundary. . 1 thing one could test additionally is to force a very high convergence in each physical timestep, i.e. usually one converges ~3 orders of magnitude in each ts -> now try converging until residual stalling in each ts. If the code versions get the same/closer results in the temporal evolution my euler wall boundary explanation would be quite reasonable.; Together with the long running unsteady simulation proposed above, I would feel more comfortable to judge. @cvencro (bringing the conversation to this place 😉 ) concerning the pitching case: the `if (dynamic_grid)` statements in the 'old' version are not necessary as that is handle",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/828#issuecomment-562621057:696,test,tests,696,https://su2code.github.io,https://github.com/su2code/SU2/issues/828#issuecomment-562621057,1,['test'],['tests']
Testability,"Hey,. @cvencro and I were discussing this issue quite a bit this morning and here an attempt of a summary:. We are looking at the following cases:; 1. 3D Onera m6, compressible euler, including euler_wall and sym_plane ; a. steady state; b. unsteady (no pitching, deforming); 2. 2D NACA64A010, compressible euler, including euler_wall; a. unsteady (no pitching/ deformation); b. pitching (with rigid and with deforming mesh -> used for the gradient validation of @cvencro 's post ). We are rather certain that the differences between the code-versions are due to the new euler_wall boundary which was introduced in #740 (by me :) ). @cvencro did a test where the old euler_wall was simply pasted into the newer function body (which currently directly calls the sym_plane boundary) -> that recovered the results obtained with the 'older' version. The steady state results (onera m6) show that both codes deliver the same results (of course with some minor differences). So far so good. Unsteady cases are a bit trickier: the latest 2D results of @RoccoBombardieri show pretty much no difference including the first timesteps. The onera m6 case in contrast converges to the same (steady-state) results for both code version eventually but their initial transient phase differs quite significantly. . A possible explanation for the different initial transient phase: In both implementations a ""reflected state"" is constructed where the normal component of the velocity is subtracted [once in the older code version & twice in the newer version]. I.e. subtracting the normal component of velocity twice means mirroring the velocity along the symmetry plane. The newer code version is a bit ""stronger"" in enforcing the boundary conditions which could lead to the reduced oscillation in CD and CL. If we agree that both code versions produce physically correct results for steady cases and unsteady cases that were integrated long enough in time to get rid of the influence of the initial condition ... then",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/828#issuecomment-563314747:648,test,test,648,https://su2code.github.io,https://github.com/su2code/SU2/issues/828#issuecomment-563314747,1,['test'],['test']
Testability,"Hi @Eduardo-Carvalho ,. your request is now merged into the develop branch and you can test/use it if you like. It will be in one of the next releases, if no further issues occur.; Handling is intuitive: Just set your restart iteration in the config file as you would do normally and activate the restart solution option. Furthermore, place your restart file (two in the case of 2nd order time integration) in the same directory as the config file of your test case. Then you are set up and can run the scripts as normal. ; For more details, I refer to pull request #964. . Best; Steffen",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/909#issuecomment-630289600:87,test,test,87,https://su2code.github.io,https://github.com/su2code/SU2/issues/909#issuecomment-630289600,2,['test'],['test']
Testability,"Hi @EduardoMolina . I will add this in the test repo. It is a standard case used in majority of the papers (relevant).; What are the changes/additions I need to carry out , can you guide me with the procedure of adding the test case in repo. Regards; Amit",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/631#issuecomment-455009027:43,test,test,43,https://su2code.github.io,https://github.com/su2code/SU2/pull/631#issuecomment-455009027,2,['test'],['test']
Testability,"Hi @Nicola-Fonzi,. I'm not 100% sure of the reasons behind the GetFSI_Simulation criteria. I'd imagine that the nMarker_Fluid_Load might have been included there to make sure that a problem is treated as FSI only if there is transfer of load from the fluid to the structural domain, even if both zones existed independently in the config. But since the GetFSI_Simulation check is set up as an ""or"" rather than ""and"", as long as one of them is satisfied, the logic will be true for an FSI simulation, which might be sufficient for your application?. For the velocity transfer, I agree with Rafa that it would be better if you could also transfer the velocity from the external structural solver. If an external structural solver is used for dynamic analysis, it probably can output the structural velocities as well as the structural displacements? I left the methods for the recalculation of the grid velocity using finite differences in the code to support fluid-only problems with dynamic grid motion, I wouldn't suggest this as the method for FSI problems. For primal analysis, results from both methods agree with FSI benchmark cases but if you are interested in adjoint analysis at any point, transferring the velocity information from the structural domain directly to the fluid domain gives a significant simplification and improvement to the gradients.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1174#issuecomment-778368854:458,log,logic,458,https://su2code.github.io,https://github.com/su2code/SU2/pull/1174#issuecomment-778368854,2,"['benchmark', 'log']","['benchmark', 'logic']"
Testability,"Hi @antares190,. Glad to see that things seem to be starting to work for you. We (Brian) are trying to improve this capability in the solver and any experiences / suggestions / help will be welcome. With that said, this seems like an interesting result. Would you mind submitting it (or other pictures that you like better) so the SU2 Foundation can use it to show this capability to others in the future? The link where you can do this is here<http://su2foundation.org/su2-promotional-material/?utm_source=hs_email&utm_medium=email&utm_content=76584389&_hsenc=p2ANqtz-9fEq2awKk2vd155cCcN_N4mWBCZK-rJ-TqNsZhqSJs-VWn-w7q-H6w8sdiA3LyuOTqlK4eqZhFFstKi-LQFyyGqYPdkwYc9JsNdB1yyd7pqMwTFzA&_hsmi=76584389>. Thanks a lot,. Juan. On Apr 29, 2020, at 1:38 PM, antares190 <notifications@github.com<mailto:notifications@github.com>> wrote:. Thanks Brian,; my bad, I misinterpreted the carpets / logs structure. I successfully ran a test of a very simple case. In the results there are some small artifacts, but the shocks are resolution improved consistently after mesh adaption.; Thanks for the support. [Comparison]<https://user-images.githubusercontent.com/41752169/80644172-84a7a580-8a69-11ea-9f16-58e98c808b73.png>; [ComparisonMesh]<https://user-images.githubusercontent.com/41752169/80644174-85403c00-8a69-11ea-819f-2ac00550a089.png>. —; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/948#issuecomment-621450497>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AA5FFRCGLBHJCB3FS4JSSV3RPCF5RANCNFSM4MQACOXA>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/948#issuecomment-621483859:883,log,logs,883,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-621483859,2,"['log', 'test']","['logs', 'test']"
Testability,"Hi @cvencro , I think it would be good to add that Testcase to the regression tests to 'guard' the code. ; I actually wanted to do that real quick but it guess that with `SINGLEZONE_DRIVER` one cannot access `TIME_ITER`, only `EXT_ITER` with the` .test_iter` variable of the python Testcase class. Not sure if that is addressed in #724 , maybe @rsanfer or @talbring can give a quick info as this is probably affecting all unsteady regression tests. . Concerning the Testcase repo: You can simply open a PR for the develop branch of the Testcase repo, and refer to the corresponding PR here (and vice versa). As far as I know the Testcase repo is not protected, i.e. you can merge without any check. And as it is just one added mesh and no other change you could do it right now from my point of view. Another point: What about the rotating_frame for incompressible flow? If it is untested I would like an error catch in place that this feature can't be used out of the box.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/767#issuecomment-527167827:78,test,tests,78,https://su2code.github.io,https://github.com/su2code/SU2/pull/767#issuecomment-527167827,2,['test'],['tests']
Testability,"Hi @koodlyakshay thanks for making the changes.; By default MPI barriers are ""never"" needed, the normal communication routines already do all synchronization required. Efficiency is probably not fundamental for that routine but this solution feels too complicated somehow, can you attend tomorrow's developers meeting? (I'm getting the ""there's gotta be a simpler way"" feeling, and if we pick the brains of a few people we are certain to find it). In the meantime, if you specify the roughness as a string+double list (exactly like MARKER_HEATFLUX), which is read with `addStringDoubleListOption` you could probably simplify the logic around heatflux and isothermal markers, which would make the setup more user friendly (having to stick with an order is bound to trip someone at some point).; Also the cht interface is ""just"" an isothermal boundary, any reason not to make this feature available for that?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/877#issuecomment-630788337:629,log,logic,629,https://su2code.github.io,https://github.com/su2code/SU2/pull/877#issuecomment-630788337,1,['log'],['logic']
Testability,"Hi @pcarruscag and @vdweide ,. Thanks for creating a test branch and for bringing this discussion. When Brian (@bmunguia ) and I mentioned PETSc, it was an idea to try a different Newton-Krylov (with preconditioner) library in order to improve the convergence of SU2. ; Since the slow convergence of the SU2-FV is the main feedback that I received from other users from industry and academia, I think it worth try an external library and evaluate the performance. ; I will be happy to help test Eigen and see if it is a good candidate. Best,; Eduardo",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/643#issuecomment-460479862:53,test,test,53,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-460479862,2,['test'],['test']
Testability,"Hi @themrdjj,; Thank you for the feedback, there was already a similar report in #796 (which incidentally went stale and was closed), I will try to do something about it, or if you would like to contribute code to the project I can point you to right place to add an error message. Meanwhile my best advice is to not start a config from scratch until you know SU2 very well (and even then...) look for a test case that uses similar features and go from there.; The minimal config is the one in Quickstart, the template is more of a catalog :) I don't think we'll ever have a unified minimal config, SU2 does many things, some mutually exclusive.; Convective options are reasonably well documented here: https://su2code.github.io/docs_v7/Convective-Schemes/; The output messages before ""Begin Solver"" can be helpful (although in this particular case you would need to know what to expect). Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/842#issuecomment-566642727:404,test,test,404,https://su2code.github.io,https://github.com/su2code/SU2/issues/842#issuecomment-566642727,1,['test'],['test']
Testability,"Hi Akshay,. Yes this is a simple fix and it could go in quickly on it's own or as part of another PR. I have this fix already modified in the draft PR #833 which is just pending the addition of a test case. I can add that and move to a PR soon if you are happy to wait?. Best wishes,; Charanya",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/860#issuecomment-582340873:196,test,test,196,https://su2code.github.io,https://github.com/su2code/SU2/issues/860#issuecomment-582340873,1,['test'],['test']
Testability,"Hi Amit,; That is also my intuition, I guess the only way to know if it is worth the extra cost is by doing.; Do you have a good supersonic case I can use for testing (all my work is subsonic)? Preferably something that converges well without initialization.; Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/691#issuecomment-499876619:159,test,testing,159,https://su2code.github.io,https://github.com/su2code/SU2/pull/691#issuecomment-499876619,1,['test'],['testing']
Testability,"Hi Josip,. in the current develop/master these features are still included. However, the plan is to remove these. The reason is simply because of maintenance. We have nobody that can spare time to test the current implementation. If you are willing to do this, please let use know. Tim",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/348#issuecomment-268010192:197,test,test,197,https://su2code.github.io,https://github.com/su2code/SU2/issues/348#issuecomment-268010192,1,['test'],['test']
Testability,"Hi Pedro, thanks for looking into this more. I had run into inconsistencies for FSI problems with relaxation which was the reason for the domain specific calls coming into the multizone driver Update function. With the changes I introduced, the velocity at the interface was being transferred correctly with and without relaxation, so I left it there but it is a bit messy. I'll test with the modified calls for the Relaxation as you suggest. I completely agree that if we can simplify the velocity transfer by just using the velocity directly, then we should. Especially since the predicted velocity is only zero order anyway.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1174#issuecomment-774993325:379,test,test,379,https://su2code.github.io,https://github.com/su2code/SU2/pull/1174#issuecomment-774993325,1,['test'],['test']
Testability,"Hi Pedro, thanks for the idea to update the windowing directly! I've updated addValue such that the values are added for new time only (replaces existing values if it is still the same time iteration). This is a lot simpler and very happy to remove the convoluted logic. The SetUpdate_Averages was still necessary though to pass the regression test for unsteady_cylinder_windowed_average.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1259#issuecomment-819111992:264,log,logic,264,https://su2code.github.io,https://github.com/su2code/SU2/pull/1259#issuecomment-819111992,2,"['log', 'test']","['logic', 'test']"
Testability,"Hi Pedro,. I can confirm that everything is now working correctly. I have tested the sensitivities against gradients from finite difference runs and the results match very closely.; I owe you a big thank you for your help with this, not only has my problem been solved but you also helped me learn a great deal about how the code works. Really appreciate it.; If we ever meet one day then drinks are on me :); Cheers,; Amir",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/679#issuecomment-500911599:74,test,tested,74,https://su2code.github.io,https://github.com/su2code/SU2/issues/679#issuecomment-500911599,1,['test'],['tested']
Testability,"Hi Sun5k,; Thanks for tackling the Transition models. As far as I see, you are adopting the CScalarSolver-Base style just as is done for the Turbulence or SpeciesTransport solver (cf #1330 #1388 ) :+1: I think you can stay close to how things are handled in these solvers. The Turbulence solver has another class in the middle though: `CScalarSolver -> CTurbSolver -> CTurbSST/SASolver` I am not sure whether sth like this makes sense for transition models? (because I have no clue of Transition models). Otherwise the CSpeciesSolver is directly based on the CScalarSolver. Please limit this PR to 1 model only! So in this case just the LM model maybe. It is much easier for you to wrap this PR up with a limited scope instead of trying to do everything at once :) (and it is easier to review for everyone else) In case you then still want to tackle another one once LM is done :D then just open another PR :+1:; ; As unfinished Transition models (or models with a questionable state) are a bit of a companion of SU2 I would also ask you to provide a meaningful testcase with this PR that proves the usability of this feature. I personally like to think of a suitable case at the beginning of development, to adopt a bit a Test-Driven-Development approach but that is of course fully up to you. In case you did not know about the Developers meeting each Wednesday 4pm Berlin time, now you do. You are kindly invited to ask any questions, just show-and-tell to get some feedback etc. it is a very open round :). Happy coding, Tobi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1496#issuecomment-1016451577:1062,test,testcase,1062,https://su2code.github.io,https://github.com/su2code/SU2/pull/1496#issuecomment-1016451577,1,['test'],['testcase']
Testability,"Hi Tim and Ole,. First of all thanks for you great support! I noticed that the convergence of the compressible case was more difficult to obtain, compared to the incompressible case. After fixing this convergence I changed the scale factor for the incompressible and compressible case. I tested the scales 1e-6 up to 10 and 5e-6 up to 5, with a step size of 10. In this reply I posted the results of scale = 0.01, which is behaving properly for the compressible case (Scale 1 of compressible and the test cases of incompressible are not working as expected). During these tests I kept an eye on the surface_adjoint files and in contrary as what Ole expected; the compressible gives a more wavy result. However the deviation of the sens_adjoint of incompressible is huge compare to the compressible case. ![image](https://user-images.githubusercontent.com/21182966/28306613-4425789c-6ba0-11e7-8337-41a99e15ebd2.png). So if I am understanding correctly, in order to determine the sensitivity an initial deviation of the control points has to be set to determine the (dx/dC)-term. In which 'x' indicates discrete points and 'C' control points. . ![image](https://latex.codecogs.com/gif.latex?%5Cfrac%7B%5Cpartial%20J%7D%7B%5Cpartial%20%5Cvec%7BC%7D%7D%20%3D%20%5Cfrac%7B%5Cpartial%20%5Cvec%7Bx%7D%7D%7B%5Cpartial%20%5Cvec%7BC%7D%7D%5Ccdot%20%5Cfrac%7B%5Cpartial%20J%7D%7B%5Cpartial%20%5Cvec%7Bx%7D%7D). Tim do you mean with the current step size the step of dC ? Because the step of the discrete point is set on 0.001 (of_grad_cd.vtk). If you mean the control point step, then there should be a parameterization step in between as well in order to know the influence of dC to dx. This should give a difference in sensitivity results, however the sensitivities of the case of scale = 0.01 and of the case scale =1 are exactly the same (for the compressible and incompressible case). The values below are gradients of the file of_grad_cd.vtk from the compressible case. ![image](https://user-images.githubu",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/409#issuecomment-316018103:288,test,tested,288,https://su2code.github.io,https://github.com/su2code/SU2/issues/409#issuecomment-316018103,3,['test'],"['test', 'tested', 'tests']"
Testability,"Hi Tim,. Thanks!. I totally agree on the fact that Python-related functionalities could be in a separate file for code clarity. Anyway, considering only the C++ structure, those functionalities are still members of the CDriver (and all child classes). So if you are OK with the fact that having members of the same C++ class in different cpp files, I am OK too. . However, if you mean creating a new class for the Python wrapper (like CPyWrapper or whatever), and leave the CDriver ""clean"", this might be more tricky. Indeed, since the wrapper has to be a top-level class, it is better to have access to all the other main classes (config, geometry, solver, ...) and the CDriver was the perfect candidate (it instanciates all of them). So now if we create a new top-level class next to the CDriver, the direct link with all those classes is lost. Basically we will have to create accessors like CDriver::GetConfig(), CDriver::GetGeometry(), ... that will return the different containers to be used by the wrapper. Obviously this is possible but not in a short time, besides this might be a significant change in the top-level code structure. We could also think about exposing thoses CConfig, CGeometry, ... classes to Python in addition to just the driver, I already made some local tests and it worked great but this approach is less user-friendly. David",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/488#issuecomment-352045091:1284,test,tests,1284,https://su2code.github.io,https://github.com/su2code/SU2/pull/488#issuecomment-352045091,1,['test'],['tests']
Testability,"Hi everyone, glad this subject is of interest. I will try to make that test case. I edit my earlier comment to avoid a mess. So I changed the terms. Still not sure but the derivation is simple. source term viscous = (0, tau_xy, tau_yy - tau_thetatheta, u* tau_yx + v* tau_yy - q)/y, right?. then from Bird:. ![IMG_20201027_115003](https://user-images.githubusercontent.com/55834287/97291927-d9767e00-184a-11eb-9418-a3ace3e3a077.jpg). bulk viscosity = 0, any derivative wrt theta = 0. For the generalised inviscid part I am pretty sure it is all correct including the jacobian. You can compare with very similar terms in any generalised flux jacobian like in Glaister's paper https://www.sciencedirect.com/science/article/pii/002199918890174X",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1095#issuecomment-713564781:71,test,test,71,https://su2code.github.io,https://github.com/su2code/SU2/pull/1095#issuecomment-713564781,1,['test'],['test']
Testability,"Hi,. Thank you for your quick answer, It indeed seems that I had some parameters that were passed that did not match su2 version 7.0.3. I am experiencing an issue while running the mesh adaptation process in SU2. The process starts but fails during the mesh generation phase, leading to a FileNotFoundError. I am looking for assistance in resolving this error.; `; SU2-AMG Anisotropic Mesh Adaptation. Mesh adaptation options:; PYADAP_COMPLEXITY : (100, 200, 300); PYADAP_SUBITE : (2, 2, 2); PYADAP_SENSOR : MACH; PYADAP_HMAX : 200; PYADAP_HMIN : 1e-8; PYADAP_HGRAD : 1.3; PYADAP_RESIDUAL_REDUCTION : (3, 3, 3); PYADAP_FLOW_ITER : (500, 500, 500). ./adap exists. Removing old mesh adaptation in 10s.; The ./adap folder was deleted. Generating GMF background surface mesh.; Initial CFD solution is provided. Starting mesh adaptation process. Iteration 0 - Mesh size coefficient 100.0; (1/2) Generating adapted mesh using AMG; AMG done: ; Running CFD; Traceback (most recent call last):; File ""/path/to/SU2/install/bin/mesh_adaptation_amg.py"", line 111, in <module>; main(); File ""/path/to/SU2/install/bin/mesh_adaptation_amg.py"", line 72, in main; options.save_all ); File ""/path/to/SU2/install/bin/mesh_adaptation_amg.py"", line 101, in mesh_adaptation_amg; SU2.run.amg(config); File ""/path/to/SU2/install/bin/SU2/run/amg.py"", line 466, in amg; os.rename(cur_solfil, cur_solfil_ini); FileNotFoundError: [Errno 2] No such file or directory: 'flo.dat' -> 'flo_ini.dat'`. and it0 folder is created, with some log.err and log.out, but they are empty, . I would appreciate any guidance or suggestions on how to resolve this issue. Thank you!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/948#issuecomment-1855842105:1505,log,log,1505,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-1855842105,2,['log'],['log']
Testability,"Hi,. here is the contents of config.log:. ```; This file contains any messages produced by compilers while; running configure, to aid debugging if configure makes a mistake. It was created by SU2 configure 4.1.0, which was; generated by GNU Autoconf 2.69. Invocation command line was. $ ./configure --prefix=/gshare/work/hpascalj/CodeSU2-master --with-CGNS-lib=/gshare/soft/code_saturne/4.0.0/prod/cgnslib_3.2.1/lib --with-CGNS-include=/gshare/soft/code_saturne/4.0.0/prod/cgnslib_3.2.1/include. ## --------- ##; ## Platform. ##; ## --------- ##. hostname = master; uname -m = x86_64; uname -r = 2.6.32-279.el6.x86_64; uname -s = Linux; uname -v = #1 SMP Wed Jun 13 18:24:36 EDT 2012. /usr/bin/uname -p = unknown; /bin/uname -X = unknown. /bin/arch = x86_64; /usr/bin/arch -k = unknown; /usr/convex/getsysinfo = unknown; /usr/bin/hostinfo = unknown; /bin/machine = unknown; /usr/bin/oslevel = unknown; /bin/universe = unknown. PATH: /opt/xcat/bin; PATH: /opt/xcat/sbin; PATH: /opt/pbs/default/bin; PATH: /opt/pbs/tools/bin; PATH: /usr/lpp/mmfs/bin/; PATH: /gshare/soft/star-ccm+/STAR-View+9.02.007; PATH: /gshare/soft/star-ccm+/STAR-CCM+9.02.007/star/bin; PATH: /opt/xcat/bin; PATH: /opt/xcat/sbin; PATH: /usr/lib64/qt-3.3/bin; PATH: /opt/pbs/default/bin; PATH: /opt/pbs/tools/bin; PATH: /usr/lpp/mmfs/bin/; PATH: /usr/local/bin; PATH: /bin; PATH: /usr/bin; PATH: /usr/local/sbin; PATH: /usr/sbin; PATH: /sbin; PATH: /gshare/soft/init; PATH: /gshare/soft/scripts; PATH: .; PATH: /gshare/soft/init; PATH: /gshare/soft/scripts; PATH: . ## ----------- ##; ## Core tests. ##; ## ----------- ##. configure:2465: checking build system type; configure:2479: result: x86_64-unknown-linux-gnu; configure:2499: checking host system type; configure:2512: result: x86_64-unknown-linux-gnu; configure:2532: checking target system type; configure:2545: result: x86_64-unknown-linux-gnu; configure:2587: checking for a BSD-compatible install; configure:2655: result: /usr/bin/install -c; configure:2666: checking whe",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:36,log,log,36,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,1,['log'],['log']
Testability,"Hi,; I went through this work but it is a bit hard to me to completely follow and continue you guys' idea. If you could help finish this issue, I am really willing to do some tests and give feedbacks ASAP. Thanks!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/2275#issuecomment-2098689280:175,test,tests,175,https://su2code.github.io,https://github.com/su2code/SU2/issues/2275#issuecomment-2098689280,1,['test'],['tests']
Testability,"I did few tests (CGNS mesh format), following are the details -; **While trying to use all 8 cores per node (Total 70 nodes, each having 24 GB RAM)-**. Loading section Connect_PRISM of element type Prism.; malloc failed for element data; malloc failed for element data; ............ malloc failed for element data; Error allocating I4->I8 data array...; malloc failed for element data; Error allocating I4->I8 data array...; malloc failed for element data; ................; malloc failed for element data; malloc failed for element data; Loading section Connect_TETRA of element type Tetrahedron. **While trying 6 cores in each node**. Loading section Connect_PRISM of element type Prism.; malloc failed for element data; malloc failed for element data; malloc failed for element data; malloc failed for element data; malloc failed for element data. **Finally settled with 4 cores at each node and memory usage at every node is--** . PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND ; 4652 aero 30 10 872m 746m 10m R 100 3.1 43:03.38 SU2_CFD ; 4653 aero 30 10 1076m 951m 10m R 100 3.9 43:12.10 SU2_CFD ; 4654 aero 30 10 1162m 1.0g 10m R 100 4.3 43:15.15 SU2_CFD ; 4655 aero 30 10 1458m 1.3g 10m R 100 5.5 43:08.96 SU2_CFD . **With above, memory usage seems to be around 16.8 % of 24 GB RAM**. Hope I am not missing something else (some other usage etc...) and what should be the approximate memory requirement for such mesh sizes (around 60 million or is there a general guideline of memory requirement with mesh size for RANS computation with Implicit solver) ?. Regards; Amit",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/291#issuecomment-232018195:10,test,tests,10,https://su2code.github.io,https://github.com/su2code/SU2/issues/291#issuecomment-232018195,1,['test'],['tests']
Testability,"I have a few updates. I found out that most of my FGMRES problems in this branch where related to the fact that I was using single precision for the linear system. You can see it in this graphs for the residuals of Rho. ![RMSRho_Mesh_3](https://github.com/user-attachments/assets/185b8195-e415-4dff-9332-cff573c069cc). The first two curves are in mixed-precision and they stop long before reaching the minimum residual required due to divergence of the linear solver. Moreover, it seems that the 2003 model here implemented (which, simply put, considers the full reynolds stress tensor for the computation of the production of k and always considers k in the stress tensor and in the thermodynamic variables) has faster convergence and increases the recirculating zone (maybe due to the reduction of turbulence kinetic energy) which is a feature that has also been seen in [DOI:10.1017/aer.2020.93]. . ![SFC_Mesh_3](https://github.com/user-attachments/assets/81a50021-6b58-4a84-9057-a18b5bab023c). There are some differences between the use of the TMR boundary conditions and the ones used before. The results improve with respect to the develop in the prediction of the SFC distribution, which has results completely off from the V&V page of SU2. ![SFC_Mesh_3_Old](https://github.com/user-attachments/assets/0f4d634b-df31-4f86-a324-d9f67947f1ff). ![RMSRho_Mesh_3_Old](https://github.com/user-attachments/assets/24d5c2f5-93fe-432f-82d9-c050a90f7339). I may keep on checking if the implementation of the v2003 model is correct or not by searching for other test cases (probably coming from DOI:10.1017/aer.2020.93).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/2329#issuecomment-2393433487:1556,test,test,1556,https://su2code.github.io,https://github.com/su2code/SU2/pull/2329#issuecomment-2393433487,1,['test'],['test']
Testability,"I have added the new option NUM_METHOD_GRAD_RECON to specify a separate method for computing the reconstruction gradient. If that option is not present, then no additional memory is allocated and no extra gradient computation occurs. I have also put in simple feedback from the linear solver residual and the nonlinear residual to the nonlinear controller. If the linear system converges less than a half an order of magnitude, then the CFL is lowered. A Cauchy-like criteria checks for stall in the nonlinear residuals and drops the CFL to the minimum floor to kick the solver out of a rut. Both of these use factors that are empirical from my tests. Will probably be improved with time and more testing, but they do seem to improve behavior. @koodlyakshay : I had success with the inc. laminar backward facing step after adding extra iterations to the linear solve. For some cases, this is necessary to get a large speedup. I am seeing good speedup for most of the cases within our TestCases repo. If you have some tough cases not covered by the repo, please give those a try.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/790#issuecomment-536145232:645,test,tests,645,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-536145232,2,['test'],"['testing', 'tests']"
Testability,"I have covered all operations used in non adjoint use, the non ideal part of the implementation I mentioned above is that the parallelization is ""local"", i.e. we get to the operation we want to make parallel and launch the threads there, for simple vector-vector operations the overhead may be significant.; Ideally we would have a parallel construct at a higher level, say CSysSolve::Solve, so that the threads are already in flight when we get to those small operations.; In principle it is not too hard to do that, but it needs to be done carefully especially when the execution gets to an MPI part of the code (which thread(s) communicate, etc.).; I will try to benchmark this to put numbers on the performance / simplicity trade-off.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/830#issuecomment-560572616:666,benchmark,benchmark,666,https://su2code.github.io,https://github.com/su2code/SU2/pull/830#issuecomment-560572616,1,['benchmark'],['benchmark']
Testability,"I just committed a second round of changes that I would appreciate some feedback on. Compilation is successful with these changes, however, upon testing, I receive the following message: . Error in ""void CConfig::SetConfig_Parsing(std::istream&)"": ; -------------------------------------------------------------------------; Line 271 SPECIFIED_SUPERSONIC_INLET_PROFILE: invalid option name. Check current SU2 options in config_template.cfg.; Did you mean SPECIFIED_INLET_PROFILE?; Line 274 SUPERSONIC_INLET_FILENAME: invalid option name. Check current SU2 options in config_template.cfg.; Did you mean INLET_FILENAME?. I had already adjusted CConfig.cpp to include supersonic inlet profile inputs, but apparently I am not implementing everything I need to. I'm unsure where else I would need to make changes. Any suggestions?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1652#issuecomment-1151296832:145,test,testing,145,https://su2code.github.io,https://github.com/su2code/SU2/pull/1652#issuecomment-1151296832,1,['test'],['testing']
Testability,"I just found [a blog post](https://codingnest.com/the-future-of-catch2/) on the future directions of Catch2. There's a couple of important points for our discussion. The developer plans to adopt a hybrid approach, with:. 1. A stripped-down, header-only version.; 2. A full-feature, typical library (i.e. it must be compiled and linked). This approach is very similar to Boost's setup. Google Test does not offer a header-only version. Additionally, the developer plans to drop C++11 support, and move to C++14. A simpler branch will still support C++03. It's not clear which features are supported in the C++03 variant, and which ones aren't. Google Test is also moving to support only C++11 in their next release, but their current release fully supports pre-C++11. All of this discussion raises the question: Do we want to require C++11 for unit tests?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-500411194:848,test,tests,848,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-500411194,1,['test'],['tests']
Testability,"I see that the Onera M6 mesh is a half-wing with a symmetry plane and I'm not sure how the mesh deformation behaves in this case (for example, there should be zero out-of-plane movement). . Personally, I like really simple examples where I know what should happen (symmetric airfoil, subsonic flow, no sweep) and I did all my testing during the last weeks with the NACA0012 3m wing. At the same time, it is closer to how I would model a ""real"" aircraft (aircraft in the center of a spherical farfield) than the Onera M6, which is more wind-tunnel-like. The mesh and everything is there, so it's no additional work for me and I would be happy to contribute this as a new example. What's the main argument in favor of the Onear M6 wing / objection against a new example?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1954#issuecomment-1547295112:326,test,testing,326,https://su2code.github.io,https://github.com/su2code/SU2/pull/1954#issuecomment-1547295112,1,['test'],['testing']
Testability,"I simple wrote a program to test the grid, which searches for the boundary elements in the single faces, i.e. faces that are only part of one volume element, of the volume grid. What the error message means is that for 4 triangular surface elements of boundary marker BODY there is no corresponding face of the volume elements that is only part of one volume element. . When I include the faces that are shared by two volume elements, only two boundary elements are not found. So in short, you have two boundary elements in boundary marker BODY that are no part of any volume element and two boundary elements that are shared by two volume elements.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/683#issuecomment-494675549:28,test,test,28,https://su2code.github.io,https://github.com/su2code/SU2/issues/683#issuecomment-494675549,1,['test'],['test']
Testability,"I think I implemented all the modifications you suggested. I am sorry you see all the commits in between, unfortunately due to Covid I work outside of office and I actually use Github to push the modified code to the office PC. I was actually working on a separate branch but, for reason that I do not understand, all the commits have been moved in the merging process... sorry about that. I am still learning git. In particular the modifications are:. - The functions related to static mesh deformation have been removed. I only included some new lines in the python wrapper ; that overwrite the initial velocities to zero and push back the solution.; - I now use the BC_Sym_Plane of the FEA solver for the deformation at the symmetry plane. I had to add a flag that avoids ; accessing LinSysReact in case of mesh deformation, as this is not initialised in that context.; - GetnMarker_Match_Deform_Mesh is not present anymore; - The marker has been renamed from MATCH_DEFORM_MESH to DEFORM_MESH_SYM_PLANE. All the functions have also ; been renamed accordingly; - I included the SU2 header in all the new files, changing the version number to 7.0.8. I did not modify the version number of ; the files that were already present in SU2 prior to this PR. I think the merging process should take care of that, am I wrong?; - The python functions that were separated in x,y,z component now give back an array and are merged into one function only; - The descriptions for the methods have been added; - The test case has been removed. I actually prepared a tutorial and all the appropriate files will be placed in the tutorial and ; website repos. I will now perform a PR for those repos so that you can see the material. Again thank you very much and sorry for the mess with the ""internal"" commits. . Please let me know if you think I missed something",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1124#issuecomment-742471972:1502,test,test,1502,https://su2code.github.io,https://github.com/su2code/SU2/pull/1124#issuecomment-742471972,1,['test'],['test']
Testability,"I was running some tests using a simple geometry but for the refinement seems to be chewing up the geometry. Has anyone who has worked on 3D geometries experienced this or figured out a way to avoid this?. I was using the following settings:; ```; % ------------- MESH ADAPTATION PARAMETER ------------%; %; % Type of sensor used for adaptation; % Options include GOAL (adjoint-based), MACH, PRES; PYADAP_SENSOR= MACH; % Maximum cell size for adaptation; PYADAP_HMAX= 500.0; % Minimum cell size for adaptation; PYADAP_HMIN= 1e-9; % Gradation factor (typically 1.2-1.8); PYADAP_HGRAD= 1.8; % Norm used for adaptation; % 1.0 or 2.0 recommended for inviscid flows; % 4.0 recommeneded for viscid; ADAP_NORM= 2.0; % Approximate mesh size (NPOI) at each level; PYADAP_COMPLEXITY= (1000000, 1300000, 1500000); % Number of adaptations performed at each level; PYADAP_SUBITE= (2, 2, 2); ```. ![refine](https://user-images.githubusercontent.com/16842258/104834786-0b94fa80-58e5-11eb-9018-687ffc5aaa9d.png). I noticed a few comments up, there is the `PYADAP_BACK` setting, which sounds like it might solve this, but how should one use this? Should the geometry alone be re-meshed to a high resolution and the whole volume exported as a SU2 block? Or should it be just a surface mesh? (It seems that Pointwise is not able to output only the surface mesh in SU2 format.)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/948#issuecomment-761751741:19,test,tests,19,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-761751741,1,['test'],['tests']
Testability,"I'll weigh in with a more in depth answer on a second email, but yes I've; found great value in being able to have a good set of unit tests. Particularly when you don't have good acceptance tests (hard in a fast; moving research code), it gives a developer confidence that new changes; aren't being fundamental assumptions in the code. It lets sub module; developers build ""armor"" around those assumptions. It is a bit of a cultural thing. People who want robust bits write more.; Some people wire less. At the bank I once worked at, unit tests were required for every module.; Some people wrote code that tested almost nothing. And it would get; through code review that way. Eventually, I added coverage analysis to the check in that exposed this; practice that gave a false assurance that things were ok. More when I can think a bit more on this and get to a real keyboard!. Pat. On Wed, Jun 5, 2019 at 1:50 PM Juan Jose Alonso <jjalonso@stanford.edu>; wrote:. > Clark,; >; > Thanks for putting this idea out there. In my experience, unit testing; > has been an intrinsic part of the the modus operandi in many multi-physics; > codes at DoE and has been well worth the additional effort. In cases where; > it makes sense (as described by Clark and in the Stack Exchange discussion); > I would advocate for using it moving forward. There may also be some; > issues that arise multiple times in existing code where a retroactive; > application of unit testing may also make sense. I am copying Pat Miller,; > formerly with DoE, who may have more experience on whether such unit; > testing approaches were useful/worth the investment in some major codes he; > worked on.; >; > Best,; >; > Juan; >; >; > On Jun 4, 2019, at 2:14 PM, Clark Pederson <notifications@github.com>; > wrote:; >; > I propose adding a unit-testing framework and unit-tests to SU2. After; > chatting with @economon <https://github.com/economon>, I've decided to; > move the discussion here to get additional input.; > What is uni",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499278427:134,test,tests,134,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427,4,['test'],"['tested', 'tests']"
Testability,"I'm late to the party here, but just a note to say that the original implementation for the incompressible source terms are indeed from the text that @WallyMaier / @vdweide shared. It was added as part of the work in this paper (https://economon.github.io/docs/AIAA-2018-3111.pdf), but I did not test it much beyond a simple laminar channel case or really attempt to treat turbulence at the time. Thanks for putting in more effort on these terms!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1095#issuecomment-727633198:296,test,test,296,https://su2code.github.io,https://github.com/su2code/SU2/pull/1095#issuecomment-727633198,1,['test'],['test']
Testability,"I've (finally) managed to go over this pull request. I didn't go into too much detail as I don't want to delay this any more, but in general it all looks great to me. I have run some extra regression tests locally in my computer, and they all seem to be working fine. I also left some comments around, but they are mostly asking for some clarification, no major issues. All cleared from my side. Sorry again for taking way too long, I was so behind myself that I needed to do some merging in my own branches to be able to understand the changes in FSI context... Thanks a lot @LaSerpe for a great work!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/322#issuecomment-258872671:200,test,tests,200,https://su2code.github.io,https://github.com/su2code/SU2/pull/322#issuecomment-258872671,1,['test'],['tests']
Testability,"If you look at the testing history, commit 4f5f3ed doesn't pass the regression tests, while commit 8551cac does. Only two tests are failing on 4f5f3ed: `discadj_topol_optim` and `discadj_fsi_airfoil`. The difference between the two commits is a simple change. I changed the `SU2_MPI::Error` routine to give a return status of `EXIT_FAILURE` instead of `0`. Since `0` is conventionally defined as a successful program exit, returning `EXIT_FAILURE` makes more sense than returning `0` when `SU2_MPI::Error` is called. So why did that change cause the regression tests to fail? My suspicion is that these two tests have been exiting with an error for some time, but these regressions were not picked up by Travis since SU2 kept on returning `0` (i.e. success). Changing the exit code of `SU2_MPI::Error` doesn't cause any errors, but it will expose errors that are (sometimes silently) occurring. @pcarruscag I think you added these tests. Any idea why they're failing?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/649#issuecomment-462951152:19,test,testing,19,https://su2code.github.io,https://github.com/su2code/SU2/pull/649#issuecomment-462951152,6,['test'],"['testing', 'tests']"
Testability,"It is a bit of a cultural thing. People who want robust bits write more.; Some people wire less. At the bank I once worked at, unit tests were required for every module.; Some people wrote code that tested almost nothing. And it would get; through code review that way. Eventually, I added coverage analysis to the check in that exposed this; practice that gave a false assurance that things were ok. More when I can think a bit more on this and get to a real keyboard!. Pat. On Wed, Jun 5, 2019 at 1:50 PM Juan Jose Alonso <jjalonso@stanford.edu>; wrote:. > Clark,; >; > Thanks for putting this idea out there. In my experience, unit testing; > has been an intrinsic part of the the modus operandi in many multi-physics; > codes at DoE and has been well worth the additional effort. In cases where; > it makes sense (as described by Clark and in the Stack Exchange discussion); > I would advocate for using it moving forward. There may also be some; > issues that arise multiple times in existing code where a retroactive; > application of unit testing may also make sense. I am copying Pat Miller,; > formerly with DoE, who may have more experience on whether such unit; > testing approaches were useful/worth the investment in some major codes he; > worked on.; >; > Best,; >; > Juan; >; >; > On Jun 4, 2019, at 2:14 PM, Clark Pederson <notifications@github.com>; > wrote:; >; > I propose adding a unit-testing framework and unit-tests to SU2. After; > chatting with @economon <https://github.com/economon>, I've decided to; > move the discussion here to get additional input.; > What is unit testing?; >; > For those not familiar with unit testing, unit testing allows the testing; > of small bits of behavior, ideally using isolated bits of code. It is not; > intended to replace validation testing or formal verification tests.; > Instead, it serves a unique purpose. Consider the three following use cases:; >; > - You're developing a new feature, and you want to test it to see if; > it works",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499278427:1453,test,testing,1453,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427,1,['test'],['testing']
Testability,"It is not intended to replace validation testing or formal verification tests. Instead, it serves a unique purpose. Consider the three following use cases:. * You're developing a new feature, and you want to test it to see if it works. You could do a full simulation, but that takes a lot of time and computing power. You want to check if your new behavior behaves as you suspect before you throw a lot of resources at it.; * You submit a PR and discover that one of the regression tests has failed. But...why? You know that something is broken, but its hard to track down what broke. You want more granular test coverage that can demonstrate what broke.; * You are fixing a very small bug. You know that you should prove that your bug fix worked, but it doesn't seem logical to dedicate an entire validation case to one small bug fix. You want to write a small test for a small fix. In all of these cases, unit testing fills a unique role. Unit testing increases time spent in development, but decreases the amount of time spent in bug-fixing and maintaining. For more information, see this relevant Stack Exchange question.<https://scicomp.stackexchange.com/questions/206/is-it-worthwhile-to-write-unit-tests-for-scientific-research-codes>. What do I propose?. My research group at UT Austing has implemented a unit testing framework on our branch, which we're happy with. Some choices were arbitrary, and some choices were made based on our development environment. Those choices may be different for other groups. Here's what we have done:. The unit testing framework is compiled and run using autotools. For more information on autotool's setup, see their documentation<https://www.gnu.org/software/automake/manual/html_node/Tests.html>. Since autotools is the build system for SU2, this involves minimal changes. Using automake, the build process for building unit tests becomes:. '''; ./bootstrap; ./configure; make; make check; '''. We use Boost's unit testing framework<https://www.boost.org",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499250240:2095,test,testing,2095,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240,1,['test'],['testing']
Testability,"It would simply take some reorganizing of the test scripts to make one function per case and maybe renaming the `TestCase` class to `RegressionTestCase` or something. For example, I rewrote one of the tests in `serial_regression.py` here: https://github.com/petebachant/SU2/commit/fe0ee432c67540067046fbebf9889660331a6592. Then I could run this with. $ cd TestCases; $ pytest serial_regression.py. the output from which was:. ```; $ pytest serial_regression.py; ======================= test session starts =======================; platform linux -- Python 3.6.3, pytest-3.2.1, py-1.4.34, pluggy-0.4.0; rootdir: /home/pete/SU2/TestCases, inifile:; collected 1 item. serial_regression.py . ====================== warnings summary =======================; serial_regression.py::TestCase; cannot collect test class 'TestCase' because it has a __init__ constructor. -- Docs: http://doc.pytest.org/en/latest/warnings.html; =============== 1 passed, 1 warnings in 92.18 seconds ==================; ```. `pytest` has a bunch of features to control the print output as well.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/462#issuecomment-342677051:46,test,test,46,https://su2code.github.io,https://github.com/su2code/SU2/issues/462#issuecomment-342677051,4,['test'],"['test', 'tests']"
Testability,"It's not required fo initialization. Ok, if it's not going to work in this way let's start a discussion about a proper way to do this. I will create a new PR for just the initialization example and put it in a regression test. Thanks for the feedback.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1960#issuecomment-1464935230:221,test,test,221,https://su2code.github.io,https://github.com/su2code/SU2/pull/1960#issuecomment-1464935230,1,['test'],['test']
Testability,"Mate... I graduated from the school of ""out of the scope of"" with honors ok... You and I know that is just code for ""I'll leave it for someone else"".; Just cut and past the parts of the implementation that are exactly the same as another scheme into a function instead of copying, and given that other NEMO schemes have Jacobians that is probably something you should look into re-using.; You also clicked the box for having added a testcase but I don't see anything, why don't you add the testcase for the pictures and plots you showed? That is the only way for anything in this code to continue working... It's good work, it went into a paper, make it reproducible.; These are the contribution guidelines https://su2code.github.io/docs_v7/Style-Guide/ they may not always make things easier for authors, but they make it easier for the people coming after them.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1773#issuecomment-1276409765:433,test,testcase,433,https://su2code.github.io,https://github.com/su2code/SU2/pull/1773#issuecomment-1276409765,2,['test'],['testcase']
Testability,"Merge and push is simpler I think, and with that the reviewers have the option of only seeing the new commits.; Thanks for the changes, we'll merge once the tests pass.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1951#issuecomment-1470769800:157,test,tests,157,https://su2code.github.io,https://github.com/su2code/SU2/pull/1951#issuecomment-1470769800,1,['test'],['tests']
Testability,"No, I think we're all set. I am going to merge this in. We have two issues that we are going to be clearing up very soon: the ONERA M6 adjoint case that is failing somewhat irregularly, and a reorganization of the test cases/config files to make the regression tests more effective (in particular for pull requests). Thanks for fixing the conflicts!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/186#issuecomment-127486074:214,test,test,214,https://su2code.github.io,https://github.com/su2code/SU2/pull/186#issuecomment-127486074,2,['test'],"['test', 'tests']"
Testability,"No… I can’t. I’m sorry. Great to hear from you. Machine learning is a very valuable research work and I will add it as a feature branch. . Removing code from the main release is a complex task and, as in the past, I have taken tough decisions. Anyway, to maintain a clean code is critical for its growing, it is like trimming a large tree. Basic criteria to maintain forever an implementation on the develop->master branch are: - Clear benefit to the CFD community (more accurate, robust, etc.) - Existing community of users or active developers - Minimal code documentation (at least the options should be in the config file). - Easy to install and use. - The implementation style should be aligned with the SU2 style - Regressions tests. Best,; Francisco. > On Oct 28, 2015, at 11:35 PM, Brendan Tracey notifications@github.com wrote:; > ; > Could you leave in the machine learning section a bit longer?; > ; > —; > Reply to this email directly or view it on GitHub https://github.com/su2code/SU2/pull/208#issuecomment-152095697.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/208#issuecomment-152384158:733,test,tests,733,https://su2code.github.io,https://github.com/su2code/SU2/pull/208#issuecomment-152384158,1,['test'],['tests']
Testability,"OK the failing regression test were due to:; 1. One simple wrong function call in Csolver; 2. Creating new output in existing groups (AERO_COEFF, FLOW_COEFF) which invalidates some regression tests; 3. pyhton code which does not test if some config variable is present or altering the python code such that it invalidates other regression tests; 4. and finally the AVG_TEMP thing above. Now all these alone were somewhat minor things. Feature_flamelet is now up-to-date with develop with all regression test working",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1223#issuecomment-898617272:26,test,test,26,https://su2code.github.io,https://github.com/su2code/SU2/pull/1223#issuecomment-898617272,5,['test'],"['test', 'tests']"
Testability,"Of the two cases with larger residual changes:; - contadj_euler_naca0012 - No idea why they changed, neither primal nor adjoint compute limiters... the primal residuals are unchanged, and the case converges to the same values (residuals and solution) so I simply updated the residuals; - transonic_stator_restart - As shown above the case is fine, so I updated the restart file, however I do not know how to change the testcases branch anymore :) but I guess once the corresponding PR is merged this will start passing. I ran some other tests with the Venkatakrishnan-Wang limiter (which requires a global min/max) and is does not seem to be covered by the tests ATM (maybe I'll use that restart case to fix that), everything looks perfect, same results with different ranks/threads and so on, the results are tens of MB so I won't upload unless someone wants to double check.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/834#issuecomment-575310823:419,test,testcases,419,https://su2code.github.io,https://github.com/su2code/SU2/pull/834#issuecomment-575310823,3,['test'],"['testcases', 'tests']"
Testability,"Ok, I went back to try varying the `.cfg` settings on the simple v7.0.3 repo `TestCases/euler/naca0012` case and managed to get `mesh_adaptation_amg.py` to run successfully. It seems that one bit of advice [from here](https://www.cfd-online.com/Forums/su2/214613-grid-adaptation-options.html) is no longer true, i.e. one needs to set:; ```; % Write binary restart files (YES, NO); WRT_BINARY_RESTART= YES; %; % Read binary restart files (YES, NO); READ_BINARY_RESTART= YES; ```; in order for the amg mesh adaptation to function. However, for some reason, I can't get it working for my actual mesh of interest. When using the same settings, I get a different ParMETIS error (from the `adap/ini/log.out`):; ```; ------------------- Geometry Preprocessing ( Zone 0 ) -------------------; Three dimensional problem.; 4929018 grid points before partitioning.; 7406196 volume elements before partitioning.; 3 surface markers.; 18040 boundary elements in index 0 (Marker = BODY).; 50968 boundary elements in index 1 (Marker = FARFIELD).; 284054 boundary elements in index 2 (Marker = SYMMETRY).; Executing the partitioning functions.; Building the graph adjacency structure.; [ 1] ***ASSERTION failed on line 207 of file ../externals/parmetis/libparmetis/comm.c:sendind[i] >= firstvtx && sendind[i] < lastvtx; [ 1] 361316 123226 246452; [1609857970.901920] [super:1060888:0] sock.c:344 UCX ERROR recv(fd=62) failed: Connection reset by peer; ```. The only difference that I can think of is that my flow is fully supersonic and my mesh is an unstructured core with a structured collar - might this be causing the issue? Kind regards.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/948#issuecomment-754686447:693,log,log,693,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-754686447,1,['log'],['log']
Testability,"On both questions the answer is yes. Option 1 can be implemented right now but will require the creation of temporary objects. Option 2 can directly forward the data to the blas routines. The tool I am developing is no tool for a specific linear algebra package. The idea is, that the tool parses the header files of the library. The user has then to define which objects are active lvalues and the derivatives for each operation in the library. For small an clear interfaces this is no problem and works already quite good. For large libraries like Eigen I adopted a whitelisting approach. That is, every function needs to be manually whitelisted to trigger the expression generation of the tool. In a prototype way I have also implemented an approach where only the active lvalues need to be defined and the tool looks then for all required functions and other objects that depend on these active objects. Long story short, the tool is designed to handle ""any"" library. It is even possible to mix several libraries together. My current status on this project is, that I am now through with the parsing of the header files and the generation of the expressions. This works quite well for Eigen which is a hardcore testcase, since every possible programming tweak in C++ is used here. The next step is to add the AD part to the expression generation process. I hope that in one or two month this will be finished and I can provide a first beta release.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/643#issuecomment-463561018:1215,test,testcase,1215,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-463561018,1,['test'],['testcase']
Testability,"SU2 modules when compiling with Codi; * SU2_ENABLE_METIS: ON|OFF; * SU2_METIS_CPPFLAGS: flags to pass when compiling Metis; * SU2_ENABLE_MKL: ON|OFF; * SU2_ENABLE_MPI: ON|OFF; * SU2_ENABLE_MUTATIONPP: ON|OFF; * SU2_ENABLE_PARMETIS: ON|OFF, only available when SU2_ENABLE_MPI is ON; * SU2_PARMETIS_CPPFLAGS: flags to pass when compiling Parmetis; * SU2_ENABLE_TECIO: ON|OFF; * SU2_TECIO_CPPFLAGS: flags to pass when compiling Tecio and TecioMPI; * SU2_TECIOMPI_CPPFLAGS: flags to pass when compiling TecioMPI, requires SU2_ENABLE_MPI. There is an additional variable that is recognized by CMake scripts - DEBUG, turning it ON enables additional STATUS messages, mainly to check that correct include directories, compile definitions and linked libraries were set up correctly. The remaining options like install location and compilers are handled by CMake. Tested this on Ubuntu with CMake 3.15.5 and everything except pySU2ad wrapper compiles. Haven't tested on earlier CMake versions so there might be bugs with them but they should be easy to resolve if any. Related Work. Resolve any issues (bug fix or feature request), note any related PRs, or mention interactions with the work of others, if any. PR Checklist. Put an X by all that apply. You can fill this out after submitting the PR. If you have any questions, don't hesitate to ask! We want to help. These are a guide for you to know what the reviewers will be looking for in your contribution. * I am submitting my contribution to the develop branch.; * My contribution generates no new compiler warnings (try with the '-Wall -Wextra -Wno-unused-parameter -Wno-empty-body' compiler flags).; * My contribution is commented and consistent with SU2 style.; * I have added a test case that demonstrates my contribution, if necessary. ________________________________; You can view, comment on, or merge this pull request online at:. https://github.com/su2code/SU2/pull/814. Commit Summary. * CMake support for SU2. File Changes. * A CMakeLists.tx",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/814#issuecomment-552242380:3247,test,tested,3247,https://su2code.github.io,https://github.com/su2code/SU2/pull/814#issuecomment-552242380,1,['test'],['tested']
Testability,"SU2/commit/ac8b3bf7636cc66ca7f47e15935942a6598e1a9f), the `SetRoe_Dissipation` function checked to see if the sensor values were valid regardless of the type of blending selected. Commit [ac8b3bf](https://github.com/su2code/SU2/commit/ac8b3bf7636cc66ca7f47e15935942a6598e1a9f) changed the behavior to only check the sensor values if they will be used. The unit test sets the convective blending to `NTS`, feeds invalid sensor values into `SetRoe_Dissipation` and checks the output. ```cpp; // Used to set the Roe-low-dissipation option; void WriteCfgFile(unsigned short nDim, const char* filename,; std::string blending) {; std::ofstream cfg_file;. cfg_file.open(filename, ios::out);; cfg_file << ""PHYSICAL_PROBLEM= NAVIER_STOKES"" << std::endl;; cfg_file << ""ROE_LOW_DISSIPATION= "" << blending << std::endl;. cfg_file.close();; }. BOOST_AUTO_TEST_CASE(BadSensorsAllowedForNTS) {. /*--- Setup ---*/. const unsigned short nDim = 3;. /*--- Set up the config class for the test ---*/; char cfg_filename[100] = ""convective_blending_test.cfg"";; WriteCfgFile(nDim, cfg_filename, ""NTS"");; CConfig* config = new CConfig(cfg_filename, SU2_CFD, 0, 1, 2, VERB_NONE);; std::remove(cfg_filename);. /*--- Inputs ---*/; const su2double dissipation_i = 0.4;; const su2double dissipation_j = 0.6;; const su2double sensor_i = NAN; // Intentionally unphysical:; const su2double sensor_j = NAN; // Intentionally unphysical:. /*--- Outputs ---*/; su2double dissipation;. /*--- Test ---*/. CNumerics numerics;; numerics.SetRoe_Dissipation(dissipation_i, dissipation_j,; sensor_i, sensor_j,; dissipation, config);. const su2double tolerance = std::numeric_limits<su2double>::epsilon();; BOOST_CHECK_CLOSE_FRACTION(dissipation, 0.5, tolerance);. /*--- Teardown ---*/; delete config;; }; ```. There's a couple problems I would fix if I had more time. Ideally, I would be writing the cfg file to an in-memory stream and not to a file. And realistically, I shouldn't need to use a config file at all for a simple test like this.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499999225:2304,test,test,2304,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499999225,1,['test'],['test']
Testability,"SU2] Feature deallocation (#174). Bringing this branch up to date with current develop branch. ; Various deallocation changes; Some regression tests fail but all run. (previously was not the case); You can view, comment on, or merge this pull request online at:;   https://github.com/su2code/SU2/pull/174; Commit Summary; - Updated GetEngine_Properties; - Fix to the last commit; - Small bug; - Merge branch 'develop' into feature_MPI; - merging; - SU2_SOL and SU2_CFD are working; - Preliminary, but complete, implementation of SU2_DEF; - More updates; - Working version; - Complete implementation (validate); - Working version of SU2_DEF; - Final push before moving to the develop branch; - New MPI (removing SU2_PRT); - Merged in Ben's ParMETIS integration and fixed some conflicts.; - Merge branch 'benkirk-parmetis_integration' into feature_MPI; - ParMETIS geometry routines have been copied over but are not activated yet.; - Small change to ParMETIS include.; - ParMETIS can now be activated for testing (PARMETIS=YES in config).; - Updated MG; - Updated EA subrotuine; - Small fix; - Fixing memory leak; - Fixing memory leaks; - Dev release v.3.2.6; - Increasing MAX_NUMBER_MARKER; - Working version with ParMETIS. Fixed bug in global index. Now clean up and testing...; - Cleaned version of ParMETIS routines with better console output during partitioning.; - Small bug in initial element division.; - Made arrays in ParMETIS call dynamic.; - Fixed compiler warnings and added MPI directives so that the pure serial code works with the ParMETIS routines.; - Bootstrap on zion.; - Added some typecasts. Still tracking down a memory problem...; - Critical bug fix for vtxdist array.; - Partial fix; - More MPI improvements.; - Fixing a bug in SU2_DEF; - Updated BC_ActDisk_Boundary (MPI); - Merge remote-tracking branch 'upstream/develop' into develop; - changing solidboundary setting to be heatflux OR euler etc instead of AND, also working on doxygen documentation; - Dynamic allocation for ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:1799,test,testing,1799,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['test'],['testing']
Testability,"So I have setup Travis to test both Python versions, but I need to learn a little bit more about automake to setup the `pySU2` Makefile properly to build against the active Python environment. Hopefully getting closer...",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/424#issuecomment-323047764:26,test,test,26,https://su2code.github.io,https://github.com/su2code/SU2/pull/424#issuecomment-323047764,1,['test'],['test']
Testability,"So I tested this on 4 mesh levels for a NACA0006 at 2.0 degrees AoA, at low (0.6) and high-ish (0.8) Mach number (Roe scheme).; These are the results for low Mach:; ![image](https://user-images.githubusercontent.com/38071223/61968547-3b08c680-afd0-11e9-8aae-9705a9441a00.png); Very small differences between recomputing a mass flux based on primitives (""Reconstructed"") or storing the flux computed during discretization of convection (""Consistent"").; However, the convergence rate for the latter approach is much worse:; ![image](https://user-images.githubusercontent.com/38071223/61968712-99ce4000-afd0-11e9-9c31-dafd7e26e3fb.png); Which makes sense because we are going from a Gauss-Seidel coupling of flow and turbulence to a half GS, half Jacobi (since the turbulence source terms were still computed with current velocity gradients).; After seeing this I only ran one mesh level (second to finest) at high Mach number and again differences were very small and convergence worse.; Some memory would indeed be saved in the discrete adjoint through the reduction of the number of pre-accumulation input variables, but only 30MB out of almost 9GB for a 2D case without MG. In summary the current approach seems to strike a good balance between accuracy, cost, and simplicity.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/721#issuecomment-515535554:5,test,tested,5,https://su2code.github.io,https://github.com/su2code/SU2/issues/721#issuecomment-515535554,1,['test'],['tested']
Testability,"Thank you @TobiKattmann for your feedback. The idea behind this new regression test config file is as follows:; We should have a test case that triggers the negative part of the SA model. Depending on the flow conditions, geometry and CFD parameters it might be triggered or not. With the previous config file, it was not. ; I think there is already a regression test in SU2 that triggers the negative SA, the `turb_oneram6_nk`. However, I decided to stick to rae2822 airfoil as it is a simpler (faster) case. In order to force the negative part of the SA for the rae2822 in a reasonable amount of iterations for a regression test, I increased the angle of attack. I have removed the multigrid as it might not be stable, but I have not tested though. Anyway, with the current configuration, e.g., convective scheme, CFL number, etc, the solution is not stable and diverges after some iterations, around 15. In that sense, I reduced the number of iterations from 20 to 10. In my opinion, a diverging regression test is not a problem at all as it might not be used as a tutorial, only to verify the integrity of the commit. ""The solution should always diverge to the same results"". If the regression test should converge, let me know and I will update the config file :)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1559#issuecomment-1067926363:79,test,test,79,https://su2code.github.io,https://github.com/su2code/SU2/pull/1559#issuecomment-1067926363,7,['test'],"['test', 'tested']"
Testability,"Thank you @pcarruscag and @kursatyurt for your comments and suggestions! I hope that I understood and applied them as intended, if not, please let me know. This is all new to me and because I'm still learning C++, it took me a few extra commits but now all tests seem to pass :) Have a good weekend!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/2024#issuecomment-1545770617:257,test,tests,257,https://su2code.github.io,https://github.com/su2code/SU2/pull/2024#issuecomment-1545770617,1,['test'],['tests']
Testability,"Thank you for the changes.; I would say a test case is always welcome. You can simply modify an existing one, this feature is orthogonal to everything else, and then please add the new options to the config_template (with maybe the nice explanation you have in CConfig).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1236#issuecomment-800292781:42,test,test,42,https://su2code.github.io,https://github.com/su2code/SU2/pull/1236#issuecomment-800292781,1,['test'],['test']
Testability,"Thank you for the feedbacks, I am working on the modifications you suggested. I will perform a couple of tests to be sure I did not break anything. Hope to commit the new code soon!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1124#issuecomment-740209039:105,test,tests,105,https://su2code.github.io,https://github.com/su2code/SU2/pull/1124#issuecomment-740209039,1,['test'],['tests']
Testability,"Thank you for the review @economon.; I just gave the multiple constraints a try on the hybrid onera m6 mesh we have in testcases, it works, both points and edges can be balanced, but the edge cuts go up by almost 50% I guess that makes sense, more constraints less minimization.; There's another reason why I like the combined function, balancing the ""num neighbors"" metric is not exactly the same as balancing the number of edges per partition, using a small negative point weight (-1, -2) yields better results (but the ideal value will be case dependent). I think the next big improvement we can make in this area is to use a partitioner that is aware of the network topology, ParMETIS assumes that the communication cost between any two ranks is the same, this simplification can be very costly on large parallel machines that have a tree-like network topology, and in older clusters with slow interconnects (relative to intra node communication).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1059#issuecomment-671054807:119,test,testcases,119,https://su2code.github.io,https://github.com/su2code/SU2/pull/1059#issuecomment-671054807,1,['test'],['testcases']
Testability,"Thank you for the thorough review @rsanfer! I'll reply to your main questions and some of the smaller ones here to centralize things. > Just a request, if it's possible that you add one or two test cases so the implementation is safe onwards (and, of course, so I can play around with the new features a little bit ). The testcases are the same, no changes there other than the one optional option introduced above. When the hybrid stuff covers most of the code I would add an entire build configuration e.g. BaseMPIOMP and corresponding testcase suite. > * Should this just run ""out of the box"" with a working installation of OpenMP in any machine, or is there anything else _fancy_ needed?. I would leave it to the community to decide what the defaults should be, probably for a lot of new users that don't run on clusters just calling SU2_CFD and not having to worry about mpi would be nice (a lot of the issues on CFD online are mpi related). > * Is the previous behaviour exactly kept, or are there any modifications in the basic, non OpenMP version of code? (Not that I mind, just curious). Other than the algorithmic changes (but mathematically equivalent) introduced to limiters and gradients in #834, yes. > What's the advantage of having one numerics term per thread?. It is a requirement, we need to write data into numerics before using them, multiple threads cannot write to the same location (i.e. the internal structures of CNumerics) therefore one per thread is required. > ...Also, I think I missed the point where the numerics container is extended beyond MAX_TERMS. The allocation of space for one numerics per thread is done above in line 1995 of my 21 Dec 2019 comment: `...MAX_TERMS*omp_get_max_threads()...`.; The instantiation of one numerics per thread is then done by executing the rest of the preprocessing in parallel and instead of using `XYZ_TERM` using `XYZ_TERM+offset` where `offset = thread_id * MAX_TERMS`.; I think someone mentioned this (maybe Tim) that we could r",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/843#issuecomment-577684728:193,test,test,193,https://su2code.github.io,https://github.com/su2code/SU2/pull/843#issuecomment-577684728,3,['test'],"['test', 'testcase', 'testcases']"
Testability,"Thanks @clarkpede to take the initiative for this topic. I think unit-tests are a useful thing and we should think about having it in addition to the regression tests. Regarding the framework I am actually a little bit hesitant to use boost. Although we are already using it for tecio, in that case it is used in a part of the code which does not change frequently so it is fine if we are just shipping it. However, if we start introducing it into the actual development process people may want to use more and more features of boost and we will have a hard time maintaining versions, compatbilities and so on. And in my opinion we should keep it as simple and lightweight as possible (one of our biggest strengths is the simple compilation/installation, which actually attracts a lot of users). So in that regard Catch2 looks like a better candidat to me. But I am happy to hear more opinions on that.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-500226914:70,test,tests,70,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-500226914,2,['test'],['tests']
Testability,"Thanks Brian,; my bad, I misinterpreted the carpets / logs structure. I successfully ran a test of a very simple case. In the results there are some small artifacts, but the shocks are resolution improved consistently after mesh adaption.; Thanks for the support. ![Comparison](https://user-images.githubusercontent.com/41752169/80644172-84a7a580-8a69-11ea-9f16-58e98c808b73.png); ![ComparisonMesh](https://user-images.githubusercontent.com/41752169/80644174-85403c00-8a69-11ea-819f-2ac00550a089.png)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/948#issuecomment-621450497:54,log,logs,54,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-621450497,2,"['log', 'test']","['logs', 'test']"
Testability,"Thanks Francisco for this contribution! Although the FFD Framework is already working quite well, there is still (like always) room for improvement. In fact, I am currently working on using BSplines instead of Bezier curves. I'm going to open a pull request end of this week. But this shouldn't affect this one I hope. Do you have by any chance a simple test case I could use to check this ?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/330#issuecomment-260475206:354,test,test,354,https://su2code.github.io,https://github.com/su2code/SU2/pull/330#issuecomment-260475206,1,['test'],['test']
Testability,"Thanks for adding the description, Heather. I think this is a very nice contribution.. we’re working on the regressions and will pull this in once we have everything straightened out (and this branch passes). In the meantime, you got me thinking: the scale, rotate, translate options might be confusing now if a user doesn’t know whether to include the markers or not. Perhaps this is a chance for separating some of the “design” options from “mesh” options. One way I could see us do this is by moving the implementation I had just committed for the “volume” scale, rotate, and translate options over into the SU2_MSH executable, which might be a more logical home for it. However, this would require adding an extra set of config options for reading in a scale/rotate/translate options for SU2_MSH. The nice thing here is that we keep the intent separate, i.e., only design variables are listed with the other design variables while the mesh transformations are elsewhere. A different, possibly simpler way would be to just create separate names for these two types in the list of available options so that there is no ambiguity. Any thoughts?. On Aug 16, 2015, at 9:21 AM, Heather Kline <notifications@github.com<mailto:notifications@github.com>> wrote:. Some illustrative images/output in case my description was hard to understand:; [image]https://cloud.githubusercontent.com/assets/5167760/9294050/52a764b2-440f-11e5-8681-b68318da0ce7.png. SU2_DEF output when only ""airfoil"" marker included:. ------------------------- Surface grid deformation ----------------------; Performing the deformation of the surface grid. ----------------------- Volumetric grid deformation ---------------------; Performing the deformation of the volumetric grid. # FGMRES residual history. # Residual tolerance target = 4.14044e-11. # Initial residual norm = 15.8102. ```; 0 1; 50 2.17385e-06; 100 1.08998e-10; ```. # FGMRES final (true) residual:. # Iteration = 105: |res|/|res0| = 3.50764e-11. Non-linear iter.: 1/",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/187#issuecomment-132065067:653,log,logical,653,https://su2code.github.io,https://github.com/su2code/SU2/pull/187#issuecomment-132065067,1,['log'],['logical']
Testability,"Thanks for bringing up this issue. It is interesting... . As Heather mentioned, is there any concern that when writing large files the lack of an endl will cause the buffer to become too large at some point (before the file gets closed and clears the stream automatically)?. Unfortunately, we do not have any regression tests that cover the output files at the moment, so it is difficult to gauge the impact of the changes, although it would be straightforward to add some tests for SU2_CFD and SU2_SOL that diff output files. Have you been able to verify that all CSV, Tecplot/ParaView files, and force breakdown files work appropriately?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/281#issuecomment-223806287:320,test,tests,320,https://su2code.github.io,https://github.com/su2code/SU2/pull/281#issuecomment-223806287,2,['test'],['tests']
Testability,"Thanks for finishing up the implementation, @VivaanKhatri! I am looking forward to reviewing this very soon. Do you have a test case to verify things are working? Even just a simple flat plate like in the paper so that we can put it under regression control?. @rsanfer: your comment reminded me about our earlier attempts to fix up the indentation issues on the fix_indentation branch. Do you think this is something we can revive to provide scripts for automatically fixing this issue once and for all? Or do we need to find a different approach?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/530#issuecomment-387921905:123,test,test,123,https://su2code.github.io,https://github.com/su2code/SU2/pull/530#issuecomment-387921905,1,['test'],['test']
Testability,"Thanks for the clarification!. Best,; Francisco. > On Apr 22, 2017, at 5:01 PM, Heather Kline <notifications@github.com> wrote:; > ; > Thanks; > The discrete adjoint can also be used with combined objectives, and uses the same config specifications. It may not be clear from this pull request since this functionality was added in a previously - when multiple objectives (limited to objectives defined inside the CFD solver) are specified, they are added together (with specified weights) in the CFD solver into the 'COMBO' output to history. This variable is registered for the discrete adjoint solver.; > An example of this can be seen in the serial_regression_AD.py, test name 'discadj_multi_py'.; > ; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/pull/385#issuecomment-296409557>, or mute the thread <https://github.com/notifications/unsubscribe-auth/AEpklrJ5WQ8CoWJNAy_FVZ0bbYN000s2ks5rypTpgaJpZM4MgM_e>.; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/385#issuecomment-296409876:670,test,test,670,https://su2code.github.io,https://github.com/su2code/SU2/pull/385#issuecomment-296409876,1,['test'],['test']
Testability,"Thanks for the explanation @suargi . I would personally advocate for that the testcases should converge to some reasonable solution people might use it as a starting point (copy the cfg and doing mild adaptions) for their own stuff. And the Testcases show off the capabilities to some degree, to do so, convergence is beneficial. But as we have a bunch of working 2D airfoils in regression already I recon that adding a clear explanation and warning to the cfg as suggested by Pedro is fine. Otherwise you might try to bisect the AoA ... maybe there is a value that triggers negative SA and does not diverge :thinking: . Knowingly adding a diverging test without a clear warning is not good imo :)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1559#issuecomment-1067977083:78,test,testcases,78,https://su2code.github.io,https://github.com/su2code/SU2/pull/1559#issuecomment-1067977083,2,['test'],"['test', 'testcases']"
Testability,"Thanks for the feedback. . I was not able to find any examples myself either. It looks like this is a feature that has been around for a while, but maybe has gotten lost in some updates. I will work on setting up a small test case for this and the FAN_FACE_MDOT and submit a PR.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1607#issuecomment-1100150640:221,test,test,221,https://su2code.github.io,https://github.com/su2code/SU2/issues/1607#issuecomment-1100150640,1,['test'],['test']
Testability,"Thanks for the fixes, Francisco. The continuous adjoint tests are now failing, but I am guessing that it is something simple with the changes to the config option. Can you please take a look when you have a moment?. Couldn't agree more about keeping an eye on the Python scripts. We'll chat about it this week at the developer meeting (we need regressions for the Python scripts). More on that to come.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/244#issuecomment-191571633:56,test,tests,56,https://su2code.github.io,https://github.com/su2code/SU2/pull/244#issuecomment-191571633,1,['test'],['tests']
Testability,"Thanks for the suggestion and I am preparing for a test.; As far as I understand it, I just find that to get the absolute value of r_ij ( showed in the highest equation) in this part of code is unnecessary. The cross-product operation is to find the grid vector mostly parallel to the vorticity vector and the absolute value may cause a nonphysical recognition.; @EduardoMolina, I don't know if I got it wrong and wish more guidance,.; ```; for (auto iDim = 0u; iDim < nDim; iDim++){; delta[iDim] = fabs(coord_j[iDim] - coord_i[iDim]);; }; ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1462#issuecomment-988581348:51,test,test,51,https://su2code.github.io,https://github.com/su2code/SU2/issues/1462#issuecomment-988581348,1,['test'],['test']
Testability,"Thanks for your feedback! I agree, `OMP_NUM_THREADS` is better than having the number of threads in the constructor. I adapted `disc_adj_flow` and `disc_adj_fea` for MPI and added both to parallel AD and hybrid AD tests.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1966#issuecomment-1472198978:214,test,tests,214,https://su2code.github.io,https://github.com/su2code/SU2/pull/1966#issuecomment-1472198978,1,['test'],['tests']
Testability,"Thanks, @clarkpede, for this PR and for the clear explanation of the features proposed. LGTM in terms of implementation and code style. I'll just wait for @EduardoMolina to comment on the contents. I only have a couple of minor questions:. > I moved the calculation of the maximum cell width to the CPhysicalGeometry class. This makes inclusion in the central/upwind blending easier. For DES and DDES, the cell lengthscale is not dependent on the flow. So there's no need to compute it every iteration in the flow solver. I can see this approach reduces the computational cost of computing the MaxLength every time at the cost of having one more double in memory per point. However, would a call to SetMaxLength() be necessary in case of deformable meshes? . Also, from PR #532:; > As for code verification, I would propose using one of the cases examined by Travin, Stretlets, Mockett, or Xiao for comparison. (...) The cases I can see where they explicitly show the results of the blending function are: Circular cylinder at Re = 50,000 (Travin et al. 2002) (...). I guess this is the case for which you are showing the rough tests results in the Code Verification section. I am currently looking into some test cases at similar Re regimes. Are you using the unsteady compressible solver for this verification? I noticed that in Ref.[1] they use artificial compressibility, and I was wondering if we could also use this test case to look into the unsteady, incompressible (preconditioned) version of the solver (PR #514).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/552#issuecomment-403842613:1128,test,tests,1128,https://su2code.github.io,https://github.com/su2code/SU2/pull/552#issuecomment-403842613,3,['test'],"['test', 'tests']"
Testability,"Thanks, @jaspe55 ! LGTM. I don't think we have any tests for the inverse design capability. Do you have a very simple test case that we can put into the regressions for this capability? I think you are working on a nozzle design.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/600#issuecomment-439496260:51,test,tests,51,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-439496260,2,['test'],"['test', 'tests']"
Testability,"Thanks, I’ll take a look at that before the weekend,. Best,; Francisco. > On Mar 2, 2016, at 8:03 PM, Thomas D. Economon notifications@github.com wrote:; > ; > Thanks for the fixes, Francisco. The continuous adjoint tests are now failing, but I am guessing that it is something simple with the changes to the config option. Can you please take a look when you have a moment?; > ; > Couldn't agree more about keeping an eye on the Python scripts. We'll chat about it this week at the developer meeting (we need regressions for the Python scripts). More on that to come.; > ; > —; > Reply to this email directly or view it on GitHub https://github.com/su2code/SU2/pull/244#issuecomment-191571633.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/244#issuecomment-191590831:216,test,tests,216,https://su2code.github.io,https://github.com/su2code/SU2/pull/244#issuecomment-191590831,1,['test'],['tests']
Testability,"Thanks; The discrete adjoint can also be used with combined objectives, and uses the same config specifications. It may not be clear from this pull request since this functionality was added in a previously - when multiple objectives (limited to objectives defined inside the CFD solver) are specified, they are added together (with specified weights) in the CFD solver into the 'COMBO' output to history. This variable is registered for the discrete adjoint solver. ; An example of this can be seen in the serial_regression_AD.py, test name 'discadj_multi_py'.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/385#issuecomment-296409557:532,test,test,532,https://su2code.github.io,https://github.com/su2code/SU2/pull/385#issuecomment-296409557,1,['test'],['test']
Testability,The Github Actions checks passed after making two changes:. 1) https://github.com/su2code/SU2/pull/1619/commits/efe98fe6070a0cb51f1082a9599363786e4d65ea; I needed to lower the warnlevel due to problems in `externals/cgns/hdf5`.; Maybe the HDF5 files should be updated to a newer version ?! But it is not clear to me which version has been used in https://github.com/su2code/SU2/pull/1500. ; @MicK7 Do you have an idea how to fix this ?. 2) https://github.com/su2code/SU2/pull/1619/commits/26140223e5838a6856c0b3c02163a826256306b1; A workaround recommended at https://github.com/su2code/SU2/issues/1568#issuecomment-1083104460. 3) The regression tests [fail](https://github.com/su2code/SU2/runs/6387003184?check_suite_focus=true) because the new `test-su2` Docker image is `private`. I will need someone with higher privileges than me to make it public.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1619#issuecomment-1123614000:645,test,tests,645,https://su2code.github.io,https://github.com/su2code/SU2/pull/1619#issuecomment-1123614000,2,['test'],"['test-', 'tests']"
Testability,"The answer to that is very simple. Look in the data set that is present in the szplt file. The z-coordinate is not in there anymore and consequently Tecplot takes the next variable, the density in this case, as the z-coordinate. Consequently you git a picture like you showed. The same is true for the field solution. Also there the z-coordinate is not present in the szplt file and hence you get a rather funny picture when you attempt to visualize this in 3D. But 2D visualization works just fine. In contrast the z-coordinate is stored in the vtu files, because the standard requires that. Hence you can still visualize this in 3D. Could you try a truly 3D test case to see if that visualizes fine? If so, please let us know such that we can close this issue.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1182#issuecomment-771407798:660,test,test,660,https://su2code.github.io,https://github.com/su2code/SU2/issues/1182#issuecomment-771407798,1,['test'],['test']
Testability,"These timings were all run this morning on the same cluster. . Using qperf, I'm seeing 80 microsecond latency. I'm also seeing the expected bandwidth using qperf as well. I would think that mpi would behave similarly but 100% sure. . I'm quite sure that the jobs are being launched correctly. I've checked that a bunch of times since that was my first instinct. I've both logged into all the machines and watched top and everything looked normal. And I've tried running SU2 v6 before and after v7, launching them the same way, and I keep getting the same numbers. I'm not sure how to check whether there is any reason non blocking comm would be ineffective. If you have any ideas I can certainly try something. I tried to download vampirtrace which seemingly can profile mpi, but it failed to compile against my version of mpi. When I get the chance I can try a different version of openmpi and see if I can get it running. The networking setup is pretty simple with all 4 machines plugged into the same switch and they share their own vlan as part of a bigger network. As I said, I ordered some faster networking equipment to see if it makes a difference (though I'm honestly not 100% sure that what I ordered will work with my comps but we'll see.)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/894#issuecomment-593144776:372,log,logged,372,https://su2code.github.io,https://github.com/su2code/SU2/issues/894#issuecomment-593144776,1,['log'],['logged']
Testability,This PR finally passed the tests! Can I get some review feedback @economon and/or @talbring? It would be great to have this merged ASAP so no one adds any new code incompatible with Python 3.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/424#issuecomment-343013631:27,test,tests,27,https://su2code.github.io,https://github.com/su2code/SU2/pull/424#issuecomment-343013631,1,['test'],['tests']
Testability,"This bug pops up because the periodic mesh reconstruction (in `SU2_MSH`) doesn't always create a valid mesh in 3D. Some points disappear, and some points are duplicated. When `SU2_CFD` (specifically, `CPhysicalGeometry`) tries to get the number of points in the domain, it calculates the wrong number because some of those points are duplicated. That leads to segfaults, because the output routine thinks the extra (missing) points belong to another processor. I've got a little toy problem with a simple periodic cube. It's easy to see on the simple 4x4x4 (+ periodic) problem that 3 nodes disappear, and 3 nodes are duplicated. I've never observed this problem in any of the 2D test cases I ran. As to why `SU2_MSH` is missing some points and duplicating others, I'm not sure. I tried running Valgrind to check for uninitialized variables or illegal memory access, but nothing there. I'll have to look more into the problem. The `su2_periodic.f90` script mentioned in #416 seems to be a workaround. I don't run into any problems when I use that script.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/431#issuecomment-337056131:680,test,test,680,https://su2code.github.io,https://github.com/su2code/SU2/issues/431#issuecomment-337056131,1,['test'],['test']
Testability,"This is obviously very good work and should make it much simpler to add new outputs etc. My main concern when first reviewing was performance (something no one seems to care about) but from the limited testing I did while merging this and CVariable there seems to be no big impact, I did not time anything though, if you have numbers to share please do.; Nevertheless if you can get away with using unordered_map instead of map it would be better. Possibly part of the reason everyone puts of reviewing this is that it is a major refactoring and yet there are no accompanying notes about the architecture the implementation choices etc. I absolutely guarantee you that is not how professional software is developed.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/724#issuecomment-534651933:202,test,testing,202,https://su2code.github.io,https://github.com/su2code/SU2/pull/724#issuecomment-534651933,1,['test'],['testing']
Testability,"This is very interesting, since I often find that I am commenting out most of the python regression script when debugging only a couple of tests locally. Can you estimate how much work this would be? Is it just a simple wrapping of what we already have? We would also have to make sure that Travis CI can handle it.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/462#issuecomment-342593274:139,test,tests,139,https://su2code.github.io,https://github.com/su2code/SU2/issues/462#issuecomment-342593274,1,['test'],['tests']
Testability,"This one is all set after a little more cleanup. I left some low-level changes to the EoS models for later. @CatarinaGarbacz @MarcoFossati : we can use a simple directory name, as you suggest. Let's just go with fluid/ since we also treat liquids with the incompressible solver. Bonus: adds a rotating frame calculation test and some extra error checks on CFL adapt params that should help avoid unreported problems with old configs.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1010#issuecomment-640170715:320,test,test,320,https://su2code.github.io,https://github.com/su2code/SU2/pull/1010#issuecomment-640170715,1,['test'],['test']
Testability,"To add some data I'll put a test where you can see the issue:. This is an inviscid Euler simulation using the Span-Wagner EoS (CoolProp) of a non-ideal MDM nozzle, see https://su2code.github.io/tutorials/NICFD_nozzle using ```GREEN_GAUSS``` for the gradient computation. Convergence can still be achieved but the solution at the inlet corner is completely wrong, while the outlet is ok most likely because characteristics are outgoing as it is supersonic. The artifacts disappear if we disable MUSCL everywhere (1st order solution) or disable it only on boundaries (not ideal solution, but disabling only on corners would still be good enough for now I believe). Using ```WEIGHTED_LEAST_SQUARES``` seems to not present the same issue, in this test case at least, as the stencil ""does not care"" about the boundary states. The boundary conditions are:; - ```MARKER_SYMMETRY``` at centerline; - ```MARKER_EULER``` at wall; - ```MARKER_RIEMANN= (INLET, TOTAL_CONDITIONS_PT, 904388, 542.13, 1.0, 0.0, 0.0)``` at inlet; - ```MARKER_RIEMANN= (OUTLET, STATIC_PRESSURE, 200000.0, 0.0, 0.0, 0.0, 0.0)``` at outlet. I tried both with and without a slope limiter as there are no discontinuities, but it makes no difference on the artifacts:. ```; SLOPE_LIMITER_FLOW= VENKATAKRISHNAN_WANG; VENKAT_LIMITER_COEFF= 0.1; ```. # Complete test case ZIP; [mdm_coolprop_nozzle.zip](https://github.com/su2code/SU2/files/15403732/mdm_coolprop_nozzle.zip). # Inlet pressure zoom; ![Screenshot from 2024-05-22 15-06-36](https://github.com/su2code/SU2/assets/79575547/9ba71127-cb12-4c5f-8e49-3ea9e839b1f4). # Notation: ; - ""1st order"" no MUSCL; - ""2nd order"" MUSCL as implemented in SU2; - ""2nd order (BC 1st order)"" I simply disabled MUSCL on ALL physical boundaries in the upwind residual computations, see code snippet below. # Proof of concept code modification for ""2nd order (BC 1st order)"":; To show that the error lies in MUSCL/gradients at boundaries I added these two lines of code in the upwind gradient computation;",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/2285#issuecomment-2124781449:28,test,test,28,https://su2code.github.io,https://github.com/su2code/SU2/issues/2285#issuecomment-2124781449,2,['test'],['test']
Testability,"Todo list:; - [x] Make sure the code can handle arbitrary many species equtions. Especially the output has to be adapted. Note the MAXNVAR of the ScalarSolver has to adapted to that need as well. Make a suitable Testcase for that.; - [x] Implement weak inlet and outlet BC. The weak approach is used in the turb and mean flow and is most likely conservative opposed to the strong one. Here a simple switch will be put in place to compare both versions.; - [x] Consolidate nVar, nSpecies, ... variable to only use 1 consistently (The choice was `nSpecies` which was already introduced for NEMO and it just makes sense to use the same container); - [x] Make the numerous reviewers happy; - [x] Check inlet profiles for Species solver (have a testcase for that) See #1427 ; - [x] Create Objective functions of Surface avg quantities (Area and Massflow? prob. And a variance-style output to capture mixing); - [x] Avoid redundant operations (pre/post processings) during solver restarts. 156d0c5. What will be done in follow-up PR's:; - Viscous contributions for BC_inlet and outlet which are currently not used (also then for Turb-solver) https://github.com/su2code/SU2/pull/1388#discussion_r752384956; - Axissymmetric source term addtion and testing; - multi-component mixing from #1332 ; - gradient validation between DA and FD",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1388#issuecomment-935901996:740,test,testcase,740,https://su2code.github.io,https://github.com/su2code/SU2/pull/1388#issuecomment-935901996,2,['test'],"['testcase', 'testing']"
Testability,"Unfortunately, I have not been able to recreate this issue on my systems with the simple test case that you shared @yukaiweng. . @talbring or @EduardoMolina, if you have some time, could you give the attached toy problem a try on your machines? I ran for a couple of unsteady iterations and then restarted on the third iteration (successfully for me). I think we're just missing something simple... [ascii_restart_test.zip](https://github.com/su2code/SU2/files/1659029/ascii_restart_test.zip)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/477#issuecomment-360050851:89,test,test,89,https://su2code.github.io,https://github.com/su2code/SU2/issues/477#issuecomment-360050851,1,['test'],['test']
Testability,"Unfortunately, I wasn't able to get all of them. I fixed a majority of the calls but couldn't find workarounds all of them. There are 8 left in the following files: . `SU2_PY/change_version_number.py`: There's 2 in here. One is a complicated command with `grep` and pipes and the other is a simple `rm -rf`, but it isn't a security risk since there is no user input into that string. `SU2_PY/SU2/util/pyCppTap.py`: This is in the diff_routine and uses `tapenade`. I have no idea what this does so I didn't touch this one. `SU2/opt/server.py`: There are 4 `scp` calls that I didn't know how to replace. `SU2_PY/compute_polar.py`: There's one left in here which is a complicated `cat` call that I couldn't figure a workaround for. . If you have any suggestions for any of these, I can try and implement them. . Otherwise, once these tests pass, its good to merge.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/781#issuecomment-533590086:831,test,tests,831,https://su2code.github.io,https://github.com/su2code/SU2/pull/781#issuecomment-533590086,1,['test'],['tests']
Testability,"We already require C++11 for some more advanced features, but it is always nice in my opinion to keep backward compatibility when possible. . However, this is not a deal breaker, I don't think, as most developers that want to use and add their own unit tests should have no problem with using C++11. If we can make it an optional dependency, to make sure the basic build still works simply, I think it could be ok.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-503685445:253,test,tests,253,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-503685445,1,['test'],['tests']
Testability,"We are wondering what the status with the merge request is. Am I supposed to do something more? is it just waiting for an additional review? . Additionally, we have many more proposed modifications, we have worked on, adding robustness to the existing turbulence models. It is expected, many of these changes will effect the test cases behaviour, are there any guidelines how to compile the code to run the full set of tests locally, or should I just open pull requests, and base upon the github test results? ; ; I am sorry if I may be asking the obvious, but I am new to contributing to open code..",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/2295#issuecomment-2219624152:325,test,test,325,https://su2code.github.io,https://github.com/su2code/SU2/pull/2295#issuecomment-2219624152,3,['test'],"['test', 'tests']"
Testability,"We will merge this PR next in order to have enough time for testing and for you to solve conflicts (if you need any help to solve those, please contact me). Even if this PR is merged, please continue to give feedback on the usability. We will still continue to work on that. Refer to the user documentation in order to learn how to adapt your config files. Let me know if you have any questions.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/724#issuecomment-534522241:60,test,testing,60,https://su2code.github.io,https://github.com/su2code/SU2/pull/724#issuecomment-534522241,1,['test'],['testing']
Testability,"Writing a simple unit test is difficult, since SU2 both doesn't have unit tests and wasn't written with unit testing in mind. That being said, I've got a unit test that I'm happy with. Our group has put our own unit-testing framework into our fork of SU2, based off of Boost and automake testing. The unit test I created runs off of that framework. That means it won't run out-of-the-box on the develop branch of SU2. When I run the unit test with no changes to `CNumerics::GetViscousProjJacs`, I get that the residuals and Jacobians match to within 10 times the machine epsilon, aside from the [4][0] value of the Jacobians. There, the relative difference is of the order 1E-6. When I switch the two lines in `CNumerics::GetViscousProjJacs` for ideal gases to be negative, the tests run with no complaints. Ideal gas and generalized variants match to within 10 times machine epsilon. I'm uploading my test file just as an example, in case anyone wants to see what I've tested.; [viscous_ideal_vs_general.zip](https://github.com/su2code/SU2/files/2590517/viscous_ideal_vs_general.zip). As for comparison to some results from another code, I think that's a lot to ask. Getting a good comparison would depend on an understanding of how the ideal gas model, viscosity, numerics, and Jacobians are handled in the external code. Small differences would make the comparison completely invalid. I completely support testing and checking the changes I'm proposing. But comparison with an external code seems to provide a very low return on investment.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/609#issuecomment-439491945:22,test,test,22,https://su2code.github.io,https://github.com/su2code/SU2/issues/609#issuecomment-439491945,12,['test'],"['test', 'tested', 'testing', 'tests']"
Testability,"YES! I am excited to try this out. I can probably test it on some of the other TMR cases (airfoils, flatplates). Will post the results when I get those done. . Side note, there was one issue that @bmunguia and I encountered when performing optimizations with adaptive CFL. Say the DIRECT simulation is run with adaptive CFL and is well converged (6 to 8 orders of residual reduction). When the discrete adjoint performs the one direct iteration to store the computational graph, it uses the initial CFL value, not the CFL that the adaptive CFL routine ended at. This results in the residuals being very high for that one iteration, which then affects the convergence of the discrete adjoint. . I will try to run an adjoint on one of these cases as well to see if the problem persists. Perhaps could be overcome with a simple additional field for CFL in the restart meta-data",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/790#issuecomment-531520526:50,test,test,50,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-531520526,1,['test'],['test']
Testability,"Yes it definitely is confusing. Then we have to use set_ffd_design_var.py giving i,j,k which are not really 'units' in x,y,z. The website should be updated to show this. I am wondering how does SU2_DEF will determine the ""logic axis"". Won't a simple x,y,z approach have been simpler?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/977#issuecomment-626875076:222,log,logic,222,https://su2code.github.io,https://github.com/su2code/SU2/issues/977#issuecomment-626875076,1,['log'],['logic']
Testability,"Yes, nothing more from me on this. Once this is merged, the comparison in PR #1260 should become simpler too. I've just updated this branch with develop, we can merge once the regression tests pass again.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1174#issuecomment-827981242:187,test,tests,187,https://su2code.github.io,https://github.com/su2code/SU2/pull/1174#issuecomment-827981242,1,['test'],['tests']
Testability,"Yet another doubt on the same subject: I just realized that SU2V7.31 (I; have not tested it on later SU2 releases) accepts imposing both adiabatic; walls plus isothermal boundary condition on some walls (when running Menter; model), but when I simply impose only isothermal conditions (leaving; commented out the adiabatic markers), I get the message: SU2 process; returned error '1'. Is there a workaround for this? Kind regards. On Thu, Sep 28, 2023 at 8:25 PM Pedro Gomes ***@***.***>; wrote:. > you are correct, there is a discussion on CFD-online about it. we impose 0; > heat flux, but report an ""apparent heat flux"" most codes will simply give; > you back the imposed heat flux value you specify, nevertheless there will; > probably be a temperature gradient close to the wall; >; > —; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/pull/2109#issuecomment-1740118992>, or; > unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AHGXZUUZNE6B63SH7XJLY2DX4YBMZANCNFSM6AAAAAA3QKLVDU>; > .; > You are receiving this because you commented.Message ID:; > ***@***.***>; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/2109#issuecomment-1775968391:82,test,tested,82,https://su2code.github.io,https://github.com/su2code/SU2/pull/2109#issuecomment-1775968391,1,['test'],['tested']
Testability,"Yikes. Thanks, @LaSerpe, for the heads up. There is clearly something wrong with SU2_SOL for many of the cases, although the compute portion is fine. We should get a test case set up for SU2_SOL, or at least try to catch these errors too. @fpalacios, can you please take a look at this problem when you have a moment? It seems to have shown up with the merging of feature_cte_cl. Just fyi for all: the Travis CI folks have generously granted extra time for our regression tests, up to 70 minutes now. This fixes the time-out issues in the short term, but there are a few strategies we should look at for caching or further decomposing our builds to keep under the time limits in the future as we keep growing.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/325#issuecomment-262118156:166,test,test,166,https://su2code.github.io,https://github.com/su2code/SU2/pull/325#issuecomment-262118156,2,['test'],"['test', 'tests']"
Testability,"You could modify `CWindowedAverage::addValue` to only ""push back"" more values if it detects a change in current time iteration, otherwise it simple overwrites the last value in the history.; Then you could get rid of the entire logic in `SetUpdate_Averages` simply making it true or false (less logic is the way for less bugs).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1259#issuecomment-817952886:228,log,logic,228,https://su2code.github.io,https://github.com/su2code/SU2/pull/1259#issuecomment-817952886,2,['log'],['logic']
Testability,"You want to check if your new behavior behaves as you suspect before you throw a lot of resources at it.; * You submit a PR and discover that one of the regression tests has failed. But...why? You know that something is broken, but its hard to track down what broke. You want more granular test coverage that can demonstrate what broke.; * You are fixing a very small bug. You know that you should prove that your bug fix worked, but it doesn't seem logical to dedicate an entire validation case to one small bug fix. You want to write a small test for a small fix. In all of these cases, unit testing fills a unique role. Unit testing increases time spent in development, but decreases the amount of time spent in bug-fixing and maintaining. For more information, see this relevant Stack Exchange question.<https://scicomp.stackexchange.com/questions/206/is-it-worthwhile-to-write-unit-tests-for-scientific-research-codes>. What do I propose?. My research group at UT Austing has implemented a unit testing framework on our branch, which we're happy with. Some choices were arbitrary, and some choices were made based on our development environment. Those choices may be different for other groups. Here's what we have done:. The unit testing framework is compiled and run using autotools. For more information on autotool's setup, see their documentation<https://www.gnu.org/software/automake/manual/html_node/Tests.html>. Since autotools is the build system for SU2, this involves minimal changes. Using automake, the build process for building unit tests becomes:. '''; ./bootstrap; ./configure; make; make check; '''. We use Boost's unit testing framework<https://www.boost.org/doc/libs/1_70_0/libs/test/doc/html/index.html>. This provides a convenient set of macros for instatiating tests, grouping tests into suites, and running checks. This choice was based on what is available in our development setup. We have integrated our unit tests into our Travis CI regression testing. Every time we ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499250240:2467,test,testing,2467,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240,1,['test'],['testing']
Testability,"```diff; $ git --no-pager diff --cached ; diff --git a/meson.build b/meson.build; index ca86992ea..b68a03c52 100644; --- a/meson.build; +++ b/meson.build; @@ -1,15 +1,12 @@; project('SU2', 'c', 'cpp',; version: '7.5.1 ""Blackbird""',; + meson_version: '0.61.1',; license: 'LGPL2',; default_options: ['buildtype=release',; 'warning_level=0',; 'c_std=c99',; 'cpp_std=c++11']); ; -if meson.version() != '0.61.1'; - error('SU2 must be configured with the extended Meson script (./meson.py) in the SU2 root directory.'); -endif; -; pymod = import('python'); python = pymod.find_installation(); ; ```. I used this patch, and then ran the following:. ```; $ meson setup builddir --wipe; The Meson build system; Version: 1.0.1; Source dir: /tmp/SU2; Build dir: /tmp/SU2/builddir; Build type: native build. meson.build:1:0: ERROR: Meson version is 1.0.1 but project requires 0.61.1; ```. Using the >= comparison, it configures fine, and downloads a git submodule for mutationpp/coolprop on demand. From a hasty look around, it seems like the other git submodules are used as externals/ directories, not meson subprojects. Another project I know uses e.g. ```; if not fs.exists('submoduledir/README.md'); error('Missing the `submoduledir` submodule! Run `git submodule update --init` to fix this.'); endif; ```. for each submodule before it gets processed by meson. This is less automatic than wrapping it in meson.py, but does provide pretty clear directions... the sticking point is if people download tarballs. You currently point people to github's autogenerated archives, which is NOT sufficient as it doesn't have submodules included. I would actually suggest using `meson dist --include-subprojects --no-tests` to produce your own tarballs and attach them as additional releases artifacts. Meson *does* include submodules (whether or not they are subprojects) automatically to the tarball it creates.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1945#issuecomment-1451057434:1699,test,tests,1699,https://su2code.github.io,https://github.com/su2code/SU2/issues/1945#issuecomment-1451057434,1,['test'],['tests']
Testability,"al changes. Using automake, the build process for building unit tests becomes:. '''; ./bootstrap; ./configure; make; make check; '''. We use Boost's unit testing framework<https://www.boost.org/doc/libs/1_70_0/libs/test/doc/html/index.html>. This provides a convenient set of macros for instatiating tests, grouping tests into suites, and running checks. This choice was based on what is available in our development setup. We have integrated our unit tests into our Travis CI regression testing. Every time we push commits or submit a pull request, the unit tests are run and checked. What is my vision for unit testing in SU2?. I am not proposing that we start trying to get 100% code coverage with pre-existing code. That would not provide a good return on investment. Instead, I see people adding unit tests as they write new code and as they find bugs. For each new behavior added to SU2, tests are first added to document the related existing behavior. These tests serve to check that the existing behavior isn't damaged by the new code. Then new tests are added to prove that the new behavior is working correctly. For bug fixes, the process is simpler. A test is added to confirm that something is not behaving as expected. Then the code is fixed to make the test pass. What frameworks are available?. For a unit testing framework, here are the most popular options, with the following pros and cons:. Roll-your-own. * Requires no external dependencies; * The most flexible option; * Involves the most work to setup; * Will lack some of the more advances features of mature unit-testing frameworks. Boost Test. * Can be header only, statically linked, or dynamically linked; * If statically or dynamically linked, then Boost is not very lightweight; * Easy to add if you're already using Boost. Google Test. * Most common unit-testing framework; * Can be easily combined with Google's powerful GMock mocking library; * Compiling and linking can be somewhat painful. Catch2. * Used by FEniCS; *",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499250240:3921,test,tests,3921,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240,1,['test'],['tests']
Testability,"also be some; > issues that arise multiple times in existing code where a retroactive; > application of unit testing may also make sense. I am copying Pat Miller,; > formerly with DoE, who may have more experience on whether such unit; > testing approaches were useful/worth the investment in some major codes he; > worked on.; >; > Best,; >; > Juan; >; >; > On Jun 4, 2019, at 2:14 PM, Clark Pederson <notifications@github.com>; > wrote:; >; > I propose adding a unit-testing framework and unit-tests to SU2. After; > chatting with @economon <https://github.com/economon>, I've decided to; > move the discussion here to get additional input.; > What is unit testing?; >; > For those not familiar with unit testing, unit testing allows the testing; > of small bits of behavior, ideally using isolated bits of code. It is not; > intended to replace validation testing or formal verification tests.; > Instead, it serves a unique purpose. Consider the three following use cases:; >; > - You're developing a new feature, and you want to test it to see if; > it works. You could do a full simulation, but that takes a lot of time and; > computing power. You want to check if your new behavior behaves as you; > suspect before you throw a lot of resources at it.; > - You submit a PR and discover that one of the regression tests has; > failed. But...why? You know that something is broken, but its hard to track; > down what broke. You want more granular test coverage that can demonstrate; > what broke.; > - You are fixing a very small bug. You know that you should prove that; > your bug fix worked, but it doesn't seem logical to dedicate an entire; > validation case to one small bug fix. You want to write a small test for a; > small fix.; >; > In all of these cases, unit testing fills a unique role. Unit testing; > increases time spent in development, but decreases the amount of time spent; > in bug-fixing and maintaining.; >; > For more information, see this relevant Stack Exchange question.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499278427:2378,test,test,2378,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427,1,['test'],['test']
Testability,"anual/html_node/Tests.html>. Since autotools is the build system for SU2, this involves minimal changes. Using automake, the build process for building unit tests becomes:. '''; ./bootstrap; ./configure; make; make check; '''. We use Boost's unit testing framework<https://www.boost.org/doc/libs/1_70_0/libs/test/doc/html/index.html>. This provides a convenient set of macros for instatiating tests, grouping tests into suites, and running checks. This choice was based on what is available in our development setup. We have integrated our unit tests into our Travis CI regression testing. Every time we push commits or submit a pull request, the unit tests are run and checked. What is my vision for unit testing in SU2?. I am not proposing that we start trying to get 100% code coverage with pre-existing code. That would not provide a good return on investment. Instead, I see people adding unit tests as they write new code and as they find bugs. For each new behavior added to SU2, tests are first added to document the related existing behavior. These tests serve to check that the existing behavior isn't damaged by the new code. Then new tests are added to prove that the new behavior is working correctly. For bug fixes, the process is simpler. A test is added to confirm that something is not behaving as expected. Then the code is fixed to make the test pass. What frameworks are available?. For a unit testing framework, here are the most popular options, with the following pros and cons:. Roll-your-own. * Requires no external dependencies; * The most flexible option; * Involves the most work to setup; * Will lack some of the more advances features of mature unit-testing frameworks. Boost Test. * Can be header only, statically linked, or dynamically linked; * If statically or dynamically linked, then Boost is not very lightweight; * Easy to add if you're already using Boost. Google Test. * Most common unit-testing framework; * Can be easily combined with Google's powerful GMock ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499250240:3850,test,tests,3850,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240,1,['test'],['tests']
Testability,"are mentioning is the same. I simply united the TIP, LOWER_SIDE and UPPER_SIDE under the marker tag WING. > The initial transient through the domain based on the initial values is unphysical to some extend and if e.g. 'steady state' results are the same for both code versions .... the problem is not that big. Although it differs quite a bit in the temporal evolution tbh; In the results (also in the mail) it looks a bit like it approaches a steady state for Cl and CD. So maybe 1000 timesteps will tell us a bit more 🤔. I guess they converge eventually to the same values. I tried to compare the same case but steady (I attach the summary). Results in this case are fairly similar and (in my opinion) raise no warnings.; [Summary_steady_6_0_1.txt](https://github.com/su2code/SU2/files/3906039/Summary_steady_6_0_1.txt); [Summary_steady_6_2_0.txt](https://github.com/su2code/SU2/files/3906010/Summary_steady_6_2_0.txt). Regarding the unsteady case, I'm aware that this test may have little physics behind (especially if comparing the first timesteps) but I wanted to investigate the reason :). Results are too different and I think these might be one of the reasons behind some discrepancies I'm encountering in my FSI framework. ; My framework for FSI features a restart from a steady solution at t=0 and an unsteady simulation with imposed boundary of the wing marker. The discrepancies in that case are huge and are clearly wrong. I went back to the root and found this weird behaviour comparing the two versions so I thought this might be one cause. > Another thing: There is no tag 6.0.2 😕 ... 6.0.1 and then 6.1.0.. Yep you are right, the version is definitely 6.0.1 as it can be seen from the Summaries: **I'm updating the issue.**. > And both versions are/were on the develop branches -> what exactly do you refer to here: config-files, code, mesh. Didn't quite understand you here. Let me know if you need any other info regarding the topic. Looking forward to hear from you!. Best,; Rocco",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/828#issuecomment-559850074:1301,test,test,1301,https://su2code.github.io,https://github.com/su2code/SU2/issues/828#issuecomment-559850074,1,['test'],['test']
Testability,"avior, ideally using isolated bits of code. It is not; > intended to replace validation testing or formal verification tests.; > Instead, it serves a unique purpose. Consider the three following use cases:; >; > - You're developing a new feature, and you want to test it to see if; > it works. You could do a full simulation, but that takes a lot of time and; > computing power. You want to check if your new behavior behaves as you; > suspect before you throw a lot of resources at it.; > - You submit a PR and discover that one of the regression tests has; > failed. But...why? You know that something is broken, but its hard to track; > down what broke. You want more granular test coverage that can demonstrate; > what broke.; > - You are fixing a very small bug. You know that you should prove that; > your bug fix worked, but it doesn't seem logical to dedicate an entire; > validation case to one small bug fix. You want to write a small test for a; > small fix.; >; > In all of these cases, unit testing fills a unique role. Unit testing; > increases time spent in development, but decreases the amount of time spent; > in bug-fixing and maintaining.; >; > For more information, see this relevant Stack Exchange question.; > <https://scicomp.stackexchange.com/questions/206/is-it-worthwhile-to-write-unit-tests-for-scientific-research-codes>; > What do I propose?; >; > My research group at UT Austing has implemented a unit testing framework; > on our branch, which we're happy with. Some choices were arbitrary, and; > some choices were made based on our development environment. Those choices; > may be different for other groups. Here's what we have done:; >; > The unit testing framework is compiled and run using autotools. For more; > information on autotool's setup, see their documentation; > <https://www.gnu.org/software/automake/manual/html_node/Tests.html>.; > Since autotools is the build system for SU2, this involves minimal changes.; >; > Using automake, the build process for",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499278427:3119,test,testing,3119,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427,1,['test'],['testing']
Testability,"aybe you refer to the develop code at the time where these tags were introduced. But maybe sth different. > I guess they converge eventually to the same values. I tried to compare the same case but steady (I attach the summary). Results in this case are fairly similar and (in my opinion) raise no warnings. That is good to hear. ; Luckily @cvencro (Thanks for that 👍 ) ran some tests and found that #740 (which rewrites Euler Wall boundaries for compressible and incompressible flows ... which was me btw) introduces the changes you see. The Euler wall for compressible is changed a bit in the way the boundary condition is enforced. Upon convergence both version should recover (close to) the same value. If the results in a steady state are the same/very-similar and if an unsteady simulation at low enough Reynolds-number converges to the same steady result (or oscillate in the same bounds) -> I would say it is simply some purely numerical effect based on the unphysical initialization and different treatment of the euler wall boundary. . 1 thing one could test additionally is to force a very high convergence in each physical timestep, i.e. usually one converges ~3 orders of magnitude in each ts -> now try converging until residual stalling in each ts. If the code versions get the same/closer results in the temporal evolution my euler wall boundary explanation would be quite reasonable.; Together with the long running unsteady simulation proposed above, I would feel more comfortable to judge. @cvencro (bringing the conversation to this place 😉 ) concerning the pitching case: the `if (dynamic_grid)` statements in the 'old' version are not necessary as that is handled by the numerics class. In the new version an appropriate 'reflected state' is constructed and the numerics container is called to compute the residual. Before, the code of one numerics ->ComputeResidual Routine was simply copied and slightly modified. But of course there is always room for errors 🐛 . Cheers, Tobi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/828#issuecomment-562621057:1381,test,test,1381,https://su2code.github.io,https://github.com/su2code/SU2/issues/828#issuecomment-562621057,1,['test'],['test']
Testability,"ble-multilib --disable-werror --enable-checking=release --enable-default-pie --enable-default-ssp --enable-cet=auto gdc_include_dir=/usr/include/dlang/gdc; Thread model: posix; gcc version 9.2.1 20200130 (Arch Linux 9.2.1+20200130-2) ; ```; I did what you suggested and here is how my meson.build file looks.; ```; # If custom mpi mode is enabled, include and library pathes for MPI have to be set manually to env variables; if get_option('custom-mpi'); mpi_dep = []; mpi = true; # Otherwise they are automatically determined; else; mpi_dep = [dependency('mpich', required : get_option('with-mpi'))]; # mpi_dep = [dependency('mpi', language:'c', required : get_option('with-mpi')),; # dependency('mpi', language:'cpp', required : get_option('with-mpi'))]; #if mpi_dep[0].found() or mpi_dep[1].found(); # mpi = true; #endif; endif; ```; My SU2 build was successful but there were a couple of warnings.; Also, instead of 870 there were only 772 files in total. Is that okay?; ```; slimshady@arch-linux-hp-probook-g3-450: SU2HOME$ ./ninja -C build install; ninja: Entering directory `build'; [756/772] Generating 'SU2_PY/pySU2/_pysu2.so.p/pySU2.cxx'.; ../SU2_PY/pySU2/../../Common/include/mpi_structure.hpp:348: Warning 325: Nested struct not currently supported (Status ignored); [760/772] Generating 'SU2_PY/pySU2/_pysu2ad.so.p/pySU2ad.cxx'.; ../SU2_PY/pySU2/../../Common/include/mpi_structure.hpp:348: Warning 325: Nested struct not currently supported (Status ignored); [771/772] Installing files.; .; .; ```; Here is the [entire output for `./ninja`](https://github.com/su2code/SU2/files/4672490/ninja_build_mpich.log). Even though the build was successful, SU2 does not seem to run properly. It displays the same thing ""NP"" (`mpirun -n NP ...`) number of times. And the console prints the output in chunks, like 57 iterations suddenly ""NP"" times, then a pause, then 57-119 ""NP"" times and so on. You can see the [logfile here](https://github.com/su2code/SU2/files/4672491/mpirun_SU2_CFD_error.log).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1000#issuecomment-633139474:2628,log,log,2628,https://su2code.github.io,https://github.com/su2code/SU2/issues/1000#issuecomment-633139474,3,['log'],"['log', 'logfile']"
Testability,"cations@github.com>> wrote:. I propose adding a unit-testing framework and unit-tests to SU2. After chatting with @economon<https://github.com/economon>, I've decided to move the discussion here to get additional input. What is unit testing?. For those not familiar with unit testing, unit testing allows the testing of small bits of behavior, ideally using isolated bits of code. It is not intended to replace validation testing or formal verification tests. Instead, it serves a unique purpose. Consider the three following use cases:. * You're developing a new feature, and you want to test it to see if it works. You could do a full simulation, but that takes a lot of time and computing power. You want to check if your new behavior behaves as you suspect before you throw a lot of resources at it.; * You submit a PR and discover that one of the regression tests has failed. But...why? You know that something is broken, but its hard to track down what broke. You want more granular test coverage that can demonstrate what broke.; * You are fixing a very small bug. You know that you should prove that your bug fix worked, but it doesn't seem logical to dedicate an entire validation case to one small bug fix. You want to write a small test for a small fix. In all of these cases, unit testing fills a unique role. Unit testing increases time spent in development, but decreases the amount of time spent in bug-fixing and maintaining. For more information, see this relevant Stack Exchange question.<https://scicomp.stackexchange.com/questions/206/is-it-worthwhile-to-write-unit-tests-for-scientific-research-codes>. What do I propose?. My research group at UT Austing has implemented a unit testing framework on our branch, which we're happy with. Some choices were arbitrary, and some choices were made based on our development environment. Those choices may be different for other groups. Here's what we have done:. The unit testing framework is compiled and run using autotools. For more i",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499250240:1757,test,test,1757,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240,1,['test'],['test']
Testability,"ch, which we're happy with. Some choices were arbitrary, and some choices were made based on our development environment. Those choices may be different for other groups. Here's what we have done:. The unit testing framework is compiled and run using autotools. For more information on autotool's setup, see their documentation<https://www.gnu.org/software/automake/manual/html_node/Tests.html>. Since autotools is the build system for SU2, this involves minimal changes. Using automake, the build process for building unit tests becomes:. '''; ./bootstrap; ./configure; make; make check; '''. We use Boost's unit testing framework<https://www.boost.org/doc/libs/1_70_0/libs/test/doc/html/index.html>. This provides a convenient set of macros for instatiating tests, grouping tests into suites, and running checks. This choice was based on what is available in our development setup. We have integrated our unit tests into our Travis CI regression testing. Every time we push commits or submit a pull request, the unit tests are run and checked. What is my vision for unit testing in SU2?. I am not proposing that we start trying to get 100% code coverage with pre-existing code. That would not provide a good return on investment. Instead, I see people adding unit tests as they write new code and as they find bugs. For each new behavior added to SU2, tests are first added to document the related existing behavior. These tests serve to check that the existing behavior isn't damaged by the new code. Then new tests are added to prove that the new behavior is working correctly. For bug fixes, the process is simpler. A test is added to confirm that something is not behaving as expected. Then the code is fixed to make the test pass. What frameworks are available?. For a unit testing framework, here are the most popular options, with the following pros and cons:. Roll-your-own. * Requires no external dependencies; * The most flexible option; * Involves the most work to setup; * Will lack some",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499250240:3515,test,tests,3515,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240,1,['test'],['tests']
Testability,"choices were made based on our development environment. Those choices; > may be different for other groups. Here's what we have done:; >; > The unit testing framework is compiled and run using autotools. For more; > information on autotool's setup, see their documentation; > <https://www.gnu.org/software/automake/manual/html_node/Tests.html>.; > Since autotools is the build system for SU2, this involves minimal changes.; >; > Using automake, the build process for building unit tests becomes:; >; > '''; > ./bootstrap; > ./configure; > make; > make check; > '''; >; > We use Boost's unit testing framework; > <https://www.boost.org/doc/libs/1_70_0/libs/test/doc/html/index.html>.; > This provides a convenient set of macros for instatiating tests, grouping; > tests into suites, and running checks. This choice was based on what is; > available in our development setup.; >; > We have integrated our unit tests into our Travis CI regression testing.; > Every time we push commits or submit a pull request, the unit tests are run; > and checked.; > What is my vision for unit testing in SU2?; >; > I am *not* proposing that we start trying to get 100% code coverage with; > pre-existing code. That would not provide a good return on investment.; >; > Instead, I see people adding unit tests as they write new code and as they; > find bugs. For each new behavior added to SU2, tests are first added to; > document the related existing behavior. These tests serve to check that the; > existing behavior isn't damaged by the new code. Then new tests are added; > to prove that the new behavior is working correctly. For bug fixes, the; > process is simpler. A test is added to confirm that something is not; > behaving as expected. Then the code is fixed to make the test pass.; > What frameworks are available?; >; > For a unit testing framework, here are the most popular options, with the; > following pros and cons:; > Roll-your-own; >; > - Requires no external dependencies; > - The most flexible",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499278427:4668,test,tests,4668,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427,1,['test'],['tests']
Testability,"ck Exchange question.<https://scicomp.stackexchange.com/questions/206/is-it-worthwhile-to-write-unit-tests-for-scientific-research-codes>. What do I propose?. My research group at UT Austing has implemented a unit testing framework on our branch, which we're happy with. Some choices were arbitrary, and some choices were made based on our development environment. Those choices may be different for other groups. Here's what we have done:. The unit testing framework is compiled and run using autotools. For more information on autotool's setup, see their documentation<https://www.gnu.org/software/automake/manual/html_node/Tests.html>. Since autotools is the build system for SU2, this involves minimal changes. Using automake, the build process for building unit tests becomes:. '''; ./bootstrap; ./configure; make; make check; '''. We use Boost's unit testing framework<https://www.boost.org/doc/libs/1_70_0/libs/test/doc/html/index.html>. This provides a convenient set of macros for instatiating tests, grouping tests into suites, and running checks. This choice was based on what is available in our development setup. We have integrated our unit tests into our Travis CI regression testing. Every time we push commits or submit a pull request, the unit tests are run and checked. What is my vision for unit testing in SU2?. I am not proposing that we start trying to get 100% code coverage with pre-existing code. That would not provide a good return on investment. Instead, I see people adding unit tests as they write new code and as they find bugs. For each new behavior added to SU2, tests are first added to document the related existing behavior. These tests serve to check that the existing behavior isn't damaged by the new code. Then new tests are added to prove that the new behavior is working correctly. For bug fixes, the process is simpler. A test is added to confirm that something is not behaving as expected. Then the code is fixed to make the test pass. What frameworks are ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499250240:3256,test,tests,3256,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240,2,['test'],['tests']
Testability,"comes:; >; > '''; > ./bootstrap; > ./configure; > make; > make check; > '''; >; > We use Boost's unit testing framework; > <https://www.boost.org/doc/libs/1_70_0/libs/test/doc/html/index.html>.; > This provides a convenient set of macros for instatiating tests, grouping; > tests into suites, and running checks. This choice was based on what is; > available in our development setup.; >; > We have integrated our unit tests into our Travis CI regression testing.; > Every time we push commits or submit a pull request, the unit tests are run; > and checked.; > What is my vision for unit testing in SU2?; >; > I am *not* proposing that we start trying to get 100% code coverage with; > pre-existing code. That would not provide a good return on investment.; >; > Instead, I see people adding unit tests as they write new code and as they; > find bugs. For each new behavior added to SU2, tests are first added to; > document the related existing behavior. These tests serve to check that the; > existing behavior isn't damaged by the new code. Then new tests are added; > to prove that the new behavior is working correctly. For bug fixes, the; > process is simpler. A test is added to confirm that something is not; > behaving as expected. Then the code is fixed to make the test pass.; > What frameworks are available?; >; > For a unit testing framework, here are the most popular options, with the; > following pros and cons:; > Roll-your-own; >; > - Requires no external dependencies; > - The most flexible option; > - Involves the most work to setup; > - Will lack some of the more advances features of mature unit-testing; > frameworks.; >; > Boost Test; >; > - Can be header only, statically linked, or dynamically linked; > - If statically or dynamically linked, then Boost is not very; > lightweight; > - Easy to add if you're already using Boost; >; > Google Test; >; > - Most common unit-testing framework; > - Can be easily combined with Google's powerful GMock mocking library; > - Comp",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499278427:5102,test,tests,5102,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427,1,['test'],['tests']
Testability,"e a small test for a small fix. In all of these cases, unit testing fills a unique role. Unit testing increases time spent in development, but decreases the amount of time spent in bug-fixing and maintaining. For more information, see this relevant Stack Exchange question.<https://scicomp.stackexchange.com/questions/206/is-it-worthwhile-to-write-unit-tests-for-scientific-research-codes>. What do I propose?. My research group at UT Austing has implemented a unit testing framework on our branch, which we're happy with. Some choices were arbitrary, and some choices were made based on our development environment. Those choices may be different for other groups. Here's what we have done:. The unit testing framework is compiled and run using autotools. For more information on autotool's setup, see their documentation<https://www.gnu.org/software/automake/manual/html_node/Tests.html>. Since autotools is the build system for SU2, this involves minimal changes. Using automake, the build process for building unit tests becomes:. '''; ./bootstrap; ./configure; make; make check; '''. We use Boost's unit testing framework<https://www.boost.org/doc/libs/1_70_0/libs/test/doc/html/index.html>. This provides a convenient set of macros for instatiating tests, grouping tests into suites, and running checks. This choice was based on what is available in our development setup. We have integrated our unit tests into our Travis CI regression testing. Every time we push commits or submit a pull request, the unit tests are run and checked. What is my vision for unit testing in SU2?. I am not proposing that we start trying to get 100% code coverage with pre-existing code. That would not provide a good return on investment. Instead, I see people adding unit tests as they write new code and as they find bugs. For each new behavior added to SU2, tests are first added to document the related existing behavior. These tests serve to check that the existing behavior isn't damaged by the new code. T",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499250240:3020,test,tests,3020,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240,1,['test'],['tests']
Testability,"e have done:; >; > The unit testing framework is compiled and run using autotools. For more; > information on autotool's setup, see their documentation; > <https://www.gnu.org/software/automake/manual/html_node/Tests.html>.; > Since autotools is the build system for SU2, this involves minimal changes.; >; > Using automake, the build process for building unit tests becomes:; >; > '''; > ./bootstrap; > ./configure; > make; > make check; > '''; >; > We use Boost's unit testing framework; > <https://www.boost.org/doc/libs/1_70_0/libs/test/doc/html/index.html>.; > This provides a convenient set of macros for instatiating tests, grouping; > tests into suites, and running checks. This choice was based on what is; > available in our development setup.; >; > We have integrated our unit tests into our Travis CI regression testing.; > Every time we push commits or submit a pull request, the unit tests are run; > and checked.; > What is my vision for unit testing in SU2?; >; > I am *not* proposing that we start trying to get 100% code coverage with; > pre-existing code. That would not provide a good return on investment.; >; > Instead, I see people adding unit tests as they write new code and as they; > find bugs. For each new behavior added to SU2, tests are first added to; > document the related existing behavior. These tests serve to check that the; > existing behavior isn't damaged by the new code. Then new tests are added; > to prove that the new behavior is working correctly. For bug fixes, the; > process is simpler. A test is added to confirm that something is not; > behaving as expected. Then the code is fixed to make the test pass.; > What frameworks are available?; >; > For a unit testing framework, here are the most popular options, with the; > following pros and cons:; > Roll-your-own; >; > - Requires no external dependencies; > - The most flexible option; > - Involves the most work to setup; > - Will lack some of the more advances features of mature unit-testing; > ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499278427:4728,test,testing,4728,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427,1,['test'],['testing']
Testability,"e useful/worth the investment in some major codes he worked on. Best,. Juan. On Jun 4, 2019, at 2:14 PM, Clark Pederson <notifications@github.com<mailto:notifications@github.com>> wrote:. I propose adding a unit-testing framework and unit-tests to SU2. After chatting with @economon<https://github.com/economon>, I've decided to move the discussion here to get additional input. What is unit testing?. For those not familiar with unit testing, unit testing allows the testing of small bits of behavior, ideally using isolated bits of code. It is not intended to replace validation testing or formal verification tests. Instead, it serves a unique purpose. Consider the three following use cases:. * You're developing a new feature, and you want to test it to see if it works. You could do a full simulation, but that takes a lot of time and computing power. You want to check if your new behavior behaves as you suspect before you throw a lot of resources at it.; * You submit a PR and discover that one of the regression tests has failed. But...why? You know that something is broken, but its hard to track down what broke. You want more granular test coverage that can demonstrate what broke.; * You are fixing a very small bug. You know that you should prove that your bug fix worked, but it doesn't seem logical to dedicate an entire validation case to one small bug fix. You want to write a small test for a small fix. In all of these cases, unit testing fills a unique role. Unit testing increases time spent in development, but decreases the amount of time spent in bug-fixing and maintaining. For more information, see this relevant Stack Exchange question.<https://scicomp.stackexchange.com/questions/206/is-it-worthwhile-to-write-unit-tests-for-scientific-research-codes>. What do I propose?. My research group at UT Austing has implemented a unit testing framework on our branch, which we're happy with. Some choices were arbitrary, and some choices were made based on our development envir",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499250240:1631,test,tests,1631,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240,1,['test'],['tests']
Testability,"eature_adapt branch`. 2. downloaded the Adaptive 2D NACA 0012 example (https://pyamg.saclay.inria.fr/pyamgexamples.html#2dnaca): `adap_NACA0012.cfg`, `mesh_NACA0012_inv.su2`, `NACA0012_ini.dat`. 3. added the following lines to the config:; ```; % Type of sensor used for adaptation; % Options include GOAL (adjoint-based), MACH, PRES; PYADAP_SENSOR= GOAL; % Objective function used for goal-oriented adaptation; OBJECTIVE_FUNCTION= LIFT; % Maximum cell size for adaptation; PYADAP_HMAX= 500.0; % Minimum cell size for adaptation; PYADAP_HMIN= 1e-9; % Gradation factor (typically 1.2-1.8); PYADAP_HGRAD= 1.8; % Norm used for adaptation; % 1.0 or 2.0 recommended for inviscid flows; % 4.0 recommeneded for viscid; ADAP_NORM= 4.0; % Approximate mesh size (NPOI) at each level; PYADAP_COMPLEXITY= (30000, 60000, 120000); % Number of adaptations performed at each level; PYADAP_SUBITE= (3, 3, 3); ```. 4. run the following command: `$ python3 SU2_RUN/mesh_adaptation_amg.py -f adap_ONERAM6.cfg -n 8`. The response I have obtained is the following:; ```; SU2-AMG Anisotropic Mesh Adaptation. Mesh adaptation options:; PYADAP_COMPLEXITY : (30000, 60000, 120000); PYADAP_SUBITE : (2, 2, 2); PYADAP_SENSOR : MACH; PYADAP_HMAX : 500.0; PYADAP_HMIN : 1e-9; PYADAP_HGRAD : 1.8; PYADAP_FLOW_ITER : (2999, 4999, 6999); PYADAP_ADJ_ITER : (2999, 4999, 6999); PYADAP_CFL : (10.0, 15.0, 20.0); PYADAP_RDG : NO. The ./adap folder was deleted. Generating GMF background surface mesh.; ## WARNING: MISSING SU2 MESH FILE KEYWORD: NCORNERS=.; Initial CFD solution is provided.; ```. As expected, a `./ADAP` folder was created, containing these docs: `amg_back_meshb`, `config_CFD.cfd`, `log.err`, `log.out` (sizes 0 byte), `mesh_NACA0012_inv.su2` (link to the mesh), `NACA0012_ini.dat` (link to the file.dat). Did I perform the procedure correctly? Or did I miss something?; If it is correct and complete, which file contains the adaptive mesh? How can I use it since there is no new .su2 file? . Thank you for the big help",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/948#issuecomment-737134105:1829,log,log,1829,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-737134105,2,['log'],['log']
Testability,"economon>, I've decided to move the discussion here to get additional input. What is unit testing?. For those not familiar with unit testing, unit testing allows the testing of small bits of behavior, ideally using isolated bits of code. It is not intended to replace validation testing or formal verification tests. Instead, it serves a unique purpose. Consider the three following use cases:. * You're developing a new feature, and you want to test it to see if it works. You could do a full simulation, but that takes a lot of time and computing power. You want to check if your new behavior behaves as you suspect before you throw a lot of resources at it.; * You submit a PR and discover that one of the regression tests has failed. But...why? You know that something is broken, but its hard to track down what broke. You want more granular test coverage that can demonstrate what broke.; * You are fixing a very small bug. You know that you should prove that your bug fix worked, but it doesn't seem logical to dedicate an entire validation case to one small bug fix. You want to write a small test for a small fix. In all of these cases, unit testing fills a unique role. Unit testing increases time spent in development, but decreases the amount of time spent in bug-fixing and maintaining. For more information, see this relevant Stack Exchange question.<https://scicomp.stackexchange.com/questions/206/is-it-worthwhile-to-write-unit-tests-for-scientific-research-codes>. What do I propose?. My research group at UT Austing has implemented a unit testing framework on our branch, which we're happy with. Some choices were arbitrary, and some choices were made based on our development environment. Those choices may be different for other groups. Here's what we have done:. The unit testing framework is compiled and run using autotools. For more information on autotool's setup, see their documentation<https://www.gnu.org/software/automake/manual/html_node/Tests.html>. Since autotools is t",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499250240:1917,log,logical,1917,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240,1,['log'],['logical']
Testability,"ed the results from the total ""iteration time"" from the history file. Doing that for before and after results allowed computing individual speedup factors for each important routine (in terms of time, otherwise they are all special and important in their own way) e.g. gradients, limiters, upwind/viscous residuals, etc.; ![image](https://user-images.githubusercontent.com/38071223/63292708-30cfa480-c2be-11e9-8d4a-5feb3dc61abf.png). Here is the data by the way: [results.xlsx](https://github.com/su2code/SU2/files/3517492/results.xlsx). As predicted the linear solvers stay the same and routines that are light see more speedup than their arithmetic-intensive friends.; What is surprising to me is how intensive the convective residuals appear to be with only a 7% improvement, so surprising in fact, I do not think the above paints the full picture. Maybe the outlet bandwidth bottleneck (into the Jacobian matrix) is more important.; To put that do the test I switched to Euler-explicit time marching and repeated the measurements:; ![image](https://user-images.githubusercontent.com/38071223/63293351-d8010b80-c2bf-11e9-8135-2502eac1128e.png); Better, but not by much, which means upwind and viscous residuals computations might gain a lot from vectorization (SIMD). And like @economon mentioned even more if they are somehow fused together.; It also means the writes to CSysMatrix are relatively expensive, I think there are two-three reasons for it.; - We do a linear search on each Add/SubtractBlock - This could be replaced by a map.; - The Jacobian contributions are first written into a temporary block - Interleaving the writes with the computation could help mask latency.; - That temporary is not stored contiguously - Which makes it hard to vectorize the writes to CSysMatrix. **So what do I think should be tackled next?**; Hybrid parallelism (wait what?!) from messing about with this case (and more refined versions) it is clear the MG puts some limits on how many cores can be used ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/716#issuecomment-522730951:4361,test,test,4361,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-522730951,1,['test'],['test']
Testability,"ee this relevant Stack Exchange question.; > <https://scicomp.stackexchange.com/questions/206/is-it-worthwhile-to-write-unit-tests-for-scientific-research-codes>; > What do I propose?; >; > My research group at UT Austing has implemented a unit testing framework; > on our branch, which we're happy with. Some choices were arbitrary, and; > some choices were made based on our development environment. Those choices; > may be different for other groups. Here's what we have done:; >; > The unit testing framework is compiled and run using autotools. For more; > information on autotool's setup, see their documentation; > <https://www.gnu.org/software/automake/manual/html_node/Tests.html>.; > Since autotools is the build system for SU2, this involves minimal changes.; >; > Using automake, the build process for building unit tests becomes:; >; > '''; > ./bootstrap; > ./configure; > make; > make check; > '''; >; > We use Boost's unit testing framework; > <https://www.boost.org/doc/libs/1_70_0/libs/test/doc/html/index.html>.; > This provides a convenient set of macros for instatiating tests, grouping; > tests into suites, and running checks. This choice was based on what is; > available in our development setup.; >; > We have integrated our unit tests into our Travis CI regression testing.; > Every time we push commits or submit a pull request, the unit tests are run; > and checked.; > What is my vision for unit testing in SU2?; >; > I am *not* proposing that we start trying to get 100% code coverage with; > pre-existing code. That would not provide a good return on investment.; >; > Instead, I see people adding unit tests as they write new code and as they; > find bugs. For each new behavior added to SU2, tests are first added to; > document the related existing behavior. These tests serve to check that the; > existing behavior isn't damaged by the new code. Then new tests are added; > to prove that the new behavior is working correctly. For bug fixes, the; > process is simple",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499278427:4306,test,test,4306,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427,1,['test'],['test']
Testability,"en new tests are added; > to prove that the new behavior is working correctly. For bug fixes, the; > process is simpler. A test is added to confirm that something is not; > behaving as expected. Then the code is fixed to make the test pass.; > What frameworks are available?; >; > For a unit testing framework, here are the most popular options, with the; > following pros and cons:; > Roll-your-own; >; > - Requires no external dependencies; > - The most flexible option; > - Involves the most work to setup; > - Will lack some of the more advances features of mature unit-testing; > frameworks.; >; > Boost Test; >; > - Can be header only, statically linked, or dynamically linked; > - If statically or dynamically linked, then Boost is not very; > lightweight; > - Easy to add if you're already using Boost; >; > Google Test; >; > - Most common unit-testing framework; > - Can be easily combined with Google's powerful GMock mocking library; > - Compiling and linking can be somewhat painful; >; > Catch2; >; > - Used by FEniCS; > - Makes unit tests easily readable with lots of syntactic sugar.; > - Has a very simple syntax; > - Is header-only; > - Requires C++11 compilation; > - Not as feature rich as Google Test or Boost Test; >; > Questions; >; > - How do developers feel about adding unit tests to SU2?; > - If a unit-testing framework were added to SU2, would you actually; > use it?; > - Do developers have a preference (or experience with) any of the unit; > testing frameworks?; > - Should unit tests be expected when submitting PRs?; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/issues/698?email_source=notifications&email_token=AA5FFRG5U3Z55N4W2XWQED3PY3LJ5A5CNFSM4HTDQXQKYY3PNVWWK3TUL52HS4DFUVEXG43VMWVGG33NNVSW45C7NFSM4GXUGGLA>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AA5FFRHOPE2MUJ2Z5RRV4HTPY3LJ5ANCNFSM4HTDQXQA>; > .; >; >; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499278427:6486,test,tests,6486,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427,4,['test'],"['testing', 'tests']"
Testability,"es were set up correctly. The remaining options like install location and compilers are handled by CMake. Tested this on Ubuntu with CMake 3.15.5 and everything except pySU2ad wrapper compiles. Haven't tested on earlier CMake versions so there might be bugs with them but they should be easy to resolve if any. Related Work. Resolve any issues (bug fix or feature request), note any related PRs, or mention interactions with the work of others, if any. PR Checklist. Put an X by all that apply. You can fill this out after submitting the PR. If you have any questions, don't hesitate to ask! We want to help. These are a guide for you to know what the reviewers will be looking for in your contribution. * I am submitting my contribution to the develop branch.; * My contribution generates no new compiler warnings (try with the '-Wall -Wextra -Wno-unused-parameter -Wno-empty-body' compiler flags).; * My contribution is commented and consistent with SU2 style.; * I have added a test case that demonstrates my contribution, if necessary. ________________________________; You can view, comment on, or merge this pull request online at:. https://github.com/su2code/SU2/pull/814. Commit Summary. * CMake support for SU2. File Changes. * A CMakeLists.txt<https://github.com/su2code/SU2/pull/814/files#diff-0> (147); * A Common/CMakeLists.txt<https://github.com/su2code/SU2/pull/814/files#diff-1> (149); * A SU2_CFD/CMakeLists.txt<https://github.com/su2code/SU2/pull/814/files#diff-2> (143); * A SU2_DEF/CMakeLists.txt<https://github.com/su2code/SU2/pull/814/files#diff-3> (13); * A SU2_DOT/CMakeLists.txt<https://github.com/su2code/SU2/pull/814/files#diff-4> (25); * A SU2_GEO/CMakeLists.txt<https://github.com/su2code/SU2/pull/814/files#diff-5> (9); * A SU2_MSH/CMakeLists.txt<https://github.com/su2code/SU2/pull/814/files#diff-6> (8); * A SU2_PY/CMakeLists.txt<https://github.com/su2code/SU2/pull/814/files#diff-7> (24); * A SU2_PY/pySU2/CMakeLists.txt<https://github.com/su2code/SU2/pull/814/files#d",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/814#issuecomment-552242380:4026,test,test,4026,https://su2code.github.io,https://github.com/su2code/SU2/pull/814#issuecomment-552242380,1,['test'],['test']
Testability,"github.com/su2code/SU2/commit/ac8b3bf7636cc66ca7f47e15935942a6598e1a9f), the `SetRoe_Dissipation` function checked to see if the sensor values were valid regardless of the type of blending selected. Commit [ac8b3bf](https://github.com/su2code/SU2/commit/ac8b3bf7636cc66ca7f47e15935942a6598e1a9f) changed the behavior to only check the sensor values if they will be used. The unit test sets the convective blending to `NTS`, feeds invalid sensor values into `SetRoe_Dissipation` and checks the output. ```cpp; // Used to set the Roe-low-dissipation option; void WriteCfgFile(unsigned short nDim, const char* filename,; std::string blending) {; std::ofstream cfg_file;. cfg_file.open(filename, ios::out);; cfg_file << ""PHYSICAL_PROBLEM= NAVIER_STOKES"" << std::endl;; cfg_file << ""ROE_LOW_DISSIPATION= "" << blending << std::endl;. cfg_file.close();; }. BOOST_AUTO_TEST_CASE(BadSensorsAllowedForNTS) {. /*--- Setup ---*/. const unsigned short nDim = 3;. /*--- Set up the config class for the test ---*/; char cfg_filename[100] = ""convective_blending_test.cfg"";; WriteCfgFile(nDim, cfg_filename, ""NTS"");; CConfig* config = new CConfig(cfg_filename, SU2_CFD, 0, 1, 2, VERB_NONE);; std::remove(cfg_filename);. /*--- Inputs ---*/; const su2double dissipation_i = 0.4;; const su2double dissipation_j = 0.6;; const su2double sensor_i = NAN; // Intentionally unphysical:; const su2double sensor_j = NAN; // Intentionally unphysical:. /*--- Outputs ---*/; su2double dissipation;. /*--- Test ---*/. CNumerics numerics;; numerics.SetRoe_Dissipation(dissipation_i, dissipation_j,; sensor_i, sensor_j,; dissipation, config);. const su2double tolerance = std::numeric_limits<su2double>::epsilon();; BOOST_CHECK_CLOSE_FRACTION(dissipation, 0.5, tolerance);. /*--- Teardown ---*/; delete config;; }; ```. There's a couple problems I would fix if I had more time. Ideally, I would be writing the cfg file to an in-memory stream and not to a file. And realistically, I shouldn't need to use a config file at all for a sim",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499999225:1288,test,test,1288,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499999225,1,['test'],['test']
Testability,"gy terms? I'm talking about terms like:. ![molecular and turbulent diffusion of tke](https://latex.codecogs.com/gif.latex?\left(&space;\mu&space;&plus;&space;\frac{\mu_t}{\sigma_k}\right)\frac{\partial&space;k}{\partial&space;x_j}). This term is listed both in Wilcox's ""Turbulence Modeling for CFD"" book and the [NASA TMR website](https://turbmodels.larc.nasa.gov/implementrans.html). NASA's page basically just copies what Wilcox states, and then says ""This expression in the energy equation is also sometimes neglected."". Rumsey clarified his position in a [2009 report](https://ntrs.nasa.gov/archive/nasa/casi.ntrs.nasa.gov/20090015399.pdf), saying that ""when considering high Mach number compressible boundary layer flows using k-omega models, the conservation of total energy should be configured to include the contribution of the turbulent kinetic energy k... It is sometimes common practice to ignore these effects, which is certainly justified when k is signficantly smaller than the square of the mean velocity."" . But he also states: ""Note that in CFL3D, the turbulence models are decoupled from the mean flow equations, k is *not* included in the definition of the total energy, and the diffusion of k does not appear in the mean flow energy equation for its models tested here."" He also omitted the 2/3 \rho k term in both the production and the turbulent stress tensor, and found that it made little difference even for M=10 wall-bounded flows. SU2's version of SST is in a weird spot right now, where it's using the turbulent kinetic energy in some places but not others. It's using it here:. + Total energy definition; + Production of turbulent kinetic energy; + RANS evolution equations; + Eddy viscosity definition. But not here:. + Molecular and turbulent diffusion of turbulent kinetic energy in the total energy conservation equation; + Isotropic part of the turbulent stress tensor. Is there any rationale behind this split, aside from simply stating that ""this seems to work?""",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/797#issuecomment-548886007:1442,test,tested,1442,https://su2code.github.io,https://github.com/su2code/SU2/issues/797#issuecomment-548886007,1,['test'],['tested']
Testability,"has been an intrinsic part of the the modus operandi in many multi-physics codes at DoE and has been well worth the additional effort. In cases where it makes sense (as described by Clark and in the Stack Exchange discussion) I would advocate for using it moving forward. There may also be some issues that arise multiple times in existing code where a retroactive application of unit testing may also make sense. I am copying Pat Miller, formerly with DoE, who may have more experience on whether such unit testing approaches were useful/worth the investment in some major codes he worked on. Best,. Juan. On Jun 4, 2019, at 2:14 PM, Clark Pederson <notifications@github.com<mailto:notifications@github.com>> wrote:. I propose adding a unit-testing framework and unit-tests to SU2. After chatting with @economon<https://github.com/economon>, I've decided to move the discussion here to get additional input. What is unit testing?. For those not familiar with unit testing, unit testing allows the testing of small bits of behavior, ideally using isolated bits of code. It is not intended to replace validation testing or formal verification tests. Instead, it serves a unique purpose. Consider the three following use cases:. * You're developing a new feature, and you want to test it to see if it works. You could do a full simulation, but that takes a lot of time and computing power. You want to check if your new behavior behaves as you suspect before you throw a lot of resources at it.; * You submit a PR and discover that one of the regression tests has failed. But...why? You know that something is broken, but its hard to track down what broke. You want more granular test coverage that can demonstrate what broke.; * You are fixing a very small bug. You know that you should prove that your bug fix worked, but it doesn't seem logical to dedicate an entire validation case to one small bug fix. You want to write a small test for a small fix. In all of these cases, unit testing fills a un",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499250240:1044,test,testing,1044,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240,3,['test'],['testing']
Testability,"here to get additional input.; > What is unit testing?; >; > For those not familiar with unit testing, unit testing allows the testing; > of small bits of behavior, ideally using isolated bits of code. It is not; > intended to replace validation testing or formal verification tests.; > Instead, it serves a unique purpose. Consider the three following use cases:; >; > - You're developing a new feature, and you want to test it to see if; > it works. You could do a full simulation, but that takes a lot of time and; > computing power. You want to check if your new behavior behaves as you; > suspect before you throw a lot of resources at it.; > - You submit a PR and discover that one of the regression tests has; > failed. But...why? You know that something is broken, but its hard to track; > down what broke. You want more granular test coverage that can demonstrate; > what broke.; > - You are fixing a very small bug. You know that you should prove that; > your bug fix worked, but it doesn't seem logical to dedicate an entire; > validation case to one small bug fix. You want to write a small test for a; > small fix.; >; > In all of these cases, unit testing fills a unique role. Unit testing; > increases time spent in development, but decreases the amount of time spent; > in bug-fixing and maintaining.; >; > For more information, see this relevant Stack Exchange question.; > <https://scicomp.stackexchange.com/questions/206/is-it-worthwhile-to-write-unit-tests-for-scientific-research-codes>; > What do I propose?; >; > My research group at UT Austing has implemented a unit testing framework; > on our branch, which we're happy with. Some choices were arbitrary, and; > some choices were made based on our development environment. Those choices; > may be different for other groups. Here's what we have done:; >; > The unit testing framework is compiled and run using autotools. For more; > information on autotool's setup, see their documentation; > <https://www.gnu.org/software/aut",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499278427:2963,log,logical,2963,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427,1,['log'],['logical']
Testability,"his involves minimal changes.; >; > Using automake, the build process for building unit tests becomes:; >; > '''; > ./bootstrap; > ./configure; > make; > make check; > '''; >; > We use Boost's unit testing framework; > <https://www.boost.org/doc/libs/1_70_0/libs/test/doc/html/index.html>.; > This provides a convenient set of macros for instatiating tests, grouping; > tests into suites, and running checks. This choice was based on what is; > available in our development setup.; >; > We have integrated our unit tests into our Travis CI regression testing.; > Every time we push commits or submit a pull request, the unit tests are run; > and checked.; > What is my vision for unit testing in SU2?; >; > I am *not* proposing that we start trying to get 100% code coverage with; > pre-existing code. That would not provide a good return on investment.; >; > Instead, I see people adding unit tests as they write new code and as they; > find bugs. For each new behavior added to SU2, tests are first added to; > document the related existing behavior. These tests serve to check that the; > existing behavior isn't damaged by the new code. Then new tests are added; > to prove that the new behavior is working correctly. For bug fixes, the; > process is simpler. A test is added to confirm that something is not; > behaving as expected. Then the code is fixed to make the test pass.; > What frameworks are available?; >; > For a unit testing framework, here are the most popular options, with the; > following pros and cons:; > Roll-your-own; >; > - Requires no external dependencies; > - The most flexible option; > - Involves the most work to setup; > - Will lack some of the more advances features of mature unit-testing; > frameworks.; >; > Boost Test; >; > - Can be header only, statically linked, or dynamically linked; > - If statically or dynamically linked, then Boost is not very; > lightweight; > - Easy to add if you're already using Boost; >; > Google Test; >; > - Most common unit-test",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499278427:5028,test,tests,5028,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427,1,['test'],['tests']
Testability,"hoices were made based on our development environment. Those choices may be different for other groups. Here's what we have done:. The unit testing framework is compiled and run using autotools. For more information on autotool's setup, see their documentation<https://www.gnu.org/software/automake/manual/html_node/Tests.html>. Since autotools is the build system for SU2, this involves minimal changes. Using automake, the build process for building unit tests becomes:. '''; ./bootstrap; ./configure; make; make check; '''. We use Boost's unit testing framework<https://www.boost.org/doc/libs/1_70_0/libs/test/doc/html/index.html>. This provides a convenient set of macros for instatiating tests, grouping tests into suites, and running checks. This choice was based on what is available in our development setup. We have integrated our unit tests into our Travis CI regression testing. Every time we push commits or submit a pull request, the unit tests are run and checked. What is my vision for unit testing in SU2?. I am not proposing that we start trying to get 100% code coverage with pre-existing code. That would not provide a good return on investment. Instead, I see people adding unit tests as they write new code and as they find bugs. For each new behavior added to SU2, tests are first added to document the related existing behavior. These tests serve to check that the existing behavior isn't damaged by the new code. Then new tests are added to prove that the new behavior is working correctly. For bug fixes, the process is simpler. A test is added to confirm that something is not behaving as expected. Then the code is fixed to make the test pass. What frameworks are available?. For a unit testing framework, here are the most popular options, with the following pros and cons:. Roll-your-own. * Requires no external dependencies; * The most flexible option; * Involves the most work to setup; * Will lack some of the more advances features of mature unit-testing frameworks. ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499250240:3569,test,testing,3569,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240,1,['test'],['testing']
Testability,"ic part of the the modus operandi in many multi-physics; > codes at DoE and has been well worth the additional effort. In cases where; > it makes sense (as described by Clark and in the Stack Exchange discussion); > I would advocate for using it moving forward. There may also be some; > issues that arise multiple times in existing code where a retroactive; > application of unit testing may also make sense. I am copying Pat Miller,; > formerly with DoE, who may have more experience on whether such unit; > testing approaches were useful/worth the investment in some major codes he; > worked on.; >; > Best,; >; > Juan; >; >; > On Jun 4, 2019, at 2:14 PM, Clark Pederson <notifications@github.com>; > wrote:; >; > I propose adding a unit-testing framework and unit-tests to SU2. After; > chatting with @economon <https://github.com/economon>, I've decided to; > move the discussion here to get additional input.; > What is unit testing?; >; > For those not familiar with unit testing, unit testing allows the testing; > of small bits of behavior, ideally using isolated bits of code. It is not; > intended to replace validation testing or formal verification tests.; > Instead, it serves a unique purpose. Consider the three following use cases:; >; > - You're developing a new feature, and you want to test it to see if; > it works. You could do a full simulation, but that takes a lot of time and; > computing power. You want to check if your new behavior behaves as you; > suspect before you throw a lot of resources at it.; > - You submit a PR and discover that one of the regression tests has; > failed. But...why? You know that something is broken, but its hard to track; > down what broke. You want more granular test coverage that can demonstrate; > what broke.; > - You are fixing a very small bug. You know that you should prove that; > your bug fix worked, but it doesn't seem logical to dedicate an entire; > validation case to one small bug fix. You want to write a small test for a; ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499278427:2003,test,testing,2003,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427,4,['test'],['testing']
Testability,"ime spent in development, but decreases the amount of time spent in bug-fixing and maintaining. For more information, see this relevant Stack Exchange question.<https://scicomp.stackexchange.com/questions/206/is-it-worthwhile-to-write-unit-tests-for-scientific-research-codes>. What do I propose?. My research group at UT Austing has implemented a unit testing framework on our branch, which we're happy with. Some choices were arbitrary, and some choices were made based on our development environment. Those choices may be different for other groups. Here's what we have done:. The unit testing framework is compiled and run using autotools. For more information on autotool's setup, see their documentation<https://www.gnu.org/software/automake/manual/html_node/Tests.html>. Since autotools is the build system for SU2, this involves minimal changes. Using automake, the build process for building unit tests becomes:. '''; ./bootstrap; ./configure; make; make check; '''. We use Boost's unit testing framework<https://www.boost.org/doc/libs/1_70_0/libs/test/doc/html/index.html>. This provides a convenient set of macros for instatiating tests, grouping tests into suites, and running checks. This choice was based on what is available in our development setup. We have integrated our unit tests into our Travis CI regression testing. Every time we push commits or submit a pull request, the unit tests are run and checked. What is my vision for unit testing in SU2?. I am not proposing that we start trying to get 100% code coverage with pre-existing code. That would not provide a good return on investment. Instead, I see people adding unit tests as they write new code and as they find bugs. For each new behavior added to SU2, tests are first added to document the related existing behavior. These tests serve to check that the existing behavior isn't damaged by the new code. Then new tests are added to prove that the new behavior is working correctly. For bug fixes, the process is simpler",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499250240:3110,test,testing,3110,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240,1,['test'],['testing']
Testability,"it testing fills a unique role. Unit testing; > increases time spent in development, but decreases the amount of time spent; > in bug-fixing and maintaining.; >; > For more information, see this relevant Stack Exchange question.; > <https://scicomp.stackexchange.com/questions/206/is-it-worthwhile-to-write-unit-tests-for-scientific-research-codes>; > What do I propose?; >; > My research group at UT Austing has implemented a unit testing framework; > on our branch, which we're happy with. Some choices were arbitrary, and; > some choices were made based on our development environment. Those choices; > may be different for other groups. Here's what we have done:; >; > The unit testing framework is compiled and run using autotools. For more; > information on autotool's setup, see their documentation; > <https://www.gnu.org/software/automake/manual/html_node/Tests.html>.; > Since autotools is the build system for SU2, this involves minimal changes.; >; > Using automake, the build process for building unit tests becomes:; >; > '''; > ./bootstrap; > ./configure; > make; > make check; > '''; >; > We use Boost's unit testing framework; > <https://www.boost.org/doc/libs/1_70_0/libs/test/doc/html/index.html>.; > This provides a convenient set of macros for instatiating tests, grouping; > tests into suites, and running checks. This choice was based on what is; > available in our development setup.; >; > We have integrated our unit tests into our Travis CI regression testing.; > Every time we push commits or submit a pull request, the unit tests are run; > and checked.; > What is my vision for unit testing in SU2?; >; > I am *not* proposing that we start trying to get 100% code coverage with; > pre-existing code. That would not provide a good return on investment.; >; > Instead, I see people adding unit tests as they write new code and as they; > find bugs. For each new behavior added to SU2, tests are first added to; > document the related existing behavior. These tests serve to",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499278427:4131,test,tests,4131,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427,1,['test'],['tests']
Testability,"iversity of Technology.; In August 2017 my colleague and I attended SU2 Summer School in; Kaiserslautern and met the Sci-Comp team developing the SU2. I think moving the main tutorials to the main repository is a good idea. We; declared to contribute some validation cases and written tutorials and; having this in main repository will ease the process of adding/modifying; the docs to a simple pull request. I also have a suggestion regarding the Test Cases and Tutorial files. I; apologize if this is the wrong place or this has been discussed already,; but still will give it a try:; - Test cases folder from SU2/su2code repository shall be moved to the; SU2/TestCases repository. Rationale: this makes one repository to store the; test case *.cfg files and mesh files.; - There shall be a TestCases/Mesh folder to store all the meshes needed for; Test Cases files, without subdivisions for RANS, Euler etc subfolders.; Considering that multiple test cases use the same mesh and all the mesh; files are distinct, this solution generates one place to store all the mesh; files. Should a user perform a test case, he/she will find the mesh by name; referenced in the *.cfg file instead searching thru multiple folders. This; will also help avoiding unnecessary copies of mesh files.; - The same should be done for Tutorial files: Tutorial/Mesh folder for; storing meshes (duplicating these few files from TestCases/Mesh should not; be a problem IMO, but will really help a new user to get up to speed with; SU2); - I have no clear opinion on where the Tutorial files folder should be; stored. But considering moving written tutorials to main repository i think; that tutorial files should also be stored in main SU2/su2code repository. Best regards and Happy New Year; Jędrzej. 2017-12-30 23:45 GMT+01:00 Tim Albring <notifications@github.com>:. > What do you think of moving the written tutorials also to the main; > repository ? Then we can have links in the wiki to the markdown files like; > thi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/485#issuecomment-354736415:1014,test,test,1014,https://su2code.github.io,https://github.com/su2code/SU2/pull/485#issuecomment-354736415,1,['test'],['test']
Testability,"le to have a good set of unit tests. Particularly when you don't have good acceptance tests (hard in a fast; moving research code), it gives a developer confidence that new changes; aren't being fundamental assumptions in the code. It lets sub module; developers build ""armor"" around those assumptions. It is a bit of a cultural thing. People who want robust bits write more.; Some people wire less. At the bank I once worked at, unit tests were required for every module.; Some people wrote code that tested almost nothing. And it would get; through code review that way. Eventually, I added coverage analysis to the check in that exposed this; practice that gave a false assurance that things were ok. More when I can think a bit more on this and get to a real keyboard!. Pat. On Wed, Jun 5, 2019 at 1:50 PM Juan Jose Alonso <jjalonso@stanford.edu>; wrote:. > Clark,; >; > Thanks for putting this idea out there. In my experience, unit testing; > has been an intrinsic part of the the modus operandi in many multi-physics; > codes at DoE and has been well worth the additional effort. In cases where; > it makes sense (as described by Clark and in the Stack Exchange discussion); > I would advocate for using it moving forward. There may also be some; > issues that arise multiple times in existing code where a retroactive; > application of unit testing may also make sense. I am copying Pat Miller,; > formerly with DoE, who may have more experience on whether such unit; > testing approaches were useful/worth the investment in some major codes he; > worked on.; >; > Best,; >; > Juan; >; >; > On Jun 4, 2019, at 2:14 PM, Clark Pederson <notifications@github.com>; > wrote:; >; > I propose adding a unit-testing framework and unit-tests to SU2. After; > chatting with @economon <https://github.com/economon>, I've decided to; > move the discussion here to get additional input.; > What is unit testing?; >; > For those not familiar with unit testing, unit testing allows the testing; > of small ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499278427:1042,test,testing,1042,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427,1,['test'],['testing']
Testability,"major codes he; > worked on.; >; > Best,; >; > Juan; >; >; > On Jun 4, 2019, at 2:14 PM, Clark Pederson <notifications@github.com>; > wrote:; >; > I propose adding a unit-testing framework and unit-tests to SU2. After; > chatting with @economon <https://github.com/economon>, I've decided to; > move the discussion here to get additional input.; > What is unit testing?; >; > For those not familiar with unit testing, unit testing allows the testing; > of small bits of behavior, ideally using isolated bits of code. It is not; > intended to replace validation testing or formal verification tests.; > Instead, it serves a unique purpose. Consider the three following use cases:; >; > - You're developing a new feature, and you want to test it to see if; > it works. You could do a full simulation, but that takes a lot of time and; > computing power. You want to check if your new behavior behaves as you; > suspect before you throw a lot of resources at it.; > - You submit a PR and discover that one of the regression tests has; > failed. But...why? You know that something is broken, but its hard to track; > down what broke. You want more granular test coverage that can demonstrate; > what broke.; > - You are fixing a very small bug. You know that you should prove that; > your bug fix worked, but it doesn't seem logical to dedicate an entire; > validation case to one small bug fix. You want to write a small test for a; > small fix.; >; > In all of these cases, unit testing fills a unique role. Unit testing; > increases time spent in development, but decreases the amount of time spent; > in bug-fixing and maintaining.; >; > For more information, see this relevant Stack Exchange question.; > <https://scicomp.stackexchange.com/questions/206/is-it-worthwhile-to-write-unit-tests-for-scientific-research-codes>; > What do I propose?; >; > My research group at UT Austing has implemented a unit testing framework; > on our branch, which we're happy with. Some choices were arbitrary, and; ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499278427:2663,test,tests,2663,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427,1,['test'],['tests']
Testability,"n for SU2_DEF; - Merge branch 'develop' into feature_dualoutput; - Removed deprecated options from quicstart config.; - Working version of the compressible actuator disk; - Updated fixed CL mode.; - Very minor change; - Merge branch 'develop' into feature_dualoutput; - Final push to 3.2.9; - Merge branch 'develop'; - Minor change; - Minor change; - Small change; - Minor change; - Bug fixing: unsigned short val_vertex --> unsigned long val_vertex; - CFL adapt now works for adjoint problems; - Merge branch 'develop' into feature_dualoutput; - Fixing a typo; - Fix in the Euler BC for grid movement cases; - merging and fixing conflicts bwtn feature_dealloc and develop; - dealloc; - Time spectral fix.; - Merging some recent bug fixes from master into the develop branch to keep nsync.; - Merge branch 'feature_gridvel_fix' into develop; - Merge remote-tracking branch 'upstream/develop' into feature_Deallocation; - correcting issues, adding more deallocation; - fixed uninitialized pointers in CConfig; - further deallocation; - some corrections needed to pass reg tests; - fixed some dealloc issues that caused errors in euler adj; - modifications needed to (mostly) pass reg tests; all run w/o segfault. File Changes; - D Articles/AIAA_2013-0287.pdf (0) ; - D Articles/AIAA_2014-0243.pdf (0) ; - M Common/doc/docmain.hpp (46) ; - M Common/include/config_structure.hpp (1038) ; - M Common/include/config_structure.inl (191) ; - M Common/include/dual_grid_structure.hpp (43) ; - M Common/include/dual_grid_structure.inl (17) ; - M Common/include/geometry_structure.hpp (432) ; - M Common/include/geometry_structure.inl (39) ; - M Common/include/grid_adaptation_structure.hpp (24) ; - M Common/include/grid_adaptation_structure.inl (15) ; - M Common/include/grid_movement_structure.hpp (330) ; - M Common/include/grid_movement_structure.inl (45) ; - M Common/include/linear_solvers_structure.hpp (78) ; - M Common/include/linear_solvers_structure.inl (15) ; - M Common/include/matrix_structure.h",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:10470,test,tests,10470,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,2,['test'],['tests']
Testability,"oc/libs/1_70_0/libs/test/doc/html/index.html>. This provides a convenient set of macros for instatiating tests, grouping tests into suites, and running checks. This choice was based on what is available in our development setup. We have integrated our unit tests into our Travis CI regression testing. Every time we push commits or submit a pull request, the unit tests are run and checked. What is my vision for unit testing in SU2?. I am not proposing that we start trying to get 100% code coverage with pre-existing code. That would not provide a good return on investment. Instead, I see people adding unit tests as they write new code and as they find bugs. For each new behavior added to SU2, tests are first added to document the related existing behavior. These tests serve to check that the existing behavior isn't damaged by the new code. Then new tests are added to prove that the new behavior is working correctly. For bug fixes, the process is simpler. A test is added to confirm that something is not behaving as expected. Then the code is fixed to make the test pass. What frameworks are available?. For a unit testing framework, here are the most popular options, with the following pros and cons:. Roll-your-own. * Requires no external dependencies; * The most flexible option; * Involves the most work to setup; * Will lack some of the more advances features of mature unit-testing frameworks. Boost Test. * Can be header only, statically linked, or dynamically linked; * If statically or dynamically linked, then Boost is not very lightweight; * Easy to add if you're already using Boost. Google Test. * Most common unit-testing framework; * Can be easily combined with Google's powerful GMock mocking library; * Compiling and linking can be somewhat painful. Catch2. * Used by FEniCS; * Makes unit tests easily readable with lots of syntactic sugar.; * Has a very simple syntax; * Is header-only; * Requires C++11 compilation; * Not as feature rich as Google Test or Boost Test. Qu",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499250240:4119,test,test,4119,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240,1,['test'],['test']
Testability,"olvers at ~10k nodes per core and about the same on a newer architecture but only at ~1k node per core.; Since hybrid parallel is supposed to be good for strong scaling, this was not good enough... With the new strategy it is ok (see ""performance"" below), hence this is ready for review. ### Overall Strategy; The strategy now is to start a parallel section in CSysSolve::Solve that covers building the preconditioner and solving the linear system.; Linear algebra routines called within this section have _worksharing_ constructs instead of _parallel_ ones, i.e. the work is distributed by however many threads arrive to that routine. This also makes the routines safe to call in serial.; The only ""dangerous"" things to do in parallel are to: manage memory for a shared object (multiple threads call `new` but there is only one shared pointer on which to call `delete`); writing to the same memory locations concurrently.; I tried to make the first issue debugable by asserting that the initialization routines of CSysMatrix and CSysVector are only called by the master thread.; For the second issue I made the associated classes as const-correct as possible, that should at least make someone think twice before changing a member variable of those classes. The risk is still there for input variables as an algorithm development aspect... For example `MatrixVectorProductTransposed` cannot be made thread-parallel as simply/naively as its normal counterpart. ### Communication Model; The MPI + Threads communication model is very simple, currently only the master thread calls MPI routines (including `Error`), this requires thread barriers before and after the communication to make sure the correct values are passed and _seen_ by all threads.; We can test other alternatives in the future but at the moment this does not seem to be a significant bottleneck.; _Worksharing_ constructs have implicit barriers at completion, for CSysVector routines I used `nowait` modifiers, it is safe to call tho",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/830#issuecomment-562646766:1147,assert,asserting,1147,https://su2code.github.io,https://github.com/su2code/SU2/pull/830#issuecomment-562646766,1,['assert'],['asserting']
Testability,"ork; > on our branch, which we're happy with. Some choices were arbitrary, and; > some choices were made based on our development environment. Those choices; > may be different for other groups. Here's what we have done:; >; > The unit testing framework is compiled and run using autotools. For more; > information on autotool's setup, see their documentation; > <https://www.gnu.org/software/automake/manual/html_node/Tests.html>.; > Since autotools is the build system for SU2, this involves minimal changes.; >; > Using automake, the build process for building unit tests becomes:; >; > '''; > ./bootstrap; > ./configure; > make; > make check; > '''; >; > We use Boost's unit testing framework; > <https://www.boost.org/doc/libs/1_70_0/libs/test/doc/html/index.html>.; > This provides a convenient set of macros for instatiating tests, grouping; > tests into suites, and running checks. This choice was based on what is; > available in our development setup.; >; > We have integrated our unit tests into our Travis CI regression testing.; > Every time we push commits or submit a pull request, the unit tests are run; > and checked.; > What is my vision for unit testing in SU2?; >; > I am *not* proposing that we start trying to get 100% code coverage with; > pre-existing code. That would not provide a good return on investment.; >; > Instead, I see people adding unit tests as they write new code and as they; > find bugs. For each new behavior added to SU2, tests are first added to; > document the related existing behavior. These tests serve to check that the; > existing behavior isn't damaged by the new code. Then new tests are added; > to prove that the new behavior is working correctly. For bug fixes, the; > process is simpler. A test is added to confirm that something is not; > behaving as expected. Then the code is fixed to make the test pass.; > What frameworks are available?; >; > For a unit testing framework, here are the most popular options, with the; > following pros and ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499278427:4558,test,tests,4558,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427,2,['test'],"['testing', 'tests']"
Testability,"ormation on autotool's setup, see their documentation<https://www.gnu.org/software/automake/manual/html_node/Tests.html>. Since autotools is the build system for SU2, this involves minimal changes. Using automake, the build process for building unit tests becomes:. '''; ./bootstrap; ./configure; make; make check; '''. We use Boost's unit testing framework<https://www.boost.org/doc/libs/1_70_0/libs/test/doc/html/index.html>. This provides a convenient set of macros for instatiating tests, grouping tests into suites, and running checks. This choice was based on what is available in our development setup. We have integrated our unit tests into our Travis CI regression testing. Every time we push commits or submit a pull request, the unit tests are run and checked. What is my vision for unit testing in SU2?. I am not proposing that we start trying to get 100% code coverage with pre-existing code. That would not provide a good return on investment. Instead, I see people adding unit tests as they write new code and as they find bugs. For each new behavior added to SU2, tests are first added to document the related existing behavior. These tests serve to check that the existing behavior isn't damaged by the new code. Then new tests are added to prove that the new behavior is working correctly. For bug fixes, the process is simpler. A test is added to confirm that something is not behaving as expected. Then the code is fixed to make the test pass. What frameworks are available?. For a unit testing framework, here are the most popular options, with the following pros and cons:. Roll-your-own. * Requires no external dependencies; * The most flexible option; * Involves the most work to setup; * Will lack some of the more advances features of mature unit-testing frameworks. Boost Test. * Can be header only, statically linked, or dynamically linked; * If statically or dynamically linked, then Boost is not very lightweight; * Easy to add if you're already using Boost. Google Test",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499250240:3762,test,tests,3762,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240,1,['test'],['tests']
Testability,"ouping; > tests into suites, and running checks. This choice was based on what is; > available in our development setup.; >; > We have integrated our unit tests into our Travis CI regression testing.; > Every time we push commits or submit a pull request, the unit tests are run; > and checked.; > What is my vision for unit testing in SU2?; >; > I am *not* proposing that we start trying to get 100% code coverage with; > pre-existing code. That would not provide a good return on investment.; >; > Instead, I see people adding unit tests as they write new code and as they; > find bugs. For each new behavior added to SU2, tests are first added to; > document the related existing behavior. These tests serve to check that the; > existing behavior isn't damaged by the new code. Then new tests are added; > to prove that the new behavior is working correctly. For bug fixes, the; > process is simpler. A test is added to confirm that something is not; > behaving as expected. Then the code is fixed to make the test pass.; > What frameworks are available?; >; > For a unit testing framework, here are the most popular options, with the; > following pros and cons:; > Roll-your-own; >; > - Requires no external dependencies; > - The most flexible option; > - Involves the most work to setup; > - Will lack some of the more advances features of mature unit-testing; > frameworks.; >; > Boost Test; >; > - Can be header only, statically linked, or dynamically linked; > - If statically or dynamically linked, then Boost is not very; > lightweight; > - Easy to add if you're already using Boost; >; > Google Test; >; > - Most common unit-testing framework; > - Can be easily combined with Google's powerful GMock mocking library; > - Compiling and linking can be somewhat painful; >; > Catch2; >; > - Used by FEniCS; > - Makes unit tests easily readable with lots of syntactic sugar.; > - Has a very simple syntax; > - Is header-only; > - Requires C++11 compilation; > - Not as feature rich as Google T",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499278427:5416,test,test,5416,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427,1,['test'],['test']
Testability,"ovides a convenient set of macros for instatiating tests, grouping; > tests into suites, and running checks. This choice was based on what is; > available in our development setup.; >; > We have integrated our unit tests into our Travis CI regression testing.; > Every time we push commits or submit a pull request, the unit tests are run; > and checked.; > What is my vision for unit testing in SU2?; >; > I am *not* proposing that we start trying to get 100% code coverage with; > pre-existing code. That would not provide a good return on investment.; >; > Instead, I see people adding unit tests as they write new code and as they; > find bugs. For each new behavior added to SU2, tests are first added to; > document the related existing behavior. These tests serve to check that the; > existing behavior isn't damaged by the new code. Then new tests are added; > to prove that the new behavior is working correctly. For bug fixes, the; > process is simpler. A test is added to confirm that something is not; > behaving as expected. Then the code is fixed to make the test pass.; > What frameworks are available?; >; > For a unit testing framework, here are the most popular options, with the; > following pros and cons:; > Roll-your-own; >; > - Requires no external dependencies; > - The most flexible option; > - Involves the most work to setup; > - Will lack some of the more advances features of mature unit-testing; > frameworks.; >; > Boost Test; >; > - Can be header only, statically linked, or dynamically linked; > - If statically or dynamically linked, then Boost is not very; > lightweight; > - Easy to add if you're already using Boost; >; > Google Test; >; > - Most common unit-testing framework; > - Can be easily combined with Google's powerful GMock mocking library; > - Compiling and linking can be somewhat painful; >; > Catch2; >; > - Used by FEniCS; > - Makes unit tests easily readable with lots of syntactic sugar.; > - Has a very simple syntax; > - Is header-only; > - Req",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499278427:5309,test,test,5309,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427,1,['test'],['test']
Testability,"ow the CPU pipelining magic to mask the latency of the latter (even if it looks like you can only write the block after it is computed, CPU's have all kinds of buffers that allow the next loop iteration to begin while data is in flight). **Therefore colouring is the way to go.**. _Note: With vectorized numerics we insert blocks for 4 or 8 edges into the matrix at a time, the data for those inserts will be in a slightly weird format, which will make `SparseMatrix::updateBlocks` a bit harder on the eye, more on that later._. ## MUSCL Reconstruction; The MUSCL reconstruction, characteristic of upwind schemes, is the simplest building block to show the (negative) implications of storing the data as structures of arrays (SoA) on the performance of some operations.; Here is the most basic numerics you can think of, reconstruct and average (the dummy matrix loop was to benchmark the writes this is to benchmark the reads); ```c++; void computeResidual(size_t nVar,; size_t nDim,; const vector<size_t>& colorStart,; const vector<size_t>& edgeIdx,; const vector<pair<size_t,size_t> >& connectivity,; const Matrix& coords,; const Matrix& phi,; const VectorOfMatrix& grad,; const Matrix& limiter,; Matrix& residual); {; residual.setZero();. for(size_t color=0; color<colorStart.size()-1; ++color); #pragma omp parallel for schedule(dynamic,CHUNK_SIZE); for(size_t k=colorStart[color]; k<colorStart[color+1]; ++k); {; size_t iEdge = edgeIdx[k];; size_t iPoint = connectivity[iEdge].first;; size_t jPoint = connectivity[iEdge].second;. double d_ij[MAXNDIM];; for(size_t iDim=0; iDim<nDim; ++iDim); d_ij[iDim] = 0.5*(coords(jPoint,iDim)-coords(iPoint,iDim));. for(size_t iVar=0; iVar<nVar; ++iVar); {; double phiL = phi(iPoint,iVar);; double phiR = phi(jPoint,iVar);. for(size_t iDim=0; iDim<nDim; ++iDim); {; phiL += limiter(iPoint,iVar)*grad(iPoint,iVar,iDim)*d_ij[iDim];; phiR -= limiter(jPoint,iVar)*grad(jPoint,iVar,iDim)*d_ij[iDim];; }. double flux = 0.5*(phiL+phiR);. residual(iPoint,iVar) += f",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-535977206:5934,benchmark,benchmark,5934,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206,2,['benchmark'],['benchmark']
Testability,"p team developing the SU2. I think moving the main tutorials to the main repository is a good idea. We; declared to contribute some validation cases and written tutorials and; having this in main repository will ease the process of adding/modifying; the docs to a simple pull request. I also have a suggestion regarding the Test Cases and Tutorial files. I; apologize if this is the wrong place or this has been discussed already,; but still will give it a try:; - Test cases folder from SU2/su2code repository shall be moved to the; SU2/TestCases repository. Rationale: this makes one repository to store the; test case *.cfg files and mesh files.; - There shall be a TestCases/Mesh folder to store all the meshes needed for; Test Cases files, without subdivisions for RANS, Euler etc subfolders.; Considering that multiple test cases use the same mesh and all the mesh; files are distinct, this solution generates one place to store all the mesh; files. Should a user perform a test case, he/she will find the mesh by name; referenced in the *.cfg file instead searching thru multiple folders. This; will also help avoiding unnecessary copies of mesh files.; - The same should be done for Tutorial files: Tutorial/Mesh folder for; storing meshes (duplicating these few files from TestCases/Mesh should not; be a problem IMO, but will really help a new user to get up to speed with; SU2); - I have no clear opinion on where the Tutorial files folder should be; stored. But considering moving written tutorials to main repository i think; that tutorial files should also be stored in main SU2/su2code repository. Best regards and Happy New Year; Jędrzej. 2017-12-30 23:45 GMT+01:00 Tim Albring <notifications@github.com>:. > What do you think of moving the written tutorials also to the main; > repository ? Then we can have links in the wiki to the markdown files like; > this (the link will be much shorter if the files are in the master branch):; > https://github.com/su2code/SU2/blob/0e36facc031aa",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/485#issuecomment-354736415:1169,test,test,1169,https://su2code.github.io,https://github.com/su2code/SU2/pull/485#issuecomment-354736415,1,['test'],['test']
Testability,"rage that can demonstrate; > what broke.; > - You are fixing a very small bug. You know that you should prove that; > your bug fix worked, but it doesn't seem logical to dedicate an entire; > validation case to one small bug fix. You want to write a small test for a; > small fix.; >; > In all of these cases, unit testing fills a unique role. Unit testing; > increases time spent in development, but decreases the amount of time spent; > in bug-fixing and maintaining.; >; > For more information, see this relevant Stack Exchange question.; > <https://scicomp.stackexchange.com/questions/206/is-it-worthwhile-to-write-unit-tests-for-scientific-research-codes>; > What do I propose?; >; > My research group at UT Austing has implemented a unit testing framework; > on our branch, which we're happy with. Some choices were arbitrary, and; > some choices were made based on our development environment. Those choices; > may be different for other groups. Here's what we have done:; >; > The unit testing framework is compiled and run using autotools. For more; > information on autotool's setup, see their documentation; > <https://www.gnu.org/software/automake/manual/html_node/Tests.html>.; > Since autotools is the build system for SU2, this involves minimal changes.; >; > Using automake, the build process for building unit tests becomes:; >; > '''; > ./bootstrap; > ./configure; > make; > make check; > '''; >; > We use Boost's unit testing framework; > <https://www.boost.org/doc/libs/1_70_0/libs/test/doc/html/index.html>.; > This provides a convenient set of macros for instatiating tests, grouping; > tests into suites, and running checks. This choice was based on what is; > available in our development setup.; >; > We have integrated our unit tests into our Travis CI regression testing.; > Every time we push commits or submit a pull request, the unit tests are run; > and checked.; > What is my vision for unit testing in SU2?; >; > I am *not* proposing that we start trying to get 100% ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499278427:3798,test,testing,3798,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427,1,['test'],['testing']
Testability,"re when I can think a bit more on this and get to a real keyboard!. Pat. On Wed, Jun 5, 2019 at 1:50 PM Juan Jose Alonso <jjalonso@stanford.edu>; wrote:. > Clark,; >; > Thanks for putting this idea out there. In my experience, unit testing; > has been an intrinsic part of the the modus operandi in many multi-physics; > codes at DoE and has been well worth the additional effort. In cases where; > it makes sense (as described by Clark and in the Stack Exchange discussion); > I would advocate for using it moving forward. There may also be some; > issues that arise multiple times in existing code where a retroactive; > application of unit testing may also make sense. I am copying Pat Miller,; > formerly with DoE, who may have more experience on whether such unit; > testing approaches were useful/worth the investment in some major codes he; > worked on.; >; > Best,; >; > Juan; >; >; > On Jun 4, 2019, at 2:14 PM, Clark Pederson <notifications@github.com>; > wrote:; >; > I propose adding a unit-testing framework and unit-tests to SU2. After; > chatting with @economon <https://github.com/economon>, I've decided to; > move the discussion here to get additional input.; > What is unit testing?; >; > For those not familiar with unit testing, unit testing allows the testing; > of small bits of behavior, ideally using isolated bits of code. It is not; > intended to replace validation testing or formal verification tests.; > Instead, it serves a unique purpose. Consider the three following use cases:; >; > - You're developing a new feature, and you want to test it to see if; > it works. You could do a full simulation, but that takes a lot of time and; > computing power. You want to check if your new behavior behaves as you; > suspect before you throw a lot of resources at it.; > - You submit a PR and discover that one of the regression tests has; > failed. But...why? You know that something is broken, but its hard to track; > down what broke. You want more granular test coverage th",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499278427:1813,test,testing,1813,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427,2,['test'],"['testing', 'tests']"
Testability,"research group at UT Austing has implemented a unit testing framework on our branch, which we're happy with. Some choices were arbitrary, and some choices were made based on our development environment. Those choices may be different for other groups. Here's what we have done:. The unit testing framework is compiled and run using autotools. For more information on autotool's setup, see their documentation<https://www.gnu.org/software/automake/manual/html_node/Tests.html>. Since autotools is the build system for SU2, this involves minimal changes. Using automake, the build process for building unit tests becomes:. '''; ./bootstrap; ./configure; make; make check; '''. We use Boost's unit testing framework<https://www.boost.org/doc/libs/1_70_0/libs/test/doc/html/index.html>. This provides a convenient set of macros for instatiating tests, grouping tests into suites, and running checks. This choice was based on what is available in our development setup. We have integrated our unit tests into our Travis CI regression testing. Every time we push commits or submit a pull request, the unit tests are run and checked. What is my vision for unit testing in SU2?. I am not proposing that we start trying to get 100% code coverage with pre-existing code. That would not provide a good return on investment. Instead, I see people adding unit tests as they write new code and as they find bugs. For each new behavior added to SU2, tests are first added to document the related existing behavior. These tests serve to check that the existing behavior isn't damaged by the new code. Then new tests are added to prove that the new behavior is working correctly. For bug fixes, the process is simpler. A test is added to confirm that something is not behaving as expected. Then the code is fixed to make the test pass. What frameworks are available?. For a unit testing framework, here are the most popular options, with the following pros and cons:. Roll-your-own. * Requires no external dependencies",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499250240:3408,test,tests,3408,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240,2,['test'],"['testing', 'tests']"
Testability,"rg/software/automake/manual/html_node/Tests.html>.; > Since autotools is the build system for SU2, this involves minimal changes.; >; > Using automake, the build process for building unit tests becomes:; >; > '''; > ./bootstrap; > ./configure; > make; > make check; > '''; >; > We use Boost's unit testing framework; > <https://www.boost.org/doc/libs/1_70_0/libs/test/doc/html/index.html>.; > This provides a convenient set of macros for instatiating tests, grouping; > tests into suites, and running checks. This choice was based on what is; > available in our development setup.; >; > We have integrated our unit tests into our Travis CI regression testing.; > Every time we push commits or submit a pull request, the unit tests are run; > and checked.; > What is my vision for unit testing in SU2?; >; > I am *not* proposing that we start trying to get 100% code coverage with; > pre-existing code. That would not provide a good return on investment.; >; > Instead, I see people adding unit tests as they write new code and as they; > find bugs. For each new behavior added to SU2, tests are first added to; > document the related existing behavior. These tests serve to check that the; > existing behavior isn't damaged by the new code. Then new tests are added; > to prove that the new behavior is working correctly. For bug fixes, the; > process is simpler. A test is added to confirm that something is not; > behaving as expected. Then the code is fixed to make the test pass.; > What frameworks are available?; >; > For a unit testing framework, here are the most popular options, with the; > following pros and cons:; > Roll-your-own; >; > - Requires no external dependencies; > - The most flexible option; > - Involves the most work to setup; > - Will lack some of the more advances features of mature unit-testing; > frameworks.; >; > Boost Test; >; > - Can be header only, statically linked, or dynamically linked; > - If statically or dynamically linked, then Boost is not very; > lightwe",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499278427:4937,test,tests,4937,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427,1,['test'],['tests']
Testability,"rth the additional effort. In cases where it makes sense (as described by Clark and in the Stack Exchange discussion) I would advocate for using it moving forward. There may also be some issues that arise multiple times in existing code where a retroactive application of unit testing may also make sense. I am copying Pat Miller, formerly with DoE, who may have more experience on whether such unit testing approaches were useful/worth the investment in some major codes he worked on. Best,. Juan. On Jun 4, 2019, at 2:14 PM, Clark Pederson <notifications@github.com<mailto:notifications@github.com>> wrote:. I propose adding a unit-testing framework and unit-tests to SU2. After chatting with @economon<https://github.com/economon>, I've decided to move the discussion here to get additional input. What is unit testing?. For those not familiar with unit testing, unit testing allows the testing of small bits of behavior, ideally using isolated bits of code. It is not intended to replace validation testing or formal verification tests. Instead, it serves a unique purpose. Consider the three following use cases:. * You're developing a new feature, and you want to test it to see if it works. You could do a full simulation, but that takes a lot of time and computing power. You want to check if your new behavior behaves as you suspect before you throw a lot of resources at it.; * You submit a PR and discover that one of the regression tests has failed. But...why? You know that something is broken, but its hard to track down what broke. You want more granular test coverage that can demonstrate what broke.; * You are fixing a very small bug. You know that you should prove that your bug fix worked, but it doesn't seem logical to dedicate an entire validation case to one small bug fix. You want to write a small test for a small fix. In all of these cases, unit testing fills a unique role. Unit testing increases time spent in development, but decreases the amount of time spent in bug-fi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499250240:1190,test,testing,1190,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240,2,['test'],"['testing', 'tests']"
Testability,"rward. There may also be some issues that arise multiple times in existing code where a retroactive application of unit testing may also make sense. I am copying Pat Miller, formerly with DoE, who may have more experience on whether such unit testing approaches were useful/worth the investment in some major codes he worked on. Best,. Juan. On Jun 4, 2019, at 2:14 PM, Clark Pederson <notifications@github.com<mailto:notifications@github.com>> wrote:. I propose adding a unit-testing framework and unit-tests to SU2. After chatting with @economon<https://github.com/economon>, I've decided to move the discussion here to get additional input. What is unit testing?. For those not familiar with unit testing, unit testing allows the testing of small bits of behavior, ideally using isolated bits of code. It is not intended to replace validation testing or formal verification tests. Instead, it serves a unique purpose. Consider the three following use cases:. * You're developing a new feature, and you want to test it to see if it works. You could do a full simulation, but that takes a lot of time and computing power. You want to check if your new behavior behaves as you suspect before you throw a lot of resources at it.; * You submit a PR and discover that one of the regression tests has failed. But...why? You know that something is broken, but its hard to track down what broke. You want more granular test coverage that can demonstrate what broke.; * You are fixing a very small bug. You know that you should prove that your bug fix worked, but it doesn't seem logical to dedicate an entire validation case to one small bug fix. You want to write a small test for a small fix. In all of these cases, unit testing fills a unique role. Unit testing increases time spent in development, but decreases the amount of time spent in bug-fixing and maintaining. For more information, see this relevant Stack Exchange question.<https://scicomp.stackexchange.com/questions/206/is-it-worthwhile-to-wr",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499250240:1357,test,test,1357,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240,1,['test'],['test']
Testability,"s a convenient set of macros for instatiating tests, grouping tests into suites, and running checks. This choice was based on what is available in our development setup. We have integrated our unit tests into our Travis CI regression testing. Every time we push commits or submit a pull request, the unit tests are run and checked. What is my vision for unit testing in SU2?. I am not proposing that we start trying to get 100% code coverage with pre-existing code. That would not provide a good return on investment. Instead, I see people adding unit tests as they write new code and as they find bugs. For each new behavior added to SU2, tests are first added to document the related existing behavior. These tests serve to check that the existing behavior isn't damaged by the new code. Then new tests are added to prove that the new behavior is working correctly. For bug fixes, the process is simpler. A test is added to confirm that something is not behaving as expected. Then the code is fixed to make the test pass. What frameworks are available?. For a unit testing framework, here are the most popular options, with the following pros and cons:. Roll-your-own. * Requires no external dependencies; * The most flexible option; * Involves the most work to setup; * Will lack some of the more advances features of mature unit-testing frameworks. Boost Test. * Can be header only, statically linked, or dynamically linked; * If statically or dynamically linked, then Boost is not very lightweight; * Easy to add if you're already using Boost. Google Test. * Most common unit-testing framework; * Can be easily combined with Google's powerful GMock mocking library; * Compiling and linking can be somewhat painful. Catch2. * Used by FEniCS; * Makes unit tests easily readable with lots of syntactic sugar.; * Has a very simple syntax; * Is header-only; * Requires C++11 compilation; * Not as feature rich as Google Test or Boost Test. Questions. * How do developers feel about adding unit tests ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499250240:4223,test,test,4223,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240,1,['test'],['test']
Testability,"s/206/is-it-worthwhile-to-write-unit-tests-for-scientific-research-codes>; > What do I propose?; >; > My research group at UT Austing has implemented a unit testing framework; > on our branch, which we're happy with. Some choices were arbitrary, and; > some choices were made based on our development environment. Those choices; > may be different for other groups. Here's what we have done:; >; > The unit testing framework is compiled and run using autotools. For more; > information on autotool's setup, see their documentation; > <https://www.gnu.org/software/automake/manual/html_node/Tests.html>.; > Since autotools is the build system for SU2, this involves minimal changes.; >; > Using automake, the build process for building unit tests becomes:; >; > '''; > ./bootstrap; > ./configure; > make; > make check; > '''; >; > We use Boost's unit testing framework; > <https://www.boost.org/doc/libs/1_70_0/libs/test/doc/html/index.html>.; > This provides a convenient set of macros for instatiating tests, grouping; > tests into suites, and running checks. This choice was based on what is; > available in our development setup.; >; > We have integrated our unit tests into our Travis CI regression testing.; > Every time we push commits or submit a pull request, the unit tests are run; > and checked.; > What is my vision for unit testing in SU2?; >; > I am *not* proposing that we start trying to get 100% code coverage with; > pre-existing code. That would not provide a good return on investment.; >; > Instead, I see people adding unit tests as they write new code and as they; > find bugs. For each new behavior added to SU2, tests are first added to; > document the related existing behavior. These tests serve to check that the; > existing behavior isn't damaged by the new code. Then new tests are added; > to prove that the new behavior is working correctly. For bug fixes, the; > process is simpler. A test is added to confirm that something is not; > behaving as expected. Then the co",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499278427:4394,test,tests,4394,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427,2,['test'],['tests']
Testability,"scid bump; b) 2D oblique shocks interaction; c) ...; 2) RANS simulations: ; a) Flatplate; b) NACA0012; c) ...; 3) Unsteady simulations:; a) Square Cylinder; b) ...; 4) Turbomachinary: ; a) ... And so on. Each of the directories would have sub-directories for different mesh sizes, with configuration files for each mesh level that have optimized parameters for best results. So for example if we are talking about the NACA0012 case, we would have something along the lines of: . a) NACA0012; i) 113 x 33; ii) 225 x 65 ; iii) 449 x 129; iv) ... This way we have a family of meshes and configuration files that are specifically built for the purpose of validating the code and comparing with other solvers. I might be useful to compress meshes that are larger than a certain size (say 10MB). We should also put a limit on the size of a single mesh that the repository can handle (say 50MB?). . Within the home directory, the README file should list all the cases in the repository, who the custodian of the test case is (person with meshes in case the meshes are too large), and which version it was last run on. . I thought about splitting it up into Verification cases and Validation cases, but I thought it would be more informative and intuitive to split up according to the physics of the simulations. My thinking might be limited because that's how I have seen the TestCases folder organized, so any other suggestions are welcome. I think it is imperative that this is accompanied with a section on the SU2 website that showcases just the results of the validation test cases (grid convergence studies, residual reductions etc) and links to the v&v repo appropriately. This way, if people are just inquisitive about SU2's performance, they can get a quick snapshot of the results, without the need to run the cases themselves. . I also wanted to broach the topic of convergence here. Would it be a good idea to standardize the termination criteria wherever possible? For example, in the NACA0012 c",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/581#issuecomment-426026053:1204,test,test,1204,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-426026053,1,['test'],['test']
Testability,"sting allows the testing of small bits of behavior, ideally using isolated bits of code. It is not intended to replace validation testing or formal verification tests. Instead, it serves a unique purpose. Consider the three following use cases:. * You're developing a new feature, and you want to test it to see if it works. You could do a full simulation, but that takes a lot of time and computing power. You want to check if your new behavior behaves as you suspect before you throw a lot of resources at it.; * You submit a PR and discover that one of the regression tests has failed. But...why? You know that something is broken, but its hard to track down what broke. You want more granular test coverage that can demonstrate what broke.; * You are fixing a very small bug. You know that you should prove that your bug fix worked, but it doesn't seem logical to dedicate an entire validation case to one small bug fix. You want to write a small test for a small fix. In all of these cases, unit testing fills a unique role. Unit testing increases time spent in development, but decreases the amount of time spent in bug-fixing and maintaining. For more information, see this relevant Stack Exchange question.<https://scicomp.stackexchange.com/questions/206/is-it-worthwhile-to-write-unit-tests-for-scientific-research-codes>. What do I propose?. My research group at UT Austing has implemented a unit testing framework on our branch, which we're happy with. Some choices were arbitrary, and some choices were made based on our development environment. Those choices may be different for other groups. Here's what we have done:. The unit testing framework is compiled and run using autotools. For more information on autotool's setup, see their documentation<https://www.gnu.org/software/automake/manual/html_node/Tests.html>. Since autotools is the build system for SU2, this involves minimal changes. Using automake, the build process for building unit tests becomes:. '''; ./bootstrap; ./confi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499250240:2061,test,testing,2061,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240,1,['test'],['testing']
Testability,"t broke. You want more granular test coverage that can demonstrate what broke.; * You are fixing a very small bug. You know that you should prove that your bug fix worked, but it doesn't seem logical to dedicate an entire validation case to one small bug fix. You want to write a small test for a small fix. In all of these cases, unit testing fills a unique role. Unit testing increases time spent in development, but decreases the amount of time spent in bug-fixing and maintaining. For more information, see this relevant Stack Exchange question.<https://scicomp.stackexchange.com/questions/206/is-it-worthwhile-to-write-unit-tests-for-scientific-research-codes>. What do I propose?. My research group at UT Austing has implemented a unit testing framework on our branch, which we're happy with. Some choices were arbitrary, and some choices were made based on our development environment. Those choices may be different for other groups. Here's what we have done:. The unit testing framework is compiled and run using autotools. For more information on autotool's setup, see their documentation<https://www.gnu.org/software/automake/manual/html_node/Tests.html>. Since autotools is the build system for SU2, this involves minimal changes. Using automake, the build process for building unit tests becomes:. '''; ./bootstrap; ./configure; make; make check; '''. We use Boost's unit testing framework<https://www.boost.org/doc/libs/1_70_0/libs/test/doc/html/index.html>. This provides a convenient set of macros for instatiating tests, grouping tests into suites, and running checks. This choice was based on what is available in our development setup. We have integrated our unit tests into our Travis CI regression testing. Every time we push commits or submit a pull request, the unit tests are run and checked. What is my vision for unit testing in SU2?. I am not proposing that we start trying to get 100% code coverage with pre-existing code. That would not provide a good return on investmen",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499250240:2703,test,testing,2703,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240,1,['test'],['testing']
Testability,"te well as shown below. I haven't finished calculating for all design variables, but I think it is enough. ![Comparison_gradient](https://user-images.githubusercontent.com/18245846/129564585-d7812108-d315-4606-83d9-e39a8c9403b3.png). In terms of flow field, the capture below is from the current develop branch. The boundary between structured grid and unstructured gird is a nearfield boundary. An object is above this capture and pressure wave propagates from there. Since this grid is inclined by Mach angle, pressure distribution on the nearfield should be fairly similar to the region above but this capture shows some strange pressure disturbance. Limiter: VAN_ALBADA_EDGE; ![NF_before](https://user-images.githubusercontent.com/18245846/129564639-030fe1b7-7e50-4bb1-9951-21f5ea27bb52.png). Limiter: VENKATAKRISHNAN_WANG; ![NF_before_VEN](https://user-images.githubusercontent.com/18245846/129568934-137681db-04db-40f1-819f-7bcc8c7e0d88.png). The capture below is from the branch with this PR. The issue I mentioned above does not exist. Limiter: VAN_ALBADA_EDGE; ![NF_after](https://user-images.githubusercontent.com/18245846/129564659-cec5a848-1b0b-4051-8298-e3d383dacc6d.png). I think the residuals for direct solver will be different like the adjoint if you run it for some hundreds more iterations (currently, the test case has only 20 iterations). However, since the nearfield boundary is a bit far from an object, it takes some iterations for pressure waves to reach the nearfield boundary. This PR also solves an issue with VENKATAKRISHNAN_WANG limiter. It seems to be much easier for convergence than VAN_ALBADA_EDGE, so it is fairly useful. I still have a gradient un-match issue with my bigger mesh but I believe it is coming from something else. > I'm sorry that you had to spend time fixing that MPI code... But at least we found out we could clean all this obsolete code. Yeah, I noticed it had been deleted. It's OK. It was still a good opportunity for me to learn how MPI works.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1351#issuecomment-899498618:1795,test,test,1795,https://su2code.github.io,https://github.com/su2code/SU2/pull/1351#issuecomment-899498618,1,['test'],['test']
Testability,"tests are first added to document the related existing behavior. These tests serve to check that the existing behavior isn't damaged by the new code. Then new tests are added to prove that the new behavior is working correctly. For bug fixes, the process is simpler. A test is added to confirm that something is not behaving as expected. Then the code is fixed to make the test pass. What frameworks are available?. For a unit testing framework, here are the most popular options, with the following pros and cons:. Roll-your-own. * Requires no external dependencies; * The most flexible option; * Involves the most work to setup; * Will lack some of the more advances features of mature unit-testing frameworks. Boost Test. * Can be header only, statically linked, or dynamically linked; * If statically or dynamically linked, then Boost is not very lightweight; * Easy to add if you're already using Boost. Google Test. * Most common unit-testing framework; * Can be easily combined with Google's powerful GMock mocking library; * Compiling and linking can be somewhat painful. Catch2. * Used by FEniCS; * Makes unit tests easily readable with lots of syntactic sugar.; * Has a very simple syntax; * Is header-only; * Requires C++11 compilation; * Not as feature rich as Google Test or Boost Test. Questions. * How do developers feel about adding unit tests to SU2?; * If a unit-testing framework were added to SU2, would you actually use it?; * Do developers have a preference (or experience with) any of the unit testing frameworks?; * Should unit tests be expected when submitting PRs?. —; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/698?email_source=notifications&email_token=AA5FFRG5U3Z55N4W2XWQED3PY3LJ5A5CNFSM4HTDQXQKYY3PNVWWK3TUL52HS4DFUVEXG43VMWVGG33NNVSW45C7NFSM4GXUGGLA>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AA5FFRHOPE2MUJ2Z5RRV4HTPY3LJ5ANCNFSM4",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499250240:4791,test,testing,4791,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240,2,"['mock', 'test']","['mocking', 'testing']"
Testability,"time spent in bug-fixing and maintaining. For more information, see this relevant Stack Exchange question.<https://scicomp.stackexchange.com/questions/206/is-it-worthwhile-to-write-unit-tests-for-scientific-research-codes>. What do I propose?. My research group at UT Austing has implemented a unit testing framework on our branch, which we're happy with. Some choices were arbitrary, and some choices were made based on our development environment. Those choices may be different for other groups. Here's what we have done:. The unit testing framework is compiled and run using autotools. For more information on autotool's setup, see their documentation<https://www.gnu.org/software/automake/manual/html_node/Tests.html>. Since autotools is the build system for SU2, this involves minimal changes. Using automake, the build process for building unit tests becomes:. '''; ./bootstrap; ./configure; make; make check; '''. We use Boost's unit testing framework<https://www.boost.org/doc/libs/1_70_0/libs/test/doc/html/index.html>. This provides a convenient set of macros for instatiating tests, grouping tests into suites, and running checks. This choice was based on what is available in our development setup. We have integrated our unit tests into our Travis CI regression testing. Every time we push commits or submit a pull request, the unit tests are run and checked. What is my vision for unit testing in SU2?. I am not proposing that we start trying to get 100% code coverage with pre-existing code. That would not provide a good return on investment. Instead, I see people adding unit tests as they write new code and as they find bugs. For each new behavior added to SU2, tests are first added to document the related existing behavior. These tests serve to check that the existing behavior isn't damaged by the new code. Then new tests are added to prove that the new behavior is working correctly. For bug fixes, the process is simpler. A test is added to confirm that something is not beh",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499250240:3171,test,test,3171,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240,1,['test'],['test']
Testability,tname = master; uname -m = x86_64; uname -r = 2.6.32-279.el6.x86_64; uname -s = Linux; uname -v = #1 SMP Wed Jun 13 18:24:36 EDT 2012. /usr/bin/uname -p = unknown; /bin/uname -X = unknown. /bin/arch = x86_64; /usr/bin/arch -k = unknown; /usr/convex/getsysinfo = unknown; /usr/bin/hostinfo = unknown; /bin/machine = unknown; /usr/bin/oslevel = unknown; /bin/universe = unknown. PATH: /opt/xcat/bin; PATH: /opt/xcat/sbin; PATH: /opt/pbs/default/bin; PATH: /opt/pbs/tools/bin; PATH: /usr/lpp/mmfs/bin/; PATH: /gshare/soft/star-ccm+/STAR-View+9.02.007; PATH: /gshare/soft/star-ccm+/STAR-CCM+9.02.007/star/bin; PATH: /opt/xcat/bin; PATH: /opt/xcat/sbin; PATH: /usr/lib64/qt-3.3/bin; PATH: /opt/pbs/default/bin; PATH: /opt/pbs/tools/bin; PATH: /usr/lpp/mmfs/bin/; PATH: /usr/local/bin; PATH: /bin; PATH: /usr/bin; PATH: /usr/local/sbin; PATH: /usr/sbin; PATH: /sbin; PATH: /gshare/soft/init; PATH: /gshare/soft/scripts; PATH: .; PATH: /gshare/soft/init; PATH: /gshare/soft/scripts; PATH: . ## ----------- ##; ## Core tests. ##; ## ----------- ##. configure:2465: checking build system type; configure:2479: result: x86_64-unknown-linux-gnu; configure:2499: checking host system type; configure:2512: result: x86_64-unknown-linux-gnu; configure:2532: checking target system type; configure:2545: result: x86_64-unknown-linux-gnu; configure:2587: checking for a BSD-compatible install; configure:2655: result: /usr/bin/install -c; configure:2666: checking whether build environment is sane; configure:2721: result: yes; configure:2872: checking for a thread-safe mkdir -p; configure:2911: result: /bin/mkdir -p; configure:2918: checking for gawk; configure:2934: found /bin/gawk; configure:2945: result: gawk; configure:2956: checking whether make sets $(MAKE); configure:2978: result: yes; configure:3075: checking whether make supports nested variables; configure:3092: result: yes; configure:3117: checking for style of include used by make; configure:3145: result: GNU; configure:3196: result: >>> MPI su,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:1561,test,tests,1561,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,1,['test'],['tests']
Testability,"w` but there is only one shared pointer on which to call `delete`); writing to the same memory locations concurrently.; I tried to make the first issue debugable by asserting that the initialization routines of CSysMatrix and CSysVector are only called by the master thread.; For the second issue I made the associated classes as const-correct as possible, that should at least make someone think twice before changing a member variable of those classes. The risk is still there for input variables as an algorithm development aspect... For example `MatrixVectorProductTransposed` cannot be made thread-parallel as simply/naively as its normal counterpart. ### Communication Model; The MPI + Threads communication model is very simple, currently only the master thread calls MPI routines (including `Error`), this requires thread barriers before and after the communication to make sure the correct values are passed and _seen_ by all threads.; We can test other alternatives in the future but at the moment this does not seem to be a significant bottleneck.; _Worksharing_ constructs have implicit barriers at completion, for CSysVector routines I used `nowait` modifiers, it is safe to call those routines in sequence since the loop sizes, and static work scheduling specifications are identical.; However, routines that access a CSysVector in a different way, should have an explicit barrier before using the vector (or risk having undefined behaviour). You will see these barriers on entry to matrix-vector product, and every `ComputeXXXPreconditioner` (if you don't, let me know xD). I think those routines are large enough to amortise the cost of this. ### Performance; Disclaimer:; - We are talking about linear solvers only, **you will not see a global improvement yet**.; - The large global improvements from ""hybridization"" will come from the multigrid behaving better on less decomposed domains, and from the ability to independently tune the number of cores used in the linear precondition",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/830#issuecomment-562646766:1934,test,test,1934,https://su2code.github.io,https://github.com/su2code/SU2/pull/830#issuecomment-562646766,1,['test'],['test']
Usability," Boost's unit testing framework<https://www.boost.org/doc/libs/1_70_0/libs/test/doc/html/index.html>. This provides a convenient set of macros for instatiating tests, grouping tests into suites, and running checks. This choice was based on what is available in our development setup. We have integrated our unit tests into our Travis CI regression testing. Every time we push commits or submit a pull request, the unit tests are run and checked. What is my vision for unit testing in SU2?. I am not proposing that we start trying to get 100% code coverage with pre-existing code. That would not provide a good return on investment. Instead, I see people adding unit tests as they write new code and as they find bugs. For each new behavior added to SU2, tests are first added to document the related existing behavior. These tests serve to check that the existing behavior isn't damaged by the new code. Then new tests are added to prove that the new behavior is working correctly. For bug fixes, the process is simpler. A test is added to confirm that something is not behaving as expected. Then the code is fixed to make the test pass. What frameworks are available?. For a unit testing framework, here are the most popular options, with the following pros and cons:. Roll-your-own. * Requires no external dependencies; * The most flexible option; * Involves the most work to setup; * Will lack some of the more advances features of mature unit-testing frameworks. Boost Test. * Can be header only, statically linked, or dynamically linked; * If statically or dynamically linked, then Boost is not very lightweight; * Easy to add if you're already using Boost. Google Test. * Most common unit-testing framework; * Can be easily combined with Google's powerful GMock mocking library; * Compiling and linking can be somewhat painful. Catch2. * Used by FEniCS; * Makes unit tests easily readable with lots of syntactic sugar.; * Has a very simple syntax; * Is header-only; * Requires C++11 compilation;",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499250240:4108,simpl,simpler,4108,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240,1,['simpl'],['simpler']
Usability," first added to document the related existing behavior. These tests serve to check that the existing behavior isn't damaged by the new code. Then new tests are added to prove that the new behavior is working correctly. For bug fixes, the process is simpler. A test is added to confirm that something is not behaving as expected. Then the code is fixed to make the test pass. What frameworks are available?. For a unit testing framework, here are the most popular options, with the following pros and cons:. Roll-your-own. * Requires no external dependencies; * The most flexible option; * Involves the most work to setup; * Will lack some of the more advances features of mature unit-testing frameworks. Boost Test. * Can be header only, statically linked, or dynamically linked; * If statically or dynamically linked, then Boost is not very lightweight; * Easy to add if you're already using Boost. Google Test. * Most common unit-testing framework; * Can be easily combined with Google's powerful GMock mocking library; * Compiling and linking can be somewhat painful. Catch2. * Used by FEniCS; * Makes unit tests easily readable with lots of syntactic sugar.; * Has a very simple syntax; * Is header-only; * Requires C++11 compilation; * Not as feature rich as Google Test or Boost Test. Questions. * How do developers feel about adding unit tests to SU2?; * If a unit-testing framework were added to SU2, would you actually use it?; * Do developers have a preference (or experience with) any of the unit testing frameworks?; * Should unit tests be expected when submitting PRs?. —; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/698?email_source=notifications&email_token=AA5FFRG5U3Z55N4W2XWQED3PY3LJ5A5CNFSM4HTDQXQKYY3PNVWWK3TUL52HS4DFUVEXG43VMWVGG33NNVSW45C7NFSM4GXUGGLA>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AA5FFRHOPE2MUJ2Z5RRV4HTPY3LJ5ANCNFSM4HTDQXQA>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499250240:5035,simpl,simple,5035,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240,1,['simpl'],['simple']
Usability," is to have a ""CMatrixDense"" class, to give concrete examples:; - For RBF interpolation the guy who worked on it before me implemented his own Cholesky and LU factorizations, matrix-matrix, matrix-vector routines, etc.; - @jayantmukho recently needed some eigenvector decomposition's for the uncertainty quantification feature.; - I imagine in some other places of the code similar routines were needed, for example small matrix inversion when computing gradients by weighted least squares (indeed what I need now is a QR decomposition). And, as an added bonus, I think some other areas of the code could be simplified / optimized by adopting a dense matrix format, for example:; - This snipped from the viscous numerics refactoring`for (iDim = 0; iDim < nDim; iDim++) {; TauElem[iDim] = 0.0;; for (jDim = 0; jDim < nDim; jDim++); TauElem[iDim] += tau[iDim][jDim]*UnitNormal[jDim];; }` would simply become `TauElem=tau*UnitNormal`; - Cumbersome allocations like `tau_jacobian_i = new su2double* [nDim];; for (iDim = 0; iDim < nDim; iDim++) {; tau_jacobian_i[iDim] = new su2double [nVar];; }` become `Matrix tau_jacobian_i(nDim,nVar);` and the cleanup is dealt with by the destructor of the object automatically. Now to answer some questions.; @juanjosealonso @erangit LAPACK and BLAS are indeed the standard, so much so that most (all?) newer libraries will call their routines behind the scenes.; However they considerably simplify the user interface by encapsulating the aforementioned construction/destruction and by exposing natural ways of manipulating the matrices, e.g. access entire rows, columns, blocks, etc.; Another issue with using BLAS routines is that we then need to provide a portable version that can be differentiated with CoDi or to implement the exact differentiation (similar to what is done in the ""solve_b"" routines). @vdweide that is not an issue with Eigen because everything is templated and therefore compatible with any type or class that overloads the appropriate arithme",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/643#issuecomment-459653772:1428,simpl,simply,1428,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459653772,1,['simpl'],['simply']
Usability," of the code. So I want to know what is exactly of the develop branch, can't be the code if you understand the tags as I do. Maybe you refer to the develop code at the time where these tags were introduced. But maybe sth different. > I guess they converge eventually to the same values. I tried to compare the same case but steady (I attach the summary). Results in this case are fairly similar and (in my opinion) raise no warnings. That is good to hear. ; Luckily @cvencro (Thanks for that 👍 ) ran some tests and found that #740 (which rewrites Euler Wall boundaries for compressible and incompressible flows ... which was me btw) introduces the changes you see. The Euler wall for compressible is changed a bit in the way the boundary condition is enforced. Upon convergence both version should recover (close to) the same value. If the results in a steady state are the same/very-similar and if an unsteady simulation at low enough Reynolds-number converges to the same steady result (or oscillate in the same bounds) -> I would say it is simply some purely numerical effect based on the unphysical initialization and different treatment of the euler wall boundary. . 1 thing one could test additionally is to force a very high convergence in each physical timestep, i.e. usually one converges ~3 orders of magnitude in each ts -> now try converging until residual stalling in each ts. If the code versions get the same/closer results in the temporal evolution my euler wall boundary explanation would be quite reasonable.; Together with the long running unsteady simulation proposed above, I would feel more comfortable to judge. @cvencro (bringing the conversation to this place 😉 ) concerning the pitching case: the `if (dynamic_grid)` statements in the 'old' version are not necessary as that is handled by the numerics class. In the new version an appropriate 'reflected state' is constructed and the numerics container is called to compute the residual. Before, the code of one numerics ->Co",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/828#issuecomment-562621057:1234,simpl,simply,1234,https://su2code.github.io,https://github.com/su2code/SU2/issues/828#issuecomment-562621057,1,['simpl'],['simply']
Usability," of the directories would have sub-directories for different mesh sizes, with configuration files for each mesh level that have optimized parameters for best results. So for example if we are talking about the NACA0012 case, we would have something along the lines of: . a) NACA0012; i) 113 x 33; ii) 225 x 65 ; iii) 449 x 129; iv) ... This way we have a family of meshes and configuration files that are specifically built for the purpose of validating the code and comparing with other solvers. I might be useful to compress meshes that are larger than a certain size (say 10MB). We should also put a limit on the size of a single mesh that the repository can handle (say 50MB?). . Within the home directory, the README file should list all the cases in the repository, who the custodian of the test case is (person with meshes in case the meshes are too large), and which version it was last run on. . I thought about splitting it up into Verification cases and Validation cases, but I thought it would be more informative and intuitive to split up according to the physics of the simulations. My thinking might be limited because that's how I have seen the TestCases folder organized, so any other suggestions are welcome. I think it is imperative that this is accompanied with a section on the SU2 website that showcases just the results of the validation test cases (grid convergence studies, residual reductions etc) and links to the v&v repo appropriately. This way, if people are just inquisitive about SU2's performance, they can get a quick snapshot of the results, without the need to run the cases themselves. . I also wanted to broach the topic of convergence here. Would it be a good idea to standardize the termination criteria wherever possible? For example, in the NACA0012 case we can ensure that residuals are reduced by 8 orders of magnitude for all meshes. Or for the ONERAM6, we use Cauchy convergence and make sure the C_L is converged to 6 orders of magnitude. This would hav",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/581#issuecomment-426026053:1437,intuit,intuitive,1437,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-426026053,1,['intuit'],['intuitive']
Usability," pass when compiling Tecio and TecioMPI; * SU2_TECIOMPI_CPPFLAGS: flags to pass when compiling TecioMPI, requires SU2_ENABLE_MPI. There is an additional variable that is recognized by CMake scripts - DEBUG, turning it ON enables additional STATUS messages, mainly to check that correct include directories, compile definitions and linked libraries were set up correctly. The remaining options like install location and compilers are handled by CMake. Tested this on Ubuntu with CMake 3.15.5 and everything except pySU2ad wrapper compiles. Haven't tested on earlier CMake versions so there might be bugs with them but they should be easy to resolve if any. Related Work. Resolve any issues (bug fix or feature request), note any related PRs, or mention interactions with the work of others, if any. PR Checklist. Put an X by all that apply. You can fill this out after submitting the PR. If you have any questions, don't hesitate to ask! We want to help. These are a guide for you to know what the reviewers will be looking for in your contribution. * I am submitting my contribution to the develop branch.; * My contribution generates no new compiler warnings (try with the '-Wall -Wextra -Wno-unused-parameter -Wno-empty-body' compiler flags).; * My contribution is commented and consistent with SU2 style.; * I have added a test case that demonstrates my contribution, if necessary. ________________________________; You can view, comment on, or merge this pull request online at:. https://github.com/su2code/SU2/pull/814. Commit Summary. * CMake support for SU2. File Changes. * A CMakeLists.txt<https://github.com/su2code/SU2/pull/814/files#diff-0> (147); * A Common/CMakeLists.txt<https://github.com/su2code/SU2/pull/814/files#diff-1> (149); * A SU2_CFD/CMakeLists.txt<https://github.com/su2code/SU2/pull/814/files#diff-2> (143); * A SU2_DEF/CMakeLists.txt<https://github.com/su2code/SU2/pull/814/files#diff-3> (13); * A SU2_DOT/CMakeLists.txt<https://github.com/su2code/SU2/pull/814/files#diff-4",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/814#issuecomment-552242380:3666,guid,guide,3666,https://su2code.github.io,https://github.com/su2code/SU2/pull/814#issuecomment-552242380,1,['guid'],['guide']
Usability," scheme for a multi-physics problem. To obtain the design accuracy in time, this implies that the loop over the number of time stages is outside the loop over the number of physical disciplines. Hence at a very high level in the hierarchy, the details of the time integration should then be known. The situation becomes even more complicated when one would like to employ time integration schemes that allow for time accurate local time stepping, e.g. the ones we are currently working on for the DG solver. I won't bore you with all the details here, but those schemes basically require the loop over the multiple disciplines to be between the predictor and corrector step, while both these steps consist of multiple stages. Although it is probably possible to come up with a data structure that supports all this, the question is whether this is desirable. Apart from the fact that it would require a major overhaul in the high level design of SU2, the implementation will be less readable, especially for people that will be starting with the code. Also the parallelization may become significantly more complicated. The alternative is that for unsteady multi-physics problems, we put the restriction that only single stage time integration schemes can be used, e.g. DT_STEPPING_1ST and DT_STEPPING_2ND. In that case, the details of the time integration scheme can be hidden at the driver level, where we then simply have a loop over the number of physical disciplines. The consequence of course is that more advanced time integration schemes will not be available for multi-physics problems. In the above I just tried to picture what, in my opinion, the consequences are for either option. I don't have a preference for one of them. The only thing I wanted to make clear is that it is not possible to hide all the details of the time integration scheme at the driver level, while also having support for all possible time integration schemes for an unsteady multi-physics problem. Regards,. Edwin",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/437#issuecomment-328441926:1780,simpl,simply,1780,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328441926,2,"['clear', 'simpl']","['clear', 'simply']"
Usability," silicon, by and large vector instructions have the same latency and throughput of their scalar versions, therefore speedups proportional to the number of SIMD lanes are possible in compute-bound code.; As we saw in #716 there is some of that in the numerics, do not expect 4x speed-ups though, low order unstructured FVM is known to be bandwidth-bound, vectorization helps a bit there too (instructions are also data that needs to travel to the CPU) (maybe for explicit schemes and 8 SIMD lanes, maybe). **Relation with data structures**; There is only one efficient way to move data between memory and registers, via `load` and `store` instructions (they do come in multiple flavors). That is, pointing to a memory location and reading or writing N elements of contiguous data.; It is not the only way, it is also possible to `gather` and `scatter` data. That is populating the register from non-contiguous locations and vice versa. This is about one order of magnitude slower, to the point where if the computations are very simple it may not pay-off to vectorize. **Relation with algorithms**; Some form of `gather` and `scatter` is required in unstructured CFD, which means SIMD has a price of admission. Some thought needs to go into designing algorithms that amortize that cost by maximizing the so called FLOP/Byte ratio, and mask the latency of those operations by being able to start computing as soon as the first element of data is available. **What elements should we try to process simultaneously?**; The choice is between multiple geometric primitives (edges/points) or multiple solution primitives (variables). The latter sounds like a sensible idea until we get to areas of the code where different primitives require different treatment, that and the fact that the number of variables might not fit evenly in the number of lanes can lead to very tricky and non-generic code. Nevertheless if the same code were to be applied to e.g. 4 solution variables, this strategy would likely pe",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-529662724:1617,simpl,simple,1617,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-529662724,1,['simpl'],['simple']
Usability," the solution at the inlet corner is completely wrong, while the outlet is ok most likely because characteristics are outgoing as it is supersonic. The artifacts disappear if we disable MUSCL everywhere (1st order solution) or disable it only on boundaries (not ideal solution, but disabling only on corners would still be good enough for now I believe). Using ```WEIGHTED_LEAST_SQUARES``` seems to not present the same issue, in this test case at least, as the stencil ""does not care"" about the boundary states. The boundary conditions are:; - ```MARKER_SYMMETRY``` at centerline; - ```MARKER_EULER``` at wall; - ```MARKER_RIEMANN= (INLET, TOTAL_CONDITIONS_PT, 904388, 542.13, 1.0, 0.0, 0.0)``` at inlet; - ```MARKER_RIEMANN= (OUTLET, STATIC_PRESSURE, 200000.0, 0.0, 0.0, 0.0, 0.0)``` at outlet. I tried both with and without a slope limiter as there are no discontinuities, but it makes no difference on the artifacts:. ```; SLOPE_LIMITER_FLOW= VENKATAKRISHNAN_WANG; VENKAT_LIMITER_COEFF= 0.1; ```. # Complete test case ZIP; [mdm_coolprop_nozzle.zip](https://github.com/su2code/SU2/files/15403732/mdm_coolprop_nozzle.zip). # Inlet pressure zoom; ![Screenshot from 2024-05-22 15-06-36](https://github.com/su2code/SU2/assets/79575547/9ba71127-cb12-4c5f-8e49-3ea9e839b1f4). # Notation: ; - ""1st order"" no MUSCL; - ""2nd order"" MUSCL as implemented in SU2; - ""2nd order (BC 1st order)"" I simply disabled MUSCL on ALL physical boundaries in the upwind residual computations, see code snippet below. # Proof of concept code modification for ""2nd order (BC 1st order)"":; To show that the error lies in MUSCL/gradients at boundaries I added these two lines of code in the upwind gradient computation; ![image](https://github.com/su2code/SU2/assets/79575547/27f2a79b-824d-4a32-a626-73cd87750c0c). # Residuals:; ![image](https://github.com/su2code/SU2/assets/79575547/3f0800fe-478e-433d-8495-cd4964d0f8ee). # Mesh:; ![image](https://github.com/su2code/SU2/assets/79575547/0ebaf86b-fbf9-40b1-aeb9-8764a90a1440)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/2285#issuecomment-2124781449:1693,simpl,simply,1693,https://su2code.github.io,https://github.com/su2code/SU2/issues/2285#issuecomment-2124781449,1,['simpl'],['simply']
Usability," threads arrive to that routine. This also makes the routines safe to call in serial.; The only ""dangerous"" things to do in parallel are to: manage memory for a shared object (multiple threads call `new` but there is only one shared pointer on which to call `delete`); writing to the same memory locations concurrently.; I tried to make the first issue debugable by asserting that the initialization routines of CSysMatrix and CSysVector are only called by the master thread.; For the second issue I made the associated classes as const-correct as possible, that should at least make someone think twice before changing a member variable of those classes. The risk is still there for input variables as an algorithm development aspect... For example `MatrixVectorProductTransposed` cannot be made thread-parallel as simply/naively as its normal counterpart. ### Communication Model; The MPI + Threads communication model is very simple, currently only the master thread calls MPI routines (including `Error`), this requires thread barriers before and after the communication to make sure the correct values are passed and _seen_ by all threads.; We can test other alternatives in the future but at the moment this does not seem to be a significant bottleneck.; _Worksharing_ constructs have implicit barriers at completion, for CSysVector routines I used `nowait` modifiers, it is safe to call those routines in sequence since the loop sizes, and static work scheduling specifications are identical.; However, routines that access a CSysVector in a different way, should have an explicit barrier before using the vector (or risk having undefined behaviour). You will see these barriers on entry to matrix-vector product, and every `ComputeXXXPreconditioner` (if you don't, let me know xD). I think those routines are large enough to amortise the cost of this. ### Performance; Disclaimer:; - We are talking about linear solvers only, **you will not see a global improvement yet**.; - The large global ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/830#issuecomment-562646766:1710,simpl,simple,1710,https://su2code.github.io,https://github.com/su2code/SU2/pull/830#issuecomment-562646766,1,['simpl'],['simple']
Usability,"# Import issues. In Python 3, relative import behaviour changes.; In Python 2, ""import module"" loads first local module, then system module. In Python 3, it is the opposite. ## Import patterns in SU2 code. If we consider, to simplify, these generic packages:; `package1/p1m1.py`; `package1/p1m2.py`; `package1/__init__.py`. `package2/p2m1.py`; `package2/__init__.py`. In SU2 code we find these patterns:. **Pattern 1**; `package1/__init__.py`; contains. ``` python; import p1m1; import p1m2; ```. These instructions are useless as it is the common behaviour of package.; If a `__init__.py` is defined, I can do from package1 import p1m1 or import package1.p1m1. Do you know why this happens ? Is there an historical reason or other ?; For example, in [`SU2_PY/SU2/__init__.py`](https://github.com/su2code/SU2/blob/master/SU2_PY/SU2/__init__.py) or [`SU2_PY/SU2/mesh/__init__.py`](https://github.com/su2code/SU2/blob/master/SU2_PY/SU2/mesh/__init__.py). **Pattern 2**; `package1/__init__.py`; contains. ``` python; from p1m1 import f; ```. **Pattern 3**; `package1/p1m1.py`; contains. ``` python; from ..p1m2 import f; ```. **Pattern 4**. ``` python; import cPickle as pickle; ```. ## Solution. I suggest these solutions:. **Pattern 1**; delete imports. **Pattern 2**; replace `from p1m1 import f` with `from .p1m1 import f` . See also next solution. **Pattern 3**. This is OK. Another approach is to always use absolute imports, for example. ``` python; from ..p1m2 import f; ```. becomes. ``` python; from package1.p1m2 import f; ```. Result is the same except that it is recommended in [PEP8](https://www.python.org/dev/peps/pep-0008/#id20) but first approach is ok too.; I can do it if you want. **Pattern 4**; Py3 pickle now manage both accelerated cPickle and pure python pickle; See https://docs.python.org/3/whatsnew/3.0.html#library-changes, 4th item.; So replace it with. ``` python; if sys.version_info.major > 2:; # Py3 pickle now manage both accelerated cPickle and pure python pickle; # S",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/246#issuecomment-197397273:225,simpl,simplify,225,https://su2code.github.io,https://github.com/su2code/SU2/issues/246#issuecomment-197397273,1,['simpl'],['simplify']
Usability,"(Krylov solvers, sparse approximate factorizations, etc.) is relatively independent from what I have in mind.; Nevertheless being able to use PETSc or HYPRE would be interesting as it would give us access to AMG, and @talbring 's branch feature_template_linear_solver would make such an integration compatible with AD.; What I would like is to have a ""CMatrixDense"" class, to give concrete examples:; - For RBF interpolation the guy who worked on it before me implemented his own Cholesky and LU factorizations, matrix-matrix, matrix-vector routines, etc.; - @jayantmukho recently needed some eigenvector decomposition's for the uncertainty quantification feature.; - I imagine in some other places of the code similar routines were needed, for example small matrix inversion when computing gradients by weighted least squares (indeed what I need now is a QR decomposition). And, as an added bonus, I think some other areas of the code could be simplified / optimized by adopting a dense matrix format, for example:; - This snipped from the viscous numerics refactoring`for (iDim = 0; iDim < nDim; iDim++) {; TauElem[iDim] = 0.0;; for (jDim = 0; jDim < nDim; jDim++); TauElem[iDim] += tau[iDim][jDim]*UnitNormal[jDim];; }` would simply become `TauElem=tau*UnitNormal`; - Cumbersome allocations like `tau_jacobian_i = new su2double* [nDim];; for (iDim = 0; iDim < nDim; iDim++) {; tau_jacobian_i[iDim] = new su2double [nVar];; }` become `Matrix tau_jacobian_i(nDim,nVar);` and the cleanup is dealt with by the destructor of the object automatically. Now to answer some questions.; @juanjosealonso @erangit LAPACK and BLAS are indeed the standard, so much so that most (all?) newer libraries will call their routines behind the scenes.; However they considerably simplify the user interface by encapsulating the aforementioned construction/destruction and by exposing natural ways of manipulating the matrices, e.g. access entire rows, columns, blocks, etc.; Another issue with using BLAS routines is th",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/643#issuecomment-459653772:1144,simpl,simplified,1144,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459653772,1,['simpl'],['simplified']
Usability,"**Disclaimer**; The performance numbers that follow are based on simple implementations of the methods, I do not claim any of my implementations or choice of methods to be optimal. If you know better speak up.; The data is from the case used to benchmark #753 (see #716), it is by no means an extensive collection of different grid types. I will share code and data with anyone who wants to repeat the tests on the condition they post detailed results. With that out of the way :) ... ### Green-Gauss Gradients. This is the plain edge-loop version of the code with boundary contributions omitted for simplicity:; ```C++; void computeGradients(size_t nEdge,; size_t nPoint,; size_t nVar,; size_t nDim,; const vector<pair<size_t,size_t> >& connectivity,; const Matrix& area,; const vector<double>& volume,; const Matrix& phi,; VectorOfMatrix& grad); {; grad.setZero();. for(size_t iEdge=0; iEdge<nEdge; ++iEdge); {; size_t iPoint = connectivity[iEdge].first;; size_t jPoint = connectivity[iEdge].second;. for(size_t iVar=0; iVar<nVar; ++iVar); {; double phi_ave = 0.5*(phi(iPoint,iVar)+phi(jPoint,iVar));. for(size_t iDim=0; iDim<nDim; ++iDim); {; double flux = phi_ave*area(iEdge,iDim);. grad(iPoint,iVar,iDim) += flux;; grad(jPoint,iVar,iDim) -= flux;; }; }; }. for(size_t iPoint=0; iPoint<nPoint; ++iPoint); for(size_t iVar=0; iVar<nVar; ++iVar); for(size_t iDim=0; iDim<nDim; ++iDim); grad(iPoint,iVar,iDim) /= volume[iPoint];; }; ```; This is more or less what SU2 does with minor differences on how the edges (`connectivity`) and area are stored, there is no vectorization nor easy way to make the loop parallel, this will be the reference for execution times. Suppose now that due to a perfect storm the number of variables is 4, here is how with a few pragmas we get gcc to vectorize:; ```C++; template<size_t nVar>; void computeGradients_impl(size_t nEdge,; size_t nPoint,; size_t nDim,; const vector<pair<size_t,size_t> >& connectivity,; const Matrix& area,; const vector<double>& volume,; con",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-530328194:65,simpl,simple,65,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530328194,2,['simpl'],"['simple', 'simplicity']"
Usability,"**SOLVED** see edit. Hello! I seem to remember that it used to be possible to get angle of attack in the history file? Is this still possible? I would like to be able to just pull the angle of attack out of the history file, along with the aero coeffs.; Context:; I have looked through the custom output document and the reference config file, and (perhaps I am secretly blind), but there does not seem to be a simple output group for it.; Reason I need it: performing analysis for fixed Cl, so angle of attack is useful information. At the moment I am getting probed data:; ```; CUSTOM_OUTPUTS='m_vel_x : Macro{VELOCITY_X};\; m_vel_y : Macro{VELOCITY_Y};\; vel_x1: Probe{$m_vel_x}[-15, -15];\; vel_y1: Probe{$m_vel_y}[-15, -15]'; ```; And just getting the tan(y/x) of the probed values for angle. This works well enough.; The other option I have is stripping the angle of attack out of the forced breakdown file, would prefer to not do, but can. EDIT:. **It can be pulled out of line 2 of flow.meta**",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/2138#issuecomment-1780159397:411,simpl,simple,411,https://su2code.github.io,https://github.com/su2code/SU2/issues/2138#issuecomment-1780159397,1,['simpl'],['simple']
Usability,"-o conftest -g -O2 conftest.c >&5; configure:5041: $? = 0; configure:5041: ./conftest; configure:5041: $? = 0; configure:5055: result: 4; configure:5069: checking size of long int; configure:5074: gcc -o conftest -g -O2 conftest.c >&5; configure:5074: $? = 0; configure:5074: ./conftest; configure:5074: $? = 0; configure:5088: result: 8; configure:5102: checking size of float; configure:5107: gcc -o conftest -g -O2 conftest.c >&5; configure:5107: $? = 0; configure:5107: ./conftest; configure:5107: $? = 0; configure:5121: result: 4; configure:5135: checking size of double; configure:5140: gcc -o conftest -g -O2 conftest.c >&5; configure:5140: $? = 0; configure:5140: ./conftest; configure:5140: $? = 0; configure:5154: result: 8; configure:5168: checking size of void *; configure:5173: gcc -o conftest -g -O2 conftest.c >&5; configure:5173: $? = 0; configure:5173: ./conftest; configure:5173: $? = 0; configure:5187: result: 8; configure:5409: checking X11/Intrinsic.h usability; configure:5409: gcc -c -g -O2 conftest.c >&5; conftest.c:61:27: error: X11/Intrinsic.h: No such file or directory; configure:5409: $? = 1; configure: failed program was:; | /* confdefs.h */; | #define PACKAGE_NAME ""SU2""; | #define PACKAGE_TARNAME ""SU2""; | #define PACKAGE_VERSION ""4.1.0""; | #define PACKAGE_STRING ""SU2 4.1.0""; | #define PACKAGE_BUGREPORT ""su2code-dev@lists.stanford.edu""; | #define PACKAGE_URL ""https://github.com/su2code""; | #define PACKAGE ""SU2""; | #define VERSION ""4.1.0""; | #define STDC_HEADERS 1; | #define HAVE_SYS_TYPES_H 1; | #define HAVE_SYS_STAT_H 1; | #define HAVE_STDLIB_H 1; | #define HAVE_STRING_H 1; | #define HAVE_MEMORY_H 1; | #define HAVE_STRINGS_H 1; | #define HAVE_INTTYPES_H 1; | #define HAVE_STDINT_H 1; | #define HAVE_UNISTD_H 1; | #define SIZEOF_SHORT_INT 2; | #define SIZEOF_INT 4; | #define SIZEOF_UNSIGNED_INT 4; | #define SIZEOF_LONG_INT 8; | #define SIZEOF_FLOAT 4; | #define SIZEOF_DOUBLE 8; | #define SIZEOF_VOID_P 8; | /* end confdefs.h. */; | #include <stdio.h>; ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/250#issuecomment-205167006:12362,usab,usability,12362,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006,1,['usab'],['usability']
Usability,".py script. The command used was:. ```; python3 $SU2_RUN/mesh_adaptation_amg.py -f adapt_Mesh.cfg -n 4; ```; The script initiates the mesh adaptation process as expected, with the following output:. ```; SU2-AMG Anisotropic Mesh Adaptation. Mesh adaptation options:; PYADAP_COMPLEXITY : (30000, 60000, 120000); PYADAP_SUBITE : (2, 2, 2); PYADAP_SENSOR : GOAL; PYADAP_HMAX : 500.0; PYADAP_HMIN : 1e-9; PYADAP_HGRAD : 1.8. ./adap exists. Removing old mesh adaptation in 10s.; The ./adap folder was deleted. Generating GMF background surface mesh.; Initial CFD solution is provided.; ```; However, no _adap\ite0_ folder gets created. ; The log.err file in the _adap/ini_ directory provides this traceback:. ```; Traceback (most recent call last):; File "".../mesh_adaptation_amg.py"", line 111, in <module>; ...; RuntimeError: ...; Error in TokenizeString(): two or more options before an ""="" sign in the configuration file.; terminate called after throwing an instance of 'int'; ...; *** Process received signal ***; Signal: Aborted (6); Signal code: (-6); ...; ```. The critical part of this error seems to be the Error in TokenizeString() message, suggesting an issue with parsing the configuration file. This error typically indicates a syntax problem, such as having multiple options on a single line without proper separation by an equal sign (=). However, upon reviewing _adap/ini/config_CFD.cfg_, was unable to find any lines that clearly violated this syntax rule. Could this error be indicative of a more subtle issue within the configuration file, or might it be related to specific aspects of the feature_adap branch? Any insights, suggestions, or guidance on how to troubleshoot this error would be greatly appreciated. If anyone has a working adapt_mesh.cfg file for a similar setup or for the feature_adap branch, I would be very interested in seeing it. Understanding the configuration details of a working example could be highly beneficial in resolving my issue. Thank you for your help!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/948#issuecomment-1847333809:1771,clear,clearly,1771,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-1847333809,2,"['clear', 'guid']","['clearly', 'guidance']"
Usability,"/21182966/28308831-b937bf76-6ba7-11e7-9108-e8a2ab959b74.png). Then I noticed a difference in SENS_GEO (which is the second term of the upper equation, right?) between compressible and incompressible. . ![image](https://user-images.githubusercontent.com/21182966/28310143-bb28c42a-6bab-11e7-8c14-8409b6b12027.png). So if the scale is adjusting current step size the step of dC and SENS_GEO represents the second term, then the SENS_GEO would change when the scale is changed. But this is not the case for incompressible and compressible. . In short, the only noticeable change, due to scaling, occurs in deformation folder of DSN_002. But this is after the optimization step, which is really confusing. Scaling adjusts the current step size and because it can not find a sufficient decrease it is halving the dv_value. But then one should expect different values in the adjoint folder for different scale factors, right?. I hope you can use this information and can tell me whether it is a correct behavior of the optimizer. I should also note that I did not make use of constraints, just as in the test case. I read that the optimizer will switch from optimization procedure. I think this should not matter because of the test case. . I attached also the configure files (compressible (working, scale= 0.01) and incompressible (not working, scale =0.01)) and the mesh file, which is in both cases the same file. [compressible_cfg.txt](https://github.com/su2code/SU2/files/1155421/compressible_cfg.txt); [incompressible_cfg.txt](https://github.com/su2code/SU2/files/1155427/incompressible_cfg.txt); [mesh_300_su2.txt](https://github.com/su2code/SU2/files/1155430/mesh_300_su2.txt). I hope I provide enough information so that one can clarify the behavior of the optimizer. I also appreciate if one can tell me which variables have to be kept in mind. I really want to learn from this and if more information is needed, I really do not mind to provide it. Many thanks in advance!. Floris van der Schuur",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/409#issuecomment-316018103:4407,learn,learn,4407,https://su2code.github.io,https://github.com/su2code/SU2/issues/409#issuecomment-316018103,1,['learn'],['learn']
Usability,"0| -inf| -inf| -0.006045| 1.258662| -inf|; ; ----------------------------- Solver Exit -------------------------------; All convergence criteria satisfied.; +-----------------------------------------------------------------------+; | Convergence Field | Value | Criterion | Converged |; +-----------------------------------------------------------------------+; | rms[Rho]| -12| < -12| Yes|; +-----------------------------------------------------------------------+. The density plot is; - different from the original `issue_simplified` singlezone solution with implicit Euler and CFL=1000. ; - similar to the `issue_simplified` multizone solution with implicit Euler and CFL=0.1. . Similarly, the TKE plots:; - `issue_simplified` singlezone implicit Euler CFL=1000; ![tke-simplified-singlezone-impliciteuler](https://user-images.githubusercontent.com/72806890/140887227-fc2ed584-53cf-413d-b5ad-18d1a12f5e4a.png); - `issue_simplified` singlezone explicit Euler CFL=0.1; ![tke-simplified-singlezone-expliciteuler](https://user-images.githubusercontent.com/72806890/140887289-0d8725a2-e51b-4704-bdae-a51b492949bf.png); (it is ""red"" throughout the domain, except for the wall marker); - `issue_simplified` multizone explicit Euler CFL=0.1: (similar image, ""red"" everywhere except wall). **Thus, the difference in solutions observed above is due to the choice of implicit vs. explicit Euler and CFL, and not due to problems regarding the interface.**. Am I doing something wrong in the explicit Euler [cfg file](https://seafile.rlp.net/d/bb0fbb16eb414263b642/files/?p=%2Fsinglezone-simplfied-expliciteuler-cfl01.cfg&dl=1), whose diff to the [SU2/TestCases/rans/naca0012/turb_NACA0012_sst.cfg](https://github.com/su2code/SU2/blob/v7.2.0/TestCases/rans/naca0012/turb_NACA0012_sst.cfg) is as follows?. 27c27; < RESTART_SOL= NO; ---; > RESTART_SOL= YES; 45c45; < REYNOLDS_NUMBER= 1.0E6; ---; > REYNOLDS_NUMBER= 6.0E6; 70c70; < MARKER_HEATFLUX= ( circle, 0.0 ); ---; > MARKER_HEATFLUX= ( airfoil, 0.0 ); 76c76",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1414#issuecomment-963921195:2041,simpl,simplified-singlezone-expliciteuler,2041,https://su2code.github.io,https://github.com/su2code/SU2/issues/1414#issuecomment-963921195,1,['simpl'],['simplified-singlezone-expliciteuler']
Usability,"2357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; 14368 Vertex ; 3 Boundary Vertices ; 58189 Tetrahedra ; 1 Triangles ; 0 Edges ; 1 Surface(s) ; % Output subdom.meshb Mesh ndimn=3, mpoin=14368, melem=58189, mface=1; Corners 0 Required 0 ; ## ERROR : TETRAHEDRON 2 BOUNDARY FACE 1 2; 9 IS MISSING ; ## ERROR : TETRAHEDRON 4 BOUNDARY FACE 3 7; 2324 IS MISSING ; ···; ## ERROR: FEFLO.A: 16740 BOUNDARY FACES ARE MISSING ; CHECK YOUR MESH . ## FATAL ERROR: FEFLOA: INITIAL OR CURRENT MESH HAS AN INCONSISTANT TOPOLOGY . Thank you for using feflo.a . ```; Which in turn creates an invalid `amg.su2` mesh in the `adap/ite0 folder`, which triggers the fault.; I'm a bit puzzled as the domain is very simple, and the `log.out` is going well (with no complains of SU2 about any negative volume or trias with wrong normals). The mesh is only made of TRIAS and TETRAS, it should work in principle.; Am I missing something in the setup / mesh? I know you have little control on the `amg.out`, but maybe there some special hint that I'm missing. . Btw the final error in the terminal is but I think the problem arises before reaching `flo.csv` file:; ```; Traceback (most recent call last):; File ""/usr/local/bin/mesh_adaptation_amg.py"", line 111, in <module>; main(); File ""/usr/local/bin/mesh_adaptation_amg.py"", line 72, in main; options.save_all ); File ""/usr/local/bin/mesh_adaptation_amg.py"", line 101, in mesh_adaptation_amg; SU2.run.amg(config); File ""/usr/local/bin/SU2/run/amg.py"", line 464, in amg; os.rename(cur_solfil, cur_solfil_ini); FileNotFoundError: [Errno 2] No such file or directory: 'flo.csv' -> 'flo_ini.csv'. ```; Thanks!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/948#issuecomment-623572280:2200,simpl,simple,2200,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-623572280,1,['simpl'],['simple']
Usability,"> ; > ; > @CatarinaGarbacz thanks for pushing your changes! I have left some comments and questions.; > ; > A bigger question I have is if there is a more general way to deal with SU2_INTERP, making it usable for all of develop. Just answering @WallyMaier comment, this should be possible by changing the file **fem_interpolation_structure.cpp** and change the function call:. output = COutputFactory::CreateOutput(**NEMO_NAVIER_STOKES**, input_config_container[ZONE_0],nDim);. So we have to replace **NEMO_NAVIER_STOKES** to something like **config[val_iZone]->GetKind_Solver()**.; ; I have not tested this change, but I tested changing it for NAVIER_STOKES, and it was able to interpolate the baseline SU2.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1160#issuecomment-760110555:202,usab,usable,202,https://su2code.github.io,https://github.com/su2code/SU2/pull/1160#issuecomment-760110555,1,['usab'],['usable']
Usability,"> ; > ; > @tollennaert, can you comment on the points raised by @pcarruscag ? I think you tried to address all points in your latest update? That makes it clear to everybody that all points have been addressed. I hope you still have time for this. I indeed tried to solve all issues that were mentioned earlier. Could you take another look to see whether I have done this well enough?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1076#issuecomment-741601433:155,clear,clear,155,https://su2code.github.io,https://github.com/su2code/SU2/pull/1076#issuecomment-741601433,1,['clear'],['clear']
Usability,"> ; > ; > Dark mode?; > ""Is it possible to learn this power?"". 🧙 Sure, if you just go to your front page (i.e. just github.com) there should be a big button directly on the right side. ; Or Settings->Appearance->Dark. Enjoy :)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1129#issuecomment-743130745:43,learn,learn,43,https://su2code.github.io,https://github.com/su2code/SU2/pull/1129#issuecomment-743130745,1,['learn'],['learn']
Usability,"> ; > ; > Dear Daumantas,; > ; > I appreciate your effort in adding support for cmake in SU2. We have recently introduced the Meson build system (https://mesonbuild.com/) (#685, #745) as a candidate to replace automake. A guide on how to use can be found [here](https://su2code.github.io/docs_v7/Build-SU2-From-Source/). The idea is that we will have this system along automake at least for the upcoming version 7 and that we get rid of automake afterwards. Considering that, I don't think that it makes sense to maintain 3 different build systems **at the moment**. I really hate turning contributions down, but this one is three months too late. However, we might reconsider adding support for another build system once we got rid of automake, or, if we feel that meson does not fit our needs.; > ; > I am all ears to hear other opinions. However, let's not start a discussion on the advantages/disadvantages of the build systems. Some benefits can be found in the Issue/PR linked above. Ok, I tried meson with MinGW but couldn't figure out how to link with MSMPI since it's not a part of MinGW. However, using CMake and with a few source code fixes, I managed to compile nearly every configuration with MSVC. Surprisingly, there were very few errors in SU2. The externals only had a few preprocessor issues. At the moment only MeDiPack fails to compile with MSVC but not with MinGW even though the MPI headers are the same so I suspect it's an issue with MSVC itself, I'm using the latest preview version.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/814#issuecomment-553571450:222,guid,guide,222,https://su2code.github.io,https://github.com/su2code/SU2/pull/814#issuecomment-553571450,1,['guid'],['guide']
Usability,"> > @jayantmukho : I am finding that the clipping limits for the SST model are very important for the UQ cases. If you adjust them slightly, the UQ regression cases tend to diverge immediately. Don't think any immediate action is needed, just wanted to bring it to your attention.; > ; > Mhmmm, that's a little odd. I wouldn't think that the UQ methodology would be affected by the clipping. I will look into this. Just to be clear, you are changing the lowerlimit and upperlimit in CTurbSSTSolver constructor? What are you changing them too? Just want to reproduce the issue. If you revert my last commit, you will see the issue. It diverges right away for me, so perhaps it is just something with the initial transient that is caught by the clipping",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/790#issuecomment-551351016:426,clear,clear,426,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-551351016,1,['clear'],['clear']
Usability,"> > I find your work really interesting. I've been studying the internal flow field in compressors and have had good results using SU2's SA_EDDES for calculating the cantilevered stator with a tip clearance. If you need help with code verification, I'd be glad to assist.; > ; > Hi @Linnnnnn23, every help on the validation/verification is gladly accepted! Let me know if you need anything by my side.; Thank you for your response. Firstly, I would like to know what Verification and Validation (V&V) work has been conducted on the SST-based DDES (Delayed Detached Eddy Simulation) model to date. Secondly, we can provide a compressor cascade validation, with an inlet Mach number of 0.4, a Reynolds number of approximately 500,000, and a spanwise height of about 20% of the chord length, ensuring that the vortices resolved by DDES can develop in three dimensions. Thirdly, as I am a rookie to GitHub, I have not yet found out how to download your pull request code. For further communication, you can contact me via email at linnnnnn2308@gmail.com",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/2150#issuecomment-2072057976:197,clear,clearance,197,https://su2code.github.io,https://github.com/su2code/SU2/pull/2150#issuecomment-2072057976,1,['clear'],['clearance']
Usability,"> > I'm thinking about reusing the SST test case ([axisymmetric_rans/air_nozzle](https://github.com/su2code/SU2/tree/master/TestCases/axisymmetric_rans/air_nozzle)) so that the same mesh can be used. Would that be fine ?; > ; > That's a quite specific testcase. How did you test the implementation? Do you have some simple results for the turbulent axisymmetric jet? We know that the results for round jets are not super good for standard SA, but at least we know what the result should look like, here on p.32 - 35 they test SA for the round jet and compare to the Wygnanski & Fiedler measurements: https://www.researchgate.net/publication/24296213_Turbulence_Modeling_Validation_Testing_and_Development; > ; > The domain is just a rectangle so pretty simple to set up.; > ; > You could also use the V&V test that we have, but it is a variable density jet: https://su2code.github.io/vandv/SANDIA_jet/. I did some tests on a supersonic jet, since I already had the files, but it's a quite complex case so it's not that good to verify the implementation. I will look into the simpler cases you mentioned !",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/2197#issuecomment-1891046092:316,simpl,simple,316,https://su2code.github.io,https://github.com/su2code/SU2/pull/2197#issuecomment-1891046092,3,['simpl'],"['simple', 'simpler']"
Usability,> @EvertBunschoten even if the performance isn't great this is a pretty small change so I think we can merge it. Do you have time to wrap it up and add a simple regression test?. I just added a test case and tutorial under the TestCases and Tutorials repo under the same branch name. I'm also writing a short tutorial on the SU2 website repo.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/2152#issuecomment-2271237145:154,simpl,simple,154,https://su2code.github.io,https://github.com/su2code/SU2/pull/2152#issuecomment-2271237145,1,['simpl'],['simple']
Usability,"> @SumanVajjala gcc 5+ have full c++ 11 support (even more than that actually). As a last resort, if you cannot figure out what is going on with the compilers (simpler guess is that there are other versions installed and they are getting mixed up?), you can try replacing the file ""allocation_toolbox.hpp"" by this:; > [allocation_toolbox_PATCH.txt](https://github.com/su2code/SU2/files/4550786/allocation_toolbox_PATCH.txt). @pcarruscag Thank you very much. This works. I have installed a sequential version and a parallel version with tecio,codipack and medipack enabled. I will try the same with Intel compilers and see if it works. Regards; Suman",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/955#issuecomment-621164605:160,simpl,simpler,160,https://su2code.github.io,https://github.com/su2code/SU2/issues/955#issuecomment-621164605,1,['simpl'],['simpler']
Usability,"> @aeroamit What does temperature do? Could you compute the heat flux from the temperature in e.g. paraview? Is the root cause the computation of the energy equation or the computation of heat flux?. Hi @bigfooted, Temperature boundary condition for wall corresponds to Isothermal wall BC (cold wall condition). This condition is applied to obtain heat flux unlike adiabatic wall (no heat transfer). ; The snapshot, I posted from ParaView shows heat flux variation with x. This is obtained directly from surface_flow.vtu. You can simply go to Filters -> Data Analysis -> Plot data and select Points_X for X Array and heat flux in variable. Regarding computing heat flux from temperature field, I am not sure, but ParaView is having calculator utility as well as option to compute gradient of unstructured grid (from there you can obtain temperature gradients in 3 directions). ; Coming to last question, root cause of the problem - @WallyMaier has run the case yesterday, we will be posting some details soon.; Best ; Amit",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1106#issuecomment-741947377:530,simpl,simply,530,https://su2code.github.io,https://github.com/su2code/SU2/pull/1106#issuecomment-741947377,1,['simpl'],['simply']
Usability,"> @bigfooted @EvertBunschoten Well fwiw the simplest way is to checkout a new branch from before the merge and open a new PR, there are no coments here yet, so its fine. (If you git revert the merge it will be a pain to then merge the other PRs). I did a git reset --merge ""commit-id"" to go back to my latest commit. I think this completely removed Evert's merge without any residual effects. So should we create a new PR or not? Your 'its fine' comment has ambiguous meaning :-)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1826#issuecomment-1328075694:44,simpl,simplest,44,https://su2code.github.io,https://github.com/su2code/SU2/pull/1826#issuecomment-1328075694,1,['simpl'],['simplest']
Usability,"> @jayantmukho : I am finding that the clipping limits for the SST model are very important for the UQ cases. If you adjust them slightly, the UQ regression cases tend to diverge immediately. Don't think any immediate action is needed, just wanted to bring it to your attention. Mhmmm, that's a little odd. I wouldn't think that the UQ methodology would be affected by the clipping. I will look into this. Just to be clear, you are changing the lowerlimit and upperlimit in CTurbSSTSolver constructor? What are you changing them too? Just want to reproduce the issue",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/790#issuecomment-551323531:417,clear,clear,417,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-551323531,1,['clear'],['clear']
Usability,"> @kursatyurt Hello, thank you so much for the lead.; > ; > Our initial scope mostly involved writing our own kernels and I did explore some libraries at the start - I was planning on using CUSP as well but my main concern was its lack of being updated to the newly compatible versions of the toolkit. cuSolver and cuBLAS do exist, but I chose to go ahead with a ""simple"" kernel implementation to have more control. I also felt that if I could keep the block size of the grid in optimal territory then they could be just as fast as those options (please do correct me if my reading of the literature or the situation was incorrect). To learn the basics, it's a good idea, but for large-scale projects, I prefer using existing libraries if possible.; Those libraries generally exploit state-of-the-art solution like mixed-precision computing. A gaming GPU is not way faster than a good CPU in double precision, but way faster in single precision, most of them have 64:1 ratio, however server class GPU have 2:1 ratio. Also when available they use vendor libraries like cuBLAS or hipBLAS. It is always nice to have you only care about connection and somebody else handle the solver as performant as possible. In future probably they will provide more and more solvers and it will be automagically works. It is kind of light-weight too, not a huge dependency like Trilinos or PETSc. ; > ; > I was not aware of Ginkgo and I will surely give it a go and try to produce some comparative results. I am currently super busy for this month and will get to working on the code with some delay.; > ; > Again, thank you for the lead!. I can test on various GPUs (P100/V100/A100 and 4070Mobile) on single node multi-gpu etc.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/2346#issuecomment-2397803409:364,simpl,simple,364,https://su2code.github.io,https://github.com/su2code/SU2/pull/2346#issuecomment-2397803409,2,"['learn', 'simpl']","['learn', 'simple']"
Usability,"> Aside from my last two comments, and the possibility I broke the code :), this looks ready. Is this missing anything, or is it ready to merge?. Thank you so much @pcarruscag for your feedback. there is one thing left, it is about the residuals of the test case (species2_primitiveVenturi_mixingmodel.cfg) that I added in the previous pull request, they have changed exceeding in some outputs the tolerance 0.00001 with respect to the values stored in the parallel_regression.py, however the test case converges very well, so could it be possible to modify the values stored in that test case in order to not have this discrepancy between values stored and computed? Thank you so much in advance!!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1690#issuecomment-1194029520:185,feedback,feedback,185,https://su2code.github.io,https://github.com/su2code/SU2/pull/1690#issuecomment-1194029520,1,['feedback'],['feedback']
Usability,"> Below you can find a transitional test case using B-C model implemented in SU2:; > https://su2code.github.io/tutorials/Transitional_Flat_Plate/. Samet, nice to meet you! Thank you for your suggestion! I have learned this model in current SU2 version. B-C model can provide quite good results in many teatcases.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/502#issuecomment-446631804:210,learn,learned,210,https://su2code.github.io,https://github.com/su2code/SU2/issues/502#issuecomment-446631804,1,['learn'],['learned']
Usability,> Can you describe the bug this is fixing a bit more. I edited the PR description. Hope it's clear now. Please let know if you need more info.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/2036#issuecomment-1551960465:93,clear,clear,93,https://su2code.github.io,https://github.com/su2code/SU2/pull/2036#issuecomment-1551960465,1,['clear'],['clear']
Usability,"> Do I understand correctly that two gradients are always computed per iteration?; > Is there any downside to using the unweighted LS for viscous flux correction? Is the statement that this type of gradient is better for reconstruction based on your observations or is it one of those well known things?. Yes - the gradient for now is computed twice and stored separately for viscous flows with 2nd-order upwind. Could be combined into one loop eventually. It is known that weighted LSQ / GG is more accurate (see Mavriplis, ""Revisiting the Least-Squares Procedure for Gradient Reconstruction on Unstructured Meshes"" for instance). However, unweighted LSQ is known to be more robust.. so a good compromise is to use it only for the reconstruction step (which is more susceptible to robustness issues than the viscous term) and then use WLSQ or GG for all other gradients in the viscous flux/sources for accuracy. > Sometimes high CFL leads to limit-cycle oscillations of the residuals and the solution is to reduce it, is this something this controller can pick up?; > High CFL also makes the linear systems harder to solve and as Edwin pointed out _somewhere_ there is not much point going above reasonable values with weakly coupled turbulence. Do you think it would be reasonable to build in some feedback from the linear solver (e.g. it is taking too much time or did not converge -> drop the CFL)?. Yes, I would also like to couple it to the linear solver so that we can remove the need to tune that as well. Ideally the user will not need to adjust parameters. There are some things I am going to try for that..",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/790#issuecomment-531890295:1300,feedback,feedback,1300,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-531890295,1,['feedback'],['feedback']
Usability,"> How should I update my branch with upstream/develop? Should I merge upstream/develop into my branch (and push to my fork on github)? Or may I rebase my branch on top of upstream/develop (and force push to my fork on github)?. Both ways are legit, feel free to use which one is easier for you [here](https://www.freecodecamp.org/news/the-ultimate-guide-to-git-merge-and-git-rebase/) a comparison between them. It depends on the taste of the developer. . > I assume I should add myself to the _Individual Contributors_ section of AUTHORS.md, is that correct?. Yes",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1951#issuecomment-1466144727:348,guid,guide-to-git-merge-and-git-rebase,348,https://su2code.github.io,https://github.com/su2code/SU2/pull/1951#issuecomment-1466144727,1,['guid'],['guide-to-git-merge-and-git-rebase']
Usability,"> I assume that your results with explicit/implicit Euler for single zone are the same?. It turns out that they are not. When I applied the above modifications (CFL: 1000 -> 0.1, TIME_DISCRE_*: EULER_IMPLICIT->EULER_EXPLICIT; additionally I had to increase ITER) to the `issue_simplified` singlezone setup (the one with AoA=10°), I obtain the following solution:. ![simplified-singlezone-expliciteuler-density](https://user-images.githubusercontent.com/72806890/140885244-abb72de1-0d2d-4dc8-bde9-e0772786e2cd.png). with the following convergence history:. +------------------------------------------------------------------------------------------+; | Inner_Iter| rms[Rho]| rms[k]| rms[w]| CL| CD| LinSolRes|; +------------------------------------------------------------------------------------------+; | 0| -3.131336| -inf| -inf| 0.000000| 2.232692| -inf|; | 1| -3.281025| -inf| -inf| 0.000000| 3.198384| -inf|; ...; | 9531740| -11.999999| -inf| -inf| -0.006045| 1.258662| -inf|; | 9531741| -12.000000| -inf| -inf| -0.006045| 1.258662| -inf|; | 9531742| -12.000000| -inf| -inf| -0.006045| 1.258662| -inf|; ; ----------------------------- Solver Exit -------------------------------; All convergence criteria satisfied.; +-----------------------------------------------------------------------+; | Convergence Field | Value | Criterion | Converged |; +-----------------------------------------------------------------------+; | rms[Rho]| -12| < -12| Yes|; +-----------------------------------------------------------------------+. The density plot is; - different from the original `issue_simplified` singlezone solution with implicit Euler and CFL=1000. ; - similar to the `issue_simplified` multizone solution with implicit Euler and CFL=0.1. . Similarly, the TKE plots:; - `issue_simplified` singlezone implicit Euler CFL=1000; ![tke-simplified-singlezone-impliciteuler](https://user-images.githubusercontent.com/72806890/140887227-fc2ed584-53cf-413d-b5ad-18d1a12f5e4a.png); - `issue_simplified` s",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1414#issuecomment-963921195:366,simpl,simplified-singlezone-expliciteuler-density,366,https://su2code.github.io,https://github.com/su2code/SU2/issues/1414#issuecomment-963921195,1,['simpl'],['simplified-singlezone-expliciteuler-density']
Usability,"> I don't known how the process to find the alpha that gives you a given CL works, but could the derivative not be obtained from this process? i.e. you could avoid the FD step entirely. It is a simple proportional controller that will change the angle of attack after a number of iterations depending on the difference between the current CL and the target CL. . So if the the option `ITER_DCL_DALPHA = 0` then it will do exactly what you suggest. It calculates the derivative based on the last update. The only problem with that is, there is no guarantee that the simulation at the previous update was converged, so the derivative might be incorrect. . But you are correct, I could just do a really tiny update (order of delta AoA ~10^-6) at the end and calculate the finite difference using that value. Let me try that and see if the gradients it calculates are reasonable, or if the update is too small and it gets clouded by numerical errors.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/780#issuecomment-539606698:194,simpl,simple,194,https://su2code.github.io,https://github.com/su2code/SU2/pull/780#issuecomment-539606698,1,['simpl'],['simple']
Usability,"> I find your work really interesting. I've been studying the internal flow field in compressors and have had good results using SU2's SA_EDDES for calculating the cantilevered stator with a tip clearance. If you need help with code verification, I'd be glad to assist. Hi @Linnnnnn23, every help on the validation/verification is gladly accepted! Let me know if you need anything by my side.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/2150#issuecomment-2071759773:195,clear,clearance,195,https://su2code.github.io,https://github.com/su2code/SU2/pull/2150#issuecomment-2071759773,1,['clear'],['clearance']
Usability,"> I want to be done with this PR folks... This is really tiring to maintain so if you don't want it please just tell me...; > Can we agree on:; > Instead of CSolver having the `node` field it will have a pure virtual function `CVariable* GetNodes()`, derived solvers need to implement this method and have a `nodes` field of the most appropriate type (e.g. CEulerVariable for CEulerSolver).; > ; > I know some of you do not like the name `nodes` but there is something to be said about consistency (that has always been the name) and I do not think changing a generic name for another generic name justifies breaking the formatting everywhere and having needlessly long calls to get some data. In the interest of keeping the PRs moving, I am ok with this. It will also be natural for folks in the short term to learn the new system, since everyone is already accustomed to using the solver->node* construct. We can always go for a targeted refactoring later separate from the changes in this PR if we would like.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/753#issuecomment-538218606:811,learn,learn,811,https://su2code.github.io,https://github.com/su2code/SU2/pull/753#issuecomment-538218606,1,['learn'],['learn']
Usability,"> I'm thinking about reusing the SST test case ([axisymmetric_rans/air_nozzle](https://github.com/su2code/SU2/tree/master/TestCases/axisymmetric_rans/air_nozzle)) so that the same mesh can be used. Would that be fine ?. That's a quite specific testcase. How did you test the implementation? Do you have some simple results for the turbulent axisymmetric jet? We know that the results for round jets are not super good for standard SA, but at least we know what the result should look like, here on p.32 - 35 they test SA for the round jet and compare to the Wygnanski & Fiedler measurements:; https://www.researchgate.net/publication/24296213_Turbulence_Modeling_Validation_Testing_and_Development. The domain is just a rectangle so pretty simple to set up. You could also use the V&V test that we have, but it is a variable density jet:; https://su2code.github.io/vandv/SANDIA_jet/",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/2197#issuecomment-1889612505:308,simpl,simple,308,https://su2code.github.io,https://github.com/su2code/SU2/pull/2197#issuecomment-1889612505,2,['simpl'],['simple']
Usability,"> If anyone as an elegant solution to simply check for EXIT_SUCCES in the regression test one could add some dry_run regression tests. This can be added to the meson tests simply enough. In other words, you could add it alongside the unit tests. You can read more about meson tests [here](https://mesonbuild.com/Unit-tests.html). If you add `SU2_CFD` as a test executable with the dry run option as a command line argument, then meson will do the dry run and mark it as failing if it does not receive `EXIT_SUCCESS`.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/858#issuecomment-581945210:38,simpl,simply,38,https://su2code.github.io,https://github.com/su2code/SU2/pull/858#issuecomment-581945210,2,['simpl'],['simply']
Usability,"> Looks quite simple to me now, what do you think?. I fully agree. The CVariable footprint is much smaller and no more nasty address handling. (Adding another variable in another solver requires a bit more code though and a little understanding of what is going on than the ""Address""-version, but on the other hand this explicit handling of each primal-solver creates a good separation :+1: )",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1536#issuecomment-1050172065:14,simpl,simple,14,https://su2code.github.io,https://github.com/su2code/SU2/pull/1536#issuecomment-1050172065,1,['simpl'],['simple']
Usability,> Mpi4 is not compatible with the version of pastix we support.; > And you have to compile scotch and pastix according to the instructions in TestCases/pastix_support/ before compiling SU2. Thanks for the clarification! I use Mpi4 for most of my programs so that's why I built it that way. I followed this guide for pastix: https://solverstack.gitlabpages.inria.fr/pastix/md_docs_doxygen_chapters_Pastix_Runtime.html. So I build pastix 6.X.X. I will check the test cases directory though for the instructions. Also how does changing openmpi change c++ command line option ? . Thanks 😊,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1349#issuecomment-894838291:306,guid,guide,306,https://su2code.github.io,https://github.com/su2code/SU2/issues/1349#issuecomment-894838291,1,['guid'],['guide']
Usability,"> Nice! By the way, did you use some scripts for going through all the files and returning 'bad' naming conventions?. No, now I am just going through it by hand probably some linters are available to at least detect them. Actually, I am a bit confused as it is not so clear in the guide. It looks like the beginning of the project was just abbreviated from the Google style guide and was not enforced. Enforcing function names in UpperCamelCase and leaving variable names to the developer seems reasonable. > Can you explain the snake/camel terminology? :). Let's say we have a variable we want to name as `number of nodes per mesh` there are 2 common choices as . ```cpp; number_of_nodes_per_mesh = 42;; numberOfNodesPerMesh = 42;; ```; The first case is called the [snake case](https://en.wikipedia.org/wiki/Snake_case) and the second one is the [camel case ](https://en.wikipedia.org/wiki/Camel_case). Snake case is generally used in Python as [PEP8](https://peps.python.org/pep-0008/) suggests. . > Please revert the python accessor changes. I merged develop many of them vanished, should I revert the remaining ones?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1981#issuecomment-1482062542:268,clear,clear,268,https://su2code.github.io,https://github.com/su2code/SU2/pull/1981#issuecomment-1482062542,3,"['clear', 'guid']","['clear', 'guide']"
Usability,"> Note that you need to checkout this branch `fix_2d_periodic_rotation` (it is not in `develop` yet). Hi Pedro,; I checked the files you sent but building SU2 from source provided some errors:. - _MinGW64_ files provided from SU2 official website are corrupted and the installation crashes; however, it is possible to install the software but the .exe file mentioned in the installation guide won't be present. ; - After building _meson.py_ , the ninja installation command was line typed and the following alert message appeared "" **ninja: fatal: chdir to 'build' - No such file or directory** "". On a different laptop (with different user, to avoid the same mistakes) the following ERROR came up after the mason.py command line:; "" **'meson.py' is not recognized as an internal or external command, operable program or batch file** "". I don't know if any other user might have experienced the same errors. ; Anyway, are the bugfix files you published already available in the pre-compiled version? ; In the meanwhile, I'll try to figure out this inconvenient. Thank you in advance.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1562#issuecomment-1069325722:387,guid,guide,387,https://su2code.github.io,https://github.com/su2code/SU2/issues/1562#issuecomment-1069325722,1,['guid'],['guide']
Usability,"> Our working branch is 'develop', so you should have started from that and also merge into it. Every 6 months or so we then make the current develop into master. I changed the target branch to develop, and also updated your branch with current develop. Can you have a look at the failed check for clang-format coding style and format the changed file accordingly? https://su2code.github.io/docs_v7/Style-Guide/. Thanks a lot! It's very much appreciated. I have implemented the clang-format according to the guide and force formatting all files by using 'pre-commit run -a'. I think the new commits should be conformed to the coding style but not sure if the previous commit is also changed.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/2173#issuecomment-1951941110:508,guid,guide,508,https://su2code.github.io,https://github.com/su2code/SU2/pull/2173#issuecomment-1951941110,1,['guid'],['guide']
Usability,"> Sounds good, with that it will be easier to reason about when the recording types are created and used, right now someone would have to sit down and reverse-engineer the process. My intuition is that we can use some of the machinery introduced for multizone (partial tape evaluation) to simplify the recording management. And just to be clear I am very interested in having this feature in the code for comparison with the FP approach. That's exactly right. We started investigating the multizone driver a while back but we didn't get very far... It's been a while so i will need a refresher. Sure, there's broader interest in comparison with FP. Ole, Nico, and I talked about doing a detailed characterization last summer and we briefly brought it up in Varenna last week",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1750#issuecomment-1785913088:184,intuit,intuition,184,https://su2code.github.io,https://github.com/su2code/SU2/pull/1750#issuecomment-1785913088,3,"['clear', 'intuit', 'simpl']","['clear', 'intuition', 'simplify']"
Usability,"> Thank you for the feedback but for 99% of cases it is easier for users if we download the dependencies for them. The philosophy behind SU2 has always been to provide as much of a self contained package as possible. But this check will allow users to use external dependencies just fine, as long as they happen to use an external 0.61.1?. ... I am not entirely sure I understand the issue here. You want to make it *easier* for users by downloading the dependencies, so you make it harder if they went and got their own dependencies? If someone has gone to the effort of getting their own dependencies instead of using your documented meson.py, it would seem like that inherently means they are the 1% of use cases and you could probably just leave them to it. Is the issue rather that only Meson 0.61.1 has been tested to work?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1945#issuecomment-1450921338:20,feedback,feedback,20,https://su2code.github.io,https://github.com/su2code/SU2/issues/1945#issuecomment-1450921338,1,['feedback'],['feedback']
Usability,"> Thank you for your answer. If you could share the configs and meshes that you are using I can try following the approach suggested by @pcarruscag and use the TKE from the turbulence solver instead of the freestream one.; > ; > Plus, I have some doubts on the default value of the turbulent to laminar viscosity ratio which is equal to 10 in SU2, although on the NASA page suggests to be in the range of 10^-2 to 10^-5. However, I think that this is another issue. @rois1995 Hi ~ . Can you give me a link to the NASA TMR guide for setting the viscosity ratio? I'm not sure where to find it. Sorry, I found it!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1851#issuecomment-2251837355:522,guid,guide,522,https://su2code.github.io,https://github.com/su2code/SU2/issues/1851#issuecomment-2251837355,1,['guid'],['guide']
Usability,"> Thanks for pointing that out. I dont think it is intentional. Maybe we can use this PR also to fix this ?. That depends on how atomic we want these PRs to be. This PR is largely a refactoring PR, and shouldn't change any underlying performance. But adding extra calculations on source terms and wall conditions might change the performance of the code. The two changes are completely compatible, so combining them wouldn't be hard. Nevertheless, I propose we keep these changes separate, so that the purpose of each PR is clear and easy to see. In my mind, two small PRs are easier to check and review than one large PR. @talbring @economon What do you think? One big PR or two small PRs?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/626#issuecomment-458177675:524,clear,clear,524,https://su2code.github.io,https://github.com/su2code/SU2/pull/626#issuecomment-458177675,1,['clear'],['clear']
Usability,"> Thanks for the fast reply! I changed the hardcoded 2 (just as a remark: the hardcoded values also appear in the calculations), added myself as an author and inserted some lines for throwing an error if the issue in #1565 occurs. I did not know exactly where to put it best.; > ; > Concerning a regression test: I strongly support the idea of introducing an axisymmetric regression test. However, I was using a testcase from @bigfooted , and I never set up such a test case on my own. There do not seem to be any axisymmetric pipe setups in the Testcases folder so far. @bigfooted , could we maybe use your mesh for the jet flow test case and, if necessary, switch to a standard flow setup?. Yes, you can use that mesh. It can be used for pipe flow setup and jets with coflows, so we can reuse it in different testcases as well if needed. But any simple rectangular mesh is fine, so a mesh from the existing testcases as @pcarruscag mentions would also work.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1571#issuecomment-1075656956:848,simpl,simple,848,https://su2code.github.io,https://github.com/su2code/SU2/pull/1571#issuecomment-1075656956,1,['simpl'],['simple']
Usability,"> Thanks for the suggestion and I am preparing for a test. As far as I understand it, I just find that to get the absolute value of r_ij ( showed in the highest equation) in this part of code is unnecessary. The cross-product operation is to find the grid vector mostly parallel to the vorticity vector and the absolute value may cause a nonphysical recognition. @EduardoMolina, I don't know if I got it wrong and wish more guidance,.; > ; > ```; > for (auto iDim = 0u; iDim < nDim; iDim++){; > delta[iDim] = fabs(coord_j[iDim] - coord_i[iDim]);; > }; > ```. Hi Shihe,. I checked the implementation and I think it is correctly done. You do need the absolute value (i.e., delta has a unit of [m] or equivalent) to keep the correct dimension of nu_t based on a Smagorinsky-type SGS model. You may find the appendix of this paper useful for your understanding of delta_omg: [https://doi.org/10.1007/s00162-011-0240-z](https://doi.org/10.1007/s00162-011-0240-z). Also note that delta_omg does not always outperforms its peers - vorticity may not be aligned to the rotation axis of a local vortex (e.g., in rotating reference frame, in attached boundary layer, to name a few), in which case the physical meaning of delta_omg becomes vague. See also my work for a brief review of DES-type methods and some applications: [https://doi.org/10.1115/1.4052019](https://doi.org/10.1115/1.4052019)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1462#issuecomment-990220976:424,guid,guidance,424,https://su2code.github.io,https://github.com/su2code/SU2/issues/1462#issuecomment-990220976,1,['guid'],['guidance']
Usability,"> The ""int"" in ""intIndexBased"" is for internal then? Because its type is also int, easy mistake to make xD. Yes.. The name was the first one I gave that routine. It somehow made it through.. Now that I had to type it several times I'd love to have it changed. But anyway.. I'm a bit puzzled that it seems to be so easy but maybe it's just as simple as you said - new approach inside `CDiscAdjSolver` and old in `CDiscAdjFEASolver` (if I got that correctly?). That would come in handy for all further developments. Let's wait for the validation. I'll also do one with this branch for the CHT adjoints tomorrow, just to be sure.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/803#issuecomment-542360883:342,simpl,simple,342,https://su2code.github.io,https://github.com/su2code/SU2/pull/803#issuecomment-542360883,1,['simpl'],['simple']
Usability,"> There was a lot of talk about refactoring the shape optimization framework to be able to work completely in memory.; > I think the idea was not to have more drivers but simply to have more granularity such that you could manipulate the geometry from python (without writing it to files).; > We also wanted introspection, i.e. you could probe SU2 via python for what variables and functions are available.; > We also talked about having the projection step (DOT) included in CFD_AD so that you only need to worry about surface sensitivities, note that DEF is already part of CFD for forward mode AD.; > (talking does not go very far); > ; > If you want to lead this work, we can help you understand the inner workings. We meet every Wednesday at 4pm CET https://meet.jit.si/SU2_DevMeeting to discuss this type of issue. Thank you for the quick reply. The discussions you mention sound very promising, I would be glad to join tomorrow afternoon and learn more, so that I might contribute. One quick remark: I am aware that it is indeed possible to deform the mesh within `SU2_CFD`, I use this extensively for static aero-elastic analysis. However, I have not been able to have the deformed mesh be written to file at output (in SU2 or CGNS format). This is fine for aero-elastic updates (movement of the surface due to _structural displacements_), where it is sufficient to see the deformed mesh in the post-processing files. It becomes impractical though, for design updates (movement of the surface to due to _design displacements_, i.e. representing changes in the design variables) where the new mesh is a useful intermediate result. Even if this is just an issue in my configuration file, I think that a stand-alone driver or equivalent of `SU2_DEF` would remain useful. For each new set of updated design variables during shape optimisation, a single mesh deformation is sufficient to provide the new, updated jig geometry which all of the aerodynamic or aero-elastic analyses (one for each oper",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1262#issuecomment-818839696:171,simpl,simply,171,https://su2code.github.io,https://github.com/su2code/SU2/issues/1262#issuecomment-818839696,2,"['learn', 'simpl']","['learn', 'simply']"
Usability,"> Why not simply use clang-format and have a script to pass files/directories to have formatted? It provides more formatting options than just stripping trailing whitespaces and replacing tabs and does it in a consistent way. Tried that on a couple of files out of curiosity, it does not look very good, for example we have the habit of aligning repetitive statements across multiple lines clang-format does not keep that, we have very long lines with chained methods that look awkward when broken up.; Clang probably has a neater architecture of tiny objects where auto formatting works very well.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/808#issuecomment-551551298:10,simpl,simply,10,https://su2code.github.io,https://github.com/su2code/SU2/pull/808#issuecomment-551551298,1,['simpl'],['simply']
Usability,"> You are proposing the exact opposite of the conclusion of the paper:; > ; > ""From the above findings, it is **recommended that all three of these terms be included** when running hypersonic, or even supersonic, turbulent flow simulations, especially for flows with shock wave-induced separations.""; > ; > And they clearly say this: ""While the full inclusion of these terms does not always result in predictions that agree better with DNS/experimental data, this is likely caused by the fact that their exclusion cancels out effects of other flaws in the RANS models employed.""; > ; > If your strategy is to get a better match with experiments by neglecting physics terms, then you should rethink your strategy. Thank you for your comment @bigfooted . The above paper is not presented to improve the current k-w SST model. . As you can see in the first post, there is a problem with the high Mach number and freestream turbulence intensity case. If high turbulence kinetic energy(TKE) and Mach number condition, the boundary condition cannot be maintained the imposed value. (I think there seems to be a bug in the temperature calculation using total energy when including the TKE). The introduction of C1 was intended to provide a 'temporary' solution at the level of first aid (simply commenting out conditional statements in code).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1851#issuecomment-1521383702:316,clear,clearly,316,https://su2code.github.io,https://github.com/su2code/SU2/issues/1851#issuecomment-1521383702,2,"['clear', 'simpl']","['clearly', 'simply']"
Usability,"> You may want to remove the string based interface since it's known to be inneficient. When replacing the string-based with index-based look-up methods, the performance improves substantially. The figure below shows the average measured evaluation time (measured with chrono library) vs the number of output variables. It's clear that using index-based look-up methods results in reduced query time, as well as improved scaling. ![scaling_nVars](https://github.com/su2code/SU2/assets/38651601/31252439-ac6e-4f1b-82d4-e13a55d54c98)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/2214#issuecomment-1952521226:325,clear,clear,325,https://su2code.github.io,https://github.com/su2code/SU2/pull/2214#issuecomment-1952521226,1,['clear'],['clear']
Usability,"> the ""modern C++"" way is to use enum class and to never rely on implicit conversions from enum to integer type. I am in. It is a little (actually quite a bit) more involved as the enum namespace has to be given now everywhere an entry is used.; I was not familiar with `enum` vs `enum class` if someone else needs an entry point [stack overflow](https://stackoverflow.com/questions/18335861/why-is-enum-class-preferred-over-plain-enum), [playin around in compiler explorer](https://gcc.godbolt.org/z/5YTd4dPoE)... oh and of course the [c++ core guidelines entry endorses the use of enum class as well](https://isocpp.github.io/CppCoreGuidelines/CppCoreGuidelines#Renum-class)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1242#issuecomment-805108781:546,guid,guidelines,546,https://su2code.github.io,https://github.com/su2code/SU2/pull/1242#issuecomment-805108781,1,['guid'],['guidelines']
Usability,"> the off-PR comments can be integrated in this PR to clear that up a bit. If not that is OK as well. It's more than OK, the CHT implementation suffers a bit from being a single person's project.. you're very welcome to have a look over it! :-). > Can you add that option to the config_template.cfg together with that description, the valid inputs and the default. Actually I'm hesitating a bit adding it to the config template right now. I'd prefer to have `DIRECT_TEMPERATURE_ROBIN_HEATFLUX` as the default and ""hide"" the rest as developer's options for the moment.; The reason simply is that those different methods need to checked and validated against each other before we make them public.; E.g. I figured that for the incompressible CHT test case from the repo, there is a severe gap between the heatfluxes obtained from the ""averaged"" approach and the direct one, see below. ![heatflux_convergence](https://user-images.githubusercontent.com/22639394/72885197-bb9e4a80-3d07-11ea-9fad-a4d709dc511e.png). That needs to be cleared up first...",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/839#issuecomment-577108935:54,clear,clear,54,https://su2code.github.io,https://github.com/su2code/SU2/pull/839#issuecomment-577108935,3,"['clear', 'simpl']","['clear', 'cleared', 'simply']"
Usability,">I found out the other day that this: unordered_map<pair<int,int>, su2double> does not work without extra tricks,. Yes, I found some examples to do it. But I was not quite understanding what are the sizes of local maps or how to communicate them over MPI. . >so if you have it out of the config in some matrix format it is probably better. In that case, I can just move the current global arrays to physical geometry class and simplify some of the function calls.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/877#issuecomment-653479936:427,simpl,simplify,427,https://su2code.github.io,https://github.com/su2code/SU2/pull/877#issuecomment-653479936,1,['simpl'],['simplify']
Usability,">Therefore, we try to avoid templates when possible …. I find this view strange. I would appreciate if current C++ software techniques can be applied. How much can they help to make the source code a bit simpler?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/400#issuecomment-360055094:204,simpl,simpler,204,https://su2code.github.io,https://github.com/su2code/SU2/issues/400#issuecomment-360055094,1,['simpl'],['simpler']
Usability,">Why are you defining an internal marker?. Haha. Initially, I thought by creating a dummy marker inside my domain and calling it ""INTERNAL"", I can output solution at any desired face in the solution_flow file without having to deal with post processing software. This is of course possible in Paraview or Tecplot, but I figured this may be more automatic and perhaps easier especially with curved surfaces. Now I am simply curious as to what is happening with the internal markers.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/986#issuecomment-628781294:416,simpl,simply,416,https://su2code.github.io,https://github.com/su2code/SU2/issues/986#issuecomment-628781294,1,['simpl'],['simply']
Usability,"@AmauryBilocq Thanks for your post. Can you please check that you are actually not running out of memory, as that can also raise such errors? Second, if Giles BC is the issue I think you will still be able to run the case with Riemann which is a bit simpler than Giles. Can you also test that?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1429#issuecomment-1025177015:250,simpl,simpler,250,https://su2code.github.io,https://github.com/su2code/SU2/issues/1429#issuecomment-1025177015,1,['simpl'],['simpler']
Usability,@EvertBunschoten even if the performance isn't great this is a pretty small change so I think we can merge it.; Do you have time to wrap it up and add a simple regression test?,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/2152#issuecomment-2269672071:153,simpl,simple,153,https://su2code.github.io,https://github.com/su2code/SU2/pull/2152#issuecomment-2269672071,1,['simpl'],['simple']
Usability,"@JedrzejMosiezny . The reason why the mesh and config files are split into separate repos is the following: ideally we want to have the test cases being closely coupled to the current version of the code as config options change quite frequently. However, the mesh files are simply too big to have them in the main repo (it takes too much time to check them out etc.). So a compromise was to still leave the config files in the main repo in order for them to stay up-to-date. We thought that the information [here](https://github.com/su2code/SU2/wiki/Test-Cases) would be quite clear for the user on how to merge config and mesh files. Following this instructions should avoid having to search for the mesh files manually. Let us know if you think different. @economon could you add Jędrzej to the dev team here on github ? Thanks!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/485#issuecomment-355152833:275,simpl,simply,275,https://su2code.github.io,https://github.com/su2code/SU2/pull/485#issuecomment-355152833,2,"['clear', 'simpl']","['clear', 'simply']"
Usability,"@Mick7: yep, I’ll look at that next. You may have noticed that the other routines for Loading and preparing adjacency are now general for any mesh reader, so all we need is to move the reader for the ASCII format into its own class. . @pcarruscag: there is at least one simple stretching function I have in some old code I can put in. Other elements would also be nice. It’s easy to cut the quads into tris (I have the same implementation for this in a python script) and hexas into tets. Might wait for a compelling need to add these features though, but I have no doubt we’ll add them",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/728#issuecomment-524179517:270,simpl,simple,270,https://su2code.github.io,https://github.com/su2code/SU2/pull/728#issuecomment-524179517,1,['simpl'],['simple']
Usability,"@Nicola-Fonzi, you may as well want to consider importing as well the structural velocities in the interface from your external solver. That information is always available and gives a consistent definition of the displacement and velocity on both the grid motions and the interface for dynamic FSI problems -- not to mention simplifying the evaluation of the mesh adjoints.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1174#issuecomment-778326558:326,simpl,simplifying,326,https://su2code.github.io,https://github.com/su2code/SU2/pull/1174#issuecomment-778326558,1,['simpl'],['simplifying']
Usability,"@SumanVajjala gcc 5+ have full c++ 11 support (even more than that actually). As a last resort, if you cannot figure out what is going on with the compilers (simpler guess is that there are other versions installed and they are getting mixed up?), you can try replacing the file ""allocation_toolbox.hpp"" by this:; [allocation_toolbox_PATCH.txt](https://github.com/su2code/SU2/files/4550786/allocation_toolbox_PATCH.txt)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/955#issuecomment-621090526:158,simpl,simpler,158,https://su2code.github.io,https://github.com/su2code/SU2/issues/955#issuecomment-621090526,1,['simpl'],['simpler']
Usability,"@bigfooted @EvertBunschoten Well fwiw the simplest way is to checkout a new branch from before the merge and open a new PR, there are no coments here yet, so its fine.; (If you git revert the merge it will be a pain to then merge the other PRs)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1826#issuecomment-1327961579:42,simpl,simplest,42,https://su2code.github.io,https://github.com/su2code/SU2/pull/1826#issuecomment-1327961579,1,['simpl'],['simplest']
Usability,"@bigfooted @economon and @pcarruscag . I created separate repo to demonstrate what I'm after in the simplest way possible: [FoamScience/AutoRegistering-Cpp-Classes](https://github.com/FoamScience/AutoRegistering-Cpp-Classes/commits/master). > If you're going to check the code, check CSolver first, then CEulerSolver ... - Commit FoamScience/AutoRegistering-Cpp-Classes@20ca601 implements the concept for a single Factory.; - (Make-believe) Standard solver classes are compiled to a library; - A (Make-beleive) Custom solver class is compiled to its own shared library; - By default, the make program knows only about CEulerSolver (from standard solvers lib); - But if you pass in a library name (eg. libCCustomSolvers.so), it gets loaded, symbols pulled and the registration map for CSolver gets updated with the new Solver automatically. - But it would bloat the code if things went this way, so commit FoamScience/AutoRegistering-Cpp-Classes@380c052 isolates self-registration code into 3 macros to:; - Declare the registration map and associated members; - Define and initialize registration-related members on the base class; - Register a class. If you only care about the interface and not how the thing is implemented, commit 380c052 is your target.; I took care to document the important parts of the code, so, please, dig in and let me know what you think. At this point, integrating this with SU2 (and at what parts, and when) is your call but If you decide to do so, l will help.; > And yes, I wrote my own build script so I can have direct control over the compiler and the linker. **One last note: I used ""dlopen"", so you will have to compile the code on Linux I suppose.**",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1058#issuecomment-680962672:100,simpl,simplest,100,https://su2code.github.io,https://github.com/su2code/SU2/issues/1058#issuecomment-680962672,1,['simpl'],['simplest']
Usability,"@bigfooted Has there ever been any discussion regarding implementation of a `START_TIME=` capability into the config file? After going through the code a bit, it looks like doing this would be a good starting point for implementing ability to adjust deltaT mid-runs, as in general the code presumes `TimeIter*deltaT` as being the current time. This would be problematic for unsteady restarts that have a varying timestep. Plus, this would allow one to, without using the Python wrapper, use a different timestep in the config file for an unsteady restart. It also may clear up some confusion to have an explicit option for this, as in #2071. It can maybe look something like:. % Start time for restarting unsteady simulations; % = -1 for default calculation (START_TIME=RESTART_ITER*TIME_STEP); START_TIME=-1. Then `CConfig::GetPhysicalTime` could be appropriately updated and used in-place of all locations in the code where a physical time is manually calculated.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/2190#issuecomment-1870730956:568,clear,clear,568,https://su2code.github.io,https://github.com/su2code/SU2/pull/2190#issuecomment-1870730956,1,['clear'],['clear']
Usability,"@clarkpede @EduardoMolina : yep, the issue is that the periodic and MPI communications are tangled up together in the current implementation. The main issue occurs when there are periodic points that are also ghost nodes. . Ideally the periodic and MPI would be separated, and the periodic communications would happen first so that all periodic BCs are synchronized before trying to send across partitions. Right now, the comms are mixed, so sometimes, we send old data at periodic points to their matching pair, which then gets updated in a later MPI comm. Therefore, the second call you have added to the MPI resends the periodic update to with the correct data that was updated with MPI in the first call. I hope this is clear.. Anyway, please go with this change as you have it. All of the MPI and periodic comms will be replaced with a cleaner/separated version right after v6.2.0 (you can see what I am working on in feature_mpi_periodic). I will likely need some help testing that soon :).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/649#issuecomment-463711280:724,clear,clear,724,https://su2code.github.io,https://github.com/su2code/SU2/pull/649#issuecomment-463711280,1,['clear'],['clear']
Usability,"@clarkpede A small discussion on the pros and cons can be found here: https://mesonbuild.com/Comparisons.html. Or https://medium.com/@germandiagogomez/getting-started-with-meson-build-system-and-c-83270f444bee Of course this article is just a personal opinion, but he makes some important points. . From my experience I can really say that the syntax of meson is extremely simple and intuitive. I managed to set it up for SU2 in like half a day, without having any prior knowledge on how it works. And it seems like that a lot of projects (for example all Gnome projects) are going to or are already using meson.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/685#issuecomment-500221287:373,simpl,simple,373,https://su2code.github.io,https://github.com/su2code/SU2/issues/685#issuecomment-500221287,2,"['intuit', 'simpl']","['intuitive', 'simple']"
Usability,"@clarkpede Great, thanks for the details. I see your point. In general, vortex shedding cases are indeed challenging to match with the experiments, but that's what makes them interesting at the end. For a start, I am aiming to obtain comparable behaviours with both the compressible and the incompressible unsteady solvers under similar settings, rather than matching with experiments; mostly as an acceptance test as well. I am now working with standard SST turbulence model, but if you could share some simple meshes/cfg files to have a first go with hybrid RANS/LES, I would really appreciate it. > Good catch. I just pushed a commit that adds SetMaxLength calculations in all the instances I could find where the geometry updates. Thanks for the fix!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/552#issuecomment-404097397:505,simpl,simple,505,https://su2code.github.io,https://github.com/su2code/SU2/pull/552#issuecomment-404097397,1,['simpl'],['simple']
Usability,"@clarkpede I have not used the mesh adaptation tools since my last post (I was simply learning to use them for an undergrad project). With that said, I do not have any other concerns. It worked well for my application. I appreciate your help.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/606#issuecomment-500491744:79,simpl,simply,79,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-500491744,2,"['learn', 'simpl']","['learning', 'simply']"
Usability,"@clarkpede I think it is simpler to lock the periodic boundaries. I can look into that if you can point me to it. I have been using BFGS but the DV_VALUE is always 0.001 in the config_DOT_AD files, even after 25 design iterations.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/976#issuecomment-626855754:25,simpl,simpler,25,https://su2code.github.io,https://github.com/su2code/SU2/issues/976#issuecomment-626855754,1,['simpl'],['simpler']
Usability,"@economon I need to fix and test a few things before I push the branch to an internal branch. But I should be able to finish by the end of the next week. If you're looking to improve the C++ inlet profile specification I started, then I'd like to get some feedback on the overall design. There are several different ways to handle this, and I chose what I thought was most logical. I want to make sure that my design choices match your use cases and SU2's design. Should I post a summary here, or would you prefer that I email you?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/467#issuecomment-366493237:256,feedback,feedback,256,https://su2code.github.io,https://github.com/su2code/SU2/issues/467#issuecomment-366493237,1,['feedback'],['feedback']
Usability,"@economon I tested a couple of simpler problems at subsonic speeds, including the ONERA M6 case at M=0.8395. There's occasionally a difference of one iteration out of about 20. Usually the current develop branch is the one that requires more iterations, but not always. I included a snapshot from my tests on the ONERA M6 case at CFL=30. ![convergence_comparison](https://user-images.githubusercontent.com/13340225/48648855-6c97af80-e9b6-11e8-863a-56dfdf0903c8.png). I don't have a good supersonic, viscous test problem, but I suspect the differences in convergence won't be huge there either. This sign change affects a single term out of many and a single component of a 4x4 or 5x5 Jacobian. My take is that the differences are there, but they are very small. I wouldn't have noticed the problem myself if I hadn't been refactoring the code to enable some changes on our end.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/609#issuecomment-439538677:31,simpl,simpler,31,https://su2code.github.io,https://github.com/su2code/SU2/issues/609#issuecomment-439538677,1,['simpl'],['simpler']
Usability,"@economon No, this looks good to me. It is merge-ready, from my perspective. I chatted with @talbring, and in a future PR we would like to add a simple set of classes to use with unit tests. For example, I've created a ""one-point geometry"" class for use in some of my tests. But I think that we should keep the PRs as incremental as possible. PSA: If anyone else wants to review this PR, they are welcome to. It is no longer a WIP.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/850#issuecomment-620382001:145,simpl,simple,145,https://su2code.github.io,https://github.com/su2code/SU2/pull/850#issuecomment-620382001,1,['simpl'],['simple']
Usability,"@elfring: thank you very much for the suggestion, but for the time being, our philosophy is to keep the code as simple as possible to keep a low barrier to entry for new users/developers. Therefore, we try to avoid templates when possible (there are a few isolated places where they are necessary). This may change in the future, but we'll close this for now.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/400#issuecomment-360053938:112,simpl,simple,112,https://su2code.github.io,https://github.com/su2code/SU2/issues/400#issuecomment-360053938,1,['simpl'],['simple']
Usability,"@fertinaz the problem is that the pkg_config name for MPICH is not ""mpi"" which is what meson is configured to look for...; It is ""mpich"", please see my reply from 23 of May, it is very simple to edit the meson.build script to look for ""mpich"" instead of ""mpi"".; I have used this on numerous machines and the code works fine...; Whatever you do, please do not follow the advice to use 6.2.0, we have all worked extremely hard to make v7.x much faster, fix bugs, and add nice features... Unfortunately we cannot test every combination of compiler, operating system, and libraries.; I'm sure that somewhere, someone has fixed similar problems, sadly not all fixes make it back into the code. Other alternatives, some of which folks have suggested on this thread.; - Use ""custom-mpi"" mode, you will need to set some environment variables (CC=mpicc CXX=mpicxx etc. see above); - Use the legacy build system (i.e. follow the instructions for 6.2.0 but with the 7.0.7 code) be sure to add ""-DNDEBUG"" to the CXXFLAGS environment variable.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1000#issuecomment-721322008:185,simpl,simple,185,https://su2code.github.io,https://github.com/su2code/SU2/issues/1000#issuecomment-721322008,1,['simpl'],['simple']
Usability,"@fpalacios - For the continuous adjoint it is NOT required to run multiple adjoints, you can actually combine them. Whether or not to do so is controlled by the OPT_COMBINE_OBJECTIVE option - I will try to add in some more comments as you suggest to make this clearer, along with other updates next week.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/385#issuecomment-294324095:260,clear,clearer,260,https://su2code.github.io,https://github.com/su2code/SU2/pull/385#issuecomment-294324095,1,['clear'],['clearer']
Usability,"@fpalacios I also think it is a good idea to keep the request open. Like I said, I can also help to simplify it. In fact, splitting it up in multiple commits is probably easier then you might think @JSmith36 :)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/412#issuecomment-315606418:100,simpl,simplify,100,https://su2code.github.io,https://github.com/su2code/SU2/pull/412#issuecomment-315606418,1,['simpl'],['simplify']
Usability,"@fpalacios, you misunderstood me. What I meant was that the CrossProduct part should be uncommented in order to remove the compiler warnings, not removed. When I read this back, this was not very clear from my side. In any case there are still two compiler warnings in geometry_structure.cpp due to this issue in the develop branch.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/506#issuecomment-364848312:196,clear,clear,196,https://su2code.github.io,https://github.com/su2code/SU2/pull/506#issuecomment-364848312,1,['clear'],['clear']
Usability,@fpalacios: I am adding you to this discussion because I have seen you are the responsible of implementing the Negative Spalart-Allmaras variation in SU2. Maybe you can shed some light into the discussion. In particular to:; > we do not consider this modification and simply consider the modified vorticity as in the standard Spalart-Allmaras,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/992#issuecomment-652635415:268,simpl,simply,268,https://su2code.github.io,https://github.com/su2code/SU2/issues/992#issuecomment-652635415,1,['simpl'],['simply']
Usability,"@hlkline : it is true that we have been experimenting a lot to find the best formula, and no doubt we will continue to tweak things as we constantly evolve. But, one constant you can always trust is that the repo will be the home for important decisions on issues and PRs, so there is no need to worry about missing critical updates. . With slack and now rocket chat, we are looking to improve communication efficiency as people collaborate on particular developments in the code (say in pairs or small groups), or perhaps in the future, it can be opened to the public as a sort of support channel. This is to be seen as we gather some experience and feedback.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/645#issuecomment-464602965:651,feedback,feedback,651,https://su2code.github.io,https://github.com/su2code/SU2/issues/645#issuecomment-464602965,1,['feedback'],['feedback']
Usability,"@jayantmukho : The difference is also observed when using SST.; ![rans_cp_compare-branch_roe_SST](https://user-images.githubusercontent.com/9790985/61556955-d372da00-aa17-11e9-9351-5d3505cc85a1.png). @economon and @clarkpede : Thanks for the feedback. @clarkpede , I will re-run using the commit that you pointed and I will post the results here.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/735#issuecomment-513330011:242,feedback,feedback,242,https://su2code.github.io,https://github.com/su2code/SU2/issues/735#issuecomment-513330011,1,['feedback'],['feedback']
Usability,"@koodlyakshay I was looking at the ADT modifications that you mention.; Do I understand correctly that the roughness height does not influence the wall distance calculation itself? But that you simply need to know what is the roughness height associated with the closest wall point? If this is the case you can probably just use the markerId returned by the wall distance function?; As for mpi aspects, each rank sees the same ADT and I recall that we do have mechanisms to access global marker information.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/877#issuecomment-595197305:194,simpl,simply,194,https://su2code.github.io,https://github.com/su2code/SU2/pull/877#issuecomment-595197305,1,['simpl'],['simply']
Usability,"@kursatyurt Hello, thank you so much for the lead. Our initial scope mostly involved writing our own kernels and I did explore some libraries at the start - I was planning on using CUSP as well but my main concern was its lack of being updated to the newly compatible versions of the toolkit. cuSolver and cuBLAS do exist, but I chose to go ahead with a ""simple"" kernel implementation to have more control. I also felt that if I could keep the block size of the grid in optimal territory then they could be just as fast as those options (please do correct me if my reading of the literature or the situation was incorrect). I was not aware of Ginkgo and I will surely give it a go and try to produce some comparative results. I am currently super busy for this month and will get to working on the code with some delay. Again, thank you for the lead!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/2346#issuecomment-2397639761:355,simpl,simple,355,https://su2code.github.io,https://github.com/su2code/SU2/pull/2346#issuecomment-2397639761,1,['simpl'],['simple']
Usability,"@lorenzob95 we talked about this issue in our weekly developers meeting.; The current implementation of LM in the code is not stable enough and it has known bugs, so we will not re enable it for now.; A revised implementation by @vdweide exist in branch https://github.com/su2code/SU2/tree/feature_LM_model, but this is based on SU2 v6.2, it has been used on simple problems, convergence is not ideal on more complicated ones.; The decision is to wait for some developments that will make it easier to bring this revised implementation into version 7 (which is different in many ways from 6).; You can follow this issue to know when this gets implemented, it will probably take a few months.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1130#issuecomment-755395168:359,simpl,simple,359,https://su2code.github.io,https://github.com/su2code/SU2/issues/1130#issuecomment-755395168,1,['simpl'],['simple']
Usability,"@marcovanderbijl : thanks for the question. The original limit there is simply to impose an upper bound for memory considerations, since the first instantiation of the array of FFD boxes (before the number of FFD boxes embedded in the mesh is detected) needs a default value. We can of course change this to automatically detect the number to avoid the requirement or make it an input option in the config, but we have not run into this issue yet. For now, you should be able to increase that to a reasonable number without any issue. Please give it a try.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/684#issuecomment-495078497:72,simpl,simply,72,https://su2code.github.io,https://github.com/su2code/SU2/issues/684#issuecomment-495078497,1,['simpl'],['simply']
Usability,@pcarruscag Based on your 2nd review we have updated the code according to your suggestions. It was not clear how to restore the accidental changes to the sha versions of submodules externals/codi/ and subprojects/CoolProp/. Please instruct us howto or override yourselves for the same if possible. Request you to please review and instruct for proceeding further.; Thank you very much.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/2142#issuecomment-1793649845:104,clear,clear,104,https://su2code.github.io,https://github.com/su2code/SU2/pull/2142#issuecomment-1793649845,1,['clear'],['clear']
Usability,"@pcarruscag I just had a chat with @TobiKattmann. Essentially there are two points that would, in our opinion, speak against moving the implementation to CSolver. 1. We dont know yet whether they might be some future differences in the implementations. ; 2. This defeats somehow the purpose of the class structure, as the base class should be free of specific implementations for a certain solver ... Although the intention would be to have it there only temporarily, we never know how long it actually stays there in the end. I don't mind having a little bit of code copy, if the structure is clear and easy to understand.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/657#issuecomment-472011300:594,clear,clear,594,https://su2code.github.io,https://github.com/su2code/SU2/pull/657#issuecomment-472011300,1,['clear'],['clear']
Usability,"@pcarruscag I tried to restart the solution with zero mach number for config. However, for some reason, convergence takes so much longer than simply solving mach=0.1 config. Indeed, i started my simulation when you post your suggestion and it still haven't converged yet. Residual getting smaller but it is so slow. Therefore it might not be an efficient solution. Thanks for advice anyway.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/997#issuecomment-632892959:142,simpl,simply,142,https://su2code.github.io,https://github.com/su2code/SU2/issues/997#issuecomment-632892959,1,['simpl'],['simply']
Usability,"@pcarruscag I went through all your comments. There is one open discussion, maybe we can see if there is a better way to do this code sharing between flamelet and species although I think what I did now is simple and effective. ; Maybe you still see some other suboptimal implementations.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1917#issuecomment-1569765685:206,simpl,simple,206,https://su2code.github.io,https://github.com/su2code/SU2/pull/1917#issuecomment-1569765685,1,['simpl'],['simple']
Usability,"@pcarruscag It is ready for some external feedback.; Some things that you might want to take a look at:; - the implementation of objectives using surface_scalar_01, surface_scalar_02,... This is a simple extension to multiple scalars but could be generalized in the future.; - the implementation of axisymmetric source terms using the already available CSourceAxisymmetric_Species, this framework was present in the species implementation. It works, but this might need some more polishing in the future.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1917#issuecomment-1466044654:42,feedback,feedback,42,https://su2code.github.io,https://github.com/su2code/SU2/pull/1917#issuecomment-1466044654,2,"['feedback', 'simpl']","['feedback', 'simple']"
Usability,"@pcarruscag thanks for the additional feedback. some of these comments were already in my plans, but can only do one thing at a time of course. In any case it's good to see we're thinking in the same way, confirms I'm heading in the right direction, so I definitely appreciate it. Others I had not thought about it at all, even more useful! Thanks!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1014#issuecomment-654324437:38,feedback,feedback,38,https://su2code.github.io,https://github.com/su2code/SU2/pull/1014#issuecomment-654324437,1,['feedback'],['feedback']
Usability,"@pcarruscag, Did you work out the analytical Jacobian for AUSM+-up? (holy cow). I have also worked out and implemented in my local machine for AUSM, up and up2 (with minor simplifications/assumptions, wherever seemed okay) . I was planning to consolidate things appropriately and refine it before pushing them to repo.; By the way, I am also observing the similar behavior with little time advantage for analytical part (a bit more refinement/cleaning in implementation from my side will be done) . So what should be the next plan ???. Cheers; Amit",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/691#issuecomment-505621705:172,simpl,simplifications,172,https://su2code.github.io,https://github.com/su2code/SU2/pull/691#issuecomment-505621705,1,['simpl'],['simplifications']
Usability,"@pcarruscag: I'm in the process of creating a test case for the 3D gust. To do so, I created a CFD mesh for a simple, rectangular 3m wing with a NACA0012 profile. The mesh has a size of 13.7 Mb and a restart solution is 16.3 Mb plus 5.5 Mb (.csv and .dat). Do you think that is acceptable?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1954#issuecomment-1545475126:110,simpl,simple,110,https://su2code.github.io,https://github.com/su2code/SU2/pull/1954#issuecomment-1545475126,1,['simpl'],['simple']
Usability,"@petebachant: the paper that I linked earlier on this thread had some fairly simple examples similar to the one you propose.. different flat plates and so on with varying y^+. You can likely reuse the grid(s) in the TestCases repo. @vdweide: it was very simple in this first implementation. It checks for a single boolean for whether or not to apply wall functions (WALL_FUNCTIONS= YES or NO, https://github.com/su2code/SU2/blob/43b8a4015c4b09b01d78e4243d32011c663c2b70/SU2_CFD/src/solver_direct_mean.cpp#L15339), and then assumes they should be applied to all no-slip walls (heat flux or isothermal, https://github.com/su2code/SU2/blob/43b8a4015c4b09b01d78e4243d32011c663c2b70/SU2_CFD/src/solver_direct_mean.cpp#L16653). This could of course be made more specific for individual markers using a config structure like MARKER_MONITORING to list them, or by making a dedicated BC type for it potentially.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/399#issuecomment-327308587:77,simpl,simple,77,https://su2code.github.io,https://github.com/su2code/SU2/issues/399#issuecomment-327308587,2,['simpl'],['simple']
Usability,"@rsanfer I am attaching [some results](https://github.com/su2code/SU2/files/2612501/FFD_verification.pdf) for FFD derivatives for FSI cases (that made use of this fix) to rekindle the discussion. I am taking this directly from my early stage so apologies if not all details are clear, the conclusion is that the fix does not break the adjoint.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/597#issuecomment-441388433:278,clear,clear,278,https://su2code.github.io,https://github.com/su2code/SU2/pull/597#issuecomment-441388433,1,['clear'],['clear']
Usability,"@rsanfer I'm using a test case from Ref [1], which doesn't exactly match the test case matching the figure I gave from Ref [2]. In Ref [1], they ran a whole ensemble of tests at various resolutions, corrections, and inflow/initial conditions. Some of the tests involved laminar separation, while others involved turbulent separation. I did not pick one of the Re = 50,000 cases because those cases involve laminar separation. Travin *et. al.* used a special nonuniform initial condition to promote laminar separation, which I viewed as overly complicated for the purposes of these tests. Instead, I picked a turbulent separation case at Re = 1.4 x 10^5 (roughly matching TS1 from Ref [1]). If you want more details/grids/cfg files, I can certainly provide them. Yes, I used the unsteady compressible solver. But I'm unsure if the circular cylinder case provides a good test case for the unsteady incompressible solver. I did very little with this test case in terms of a proper validation. The references I listed went to great lengths to ensure that the numerical results were consistent with experiments. It seems like a challenging test case. There were a lot of improvements I should have made if I were also trying to get consistent results. For example, my spanwise length was too short, and I didn't look into the impact of the rotation correction for the SA model. I skipped these improvements in the interest of time, since I wasn't aiming for validation, but rather a simple acceptance test.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/552#issuecomment-403850762:1478,simpl,simple,1478,https://su2code.github.io,https://github.com/su2code/SU2/pull/552#issuecomment-403850762,1,['simpl'],['simple']
Usability,"@rsanfer and me had a discussion on it. We both came to the agreement that it might the best if we just remove the generated files from the repo in general. Since buildtools are already required to have 'make' it shouldn't be much of a burden to also require autotools/automake to be installed. Furthermore, we eventually could provide a simple way of installing/compiling it within the preconfigure.py script if necessary.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/586#issuecomment-423942141:338,simpl,simple,338,https://su2code.github.io,https://github.com/su2code/SU2/pull/586#issuecomment-423942141,1,['simpl'],['simple']
Usability,"@talbring I agree with your assessment of Boost. I think it's a heavyweight solution to a lightweight use-case. We could always include just the unit-testing header (they offer a header-only version), but ""people may want to use more and more features of boost,"" as you point out. If we as developers want to add Boost as a formal dependency for SU2, then that seems like a fine route. But I have the feeling that many developers do not want to add a Boost dependency. Honestly, Boost UTF doesn't offer anything that we can't get from Google Test. Catch2 is definitely the simplest and easiest of the unit-testing frameworks I listed. The only sticking point is that it requires c++03, and that the full-feature version requires C++11.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-500393344:573,simpl,simplest,573,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-500393344,1,['simpl'],['simplest']
Usability,"@talbring Thanks for getting this sorted, Tim! I also think it's the best way to maintain a clear difference between regressions and Tutorials. I do have a suggestion though. Although I think it's very nice to have the written tutorials directly in git, so people can contribute directly, I wonder if it's the best idea to have them in the main repo. As the number of tutorials grows, we will have the same problems as for the meshes, with too many files to check out (images, md files, etc). Given that there is a new ""Tutorials"" repository, would it be a good idea to incorporate them there? I think it makes sense in terms of clarity, and we could make use of github pages, which allows to create a website per repository. That way we could have a site for the tutorials - and eventually this could be incorporated seamlessly into the SU2 website. What do you think?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/485#issuecomment-355262713:92,clear,clear,92,https://su2code.github.io,https://github.com/su2code/SU2/pull/485#issuecomment-355262713,1,['clear'],['clear']
Usability,"@talbring Thanks for the quick and helpful answer! I'm looking at creating an ebuild/package for gentoo, compilation is a lot simpler than OpenFoam :P which is a big plus :). Anyway, I was looking at the old docs (the main docs still point to 6.0, I missed the red text that mentioned that somehow :P), not sure why, but you're right it's indeed mentioned in the 7.0 docs here https://su2code.github.io/docs_v7/Build-SU2-Linux-MacOS/#configuration-and-compilation. The ""Automatically installed dependencies"" section left me a bit confused because it sounded like the things listed there, which includes meson and ninja, would always get installed.; Maybe merging that section into the configuration and compilation section might help to make it more clear?. If you don't mind I have some additional questions:; - I didn't initialize the git submodule at all and configuration, compilation and running worked fine. Does this mean the CoDiPack and MeDiPack dependencies are optional? Or does this mean I could have a crash at runtime somewhere?; - Would it be possible to add a source package to the GitHub releases (in addition to the binary ones) that includes the (CoDiPack and MeDiPack) submodules? Unfortunately the GitHub provided source downloads don't include submodules.; - Are MKL and OpenBLAS build-time and exclusive options or can they both be compiled in and chosen at runtime?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/911#issuecomment-598751341:126,simpl,simpler,126,https://su2code.github.io,https://github.com/su2code/SU2/issues/911#issuecomment-598751341,2,"['clear', 'simpl']","['clear', 'simpler']"
Usability,"@talbring Thanks! Works like a charm now! Thanks for implementing this, I think this building method is a lot simpler than the previous one.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/745#issuecomment-521545657:110,simpl,simpler,110,https://su2code.github.io,https://github.com/su2code/SU2/pull/745#issuecomment-521545657,1,['simpl'],['simpler']
Usability,"@talbring that is definitely the long term goal, this was only the first step to make the templating simpler.; Thanks @rsanfer.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/650#issuecomment-475180235:101,simpl,simpler,101,https://su2code.github.io,https://github.com/su2code/SU2/pull/650#issuecomment-475180235,1,['simpl'],['simpler']
Usability,"@talbring: thanks for adding the regressions. One iteration is perfect just to check they're running, if they have the originals still being tested in the TestCases. I think the idea of having the written tutorials/documentation for the test cases in the main repository is a very good one, for several reasons. In particular, it will make it easier for people to add documentation, and we could eventually even test for its existence in Travis or make it a strict requirement for PRs in the future. My only concern at the moment is making sure that they look ""nice"" when viewed and that the links are easy to update/follow. We should probably add a title at the top of each tutorial markdown file now (above the first image), since the titles from the wiki page are missing. The image files should be moved from the website repo (su2code.github.io/github_wiki/) to these Tutorials folders. Another idea is to put a top-level ""Tutorials"" markdown file that will be linked from the wiki at the root Tutorials/ directory so that one only has to update the links to new tutorials in that file in the main repo, rather than always updating both the main repo and manually updating the wiki too. Any other ideas for making this seamless and user-friendly are most welcome! Let me know if you need any help.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/485#issuecomment-355216605:1236,user-friendly,user-friendly,1236,https://su2code.github.io,https://github.com/su2code/SU2/pull/485#issuecomment-355216605,1,['user-friendly'],['user-friendly']
Usability,"@timjim333, I checked your grid with just connectivity info and I get the following error messages. Boundary marker BODY, surface element 77477: No corresponding volume element found.; Coordinates of the points; 0.1815790.04981870.0020471; 0.181850.04994770.00205104; 0.1816670.04971090.00204381. Boundary marker BODY, surface element 133348: No corresponding volume element found.; Coordinates of the points; 0.1814850.04947420.00203657; 0.1813090.04968980.00204316; 0.181230.04944470.00204356. Boundary marker BODY, surface element 134774: No corresponding volume element found.; Coordinates of the points; 0.181230.04944470.00204356; 0.1813020.04923740.00202934; 0.1814850.04947420.00203657. Boundary marker BODY, surface element 135217: No corresponding volume element found.; Coordinates of the points; 0.1816670.04971090.00204381; 0.181850.04994770.00205104; 0.1815790.04981870.0020471. So clearly the grid is invalid.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/683#issuecomment-494393404:896,clear,clearly,896,https://su2code.github.io,https://github.com/su2code/SU2/issues/683#issuecomment-494393404,1,['clear'],['clearly']
Usability,"@timjim333,. Yah, those are the general guidelines you mentioned but they do not always work in practical cases.; We will probably know more details when people will share their experiences and issues faced. I have tried meshes with max include angle 175 or below, they go well. Even upto 179 also go through.; But I had trouble recently while just giving a trial for 179.8 or more case.; One thing to note is, SU2 constructs dual mesh from the primal mesh we supply but anyway properties of the primal mesh will carry forward. Regards; Amit",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/683#issuecomment-494932014:40,guid,guidelines,40,https://su2code.github.io,https://github.com/su2code/SU2/issues/683#issuecomment-494932014,1,['guid'],['guidelines']
Usability,@timjim333. The guidelines you mentioned are perfect but geometry complexity/time constraints at times push it beyond those numbers. Infact most of the Solvers (especially commercial) are robust enough to take (as I mentioned) the mesh crossing these specific guidelines. I think SU2 also handles it reasonably well. Latest version of Pointwise has direct export to SU2 (I think 17.3 onwards or so). Did you try CGNS format? . Best; Amit,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/683#issuecomment-495921430:16,guid,guidelines,16,https://su2code.github.io,https://github.com/su2code/SU2/issues/683#issuecomment-495921430,2,['guid'],['guidelines']
Usability,"@tollennaert, can you comment on the points raised by @pcarruscag ? I think you tried to address all points in your latest update? That makes it clear to everybody that all points have been addressed. I hope you still have time for this.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1076#issuecomment-733607872:145,clear,clear,145,https://su2code.github.io,https://github.com/su2code/SU2/pull/1076#issuecomment-733607872,1,['clear'],['clear']
Usability,"A short summary of the things I did in the additional commits:. - I added a consistent error handling that can be used throughout the code. For example if a marker is not specified the error looks like that: ; ```; -------------------------------- Error ---------------------------------; In ""short unsigned int CConfig::GetMarker_CfgFile_TagBound(std::__cxx11::string)"": ; ------------------------------------------------------------------------; The configuration file doesn't have any definition for marker airfoil; ------------------------------------------------------------------------; Exiting now ...; ```; or if a solution cannot be found:. ```; -------------------------------- Error ---------------------------------; In ""void CSolver::Read_SU2_Restart_Metadata(CGeometry*, CConfig*, bool, std::__cxx11::string)"": ; ------------------------------------------------------------------------; Unable to open SU2 restart file solution_flow.dat; ------------------------------------------------------------------------; Exiting now ...; ```; In case you want to throw an error, you can simply call the function `SU2_MPI::Error(""Error Message"", CURRENT_FUNCTION)` where `CURRENT_FUNCTION` is a predefined macro which expands to the name of the routine at compile time. I already replaced almost all error messages in the code. - More MPI functions are included in the MPI Wrapper. - The rank/size is now stored in most of the bigger classes and initialized in the constructor. That means there are no calls to MPI_Comm_rank / MPI_Comm_size anymore in every routine ... For convenience there is also a SU2_MPI::GetRank() / SU2_MPI::GetSize(), in case you need it outside of the main classes. Let me know what you think. Not everything I did has to stay the way I implemented it :)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/473#issuecomment-347663941:1092,simpl,simply,1092,https://su2code.github.io,https://github.com/su2code/SU2/pull/473#issuecomment-347663941,1,['simpl'],['simply']
Usability,"A simple workaround would be to add an if line before the split:; Line 84 of parse_config.py; if np.size(s2) > 1:; thisval = s2.split('""')[1]; Yes, it requires also ; import numpy as np; at the beginning of the script.; Now it runs with no error message but no output produced.; Also config_gui.py is running, but it opens an empty window,; so apparently this is not good enough. best,; Eran",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/216#issuecomment-241208818:2,simpl,simple,2,https://su2code.github.io,https://github.com/su2code/SU2/issues/216#issuecomment-241208818,1,['simpl'],['simple']
Usability,Actually I had a look at your branch and the way it is right now is not correct I believe because I had taken the other variables v and 1/y out of the derivative using the chain rule and combined them with the other derivatives to end up with the terms as they are now so only d(mu)/dy was missing. The AxiAuxVarGrad you are using is apparently d(v*mu/y)/dy so the other terms have to be different. I will change them. Why not just simply compute the viscosity gradient? Is there any reason not to pull the other variables out?. Is there not already an AuxVar being just v*mu or something? . Anyway I guess it will work the same either way,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1095#issuecomment-727969107:432,simpl,simply,432,https://su2code.github.io,https://github.com/su2code/SU2/pull/1095#issuecomment-727969107,1,['simpl'],['simply']
Usability,"Agreed that the style needs some attention. I am open to ideas about this. You may have noticed that I integrated Codacy recently to test it out: https://www.codacy.com. We have the style guide, but honestly, it's not getting much attention. We should automate checks or have scripts that automatically enforce style constraints. Vera++ sounds interesting in this regard. A little while back, @rsanfer and I had been working on indentation issues with the uncrustify tool. Should we open this as an issue and get some input? Find volunteers to look into these things?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/426#issuecomment-323636235:188,guid,guide,188,https://su2code.github.io,https://github.com/su2code/SU2/pull/426#issuecomment-323636235,1,['guid'],['guide']
Usability,"Agreed. We removed some remaining long arrays with maps (e.g., local to global mappings) in v5, so we should be consistently using unsigned long in reference to grid node index values. In the future, we will likely have an ""su2int"" data type too that we can simply typedef. Closing.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/3#issuecomment-307590742:258,simpl,simply,258,https://su2code.github.io,https://github.com/su2code/SU2/issues/3#issuecomment-307590742,1,['simpl'],['simply']
Usability,"Ah! Cool, sure open a new PR @maxaehle.; What adjoint stuff? file names and so on?; I think removing irrelevant options would be make the tests clearer, there are lots with Roe and JST options specified and vice versa which probably confuses new users.; I'm not so sure about removing all defaults thought... On one hand it would serve as regression for the default values set by CConfig, on the other it hides the tuning parameters of some methods... but then again those are more or less documented now.; :shrug:",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1236#issuecomment-804035589:144,clear,clearer,144,https://su2code.github.io,https://github.com/su2code/SU2/pull/1236#issuecomment-804035589,1,['clear'],['clearer']
Usability,"Ah, I wasn't aware of the corrected version. Thanks for pointing out my mistake. The corrected version does make more sense, and the main changes seem to be:. + Changing the location of the sqrt in the definition of `Lturb`; + Changing `ch3` from 0.5 to 2.0; + Clarifying that S and Omega should have a factor of sqrt(2). As for code verification, I would propose using one of the cases examined by Travin, Stretlets, Mockett, or Xiao for comparison. We know that they got a nice range of values for the blending constant on their tests with DDES. The cases I can see where they explicitly show the results of the blending function are:. + Circular cylinder at Re = 50,000 (Travin _et al._ 2002); + Tandem cylinders at Re = 166,000 (Xiao _et al._ 2012); + NACA0021 airfoil in deep stall (Mockett 2009). The tricky thing is that the value of the blending constant is determined by the flow solution, which is determined by the solver. So the values we obtain will be dependent both on the version of DDES used and the nature of the code. We can't expect to match any of these papers exactly. We could also use a simpler flow, such as fully developed channel flow or a flat plate boundary layer. The tradeoff would be simplicity for ease of comparison.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/532#issuecomment-388189377:1111,simpl,simpler,1111,https://su2code.github.io,https://github.com/su2code/SU2/pull/532#issuecomment-388189377,2,['simpl'],"['simpler', 'simplicity']"
Usability,"Ah, that tutorial page is very important.. I don't think it was ever linked in the main wiki menu, but it is critical for making the options clear to the user (especially the surface handling). We need to make the design features as easy to use as possible - it is already hard enough for experts to use adjoints :). This is a good opportunity to move it over to the new repo where we are placing the tutorials here: https://su2code.github.io/Tutorials/docs/home/. The files, including the markdown, mesh, config, and images, can be moved to that repo. The markdown portion goes into the _docs directory, and we should make sure it's linked under the shape design tutorials. Do you have some time for this? Let me know if you need some help.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/494#issuecomment-357458143:141,clear,clear,141,https://su2code.github.io,https://github.com/su2code/SU2/pull/494#issuecomment-357458143,1,['clear'],['clear']
Usability,"Alex, Heather,. Thanks for commenting and straightening this out. Since this is a frequently asked question, I have added a new section in the documentation on how to use the test cases, which will hopefully clear things up more in the future: https://github.com/su2code/SU2/wiki/Test-Cases. Tom",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/222#issuecomment-171108493:208,clear,clear,208,https://su2code.github.io,https://github.com/su2code/SU2/issues/222#issuecomment-171108493,1,['clear'],['clear']
Usability,"All above,. Can any one share the experience of the mesh quality matrix acceptable by SU2. In Pointwise, one can follow maximum included angle, centroid skewness or equiangle skew as guiding parameters. I have observed that some of the commercial Solvers can accepts and run a very high max included angle (179.99 or so) also without trouble but some others have issues with the same. . Many times due to complex geometry, one ends up with these high numbers. . Any guidelines for SU2 on mesh quality is appreciated. Regards ; Amit",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/683#issuecomment-494217280:183,guid,guiding,183,https://su2code.github.io,https://github.com/su2code/SU2/issues/683#issuecomment-494217280,2,['guid'],"['guidelines', 'guiding']"
Usability,"All,. For whatever it is worth, here are some thoughts. It is clear that we need to strike the right level and hierarchy of abstraction: at the highest level one really ought to be describing the physical problem, not the number of zones or the specific time-stepping algorithm that would be used. But preventing future multi-zone calculations from reaching the (time) order of accuracy desired is also an important issue that SU2 must support (and that I think would be very important for those doing unsteady turbomachinery calculations). Just as important: even for multi-physics problems (say fluid-structure interaction, when the fluid and structural solvers are not closely integrated into the same source) we need to ensure that the time accuracy of the full multi-physics calculation is as high as those of the component physics solvers. This is a very valid and useful discussion and some proposals are on the table. Given that we are planning a developer’s meeting sometime before the end of the year, this may actually be one of the items in the agenda for discussion, so some decisions can be reached that both make sense and minimize the pain of changes for any part of the existing code. I would suggest that the conversation continue and that other proposals are put forward so the discussion can be finalized at the developer’s meeting. Best,. Juan. On Sep 10, 2017, at 1:09 PM, Edwin van der Weide <notifications@github.com<mailto:notifications@github.com>> wrote:. Dear @rsanfer<https://github.com/rsanfer>,. I agree with you that the outer loop should be the loop over the number of physical disciplines involved in the problem and not the zones. Whether the individual disciplines contain one or multiple zones is irrelevant at this level, in my opinion. The loop over the multiple zones of a single discipline should take place at a much lower level, namely where the spatial residual is computed. At least, this should be the case for the fluid dynamics part. I don't know whethe",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/437#issuecomment-328403160:62,clear,clear,62,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328403160,1,['clear'],['clear']
Usability,"All,. I looked a bit more through Eigen and, indeed, the performance is pretty impressive and generally better than MKL and Atlas (the self-tuned implementation of LAPACK) ant most/all matrix sizes. I agree with comments made by @pcarruscg that having a standard for matrix operations throughout the source would clean up /simplify the code considerably and, since it does not seem to impact the AD approach, it should be pursued. It sounds like a quick test branch like @vdweide is suggesting makes sense. A quick driver code to test the performance of the Eigen routines vs MKL makes sense too. The only thing that @vdweide should comment on is how much work it would be to change the LAPACK/BLAS based implementation in the DG-FEM solver to the interface that Eigen exposes. Best,. Juan. On Feb 1, 2019, at 4:19 AM, Edwin van der Weide <notifications@github.com<mailto:notifications@github.com>> wrote:. Would it be an idea to create a branch to test things out and make a decision based on the results? It would be interesting to see the performance for e.g. the dense matrix multiplications in the DG-solver compared to Intel's MKL. —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/643#issuecomment-459705131>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADpSxM1gm0iy_FeGBMFzxVQnYFFzEHt4ks5vJDDlgaJpZM4adbAo>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/643#issuecomment-459845576:323,simpl,simplify,323,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459845576,1,['simpl'],['simplify']
Usability,"All,. Of course, another approach to verifying which sign is correct is to do an analytic differentiation (using CoDi?) or simply using complex-step on the residual calculation routine to get exact Jacobians (for a particular state) and confirm the correct sign. This does require some code extraction / refactoring to perform the test, but it has the benefit that you would know exactly what the correct answer is for the specific residual implementation. Best,. Juan. On Nov 16, 2018, at 11:03 AM, Thomas D. Economon <notifications@github.com<mailto:notifications@github.com>> wrote:. As Jacobians affect convergence rate and not accuracy, you could do a quick test of the same problem with the current version and the sign flipped to see if there is measurable difference in the convergence rate. If yes, then it should give you a hint about which direction. If no, then we should still correct it, but prob don't need to put in too much effort. @clarkpede<https://github.com/clarkpede> : I'm interested in your unit testing set up... —; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/609#issuecomment-439493827>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADpSxInSS3cmLF8iFkD22AoYAp0G3G2yks5uvwvxgaJpZM4YeD9V>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/609#issuecomment-439500791:123,simpl,simply,123,https://su2code.github.io,https://github.com/su2code/SU2/issues/609#issuecomment-439500791,1,['simpl'],['simply']
Usability,"All,. The following page has performance comparisons between eigen and mkl (and others):. http://eigen.tuxfamily.org/index.php?title=Benchmark. They are dated 2011, so they are a bit old, but if the quoted performance is real, I would say it is a no-brainer to switch to eigen. If the performance tests (for at least simple things like daxpy and gemm) could be repeated to verify the numbers, that would help us make a final decision. Best,. Juan. On Feb 2, 2019, at 1:58 AM, Edwin van der Weide <notifications@github.com<mailto:notifications@github.com>> wrote:. @pcarruscag<https://github.com/pcarruscag>, I agree with you it will be hard to beat the MKL (running at 60 percent peak for most of the gemm calls for the DG-solver), but if you don't have any performance loss, that would already be nice, as it improves readability. Furthermore, the performance of the DG solver in combination with the discrete adjoint is horrible, because it relies on my very naive implementation of the matrix products. So it would already be something if we can get an improvement there, although we do not use the DG adjoint solver (yet). For me the easiest way to test things out for the DG-solver would actually be in SU2 itself. @economon<https://github.com/economon> put some nice profiling routines in there for the gemm calls, which can be used without any additional work to test eigen. @pcarruscag<https://github.com/pcarruscag> (or somebody else), could you create a branch in which eigen is downloaded in the external directory? I think I can manage from there. Thanks,. Edwin. —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/643#issuecomment-459952137>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADpSxCgydwy1nS3qPJvyCMJXLXWNMSFsks5vJWEkgaJpZM4adbAo>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/643#issuecomment-459986613:317,simpl,simple,317,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459986613,1,['simpl'],['simple']
Usability,"Alright. I did some digging, and the problem has nothing to do with the warning message. It goes much deeper. In a recent release, SU2 switched to reading and writing binary restart files instead of ASCII. The grid adaptation code is still written only for ASCII. If I'm right, then trying to read a binary restart file with the flow solution breaks the program. I'll submit an issue detailing the bug. For now, try adding the following lines to your cfg file when you run `SU2_CFD`:. %; % Write binary restart files (YES, NO); WRT_BINARY_RESTART= NO; %; % Read binary restart files (YES, NO); READ_BINARY_RESTART= NO. Then run `SU2_MSH`, just like you have been. Does that clear things up?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/606#issuecomment-436131167:674,clear,clear,674,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-436131167,1,['clear'],['clear']
Usability,"Alright. I've copied over my changes, with a few improvements. They're on the branch `feature_fileprofile`. One important change is that the user no longer needs to specify the node numbers. For each inlet node on the mesh, the code looks for the closest point from the inlet file. If that closest point is within a specified distance, it deems it a match. If not, it returns an error. Some points:. + The code will generate an example inlet file if the inlet file is missing / is invalid.; + I have not added interpolation. Since python makes interpolation easy, I didn't view this as a high priority.; + I have not added support for multigrid. I'm unsure of how to do this, since I'm not familiar with the multigrid code. It's not as simple as copying what's done for the restarts in the volume mesh. That's a volume based agglomeration, whereas the boundaries are faces. Feel free to modify my implementation however you want.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/467#issuecomment-368990059:736,simpl,simple,736,https://su2code.github.io,https://github.com/su2code/SU2/issues/467#issuecomment-368990059,1,['simpl'],['simple']
Usability,Also nice would be a clear separation between the blocks. Atm at ending u get Exit .....; Somethin like that:; ![unbenannt](https://cloud.githubusercontent.com/assets/11041576/15497673/13a67f62-219c-11e6-9c89-7dcc1236a706.PNG),MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/257#issuecomment-221203675:21,clear,clear,21,https://su2code.github.io,https://github.com/su2code/SU2/issues/257#issuecomment-221203675,1,['clear'],['clear']
Usability,"Also works for me now! Thanks for fixing this. ~~Travis failed due to reaching the maximum time for a job. The usual time the serial test take in other PRs is like 45 min, but this one was killed after 1h 9 min. Is there something that could go wrong in the non-mpi case ?~~. ~~I just restarted the tests to see whether it occurs again.~~ . Now it has passed. If it happens again, simply restart the job in Travis ...",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/328#issuecomment-264239270:381,simpl,simply,381,https://su2code.github.io,https://github.com/su2code/SU2/pull/328#issuecomment-264239270,1,['simpl'],['simply']
Usability,"Also, this might be more of a question I guess, why does this `meson.py` script exist/why isn't the normal way of using meson (simply running `meson <builddir>`) used?. [edit] Just noticed `meson build` also works and uses the system installed `ninja` as expected. Still not really sure what the script is for.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/911#issuecomment-598376736:127,simpl,simply,127,https://su2code.github.io,https://github.com/su2code/SU2/issues/911#issuecomment-598376736,1,['simpl'],['simply']
Usability,"And here is a simple test case demonstrating potential use. A major benefit of the supersonic inlet is being able to model supersonic propulsion systems, such as a scramjet, where the propulsion system exit boundary is modeled as a supersonic inlet, with distinct properties from the farfield flow conditions. Here we have a two dimensional test case demonstrating the interaction of exhaust flow with free-stream flow at the exit plane of a 2D scramjet system. Flow conditions adapted from [A Design Method for Three-Dimensional Scramjet Nozzles with Shape Transition](https://arc-aiaa-org.stanford.idm.oclc.org/doi/abs/10.2514/1.B38293); Jens Kunze, Michael K. Smart, and Rowan Gollan; Journal of Propulsion and Power 2022 38:1, 3-17. <img width=""1262"" alt=""image"" src=""https://user-images.githubusercontent.com/44848904/211415971-b6122204-0d95-43ca-903b-d60fd6326c39.png"">",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1862#issuecomment-1375043856:14,simpl,simple,14,https://su2code.github.io,https://github.com/su2code/SU2/pull/1862#issuecomment-1375043856,1,['simpl'],['simple']
Usability,"Any other comments here? Otherwise, this is a simple addition that we can put in right away, and folks can hack away on Doxygen whenever their heart desires.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/373#issuecomment-279838683:46,simpl,simple,46,https://su2code.github.io,https://github.com/su2code/SU2/pull/373#issuecomment-279838683,1,['simpl'],['simple']
Usability,"As @gbaty said, it's usually easy to support both. Many times it can be done with a simple. ``` python; from __future__ import division, print_function; ```. at the top of each file, and tweaking the `print` and `import` statements. In my experience, the Anaconda (or miniconda) Python distribution makes it very easy to setup just about any version of Python you like on a cluster, since it's installed in the user's home directory by default. . Most scientific packages (NumPy, SciPy, Matplotlib, Pandas) already support both 2.7 and 3.x within a single codebase. Python 3 is the future!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/246#issuecomment-195767843:84,simpl,simple,84,https://su2code.github.io,https://github.com/su2code/SU2/issues/246#issuecomment-195767843,1,['simpl'],['simple']
Usability,"As we mentioned in the dev meeting where you exposed the problem, the implementation is not good for strongly coupled flows, and I would guess that it is worse for diffusion than convection (because diffusion is elliptic).; I suspect the main problem is that the linear system does not contain information from the other side of the interface, meaning the solution of the two domains is effectively decoupled.; You could try running the case at much lower CFL (below 1) even with an explicit method.; It is also possible that the current treatment could be improved, since it is an example of multiplicative Schwartz decomposition, maybe there is an ""optimal"" way of implementing that from a physics point of view. Just speculating here, but maybe it would help treating the interface as an outlet if flow is going out, and as an inlet if flow is coming in.; On the numerics side, you can also try hacking the MZ driver to use something more stable than block-Gauss-Seidel (e.g. some quasi-Newton thing for the interface). But those are all band-aids IMO, if you want a robust fluid-fluid interface you need the coupling to be present in the linear system. The simplest way to do that is to have an internal boundary and treat the problem as single zone.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1414#issuecomment-951848509:1161,simpl,simplest,1161,https://su2code.github.io,https://github.com/su2code/SU2/issues/1414#issuecomment-951848509,1,['simpl'],['simplest']
Usability,"At some point the marker starts being partitioned, some of it is in one rank, some in other(s).; Your print function truncates the file when it opens it, and so you only get the output from the last rank that opened the file.; You could make the file a member of the class, so that you can guarantee it is only opened once (other ranks would need to open in append mode), but then you still have a race condition when multiple ranks try to write simultaneously to the file (the result might be mixed lines, especially when `endl` is used to terminate lines because it forces a flush, maybe with ""\n"" and some luck it would be ok, but the order of the lines is still unpredictable).; To my knowledge mpi does not have simple ways to guarantee ordered execution of certain code regions. So unless you want to get knee deep in mpi, I recommend you keep this file output as a debug feature (that works on a single core) and use the normal surface output files (paraview, tecplot, etc.) for visualization.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/944#issuecomment-616367257:717,simpl,simple,717,https://su2code.github.io,https://github.com/su2code/SU2/issues/944#issuecomment-616367257,1,['simpl'],['simple']
Usability,"Both ‘**rapidjson**’ and ‘**CoolProp**’ are licensed under the shortest and simplest permissive **MIT** license. I am not an expert but whether indicating the text of the licenses and copyright marks at the beginning of each of my files is reasonable?. Honestly, I don’t like the idea to treat **rapidjson** as a git submodule because some **rapidjson** internals are Windows specific (e.g., _/include/rapidjson/msinttypes_ subfolder content) and I don’t really confident with Meson build setup procedure. . Actually, I generated the **all_cubics_extended_JSON_binary** variable in the following way.; **CoolProp** library contains dozens of json files from which I assembled the single file for my own needs. Then, I made some modifications to the _generate_headers.py_ file (under _/dev_ subfolder of the **CoolProp** root) and run it in order to translate my large json file into the C++ header file. The generated file is not as large (~1.3 MB) as it seems but verbose a little bit. Could you clarify what **tecplot** sources do you mean?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1402#issuecomment-942054879:76,simpl,simplest,76,https://su2code.github.io,https://github.com/su2code/SU2/pull/1402#issuecomment-942054879,1,['simpl'],['simplest']
Usability,"Bumping this thread... Files are now starting to be divided in several PRs, but we should set a clear policy for this. Seems that the consensus is to carry one class per file, move the inlines to the headers, and create subfolders where possible (i.e., have a more flat hierarchy in the src directory based on logical groups such as numerics, geometry, solvers, etc). We do not have a clear naming convention yet, but if it is one class per file, then an option is simply the class name. Am I capturing the current consensus correctly? Anything I am missing? Naming preferences?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/583#issuecomment-500945013:96,clear,clear,96,https://su2code.github.io,https://github.com/su2code/SU2/issues/583#issuecomment-500945013,3,"['clear', 'simpl']","['clear', 'simply']"
Usability,"By complex, I meant more complex than my simple toy problem. So if it's working for you, then that's what I was aiming for. I'll open a PR shortly.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/970#issuecomment-628681947:41,simpl,simple,41,https://su2code.github.io,https://github.com/su2code/SU2/issues/970#issuecomment-628681947,1,['simpl'],['simple']
Usability,"By the way, there's also this cool tool called vera++ that allows you to check the style of the entire codebase. This could be integrated with Travis so make sure PRs are consistent with the coding style guide.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/426#issuecomment-323580700:204,guid,guide,204,https://su2code.github.io,https://github.com/su2code/SU2/pull/426#issuecomment-323580700,1,['guid'],['guide']
Usability,"Can we please have different enum names than RHO and RHO_ENERGY? Those enum options are at the highest level of the code. In a random context, it's not clear that RHO is a residual. RHO_RESIDUAL and RHO_ENERGY_RESIDUAL would be better, and I personally feel that DENSITY_RESIDUAL would be better yet, though Francisco may disagree.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/87#issuecomment-58026023:152,clear,clear,152,https://su2code.github.io,https://github.com/su2code/SU2/pull/87#issuecomment-58026023,1,['clear'],['clear']
Usability,"Charanya,. thanks for the detailed answer. Let me ask you some more info. Apparently, you where able to reproduce the results I had comparing the two code versions simply using different boundary conditions on the latest code version. Can you specify me how?. Tobi,. In the meanwhile, to narrow down the problem, I ran also a couple tests in 2D to seek confirmation. For the (Euler) **pitching_NACA64A010.cfg** test case in the repository I rerun the same test at AoA of 1 deg and removing the pitching (no mesh deforming). I attach config files and summaries relative to the test cases. [config_CFD_6_2_0.txt](https://github.com/su2code/SU2/files/3938858/config_CFD_6_2_0.txt); [Summary_6_2_0.txt](https://github.com/su2code/SU2/files/3938859/Summary_6_2_0.txt); [config_CFD_6_0_1.txt](https://github.com/su2code/SU2/files/3938863/config_CFD_6_0_1.txt); [Summary_6_0_1.txt](https://github.com/su2code/SU2/files/3938865/Summary_6_0_1.txt). In this case the situation is definitely better as the two solvers give the same results. It looks like it is an issue related to the 3D case. <img width=""1220"" alt=""Screenshot 2019-12-09 at 11 27 27"" src=""https://user-images.githubusercontent.com/23583209/70424365-f316a780-1a77-11ea-8f68-4fc83e188ed7.png"">. I also quote Charanya in saying that it is definitely good that convergence to same values is reached but the transient response is fundamental and holds physical/mathematical values (I think of Wagner et similia) :). I would also suggest to add a regression test in this sense. Best, ; Rocco",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/828#issuecomment-563150217:164,simpl,simply,164,https://su2code.github.io,https://github.com/su2code/SU2/issues/828#issuecomment-563150217,1,['simpl'],['simply']
Usability,"Check out the branch [fix_inlet_file_shape_opt](https://github.com/su2code/SU2/tree/fix_inlet_file_shape_opt). There's just one commit that differs from develop (921e85b9d7d9c152c131874a84f3534caf5705c2). I tested it on a simple case, and it seemed to work. But I don't have any more complex test cases to test it on. All my ""complex"" test cases involve other features not merged with develop. You can either merge that branch or (if your branch is not up to date with develop) cherry-pick the commit.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/970#issuecomment-627095055:222,simpl,simple,222,https://su2code.github.io,https://github.com/su2code/SU2/issues/970#issuecomment-627095055,1,['simpl'],['simple']
Usability,"Checkout the small_fixes branch please, I hope the problem is ""that"" simple as I will not debug that function any further because it has the world record for nested loops. If it does not work you will have to hope for help from the turbo folks.; ```c++; for (iMarker = 0; iMarker < nMarker; iMarker++){; for (iMarkerTP=1; iMarkerTP < config->GetnMarker_Turbomachinery()+1; iMarkerTP++){; if (config->GetMarker_All_Turbomachinery(iMarker) == iMarkerTP){; if (config->GetMarker_All_TurbomachineryFlag(iMarker) == marker_flag){; for (iVertex = 0; iVertex < nVertex[iMarker]; iVertex++) {; iPoint = vertex[iMarker][iVertex]->GetNode();; for (jMarker = 0; jMarker < nMarker; jMarker++){; if (config->GetMarker_All_KindBC(jMarker) == PERIODIC_BOUNDARY) {; PeriodicBoundary = config->GetMarker_All_PerBound(jMarker);; jVertex = nodes->GetVertex(iPoint, jMarker);; if ((jVertex != -1) && (PeriodicBoundary == (val_iZone + 1))){; coord = nodes->GetCoord(iPoint);; switch (config->GetKind_TurboMachinery(val_iZone)){; case CENTRIFUGAL; ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1219#issuecomment-790064117:69,simpl,simple,69,https://su2code.github.io,https://github.com/su2code/SU2/issues/1219#issuecomment-790064117,1,['simpl'],['simple']
Usability,"Closing this for now. After talking with @oleburghardt and @talbring there are features being worked on that are much simpler to develop using Eigen, we may see a PR for that in the not too distant future.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/643#issuecomment-592951260:118,simpl,simpler,118,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-592951260,1,['simpl'],['simpler']
Usability,"Config options and their options can be found in:; https://github.com/su2code/SU2/blob/master/config_template.cfg; As a part of the code repository, this document will remain up to date with whatever version of the code you have. I believe that this is the single document to which you refer. I apologize that its location or purpose may not have been clear - I will shortly go edit the wiki to see if I can make it clearer that this file exists. . Additionally, the file config_template_basic.cfg in the same directory is a shorter version with only the options most commonly used. . Further documentation of the config options is also available in the comments of:; https://github.com/su2code/SU2/blob/master/Common/src/config_structure.cpp. And although it has not been up to date as we moved towards the wiki and config file template rather than keeping doxygen up to date, additional documentation can be produced using the files in su2code/Documentation/Doxygen.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/183#issuecomment-111755617:352,clear,clear,352,https://su2code.github.io,https://github.com/su2code/SU2/issues/183#issuecomment-111755617,2,['clear'],"['clear', 'clearer']"
Usability,Could you leave in the machine learning section a bit longer?,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/208#issuecomment-152095697:31,learn,learning,31,https://su2code.github.io,https://github.com/su2code/SU2/pull/208#issuecomment-152095697,1,['learn'],['learning']
Usability,"Dark mode?; ""Is it possible to learn this power?""",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1129#issuecomment-743123950:31,learn,learn,31,https://su2code.github.io,https://github.com/su2code/SU2/pull/1129#issuecomment-743123950,1,['learn'],['learn']
Usability,"Dear @oleburghardt, . Unfortunately, your initial reply lacks of any constructive contribution. . SU2 depends on the feedback of you all. We should not discourage anybody to change/improve, show interest, ask for clarification, etc. The tone of your initial replay was unjustified and not polite.; From now on, your profile as a member of the developer team (collaborator) will be not longer active. Peace,; Francisco",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/405#issuecomment-313775430:117,feedback,feedback,117,https://su2code.github.io,https://github.com/su2code/SU2/issues/405#issuecomment-313775430,1,['feedback'],['feedback']
Usability,"Dear @salvovitale,. I realize that it requires significant changes in the code structure and I don't have a clear answer how to do this, also because I don't know all the details of the implementation of the multi-physics simulations. . The only thing I do know is that the loop over the zones must be inside the loop over the RK stages, at least for the fluid zones. Whether this is also the case for e.g. fluid-structure problems, I don't know. As you mentioned, the opinion of the other developers is greatly appreciated on this matter. Regards,. Edwin",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/437#issuecomment-328302068:108,clear,clear,108,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328302068,1,['clear'],['clear']
Usability,"Dear @vdweide,. I clearly see your point. However, this can be quite a big structural change of the code and I think we should plan very well how to address this issue. The reason of having a driver class was to facilitate the extension of SU2 to multi-physics applications both for analysis (direct solver) and design (adjoint). Thanks to the high level of abstraction of the CInterpolator, CTransfer and the CIteration classes, it was kind of natural to treat fluid-fluid problems similarly to multi-physics problem (i.e. fluid-structure and fluid-heat). As a matter of fact, the multi-stage turbomachinery approach , its adjoint counterpart, the sliding interface they all rely on this driver structure in which we loop among all the zones. If i understood correctly, you suggest to move only the fluid-fluid multi-zone loop at lower level in order to integrate in time only after having coupled all the fluid zones. Right? If so, we need to design the code in such a way that the fluid zones loop is separated from the multi-physics one.; To solve this issue, I think, we just need to find a smart way to differentiate fluid-zones from the rest. Perhaps we can do that by instantiating one Iteration per physical problem instead than per zone. So that inside the iteration we can couple all the fluid zones, and in the driver we can couple the different physics (Iteration). Indeed, this is just a preliminary idea. In general I think we should aim to a structure that can flexibly accommodate multi-physics problems with multi-zones for different physics. A good example is solving fluid-structure in multi-stage turbomachinery, in which we have multiple fluid-zones and multiple structure-zones. ; ; I would like to hear on this matter also from @fpalacios @talbring , @economon , @rsanfer @oleburghardt ,@LaSerpe and @arubino. Thanks @vdweide againg for raising this issue. cheers. Salvo",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/437#issuecomment-328274125:18,clear,clearly,18,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328274125,1,['clear'],['clearly']
Usability,"Dear Daumantas,. I appreciate your effort in adding support for cmake in SU2. We have recently introduced the Meson build system (https://mesonbuild.com/) (#685, #745) as a candidate to replace automake. A guide on how to use can be found [here](https://su2code.github.io/docs_v7/Build-SU2-From-Source/). The idea is that we will have this system along automake at least for the upcoming version 7 and that we get rid of automake afterwards. Considering that, I don't think that it makes sense to maintain 3 different build systems **at the moment**. I really hate turning contributions down, but this one is three months too late. However, we might reconsider adding support for another build system once we got rid of automake, or, if we feel that meson does not fit our needs. I am all ears to hear other opinions. However, let's not start a discussion on the advantages/disadvantages of the build systems. Some benefits can be found in the Issue/PR linked above.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/814#issuecomment-552360147:206,guid,guide,206,https://su2code.github.io,https://github.com/su2code/SU2/pull/814#issuecomment-552360147,1,['guid'],['guide']
Usability,"Dear Dr Albring,. I just followed the procedures and included the files to create a test case to SU2_CFD_AD [a coarse mesh, a TargetCp.dat and a config file for an Arina nozzle. The coarse mesh is a 2000 triangles one; which is enough to give us an idea of the shockwave location and the geometry modifications. The next mesh I have would be an ~85000 elements which gives us a good information on the 27th function call]. ; I had some segmentation faults during long jobs: Is there some recommended tuning I can do on OS/HW or SU2 in order to minimize them?. With kind regards,. Jairo. > On Dec 7, 2018, at 09:45, Jairo Paes Cavalcante Filho <jairo.pcfilho@gmail.com> wrote:; > ; > Hello Dr. Albring,; > ; > Yes! Sorry for the delay due some internal presentations and events here.; > I just finished a small model and successfully tested it on openSUSE. I expect to upload it today.; > ; > With kind regards,; > ; > Jairo; > ; >> On Dec 7, 2018, at 06:35, Tim Albring <notifications@github.com <mailto:notifications@github.com>> wrote:; >> ; >> Hi Jairo,; >> ; >> what is the status here ? Is it possible to provide a simpler (smaller) case ?; >> ; >> —; >> You are receiving this because you were mentioned.; >> Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/pull/600#issuecomment-445175541>, or mute the thread <https://github.com/notifications/unsubscribe-auth/Ac180u4PogeqhPW9rrfY4mW705IYKjvhks5u2jZpgaJpZM4X34F2>.; >> ; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/600#issuecomment-445429636:1120,simpl,simpler,1120,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-445429636,1,['simpl'],['simpler']
Usability,"Dear Dr. Economon,. I just finished the run on AD with the files you have adjusted and it did; converge. I also have successfully run some simple inverse design tests; with a limit on the number of cycles.; Thank you very much for your guidance and help. With kind regards,. Jairo. On Wed, Jan 30, 2019 at 2:13 PM Thomas D. Economon <notifications@github.com>; wrote:. > *@economon* approved this pull request.; >; > LGMT. Thanks @jaspe55 <https://github.com/jaspe55>; >; > Just one request: I have adjusted the number of iterations for the; > regression test and updated the residual values in the python script. I; > also had to move around some files. Can you please run the case (to; > convergence) and verify that the results are what you expect? Note that the; > config file and target Cp are in the code repository and the mesh and; > solution file are in the testcases repository. If everything looks ok, then; > this is ready to be merged.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/pull/600#pullrequestreview-198200089>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/Ac180hqzVnSUPCnSBkQrTPfIv0kIltygks5vIdKrgaJpZM4X34F2>; > .; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/600#issuecomment-459568514:139,simpl,simple,139,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-459568514,2,"['guid', 'simpl']","['guidance', 'simple']"
Usability,"Dear Dr. Economon,. Thank you again for your guidance.; The git add, git commit and git push commands worked as expected.; The only problem I had was when I tried to upload the mesh file to https://github.com/su2code/TestCases/tree/develop/disc_adj_euler: <https://github.com/su2code/TestCases/tree/develop/disc_adj_euler:> I wanted to upload a folder “arina2k”, whose contents is the mesh file (.su2). I could not just upload the folder name: the system appears to be waiting for an actual file name. When I choose the file name inside that folder , it appears that the system would upload the file within the repository, but 'discarding’ its folder name, so I would have an ‘orphaned’ file there. I tried also to create a file (which would be my folder name), but again, I am prompted with an editor in order to write an actual file, using directly the browser. I believe that there is a simple way to upload a sub-directory/filename, but i could not realize it. With kind regards,. Jairo. > On Dec 14, 2018, at 01:26, Thomas D. Economon <notifications@github.com> wrote:; > ; > @jaspe55 <https://github.com/jaspe55> : I see that you have added the residual check for the python regression script, but I do not see the config file, target file, or mesh. The config file and target file should be placed in SU2/TestCases/disc_adj_euler/arina2k/ (according to your path in the regression script), and the mesh placed in the TestCases/disc_adj_euler/arina2k/ directory in the TestCases repository here (develop): https://github.com/su2code/TestCases/tree/develop <https://github.com/su2code/TestCases/tree/develop>. Don't forget to 'git add' the files to make sure they are included on push. We can help diagnose any segfaults with the files.; > ; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/pull/600#issuecomment-447209397>, or mute the thread <https://github.com/notifications/unsubscribe-auth/Ac180hTDp",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/600#issuecomment-447475363:45,guid,guidance,45,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-447475363,2,"['guid', 'simpl']","['guidance', 'simple']"
Usability,"Dear Heather,; I am analyzing a propeller of an UAV. I have static thrust measurements such that when I used Euler results I got 3.5 lbf thrust as compared to the measured 6 lbs. My next step was to perform an NS equation with SA turb model. I got 7 times over predicted results such that the mesh has a Y+ of less than 1. Then I thought of doing an SST but was not long enough that it gave me error with divergence. I have been setting up my SST case as per the tutorial example of NACA0012. However, I do not happen to see any entry with regards to eddy frequency etc. (usually required by SST) in the config file. Any guidance will be great.; Thanks; Jehan; From: Heather Kline notifications@github.com; To: su2code/SU2 SU2@noreply.github.com ; Sent: Tuesday, May 12, 2015 11:43 AM; Subject: [SU2] Feature deallocation (#174). Bringing this branch up to date with current develop branch. ; Various deallocation changes; Some regression tests fail but all run. (previously was not the case); You can view, comment on, or merge this pull request online at:;   https://github.com/su2code/SU2/pull/174; Commit Summary; - Updated GetEngine_Properties; - Fix to the last commit; - Small bug; - Merge branch 'develop' into feature_MPI; - merging; - SU2_SOL and SU2_CFD are working; - Preliminary, but complete, implementation of SU2_DEF; - More updates; - Working version; - Complete implementation (validate); - Working version of SU2_DEF; - Final push before moving to the develop branch; - New MPI (removing SU2_PRT); - Merged in Ben's ParMETIS integration and fixed some conflicts.; - Merge branch 'benkirk-parmetis_integration' into feature_MPI; - ParMETIS geometry routines have been copied over but are not activated yet.; - Small change to ParMETIS include.; - ParMETIS can now be activated for testing (PARMETIS=YES in config).; - Updated MG; - Updated EA subrotuine; - Small fix; - Fixing memory leak; - Fixing memory leaks; - Dev release v.3.2.6; - Increasing MAX_NUMBER_MARKER; - Working versi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/174#issuecomment-101443812:621,guid,guidance,621,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812,1,['guid'],['guidance']
Usability,"Dear all, ; I have added a pdf file here that includes some test case results obtained with our BC transition model. These zero pressure gradient and variable pressure gradient flat plate test cases are very popular for model validation. I have also included Eppler E387 airfoil results. I would appreciate if you have any 3-D test case and share it with me.; Looking forward to hear your feedback. ; Sincerely,; Samet. [BC_model_TestCaseResults.pdf](https://github.com/su2code/SU2/files/562425/BC_model_TestCaseResults.pdf)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/326#issuecomment-257360833:389,feedback,feedback,389,https://su2code.github.io,https://github.com/su2code/SU2/pull/326#issuecomment-257360833,1,['feedback'],['feedback']
Usability,"Folks,. Perhaps we can split this issue to a separate thread. But it is indeed a critical one. Improving performance of the solver (or trying other preconditioned solvers) would be a significant improvement amortized over a very large number of users. Add it as a topic of discussion for the Annual Meeting in May?. Juan. On Feb 5, 2019, at 6:54 AM, pcarruscag <notifications@github.com<mailto:notifications@github.com>> wrote:. Hi @EduardoMolina<https://github.com/EduardoMolina>,. That is something I am also interested in as for some of my structural cases the current linear solvers simply do not converge. However Eigen is not the tool for that as the sparse linear solvers it has are similar and are not distributed parallel.; When I opened this issue I was thinking exclusively about how we handle small-medium dense matrices that live on a single rank, and associated algorithms (the kind used for RBF interpolation for example).; I think the two issues are fairly orthogonal, so we can open another to discuss large solvers, for which related work has already been started. Cheers,; Pedro. —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/643#issuecomment-460666656>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADpSxClv7-iTk5lFN9sK4fkqM7lk0FZEks5vKZsPgaJpZM4adbAo>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/643#issuecomment-460714752:587,simpl,simply,587,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-460714752,1,['simpl'],['simply']
Usability,"Food for thought: According to his most recent AIAA talk, Spalart himself has tried to keep the model variants ""modular."" Some of the variants are compatible with each other. For example, you can add a ""rotation-curvature correction"" and a ""compressiblity correction"". The NASA TMR catalogue reflects this design by stating ""These corrections can be applied individually or together in combination with the General Model."". A simple `SA_QCR` or `SA_COMP` naming scheme doesn't match the underlying design. On the user-facing side, separate config options might be better for some of the variations. On the code side, bit flags (Issue #770) might be a good way to gather all the model variants together into a single config option.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/992#issuecomment-652446915:426,simpl,simple,426,https://su2code.github.io,https://github.com/su2code/SU2/issues/992#issuecomment-652446915,1,['simpl'],['simple']
Usability,"For the time being, lets use Gitter to communicate! Its free and you can simply log in with your github account. https://gitter.im/su2code/community",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/645#issuecomment-515048317:73,simpl,simply,73,https://su2code.github.io,https://github.com/su2code/SU2/issues/645#issuecomment-515048317,1,['simpl'],['simply']
Usability,"From the SU2 paper, talking about ""guiding principles"":. <img width=""574"" alt=""Screen Shot 2019-10-09 at 3 26 46 PM"" src=""https://user-images.githubusercontent.com/19416354/66525312-edb5d480-eaa9-11e9-9c0f-158b3941b407.png"">. I particularly like. > Full documentation, including a comprehensive set of tutorials. (""including"" implying that the tutorials are a subset of the documentation), and . > expose the full set of options [...] to the practitioner. This conflicts with our ""operating principle"", laid out on the tutorials page:. > Rather than writing a long manual on all available (and constantly evolving) configuration options available in SU2[...]. The Guide to V7 is a good start, but I think at the bare minimum (since I agree that full documentation would be a huge task, though one that's apparently promised on a paper we link on our homepage), we should provide more information about the existing options beyond forcing the user to scroll through config_template.cfg or dig through the tutorials.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/775#issuecomment-540239931:35,guid,guiding,35,https://su2code.github.io,https://github.com/su2code/SU2/issues/775#issuecomment-540239931,1,['guid'],['guiding']
Usability,"Giulio,. Yes! It would be excellent to have the HLLC Jacobians for the ideal gas case too. Please let me know if I can assist with anything. You might also have noticed some old commented out code that you could use as a guideline. Tom",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/209#issuecomment-171112223:221,guid,guideline,221,https://su2code.github.io,https://github.com/su2code/SU2/pull/209#issuecomment-171112223,1,['guid'],['guideline']
Usability,"Good Morning,. I'm from Chair of Thermal Engineering of Poznań University of Technology.; In August 2017 my colleague and I attended SU2 Summer School in; Kaiserslautern and met the Sci-Comp team developing the SU2. I think moving the main tutorials to the main repository is a good idea. We; declared to contribute some validation cases and written tutorials and; having this in main repository will ease the process of adding/modifying; the docs to a simple pull request. I also have a suggestion regarding the Test Cases and Tutorial files. I; apologize if this is the wrong place or this has been discussed already,; but still will give it a try:; - Test cases folder from SU2/su2code repository shall be moved to the; SU2/TestCases repository. Rationale: this makes one repository to store the; test case *.cfg files and mesh files.; - There shall be a TestCases/Mesh folder to store all the meshes needed for; Test Cases files, without subdivisions for RANS, Euler etc subfolders.; Considering that multiple test cases use the same mesh and all the mesh; files are distinct, this solution generates one place to store all the mesh; files. Should a user perform a test case, he/she will find the mesh by name; referenced in the *.cfg file instead searching thru multiple folders. This; will also help avoiding unnecessary copies of mesh files.; - The same should be done for Tutorial files: Tutorial/Mesh folder for; storing meshes (duplicating these few files from TestCases/Mesh should not; be a problem IMO, but will really help a new user to get up to speed with; SU2); - I have no clear opinion on where the Tutorial files folder should be; stored. But considering moving written tutorials to main repository i think; that tutorial files should also be stored in main SU2/su2code repository. Best regards and Happy New Year; Jędrzej. 2017-12-30 23:45 GMT+01:00 Tim Albring <notifications@github.com>:. > What do you think of moving the written tutorials also to the main; > repository ? Then",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/485#issuecomment-354736415:453,simpl,simple,453,https://su2code.github.io,https://github.com/su2code/SU2/pull/485#issuecomment-354736415,1,['simpl'],['simple']
Usability,"Good catch! yep! I implemented an interesting/important change: Before, WALL_DISTANCE was computed using only the surfaces that you have identified as moving surfaces... as you can imagine that only works when you have a very simple problem (maybe an airfoil) but... if you have a problem with more Navier-Stokes markers together and you are moving only one of them the method doesn't work (e.g. wing-fuselage). For that reason I reimplemented WALL_DISTANCE which now is computed from all the solid surfaces and I also created DEF_WALL_DISTANCE that computes the distance from the surfaces that we are moving (as before). Frankly, I haven't found a situation in which DEF_WALL_DISTANCE outperforms the new solid WALL_DISTANCE... And, my suggestion is to eliminate DEF_WALL_DISTANCE in the future. For the time being I have added DEFORM_STIFFNESS_TYPE= DEF_WALL_DISTANCE to the config files to see if that solves the problem. Thanks!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/412#issuecomment-318673304:226,simpl,simple,226,https://su2code.github.io,https://github.com/su2code/SU2/pull/412#issuecomment-318673304,1,['simpl'],['simple']
Usability,"Good point about making the eigen-functions static. That makes it a lot more accessible in other parts of the code. Will include that in the changes along with the option name changes. . I like the idea about the static allocation, but I foresee a problem that you actually mention. If I convert the variables to be statically defined, I would have to make the eigen-functions accept statically defined arrays. Since most arrays in SU2 are dynamically allocated, this would cause some compatibility issues. . In general, I see the value in making a math library associated with matrix operations. Maybe you could pitch the idea in an issue and get feedback on it?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/570#issuecomment-433963723:648,feedback,feedback,648,https://su2code.github.io,https://github.com/su2code/SU2/pull/570#issuecomment-433963723,1,['feedback'],['feedback']
Usability,"Good point, Jayant. Maybe a brief tutorial and an example can be created so people know how to use this new feature? There will be a presentation by Edwin and Tom at the annual meeting that might also be helpful. Best,; Juan. On Apr 24, 2019, at 11:32 AM, Jayant Mukhopadhaya <notifications@github.com<mailto:notifications@github.com>> wrote:. I am not a 100% clear on all the things this new feature can do. From what I gather we can now set an initial flow field that is not just freestream condition everywhere? If this is the case, this is a hugely useful feature so thank you guys for doing that. How exactly is this allowing for solution verification? Is it allowing you to run the same case with a bunch of different solver schemes? Can it run the solvers on a set of meshes or do you still have to run on each mesh refinement individually?. —; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/pull/672#issuecomment-486373335>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AA5FFRDJGI6HH6HEUDATJS3PSCRUZANCNFSM4HH7BJ7A>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/672#issuecomment-486418280:360,clear,clear,360,https://su2code.github.io,https://github.com/su2code/SU2/pull/672#issuecomment-486418280,1,['clear'],['clear']
Usability,"Great! Sounds good, just figured id bring it up to get some of these ancient issue cleared up. :)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/691#issuecomment-501794908:83,clear,cleared,83,https://su2code.github.io,https://github.com/su2code/SU2/pull/691#issuecomment-501794908,1,['clear'],['cleared']
Usability,"Guys, we cannot simply change defaults like that, update regressions, and call it a day... Even fixing #1551 is a major change that should warrant a major version update. We want SU2 users to be able to rely and trust the code we release...; That is why I suggested that this PR should be used only to change the way of specifying SST options, and introduce simple ones like the V and KL modifications. Then the validation work for SST 2003 (with and w/o modification) would be done in #1557.; But ok, let me look at this and propose a way forward that gets in develop ASAP, **please don't start updating regressions**.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1560#issuecomment-1084549672:16,simpl,simply,16,https://su2code.github.io,https://github.com/su2code/SU2/pull/1560#issuecomment-1084549672,2,['simpl'],"['simple', 'simply']"
Usability,"Guys,. Thanks for your feedback. @pcarruscag, the reason why I made a different enum rather than a boolean USE_SST_SUSTAINING_TERMS is that all different SA versions also have a different enum. So I thought this was more consistent. But if there is a strong preference for an additional boolean, I'm fine with that as well. What we can do is to keep the enum and set the boolean USE_SST_SUSTAINING_TERMS internally and overwrite SST_SUST to SST. @talbring, @jayantmukho, I am in favor of keeping the original version of SST. Although the difference between the models is rather small, basically the addition of one term, the difference in results can be quite significant, especially for relatively low Reynolds numbers and large value of the turbulent intensity. . @economon, you are right that a lot of the checks for SST are actually more general checks for a two equation model. So I think that most, if not all, checks for SST can be replaced be a check for the number of turbulent equations. That is more general as well, in case we want to add additional turbulence models in the future, assuming that an equation is present for the turbulent kinetic energy if the number of turbulence equations is two or bigger.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/765#issuecomment-524053082:23,feedback,feedback,23,https://su2code.github.io,https://github.com/su2code/SU2/pull/765#issuecomment-524053082,1,['feedback'],['feedback']
Usability,"Have a look at my last comment in #763, I think there is a better way of handling linear system periodicity instead of what we do, which may allow you to run at higher CFL (and with simpler periodic comms). But at the moment you are missing the PERIODIC_IMPLICIT comms after solving the linear system, see CompleteImplicitIteration_impl in CFVMFlowSolverBase.hpp.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1382#issuecomment-927138184:182,simpl,simpler,182,https://su2code.github.io,https://github.com/su2code/SU2/pull/1382#issuecomment-927138184,1,['simpl'],['simpler']
Usability,"Heather: I know we talked about this one in person the other day, but I am still weighing things... Even though it looks like a small change, it's a really big one, and I want to make sure we keep things as clear and user-friendly as possible. . If anyone else has thoughts on this, please feel free to chime in. Maybe we can catch up about it again early this week.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/241#issuecomment-184449921:207,clear,clear,207,https://su2code.github.io,https://github.com/su2code/SU2/pull/241#issuecomment-184449921,2,"['clear', 'user-friendly']","['clear', 'user-friendly']"
Usability,"Hello @aditya12398 ,. No such thing as a noob question!. To use your system meson, instead of using: `./meson.py <arguments>` in your SU2 root dir, use `meson <arguments>`. This assumes your system meson is in front of your current directory in your path, of course. Likewise, to use system ninja, instead of using: `./ninja -C build install`, simply use `ninja -C build install`. I found, for some reason, that when using my system meson and ninja with the changes made in `fix_python_3.8`, I am not getting errors, but when I use SU2's included `./meson.py`, I'm still getting those errors. Not sure why this is happening, though. -Paul",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/991#issuecomment-631584658:344,simpl,simply,344,https://su2code.github.io,https://github.com/su2code/SU2/issues/991#issuecomment-631584658,1,['simpl'],['simply']
Usability,"Hello @aditya12398 ,. The fifth line of the file you attached shows a call to `c++`, rather than `mpicxx`, which could cause those undefined references. Basically, the linker is not seeing your mpi libraries. I believe that, in order to use the `-Dcustom-mpi=true` flag, you may need to define your compiler environment variables (such as `$CC`, `$CXX`, `$LD`, `$MPICXX`, etc). Having both OpenMPI and MPICH installed on your system is complicating things, I think. Without some manual configuration of your system's environment, it may not be clear to meson/ninja which mpi implementation should be used. You may need to do some digging around on the internet to see how to properly resolve which MPI implementation gets used for different applications. -Paul",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1000#issuecomment-634825410:544,clear,clear,544,https://su2code.github.io,https://github.com/su2code/SU2/issues/1000#issuecomment-634825410,1,['clear'],['clear']
Usability,"Hello @pcarruscag @TobiKattmann and SU2 developers,. We have been busy making several code updates, performing cleanup, etc. for this PR. Can you please review and provide feedback when you get the chance? Thank you in advance!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1300#issuecomment-1061224541:172,feedback,feedback,172,https://su2code.github.io,https://github.com/su2code/SU2/pull/1300#issuecomment-1061224541,1,['feedback'],['feedback']
Usability,"Hello Dr. Albring,. Yes! Sorry for the delay due some internal presentations and events here.; I just finished a small model and successfully tested it on openSUSE. I expect to upload it today. With kind regards,. Jairo. > On Dec 7, 2018, at 06:35, Tim Albring <notifications@github.com> wrote:; > ; > Hi Jairo,; > ; > what is the status here ? Is it possible to provide a simpler (smaller) case ?; > ; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/pull/600#issuecomment-445175541>, or mute the thread <https://github.com/notifications/unsubscribe-auth/Ac180u4PogeqhPW9rrfY4mW705IYKjvhks5u2jZpgaJpZM4X34F2>.; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/600#issuecomment-445209093:373,simpl,simpler,373,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-445209093,1,['simpl'],['simpler']
Usability,"Hello Dr. Economon,; ; At this moment, I am running a case which is lighter but sill not very simple (I am running it on a Mac with four cores, and it will finish by Monday, I suspect). As soon as it successfully completes, I will work on a simpler sample case in order to include it in the test suite, willing God. With kind regards,. Jairo. > On Nov 16, 2018, at 16:12, Thomas D. Economon <notifications@github.com> wrote:; > ; > Thanks, @jaspe55 <https://github.com/jaspe55> ! LGTM. I don't think we have any tests for the inverse design capability. Do you have a very simple test case that we can put into the regressions for this capability? I think you are working on a nozzle design.; > ; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/pull/600#issuecomment-439496260>, or mute the thread <https://github.com/notifications/unsubscribe-auth/Ac180nOm5nOlpnYLID7YMRQeFOsAZQJYks5uvw4MgaJpZM4X34F2>.; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/600#issuecomment-439506935:94,simpl,simple,94,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-439506935,3,['simpl'],"['simple', 'simpler']"
Usability,"Hello Pedro, thanks for your quick reply! ; More than the differentiation of the mesh deformation problem I was referring to what SU2_DOT does in the specific, at least in terms of workflow.; In fact, reading your answer I realise that maybe I'm misunderstanding the process done by SU2_DOT.; I thought that, in case of Disc. Adjoint, SU2 solver was already providing the _total_ sensitivity of the objective function with respect to the boundary grid nodes displacements. This already includes the contribution of the mesh deformation. given this, I thought that SU2_DOT was simply projecting such sensitivities on the FFD box point displacements chosen as design variables. But I cannot understand then why the need to include the mesh deformation problem within SU2_DOT.; Can you let me know about that please?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1017#issuecomment-640071772:576,simpl,simply,576,https://su2code.github.io,https://github.com/su2code/SU2/issues/1017#issuecomment-640071772,1,['simpl'],['simply']
Usability,"Hello Tobi,. Thanks for your quick reply! I'll address you doubts as follows. > I used this mesh <Testcases>/control_surface/mesh_ONERAM6_inv.su2 and the boundary marker names are a bit different in the mesh, compared to your provided config (WING vs LOWER_SIDE, UPPER_SIDE, TIP + SYMMETRY vs SYMMETRY_FACE). . Yeah, the mesh you are mentioning is the same. I simply united the TIP, LOWER_SIDE and UPPER_SIDE under the marker tag WING. > The initial transient through the domain based on the initial values is unphysical to some extend and if e.g. 'steady state' results are the same for both code versions .... the problem is not that big. Although it differs quite a bit in the temporal evolution tbh; In the results (also in the mail) it looks a bit like it approaches a steady state for Cl and CD. So maybe 1000 timesteps will tell us a bit more 🤔. I guess they converge eventually to the same values. I tried to compare the same case but steady (I attach the summary). Results in this case are fairly similar and (in my opinion) raise no warnings.; [Summary_steady_6_0_1.txt](https://github.com/su2code/SU2/files/3906039/Summary_steady_6_0_1.txt); [Summary_steady_6_2_0.txt](https://github.com/su2code/SU2/files/3906010/Summary_steady_6_2_0.txt). Regarding the unsteady case, I'm aware that this test may have little physics behind (especially if comparing the first timesteps) but I wanted to investigate the reason :). Results are too different and I think these might be one of the reasons behind some discrepancies I'm encountering in my FSI framework. ; My framework for FSI features a restart from a steady solution at t=0 and an unsteady simulation with imposed boundary of the wing marker. The discrepancies in that case are huge and are clearly wrong. I went back to the root and found this weird behaviour comparing the two versions so I thought this might be one cause. > Another thing: There is no tag 6.0.2 😕 ... 6.0.1 and then 6.1.0.. Yep you are right, the version is definitely 6.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/828#issuecomment-559850074:360,simpl,simply,360,https://su2code.github.io,https://github.com/su2code/SU2/issues/828#issuecomment-559850074,1,['simpl'],['simply']
Usability,"Hello all, ; as I have mentioned before, this PR is the first of a series that are coming soon for general maintenance and improved usability of the code. As you all know, we are working hard to improve the generality and usability of the code and to maintain it healthy. ; We have some other improvements/generalizations that rely on this one. Therefore, I think it would be a good idea to merge this in sooner than later, to transition smoothly to this new structure.; Best,; Ruben",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/585#issuecomment-441210349:132,usab,usability,132,https://su2code.github.io,https://github.com/su2code/SU2/pull/585#issuecomment-441210349,2,['usab'],['usability']
Usability,"Hello, ; You are right, this pr cannot solve the problem but just make the solution look reasonable.; For some complicated case, it is hard to converge, not like in the simple cases.; I have read the relevant code and book, and I think maybe a good way is to rewrite the bc code and move the nonzero normal components limitation to where the flux are calculated. Or we can store the flux of the points on the sym bc, and in CFVMFlowSolverBase<V, R>::BC_Sym_Plane we just use the stored flux without recalculation.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/2174#issuecomment-1868453319:169,simpl,simple,169,https://su2code.github.io,https://github.com/su2code/SU2/pull/2174#issuecomment-1868453319,1,['simpl'],['simple']
Usability,"Hello, @aeroamit . Thank you very much. I try for some times and find that mach number matters. When I simulate two-dimensional lid-driven cavity flow, the flow starts from static. So this case always fails. I try laminar boundary layer case with 0.1 incoming mach number. This time SU2 runs well with AUSMPLUSUP, at a very low CFL number(0.01 or lower), converging slowly. I learn that this scheme is perfect for high speed flow, but it may not be good at low mach number case. Perhaps there are some mistakes when I use it. I think I am not familiar with this scheme enough and that I know SU2 not very well. Before using it in practice, I should read more papers and codes. By the way, SU2 6.2.0 doesn't have the option 'USE_ACCURATE_FLUX_JACOBIANS'. Thanks again. Regards; Cao J. Z.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/628#issuecomment-523374440:376,learn,learn,376,https://su2code.github.io,https://github.com/su2code/SU2/pull/628#issuecomment-523374440,1,['learn'],['learn']
Usability,"Hello,. I have been debugging the differences between the two versions. I found 5 differences that lead to slightly different results. Two of them have been verified to be an improvement of physical modelling. The other 3 I am still trying to figure out. Could you please run the same tests with MUSCL_FLOW=NO and see if you're still facing this issue?. I see that the MUSCL reconstruction is one of the 3 things that have been modified and not sure if could be the cause of the problem or not. I will keep working on understanding the impact of the other 2 things. When you do this - could you please save the simulation output log of both versions and send those back to me too (in this way I'll have a better feeling of what is happening to the residuals throughout the simulation)? We can just focus on the invbb case to make it simpler.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/2026#issuecomment-1562975684:833,simpl,simpler,833,https://su2code.github.io,https://github.com/su2code/SU2/issues/2026#issuecomment-1562975684,1,['simpl'],['simpler']
Usability,"Hello,; As a simple user, when I forget to save the last history before continuing a simulation I am very frustrated, because it is lost forever... Since the new history file erases the previous one.; Also, making these history backups is not very practical...; I would very prefer an option in the config file like: ""when RESTART_SOL= YES append to the history or not?"".; I think it would not be difficult to set another variable like: ""max_it must be counted from the beginning or from the last launch?"".; I agree it makes it a bit more complex, but not too much I think :)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/99#issuecomment-103369490:13,simpl,simple,13,https://su2code.github.io,https://github.com/su2code/SU2/issues/99#issuecomment-103369490,1,['simpl'],['simple']
Usability,Here is a quick summary for the inviscid wedge case using different NEMO schemes. There is clearly work to be done in the convergence/robustness world.; [nemo_scheme_regressions.pdf](https://github.com/su2code/SU2/files/10441554/nemo_scheme_regressions.pdf),MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1885#issuecomment-1386403998:91,clear,clearly,91,https://su2code.github.io,https://github.com/su2code/SU2/pull/1885#issuecomment-1386403998,1,['clear'],['clearly']
Usability,"Here is a simple proof-of-concept for the fluid iteration where we catch SIGTERM. If you run it and hit ctrl-c, we catch the signal and we set stopcalc to true. This will exit the for-loop and also forces a saving of the files.; I think implementing the signal handler like this is the best, because we let the solver handle all the cleanup.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/2110#issuecomment-1678550840:10,simpl,simple,10,https://su2code.github.io,https://github.com/su2code/SU2/pull/2110#issuecomment-1678550840,1,['simpl'],['simple']
Usability,"Here is the patch from the develop branch. As I stated before, this adds the 'increment-progress' logic to the vertex export process; this causes the sub-progress bar to shows the progress of the vertex export for a more accurate experience. Thanks again,. Ethan Alan",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/72#issuecomment-56592650:154,progress bar,progress bar,154,https://su2code.github.io,https://github.com/su2code/SU2/pull/72#issuecomment-56592650,1,['progress bar'],['progress bar']
Usability,"Hey @LaSerpe (Giulio),. I had a look at the new driver structure and it look clear to me. My only comments is on the name of the classes: I agree on having a GeneralDriver in place of the SingleZone and MultiZone Driver, as @tobadavid said we should distinguish the drivers for the different physics/applications, but the name CFluidDriver I think is a bit misleading considering the fact that is specifically for multizone fluid with sliding-mesh interface. Perhaps a SlidingMeshDriver sounds better??? Any suggestion from the others?. Regarding the fact that you still have to specify the FSI_MARKER, i would fix this before merging with the develop. . Anyway good job!!! . cheers. Salvo",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/322#issuecomment-255340813:77,clear,clear,77,https://su2code.github.io,https://github.com/su2code/SU2/pull/322#issuecomment-255340813,1,['clear'],['clear']
Usability,"Hey @pcarruscag !. Thanks for the suggestions. . 1) That's a good point. I will change the option names to be more specific. . 2) Not a 100% certain what you mean by this. To be clear, instead of allocating memory using the keyword new (MeanReynoldsStress = new su2double* [3];), I should be declaring them statically (su2double MeanReynoldsStress[3][3])? I was following the variable declaration norms I saw in the code. But I guess those were usually for allocations to nDim. Is that what you are suggesting?. 3) I have generalized the Eigen-value functions to n order matrices now. But I think I am going to keep them in the numerics class. Since it seems like that is where they would be most useful. Would you suggest otherwise?. Cheers,",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/570#issuecomment-433784029:178,clear,clear,178,https://su2code.github.io,https://github.com/su2code/SU2/pull/570#issuecomment-433784029,1,['clear'],['clear']
Usability,"Hey @timjim333 that's nice to hear,. I would put it in the .bashrc if you consistently call SU2 with your command, like that you can always switch the SU2-build and still have your clear settings already in place. Image having the master, develop and feature_whatever installed, you don't need to apply your patch to all of these versions if you put it in the bashrc.; But editing interface.py has the same effect, so its up to you what you prefer. Tobi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/526#issuecomment-429668015:181,clear,clear,181,https://su2code.github.io,https://github.com/su2code/SU2/issues/526#issuecomment-429668015,1,['clear'],['clear']
Usability,"Hey,. @cvencro and I were discussing this issue quite a bit this morning and here an attempt of a summary:. We are looking at the following cases:; 1. 3D Onera m6, compressible euler, including euler_wall and sym_plane ; a. steady state; b. unsteady (no pitching, deforming); 2. 2D NACA64A010, compressible euler, including euler_wall; a. unsteady (no pitching/ deformation); b. pitching (with rigid and with deforming mesh -> used for the gradient validation of @cvencro 's post ). We are rather certain that the differences between the code-versions are due to the new euler_wall boundary which was introduced in #740 (by me :) ). @cvencro did a test where the old euler_wall was simply pasted into the newer function body (which currently directly calls the sym_plane boundary) -> that recovered the results obtained with the 'older' version. The steady state results (onera m6) show that both codes deliver the same results (of course with some minor differences). So far so good. Unsteady cases are a bit trickier: the latest 2D results of @RoccoBombardieri show pretty much no difference including the first timesteps. The onera m6 case in contrast converges to the same (steady-state) results for both code version eventually but their initial transient phase differs quite significantly. . A possible explanation for the different initial transient phase: In both implementations a ""reflected state"" is constructed where the normal component of the velocity is subtracted [once in the older code version & twice in the newer version]. I.e. subtracting the normal component of velocity twice means mirroring the velocity along the symmetry plane. The newer code version is a bit ""stronger"" in enforcing the boundary conditions which could lead to the reduced oscillation in CD and CL. If we agree that both code versions produce physically correct results for steady cases and unsteady cases that were integrated long enough in time to get rid of the influence of the initial condition ... then",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/828#issuecomment-563314747:682,simpl,simply,682,https://su2code.github.io,https://github.com/su2code/SU2/issues/828#issuecomment-563314747,1,['simpl'],['simply']
Usability,"Hi @Eduardo-Carvalho ,. your request is now merged into the develop branch and you can test/use it if you like. It will be in one of the next releases, if no further issues occur.; Handling is intuitive: Just set your restart iteration in the config file as you would do normally and activate the restart solution option. Furthermore, place your restart file (two in the case of 2nd order time integration) in the same directory as the config file of your test case. Then you are set up and can run the scripts as normal. ; For more details, I refer to pull request #964. . Best; Steffen",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/909#issuecomment-630289600:193,intuit,intuitive,193,https://su2code.github.io,https://github.com/su2code/SU2/issues/909#issuecomment-630289600,1,['intuit'],['intuitive']
Usability,"Hi @EduardoMolina . I will add this in the test repo. It is a standard case used in majority of the papers (relevant).; What are the changes/additions I need to carry out , can you guide me with the procedure of adding the test case in repo. Regards; Amit",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/631#issuecomment-455009027:181,guid,guide,181,https://su2code.github.io,https://github.com/su2code/SU2/pull/631#issuecomment-455009027,1,['guid'],['guide']
Usability,"Hi @EduardoMolina,. That is something I am also interested in as for some of my structural cases the current linear solvers simply do not converge. However Eigen is not the tool for that as the sparse linear solvers it has are similar and are not distributed parallel.; When I opened this issue I was thinking exclusively about how we handle small-medium dense matrices that live on a single rank, and associated algorithms (the kind used for RBF interpolation for example).; I think the two issues are fairly orthogonal, so we can open another to discuss large solvers, for which related work has already been started. Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/643#issuecomment-460666656:124,simpl,simply,124,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-460666656,1,['simpl'],['simply']
Usability,"Hi @Nicola-Fonzi,. I'm not 100% sure of the reasons behind the GetFSI_Simulation criteria. I'd imagine that the nMarker_Fluid_Load might have been included there to make sure that a problem is treated as FSI only if there is transfer of load from the fluid to the structural domain, even if both zones existed independently in the config. But since the GetFSI_Simulation check is set up as an ""or"" rather than ""and"", as long as one of them is satisfied, the logic will be true for an FSI simulation, which might be sufficient for your application?. For the velocity transfer, I agree with Rafa that it would be better if you could also transfer the velocity from the external structural solver. If an external structural solver is used for dynamic analysis, it probably can output the structural velocities as well as the structural displacements? I left the methods for the recalculation of the grid velocity using finite differences in the code to support fluid-only problems with dynamic grid motion, I wouldn't suggest this as the method for FSI problems. For primal analysis, results from both methods agree with FSI benchmark cases but if you are interested in adjoint analysis at any point, transferring the velocity information from the structural domain directly to the fluid domain gives a significant simplification and improvement to the gradients.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1174#issuecomment-778368854:1312,simpl,simplification,1312,https://su2code.github.io,https://github.com/su2code/SU2/pull/1174#issuecomment-778368854,1,['simpl'],['simplification']
Usability,Hi @TobiKattmann . I am OK if we clearly explain the changes in the config template as my main concern is with the users side.; Thanks!. Eduardo,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/735#issuecomment-513959331:33,clear,clearly,33,https://su2code.github.io,https://github.com/su2code/SU2/issues/735#issuecomment-513959331,1,['clear'],['clearly']
Usability,"Hi @antares190,. Glad to see that things seem to be starting to work for you. We (Brian) are trying to improve this capability in the solver and any experiences / suggestions / help will be welcome. With that said, this seems like an interesting result. Would you mind submitting it (or other pictures that you like better) so the SU2 Foundation can use it to show this capability to others in the future? The link where you can do this is here<http://su2foundation.org/su2-promotional-material/?utm_source=hs_email&utm_medium=email&utm_content=76584389&_hsenc=p2ANqtz-9fEq2awKk2vd155cCcN_N4mWBCZK-rJ-TqNsZhqSJs-VWn-w7q-H6w8sdiA3LyuOTqlK4eqZhFFstKi-LQFyyGqYPdkwYc9JsNdB1yyd7pqMwTFzA&_hsmi=76584389>. Thanks a lot,. Juan. On Apr 29, 2020, at 1:38 PM, antares190 <notifications@github.com<mailto:notifications@github.com>> wrote:. Thanks Brian,; my bad, I misinterpreted the carpets / logs structure. I successfully ran a test of a very simple case. In the results there are some small artifacts, but the shocks are resolution improved consistently after mesh adaption.; Thanks for the support. [Comparison]<https://user-images.githubusercontent.com/41752169/80644172-84a7a580-8a69-11ea-9f16-58e98c808b73.png>; [ComparisonMesh]<https://user-images.githubusercontent.com/41752169/80644174-85403c00-8a69-11ea-819f-2ac00550a089.png>. —; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/948#issuecomment-621450497>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AA5FFRCGLBHJCB3FS4JSSV3RPCF5RANCNFSM4MQACOXA>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/948#issuecomment-621483859:935,simpl,simple,935,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-621483859,1,['simpl'],['simple']
Usability,"Hi @bmunguia ,; I was in the same situation as @MiracAydin1, so thanks for the hint. Nevertheless I'm having some problems. I followed your instructions to install the branch:. 1. downloaded the [feature_adapt_sst](https://github.com/su2code/SU2/tree/feature_adap_sst) branch.; 2. Used meson to configure the build; `./meson.py build -Denable-autodiff=true -Denable-directdiff=true`; 3. Added the environment variables to the .bashrc; 4. ninja build.; `./ninja -C build install`. The build didn't show any errors, only few warnings during meson ( `gcc1: warning: command line option ‘-Wno-non-virtual-dtor’ is valid for C++/ObjC++ but not for C`). When I try to run the mesh_adaption (or even run simply the solver through parallel_computation.py):. `$SU2_RUN/mesh_adaptation_amg.py -f invCyl.cfg -n 6`. It immediately shows an error (without even showing the SU2 splash screen) :; `Traceback (most recent call last):`; ` File ""/usr/local/bin/mesh_adaptation_amg.py"", line 38, in <module>`; ` import SU2`; ` File ""/usr/local/bin/SU2/__init__.py"", line 14, in <module>`; ` from SU2 import amginria`; ` File ""/usr/local/bin/SU2/amginria/__init__.py"", line 4, in <module>`; ` from .interface import *`; ` File ""/usr/local/bin/SU2/amginria/interface.py"", line 41, in <module>`; ` import _amgio as amgio`; `ImportError: No module named _amgio`. Am I missing any dependencies? ; Please note that I previously compiled SU2 master branch without issues, and have already installed mpich, numpy, scipy.; Any help would be really appreciated.; Thanks",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/948#issuecomment-619332650:697,simpl,simply,697,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-619332650,1,['simpl'],['simply']
Usability,"Hi @clarkpede ,. Thanks for the contribution. The example of the central/upwind blending is very clear. Ready to merge. Eduardo",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/850#issuecomment-620948043:97,clear,clear,97,https://su2code.github.io,https://github.com/su2code/SU2/pull/850#issuecomment-620948043,1,['clear'],['clear']
Usability,Hi @clarkpede and @economon .; Thanks for the clear explanation.; Merging now. Eduardo,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/649#issuecomment-463729246:46,clear,clear,46,https://su2code.github.io,https://github.com/su2code/SU2/pull/649#issuecomment-463729246,1,['clear'],['clear']
Usability,"Hi @cvencro , I think it would be good to add that Testcase to the regression tests to 'guard' the code. ; I actually wanted to do that real quick but it guess that with `SINGLEZONE_DRIVER` one cannot access `TIME_ITER`, only `EXT_ITER` with the` .test_iter` variable of the python Testcase class. Not sure if that is addressed in #724 , maybe @rsanfer or @talbring can give a quick info as this is probably affecting all unsteady regression tests. . Concerning the Testcase repo: You can simply open a PR for the develop branch of the Testcase repo, and refer to the corresponding PR here (and vice versa). As far as I know the Testcase repo is not protected, i.e. you can merge without any check. And as it is just one added mesh and no other change you could do it right now from my point of view. Another point: What about the rotating_frame for incompressible flow? If it is untested I would like an error catch in place that this feature can't be used out of the box.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/767#issuecomment-527167827:489,simpl,simply,489,https://su2code.github.io,https://github.com/su2code/SU2/pull/767#issuecomment-527167827,1,['simpl'],['simply']
Usability,"Hi @koodlyakshay thanks for making the changes.; By default MPI barriers are ""never"" needed, the normal communication routines already do all synchronization required. Efficiency is probably not fundamental for that routine but this solution feels too complicated somehow, can you attend tomorrow's developers meeting? (I'm getting the ""there's gotta be a simpler way"" feeling, and if we pick the brains of a few people we are certain to find it). In the meantime, if you specify the roughness as a string+double list (exactly like MARKER_HEATFLUX), which is read with `addStringDoubleListOption` you could probably simplify the logic around heatflux and isothermal markers, which would make the setup more user friendly (having to stick with an order is bound to trip someone at some point).; Also the cht interface is ""just"" an isothermal boundary, any reason not to make this feature available for that?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/877#issuecomment-630788337:356,simpl,simpler,356,https://su2code.github.io,https://github.com/su2code/SU2/pull/877#issuecomment-630788337,2,['simpl'],"['simpler', 'simplify']"
Usability,"Hi @pcarruscag I just tried a simpler mesh and using MPI I get the UCX crash.; [err_log_SU2v7.0.3.txt](https://github.com/su2code/SU2/files/5810207/err_log_SU2v7.0.3.txt). To double check, I also used the master v7.0.8 SU2_CFD. When I run with MPI, I get the UCX error but when I run in serial, the solution appears to converge fine. I suspect that this means it's probably not the mesh that is causing the issues - what are your thoughts?; [su2_out_serial.txt](https://github.com/su2code/SU2/files/5810208/su2_out_serial.txt)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1156#issuecomment-759607361:30,simpl,simpler,30,https://su2code.github.io,https://github.com/su2code/SU2/issues/1156#issuecomment-759607361,1,['simpl'],['simpler']
Usability,"Hi @pcarruscag and @aeroamit ,. Thanks for the discussion and for share the ideas/results. I think this is the beauty of open-source, everyone is welcome to jump in and review all the pull requests. Certainly, as you said @aeroamit, we will all learn something fruitful when we review and merge each PR. Best regards,. Eduardo",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/691#issuecomment-511209774:245,learn,learn,245,https://su2code.github.io,https://github.com/su2code/SU2/pull/691#issuecomment-511209774,1,['learn'],['learn']
Usability,"Hi @pcarruscag and @vdweide ,. Thanks for creating a test branch and for bringing this discussion. When Brian (@bmunguia ) and I mentioned PETSc, it was an idea to try a different Newton-Krylov (with preconditioner) library in order to improve the convergence of SU2. ; Since the slow convergence of the SU2-FV is the main feedback that I received from other users from industry and academia, I think it worth try an external library and evaluate the performance. ; I will be happy to help test Eigen and see if it is a good candidate. Best,; Eduardo",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/643#issuecomment-460479862:323,feedback,feedback,323,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-460479862,1,['feedback'],['feedback']
Usability,"Hi @pcarruscag, just a small follow-up to my comment in the code section concerning the new adjoint implementation that might also help here (either by using it directly or just for getting some ideas). What I would like to change is in fact not the `CDiscAdjSolver` (which I find is very good) - but I'd like to propose some changes for the *interface* to the AD tool. And some subsequent stuff.; It will allow for a more direct control of derivatives which is favourable in case one deals with multiple zones, multiple sets of conservative variables, geometry coordinates in case of FSI, and so on. And of course in terms of performance as one needs only one tape that one can keep during all iterations, regardless of what their variables might be. In case you are interested, take a look at the implementation in [su2code:sc_develop](https://github.com/su2code/SU2/tree/sc_develop). I'll open the PR as soon as @talbring opened his one for his great rework on input/ouput. As for this PR, let me wait a second if we can clear up the issue concerning the registration and I'll leave a small review afterwards.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/615#issuecomment-457582842:1024,clear,clear,1024,https://su2code.github.io,https://github.com/su2code/SU2/pull/615#issuecomment-457582842,1,['clear'],['clear']
Usability,"Hi @pcarruscag,; You are right, it shares a lot of code with previous PR. Here constants does not change. Differences are as follows - . 1- It has different pressure flux definition (new expression); 2 - Here sum of squares of velocity components were needed for left and right state; 3- removed few variables and added few.; 4- Also left and right state split Mach numbers are Mach number polynomials only (for programming purpose) without pressure terms. Previously SLAU and SLAU2 scheme have already been implemented in the code separately. I mean some of these sucessive schemes share a lot of common formulation but differ with some expressions, constants etc. ; So it may be fine to keep them separate. . I will see your advice and further look into similar variation implementation in the code (sorry if I missed out some simple point you mentioned). . Thanks ; Amit",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/631#issuecomment-446730390:829,simpl,simple,829,https://su2code.github.io,https://github.com/su2code/SU2/pull/631#issuecomment-446730390,1,['simpl'],['simple']
Usability,"Hi @pcarruscag,; thank you very much for the insight and the well thought proposed solution. I wasn't aware that there was such a loss in performance, it seems clear that something needs to be done. The only question I have is regarding the following comment . > There are no free lunches and this performance improvement would come at the cost of losing the ability to have different types of variables in different parts of the domain. I'm using this feature more and more, I was planning to extend it in the structural solver to remove the `if fsi` statements, and I also used it in the rework of the mesh solver, as defining variables at the interface only reduces greatly the memory footprint (sort of like the node-vertex structures in geometry). You mention there are options to keep this versatility, how difficult do you think would be to implement them?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/716#issuecomment-507998889:160,clear,clear,160,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-507998889,1,['clear'],['clear']
Usability,"Hi @rois1995 . For now, I'm ignoring all TKE in Total Energy in personal research. I don't remember the details clearly. ; The problem was that the enthalpy added TKE was stored in the primitive variables. ; When I tried to fix it, the problem was when the enthalpy added TKE was stored in the primitive variables. For the Roe scheme in convective flux calculations (not sure about other flux scheme), the Roe speed of sound is calculated using enthalpy. But as I mentioned above, the stored enthalpy is higher than other simulation because of TKE. I thought it make a problem.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1851#issuecomment-2245163889:112,clear,clearly,112,https://su2code.github.io,https://github.com/su2code/SU2/issues/1851#issuecomment-2245163889,1,['clear'],['clearly']
Usability,"Hi @rois1995. The LM model code under the development clearly has some problems. I've not finished yet all validation cases for commonly used. So, I can't help with the E387 profile problem. but, I think I can give some helpful comments. . Check the numerical scheme which you used. like Roe and L2Roe, AUSM and SLAU. In my case, I didn't think to use the low dissipation scheme because I thought the code was wrong. I upload the configure file for the T3A flat plate case, which I used.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1592#issuecomment-1111261534:54,clear,clearly,54,https://su2code.github.io,https://github.com/su2code/SU2/pull/1592#issuecomment-1111261534,1,['clear'],['clearly']
Usability,Hi @simonvanderveldt. Thanks for the questions. The custom meson.py script shipped with su2 also initializes the git submodules. You can of course also use an installed version of meson/ninja for building (should be also noted in the documentation on the website) by simply replacing `./meson.py` with `meson`.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/911#issuecomment-598496636:267,simpl,simply,267,https://su2code.github.io,https://github.com/su2code/SU2/issues/911#issuecomment-598496636,1,['simpl'],['simply']
Usability,"Hi @talbring, I cannot agree more with you, . @JSmith36 has introduced too many changes in one pull request which has, as you pointed out, some important problems. On the other hand, @JSmith36 situation is not so strange. It is quite common to find contributors who are working on their own branch for a long time and at a certain point decide to contribute (which is very generous of them). My suggestion is the following... let's keep the pull request open (we don't want to lose this contribution) and meanwhile, @JSmith36 why don't you create pull request with the most-easy to- divide parts of your contribution. e.g. Let's start with ; ""Renaming of the keywords REF_LENGTH_MOMENT (the word MOMENT was really confusing) or RefAreaCoeff."". That is easy to reimplement and it will simplify the main pull request. For the future, please, let's all of us to keep the contributions the most simple and modular as possible. Thank you very much to each of you who contribute to this great community and great code!. Best,; Francisco",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/412#issuecomment-315563582:784,simpl,simplify,784,https://su2code.github.io,https://github.com/su2code/SU2/pull/412#issuecomment-315563582,2,['simpl'],"['simple', 'simplify']"
Usability,"Hi @talbring,; thanks for this, I think it makes the output a lot clearer. ; We should merge this in soon, and open a discussion on how to improve the screen output, not only in terms of the residual convergence (I know you have been working hard on that and it's looking great) but also on the initial print-out, which is currently very chunky and not so easy to add new options to.; Ruben",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/633#issuecomment-455978636:66,clear,clearer,66,https://su2code.github.io,https://github.com/su2code/SU2/pull/633#issuecomment-455978636,1,['clear'],['clearer']
Usability,"Hi @themrdjj,; Thank you for the feedback, there was already a similar report in #796 (which incidentally went stale and was closed), I will try to do something about it, or if you would like to contribute code to the project I can point you to right place to add an error message. Meanwhile my best advice is to not start a config from scratch until you know SU2 very well (and even then...) look for a test case that uses similar features and go from there.; The minimal config is the one in Quickstart, the template is more of a catalog :) I don't think we'll ever have a unified minimal config, SU2 does many things, some mutually exclusive.; Convective options are reasonably well documented here: https://su2code.github.io/docs_v7/Convective-Schemes/; The output messages before ""Begin Solver"" can be helpful (although in this particular case you would need to know what to expect). Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/842#issuecomment-566642727:33,feedback,feedback,33,https://su2code.github.io,https://github.com/su2code/SU2/issues/842#issuecomment-566642727,1,['feedback'],['feedback']
Usability,"Hi @timjim333 ,. Exactly (concerning your first question). . For the %s : In your initial post you stated that `mpirun --use-hwthread-cpus -np 12 SU2_CFD turb_ONERAM6.cfg` worked for you. So %s is simply the place-holder for the SU2 module together with the configure script. Which in your case would be `SU2_CFD turb_ONERAM6.cfg` . But `parallel_computation.py` will also call `SU2_SOL turb_ONERAM6.cfg` for you after the solver routine to create output files for visualization. ; If you take a look into the `interface.py` (as in my previous post) and the `parallel_computation.py` you'll find exactly how its done. Cheers, Tobi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/526#issuecomment-395712721:197,simpl,simply,197,https://su2code.github.io,https://github.com/su2code/SU2/issues/526#issuecomment-395712721,1,['simpl'],['simply']
Usability,"Hi Akshay,. Yes this is a simple fix and it could go in quickly on it's own or as part of another PR. I have this fix already modified in the draft PR #833 which is just pending the addition of a test case. I can add that and move to a PR soon if you are happy to wait?. Best wishes,; Charanya",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/860#issuecomment-582340873:26,simpl,simple,26,https://su2code.github.io,https://github.com/su2code/SU2/issues/860#issuecomment-582340873,1,['simpl'],['simple']
Usability,"Hi All,. We are lucky, Florian Menter just replied to me. He agreed that the factor (1-F1) should activate the CD term only at the ""k-epsilon"" branch, where the CD term is already positive.; Therefore, clipping with zero is in terms of the model and is not incorrect. Me: A simple boundary layer simulation will reveal that the CD term switch sign is inside the boundary layer and that the F1 function switches from 1 to zero outside the boundary layer. Namely, the CD term should be positive. Florian is unaware of the occasions when it may be negative (even though the model was designed so that this term will be activated when it is positive). . Best wishes,; Yair",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/2329#issuecomment-2256154395:274,simpl,simple,274,https://su2code.github.io,https://github.com/su2code/SU2/pull/2329#issuecomment-2256154395,1,['simpl'],['simple']
Usability,"Hi Amir,; If you create a solver object inside numerics how will this new solver know about the solver that is actually using numerics? The way the code is written does not make the relations between classes very clear as the solver and numerics containers get passed around quite freely... But the solvers are clients of the numerics (I think there are good diagrams of this in some of the papers), i.e. the solvers call methods of the numerics and not the other way around.; It is the numerics that needs a method whereby the solver can set the value of cb1, this is more or less what is done in the elasticity solver, so yes, try to follow that ""recipe"" as close as possible and it should work.; Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/679#issuecomment-494118969:213,clear,clear,213,https://su2code.github.io,https://github.com/su2code/SU2/issues/679#issuecomment-494118969,1,['clear'],['clear']
Usability,"Hi Amit,; That is also my intuition, I guess the only way to know if it is worth the extra cost is by doing.; Do you have a good supersonic case I can use for testing (all my work is subsonic)? Preferably something that converges well without initialization.; Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/691#issuecomment-499876619:26,intuit,intuition,26,https://su2code.github.io,https://github.com/su2code/SU2/pull/691#issuecomment-499876619,1,['intuit'],['intuition']
Usability,"Hi Economon,. I encountered an issue very similar to what Auzbaig reported: the error message ""OBJECTIVE_FUNCTION: invalid option value EntropyGeneration"" during optimization with SU2. (I am using SU2 version 8.0.1 ""Harrier.""). After thoroughly examining the existing Python optimization framework, I found that one of the steps in the optimization chain is generating different config.cfg files, with a focus on DV_VALUE and OBJECTIVE_FUNCTION. DV_VALUE controls the geometry deformation;; OBJECTIVE_FUNCTION determines the type of objective/constraints.; Then the framework calls SU2_CFD and SU2_DOT to obtain performance metrics or gradient information.; As you mentioned, ""You might need to run updateHistoryMap.py to register new outputs with Python."" Initially, I thought it meant simply providing a new input for OBJECTIVE_FUNCTION in the Python optimization framework. However, it seems that this may not work at the C++ level. To verify this, I ran $ SU2_CFD your_config.cfg -d and observed all available history outputs. However, I suspect that OBJECTIVE_FUNCTION cannot use every history output, meaning that the adjoint solver might not recognize some objective functions. Does this imply that additional modifications in the C++ code are required?. Additionally, I would appreciate more information regarding CUSTOM_OBJFUNC. From TestCases/user_defined_functions/lam_flatplate.cfg, I understand that CUSTOM_OBJFUNC allows combinations of existing OBJECTIVE_FUNCTIONs and can also utilize CUSTOM_OUTPUTS. The flexibility of CUSTOM_OUTPUTS seems to enable the construction of various desired variables. However, I am unsure whether using OBJECTIVE_FUNCTION= CUSTOM_OBJFUNC along with CUSTOM_OUTPUTS can entirely replace the need for additional modifications in the C++ code. Since I’m not very proficient in C++, I would greatly appreciate your guidance. Sincerely,; Tongtong",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/889#issuecomment-2324575133:787,simpl,simply,787,https://su2code.github.io,https://github.com/su2code/SU2/issues/889#issuecomment-2324575133,2,"['guid', 'simpl']","['guidance', 'simply']"
Usability,"Hi Eduardo,. both, 'symmetry plane' and 'symmetry as the slip wall' should work in the code (upon fixing this) and it should be made clear (e.g. in the config_template.cfg) what the BC is suitable for, independent of how it is named in the end. ; The simplest solution is probably the patch I provided together with a short note in the config_template (maybe even a reference to this issue), as both 'options' will work as expected (using the very same code). It will basically 'restore' the behaviour of MARKER_SYM of before the fix in #657. The downside is some more computational cost (in case of a plane) which has to be done for each vertex on the marker. I cant say to which extend this takes more time but I would guess it is not too costly. Depends on the case as well. I can do a little check with your case here. . That's it for the diplomatic part :) (Please take the following with a grain). For me a symmetry has to be a line or plane. To cite Jiri Blazek's book 'Computational Fluid Dynamics'(...) 3rd edition using a screenshot:. ![blazekbook](https://user-images.githubusercontent.com/31306376/61662377-9ab05a80-acce-11e9-85bf-5998db204d92.png). The chapter is called 'symmetry plane' which already is kinda biased. But there is no 'slip wall for viscous flow' mentioned to my knowledge. In another book (from Ferziger&Peric, which I only have in german) symmetry is only used in the context of symmetry planes as well. ; To me, symmetry BC's are also linked to visualization using mirroring. And mirroring (as the word is commonly meant) is only possible along planes and its little brother, the straight line. I can be wrong or it might be a question of research background. So how to proceed? Trial by combat might have some unpleasant aftermath for the winner so we might go the democratic way and do a poll :) . Cheers, ; Tobi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/735#issuecomment-513957018:133,clear,clear,133,https://su2code.github.io,https://github.com/su2code/SU2/issues/735#issuecomment-513957018,2,"['clear', 'simpl']","['clear', 'simplest']"
Usability,"Hi Giulio,; Thank you for the feedback. I inherited some of this code from a previous student of my PhD supervisor and I thought the same when I saw the CSymmetricMatrix class. However, as I understand it, CSysMatrix implements a block sparse format and here we have a simpler dense format. Another big difference is that CSymmetricMatrix does not need to be used in parallel. But I agree that making these two classes related somehow would be better, so I am open to suggestions.; Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/555#issuecomment-406516746:30,feedback,feedback,30,https://su2code.github.io,https://github.com/su2code/SU2/pull/555#issuecomment-406516746,2,"['feedback', 'simpl']","['feedback', 'simpler']"
Usability,"Hi Heather, I think we are getting closer. Something that is not clear for me is why we can only combine objective functions with the continuous adjoint. In principle, it is ""easier"" to combine objective functions with he discrete adjoint. Isn't it? Is there a particular reason for not combining the objective functions with he discrete adjoint? Thanks! Francisco",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/385#issuecomment-296408505:65,clear,clear,65,https://su2code.github.io,https://github.com/su2code/SU2/pull/385#issuecomment-296408505,1,['clear'],['clear']
Usability,"Hi JSmith86,. I really appreciate your effort in cleaning up the changes. But it looks like as if there are still a lot of changes in other parts that are not related to the things you describe. Furthermore I really request you to split this up in multiple commits so that it is immediately clear what you did in each single one (this can be done quite simple with a proper diff tool like [meld](http://meldmerge.org/)). Let me emphasize that this is not to bother you in any way but rather to ease understanding and maintainability. I know from my own experience that this requires some additional work, but in the end it certainly pays off. . Thanks!; Tim",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/412#issuecomment-315320576:291,clear,clear,291,https://su2code.github.io,https://github.com/su2code/SU2/pull/412#issuecomment-315320576,2,"['clear', 'simpl']","['clear', 'simple']"
Usability,"Hi Jairo, . what is the status here ? Is it possible to provide a simpler (smaller) case ?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/600#issuecomment-445175541:66,simpl,simpler,66,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-445175541,1,['simpl'],['simpler']
Usability,"Hi Jean,; Sorry for the delay. The hypothesis I have for the less robust behavior of periodic BC's is that the linear solver is not completely aware of the periodicity. In fact after the linear solve we have to force the matching nodes to have the same value.; This is done in CFVMFlowSolverBase.hpp::CompleteImplicitIteration_impl, in the call to InitiatePeriodicComms.; The idea is to make the linear solver aware of the periodicity, to do so would require including periodic communications in the preconditioners and the matrix-vector product.; These are all in CSysMatrix.cpp, so before each of the `/*--- MPI Parallelization ---*/` bits we would need periodic comms, for preconditioners these comms would simply make the values equal, like in CSolver::InitiatePeriodicComms(PERIODIC_IMPLICIT) whereas for the matrix-vector product we need to add the values (effectively periodicity splits a row of the matrix into two ""half rows"") and this would be similar to what is done with the linear residual in CSolver::InitiatePeriodicComms(PERIODIC_RESIDUAL).; I think @TobiKattmann was also interested in having a look into this.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1467#issuecomment-1017640248:710,simpl,simply,710,https://su2code.github.io,https://github.com/su2code/SU2/issues/1467#issuecomment-1017640248,1,['simpl'],['simply']
Usability,"Hi Josip,. in the current develop/master these features are still included. However, the plan is to remove these. The reason is simply because of maintenance. We have nobody that can spare time to test the current implementation. If you are willing to do this, please let use know. Tim",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/348#issuecomment-268010192:128,simpl,simply,128,https://su2code.github.io,https://github.com/su2code/SU2/issues/348#issuecomment-268010192,1,['simpl'],['simply']
Usability,"Hi Pedro, ; As discussed last week, I now translate and rotate the whole aircraft in the elastic mesh in combination with a farfield onflow. Implementing and doing the coordinate transformations right took me a few hours, but now everything seems to work properly and fast :). 1. Currently, activating the gust resets/overwrites the grid velocities due to the deformed mesh, but I haven't found the place yet. Any ideas?. 2. Should I clean up / remove the split velocity approach as described in the first post or would you like to keep it?. 4. How to handle the new approach, should I close this pull request and open a new one? There are a few commits which I needed to undo. 5. Generally, I still need the rotating frame approach for steady maneuver load cases, e.g. to calculate the pitching, rolling or yawing aircraft in a steady simulation. The acceleration terms are zero in this case, but I understood that the Coriolis-Term with omega x velocity is missing. Is that correct? I guess they are probably important for objects like a propeller which spins at a couple of thousand RPMs but maybe it is justified to neglect them for slow objects?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1954#issuecomment-1505397240:672,undo,undo,672,https://su2code.github.io,https://github.com/su2code/SU2/pull/1954#issuecomment-1505397240,1,['undo'],['undo']
Usability,"Hi Pedro, ; I'm slightly confused right now and not sure if I'm able to do the necessary modifications. I understand that it is unlikely someone else might implement this but I think that this is beyond my abilities right now. If you don't mind, do you have some time to talk through my options in a video call? I hope that will help me to get a clearer picture. Next week, I'm generally available except for Monday, which is a public holiday here. Germany is 9 hours in advance of California, so your morning / my evening might work?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1954#issuecomment-1497398492:346,clear,clearer,346,https://su2code.github.io,https://github.com/su2code/SU2/pull/1954#issuecomment-1497398492,1,['clear'],['clearer']
Usability,"Hi Pedro, thanks for looking into this more. I had run into inconsistencies for FSI problems with relaxation which was the reason for the domain specific calls coming into the multizone driver Update function. With the changes I introduced, the velocity at the interface was being transferred correctly with and without relaxation, so I left it there but it is a bit messy. I'll test with the modified calls for the Relaxation as you suggest. I completely agree that if we can simplify the velocity transfer by just using the velocity directly, then we should. Especially since the predicted velocity is only zero order anyway.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1174#issuecomment-774993325:477,simpl,simplify,477,https://su2code.github.io,https://github.com/su2code/SU2/pull/1174#issuecomment-774993325,1,['simpl'],['simplify']
Usability,"Hi Pedro, thanks for the idea to update the windowing directly! I've updated addValue such that the values are added for new time only (replaces existing values if it is still the same time iteration). This is a lot simpler and very happy to remove the convoluted logic. The SetUpdate_Averages was still necessary though to pass the regression test for unsteady_cylinder_windowed_average.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1259#issuecomment-819111992:216,simpl,simpler,216,https://su2code.github.io,https://github.com/su2code/SU2/pull/1259#issuecomment-819111992,1,['simpl'],['simpler']
Usability,"Hi Pedro,. I can confirm that everything is now working correctly. I have tested the sensitivities against gradients from finite difference runs and the results match very closely.; I owe you a big thank you for your help with this, not only has my problem been solved but you also helped me learn a great deal about how the code works. Really appreciate it.; If we ever meet one day then drinks are on me :); Cheers,; Amir",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/679#issuecomment-500911599:292,learn,learn,292,https://su2code.github.io,https://github.com/su2code/SU2/issues/679#issuecomment-500911599,1,['learn'],['learn']
Usability,"Hi Pedro,. It is indeed a good idea to keep similar schemes (with minor variations) under one umbrella, especially central scheme as only the dissipation term calculation differs. . - In case of AUSM+-up1/2 and SLAU1/2, each can be reduced by having a separate pressure flux definition. - But if we try to combine AUSM+-up and SLAU, will it be a clear/helpful implementation as mass flux definitions/calculations (which is substantial portion) are different (unlike the central scheme, where only dissipation term varies)?. - Also could you please shed some light on Jacobian part for these schemes (as you mentioned - “...Isolating the computation of mass and pressure fluxes could be an interesting way to compute the Jacobians of these schemes in a hybrid way ...”). Best; Amit",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/691#issuecomment-499205201:346,clear,clear,346,https://su2code.github.io,https://github.com/su2code/SU2/pull/691#issuecomment-499205201,1,['clear'],['clear']
Usability,"Hi Ruben,. Thank you for your feedback !. It is hard to tell what to do you to avoid conflicts. Anyway, the most significant part of the changes concerns the parent CDriver class, especially the constructor and some new functions that are pieces of code coming from the main function (like Output and Monitor). So if the contributions are focused on one particular driver (single, multi, ...) and if they are more or less compatible with the main ""driver->run"" then ""driver->update"" structure, it should be straightforward to solve the potential confilcts. Best,. David",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/295#issuecomment-237702911:30,feedback,feedback,30,https://su2code.github.io,https://github.com/su2code/SU2/pull/295#issuecomment-237702911,1,['feedback'],['feedback']
Usability,"Hi Soumen,. As Tom said, the routines are all in place and I have been putting them; together for solution interpolation from one mesh to another for unsteady; simulation as post-processing step. So probing at a particular location for; unsteady solution can be also done with this framework. The probe search; implementation is in place for 2D configuration currently. It will be; extended to 3D and probably available in the main branch in the next 2; months.; The implementation so far is in feature_MeshInterpolation branch if you; want to take a look. Sravya. On Thu, Nov 2, 2017 at 10:09 PM, Thomas D. Economon <; notifications@github.com> wrote:. > Hi Soumen: yes, this is something that the developers are actively working; > on at the moment (in particular, @sravya91 <https://github.com/sravya91>; > has been taking the lead on this). It is true that most of the ingredients; > are already available in SU2 (fast searches, interpolation routines, etc.),; > but the trick is combining them all and making it general.; >; > Do you have any other requirements beyond simple probes? I am guessing we; > should have something available in the next few months, but it's not set; > yet.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/issues/466#issuecomment-341623660>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/AHenII5B0Xtb2U_hj2vbBesf5Oc51uvzks5syqAEgaJpZM4QPYh8>; > .; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/466#issuecomment-342266341:1074,simpl,simple,1074,https://su2code.github.io,https://github.com/su2code/SU2/issues/466#issuecomment-342266341,1,['simpl'],['simple']
Usability,"Hi Soumen: yes, this is something that the developers are actively working on at the moment (in particular, @sravya91 has been taking the lead on this). It is true that most of the ingredients are already available in SU2 (fast searches, interpolation routines, etc.), but the trick is combining them all and making it general. Do you have any other requirements beyond simple probes? I am guessing we should have something available in the next few months, but it's not set yet.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/466#issuecomment-341623660:370,simpl,simple,370,https://su2code.github.io,https://github.com/su2code/SU2/issues/466#issuecomment-341623660,1,['simpl'],['simple']
Usability,"Hi Sun5k,; Thanks for tackling the Transition models. As far as I see, you are adopting the CScalarSolver-Base style just as is done for the Turbulence or SpeciesTransport solver (cf #1330 #1388 ) :+1: I think you can stay close to how things are handled in these solvers. The Turbulence solver has another class in the middle though: `CScalarSolver -> CTurbSolver -> CTurbSST/SASolver` I am not sure whether sth like this makes sense for transition models? (because I have no clue of Transition models). Otherwise the CSpeciesSolver is directly based on the CScalarSolver. Please limit this PR to 1 model only! So in this case just the LM model maybe. It is much easier for you to wrap this PR up with a limited scope instead of trying to do everything at once :) (and it is easier to review for everyone else) In case you then still want to tackle another one once LM is done :D then just open another PR :+1:; ; As unfinished Transition models (or models with a questionable state) are a bit of a companion of SU2 I would also ask you to provide a meaningful testcase with this PR that proves the usability of this feature. I personally like to think of a suitable case at the beginning of development, to adopt a bit a Test-Driven-Development approach but that is of course fully up to you. In case you did not know about the Developers meeting each Wednesday 4pm Berlin time, now you do. You are kindly invited to ask any questions, just show-and-tell to get some feedback etc. it is a very open round :). Happy coding, Tobi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1496#issuecomment-1016451577:1100,usab,usability,1100,https://su2code.github.io,https://github.com/su2code/SU2/pull/1496#issuecomment-1016451577,2,"['feedback', 'usab']","['feedback', 'usability']"
Usability,"Hi Tim, Heather: yes, this is an important issue to clear up before releasing v5 this week. Let's use this PR to fix the issue (even if just short term), and we'll find a better long term solution. I'm taking a look at this now too.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/352#issuecomment-271199146:52,clear,clear,52,https://su2code.github.io,https://github.com/su2code/SU2/pull/352#issuecomment-271199146,1,['clear'],['clear']
Usability,"Hi Tim,. Thanks!. I totally agree on the fact that Python-related functionalities could be in a separate file for code clarity. Anyway, considering only the C++ structure, those functionalities are still members of the CDriver (and all child classes). So if you are OK with the fact that having members of the same C++ class in different cpp files, I am OK too. . However, if you mean creating a new class for the Python wrapper (like CPyWrapper or whatever), and leave the CDriver ""clean"", this might be more tricky. Indeed, since the wrapper has to be a top-level class, it is better to have access to all the other main classes (config, geometry, solver, ...) and the CDriver was the perfect candidate (it instanciates all of them). So now if we create a new top-level class next to the CDriver, the direct link with all those classes is lost. Basically we will have to create accessors like CDriver::GetConfig(), CDriver::GetGeometry(), ... that will return the different containers to be used by the wrapper. Obviously this is possible but not in a short time, besides this might be a significant change in the top-level code structure. We could also think about exposing thoses CConfig, CGeometry, ... classes to Python in addition to just the driver, I already made some local tests and it worked great but this approach is less user-friendly. David",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/488#issuecomment-352045091:1336,user-friendly,user-friendly,1336,https://su2code.github.io,https://github.com/su2code/SU2/pull/488#issuecomment-352045091,1,['user-friendly'],['user-friendly']
Usability,"Hi Tom,. Sounds like a plan then to have a look at CIntegration to see what we can do to generalize the time integration. I definitely want to help with this, but I don't think I am the appropriate person to take the lead, because I simply don't have a good overview of all the multi-physics options. Tom, are you willing to take the lead for this?. Furthermore, it is good to have other people involved as well, preferably with detailed knowledge of the different disciplines. Any volunteers?. Thanks,. Edwin",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/437#issuecomment-329096830:233,simpl,simply,233,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-329096830,1,['simpl'],['simply']
Usability,"Hi Tom,; ; I would like to work on the ALE and rotating frame implementations for incompressible solver. Under Edwin's guidance I have been looking at SU2 closely over the past few months and, as you might have heard from him, we are looking to implement a pressure based scheme. . Also, could you tell me more about what are the changes you are planning for the incompressible solver? . Thanks a lot.; Regards,; Akshay",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/468#issuecomment-343086793:119,guid,guidance,119,https://su2code.github.io,https://github.com/su2code/SU2/issues/468#issuecomment-343086793,1,['guid'],['guidance']
Usability,"Hi Wally, ; I have run some axisymmetric cases earlier for pressure distribution (Cp) computation over typical payload fairing configuration (with older versions of SU2). Pressure distribution seemed to be fine with earlier runs (and also it matched well with other codes). ; Issue popped up while trying to compute heat flux for axisymmetric problems. I have seen folks and students running their cases with axisymmetric formulation. Now the issue has surfaced clearly, it need to be fixed asap.; How is solution of the case, you have been trying? . Best; Amit",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1063#issuecomment-699627809:462,clear,clearly,462,https://su2code.github.io,https://github.com/su2code/SU2/issues/1063#issuecomment-699627809,1,['clear'],['clearly']
Usability,"Hi all, . After the initial excitement of clearing all tabs and trailing whitespaces... I guess it is more reasonable to follow @pcarruscag proposal:; > What about running the solution you propose only on subfolders? i.e. on src/something/ . I now trimmed all `C*.cpp`, `C*.hpp` and `C*.inl` files in `SU2_CFD` which is equivalent to all restructured files in the Sub-folders. I added a basic script `replace-tabs-...sh ` in `externals/utils` which provides this functionality. I would enhance that script if this is the way to go.; The commit size now shrunk down to ~4k changed lines. Possible merge problems will be much smaller. . I found to have to no problem when merging the develop first -> clearing all tabs/whitespaces in the feature_branch with the provided script -> merge this develop_noWhitespaces using the `--strategy-option=ours` option. Merge conflicts will be purely due to tabs/whitespaces therefore one always wants the own code in case of conflict, as all conflicts with the develop related to other stuff were already resolved in the first merge. . Now that the commit is a lot smaller, there should be even less problems. Maybe some folks will have no problems at all. . After some back and forth in the commits I briefly chatted with @talbring to do a git rebase / squash to not have these huge commits in the history. Otherwise one could open a new & clean PR if we can agree on an approach here to keep the discussion in one place.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/808#issuecomment-553412130:42,clear,clearing,42,https://su2code.github.io,https://github.com/su2code/SU2/pull/808#issuecomment-553412130,2,['clear'],['clearing']
Usability,"Hi all, thank you so much for your feedback. Are there things left for this pull request? ; Thank you so much in advance.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1620#issuecomment-1150869650:35,feedback,feedback,35,https://su2code.github.io,https://github.com/su2code/SU2/pull/1620#issuecomment-1150869650,1,['feedback'],['feedback']
Usability,"Hi everyone, glad this subject is of interest. I will try to make that test case. I edit my earlier comment to avoid a mess. So I changed the terms. Still not sure but the derivation is simple. source term viscous = (0, tau_xy, tau_yy - tau_thetatheta, u* tau_yx + v* tau_yy - q)/y, right?. then from Bird:. ![IMG_20201027_115003](https://user-images.githubusercontent.com/55834287/97291927-d9767e00-184a-11eb-9418-a3ace3e3a077.jpg). bulk viscosity = 0, any derivative wrt theta = 0. For the generalised inviscid part I am pretty sure it is all correct including the jacobian. You can compare with very similar terms in any generalised flux jacobian like in Glaister's paper https://www.sciencedirect.com/science/article/pii/002199918890174X",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1095#issuecomment-713564781:186,simpl,simple,186,https://su2code.github.io,https://github.com/su2code/SU2/pull/1095#issuecomment-713564781,1,['simpl'],['simple']
Usability,"Hi everyone,; I was tring to use the mesh adaptation feature but the whole procedure is not clear to me.; Following the previous indications I:. 1. downloaded the `feature_adapt branch`. 2. downloaded the Adaptive 2D NACA 0012 example (https://pyamg.saclay.inria.fr/pyamgexamples.html#2dnaca): `adap_NACA0012.cfg`, `mesh_NACA0012_inv.su2`, `NACA0012_ini.dat`. 3. added the following lines to the config:; ```; % Type of sensor used for adaptation; % Options include GOAL (adjoint-based), MACH, PRES; PYADAP_SENSOR= GOAL; % Objective function used for goal-oriented adaptation; OBJECTIVE_FUNCTION= LIFT; % Maximum cell size for adaptation; PYADAP_HMAX= 500.0; % Minimum cell size for adaptation; PYADAP_HMIN= 1e-9; % Gradation factor (typically 1.2-1.8); PYADAP_HGRAD= 1.8; % Norm used for adaptation; % 1.0 or 2.0 recommended for inviscid flows; % 4.0 recommeneded for viscid; ADAP_NORM= 4.0; % Approximate mesh size (NPOI) at each level; PYADAP_COMPLEXITY= (30000, 60000, 120000); % Number of adaptations performed at each level; PYADAP_SUBITE= (3, 3, 3); ```. 4. run the following command: `$ python3 SU2_RUN/mesh_adaptation_amg.py -f adap_ONERAM6.cfg -n 8`. The response I have obtained is the following:; ```; SU2-AMG Anisotropic Mesh Adaptation. Mesh adaptation options:; PYADAP_COMPLEXITY : (30000, 60000, 120000); PYADAP_SUBITE : (2, 2, 2); PYADAP_SENSOR : MACH; PYADAP_HMAX : 500.0; PYADAP_HMIN : 1e-9; PYADAP_HGRAD : 1.8; PYADAP_FLOW_ITER : (2999, 4999, 6999); PYADAP_ADJ_ITER : (2999, 4999, 6999); PYADAP_CFL : (10.0, 15.0, 20.0); PYADAP_RDG : NO. The ./adap folder was deleted. Generating GMF background surface mesh.; ## WARNING: MISSING SU2 MESH FILE KEYWORD: NCORNERS=.; Initial CFD solution is provided.; ```. As expected, a `./ADAP` folder was created, containing these docs: `amg_back_meshb`, `config_CFD.cfd`, `log.err`, `log.out` (sizes 0 byte), `mesh_NACA0012_inv.su2` (link to the mesh), `NACA0012_ini.dat` (link to the file.dat). Did I perform the procedure correctly? Or did I m",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/948#issuecomment-737134105:92,clear,clear,92,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-737134105,1,['clear'],['clear']
Usability,"Hi guys,; I agree with you, we should change the name of that function including the word ""fluid"". ; In this way the purpose of the function is stated clearly against its counterparts (structural, poisson, heat, etc)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/375#issuecomment-279957104:151,clear,clearly,151,https://su2code.github.io,https://github.com/su2code/SU2/pull/375#issuecomment-279957104,1,['clear'],['clearly']
Usability,"Hi rois1995,. First of all, enjoy your time in Las Vegas. Any paper that you are presenting?. As for our discussion about the cross-diffusion term, I've emailed the ""source"" (Menter). I believe he will make it clear.; It may be that he will be able to answer only in a while ...",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/2329#issuecomment-2252939132:210,clear,clear,210,https://su2code.github.io,https://github.com/su2code/SU2/pull/2329#issuecomment-2252939132,1,['clear'],['clear']
Usability,"Hi there,. I went ahead and created a dummy geometry, that is:; 1. I altered the planform so that the sweep, twist, dihedral, taper... are now different from the actual wing; 2. I replaced the airfoil by the NASA SC(2)-0712. The dummy wing has a double planform defined as:; - semi span = [5; 10]; - taper = [0.55; 0.35]; - dihedral angle = [5°; 2.5°]; - twist angle = [1°; 0°; -1°] (given for root, kink and tip airfoil sections); - sweep angle at LE = 25°; - Aspect ratio = 11.8; - semi area = 38. I defined the reference length as:; - reference (semi) area = 45; - reference chord = 3; - reference (semi) span = 15. The flight conditions remained unchanged:; - Mach number: 0.78; - Temperature = ~217 K; - Reynolds number: ~19 millions; - AoA = 0°. I created the exact same grid as before (same number of cells, same progression), ensuring my first cell was at y+<1. Things is, this time, SU2 did not have any trouble converging and computed the right z-projected area... I checked the results with another software and the pressure distribution (taken along the chord near the kink) match, see attached Figure. I am attaching the dummy configuration file (dum.txt) as well as the mesh (dum_mesh.txt) if it can be of interest to you. The mesh is a .geo gmsh file. To get the mesh, simply open with gmsh and click mesh 3D (or, from the console: gmsh dum_mesh.txt -3). At this point, I think that my problem might be related to the actual wing airfoil geometry, which is somehow not well pre-processed by SU2... I will continue investigating and keep you posted if I find a solution. Thank you for the time you took reading this issue.; ![cp](https://user-images.githubusercontent.com/39187559/40602255-3de183ae-6258-11e8-9aba-6c8d374dc34e.png); [dum.txt](https://github.com/su2code/SU2/files/2044072/dum.txt); [dum_mesh.txt](https://github.com/su2code/SU2/files/2044073/dum_mesh.txt)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/533#issuecomment-392442127:1284,simpl,simply,1284,https://su2code.github.io,https://github.com/su2code/SU2/issues/533#issuecomment-392442127,1,['simpl'],['simply']
Usability,"Hi, . I'm not sure what ""new boundary conditions"" means. Is someone replacing the present far-field BC of the TKE and Omega? ; I recognize these ""new"" BCs as the ones given on the TMR (proposed in the original paper). I find the present setting in SU2 very comfortable and more ""intuitive"" than that given on the TMR.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/2329#issuecomment-2307448209:279,intuit,intuitive,279,https://su2code.github.io,https://github.com/su2code/SU2/pull/2329#issuecomment-2307448209,1,['intuit'],['intuitive']
Usability,"Hi, ; thanks for this contribution, I will get a more detailed feedback soon. A first comment about the CSymmetricMatrix class came up to my mind, from a first brief review.; There is already a CSysMatrix class and a few routines added in this pull request look redundant (matvect product for instance).; On the other hand, many of those routines (cholesky decomposition and so on) could turn out to be very useful also for other future code developments.; That said, perhaps it would be nice to collect all the matrix-related routines into the CSymmetricMatrix class (removing redundancies) to make them available at an higher level. Cheers,; Giulio",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/555#issuecomment-406370798:63,feedback,feedback,63,https://su2code.github.io,https://github.com/su2code/SU2/pull/555#issuecomment-406370798,1,['feedback'],['feedback']
Usability,"Hi, are there any updates on this feature? Or maybe some simple example?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1750#issuecomment-2337835036:57,simpl,simple,57,https://su2code.github.io,https://github.com/su2code/SU2/pull/1750#issuecomment-2337835036,1,['simpl'],['simple']
Usability,"Hi, please attach the exact files you are using, and commands you are running, to the discussion you already opened. That will make it easier for someone to help.; The best way to get help from a developer is to make it very simple to replicate the problem.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1458#issuecomment-984084597:225,simpl,simple,225,https://su2code.github.io,https://github.com/su2code/SU2/issues/1458#issuecomment-984084597,1,['simpl'],['simple']
Usability,"Hi, thanks for this interesting discussion. Just a reminder... there is a third place where the default values are stored! the config_template.cfg file. I have had similar problems to what @erangit is describing with the multiple definition of the default values in different places, in fact, sometimes is not clear what is the minimum number of parameters that you can use in a config file. I think that the ideal scenario would be to use the config_template.cfg file as the default value keeper and create subroutines in C++ and python that update the defaults with the existing information in that file. Remember that config_template.cfg is always required otherwise the user doesn't know that are the existing options. By the way... this discussion reminds me that we should update SetRunTime_Options(void). This is an incredible useful small subroutine to modify the software parameters during runtime. EXT_ITER is the only parameters currently accepted but in the near future we should add all or most of them.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/520#issuecomment-381411950:310,clear,clear,310,https://su2code.github.io,https://github.com/su2code/SU2/pull/520#issuecomment-381411950,1,['clear'],['clear']
Usability,"Hi, this sounds very interesting!; I'll take the chance to raise a point: we still don't have a clear strategy to manage the output of multi-zone simulations. Indeed, earlier we used to have the residuals plotted for each zone (so we used to have a line for each zone), currently we just get the residuals corresponding to ZONE_0 (this was probably changed in one of the latest pull request, I think it could be the one from @salvovitale ). We should decide if to restore the previous ""multi-residual"" output or if to sum up residuals from each zone and print out the results.; Cause right now we can't know how the residuals are behaving in the rest of the domain.; We could perhaps create an additional ""special"" output to manage multi-zone computations. cheers,; Giulio",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/432#issuecomment-326204080:96,clear,clear,96,https://su2code.github.io,https://github.com/su2code/SU2/pull/432#issuecomment-326204080,1,['clear'],['clear']
Usability,"Hi,. Thank you for your quick answer, It indeed seems that I had some parameters that were passed that did not match su2 version 7.0.3. I am experiencing an issue while running the mesh adaptation process in SU2. The process starts but fails during the mesh generation phase, leading to a FileNotFoundError. I am looking for assistance in resolving this error.; `; SU2-AMG Anisotropic Mesh Adaptation. Mesh adaptation options:; PYADAP_COMPLEXITY : (100, 200, 300); PYADAP_SUBITE : (2, 2, 2); PYADAP_SENSOR : MACH; PYADAP_HMAX : 200; PYADAP_HMIN : 1e-8; PYADAP_HGRAD : 1.3; PYADAP_RESIDUAL_REDUCTION : (3, 3, 3); PYADAP_FLOW_ITER : (500, 500, 500). ./adap exists. Removing old mesh adaptation in 10s.; The ./adap folder was deleted. Generating GMF background surface mesh.; Initial CFD solution is provided. Starting mesh adaptation process. Iteration 0 - Mesh size coefficient 100.0; (1/2) Generating adapted mesh using AMG; AMG done: ; Running CFD; Traceback (most recent call last):; File ""/path/to/SU2/install/bin/mesh_adaptation_amg.py"", line 111, in <module>; main(); File ""/path/to/SU2/install/bin/mesh_adaptation_amg.py"", line 72, in main; options.save_all ); File ""/path/to/SU2/install/bin/mesh_adaptation_amg.py"", line 101, in mesh_adaptation_amg; SU2.run.amg(config); File ""/path/to/SU2/install/bin/SU2/run/amg.py"", line 466, in amg; os.rename(cur_solfil, cur_solfil_ini); FileNotFoundError: [Errno 2] No such file or directory: 'flo.dat' -> 'flo_ini.dat'`. and it0 folder is created, with some log.err and log.out, but they are empty, . I would appreciate any guidance or suggestions on how to resolve this issue. Thank you!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/948#issuecomment-1855842105:1571,guid,guidance,1571,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-1855842105,1,['guid'],['guidance']
Usability,"Hi,. This error simply occurs because the prototype of the CDriver (and child classes) has changed. There is an additional `bool val_periodic` argument that have to be passed. The current fsi_computation.py is not up-to-date. Here are solutions to fix that:. - Change the fsi_computation.py and pass an extra `False` argument between the number of dimensions and the communicator. or. - Do you need the very last develop branch ? Because it seems like in the master branch the constructor of the CDriver is still the compatible one. So you could use this branch without modifying anything. I hope this will help. Cheers,. David",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/531#issuecomment-388288297:16,simpl,simply,16,https://su2code.github.io,https://github.com/su2code/SU2/issues/531#issuecomment-388288297,1,['simpl'],['simply']
Usability,"Hi,; I just had a few (very minor) comments.; Regarding the main contribution, everything makes sense to me and I didn't find any relevant issue.; This is a very nice contribution and the implementation is quite clear, we can go ahead and merge this in soon. Regarding the matrix stuff, perhaps we could start having a new, general, matrix class in Common and then extend it to parallel in future pushes.; It may not be ideal, but at least we'll get started.; I am just afraid that if we leave those potentially useful routines there, in the interpolator, we will soon forget about them (of course it doesn't have to be addressed in this PR but we should really discuss about this). ciao,; Giulio",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/555#issuecomment-407014370:212,clear,clear,212,https://su2code.github.io,https://github.com/su2code/SU2/pull/555#issuecomment-407014370,1,['clear'],['clear']
Usability,"Hi,; I went through this work but it is a bit hard to me to completely follow and continue you guys' idea. If you could help finish this issue, I am really willing to do some tests and give feedbacks ASAP. Thanks!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/2275#issuecomment-2098689280:190,feedback,feedbacks,190,https://su2code.github.io,https://github.com/su2code/SU2/issues/2275#issuecomment-2098689280,1,['feedback'],['feedbacks']
Usability,"Hi,; So far as I can tell from the code, no.; It would however be very simple to hack that kind of feature, I can point you to the right places if you want.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/973#issuecomment-626357981:71,simpl,simple,71,https://su2code.github.io,https://github.com/su2code/SU2/issues/973#issuecomment-626357981,1,['simpl'],['simple']
Usability,"I agree with @pcarruscag , we should try to merge options. I have been thinking for quite some time that we should make the mesh deformation a full solver on its own and homogenise all the options and procedures, be able to define different boundary conditions, etc. It should be based on the linear elasticity but have it's own variable definition, so it's usable out of the box with the adjoint solver. I have a preliminary implementation in [`feature_mesh_solver` ](https://github.com/su2code/SU2/tree/feature_mesh_solver), but I would need some help with that.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/623#issuecomment-456293206:358,usab,usable,358,https://su2code.github.io,https://github.com/su2code/SU2/pull/623#issuecomment-456293206,1,['usab'],['usable']
Usability,"I agree with Heather on that. It is only intuitive if you already have the experience. And in that case you know what an appropriate step size is, so you can also specify it directly without having it scaled by some reference length (and of course also consider the case where you don't have an aircraft, wing or airfoil).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/367#issuecomment-284349273:41,intuit,intuitive,41,https://su2code.github.io,https://github.com/su2code/SU2/issues/367#issuecomment-284349273,1,['intuit'],['intuitive']
Usability,"I agree with the final conclusion here... thanks for discussing this and working toward a solution. . We have found in some of our performance optimization work that continuously allocating/deallocating memory is a performance killer, and I am in favor of uniform behavior across the code for readability/usability. Let's merge this in.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/200#issuecomment-149771091:305,usab,usability,305,https://su2code.github.io,https://github.com/su2code/SU2/pull/200#issuecomment-149771091,1,['usab'],['usability']
Usability,"I agree with the proposed changes, but I also think this could go farther. Some of the most common issues for users involve misuse of the *_ORDER options, dissipation coefficients, and limiters. Overall, it is still not very clear for a user how the centered schemes work. For instance, Lax is always first order and JST is always second order, but sometimes there are not error messages when trying to change the ""ORDER"" option when using these schemes. Also, if we rename the coefficients for JST as proposed, shouldn't we also separate the first coefficient that is only used for Lax? It would make treating the dissipation more clear.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/451#issuecomment-335205189:225,clear,clear,225,https://su2code.github.io,https://github.com/su2code/SU2/pull/451#issuecomment-335205189,2,['clear'],['clear']
Usability,"I also agree that there should be an explicit option, and that it should; default to the current behavior, however it may be more intuitive for the; user to specify the actual step size- people who don't have Francisco's; extensive experience will not intuit that the finite difference step will; be 1/100 of the reference length, and may have difficulty figuring that out; without help. I suggest something like FD_STEP_SIZE, either way with; documentation explaining it.; -H. On Mar 6, 2017 5:26 PM, ""juanjosealonso"" <notifications@github.com> wrote:. > Agree with Francisco: the best solution is to have an input parameter that; > can be used to scale the FD step size. I would suggest FD_REFERENCE_LENGTH; > to be created (and possibly specified in the config file). If; > FD_REFERENCE_LENGTH is not specified, then it could default to; > REF_LENGTH_MOMENT.; >; > Best,; >; > Juan; >; > On Mar 5, 2017, at 6:35 PM, Francisco Palacios <notifications@github.com<; > mailto:notifications@github.com>> wrote:; >; > Hi,; >; > Yep, I changed that. I know that from the math point of view it doesn’t; > make a lot of sense but, from the practical point of view, it is useful.; >; > There are some cases, in which computing gradients using finite; > differences is the only choice. And with the shape_optimization script it; > was not possible to control the step size for the finite differences. The; > option for step size was only in finite_differences.py.; >; > The step size is scaled with the reference length because from the; > practical point of view, I have found that the size of the aircraft, wing,; > airfoil, is important to determine a meaningful step size. e.g. should we; > use the same step for an aircraft with a MAC of ~150in than for an airfoil; > with a chord of 1in.; >; > Remember that most of the times we are using FD when the adjoint is not; > converging… so we have bad convergence of the direct problem (including; > some level of unsteadiness that we want to filter with the ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/367#issuecomment-284314148:130,intuit,intuitive,130,https://su2code.github.io,https://github.com/su2code/SU2/issues/367#issuecomment-284314148,2,['intuit'],"['intuit', 'intuitive']"
Usability,"I also like the idea of renaming to ""SOLVER"" but I would also say to avoid as much churn as possible in the conditionals throughout the code... looks like a wash when reading through the PR changes (almost as many +'s as -'s). Unless the changes are going to make something much more flexible or clear, I would say just keep Kind_Regime and set it in config postprocessing.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/756#issuecomment-520705829:296,clear,clear,296,https://su2code.github.io,https://github.com/su2code/SU2/pull/756#issuecomment-520705829,1,['clear'],['clear']
Usability,"I am a little partial because I wrote it, but this https://github.com/su2code/FADO should do any kind of optimization you want.; Multiple operating points, manipulations of variables, running everything simultaneously... But I guess for something simple it is a little more work to setup.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1279#issuecomment-833754354:247,simpl,simple,247,https://su2code.github.io,https://github.com/su2code/SU2/issues/1279#issuecomment-833754354,1,['simpl'],['simple']
Usability,"I am not a 100% clear on all the things this new feature can do. From what I gather we can now set an initial flow field that is not just freestream condition everywhere? If this is the case, this is a hugely useful feature so thank you guys for doing that. . How exactly is this allowing for solution verification? Is it allowing you to run the same case with a bunch of different solver schemes? Can it run the solvers on a set of meshes or do you still have to run on each mesh refinement individually?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/672#issuecomment-486373335:16,clear,clear,16,https://su2code.github.io,https://github.com/su2code/SU2/pull/672#issuecomment-486373335,1,['clear'],['clear']
Usability,"I am not sure about why periodic boundaries are allowed to deform. It doesn't seem to be a good idea unless there is a way to deform its periodic pair in the same way. As for @auzbaig's question about why SLSQP converges in one step: There is a huge difference in the magnitude of the objective function, O(1) and the gradient O(-11). I am guessing the optimizer doesn't think it can reduce the function value any further since the gradient with respect to the DVs is so small. . To change the relative magnitudes of the objective and gradient, you need to change the DV scaling. This isn't intuitive and is one of the things we are hoping to address in #922 . Check out the `obj_df` function in `SU2_PY/SU2/eval/design.py` (line 386 in the develop branch). There you see how the gradient is scaled: . `grad[k] = grad[k] * sign * scale * global_factor / dv_scl` . Here `scale` is the objective function scaling factor, `global_factor` is what you specify for the `OPT_GRADIENT_FACTOR`, the `dv_scl` is the design variable scaling. . So if you wanted to bring the gradient norm to O(1), you'd have to specify a DV scaling of 1e-11. Usually a gradient norm of O(-6) is what seems to work best with SLSQP.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/976#issuecomment-628724163:591,intuit,intuitive,591,https://su2code.github.io,https://github.com/su2code/SU2/issues/976#issuecomment-628724163,1,['intuit'],['intuitive']
Usability,"I am using Intel MPI as well, but on Ubuntu 18.04 and I get a clear error message. The likely reason why it hangs for you for this grid and not for the others is that this grid has an issue and the others do not. . Can you run it on one core of your supercomputer?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/683#issuecomment-493914393:62,clear,clear,62,https://su2code.github.io,https://github.com/su2code/SU2/issues/683#issuecomment-493914393,1,['clear'],['clear']
Usability,I am using the binary of SU2_CFD on Mac Os X for a single core run. There are no restart files for SU2_SOL to work with. IS there a way to simply export in CSV format? config_template.cfg is missing in the folders.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/787#issuecomment-528450087:139,simpl,simply,139,https://su2code.github.io,https://github.com/su2code/SU2/issues/787#issuecomment-528450087,1,['simpl'],['simply']
Usability,"I came across this when I was working on a mesh generation program that generates an extruded boundary layer. I had checks in the program to make sure I was generating elements of positive volume and that they weren't self intersecting. While some of the elements were very badly skewed, I knew I didn't want the elements to be reoriented. However, SU2 reorients several of the prisms and tries to reorient some of the pyramids as well (which isn't a defined operation in SU2). . This is why in my particular case it was easier for me to just turn off the feature. . In general though, I think that the reorientation check could be a bit better. Currently for the prism element for example, it does a volume like calculation using the top and bottom triangles separately, and reorients if either one is negative. Obviously if only one of these calculations is negative, by reorienting, the other calculation would become negative. Similar things are done for pyramids and hexas. . A simple solution would be to change the ""or"" conditions in these calculations to ""and"", so that it is only reoriented if it fails all the checks. I think a better solution would be to decide on a volume calculation method for each element type, and then use that as a criteria. . If you'd prefer to just improve the reorientation checks instead of adding this configuration option, I could submit work on a pull request for that if you'd like.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/162#issuecomment-103679295:983,simpl,simple,983,https://su2code.github.io,https://github.com/su2code/SU2/pull/162#issuecomment-103679295,1,['simpl'],['simple']
Usability,"I can do that. I will follow the above mentioned papers to implement the original SA and SA_NEG. So we will end up with SA, SA_NEG along with SA_NOFT2 and SA_NEG_NOFT2**. SA_NEG_NOFT2**:; > we do not consider this modification and simply consider the modified vorticity as in the standard Spalart-Allmaras",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/992#issuecomment-652248694:231,simpl,simply,231,https://su2code.github.io,https://github.com/su2code/SU2/issues/992#issuecomment-652248694,1,['simpl'],['simply']
Usability,"I checked and I could not find a place in the code where this option is used explicitly. Since all the drivers split between primary recording for state variables and secondary recording for geometry variables for efficiency. My own use case was for research I did, where I needed to record a tape w.r.t. to both. Since this is not ready to become a pull request any time soon, I do not really need this option. If you suggest I can create a commit to remove the enum option for simplicity.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1492#issuecomment-1012241237:479,simpl,simplicity,479,https://su2code.github.io,https://github.com/su2code/SU2/pull/1492#issuecomment-1012241237,1,['simpl'],['simplicity']
Usability,"I could but I do not think updating that branch will fix your problem. We have not found any mesh handling bugs recently.; Creating / modifying meshes manually can get tricky (at least in my experience).; Have you tried simpler problems? Try starting with a problem that is known to work (there is a long issue with success stories, do a search for mesh adaptation here on github). Then build up from it, e.g. take the same problem and use a finer grid, change the physics to what you need, use a grid for your problem (ideally change one thing at a time).; Also keep in mind that if that branch was finished work it would probably have been merged into develop by now...",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1156#issuecomment-757123547:220,simpl,simpler,220,https://su2code.github.io,https://github.com/su2code/SU2/issues/1156#issuecomment-757123547,1,['simpl'],['simpler']
Usability,"I could create a ""safe Allgatherv"" function, e.g. in [`mpi_structure.hpp`](https://github.com/su2code/SU2/blob/1b085062547ec5b066a28ddeeacf4907588f4f5a/Common/include/parallelization/mpi_structure.hpp) or in [`ndflattener.hpp`](https://github.com/su2code/SU2/blob/1b085062547ec5b066a28ddeeacf4907588f4f5a/Common/include/toolboxes/ndflattener.hpp). This function should check the number of processes, perform a simple copy if it is 1, and otherwise calls the regular Allgatherv. It would then be used [here](https://github.com/su2code/SU2/blob/1b085062547ec5b066a28ddeeacf4907588f4f5a/Common/include/toolboxes/ndflattener.hpp#L235) instead of `SU2_MPI::Allgatherv`.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1893#issuecomment-1397491031:410,simpl,simple,410,https://su2code.github.io,https://github.com/su2code/SU2/issues/1893#issuecomment-1397491031,1,['simpl'],['simple']
Usability,"I did few tests (CGNS mesh format), following are the details -; **While trying to use all 8 cores per node (Total 70 nodes, each having 24 GB RAM)-**. Loading section Connect_PRISM of element type Prism.; malloc failed for element data; malloc failed for element data; ............ malloc failed for element data; Error allocating I4->I8 data array...; malloc failed for element data; Error allocating I4->I8 data array...; malloc failed for element data; ................; malloc failed for element data; malloc failed for element data; Loading section Connect_TETRA of element type Tetrahedron. **While trying 6 cores in each node**. Loading section Connect_PRISM of element type Prism.; malloc failed for element data; malloc failed for element data; malloc failed for element data; malloc failed for element data; malloc failed for element data. **Finally settled with 4 cores at each node and memory usage at every node is--** . PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND ; 4652 aero 30 10 872m 746m 10m R 100 3.1 43:03.38 SU2_CFD ; 4653 aero 30 10 1076m 951m 10m R 100 3.9 43:12.10 SU2_CFD ; 4654 aero 30 10 1162m 1.0g 10m R 100 4.3 43:15.15 SU2_CFD ; 4655 aero 30 10 1458m 1.3g 10m R 100 5.5 43:08.96 SU2_CFD . **With above, memory usage seems to be around 16.8 % of 24 GB RAM**. Hope I am not missing something else (some other usage etc...) and what should be the approximate memory requirement for such mesh sizes (around 60 million or is there a general guideline of memory requirement with mesh size for RANS computation with Implicit solver) ?. Regards; Amit",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/291#issuecomment-232018195:1477,guid,guideline,1477,https://su2code.github.io,https://github.com/su2code/SU2/issues/291#issuecomment-232018195,1,['guid'],['guideline']
Usability,"I don't think the fix is as simple as it seems.; Indeed looking back at how we developed the CGNS reader, It was originally meant to read multiple zone in a single file. But during development, someone decided to restrict the reader to only one zone per file (and I don't know if it was validated). So now we are seating in the middle. If we replace line 169 of CGNSFVMMeshReader :; <pre>; if ( nzones > 1 ) {; SU2_MPI::Error(string(""CGNS reader currently expects only 1 zone per CGNS file."") +; string(""Multizone problems can be run with separate CGNS files for each zone.""), CURRENT_FUNCTION);; }; </pre>; by; <pre>; if ( cgnsZone > nzones) {; cgnsZone = 1;; }; </pre>. we can easily support multiple zone in one file. To support one CGNS zone per file, I guess that user should provide either the index in the cgns file of the zone we want to read or even better its name and not rely on SU2 numbering of zones. I think that supporting multiple mesh zones in the same file at the same time as one zone per mesh file should be possible as long as enough information is provided by the user. In this case, I am wondering how the option MULTIZONE_MESH and MULTIZONE option are interacting in the related issue. When MULTIZONE_MESH is set to NO do we expect one mesh file per zone ?; And in this case we can force CGNS Reader to read only the first Zone. In a more generic way something like this should be possible:; MULTIZONE=YES; CONFIG_LIST= (zone_1.cfg, zone_2.cfg, zone_3.cfg); CGNSZONENAMES = (""FluidRotor"", ""Solid"", ""FluidStator"") # To let CGNS pick the right zone in the file and if it not found the first zone can be used (current SU2 behavior). CGNSZONENAMES could also be set in each config file.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1566#issuecomment-1073204565:28,simpl,simple,28,https://su2code.github.io,https://github.com/su2code/SU2/pull/1566#issuecomment-1073204565,1,['simpl'],['simple']
Usability,"I expect that epsilon to be a simple measure to avoid division by 0, if that lower bound had physical meaning it would have to be multiplied by some reference factors to make its dimensions appropriate, otherwise SST would not give the same results for the same Reynolds obtained with different rho and mu.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/2329#issuecomment-2284506205:30,simpl,simple,30,https://su2code.github.io,https://github.com/su2code/SU2/pull/2329#issuecomment-2284506205,1,['simpl'],['simple']
Usability,"I find your work really interesting. I've been studying the internal flow field in compressors and have had good results using SU2's SA_EDDES for calculating the cantilevered stator with a tip clearance. If you need help with code verification, I'd be glad to assist.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/2150#issuecomment-2066011801:193,clear,clearance,193,https://su2code.github.io,https://github.com/su2code/SU2/pull/2150#issuecomment-2066011801,1,['clear'],['clearance']
Usability,"I have a few updates. I found out that most of my FGMRES problems in this branch where related to the fact that I was using single precision for the linear system. You can see it in this graphs for the residuals of Rho. ![RMSRho_Mesh_3](https://github.com/user-attachments/assets/185b8195-e415-4dff-9332-cff573c069cc). The first two curves are in mixed-precision and they stop long before reaching the minimum residual required due to divergence of the linear solver. Moreover, it seems that the 2003 model here implemented (which, simply put, considers the full reynolds stress tensor for the computation of the production of k and always considers k in the stress tensor and in the thermodynamic variables) has faster convergence and increases the recirculating zone (maybe due to the reduction of turbulence kinetic energy) which is a feature that has also been seen in [DOI:10.1017/aer.2020.93]. . ![SFC_Mesh_3](https://github.com/user-attachments/assets/81a50021-6b58-4a84-9057-a18b5bab023c). There are some differences between the use of the TMR boundary conditions and the ones used before. The results improve with respect to the develop in the prediction of the SFC distribution, which has results completely off from the V&V page of SU2. ![SFC_Mesh_3_Old](https://github.com/user-attachments/assets/0f4d634b-df31-4f86-a324-d9f67947f1ff). ![RMSRho_Mesh_3_Old](https://github.com/user-attachments/assets/24d5c2f5-93fe-432f-82d9-c050a90f7339). I may keep on checking if the implementation of the v2003 model is correct or not by searching for other test cases (probably coming from DOI:10.1017/aer.2020.93).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/2329#issuecomment-2393433487:532,simpl,simply,532,https://su2code.github.io,https://github.com/su2code/SU2/pull/2329#issuecomment-2393433487,1,['simpl'],['simply']
Usability,"I have added the new option NUM_METHOD_GRAD_RECON to specify a separate method for computing the reconstruction gradient. If that option is not present, then no additional memory is allocated and no extra gradient computation occurs. I have also put in simple feedback from the linear solver residual and the nonlinear residual to the nonlinear controller. If the linear system converges less than a half an order of magnitude, then the CFL is lowered. A Cauchy-like criteria checks for stall in the nonlinear residuals and drops the CFL to the minimum floor to kick the solver out of a rut. Both of these use factors that are empirical from my tests. Will probably be improved with time and more testing, but they do seem to improve behavior. @koodlyakshay : I had success with the inc. laminar backward facing step after adding extra iterations to the linear solve. For some cases, this is necessary to get a large speedup. I am seeing good speedup for most of the cases within our TestCases repo. If you have some tough cases not covered by the repo, please give those a try.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/790#issuecomment-536145232:253,simpl,simple,253,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-536145232,2,"['feedback', 'simpl']","['feedback', 'simple']"
Usability,"I have covered all operations used in non adjoint use, the non ideal part of the implementation I mentioned above is that the parallelization is ""local"", i.e. we get to the operation we want to make parallel and launch the threads there, for simple vector-vector operations the overhead may be significant.; Ideally we would have a parallel construct at a higher level, say CSysSolve::Solve, so that the threads are already in flight when we get to those small operations.; In principle it is not too hard to do that, but it needs to be done carefully especially when the execution gets to an MPI part of the code (which thread(s) communicate, etc.).; I will try to benchmark this to put numbers on the performance / simplicity trade-off.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/830#issuecomment-560572616:242,simpl,simple,242,https://su2code.github.io,https://github.com/su2code/SU2/pull/830#issuecomment-560572616,2,['simpl'],"['simple', 'simplicity']"
Usability,"I have seen that it is possible to specify the number of iterations in command line (shape_optimization.py)... but, I think it is clear to have both options (number of iterations and bounds - same for all the variables- ) in the config file.; Thanks!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/49#issuecomment-54920484:130,clear,clear,130,https://su2code.github.io,https://github.com/su2code/SU2/issues/49#issuecomment-54920484,1,['clear'],['clear']
Usability,"I have simplified the input method now. Users need to simply add a line; ; MARKER_ROUGHWALL = (marker_name_1, k_1, marker_name_2, k_2, ..). By default all walls are smooth and only the rough walls need to be listed and the order shouldn't matter. . Edit: Just realized you asked me to use a different name. Will fix it in the next commit.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/877#issuecomment-642800393:7,simpl,simplified,7,https://su2code.github.io,https://github.com/su2code/SU2/pull/877#issuecomment-642800393,2,['simpl'],"['simplified', 'simply']"
Usability,I have the same problem but I don't understand the solutions you suggested. Could you explain to me a bit clear?,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/469#issuecomment-707290679:106,clear,clear,106,https://su2code.github.io,https://github.com/su2code/SU2/issues/469#issuecomment-707290679,1,['clear'],['clear']
Usability,"I haven't looked at the python wrapper in detail, we had previously tracked several properties which are not available in the conventional convergence tracker (such as Cmy) and used the stop file to obtain the data when appropriate. We have considered increasing the save frequency, but there are several files which are not created at every save point; thereby forcing each ""standard"" run to become a ""run to nearest save"" then ""resume for 1 time-step to get the actual output data"". As the decomposition and some of the file writes take a significant amount of time, it is a non-starter for commercial applications. We would switch back to v6 (which had the capability) but we need some of the other features in v7. I'll take a look at the python wrapper. Thank you for your candor.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1304#issuecomment-862344695:430,resume,resume,430,https://su2code.github.io,https://github.com/su2code/SU2/issues/1304#issuecomment-862344695,1,['resume'],['resume']
Usability,"I implemented most of the reviewers suggestions. The only suggestion I left unchanged is the upper-case consistency issue raised by Wally. Since it is an optional output and it depends on the controlling variable names the user provides, I think it would be more intuitive to keep the font case consistent between the names under `CONTROLLING_VARIABLE_NAMES` and the corresponding `RMS_` outputs.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/2057#issuecomment-1643680580:263,intuit,intuitive,263,https://su2code.github.io,https://github.com/su2code/SU2/pull/2057#issuecomment-1643680580,1,['intuit'],['intuitive']
Usability,"I just committed a second round of changes that I would appreciate some feedback on. Compilation is successful with these changes, however, upon testing, I receive the following message: . Error in ""void CConfig::SetConfig_Parsing(std::istream&)"": ; -------------------------------------------------------------------------; Line 271 SPECIFIED_SUPERSONIC_INLET_PROFILE: invalid option name. Check current SU2 options in config_template.cfg.; Did you mean SPECIFIED_INLET_PROFILE?; Line 274 SUPERSONIC_INLET_FILENAME: invalid option name. Check current SU2 options in config_template.cfg.; Did you mean INLET_FILENAME?. I had already adjusted CConfig.cpp to include supersonic inlet profile inputs, but apparently I am not implementing everything I need to. I'm unsure where else I would need to make changes. Any suggestions?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1652#issuecomment-1151296832:72,feedback,feedback,72,https://su2code.github.io,https://github.com/su2code/SU2/pull/1652#issuecomment-1151296832,1,['feedback'],['feedback']
Usability,"I just found [a blog post](https://codingnest.com/the-future-of-catch2/) on the future directions of Catch2. There's a couple of important points for our discussion. The developer plans to adopt a hybrid approach, with:. 1. A stripped-down, header-only version.; 2. A full-feature, typical library (i.e. it must be compiled and linked). This approach is very similar to Boost's setup. Google Test does not offer a header-only version. Additionally, the developer plans to drop C++11 support, and move to C++14. A simpler branch will still support C++03. It's not clear which features are supported in the C++03 variant, and which ones aren't. Google Test is also moving to support only C++11 in their next release, but their current release fully supports pre-C++11. All of this discussion raises the question: Do we want to require C++11 for unit tests?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-500411194:513,simpl,simpler,513,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-500411194,2,"['clear', 'simpl']","['clear', 'simpler']"
Usability,"I just ran the case and I see this as well, even after complete convergence. You clearly can see this in the energy and pressure (and density) but not in the momentum terms. The temperature field also looks smooth. So may be related to density/pressure.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1373#issuecomment-932510910:81,clear,clearly,81,https://su2code.github.io,https://github.com/su2code/SU2/issues/1373#issuecomment-932510910,1,['clear'],['clearly']
Usability,"I know that it can be frustrating sometimes operating within the constraints of an open-source project such as ours. However, I can assure you that folks do indeed care about performance, and sometimes I have the impression that we stress over relatively small performance issues (remember to keep the total pie chart of where the major work of the solver resides in mind). . The option WRT_PERFORMANCE= YES is available to get timings for runs broken down by preprocessing, compute, and output phases, and I think we should focus our performance concerns first on issues within the compute phase, unless a major bottleneck appears in the other two phases that completely prohibits us from running larger cases (we have been clearing many of those out lately). We do not have the resources of a professional software company, but what we do have is a great community of folks who are putting in lots of effort on a volunteer basis. @pcarruscag: your reviews have been very helpful for improving contributions - thank you for that effort. Let's keep supporting each other, but let's also make sure we stay positive and foster a welcoming environment to encourage more participation.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/724#issuecomment-534682406:725,clear,clearing,725,https://su2code.github.io,https://github.com/su2code/SU2/pull/724#issuecomment-534682406,1,['clear'],['clearing']
Usability,"I noticed the addition of the Guide to V7 page being introduced to the SU2 page. I think this would make a great starting point to beef up our documentation/tutorial pages. Using a similar format, we could discuss the available options in SU2. Speaking from experience, new SU2 users face an extremely high learning curve, often scaring them away. I believe this would help alleviate that problem. I understand this is no small task, and welcome others thoughts on the issue",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/775#issuecomment-536031012:307,learn,learning,307,https://su2code.github.io,https://github.com/su2code/SU2/issues/775#issuecomment-536031012,1,['learn'],['learning']
Usability,"I see that the Onera M6 mesh is a half-wing with a symmetry plane and I'm not sure how the mesh deformation behaves in this case (for example, there should be zero out-of-plane movement). . Personally, I like really simple examples where I know what should happen (symmetric airfoil, subsonic flow, no sweep) and I did all my testing during the last weeks with the NACA0012 3m wing. At the same time, it is closer to how I would model a ""real"" aircraft (aircraft in the center of a spherical farfield) than the Onera M6, which is more wind-tunnel-like. The mesh and everything is there, so it's no additional work for me and I would be happy to contribute this as a new example. What's the main argument in favor of the Onear M6 wing / objection against a new example?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1954#issuecomment-1547295112:216,simpl,simple,216,https://su2code.github.io,https://github.com/su2code/SU2/pull/1954#issuecomment-1547295112,1,['simpl'],['simple']
Usability,"I simple wrote a program to test the grid, which searches for the boundary elements in the single faces, i.e. faces that are only part of one volume element, of the volume grid. What the error message means is that for 4 triangular surface elements of boundary marker BODY there is no corresponding face of the volume elements that is only part of one volume element. . When I include the faces that are shared by two volume elements, only two boundary elements are not found. So in short, you have two boundary elements in boundary marker BODY that are no part of any volume element and two boundary elements that are shared by two volume elements.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/683#issuecomment-494675549:2,simpl,simple,2,https://su2code.github.io,https://github.com/su2code/SU2/issues/683#issuecomment-494675549,1,['simpl'],['simple']
Usability,"I suggest that you incorporate Wray-Agarwal (WA) one equation RANS model listed on NASA TMR in SU2. NASA is planning to list two equation WA-gamma transition model on NASA TMR next month. WA model is available on Github and WA model will also be posted on Github as source code. If you need any additional information or help, let me know.; Ramesh Agarwal; ________________________________; From: Pedro Gomes <notifications@github.com>; Sent: Wednesday, January 6, 2021 10:13 AM; To: su2code/SU2 <SU2@noreply.github.com>; Cc: Agarwal, Ramesh <rka@wustl.edu>; Comment <comment@noreply.github.com>; Subject: Re: [su2code/SU2] Info on current status of LM transition model in SU2 (#1130). @lorenzob95<https://github.com/lorenzob95> we talked about this issue in our weekly developers meeting.; The current implementation of LM in the code is not stable enough and it has known bugs, so we will not re enable it for now.; A revised implementation by @vdweide<https://github.com/vdweide> exist in branch https://github.com/su2code/SU2/tree/feature_LM_model, but this is based on SU2 v6.2, it has been used on simple problems, convergence is not ideal on more complicated ones.; The decision is to wait for some developments that will make it easier to bring this revised implementation into version 7 (which is different in many ways from 6).; You can follow this issue to know when this gets implemented, it will probably take a few months. —; You are receiving this because you commented.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/1130#issuecomment-755395168>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/ASK3WAEG3LW3AZJRUPORJPDSYSD2VANCNFSM4UVYXAAA>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1130#issuecomment-755440165:1104,simpl,simple,1104,https://su2code.github.io,https://github.com/su2code/SU2/issues/1130#issuecomment-755440165,1,['simpl'],['simple']
Usability,"I tend to agree w Eran on this topic. When it is working as it should, it is very convenient to have the makefiles already available in the repo. I switch between Mac, Ubuntu, and a red hat cluster without needing to update anything or call the bootstrap script. I rarely use it.. basically only when adding or removing files to the build. Also, it is good to minimize dependencies, as sometimes old machines or clusters have limited tool sets. But, clearly we should at a minimum fix the issue that some of you are finding with the autotools, which should just need an update. What systems are you having trouble with? It’s important that we don’t jump too far ahead for portability reasons (that’s why we have kept the old versions for so long). Do you have an idea of the minimum autotools you need for the failing systems? We could start by updating to that version and see if things stabilize.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/586#issuecomment-424210049:450,clear,clearly,450,https://su2code.github.io,https://github.com/su2code/SU2/pull/586#issuecomment-424210049,1,['clear'],['clearly']
Usability,"I think I implemented all the modifications you suggested. I am sorry you see all the commits in between, unfortunately due to Covid I work outside of office and I actually use Github to push the modified code to the office PC. I was actually working on a separate branch but, for reason that I do not understand, all the commits have been moved in the merging process... sorry about that. I am still learning git. In particular the modifications are:. - The functions related to static mesh deformation have been removed. I only included some new lines in the python wrapper ; that overwrite the initial velocities to zero and push back the solution.; - I now use the BC_Sym_Plane of the FEA solver for the deformation at the symmetry plane. I had to add a flag that avoids ; accessing LinSysReact in case of mesh deformation, as this is not initialised in that context.; - GetnMarker_Match_Deform_Mesh is not present anymore; - The marker has been renamed from MATCH_DEFORM_MESH to DEFORM_MESH_SYM_PLANE. All the functions have also ; been renamed accordingly; - I included the SU2 header in all the new files, changing the version number to 7.0.8. I did not modify the version number of ; the files that were already present in SU2 prior to this PR. I think the merging process should take care of that, am I wrong?; - The python functions that were separated in x,y,z component now give back an array and are merged into one function only; - The descriptions for the methods have been added; - The test case has been removed. I actually prepared a tutorial and all the appropriate files will be placed in the tutorial and ; website repos. I will now perform a PR for those repos so that you can see the material. Again thank you very much and sorry for the mess with the ""internal"" commits. . Please let me know if you think I missed something",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1124#issuecomment-742471972:401,learn,learning,401,https://su2code.github.io,https://github.com/su2code/SU2/pull/1124#issuecomment-742471972,1,['learn'],['learning']
Usability,"I think its a good idea to separate the weight from the objective function. This makes it more clear and flexible. However, what bothers me a little bit is that the OBJECTIVE_FUNCTION option is now used for two things. Namely for the optimization and for the individual adjoint runs. Maybe it would be good to still have another option for specifying the obj. function for the adjoint run itself (with a completely different name, so that there won't be any confusions). . Maybe it's less of a problem then I think, though.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/241#issuecomment-185126081:95,clear,clear,95,https://su2code.github.io,https://github.com/su2code/SU2/pull/241#issuecomment-185126081,1,['clear'],['clear']
Usability,"I think the last commit addressed your concerns @arubino, thanks for the feedback.; @LaSerpe - that fsi bug was fixed in a separate pull request.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/312#issuecomment-253286105:73,feedback,feedback,73,https://su2code.github.io,https://github.com/su2code/SU2/pull/312#issuecomment-253286105,1,['feedback'],['feedback']
Usability,"I think the problem is in the fix for the symmetry boundary in PR #2194. I tried with the develop at the last commit (LC), at the commit before the implementation of the correction (BC) and at the commit of the implementation (AC). It is clearly visible that something is happening with the symmetry BC correction. I will look further into it. ![CommitsComparison_RMSRho](https://github.com/user-attachments/assets/7db41c0e-2885-4e66-bd1c-d01b038430bc). Also the profiles of the Mach number and nu_tilde are the same between LC and AC. With the BC instead the Mach number and nu_tilde are correct.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/2329#issuecomment-2370888175:238,clear,clearly,238,https://su2code.github.io,https://github.com/su2code/SU2/pull/2329#issuecomment-2370888175,1,['clear'],['clearly']
Usability,"I think the writing is clear, but inaccurate. The line I quote in the initial report is still there. . The code does seem to have been updated, and it now lives in CPhysicalGeometry::Read_SU2_Format_Parallel; Here is the relevant code (for 2D I think). Current lines 6100-6104 of geometry_structure.cpp. ```; #ifndef HAVE_MPI; point_line >> Coord_2D[0]; point_line >> Coord_2D[1];; #else; if (size > SINGLE_NODE) { point_line >> Coord_2D[0]; point_line >> Coord_2D[1]; point_line >> LocalIndex; point_line >> GlobalIndex; }; else { point_line >> Coord_2D[0]; point_line >> Coord_2D[1]; LocalIndex = iPoint; GlobalIndex = node_count; }; ```. In serial, the index is completely ignored. In parallel, both are used. Unlike what the documentation says, the node index is completely meaningless in parallel, and there is no documentation of a needed global index in parallel. . I don't know what the correct behavior should be. That is a team decision. I think that the behavior should be roughly the same in serial and parallel. Either the local indices matter, or they don't. If they don't matter, they should be removed. Actually implementing this behavior (in either direction), however, could break a lot of people's code, as in either direction mesh files that were previously working could be different. We could also just have different behavior in serial and parallel, but it should be documented as such. . Thoughts @economon @fpalacios ?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/47#issuecomment-104360874:23,clear,clear,23,https://su2code.github.io,https://github.com/su2code/SU2/issues/47#issuecomment-104360874,1,['clear'],['clear']
Usability,"I totally agree. On real meshes, Omega usually drops to extremely low values. In cases where the cross-diffusion term is negative (allowed to be negative), it behaves as a sink term, further amplifying the drop of Omega. A simple addition of this term to the implicit diagonal is insufficient (I tried this). Other more rigorous methods are required (some available in the open literature). . My main argument is that the factor (1-F1) guarantees only the k-epsilon branch outside the boundary layer, in which the cross-diffusion term is already positive. It may not be so because of numerical errors.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/2329#issuecomment-2253297698:223,simpl,simple,223,https://su2code.github.io,https://github.com/su2code/SU2/pull/2329#issuecomment-2253297698,1,['simpl'],['simple']
Usability,"I tried changing line 1387 in CEulerSolver::SetReferenceValues to simply if (dynamic_grid) {...}, but that had no effect.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1954#issuecomment-1463922825:66,simpl,simply,66,https://su2code.github.io,https://github.com/su2code/SU2/pull/1954#issuecomment-1463922825,1,['simpl'],['simply']
Usability,"I understand your frustration, and the feedback is helpful. Encouraging more participation in Issues and PRs is very important for us. We are still learning and improving our processes. A good metric for us to increase in the project is the total number of *different* people submitting/participating in PRs/Issues (not the total number of comments from just a handful). The best way to scale is to have the work evenly distributed among many folks, rather than just a handful processing the PRs. This will likely take some time & training, but I expect we can accomplish it while remaining positive. Open to good ideas there on how to better achieve it. . As for the other topic - I think that our recent move toward draft PRs may help with describing design decisions. This will also take some time to be adopted, and may or may not reach the depth necessary in the descriptions, but it is a good first step so that we can see things progress in real time. Using the project boards to list tasks and post comments is also helpful (but takes more effort). Open to ideas there too.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/724#issuecomment-534720511:39,feedback,feedback,39,https://su2code.github.io,https://github.com/su2code/SU2/pull/724#issuecomment-534720511,2,"['feedback', 'learn']","['feedback', 'learning']"
Usability,"I understand, but it helps to keep the code more approachable and portable. That being said, there may be some work proposed soon using templates in the linear solver classes, and it would be great to have your feedback then. We really appreciate your interest!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/400#issuecomment-360075745:211,feedback,feedback,211,https://su2code.github.io,https://github.com/su2code/SU2/issues/400#issuecomment-360075745,1,['feedback'],['feedback']
Usability,"I use the connection as the additional marker. Since the connection is two sided, nodes are duplicated. This is quote from the forum post I linked earlier . >....creates unique (yet coincident) points for each ""side"" of the domain.... The quote was about Gmsh exporter and not SU2, but later on they say this is the case for all exporters except Fluent. These duplicated nodes affect the mass and momentum balance because they each carry information about the neighbors on their respective side only. . This might not be a problem if we were to apply a strong boundary condition like a wall because the dirichlet condition will simply overwrite any residuals and apply the appropriate value to both the nodes. However when used as an internal marker or any other weak boundary condition, the duplicate nodes each carry part of the residuals and if they don't communicate with each other an imbalance will occur. At the moment, it appears they do not communicate with each other.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/986#issuecomment-629182862:628,simpl,simply,628,https://su2code.github.io,https://github.com/su2code/SU2/issues/986#issuecomment-629182862,1,['simpl'],['simply']
Usability,"I was running some tests using a simple geometry but for the refinement seems to be chewing up the geometry. Has anyone who has worked on 3D geometries experienced this or figured out a way to avoid this?. I was using the following settings:; ```; % ------------- MESH ADAPTATION PARAMETER ------------%; %; % Type of sensor used for adaptation; % Options include GOAL (adjoint-based), MACH, PRES; PYADAP_SENSOR= MACH; % Maximum cell size for adaptation; PYADAP_HMAX= 500.0; % Minimum cell size for adaptation; PYADAP_HMIN= 1e-9; % Gradation factor (typically 1.2-1.8); PYADAP_HGRAD= 1.8; % Norm used for adaptation; % 1.0 or 2.0 recommended for inviscid flows; % 4.0 recommeneded for viscid; ADAP_NORM= 2.0; % Approximate mesh size (NPOI) at each level; PYADAP_COMPLEXITY= (1000000, 1300000, 1500000); % Number of adaptations performed at each level; PYADAP_SUBITE= (2, 2, 2); ```. ![refine](https://user-images.githubusercontent.com/16842258/104834786-0b94fa80-58e5-11eb-9018-687ffc5aaa9d.png). I noticed a few comments up, there is the `PYADAP_BACK` setting, which sounds like it might solve this, but how should one use this? Should the geometry alone be re-meshed to a high resolution and the whole volume exported as a SU2 block? Or should it be just a surface mesh? (It seems that Pointwise is not able to output only the surface mesh in SU2 format.)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/948#issuecomment-761751741:33,simpl,simple,33,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-761751741,1,['simpl'],['simple']
Usability,"I wonder if maybe it would be a better idea to delete this (and other stuff) from externals/ and add it to subrojects/ instead. You can use `meson wrap install catch2`, and it's a simple ini file to vet instead of an 18k line file. git diffs become a lot simpler too.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1726#issuecomment-1198882302:180,simpl,simple,180,https://su2code.github.io,https://github.com/su2code/SU2/pull/1726#issuecomment-1198882302,2,['simpl'],"['simple', 'simpler']"
Usability,"I'll try to break down each request to make it clearer. Request: Use nomenclature consistent with the C++ interface (point instead of node, etc.); Reason: People who know the C++ interface will know how to use the python wrapper straight away, people who learn how to use the python wrapper will be able to understand the C++ implementation (without needing a translation layer in their mind all the time). Request: Return connectivity/adjacency as local indices instead of global; Reason: This is the natural way of referencing data in an MPI code, local indices correspond directly to data stored in the partition thereby making it more efficient to access (without global-to-local conversions, which are much more expensive than local-to-global). Furthermore, the local ordering strategy improves the efficiency of loops (over edges, neighboring points, etc.). Request: Do not apply unnecessary ""transformations"" to the connectivity/adjacency as part of the API; Reason: Increases the maintenance burden and makes for a less versatile API. By returning the local indices that form a marker or element, it is trivial to retrieve any other data for those indices (the ""transformation""). For example, the solution at those points, the point coordinates, whether the points are halo or domain points, the global indices, etc.; This way, by adding a **single** function to the API e.g. get the global index of a point of element, the functionality of the API grows a lot more because the user can apply the function to **any** connectivity/adjacency function. Request: Do not offer too many overloads of the same function; Reason: Increases the maintenance burden and it's returning the data in structures that are not very efficient, namely vector of vectors. It is much easier to offer domain-wide data access on the python side, as a very small function that can be part of wrapper utilities (i.e. live only in python but not c++). It may even be more efficient since you make a numpy array/matrix in",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1300#issuecomment-1402197827:47,clear,clearer,47,https://su2code.github.io,https://github.com/su2code/SU2/pull/1300#issuecomment-1402197827,2,"['clear', 'learn']","['clearer', 'learn']"
Usability,"I'm at the beginning, so i have no really clear my path. Anyway a soon as; possible i will follow your instructions. Sorry for this difficulty, but to; me a su2 development group is something totally new and i have to clarify; some aspects with my PhD student and with my professor. Thanks for your help; Marco. Il giorno gio 20 gen 2022 alle ore 11:47 Nijso ***@***.***>; ha scritto:. > Hi! If you want to work together over github, you can also create a; > project here:; > https://github.com/su2code/SU2/projects?type=beta and define tasks and; > divide the work. It would be good if you can sort out what the overlap is; > and what the unique parts of your research will be.; >; > —; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/pull/1496#issuecomment-1017354022>, or; > unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AXL7TQXSL55PQIEHSDCPT4LUW7R3TANCNFSM5MC56OYQ>; > .; > Triage notifications on the go with GitHub Mobile for iOS; > <https://apps.apple.com/app/apple-store/id1477376905?ct=notification-email&mt=8&pt=524675>; > or Android; > <https://play.google.com/store/apps/details?id=com.github.android&referrer=utm_campaign%3Dnotification-email%26utm_medium%3Demail%26utm_source%3Dgithub>.; >; > You are receiving this because you commented.Message ID:; > ***@***.***>; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1496#issuecomment-1017587516:42,clear,clear,42,https://su2code.github.io,https://github.com/su2code/SU2/pull/1496#issuecomment-1017587516,1,['clear'],['clear']
Usability,I'm glad you made it work. Like I said it's not needed for simple tutorials.; The general conditions in which you may find it useful are described here: https://su2code.github.io/docs_v7/Linear-Solvers-and-Preconditioners/,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1349#issuecomment-895948814:59,simpl,simple,59,https://su2code.github.io,https://github.com/su2code/SU2/issues/1349#issuecomment-895948814,1,['simpl'],['simple']
Usability,"I'm late to the party here, but just a note to say that the original implementation for the incompressible source terms are indeed from the text that @WallyMaier / @vdweide shared. It was added as part of the work in this paper (https://economon.github.io/docs/AIAA-2018-3111.pdf), but I did not test it much beyond a simple laminar channel case or really attempt to treat turbulence at the time. Thanks for putting in more effort on these terms!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1095#issuecomment-727633198:318,simpl,simple,318,https://su2code.github.io,https://github.com/su2code/SU2/pull/1095#issuecomment-727633198,1,['simpl'],['simple']
Usability,"I'm still not clear on how the convection BC is supposed to work. If I understand correctly up to this point HEAT_FLUX and HEAT_TRANSFER are largely identical:; https://github.com/su2code/SU2/blob/1b085062547ec5b066a28ddeeacf4907588f4f5a/SU2_CFD/src/solvers/CNSSolver.cpp#L476-L479. Essentially in both cases the heat flux is calculated and saved to `Wall_HeatFlux`. For both BCs this is taken into account via the residuals:; https://github.com/su2code/SU2/blob/1b085062547ec5b066a28ddeeacf4907588f4f5a/SU2_CFD/src/solvers/CNSSolver.cpp#L491-L496. and the residual contributions is added:; https://github.com/su2code/SU2/blob/1b085062547ec5b066a28ddeeacf4907588f4f5a/SU2_CFD/src/solvers/CNSSolver.cpp#L530-L532. But I'm a bit lost why HEAT_TRANSFER is treated differently here:; https://github.com/su2code/SU2/blob/1b085062547ec5b066a28ddeeacf4907588f4f5a/SU2_CFD/src/solvers/CNSSolver.cpp#L538-L559. Why is this special treatment necessary if HEAT_TRANSFER essentially is just a different way to calculate `Wall_HeatFlux`? If I disable the additional Jacobian contributions, shouldn't the solution still be accurate?. Regards,; Christian",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1872#issuecomment-1643910412:14,clear,clear,14,https://su2code.github.io,https://github.com/su2code/SU2/issues/1872#issuecomment-1643910412,1,['clear'],['clear']
Usability,"I've (finally) managed to go over this pull request. I didn't go into too much detail as I don't want to delay this any more, but in general it all looks great to me. I have run some extra regression tests locally in my computer, and they all seem to be working fine. I also left some comments around, but they are mostly asking for some clarification, no major issues. All cleared from my side. Sorry again for taking way too long, I was so behind myself that I needed to do some merging in my own branches to be able to understand the changes in FSI context... Thanks a lot @LaSerpe for a great work!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/322#issuecomment-258872671:374,clear,cleared,374,https://su2code.github.io,https://github.com/su2code/SU2/pull/322#issuecomment-258872671,1,['clear'],['cleared']
Usability,"I've also asked on OpenMPI mail-list and they said ""Can you or they provide a small, simple MPI application that replicates the issue? That would be something we could dig into and investigate.""",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/2103#issuecomment-1673166638:85,simpl,simple,85,https://su2code.github.io,https://github.com/su2code/SU2/issues/2103#issuecomment-1673166638,1,['simpl'],['simple']
Usability,"I've changed some 'get' functions to 'compute' to be more clear. After some conversations with @pcarruscag Ive also added some 'const' to some 'get' functions. More work can be done in this regard, and that process is ongoing. I can continue doing so in this PR, or in a future one.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1111#issuecomment-730849653:58,clear,clear,58,https://su2code.github.io,https://github.com/su2code/SU2/pull/1111#issuecomment-730849653,1,['clear'],['clear']
Usability,"I've run into some headaches getting the optimization to run efficiently on my end, which is why I ask. Playing with a toy problem, SLSQP actually does a great job on its own (with all tuning parameters set to 1.0) if the following conditions are met:. + The constraints and bounds effectively bound ""reasonable"" solutions, so you don't have to worry about unrealistic deformations.; + The optimization function is (relatively) convex. If those conditions are met, then playing with any of the tuning parameters makes SLSQP converge more slowly, sometimes with 10x the iterations. So its not clear to me when the tuning parameters are necessary, and how those tuning parameters affect the convergence in those cases. I'm not arguing that the tuning parameters aren't necessary, just that their effects aren't clear. And I agree, the proper way to nondimensionalize and regularize these problems is not clear from a brief search of the literature.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/733#issuecomment-616825497:592,clear,clear,592,https://su2code.github.io,https://github.com/su2code/SU2/issues/733#issuecomment-616825497,3,['clear'],['clear']
Usability,"If you _must_ use `restart_flow.dat`, then look at np.genfromtxt and the `invalid_raise` option. Here's a simple example:. ```python; import numpy as np; import matplotlib.pyplot as plt. data = np.genfromtxt(""solution_adj_combo.dat"", names=True, invalid_raise=False). plt.tricontourf(data[""x""], data[""y""], data[""Adjoint_Density""]); plt.show(); ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/787#issuecomment-528493781:106,simpl,simple,106,https://su2code.github.io,https://github.com/su2code/SU2/issues/787#issuecomment-528493781,1,['simpl'],['simple']
Usability,"If you don't mind I'll leave this question open for now.; I'm planning to provide a simplified example setup later on, once I've had time to properly dive into the wrapper API.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1553#issuecomment-1071052958:84,simpl,simplified,84,https://su2code.github.io,https://github.com/su2code/SU2/issues/1553#issuecomment-1071052958,1,['simpl'],['simplified']
Usability,"If you look at the testing history, commit 4f5f3ed doesn't pass the regression tests, while commit 8551cac does. Only two tests are failing on 4f5f3ed: `discadj_topol_optim` and `discadj_fsi_airfoil`. The difference between the two commits is a simple change. I changed the `SU2_MPI::Error` routine to give a return status of `EXIT_FAILURE` instead of `0`. Since `0` is conventionally defined as a successful program exit, returning `EXIT_FAILURE` makes more sense than returning `0` when `SU2_MPI::Error` is called. So why did that change cause the regression tests to fail? My suspicion is that these two tests have been exiting with an error for some time, but these regressions were not picked up by Travis since SU2 kept on returning `0` (i.e. success). Changing the exit code of `SU2_MPI::Error` doesn't cause any errors, but it will expose errors that are (sometimes silently) occurring. @pcarruscag I think you added these tests. Any idea why they're failing?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/649#issuecomment-462951152:245,simpl,simple,245,https://su2code.github.io,https://github.com/su2code/SU2/pull/649#issuecomment-462951152,1,['simpl'],['simple']
Usability,If you run the code with enabled mpi support SU2_CFD will only write the restart files. You need to use SU2_SOL to convert them to .vtk. Therefore simply copy the restart_flow.dat to solution_flow.dat and run SU2_SOL. Or you could just use the parallel_computation.py script that does this automatically.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/173#issuecomment-99219314:147,simpl,simply,147,https://su2code.github.io,https://github.com/su2code/SU2/issues/173#issuecomment-99219314,1,['simpl'],['simply']
Usability,If you share the mesh I should be able to give better guidance.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1519#issuecomment-1019359579:54,guid,guidance,54,https://su2code.github.io,https://github.com/su2code/SU2/issues/1519#issuecomment-1019359579,1,['guid'],['guidance']
Usability,"If you'd like me to revert the changes updating the autotools version and/or removal of auto-generated files, just let me know (you can also simply revert the last few commits for the same effect).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/586#issuecomment-427689344:141,simpl,simply,141,https://su2code.github.io,https://github.com/su2code/SU2/pull/586#issuecomment-427689344,1,['simpl'],['simply']
Usability,"In the lab we are also writing/rewriting another largish solver with eigen (https://ic-sharpy.rtfd.io/). A major advantage (and, I think, critical for open source) was code readability to ease the learning curve for newcomers, with no reported penalty on performance. I second all the other nice things about it written by @pcarruscag.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/643#issuecomment-459943384:197,learn,learning,197,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459943384,1,['learn'],['learning']
Usability,"Indeed, this helps, but it could be more general, since you only get to see this in the console output. I was thinking that a simple tag in the optimization history file for the evaluations that are 'major' would make this much simpler (and easier to post-process).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/108#issuecomment-102168908:126,simpl,simple,126,https://su2code.github.io,https://github.com/su2code/SU2/issues/108#issuecomment-102168908,2,['simpl'],"['simple', 'simpler']"
Usability,Is there a simple example to reproduce the issue?,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/2109#issuecomment-1776057496:11,simpl,simple,11,https://su2code.github.io,https://github.com/su2code/SU2/pull/2109#issuecomment-1776057496,1,['simpl'],['simple']
Usability,"It does output the file, Paraview & Tecplot formats (binary & ASCII) both work. However, I need the raw data as I will be subjecting it to a Machine Learning Algorithm in Python. Manually deleting the lines for cell numbers in Tecplot format is an additional time consuming step, that hinders full automation. Hence a simple file as flow.csv (CSV format) may help me run it more efficiently. 1. Ganti, Himakar & Khare, Prashant. (2018). Spatio-Temporal Prediction of Gaseous and Liquid Spray Fields using Machine Learning. 10.2514/6.2018-4760. . 2. Ganti, Himakar & Kamin, Manu & Khare, Prashant. (2019). Design Space Exploration for Vaporizing Liquid Jet in Air Crossflow using Machine Learning. 10.2514/6.2019-2211.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/787#issuecomment-528453362:318,simpl,simple,318,https://su2code.github.io,https://github.com/su2code/SU2/issues/787#issuecomment-528453362,1,['simpl'],['simple']
Usability,"It would simply take some reorganizing of the test scripts to make one function per case and maybe renaming the `TestCase` class to `RegressionTestCase` or something. For example, I rewrote one of the tests in `serial_regression.py` here: https://github.com/petebachant/SU2/commit/fe0ee432c67540067046fbebf9889660331a6592. Then I could run this with. $ cd TestCases; $ pytest serial_regression.py. the output from which was:. ```; $ pytest serial_regression.py; ======================= test session starts =======================; platform linux -- Python 3.6.3, pytest-3.2.1, py-1.4.34, pluggy-0.4.0; rootdir: /home/pete/SU2/TestCases, inifile:; collected 1 item. serial_regression.py . ====================== warnings summary =======================; serial_regression.py::TestCase; cannot collect test class 'TestCase' because it has a __init__ constructor. -- Docs: http://doc.pytest.org/en/latest/warnings.html; =============== 1 passed, 1 warnings in 92.18 seconds ==================; ```. `pytest` has a bunch of features to control the print output as well.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/462#issuecomment-342677051:9,simpl,simply,9,https://su2code.github.io,https://github.com/su2code/SU2/issues/462#issuecomment-342677051,1,['simpl'],['simply']
Usability,"It's not always the case that using a restart file is continuing from a simulation. For example, if one has a simulation that has a similar solution as a seed. An example would be doing optimization and using a nearby flow solution. Here, having the iteration count start from zero is useful, because it's the more accurate measure. We would also have to this about how this interfaces with MAX_ITER. Right now it's really clear, but which does it mean when iterations don't start from zero?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/99#issuecomment-103239930:423,clear,clear,423,https://su2code.github.io,https://github.com/su2code/SU2/issues/99#issuecomment-103239930,1,['clear'],['clear']
Usability,"It's not required fo initialization. Ok, if it's not going to work in this way let's start a discussion about a proper way to do this. I will create a new PR for just the initialization example and put it in a regression test. Thanks for the feedback.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1960#issuecomment-1464935230:242,feedback,feedback,242,https://su2code.github.io,https://github.com/su2code/SU2/pull/1960#issuecomment-1464935230,1,['feedback'],['feedback']
Usability,"Just my 2¢ here. I've been struggling with a relatively simple simulation, Euler, 2D axisymmetric, supersonic, AUSM (SU2 7.5.1). I tried several meshes (and meshers) and always diverged no matter what (quality is ok, CFL as well). Conditions were ok, and were mimicking inv_wedge tutorial (which, btw was running ok even with axisymmetry ON). Long story short, I opened with a text editor the original geometry STEP file, and noticed it was carrying from the CAD some (engineering wise negligible) numerical terms (say, point 0, 0 was actually 0, 1e-6). Hence the symmetry axis was somewhat off. By correcting the STEP file, everything went fine. I wonder whether this is the expected behavior of this kind of simulation, and / or if there is any artificial diffusion parameter (such as ENTROPY_FIX_COEFF) that actually can sort things out for the EULER mode. Did any of you experienced anything similar?. Thanks!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1373#issuecomment-1464335191:56,simpl,simple,56,https://su2code.github.io,https://github.com/su2code/SU2/issues/1373#issuecomment-1464335191,1,['simpl'],['simple']
Usability,"Just to clarify things, I am not against pull requests with a lot of changes, @fpalacios. For me the problem in #412 is simply the fact that everything is included in one commit.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/413#issuecomment-316343468:120,simpl,simply,120,https://su2code.github.io,https://github.com/su2code/SU2/pull/413#issuecomment-316343468,1,['simpl'],['simply']
Usability,"KER_MONITORING, MARKER_DESIGNING: The main idea is to be able to compute to different integrals over the surfaces: one for simulation and the other for design. e.g. You maybe want to include all the solid surfaces and fan faces, and charging stations in MARKER_MONITORING to compute (Drag-Thrust) but in MArKER DESIGN you are only interested on the wing surface for design.; > ; > DV_MARKER. This is an unfortunately name. At the very beginning the mesh deformation capability was developed only for shape design (DV = Design Variables). We should generalize the names of the grid deformation parameters without using DV. Thanks!; Francisco. On Aug 18, 2015, at 4:31 AM, Heather Kline notifications@github.com wrote:. > Thanks Tom; > I agree that we should make things easy to understand. ; > My thinking was that most users will want to know what parts of the mesh they are moving, but don't necessarily need to know what's happening underneath - if they specify the entire mesh the code just reverts to the more efficient method. But (from the users perspective) it may be just as easy to have a separate specification for scaling the entire mesh.; > ; > In terms of moving it to SU2_MSH; I think it may make sense to include scale/rotate/translate in SU2_MSH, but I think it would be confusing to have two options that do the same thing. I would side with separate option names (this would also eliminate a loop over markers in this pull request); > ; > On this topic, I have sometimes found MARKER_DESIGNING and DV_MARKER to be confusing; on their own they sound very similar, in the description MARKER_DESIGNING is where the objective function is evaluated - but in the code, it's not clear what MARKER_DESIGNING does - the surfaces specified by MARKER_MONITORING are what are actually used to evaluate the objective function value.; > ; > There may be other similar areas where config file options could be clarified or compressed.; > ; > —; > Reply to this email directly or view it on GitHub.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/187#issuecomment-133010923:2146,clear,clear,2146,https://su2code.github.io,https://github.com/su2code/SU2/pull/187#issuecomment-133010923,1,['clear'],['clear']
Usability,"LGTM. Thanks for the fix and updating all regressions, @TobiKattmann . Final question: in the end, the Euler and symmetry BCs are identical implementations, so do we have a practical guideline for when to use one or the other (or some error check), or will we just carry both and allow them to be used interchangeably?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/740#issuecomment-536752462:183,guid,guideline,183,https://su2code.github.io,https://github.com/su2code/SU2/pull/740#issuecomment-536752462,1,['guid'],['guideline']
Usability,"Let's continue this here @suargi as it should be more visible for everyone. In principle, I like what you suggest, it is clean and concise.; However, I see one big issue with backwards compatibility of the config. KIND_TURB_MODEL is in almost every config (in the world) and we cannot simply break compatibility, something with this much impact would require SU2 v8 :smile: . This is not to say you could not implement what you propose, just that you need to make it compatible with the status quo.; For example:; KIND_TURB_MODEL= SA-NEQ; QCR= YES; (I'm not even sure if that makes sense but anyway); Needs to be converted internally to:; KIND_TURB_MODEL= SA; TURB_MODEL_CORRECTIONS= SA-NEG, SA-QCR2000. And of course, if someone uses the new option TURB_MODEL_CORRECTIONS you can enforce that KIND_TURB_MODEL only contains NONE, or SA, or SST, and that corrections do not appear in the config in any other way.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1364#issuecomment-907388593:285,simpl,simply,285,https://su2code.github.io,https://github.com/su2code/SU2/issues/1364#issuecomment-907388593,1,['simpl'],['simply']
Usability,"Let's keep the dimensional outputs, we are already trying to have dimensional inputs to keep things simple.; In the longer term we should aim to have dimensional inputs and outputs and make the non-dimensionalization an internal detail of the solvers that users don't have to worry with.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/2109#issuecomment-1684078599:100,simpl,simple,100,https://su2code.github.io,https://github.com/su2code/SU2/pull/2109#issuecomment-1684078599,1,['simpl'],['simple']
Usability,Lots of different updates have been done to incorporate all feedback and make improvements to this PR. It seems to be in a solid place to be merged with develop. @pcarruscag @talbring,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1014#issuecomment-663934671:60,feedback,feedback,60,https://su2code.github.io,https://github.com/su2code/SU2/pull/1014#issuecomment-663934671,1,['feedback'],['feedback']
Usability,"Mate... I graduated from the school of ""out of the scope of"" with honors ok... You and I know that is just code for ""I'll leave it for someone else"".; Just cut and past the parts of the implementation that are exactly the same as another scheme into a function instead of copying, and given that other NEMO schemes have Jacobians that is probably something you should look into re-using.; You also clicked the box for having added a testcase but I don't see anything, why don't you add the testcase for the pictures and plots you showed? That is the only way for anything in this code to continue working... It's good work, it went into a paper, make it reproducible.; These are the contribution guidelines https://su2code.github.io/docs_v7/Style-Guide/ they may not always make things easier for authors, but they make it easier for the people coming after them.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1773#issuecomment-1276409765:696,guid,guidelines,696,https://su2code.github.io,https://github.com/su2code/SU2/pull/1773#issuecomment-1276409765,1,['guid'],['guidelines']
Usability,"Maybe CNumerics is not the perfect place, but it is good enough for government work (there are much more misplaced things in there). The ""everything is class"" OO approach applied to the lowest level of abstraction is... well I think it is terrible -- and it has taken me a mighty long time to get rid of it in CPoint and CVariable and to design alternative Numerics -- because:; - Boilerplate: Set this, get that, constructor, destructor;; - Thread safety: Those classes always end up having some mutable state that renders them thread-unsafe;; - Correctness: Many of the classes we have follow this paradigm of ""pass by member variable"" - I like to know what are the inputs and outputs of something just by looking at the signature;; - Slowww: Too much virtual;; - Unnecessary complexity: A case of using a canon to kill the mosquito, good code should be as simple as possible, if a function does the job then that is the level of abstraction we should use. My introduction to C++ was also the ""everything is class"", then one day I read ""From Mathematics to Generic Programming"" and well, I started liking C++ a whole lot more.; The standard template library is incredibly successful, and it ""just"" provides some containers and generic algorithms which are functions. That is what we need in SU2, some decent containers and generic algorithms to operate on them. OO and its patterns are very good high level tools to achieve encapsulation and to isolate code, which are very important for projects with millions of lines of code, but for low level things they are overkill. Sorry for the rant, I guess I have strong feelings about tiny classes.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1127#issuecomment-742629412:859,simpl,simple,859,https://su2code.github.io,https://github.com/su2code/SU2/pull/1127#issuecomment-742629412,1,['simpl'],['simple']
Usability,Maybe also an explanation why I specifically state `single straight`:; Take a case with two symmetry planes on either side of a channel -> it could be reasonable to put both in the same Marker in the su2 mesh -> both planes are straight for themselves but as I simply loop over all nodes in a marker I then have 2 different unit normals for the same marker -> thats why the specific `single` is used,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/740#issuecomment-537206528:261,simpl,simply,261,https://su2code.github.io,https://github.com/su2code/SU2/pull/740#issuecomment-537206528,1,['simpl'],['simply']
Usability,"Merge and push is simpler I think, and with that the reviewers have the option of only seeing the new commits.; Thanks for the changes, we'll merge once the tests pass.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1951#issuecomment-1470769800:18,simpl,simpler,18,https://su2code.github.io,https://github.com/su2code/SU2/pull/1951#issuecomment-1470769800,1,['simpl'],['simpler']
Usability,"Nice analysis @clarkpede. It is true that we simplify the Jacobians at the periodic boundaries, mostly to avoid issues with adding entries to the Jacobian from the neighbors that potentially do not live on our rank and to keep communication costs low (those neighbors are treated explicitly). This could be changed to communicate the full Jacobian.. but I am not sure it is worth the effort/cost. The approximation that is made should still be consistent though, because we only allow one of the repeated periodic nodes to participate in the linear solve with each nonlinear iteration, and then we communicate its update to its periodic pair. In short, the value of the solution should always be the same on periodic points with each iteration update, and if the problem converges to a steady-state (even in time stepping mode), the Jacobian should only affect convergence (the RHS should be the same). You could try the time stepping option with one of the RK methods to see if going fully explicit helps further isolate the issue. It could also be something related to the time step that is communicated. In the SetTime_Step() routine in the flow solver class, we do some special checks for time stepping mode to make sure that the minimum global time step is used in all cells. Might want to print out the dT communicated in the periodic comms or write the dT to the solution file to make sure everything is ok there too. Honestly, I don't think a ton of folks use the time stepping option in general with the FVM solver, so double-checking that it behaves well for a non-periodic problem could shed some light too, unless you have already done that.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/763#issuecomment-524007345:45,simpl,simplify,45,https://su2code.github.io,https://github.com/su2code/SU2/issues/763#issuecomment-524007345,1,['simpl'],['simplify']
Usability,"Nice progress @pcarruscag!. I like the concept of your SIMD-friendly class that will take care of the data structure under the hood coupled with a standard type of loop statement (w/ +SIMDLEN). This should make it pretty easy for folks to still modify the kernels without having to worry about the data alignment, and they can reuse the same simple 'for' construct repeatedly. . Another reason to have our own lightweight class for this is that you can avoid dependence on OpenMP for SIMD (although that feature looks to have potential and wasn't available until somewhat recently) as well as the intrinsics. In my experience, the latter is especially bad for portability and readability (part of why we left the CaF work in a separate repo). It starts to become so specialized that compiling and modifying become difficult. W.r.t. OpenMP, another roadblock there a few years ago was making sure it is interoperable with CoDi for the adjoint, but I know this has been worked on and may be available by now. Might keep an open mind about point vs. edge. In some places, we may be able to pump up the compute in our loops by fusing kernels, as previously discussed (and I am guessing you are working on this already with gradients/limiters). Could change the final performance numbers significantly. Lastly, I know you are not there yet, but it is worth considering whether you can reuse anything you are developing in the kernels here for the linear solver routines. At some point, you will successfully reduce the cost of the residual kernels (RHS) to the bandwidth limit, and the majority of the iteration cost will be in the linear solver (it is already about 50% of the iteration cost before optimization, if I recall). Before making final decisions on strategy, you should consider if it will help in any of the linear solver routines too.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-530440072:342,simpl,simple,342,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530440072,1,['simpl'],['simple']
Usability,"No need for Intel buddies, I know what's up. Take [this code:](https://gcc.godbolt.org/z/siQamn); ```; class Base {; public:; inline virtual double get() const {return 0.0;}; };. class Derived : public Base {; double val;; public:; Derived(double a) : val(a) {}. inline double get() const final {return val;}; };. double fun1(Base* obj) {; return obj->get();; }. double fun2(Base* obj) {; return static_cast<Derived*>(obj)->get();; }; ```. `get` of derived has been marked `final` so in `fun2` polymorphism should be optimized away. Here is the assembly for gcc 5.4:. ```; fun1(Base*):; mov rax, QWORD PTR [rdi]; jmp [QWORD PTR [rax]]; fun2(Base*):; movsd xmm0, QWORD PTR [rdi+8]; ret; ```; `fun1` needs a jump, `fun2` knows what to return right away. Here is the assembly for icc 17:; ```; fun1(Base*):; mov rax, QWORD PTR [rdi] #16.12; mov rdx, QWORD PTR [rax] #16.12; jmp rdx #16.12; fun2(Base*):; mov rax, QWORD PTR [rdi] #20.34; mov rdx, QWORD PTR [rax] #20.34; jmp rdx #20.34; ```. @vdweide please tell me you did not use icc 19, because it performs this optimization just fine on this simple example. By the way @talbring (since you asked in #753), take away the `final` keyword and nothing gets optimized by the `static_cast`.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/716#issuecomment-523952473:1092,simpl,simple,1092,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-523952473,1,['simpl'],['simple']
Usability,"No, I think we're all set. I am going to merge this in. We have two issues that we are going to be clearing up very soon: the ONERA M6 adjoint case that is failing somewhat irregularly, and a reorganization of the test cases/config files to make the regression tests more effective (in particular for pull requests). Thanks for fixing the conflicts!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/186#issuecomment-127486074:99,clear,clearing,99,https://su2code.github.io,https://github.com/su2code/SU2/pull/186#issuecomment-127486074,1,['clear'],['clearing']
Usability,"No… I can’t. I’m sorry. Great to hear from you. Machine learning is a very valuable research work and I will add it as a feature branch. . Removing code from the main release is a complex task and, as in the past, I have taken tough decisions. Anyway, to maintain a clean code is critical for its growing, it is like trimming a large tree. Basic criteria to maintain forever an implementation on the develop->master branch are: - Clear benefit to the CFD community (more accurate, robust, etc.) - Existing community of users or active developers - Minimal code documentation (at least the options should be in the config file). - Easy to install and use. - The implementation style should be aligned with the SU2 style - Regressions tests. Best,; Francisco. > On Oct 28, 2015, at 11:35 PM, Brendan Tracey notifications@github.com wrote:; > ; > Could you leave in the machine learning section a bit longer?; > ; > —; > Reply to this email directly or view it on GitHub https://github.com/su2code/SU2/pull/208#issuecomment-152095697.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/208#issuecomment-152384158:56,learn,learning,56,https://su2code.github.io,https://github.com/su2code/SU2/pull/208#issuecomment-152384158,2,['learn'],['learning']
Usability,"OK the failing regression test were due to:; 1. One simple wrong function call in Csolver; 2. Creating new output in existing groups (AERO_COEFF, FLOW_COEFF) which invalidates some regression tests; 3. pyhton code which does not test if some config variable is present or altering the python code such that it invalidates other regression tests; 4. and finally the AVG_TEMP thing above. Now all these alone were somewhat minor things. Feature_flamelet is now up-to-date with develop with all regression test working",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1223#issuecomment-898617272:52,simpl,simple,52,https://su2code.github.io,https://github.com/su2code/SU2/pull/1223#issuecomment-898617272,1,['simpl'],['simple']
Usability,"Obviously it is possible to implement this, but it would significantly complicate the config parsing code. Right now the parser is very simple: Go through each line, and get the name and the tokens. As far as I can see there aren't good ways to allow this aside from either having a whitelist of options that can go on multiple lines (thus, only some options are allowed to do so), or to switch up the config file entirely and go to a more standard format like JSON.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/166#issuecomment-103241030:136,simpl,simple,136,https://su2code.github.io,https://github.com/su2code/SU2/issues/166#issuecomment-103241030,1,['simpl'],['simple']
Usability,"Of the two cases with larger residual changes:; - contadj_euler_naca0012 - No idea why they changed, neither primal nor adjoint compute limiters... the primal residuals are unchanged, and the case converges to the same values (residuals and solution) so I simply updated the residuals; - transonic_stator_restart - As shown above the case is fine, so I updated the restart file, however I do not know how to change the testcases branch anymore :) but I guess once the corresponding PR is merged this will start passing. I ran some other tests with the Venkatakrishnan-Wang limiter (which requires a global min/max) and is does not seem to be covered by the tests ATM (maybe I'll use that restart case to fix that), everything looks perfect, same results with different ranks/threads and so on, the results are tens of MB so I won't upload unless someone wants to double check.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/834#issuecomment-575310823:256,simpl,simply,256,https://su2code.github.io,https://github.com/su2code/SU2/pull/834#issuecomment-575310823,1,['simpl'],['simply']
Usability,Ok thats to be expected (as I learned) because you have probably openmpi installed. The binaries are compiled with mpich.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/813#issuecomment-557430771:30,learn,learned,30,https://su2code.github.io,https://github.com/su2code/SU2/pull/813#issuecomment-557430771,1,['learn'],['learned']
Usability,"Ok the ""simple"" version of ""going parallel"" whenever we get to a linear algebra operation did not make the cut.; On an older architecture there was a 10% slowdown of the linear solvers at ~10k nodes per core and about the same on a newer architecture but only at ~1k node per core.; Since hybrid parallel is supposed to be good for strong scaling, this was not good enough... With the new strategy it is ok (see ""performance"" below), hence this is ready for review. ### Overall Strategy; The strategy now is to start a parallel section in CSysSolve::Solve that covers building the preconditioner and solving the linear system.; Linear algebra routines called within this section have _worksharing_ constructs instead of _parallel_ ones, i.e. the work is distributed by however many threads arrive to that routine. This also makes the routines safe to call in serial.; The only ""dangerous"" things to do in parallel are to: manage memory for a shared object (multiple threads call `new` but there is only one shared pointer on which to call `delete`); writing to the same memory locations concurrently.; I tried to make the first issue debugable by asserting that the initialization routines of CSysMatrix and CSysVector are only called by the master thread.; For the second issue I made the associated classes as const-correct as possible, that should at least make someone think twice before changing a member variable of those classes. The risk is still there for input variables as an algorithm development aspect... For example `MatrixVectorProductTransposed` cannot be made thread-parallel as simply/naively as its normal counterpart. ### Communication Model; The MPI + Threads communication model is very simple, currently only the master thread calls MPI routines (including `Error`), this requires thread barriers before and after the communication to make sure the correct values are passed and _seen_ by all threads.; We can test other alternatives in the future but at the moment this does n",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/830#issuecomment-562646766:8,simpl,simple,8,https://su2code.github.io,https://github.com/su2code/SU2/pull/830#issuecomment-562646766,1,['simpl'],['simple']
Usability,"Ok! The workflow about this branch is now quite hard to follow. ; So to resume :; - **#424 is the branch to work on**. #424 is ""py2_and_py3_support"" merged on a recent ""develop"" branch (2017/08/11); - #260 is obsolete and replaced by previous one. That is why I close it",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/260#issuecomment-323942805:72,resume,resume,72,https://su2code.github.io,https://github.com/su2code/SU2/pull/260#issuecomment-323942805,1,['resume'],['resume']
Usability,"Ok, I went back to try varying the `.cfg` settings on the simple v7.0.3 repo `TestCases/euler/naca0012` case and managed to get `mesh_adaptation_amg.py` to run successfully. It seems that one bit of advice [from here](https://www.cfd-online.com/Forums/su2/214613-grid-adaptation-options.html) is no longer true, i.e. one needs to set:; ```; % Write binary restart files (YES, NO); WRT_BINARY_RESTART= YES; %; % Read binary restart files (YES, NO); READ_BINARY_RESTART= YES; ```; in order for the amg mesh adaptation to function. However, for some reason, I can't get it working for my actual mesh of interest. When using the same settings, I get a different ParMETIS error (from the `adap/ini/log.out`):; ```; ------------------- Geometry Preprocessing ( Zone 0 ) -------------------; Three dimensional problem.; 4929018 grid points before partitioning.; 7406196 volume elements before partitioning.; 3 surface markers.; 18040 boundary elements in index 0 (Marker = BODY).; 50968 boundary elements in index 1 (Marker = FARFIELD).; 284054 boundary elements in index 2 (Marker = SYMMETRY).; Executing the partitioning functions.; Building the graph adjacency structure.; [ 1] ***ASSERTION failed on line 207 of file ../externals/parmetis/libparmetis/comm.c:sendind[i] >= firstvtx && sendind[i] < lastvtx; [ 1] 361316 123226 246452; [1609857970.901920] [super:1060888:0] sock.c:344 UCX ERROR recv(fd=62) failed: Connection reset by peer; ```. The only difference that I can think of is that my flow is fully supersonic and my mesh is an unstructured core with a structured collar - might this be causing the issue? Kind regards.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/948#issuecomment-754686447:58,simpl,simple,58,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-754686447,1,['simpl'],['simple']
Usability,"Ok, so to be clear, if you take a fresh directory, place the restart file there and run the code, will it still have this issue?; It sounds like this does not have anything to do with writing, but reading instead... :thinking:",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1342#issuecomment-891991181:13,clear,clear,13,https://su2code.github.io,https://github.com/su2code/SU2/pull/1342#issuecomment-891991181,1,['clear'],['clear']
Usability,"Ok, sounds good. I'll go ahead and close this since it is being replaced by the other pull request. ; Since you mention formatting, [here](https://github.com/su2code/SU2/wiki/Style-Guide) is our style guide for reference. I think you are probably right that there are places where it is not strictly followed, and if you would like to spend the time to fix those things that would be welcome. Thanks again for the pull request.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/331#issuecomment-261699279:201,guid,guide,201,https://su2code.github.io,https://github.com/su2code/SU2/pull/331#issuecomment-261699279,1,['guid'],['guide']
Usability,"Ok. Thanks for the reply. If it's not simple to separate into a branch, don't worry. I have already downloaded the current master and can maintain a local copy. I see that there is at least one issue related to that segment (I would have responded had I seen it). Are users interested in using that segment of the code? If so, I'd be more than happy to add documentation and a usage example I the develop branch. When thus code went live we decided it was better to not add documentation since the feature is experimental. This is certainly a fixable situation on the develop branch.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/208#issuecomment-152404327:38,simpl,simple,38,https://su2code.github.io,https://github.com/su2code/SU2/pull/208#issuecomment-152404327,1,['simpl'],['simple']
Usability,Ok.. thanks for the feedback. We'll go ahead with the current version (handled like the --enable-mpi option) for now.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/298#issuecomment-240882029:20,feedback,feedback,20,https://su2code.github.io,https://github.com/su2code/SU2/pull/298#issuecomment-240882029,1,['feedback'],['feedback']
Usability,Okay @pcarruscag I believe ; I reverted all the annoying format changes. Can you please review the code when you get the chance?. BTW I am aware about the boilerplate code in `python_wrapper_structure.cpp` and I plan to adapt `CPyWrapperMatrixView`. Would appreciate some feedback anyways,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1750#issuecomment-1779150012:272,feedback,feedback,272,https://su2code.github.io,https://github.com/su2code/SU2/pull/1750#issuecomment-1779150012,1,['feedback'],['feedback']
Usability,"On both questions the answer is yes. Option 1 can be implemented right now but will require the creation of temporary objects. Option 2 can directly forward the data to the blas routines. The tool I am developing is no tool for a specific linear algebra package. The idea is, that the tool parses the header files of the library. The user has then to define which objects are active lvalues and the derivatives for each operation in the library. For small an clear interfaces this is no problem and works already quite good. For large libraries like Eigen I adopted a whitelisting approach. That is, every function needs to be manually whitelisted to trigger the expression generation of the tool. In a prototype way I have also implemented an approach where only the active lvalues need to be defined and the tool looks then for all required functions and other objects that depend on these active objects. Long story short, the tool is designed to handle ""any"" library. It is even possible to mix several libraries together. My current status on this project is, that I am now through with the parsing of the header files and the generation of the expressions. This works quite well for Eigen which is a hardcore testcase, since every possible programming tweak in C++ is used here. The next step is to add the AD part to the expression generation process. I hope that in one or two month this will be finished and I can provide a first beta release.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/643#issuecomment-463561018:459,clear,clear,459,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-463561018,1,['clear'],['clear']
Usability,"On the subject of virtual functions I would like to put another idea forward.; After moving things around in #725 I noticed that we have tons of `inline virtual` methods.; The keyword `inline` has two meanings to the compiler:; - ""Dear merciful compiler please copy paste the body of this function and then do all your wonderful optimizations, if that pleases your excellency.""; - ""Dear forgiving compiler, you will find this method defined in multiple units, please don't be mad"" (i.e. ignore the one-definition-rule). `virtual` means determine what version of the method to call at runtime. This is not compatible with the first (and often the intended one) meaning of inline, therefore the compiler will in general not inline those methods.; They will only be inlined if they are being called on a pointer to the derived class that does not declare the method to be virtual anymore. CSolver knows what variables it creates and so in hot areas of the code it could do a static downcast to allow inlining (e.g. `static_cast<CEulerVariable*>(node[iNode])->DoStuff()`).; Where is this important? For example when computing gradients, where simple additions and subtractions are hidden behind virtual functions.; If you are worried about maintenance each solver can typedef its most safe downcast level or better yet (or just more modern), methods that could benefit from this can be templated for the type of downcast.; Those in favour say Yea those against say Nay.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/716#issuecomment-509273008:1139,simpl,simple,1139,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-509273008,1,['simpl'],['simple']
Usability,"One of the interesting paper -. "" Comparison of numerical and Analytical Jacobians"", Kirk J. Vanden, Paul D. Orkwis; AIAA, Vol 34, No. 6, June 1996. They computed the exact analytical Jacobian with symbolic manipulation. In conclusion they are showing that both analytical and numerical Jacobians showed similar performance and suggesting that for simpler numerical fluxes, analytical Jacobians should be the best way to go and for complex numerical fluxes, numerical Jacobian can be preferable choice (but if one can work out analytical, that should be good as well, I guess (one time effort) ). Best; Amit",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/691#issuecomment-505615012:348,simpl,simpler,348,https://su2code.github.io,https://github.com/su2code/SU2/pull/691#issuecomment-505615012,1,['simpl'],['simpler']
Usability,"Overall some solid looking code @jayantmukho, thanks!; I have a few suggestions:; 1 - Some of the config variables have fairly broad names, ""permute"" for example, I think prefixing them with UQ would more clearly identify what they are meant for.; 2 - There are a lot of dynamic allocations of static size, if the current implementation is compatible with 2 and 3 dimensions I would allocate those variables statically, makes for cleaner and faster code (stack allocations are much faster and subsequent loops would likely be unrolled by the compiler).; 3 - It looks like some of the new methods in CNumerics are for generic ""Eigenvalue-stuff"" for re-usability I suggest moving those methods to a helper class, even if for now that class becomes just a collection of static methods. In the implementation of those methods the dimension of the inputs is being assumed, if you do move them please make them generic.; Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/570#issuecomment-427468893:205,clear,clearly,205,https://su2code.github.io,https://github.com/su2code/SU2/pull/570#issuecomment-427468893,2,"['clear', 'usab']","['clearly', 'usability']"
Usability,"Please see the response on the [forum](https://www.cfd-online.com/Forums/su2/184789-poor-quality-mesh-after-deformation-su2-5-0-0-a.html#post640783).; In the future, please note that it is [recommended](https://www.cfd-online.com/Forums/site-help-feedback-discussions/175429-guide-how-ask-question-forums.html#post612025) not to double-post questions.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/384#issuecomment-286555388:247,feedback,feedback-discussions,247,https://su2code.github.io,https://github.com/su2code/SU2/issues/384#issuecomment-286555388,2,"['feedback', 'guid']","['feedback-discussions', 'guide-how-ask-question-forums']"
Usability,Problem solved. Script Workshop now. Just a simple DOS/Windows-Unix fileformat error. -.-,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/279#issuecomment-222963559:44,simpl,simple,44,https://su2code.github.io,https://github.com/su2code/SU2/issues/279#issuecomment-222963559,1,['simpl'],['simple']
Usability,"Quite simple I imagine.; Since I have everything in place now to open, manipulate and export the mesh in SU2 format (c.f. #1877 ) I could easily filter points and assign their IDs to arbitrary markers or elements or simply export their ID to a different file.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1894#issuecomment-1396188450:6,simpl,simple,6,https://su2code.github.io,https://github.com/su2code/SU2/issues/1894#issuecomment-1396188450,2,['simpl'],"['simple', 'simply']"
Usability,"Regarding periodic boundaries: You have two options. You can hack the code to not allow grid deformation on periodic boundaries. That's a simple code edit, since the code already prevents most boundaries from being deformed. Let me know if you want to use this option, and I can point you to those lines. Second, you can use the `HOLD_GRID_FIXED` and `HOLD_GRID_FIXED_COORD` options to prevent grid deformation outside a specific box. I have found this option to be better overall, since it also makes the linear system easier to solve in `SU2_DEF`. The `DV_VALUE` and `FINDIFF_STEP` are different. I've only seen `FINDIFF_STEP` used for the finite-differencing python script, though it may have other uses I am not aware of. The `DV_VALUE` depends on the context. When using `SU2_DOT`, `DV_VALUE` is set to its default value. But when performing shape optimization using SU2's framework, the `DV_VALUE` parameters will be set based on the output of SLSQP (or whatever optimization framework you're using).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/976#issuecomment-626799862:138,simpl,simple,138,https://su2code.github.io,https://github.com/su2code/SU2/issues/976#issuecomment-626799862,1,['simpl'],['simple']
Usability,"Reviving the parsing script can be a simple and effective solution for syncing the defaults.; I shall be out of the country for the next three weeks. I shall try my hand at your suggestion once I return. Meanwhile, I hope the current PR will complete its approval cycle. Current Travis failures are marked by ! only.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/520#issuecomment-377499319:37,simpl,simple,37,https://su2code.github.io,https://github.com/su2code/SU2/pull/520#issuecomment-377499319,1,['simpl'],['simple']
Usability,"SU2/commit/ac8b3bf7636cc66ca7f47e15935942a6598e1a9f), the `SetRoe_Dissipation` function checked to see if the sensor values were valid regardless of the type of blending selected. Commit [ac8b3bf](https://github.com/su2code/SU2/commit/ac8b3bf7636cc66ca7f47e15935942a6598e1a9f) changed the behavior to only check the sensor values if they will be used. The unit test sets the convective blending to `NTS`, feeds invalid sensor values into `SetRoe_Dissipation` and checks the output. ```cpp; // Used to set the Roe-low-dissipation option; void WriteCfgFile(unsigned short nDim, const char* filename,; std::string blending) {; std::ofstream cfg_file;. cfg_file.open(filename, ios::out);; cfg_file << ""PHYSICAL_PROBLEM= NAVIER_STOKES"" << std::endl;; cfg_file << ""ROE_LOW_DISSIPATION= "" << blending << std::endl;. cfg_file.close();; }. BOOST_AUTO_TEST_CASE(BadSensorsAllowedForNTS) {. /*--- Setup ---*/. const unsigned short nDim = 3;. /*--- Set up the config class for the test ---*/; char cfg_filename[100] = ""convective_blending_test.cfg"";; WriteCfgFile(nDim, cfg_filename, ""NTS"");; CConfig* config = new CConfig(cfg_filename, SU2_CFD, 0, 1, 2, VERB_NONE);; std::remove(cfg_filename);. /*--- Inputs ---*/; const su2double dissipation_i = 0.4;; const su2double dissipation_j = 0.6;; const su2double sensor_i = NAN; // Intentionally unphysical:; const su2double sensor_j = NAN; // Intentionally unphysical:. /*--- Outputs ---*/; su2double dissipation;. /*--- Test ---*/. CNumerics numerics;; numerics.SetRoe_Dissipation(dissipation_i, dissipation_j,; sensor_i, sensor_j,; dissipation, config);. const su2double tolerance = std::numeric_limits<su2double>::epsilon();; BOOST_CHECK_CLOSE_FRACTION(dissipation, 0.5, tolerance);. /*--- Teardown ---*/; delete config;; }; ```. There's a couple problems I would fix if I had more time. Ideally, I would be writing the cfg file to an in-memory stream and not to a file. And realistically, I shouldn't need to use a config file at all for a simple test like this.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499999225:2297,simpl,simple,2297,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499999225,1,['simpl'],['simple']
Usability,"Sc, @juanjosealonso and @erangit have a point here. Looks like I start to belong to the group of old conservatives as well.... >@economon ; >(...) If you really would like to give PETSc a shot, I recommend talking with @anilvar who had an interface for connecting it to SU2 in one of our branches. >@pcarruscag; >(...) being able to use PETSc or HYPRE would be interesting as it would give us access to AMG, and @talbring 's branch feature_template_linear_solver would make such an integration compatible with AD. (...). >@EduardoMolina; >(...) When Brian (@bmunguia ) and I mentioned PETSc, it was an idea to try a different Newton-Krylov (with preconditioner) library in order to improve the convergence of SU2.; Since the slow convergence of the SU2-FV is the main feedback that I received from other users from industry and academia, I think it worth try an external library and evaluate the performance. (...). >@pcarruscag ; >(...) That is something I am also interested in as for some of my structural cases the current linear solvers simply do not converge. (...). >@economon ; >I would add one practical comment for consideration: it is worth checking whether the main restriction we have is related to approximations in the Jacobian that limit the effective CFL we can use or whether the convergence of the linear solver itself is a problem (speed or complete lack of convergence). A quick test without resorting to another library is to increase the fill-in for ILU-preconditioned GMRES, which is very expensive/slow but should converge difficult problems, and to check how high we can take the CFL when allowing each nonlinear iteration to converge to a tight tolerance in the linear solver, say 1e-14 (you can output the linear solver residuals to verify convergence). If we can take the CFL higher with a more performant linear solver, then it could be worth the effort to try other options.; >If the CFL must remain low for stability, then perhaps we should look at the quality of the J",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/648#issuecomment-460853218:3095,simpl,simply,3095,https://su2code.github.io,https://github.com/su2code/SU2/issues/648#issuecomment-460853218,1,['simpl'],['simply']
Usability,"Simplest is to just copy the saved file again, with an iteration number appended. No keeping track of what the iteration number at the previous write was, no copying of the final saved file with manually appending the final iteration number, no lag of WRT_FREQ in the availability of the restart_xxx.dat file. It does mean that we do a copy instead of a rename. But I think this is the better (because the simplest) solution. I will extend it to the other file options.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1465#issuecomment-1005529868:406,simpl,simplest,406,https://su2code.github.io,https://github.com/su2code/SU2/pull/1465#issuecomment-1005529868,1,['simpl'],['simplest']
Usability,"So I have setup Travis to test both Python versions, but I need to learn a little bit more about automake to setup the `pySU2` Makefile properly to build against the active Python environment. Hopefully getting closer...",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/424#issuecomment-323047764:67,learn,learn,67,https://su2code.github.io,https://github.com/su2code/SU2/pull/424#issuecomment-323047764,1,['learn'],['learn']
Usability,"So I tested this on 4 mesh levels for a NACA0006 at 2.0 degrees AoA, at low (0.6) and high-ish (0.8) Mach number (Roe scheme).; These are the results for low Mach:; ![image](https://user-images.githubusercontent.com/38071223/61968547-3b08c680-afd0-11e9-8aae-9705a9441a00.png); Very small differences between recomputing a mass flux based on primitives (""Reconstructed"") or storing the flux computed during discretization of convection (""Consistent"").; However, the convergence rate for the latter approach is much worse:; ![image](https://user-images.githubusercontent.com/38071223/61968712-99ce4000-afd0-11e9-9c31-dafd7e26e3fb.png); Which makes sense because we are going from a Gauss-Seidel coupling of flow and turbulence to a half GS, half Jacobi (since the turbulence source terms were still computed with current velocity gradients).; After seeing this I only ran one mesh level (second to finest) at high Mach number and again differences were very small and convergence worse.; Some memory would indeed be saved in the discrete adjoint through the reduction of the number of pre-accumulation input variables, but only 30MB out of almost 9GB for a 2D case without MG. In summary the current approach seems to strike a good balance between accuracy, cost, and simplicity.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/721#issuecomment-515535554:1266,simpl,simplicity,1266,https://su2code.github.io,https://github.com/su2code/SU2/issues/721#issuecomment-515535554,1,['simpl'],['simplicity']
Usability,"So just to be clear: In my opinion, after calling SU2Driver.Run() the iteration count should be increased immediately. Now we postpone it in the python scripts, which means we have to add +1 in monitor to get the correct iteration count.; With the current change, Monitor has the correct (imo) behavior.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1960#issuecomment-1464364540:14,clear,clear,14,https://su2code.github.io,https://github.com/su2code/SU2/pull/1960#issuecomment-1464364540,1,['clear'],['clear']
Usability,"Sorry for the late reply! Thanks for all the help, and i am afraid i am using a 7.2.0 version and the newly released version 7.2.1 remains the same code. The problem is just lying on ""delta[iDim] = fabs(coord_j[iDim] - coord_i[iDim]);"" which is also in @TobiKattmann 's code post(thanks for your kind guidance ).; In deed, this part of code should give the credit to @EduardoMolina, and the function is a part of his doctoral thesis(2018) which i just couldnot found a link or doi of. But in this paper(https://www.researchgate.net/publication/318143234; ), he gives the official definition as below without the implementation in above picture.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1462#issuecomment-986239816:301,guid,guidance,301,https://su2code.github.io,https://github.com/su2code/SU2/issues/1462#issuecomment-986239816,1,['guid'],['guidance']
Usability,Sounds good to me. I have been prototyping the multizone driver in the last couple of weeks. It's still in the early stages but it's slowly taking shape. You can find it here:; https://github.com/su2code/SU2/tree/feature_reformat_config. I also outlined some of the changes (particularly in what respects to the config file) in the Dev-society forum: https://su2devsociety.org/forum/?view=thread&id=5 . We could keep the conversation there if you want. Happy to set up a meeting to explain a bit what I have been doing and receive some feedback (and helping hands would also be welcome!) from the different groups.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/528#issuecomment-392061901:536,feedback,feedback,536,https://su2code.github.io,https://github.com/su2code/SU2/pull/528#issuecomment-392061901,1,['feedback'],['feedback']
Usability,"Sounds good, with that it will be easier to reason about when the recording types are created and used, right now someone would have to sit down and reverse-engineer the process.; My intuition is that we can use some of the machinery introduced for multizone (partial tape evaluation) to simplify the recording management.; And just to be clear I am very interested in having this feature in the code for comparison with the FP approach.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1750#issuecomment-1780662970:183,intuit,intuition,183,https://su2code.github.io,https://github.com/su2code/SU2/pull/1750#issuecomment-1780662970,3,"['clear', 'intuit', 'simpl']","['clear', 'intuition', 'simplify']"
Usability,"Sounds good. I applied Pedro's fix to my code (temporarily), and it seems to have cleared up the problem. Thanks guys! Do you want me to close this now, or wait until the PRs are applied to develop?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/956#issuecomment-620142891:82,clear,cleared,82,https://su2code.github.io,https://github.com/su2code/SU2/issues/956#issuecomment-620142891,1,['clear'],['cleared']
Usability,"Sounds like a reasonable optimization, the only other place that handles averages is `COutput::Postprocess_HistoryData`, so this should be a very local change and thus a good first issue. Do you want to give it a go at creating a pull request for this? We can give you some pointers. But it should be simple to modify the `addValue` function to take the window type as argument and only `push_back` for non trivial windows.; Even those could be optimized by caching the sum over n-1 elements, this would avoid traversing the entire history of values when only the last entry is modified during inner iterations.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1545#issuecomment-1037249095:301,simpl,simple,301,https://su2code.github.io,https://github.com/su2code/SU2/issues/1545#issuecomment-1037249095,1,['simpl'],['simple']
Usability,"Sure; If you want to install Su2 version 7.0.0 from scratch, you need python 3.5; atleast; The installation guide says just python 3; One of the functions used in meson.py is only available in python 3.5. On Mon, Feb 3, 2020, 12:51 AM Tim Albring <notifications@github.com> wrote:. > Thanks for opening the issue. Can you give a little bit more details on; > what you mean exactly ?; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/issues/855?email_source=notifications&email_token=AIENZ3WCJDNJV4LP655MB33RA7LI5A5CNFSM4KNO4QLKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEKS7V6I#issuecomment-581303033>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AIENZ3TDY7ZCOS27JO7IYXTRA7LI5ANCNFSM4KNO4QLA>; > .; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/855#issuecomment-581453436:108,guid,guide,108,https://su2code.github.io,https://github.com/su2code/SU2/issues/855#issuecomment-581453436,1,['guid'],['guide']
Usability,"Surprisingly I have found the existing content related to plasma simulation in SU2. Really amazing. Could anyone give me any clues of the correspondent .cfg files? Or help me find the governing equations change which makes the plasma equations different from the neutral gas. ; ; ![image](https://user-images.githubusercontent.com/33152225/61871269-5fef3200-af1b-11e9-82c5-cd8418a6f83c.png). It already seems good enough at considering *E* field, but *B* is omitted. I can strive to supplement the equation. Could anyone give some guidance to me, a newcomer of SU2?. [Stanford University Unstructured An open-source integrated computational environment for multi-physics simula.pdf](https://github.com/su2code/SU2/files/3431264/Stanford.University.Unstructured.An.open-source.integrated.computational.environment.for.multi-physics.simula.pdf)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/741#issuecomment-515010918:531,guid,guidance,531,https://su2code.github.io,https://github.com/su2code/SU2/issues/741#issuecomment-515010918,1,['guid'],['guidance']
Usability,"Thank you @TobiKattmann for your feedback. The idea behind this new regression test config file is as follows:; We should have a test case that triggers the negative part of the SA model. Depending on the flow conditions, geometry and CFD parameters it might be triggered or not. With the previous config file, it was not. ; I think there is already a regression test in SU2 that triggers the negative SA, the `turb_oneram6_nk`. However, I decided to stick to rae2822 airfoil as it is a simpler (faster) case. In order to force the negative part of the SA for the rae2822 in a reasonable amount of iterations for a regression test, I increased the angle of attack. I have removed the multigrid as it might not be stable, but I have not tested though. Anyway, with the current configuration, e.g., convective scheme, CFL number, etc, the solution is not stable and diverges after some iterations, around 15. In that sense, I reduced the number of iterations from 20 to 10. In my opinion, a diverging regression test is not a problem at all as it might not be used as a tutorial, only to verify the integrity of the commit. ""The solution should always diverge to the same results"". If the regression test should converge, let me know and I will update the config file :)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1559#issuecomment-1067926363:33,feedback,feedback,33,https://su2code.github.io,https://github.com/su2code/SU2/pull/1559#issuecomment-1067926363,2,"['feedback', 'simpl']","['feedback', 'simpler']"
Usability,"Thank you @pcarruscag and @kursatyurt for your comments and suggestions! I hope that I understood and applied them as intended, if not, please let me know. This is all new to me and because I'm still learning C++, it took me a few extra commits but now all tests seem to pass :) Have a good weekend!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/2024#issuecomment-1545770617:200,learn,learning,200,https://su2code.github.io,https://github.com/su2code/SU2/pull/2024#issuecomment-1545770617,1,['learn'],['learning']
Usability,"Thank you for all your answers. @economon very good news! I am looking forward this improvement. I will rebase my branch on it. @aerialhedgehog: For first pattern, I didn't thought about this case. Thanks for feedback.; So ok to not change code matching pattern 1. In my own experience, in such cases, I prefer to create a new user friendly module that do all imports. In one hand, users have a very simple module and developers keep all real packages as clean as possible. But in other hand, it is true that there is a bit of duplication and can be confusing for whom exploring code. For pattern 4, yes, if I remember well, It happens only two times. So no need to write an helper function I think.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/246#issuecomment-201337122:209,feedback,feedback,209,https://su2code.github.io,https://github.com/su2code/SU2/issues/246#issuecomment-201337122,2,"['feedback', 'simpl']","['feedback', 'simple']"
Usability,"Thank you for replying while busy preparing the High Lift Prediction Workshop 5. Sorry, I didn't clearly understand. From what I understand, I can suggest another energy equation calculating method instead of the current SU2 method(reading calculated TKE from inlet boundary condition and using it as an energy equation). Is that right? If not, could you please explain in more detail?. > @sun5k maybe you can try implementing the alternative I suggested of obtaining turbulence kinetic energy at inlets from the turbulence solver instead of assuming that the free stream value is imposed exactly? In the SWBLI case the SST-m versions (without divergence terms in the stress tensor) seem to underpredict the separation region https://su2code.github.io/vandv/swbli/",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1851#issuecomment-1525805374:97,clear,clearly,97,https://su2code.github.io,https://github.com/su2code/SU2/issues/1851#issuecomment-1525805374,1,['clear'],['clearly']
Usability,"Thank you for the changes.; I would say a test case is always welcome. You can simply modify an existing one, this feature is orthogonal to everything else, and then please add the new options to the config_template (with maybe the nice explanation you have in CConfig).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1236#issuecomment-800292781:79,simpl,simply,79,https://su2code.github.io,https://github.com/su2code/SU2/pull/1236#issuecomment-800292781,1,['simpl'],['simply']
Usability,Thank you for the feedback but for 99% of cases it is easier for users if we download the dependencies for them. The philosophy behind SU2 has always been to provide as much of a self contained package as possible.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1945#issuecomment-1450323672:18,feedback,feedback,18,https://su2code.github.io,https://github.com/su2code/SU2/issues/1945#issuecomment-1450323672,1,['feedback'],['feedback']
Usability,"Thank you for the feedbacks, I am working on the modifications you suggested. I will perform a couple of tests to be sure I did not break anything. Hope to commit the new code soon!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1124#issuecomment-740209039:18,feedback,feedbacks,18,https://su2code.github.io,https://github.com/su2code/SU2/pull/1124#issuecomment-740209039,1,['feedback'],['feedbacks']
Usability,"Thank you for the pull request. ; Pull requests must be both to and from the ""develop"" branch (or the relevant feature branch if applicable). In order to make a pull request, please check out the develop branch, make your changes, and submit the pull request into to develop branch. . While this might be useful in some situations, and particularly the record of this pull request can be an example to other users who want to use Docker with SU2, it looks like this is specific to a version of Ubuntu, and that you have hard-coded some lines to refer to locations on your own file system. We try to make it such that SU2 will be usable in most operating systems, with appropriate changes to the configuration steps. . Since it is setting up a development environment this would be more appropriate to SU2_IDE/, rather than Quickstart/ - which is intended as the main tutorial for new users, who are not necessarily developers and who may not have heard of Docker.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/169#issuecomment-96786749:629,usab,usable,629,https://su2code.github.io,https://github.com/su2code/SU2/pull/169#issuecomment-96786749,1,['usab'],['usable']
Usability,"Thank you for the review @economon.; I just gave the multiple constraints a try on the hybrid onera m6 mesh we have in testcases, it works, both points and edges can be balanced, but the edge cuts go up by almost 50% I guess that makes sense, more constraints less minimization.; There's another reason why I like the combined function, balancing the ""num neighbors"" metric is not exactly the same as balancing the number of edges per partition, using a small negative point weight (-1, -2) yields better results (but the ideal value will be case dependent). I think the next big improvement we can make in this area is to use a partitioner that is aware of the network topology, ParMETIS assumes that the communication cost between any two ranks is the same, this simplification can be very costly on large parallel machines that have a tree-like network topology, and in older clusters with slow interconnects (relative to intra node communication).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1059#issuecomment-671054807:765,simpl,simplification,765,https://su2code.github.io,https://github.com/su2code/SU2/pull/1059#issuecomment-671054807,1,['simpl'],['simplification']
Usability,"Thank you so much, Tobi and Pedro. Yes, there is a temperature gradient; close to the wall. So SU2 gives me, in this case, a 'virtual heat flux'!; Kind regards. On Thu, Sep 28, 2023 at 8:25 PM Pedro Gomes ***@***.***>; wrote:. > you are correct, there is a discussion on CFD-online about it. we impose 0; > heat flux, but report an ""apparent heat flux"" most codes will simply give; > you back the imposed heat flux value you specify, nevertheless there will; > probably be a temperature gradient close to the wall; >; > —; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/pull/2109#issuecomment-1740118992>, or; > unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AHGXZUUZNE6B63SH7XJLY2DX4YBMZANCNFSM6AAAAAA3QKLVDU>; > .; > You are receiving this because you commented.Message ID:; > ***@***.***>; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/2109#issuecomment-1740735437:369,simpl,simply,369,https://su2code.github.io,https://github.com/su2code/SU2/pull/2109#issuecomment-1740735437,1,['simpl'],['simply']
Usability,"Thank you so much. Jehan. Sent from Yahoo Mail on Android. From:""Tim Albring"" notifications@github.com; Date:Tue, May 5, 2015 at 4:56 PM; Subject:Re: [SU2] SU2 do not produce plot files such as vtk etc. (#173). If you run the code with enabled mpi support SU2_CFD will only write the restart files. You need to use SU2_SOL to convert them to .vtk. Therefore simply copy the restart_flow.dat to solution_flow.dat and run SU2_SOL. Or you could just use the parallel_computation.py script that does this automatically. —; Reply to this email directly or view it on GitHub.￼",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/173#issuecomment-99235355:358,simpl,simply,358,https://su2code.github.io,https://github.com/su2code/SU2/issues/173#issuecomment-99235355,1,['simpl'],['simply']
Usability,"Thank you, @economon. It turns out, that does indeed remove the issue. I updated to the latest version (7.0.5) at the same time. When checking the default behavior, the QuickStart case would run correctly the 1st time then it would fail if the restart file was not removed prior to the output stage of subsequent runs. Commenting out line 223 does appear to resolve the issues we have been encountering. Original:; Now it seems to get stuck (simply freezes for >60 sec) when writing surface_flow.vtu (from QuickStart). I don't suppose there's another flag like this in that code vicinity?. Update: This issue resolved itself. The file system was being taxed by other runs. Thank you all for your time!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/971#issuecomment-644968380:442,simpl,simply,442,https://su2code.github.io,https://github.com/su2code/SU2/issues/971#issuecomment-644968380,1,['simpl'],['simply']
Usability,"Thanks @FlorianDm for putting in the fix!. Although, it sound like we still need something more general.. I think the normal neighbor concept could still work, it's just that you need to be starting from the vertex list on the axis (not the inlet or the outlet) to find it. Another simple thing to try is just setting AxiFactor = 0.0 if the y coord = 0.0, instead of 1.0. If this grid is stretched with small spacing near the wall, the contribution from the dual CV on the axis could be very small.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/927#issuecomment-611266566:282,simpl,simple,282,https://su2code.github.io,https://github.com/su2code/SU2/pull/927#issuecomment-611266566,1,['simpl'],['simple']
Usability,"Thanks @MicK7 I will have a look, my initial thought was to have a simple strategy where within each MPI rank parallelism is extracted via colouring or scatter-to-gather transformations and only one thread per rank participates in the message passing, I have no experience here though so this might be a bad strategy, idk. **Back to business:**; I went silent for a bit because in prototyping a typical residual computation and matrix update loop I made some realisations that made me go back to the drawing board regarding data structures, and eventually back to square 0. . ## Parallel strategy for flux computation; Because significant computation is required to obtain each edge's flux, it does not make sense to attempt a ""point-loop"" strategy (which would double the effort).; However, one can either use colouring to avoid the race conditions that would result from updating the residual of cells i and j, or store the edge fluxes and then, on a second point-loop perform the summation of fluxes for each cell, with the direction being accounted by the same adjacency information used in the point-loop GG gradient computation.; If we consider only the update of residuals the two strategies are fairly equivalent performance wise, the tie breaker is the matrix updates. ## Matrix Updates; By this I mean the `addBlock`, `subBlock` we do (two times each) to update diagonal and off-diagonal blocks for each edge.; Here is a dummy numerics loop that does nothing else but setting blocks in the matrix (with colouring).; ```c++; void testLoop1(const vector<size_t>& colorStart,; const vector<size_t>& edgeIdx,; const vector<pair<size_t,size_t> >& connectivity,; double** blk_i, double** blk_j,; SparseMatrix& matrix); {; matrix.setZero();. for(size_t color=0; color<colorStart.size()-1; ++color); #pragma omp parallel for schedule(dynamic,CHUNK_SIZE); for(size_t k=colorStart[color]; k<colorStart[color+1]; ++k); {; size_t iEdge = edgeIdx[k];; size_t iPoint = connectivity[iEdge].first;; size_t j",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-535977206:67,simpl,simple,67,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206,1,['simpl'],['simple']
Usability,"Thanks @clarkpede to take the initiative for this topic. I think unit-tests are a useful thing and we should think about having it in addition to the regression tests. Regarding the framework I am actually a little bit hesitant to use boost. Although we are already using it for tecio, in that case it is used in a part of the code which does not change frequently so it is fine if we are just shipping it. However, if we start introducing it into the actual development process people may want to use more and more features of boost and we will have a hard time maintaining versions, compatbilities and so on. And in my opinion we should keep it as simple and lightweight as possible (one of our biggest strengths is the simple compilation/installation, which actually attracts a lot of users). So in that regard Catch2 looks like a better candidat to me. But I am happy to hear more opinions on that.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-500226914:650,simpl,simple,650,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-500226914,2,['simpl'],['simple']
Usability,"Thanks @pcarruscag , I had to do a few additional things together with the PERIODIC_IMPLICIT communication to make it work, but that also brought me on the right track 👍 Now it works really nicely from my point of view. > Have a look at my last comment in #763, I think there is a better way of handling linear system periodicity instead of what we do, which may allow you to run at higher CFL (and with simpler periodic comms). I need to have a second look at this. So non of your thoughts back then are yet incorporated in this PR",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1382#issuecomment-927303571:404,simpl,simpler,404,https://su2code.github.io,https://github.com/su2code/SU2/pull/1382#issuecomment-927303571,1,['simpl'],['simpler']
Usability,"Thanks Brian,; my bad, I misinterpreted the carpets / logs structure. I successfully ran a test of a very simple case. In the results there are some small artifacts, but the shocks are resolution improved consistently after mesh adaption.; Thanks for the support. ![Comparison](https://user-images.githubusercontent.com/41752169/80644172-84a7a580-8a69-11ea-9f16-58e98c808b73.png); ![ComparisonMesh](https://user-images.githubusercontent.com/41752169/80644174-85403c00-8a69-11ea-819f-2ac00550a089.png)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/948#issuecomment-621450497:106,simpl,simple,106,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-621450497,1,['simpl'],['simple']
Usability,"Thanks Edwin, the vectorized loops in the code are probably very simple array copies, hence the low efficiency? I would put money on not a single vector instruction being generated for the important stuff. I was surprised by the 1.25 to 1.3 factor you are seeing, for the exact same case I measured 1.39 (to be more precise). Initially I thought it had something to do with running single core, thus leaving vast amounts of L3 for only that core to use, so on the same 24c platform I ran 2 processes (30MB of cache for each) (very uncivilised) and the factor went down to 1.37, so cache was not the reason.; So then I thought maybe the Intel compilers are very good at optimizing polymorphism away, but the development branch compiled with icc 17 runs at exactly the same speed as when compiled with gcc 5.4. Then I compiled feature_contiguous_cvariable with icc 17 and it runs 9% slower than the gcc binaries, and so with icc 17 the speedup for this case was 1.27 errrrr... Anyone got a buddy at Intel?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/716#issuecomment-523930905:65,simpl,simple,65,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-523930905,1,['simpl'],['simple']
Usability,"Thanks Francisco for this contribution! Although the FFD Framework is already working quite well, there is still (like always) room for improvement. In fact, I am currently working on using BSplines instead of Bezier curves. I'm going to open a pull request end of this week. But this shouldn't affect this one I hope. Do you have by any chance a simple test case I could use to check this ?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/330#issuecomment-260475206:347,simpl,simple,347,https://su2code.github.io,https://github.com/su2code/SU2/pull/330#issuecomment-260475206,1,['simpl'],['simple']
Usability,"Thanks Pedro for hinting me at this coupling issue again, now I think I understand it! . **For the record**, here is what I talked about in today's developer meeting:; When I make the following changes in the `issue_simplified/multizone/multizone-i.cfg` :. 88c88; < CFL_NUMBER= 0.1; ---; > CFL_NUMBER= 1000.0; 162c162; < TIME_DISCRE_FLOW= EULER_EXPLICIT; ---; > TIME_DISCRE_FLOW= EULER_IMPLICIT; 177c177; < TIME_DISCRE_TURB= EULER_EXPLICIT; ---; > TIME_DISCRE_TURB= EULER_IMPLICIT. then the simplified multizone setup converges, albeit to a different solution:; ![simplified-multizone-explicit-cfl01-density](https://user-images.githubusercontent.com/72806890/139096529-5063dbe7-8ee8-4c53-a7c6-a2b6b3a031a1.png); than what the simplified singlezone setup (from above) converged to: ; ![simplified-singlezone-density](https://user-images.githubusercontent.com/72806890/139096586-7d096c5f-4d34-4ddb-94fa-0deab52df5e4.png). The same observation can be made analogously for `issue_complicated`:; The multizone setup with explicit Euler and CFL=0.1 (nearly) converges (actually the residual stalls at `avg[bgs][0]` approximately -13) to the following limit:; ![complicated-multizone-explicit-cfl01-density](https://user-images.githubusercontent.com/72806890/139096973-e9547f9f-521e-4920-aba5-2621fad79944.png); while the singlezone solution (with implicit Euler and CFL 1000) is (**EDIT**: was momentum plot, replaced by density plot); ![complicated-singlezone-density](https://user-images.githubusercontent.com/72806890/139109790-e5cae4be-041e-4c29-93a5-e086a26f72a4.png)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1414#issuecomment-953043430:491,simpl,simplified,491,https://su2code.github.io,https://github.com/su2code/SU2/issues/1414#issuecomment-953043430,4,['simpl'],"['simplified', 'simplified-multizone-explicit-', 'simplified-singlezone-density']"
Usability,"Thanks Tom for the comments! ; I think I have covered them all but let me know if you still have comments. I will do some updates tomorrow morning. I agree this is a very large pull request, it's the result of over a year of work, so I would really appreciate any more feedback from the community! ; Thanks!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/452#issuecomment-337575805:269,feedback,feedback,269,https://su2code.github.io,https://github.com/su2code/SU2/pull/452#issuecomment-337575805,1,['feedback'],['feedback']
Usability,"Thanks Tom; I agree that we should make things easy to understand. ; My thinking was that most users will want to know what parts of the mesh they are moving, but don't necessarily need to know what's happening underneath - if they specify the entire mesh the code just reverts to the more efficient method. But (from the users perspective) it may be just as easy to have a separate specification for scaling the entire mesh. . In terms of moving it to SU2_MSH; I think it may make sense to include scale/rotate/translate in SU2_MSH, but I think it would be confusing to have two options that do the same thing. I would side with separate option names (this would also eliminate a loop over markers in this pull request). On this topic, I have sometimes found MARKER_DESIGNING and DV_MARKER to be confusing; on their own they sound very similar, in the description MARKER_DESIGNING is where the objective function is evaluated - but in the code, it's not clear what MARKER_DESIGNING does - the surfaces specified by MARKER_MONITORING are what are actually used to evaluate the objective function value. . There may be other similar areas where config file options could be clarified or compressed.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/187#issuecomment-132181536:955,clear,clear,955,https://su2code.github.io,https://github.com/su2code/SU2/pull/187#issuecomment-132181536,1,['clear'],['clear']
Usability,"Thanks a lot @pcarruscag but for the moment I decided to use [NaSt3DGP](https://ins.uni-bonn.de/media/public/u/griebel/NaSt3DGP/index.html) instead. It is a very simple code that implements 3D incompressible NS with natural convection, and it can be very easily understood because it's really a very minimal implementation (parallelized, though). I'm closing this, although if you consider this feature would be of interest for SU2, don't hesitate to open this issue again, as a feature request.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/973#issuecomment-626360321:162,simpl,simple,162,https://su2code.github.io,https://github.com/su2code/SU2/issues/973#issuecomment-626360321,1,['simpl'],['simple']
Usability,"Thanks a lot for your feedback, we have updated the files. ; For the time being, just remove MG_CFL_REDUCTION= 0.9 in your config file.; Best,; Francisco",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/44#issuecomment-54904983:22,feedback,feedback,22,https://su2code.github.io,https://github.com/su2code/SU2/issues/44#issuecomment-54904983,1,['feedback'],['feedback']
Usability,Thanks again for the helpful feedback @oleburghardt. Time to get this one merged so we can keep moving.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/625#issuecomment-459996705:29,feedback,feedback,29,https://su2code.github.io,https://github.com/su2code/SU2/pull/625#issuecomment-459996705,1,['feedback'],['feedback']
Usability,"Thanks at all for being so responsive to this mishap. When I started contributing I learned that something like a 2-LGTM-rule was applying. But apparently it evolved to have someone merge a pull request if he or she can judge the content and feels comfortable with it, as the other approach ended up having a large list of unmerged pull requests **or** having two LGTM's of non-independent reviewers. @economon Maybe you can bring it up at the next meeting how we could address this little double bind?. So sorry again for the trouble (at least a revert of the very latest commit would not be too difficult). Still I'll wait if @pcarruscag and @talbring want to do now the way Tim suggested.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/667#issuecomment-480015080:27,responsiv,responsive,27,https://su2code.github.io,https://github.com/su2code/SU2/pull/667#issuecomment-480015080,2,"['learn', 'responsiv']","['learned', 'responsive']"
Usability,"Thanks for bringing up this issue. It is interesting... . As Heather mentioned, is there any concern that when writing large files the lack of an endl will cause the buffer to become too large at some point (before the file gets closed and clears the stream automatically)?. Unfortunately, we do not have any regression tests that cover the output files at the moment, so it is difficult to gauge the impact of the changes, although it would be straightforward to add some tests for SU2_CFD and SU2_SOL that diff output files. Have you been able to verify that all CSV, Tecplot/ParaView files, and force breakdown files work appropriately?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/281#issuecomment-223806287:240,clear,clears,240,https://su2code.github.io,https://github.com/su2code/SU2/pull/281#issuecomment-223806287,1,['clear'],['clears']
Usability,"Thanks for finishing up the implementation, @VivaanKhatri! I am looking forward to reviewing this very soon. Do you have a test case to verify things are working? Even just a simple flat plate like in the paper so that we can put it under regression control?. @rsanfer: your comment reminded me about our earlier attempts to fix up the indentation issues on the fix_indentation branch. Do you think this is something we can revive to provide scripts for automatically fixing this issue once and for all? Or do we need to find a different approach?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/530#issuecomment-387921905:175,simpl,simple,175,https://su2code.github.io,https://github.com/su2code/SU2/pull/530#issuecomment-387921905,1,['simpl'],['simple']
Usability,"Thanks for taking care of the merge with develop @pcarruscag, I am going to make some simple formatting changes to the `CFEASolver` and `CMeshSolver` so that they conform to the rest of the solver files",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/849#issuecomment-578283139:86,simpl,simple,86,https://su2code.github.io,https://github.com/su2code/SU2/pull/849#issuecomment-578283139,1,['simpl'],['simple']
Usability,"Thanks for the clarification!. Best,; Francisco. > On Apr 22, 2017, at 5:01 PM, Heather Kline <notifications@github.com> wrote:; > ; > Thanks; > The discrete adjoint can also be used with combined objectives, and uses the same config specifications. It may not be clear from this pull request since this functionality was added in a previously - when multiple objectives (limited to objectives defined inside the CFD solver) are specified, they are added together (with specified weights) in the CFD solver into the 'COMBO' output to history. This variable is registered for the discrete adjoint solver.; > An example of this can be seen in the serial_regression_AD.py, test name 'discadj_multi_py'.; > ; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/pull/385#issuecomment-296409557>, or mute the thread <https://github.com/notifications/unsubscribe-auth/AEpklrJ5WQ8CoWJNAy_FVZ0bbYN000s2ks5rypTpgaJpZM4MgM_e>.; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/385#issuecomment-296409876:264,clear,clear,264,https://su2code.github.io,https://github.com/su2code/SU2/pull/385#issuecomment-296409876,1,['clear'],['clear']
Usability,"Thanks for the comments, Tom! I understand it's a big change, so I would welcome some more feedback! . I am working in other ways to improve the generalization/sustainability of the code, so any comments would also be considered for that stage :D",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/528#issuecomment-388799884:91,feedback,feedback,91,https://su2code.github.io,https://github.com/su2code/SU2/pull/528#issuecomment-388799884,1,['feedback'],['feedback']
Usability,"Thanks for the commit, I've installed it using your hints (I also changed some aliases to always point to python3), and now `parallel_computation.py` it is running properly.; `mesh_adaption_amg.py` runs, until it complains about Ncorners in the SU2 mesh.; ` ## WARNING: MISSING SU2 MESH FILE KEYWORD: NCORNERS=.` ; and then mesh_adapt fails, I can't find any reference to NCORNERS in *.su2 mesh files by the way. As far as` locate Python.h` that's the output :; ```/home/antares/Downloads/SALOME-9.3.0-UB18.04-SRC/BINARIES-UB18.04/ParaView/include/paraview-5.6/vtkPython.h; /home/antares/Downloads/SALOME-9.3.0-UB18.04-SRC/BINARIES-UB18.04/Python/include/python3.6/Python.h; /home/antares/Downloads/SALOME-9.3.0-UB18.04-SRC/BINARIES-UB18.04/gmsh/include/FieldPython.h; /home/antares/Downloads/SALOME-9.3.0-UB18.04-SRC/BINARIES-UB18.04/gmsh/include/simpleFunctionPython.h; /home/antares/Downloads/ThirdParty-v1806/ParaView-v5.5.2/VTK/Utilities/Python/vtkPython.h; /home/antares/OpenFOAM/ThirdParty-v1806/ParaView-v5.5.2/VTK/Utilities/Python/vtkPython.h; /usr/include/python3.6m/Python.h; ```. Thanks",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/948#issuecomment-619409024:848,simpl,simpleFunctionPython,848,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-619409024,1,['simpl'],['simpleFunctionPython']
Usability,"Thanks for the explanation @suargi . I would personally advocate for that the testcases should converge to some reasonable solution people might use it as a starting point (copy the cfg and doing mild adaptions) for their own stuff. And the Testcases show off the capabilities to some degree, to do so, convergence is beneficial. But as we have a bunch of working 2D airfoils in regression already I recon that adding a clear explanation and warning to the cfg as suggested by Pedro is fine. Otherwise you might try to bisect the AoA ... maybe there is a value that triggers negative SA and does not diverge :thinking: . Knowingly adding a diverging test without a clear warning is not good imo :)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1559#issuecomment-1067977083:420,clear,clear,420,https://su2code.github.io,https://github.com/su2code/SU2/pull/1559#issuecomment-1067977083,2,['clear'],['clear']
Usability,"Thanks for the feedback @pcarruscag. @jayantmukho and I discussed this when we implemented the objective function. The main motivation was that since our implementation of the separation sensor is computed using the skin friction coefficient, we only defined the variables Buffet_Sensor, Buffet_Metric, etc. for the NSSolver class. Since the NSSolver needs to be able to evaluate all the same objectives as the EulerSolver, but the buffet objective is exclusive to the NSSolver, I copy pasted the function and added the new objective. Let me know if you have any suggestions for a cleaner implementation. We were basically choosing between defining all the Buffet_* variables in EulerSolver which would just add unnecessary variables to the constantly growing list of variables, or copying EvaluateObj_Func to allow for NS-specific objectives.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/614#issuecomment-441300657:15,feedback,feedback,15,https://su2code.github.io,https://github.com/su2code/SU2/pull/614#issuecomment-441300657,1,['feedback'],['feedback']
Usability,"Thanks for the feedback and suggestions. Nice teamwork! I am also plenty happy with this now. Last comment: it was mentioned at the meeting (maybe in the V&V working group), that it would be good to have a separate option for the user-defined solution, in the case of setting a custom initial condition or BC, that sits outside the KIND_VERIFICATION_SOLUTION option list. Doesn't have to necessarily be acted upon now, but want it on record.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/672#issuecomment-498834929:15,feedback,feedback,15,https://su2code.github.io,https://github.com/su2code/SU2/pull/672#issuecomment-498834929,1,['feedback'],['feedback']
Usability,"Thanks for the feedback. . I was not able to find any examples myself either. It looks like this is a feature that has been around for a while, but maybe has gotten lost in some updates. I will work on setting up a small test case for this and the FAN_FACE_MDOT and submit a PR.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1607#issuecomment-1100150640:15,feedback,feedback,15,https://su2code.github.io,https://github.com/su2code/SU2/issues/1607#issuecomment-1100150640,1,['feedback'],['feedback']
Usability,Thanks for the feedback. I will modify the class in a way that it is possible to specify the separator and other decoration.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/591#issuecomment-427287405:15,feedback,feedback,15,https://su2code.github.io,https://github.com/su2code/SU2/issues/591#issuecomment-427287405,1,['feedback'],['feedback']
Usability,"Thanks for the feedback. The GitHub pages site is now the official project page, and the redirect has been put in place. Please let me know asap if any problems arise. @vdweide: yes, let's keep with our normal development process for the website, including PRs and code reviews, etc., in order to maintain quality and keep everyone informed. Lastly, if anyone is very interested in working on a website overhaul, please let us know.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/436#issuecomment-329063810:15,feedback,feedback,15,https://su2code.github.io,https://github.com/su2code/SU2/pull/436#issuecomment-329063810,1,['feedback'],['feedback']
Usability,Thanks for the feedback.. this is resolved in #600,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/515#issuecomment-459228891:15,feedback,feedback,15,https://su2code.github.io,https://github.com/su2code/SU2/issues/515#issuecomment-459228891,1,['feedback'],['feedback']
Usability,"Thanks for the fixes, Francisco. The continuous adjoint tests are now failing, but I am guessing that it is something simple with the changes to the config option. Can you please take a look when you have a moment?. Couldn't agree more about keeping an eye on the Python scripts. We'll chat about it this week at the developer meeting (we need regressions for the Python scripts). More on that to come.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/244#issuecomment-191571633:118,simpl,simple,118,https://su2code.github.io,https://github.com/su2code/SU2/pull/244#issuecomment-191571633,1,['simpl'],['simple']
Usability,"Thanks for the hint, just uploaded a screenshot of the mesh adaption!; Now I'm trying to run a simple 3D case, but unfortunately the amg.out fails during the first try (in the adap/ini folder):; ```; ## 16739 TRIANGLE(S) DISCARDED ; fefloa_Python2Mesh : 3d mesh on input ; fefloa_Python2Mesh : msh->NbrVer 14368 ; fefloa_Python2Mesh : msh->NbrTet 58189 ; fefloa_Python2Mesh : leaving with 14368 ver. 16740 tri. 0 edg. ; -- Maximal memory ; Maximum number of Points 53800000 ; Maximun number of Bnd Points 10760000; Maximum number of Triangles 21520000 ; Maximum number of Tetrahedra 295900000 ; Allocated Memory 50.105 Gb ; Physical Memory 62.729 Gb; bounding box x: -100 200 y: -150 150 z: -150 150 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; 14368 Vertex ; 3 Boundary Vertices ; 58189 Tetrahedra ; 1 Triangles ; 0 Edges ; 1 Surface(s) ; % Output subdom.meshb Mesh ndimn=3, mpoin=14368, melem=58189, mface=1; Corners 0 Required 0 ; ## ERROR : TETRAHEDRON 2 BOUNDARY FACE 1 2; 9 IS MISSING ; ## ERROR : TETRAHEDRON 4 BOUNDARY FACE 3 7; 2324 IS MISSING ; ···; ## ERROR: FEFLO.A: 16740 BOUNDARY FACES ARE MISSING ; CHECK YOUR MESH . ## FATAL ERROR: FEFLOA: INITIAL OR CURRENT MESH HAS AN IN",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/948#issuecomment-623572280:95,simpl,simple,95,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-623572280,1,['simpl'],['simple']
Usability,Thanks for the improvements! Just a quick suggestion: maybe we should use for the distance computation the already available ADT structure ? Just have a look at CPhysicalGeometry::ComputeWall_Distance on how to use it. Should be more or less a simple copy/paste.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/444#issuecomment-331841826:244,simpl,simple,244,https://su2code.github.io,https://github.com/su2code/SU2/pull/444#issuecomment-331841826,1,['simpl'],['simple']
Usability,"Thanks for the quick review @pcarruscag. I have cleaned up a little bit. Also added a nicer table of the output. l prefer that we always compute the min/max values, at least for the FVM CFD solvers, for a few reasons. The most important reason is that we should start to build up some intuition about the correlation between mesh quality metrics and accuracy + convergence in the solvers. This can be especially important during optimization when the mesh is deforming. I think the metrics are valuable to print every time for this reason, which might help users diagnose problems eventually. Additionally, the cost is relatively small (on par with the other pre-processing routines, it is only executed once and it is parallelized, and the memory is released if we don't write).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/778#issuecomment-526456264:285,intuit,intuition,285,https://su2code.github.io,https://github.com/su2code/SU2/pull/778#issuecomment-526456264,1,['intuit'],['intuition']
Usability,"Thanks for the suggestion and I am preparing for a test.; As far as I understand it, I just find that to get the absolute value of r_ij ( showed in the highest equation) in this part of code is unnecessary. The cross-product operation is to find the grid vector mostly parallel to the vorticity vector and the absolute value may cause a nonphysical recognition.; @EduardoMolina, I don't know if I got it wrong and wish more guidance,.; ```; for (auto iDim = 0u; iDim < nDim; iDim++){; delta[iDim] = fabs(coord_j[iDim] - coord_i[iDim]);; }; ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1462#issuecomment-988581348:424,guid,guidance,424,https://su2code.github.io,https://github.com/su2code/SU2/issues/1462#issuecomment-988581348,1,['guid'],['guidance']
Usability,"Thanks for your comments! Except for mixing plane and frozen rotor, sliding plane is also pretty common in turbomachinery simulation, it is indeed implemented in some, if not all, in-house codes. ; MRF is quite useful in turbomachinery simulation, expecially when we deal with transient simulation. Actually it is really rare to move the rotor mesh like in reality. One reason is that MRF is more efficient and accurate. Otherwise, you introduce new disturbance into the transient flow field every physical time step, which is not good. Because when you rotate the mesh, the velocity direction of each grid point inherited from last time step is not rotated. To make it more clear, you will have a flow going towards casing instead of parallel to, at the start of next physical time step. So you need more pseudo time steps to get a proper velocity variable. As a result, you get a zig-zag shape in the residual history.; I'm not actually moving the interface. The rotor mesh is not rotated, so as the interface at rotor zone. I'm just virtually rotating the rotor interface to find the new matching points between rotor and stator for each physical time step, so that the variable could be passed across the interface. In other words, only the passing variables are actually rotated. If I understand it correctly, there is no additional moving mesh restriction introduced here.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/2173#issuecomment-1953783506:675,clear,clear,675,https://su2code.github.io,https://github.com/su2code/SU2/pull/2173#issuecomment-1953783506,1,['clear'],['clear']
Usability,"Thanks for your feedback! I agree, `OMP_NUM_THREADS` is better than having the number of threads in the constructor. I adapted `disc_adj_flow` and `disc_adj_fea` for MPI and added both to parallel AD and hybrid AD tests.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1966#issuecomment-1472198978:16,feedback,feedback,16,https://su2code.github.io,https://github.com/su2code/SU2/pull/1966#issuecomment-1472198978,1,['feedback'],['feedback']
Usability,Thanks for your guidence.; I found the code snippet you metioned in version 7.4.0 hasnot shown up in my current version 7.2.0. Quite happy to see contributors have revised this.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1809#issuecomment-1308341917:16,guid,guidence,16,https://su2code.github.io,https://github.com/su2code/SU2/issues/1809#issuecomment-1308341917,1,['guid'],['guidence']
Usability,"Thanks for your kindly reply, Clark. It is a good habit to have a search before asking, and I should keep it. . ""feature-AdjTNE2"" seems to be a good example to learn from how to edit the kernel of governing equations. I would try to deepen the utilities of electromagnetic computation. And I have found the commit that deleting all plasma computational relevant content. 45c2a63d1a0773dd2e9ca05b5a1798ea575d47f8 Anybody willing to tell me why we delete that part? Too complicated to handle?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/741#issuecomment-515276512:160,learn,learn,160,https://su2code.github.io,https://github.com/su2code/SU2/issues/741#issuecomment-515276512,1,['learn'],['learn']
Usability,"Thanks, @clarkpede, for this PR and for the clear explanation of the features proposed. LGTM in terms of implementation and code style. I'll just wait for @EduardoMolina to comment on the contents. I only have a couple of minor questions:. > I moved the calculation of the maximum cell width to the CPhysicalGeometry class. This makes inclusion in the central/upwind blending easier. For DES and DDES, the cell lengthscale is not dependent on the flow. So there's no need to compute it every iteration in the flow solver. I can see this approach reduces the computational cost of computing the MaxLength every time at the cost of having one more double in memory per point. However, would a call to SetMaxLength() be necessary in case of deformable meshes? . Also, from PR #532:; > As for code verification, I would propose using one of the cases examined by Travin, Stretlets, Mockett, or Xiao for comparison. (...) The cases I can see where they explicitly show the results of the blending function are: Circular cylinder at Re = 50,000 (Travin et al. 2002) (...). I guess this is the case for which you are showing the rough tests results in the Code Verification section. I am currently looking into some test cases at similar Re regimes. Are you using the unsteady compressible solver for this verification? I noticed that in Ref.[1] they use artificial compressibility, and I was wondering if we could also use this test case to look into the unsteady, incompressible (preconditioned) version of the solver (PR #514).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/552#issuecomment-403842613:44,clear,clear,44,https://su2code.github.io,https://github.com/su2code/SU2/pull/552#issuecomment-403842613,1,['clear'],['clear']
Usability,"Thanks, @jaspe55 ! LGTM. I don't think we have any tests for the inverse design capability. Do you have a very simple test case that we can put into the regressions for this capability? I think you are working on a nozzle design.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/600#issuecomment-439496260:111,simpl,simple,111,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-439496260,1,['simpl'],['simple']
Usability,"Thanks, David & Ruben. If anyone else has feedback or concerns, please let us know. We'll likely merge this in tomorrow. If folks have trouble with conflicts from the previous memory fixes, or have conflicts with these CDriver changes, We're happy to work with you directly. Just let me know.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/295#issuecomment-237737515:42,feedback,feedback,42,https://su2code.github.io,https://github.com/su2code/SU2/pull/295#issuecomment-237737515,1,['feedback'],['feedback']
Usability,"Thanks, Edwin. I had originally toyed around with this too, but I thought using the system-specific versions would be most portable at first. However, for something this simple, I agree that we should just do it ourselves. I have reused your implementation with some minor modifications. Could you please just confirm that the code posted above is yours, you are ok with me adapting it, and that I can name you as an author at the top of the file (I have added you there)?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/562#issuecomment-414092502:170,simpl,simple,170,https://su2code.github.io,https://github.com/su2code/SU2/pull/562#issuecomment-414092502,1,['simpl'],['simple']
Usability,"Thanks, I’ll take a look at that before the weekend,. Best,; Francisco. > On Mar 2, 2016, at 8:03 PM, Thomas D. Economon notifications@github.com wrote:; > ; > Thanks for the fixes, Francisco. The continuous adjoint tests are now failing, but I am guessing that it is something simple with the changes to the config option. Can you please take a look when you have a moment?; > ; > Couldn't agree more about keeping an eye on the Python scripts. We'll chat about it this week at the developer meeting (we need regressions for the Python scripts). More on that to come.; > ; > —; > Reply to this email directly or view it on GitHub https://github.com/su2code/SU2/pull/244#issuecomment-191571633.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/244#issuecomment-191590831:278,simpl,simple,278,https://su2code.github.io,https://github.com/su2code/SU2/pull/244#issuecomment-191590831,1,['simpl'],['simple']
Usability,"Thanks, Tim. Adding flexibility to the FFD is a great contribution. I was just going through the changes and I have a couple of questions:; 1. I noticed that you have added AD as an option for computing the geometric sensitivity component (change in the surface location due to a delta change in the design variable) that multiplies the adjoint sensitivity. Is there a way to make this usable for the continuous adjoint too rather than using finite differencing? This assumes that the user has built the AD version, even though they use the continuous adjoint.; 2. On a related note (I think), is the finite differencing that is currently used for computing the geometric sensitivity the only roadblock to arbitrary FFD movements for the continuous adjoint?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/239#issuecomment-183462794:386,usab,usable,386,https://su2code.github.io,https://github.com/su2code/SU2/pull/239#issuecomment-183462794,1,['usab'],['usable']
Usability,"Thanks; The discrete adjoint can also be used with combined objectives, and uses the same config specifications. It may not be clear from this pull request since this functionality was added in a previously - when multiple objectives (limited to objectives defined inside the CFD solver) are specified, they are added together (with specified weights) in the CFD solver into the 'COMBO' output to history. This variable is registered for the discrete adjoint solver. ; An example of this can be seen in the serial_regression_AD.py, test name 'discadj_multi_py'.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/385#issuecomment-296409557:127,clear,clear,127,https://su2code.github.io,https://github.com/su2code/SU2/pull/385#issuecomment-296409557,1,['clear'],['clear']
Usability,"That looks a bit strange, you still get Release 6.2.0 but in the aforementioned PR @jayantmukho clearly updated the version to 7.0.2, I use the old build system in an old computer and it is currently working...",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/910#issuecomment-598733874:96,clear,clearly,96,https://su2code.github.io,https://github.com/su2code/SU2/issues/910#issuecomment-598733874,1,['clear'],['clearly']
Usability,The Github Actions checks passed after making two changes:. 1) https://github.com/su2code/SU2/pull/1619/commits/efe98fe6070a0cb51f1082a9599363786e4d65ea; I needed to lower the warnlevel due to problems in `externals/cgns/hdf5`.; Maybe the HDF5 files should be updated to a newer version ?! But it is not clear to me which version has been used in https://github.com/su2code/SU2/pull/1500. ; @MicK7 Do you have an idea how to fix this ?. 2) https://github.com/su2code/SU2/pull/1619/commits/26140223e5838a6856c0b3c02163a826256306b1; A workaround recommended at https://github.com/su2code/SU2/issues/1568#issuecomment-1083104460. 3) The regression tests [fail](https://github.com/su2code/SU2/runs/6387003184?check_suite_focus=true) because the new `test-su2` Docker image is `private`. I will need someone with higher privileges than me to make it public.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1619#issuecomment-1123614000:304,clear,clear,304,https://su2code.github.io,https://github.com/su2code/SU2/pull/1619#issuecomment-1123614000,1,['clear'],['clear']
Usability,"The MPI_Type_create_hindexed will indeed solve the integer overflow encountered in MPI_Type_indexed, as the former uses MPI_Aint (8 byte integers) for the the displacements and the latter regular 4 byte integers. However, as @GomerOfDoom mentioned, there may be issues for the discrete adjoint (I saw that Type_indexed is actually present in medi) if we simply replace MPI_Type_indexed by MPI_Type_create_hindexed. So @talbring, @MaxSagebaum and @economon, do you foresee any problems here? If not, then it is a very simple change of a couple of lines.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/949#issuecomment-622319245:354,simpl,simply,354,https://su2code.github.io,https://github.com/su2code/SU2/issues/949#issuecomment-622319245,2,['simpl'],"['simple', 'simply']"
Usability,"The _amgio extension should be built by default. I haven't had any issues on any of the machines I've built on, so I appreciate the feedback. Just curious, are you running with python >=3.7? The shebang in all the SU2 python scripts; ```; #!/usr/bin/env python; ```; uses whatever python is set to in your environment variables, but pyamg/_amgio will only build/run with python >=3.7. Could you also check if the _amgio extension was installed in your site-packages (probably located in ~/.local/lib/python3.x/site-packages)?. If it didn't build/install, you could go into extensions/AMGIO/su2io and run; ```; python3 setup.py build_ext && python3 setup.py install; ```; If it did build/install, try the command; ```; python3 $SU2_RUN/mesh_adaptation_amg.py -f invCyl.cfg -n 6; ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/948#issuecomment-619334494:132,feedback,feedback,132,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-619334494,1,['feedback'],['feedback']
Usability,"The answer to that is very simple. Look in the data set that is present in the szplt file. The z-coordinate is not in there anymore and consequently Tecplot takes the next variable, the density in this case, as the z-coordinate. Consequently you git a picture like you showed. The same is true for the field solution. Also there the z-coordinate is not present in the szplt file and hence you get a rather funny picture when you attempt to visualize this in 3D. But 2D visualization works just fine. In contrast the z-coordinate is stored in the vtu files, because the standard requires that. Hence you can still visualize this in 3D. Could you try a truly 3D test case to see if that visualizes fine? If so, please let us know such that we can close this issue.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1182#issuecomment-771407798:27,simpl,simple,27,https://su2code.github.io,https://github.com/su2code/SU2/issues/1182#issuecomment-771407798,1,['simpl'],['simple']
Usability,"The dimensional inconsistency comes from the multiplicity of the normal velocity eigenvalue and the manipulation Hirsch does with the corresponding eigenvectors in order to obtain a formulation that is valid for any normal vector. When you use the P matrix to form the characteristic variables, the dimensional inconsistency disappears again, as it should. Never looked at it this way. Thanks for clearing this up Francisco.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/423#issuecomment-322124810:397,clear,clearing,397,https://su2code.github.io,https://github.com/su2code/SU2/issues/423#issuecomment-322124810,1,['clear'],['clearing']
Usability,"The documentation is now at:; https://github.com/su2code/SU2/wiki/Mesh-File. I would assume the actual behavior is still the same. Brendan, can you please check the documentation to see if you think it is clear now, and update it if not?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/47#issuecomment-104355161:205,clear,clear,205,https://su2code.github.io,https://github.com/su2code/SU2/issues/47#issuecomment-104355161,1,['clear'],['clear']
Usability,The dummy layer is what we used before version 7 and moved away from it for simplicity.; Two layers doesn't sound possible for unstructured meshes.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/2038#issuecomment-1557818415:76,simpl,simplicity,76,https://su2code.github.io,https://github.com/su2code/SU2/pull/2038#issuecomment-1557818415,1,['simpl'],['simplicity']
Usability,"The fix is not as simple, using the strategy from #1631 makes it worse.; Intersection with symmetry/euler look ok, so the best is to extend the domain...",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1639#issuecomment-1132302976:18,simpl,simple,18,https://su2code.github.io,https://github.com/su2code/SU2/issues/1639#issuecomment-1132302976,1,['simpl'],['simple']
Usability,The iteration number is now stored in the restart files so we should definitely have this feature. Because at the moment it is not clear when the iteration stops (because EXT_ITER is still counted from 0).,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/99#issuecomment-308412942:131,clear,clear,131,https://su2code.github.io,https://github.com/su2code/SU2/issues/99#issuecomment-308412942,1,['clear'],['clear']
Usability,"The motivation of having it as the default was to make the code as user-friendly as possible (fewer knobs exposed in the config), but options are good of course. I would propose then that we add an option for the reconstruction gradient, something like:; ```; NUM_METHOD_GRAD_RECON= LEAST_SQUARES; ```; to let users decide if they want a separate option for the reconstruction gradients. If it does not appear, then the default is to use the same method as defined by NUM_METHOD_GRAD without a second gradient computation (basically what we have now). The nice thing about that is we can even try out other combos such as WLS+GG for the two different gradients. I will throw an error if users try to use LSQ for the viscous/source gradients, to avoid accuracy issues. What do you think?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/790#issuecomment-533259202:67,user-friendly,user-friendly,67,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-533259202,1,['user-friendly'],['user-friendly']
Usability,"The original Spalart-Allmaras turbulence model encloses the ft2 term: https://www.researchgate.net/publication/236888804_A_One-Equation_Turbulence_Model_for_Aerodynamic_Flows or https://turbmodels.larc.nasa.gov/spalart.html#sa. After that, some modifications were introduced and the ft2 term was neglected. But accordingly, a different name is used, i.e., Spalart-Allmaras One-Equation Model without ft2 Term.; So, I would also vote for implementing the original model along with the SA-noft2 variant. Also, I would like to point out a fact about the current implementation of the Negative Spalart-Allmaras variant. From theory, https://www.iccfd.org/iccfd7/assets/pdf/papers/ICCFD7-1902_paper.pdf equation 12, the model introduces the modified vorticity S_tilde. However, in SU2 (SU2/SU2_CFD/src/numerics/turbulent/turb_sources.cpp and CSourcePieceWise_TurbSA_Neg::ComputeResidual) we do not consider this modification and simply consider the modified vorticity as in the standard Spalart-Allmaras:. Shat = S + TurbVar_i[0]*fv2*inv_k2_d2;. (Sbar is used as S_tilde). Is there any reason for that?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/992#issuecomment-648883933:924,simpl,simply,924,https://su2code.github.io,https://github.com/su2code/SU2/issues/992#issuecomment-648883933,1,['simpl'],['simply']
Usability,The primary solution in the linked issue is to use a virtualenv. I quote:. > The easiest workaround: Switch to a [virtualenv](https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/). This will ensure that all of your python packages are stored in single location.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1575#issuecomment-1076307528:155,guid,guides,155,https://su2code.github.io,https://github.com/su2code/SU2/issues/1575#issuecomment-1076307528,1,['guid'],['guides']
Usability,"The solver with the closest functionality to what you are trying to do is the elasticity solver, it may be worth having a look there. But in a nutshell there the variables we want to differentiate are held by (members of) the discrete adjoint solver, they are reset before being registered as inputs to clear the derivative information, and it is important that they are left alone during the recording phase.; You will see that the adjoint iteration class for this solver then needs to update the numerics classes (in SetDependencies), at least for the source term the SA coefficients are set in the constructor of the corresponding numerics so maybe this step is missing?; The key point is that whenever a coefficient is used you need to be able to trace its value back to the original variable you registered.; Also the derivatives should be extracted in the same order they were registered, and you cannot access them multiple times by calling ""GetDerivative"" on them repeatedly (not 100% sure if this restriction still exists after the update of CoDi).; If none of this makes sense point me to branch you are working on.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/679#issuecomment-491910935:303,clear,clear,303,https://su2code.github.io,https://github.com/su2code/SU2/issues/679#issuecomment-491910935,1,['clear'],['clear']
Usability,"The source term is pretty simple but the feature as a whole is very intrusive on the code, even the mesh deformation is getting involved in this.; Would it be viable to use the python wrapper to provide the source term?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/2273#issuecomment-2098573850:26,simpl,simple,26,https://su2code.github.io,https://github.com/su2code/SU2/pull/2273#issuecomment-2098573850,1,['simpl'],['simple']
Usability,The style guide is now posted at:; https://github.com/su2code/SU2/wiki/Style-Guide,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/89#issuecomment-102195159:10,guid,guide,10,https://su2code.github.io,https://github.com/su2code/SU2/issues/89#issuecomment-102195159,1,['guid'],['guide']
Usability,"There is no automatic way of doing that. If you want a simpler code to port to GPU, the best advice I can give you is to chose something else other than SU2. In the future please open ""discussions"" instead of issues, these are not SU2 code issues.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1407#issuecomment-947489209:55,simpl,simpler,55,https://su2code.github.io,https://github.com/su2code/SU2/issues/1407#issuecomment-947489209,1,['simpl'],['simpler']
Usability,"There was a lot of talk about refactoring the shape optimization framework to be able to work completely in memory.; I think the idea was not to have more drivers but simply to have more granularity such that you could manipulate the geometry from python (without writing it to files).; We also wanted introspection, i.e. you could probe SU2 via python for what variables and functions are available.; We also talked about having the projection step (DOT) included in CFD_AD so that you only need to worry about surface sensitivities, note that DEF is already part of CFD for forward mode AD.; (talking does not go very far). If you want to lead this work, we can help you understand the inner workings. We meet every Wednesday at 4pm CET https://meet.jit.si/SU2_DevMeeting to discuss this type of issue.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1262#issuecomment-818786416:167,simpl,simply,167,https://su2code.github.io,https://github.com/su2code/SU2/issues/1262#issuecomment-818786416,1,['simpl'],['simply']
Usability,"These timings were all run this morning on the same cluster. . Using qperf, I'm seeing 80 microsecond latency. I'm also seeing the expected bandwidth using qperf as well. I would think that mpi would behave similarly but 100% sure. . I'm quite sure that the jobs are being launched correctly. I've checked that a bunch of times since that was my first instinct. I've both logged into all the machines and watched top and everything looked normal. And I've tried running SU2 v6 before and after v7, launching them the same way, and I keep getting the same numbers. I'm not sure how to check whether there is any reason non blocking comm would be ineffective. If you have any ideas I can certainly try something. I tried to download vampirtrace which seemingly can profile mpi, but it failed to compile against my version of mpi. When I get the chance I can try a different version of openmpi and see if I can get it running. The networking setup is pretty simple with all 4 machines plugged into the same switch and they share their own vlan as part of a bigger network. As I said, I ordered some faster networking equipment to see if it makes a difference (though I'm honestly not 100% sure that what I ordered will work with my comps but we'll see.)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/894#issuecomment-593144776:955,simpl,simple,955,https://su2code.github.io,https://github.com/su2code/SU2/issues/894#issuecomment-593144776,1,['simpl'],['simple']
Usability,This PR finally passed the tests! Can I get some review feedback @economon and/or @talbring? It would be great to have this merged ASAP so no one adds any new code incompatible with Python 3.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/424#issuecomment-343013631:56,feedback,feedback,56,https://su2code.github.io,https://github.com/su2code/SU2/pull/424#issuecomment-343013631,1,['feedback'],['feedback']
Usability,"This bug pops up because the periodic mesh reconstruction (in `SU2_MSH`) doesn't always create a valid mesh in 3D. Some points disappear, and some points are duplicated. When `SU2_CFD` (specifically, `CPhysicalGeometry`) tries to get the number of points in the domain, it calculates the wrong number because some of those points are duplicated. That leads to segfaults, because the output routine thinks the extra (missing) points belong to another processor. I've got a little toy problem with a simple periodic cube. It's easy to see on the simple 4x4x4 (+ periodic) problem that 3 nodes disappear, and 3 nodes are duplicated. I've never observed this problem in any of the 2D test cases I ran. As to why `SU2_MSH` is missing some points and duplicating others, I'm not sure. I tried running Valgrind to check for uninitialized variables or illegal memory access, but nothing there. I'll have to look more into the problem. The `su2_periodic.f90` script mentioned in #416 seems to be a workaround. I don't run into any problems when I use that script.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/431#issuecomment-337056131:498,simpl,simple,498,https://su2code.github.io,https://github.com/su2code/SU2/issues/431#issuecomment-337056131,2,['simpl'],['simple']
Usability,"This could be a very interesting contribution! Please, feel free to work on this and create a push request to the developer release. SU2 is looking forward for contributions from the open-source community. Thanks!; Francisco. Sent from my iPhone. > On Mar 12, 2016, at 8:07 AM, Pete Bachant notifications@github.com wrote:; > ; > As @gbaty said, it's usually easy to support both. Many times it can be done with a simple; > ; > from **future** import division, print_function; > at the top of each file, and tweaking the print and import statements. In my experience, the Anaconda (or miniconda) Python distribution makes it very easy to setup just about any version of Python you like on a cluster, since it's installed in the user's home directory by default.; > ; > Most scientific packages (NumPy, SciPy, Matplotlib, Pandas) already support both 2.7 and 3.x within a single codebase. Python 3 is the future!; > ; > —; > Reply to this email directly or view it on GitHub.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/246#issuecomment-195781648:414,simpl,simple,414,https://su2code.github.io,https://github.com/su2code/SU2/issues/246#issuecomment-195781648,1,['simpl'],['simple']
Usability,"This has been a long long exposition (nerd joke) but bear with me I am almost done, and I will summarise the results in the form of a proposal (I'll probably put that at the top of the first post). ## ""Real"" numerics; Real in the sense that the flop to byte ratio (amount of computation per amount of data) is comparable to a real numerics scheme, say Roe for example.; The simplest way to do this is to combine the example code for MUSCL reconstruction with the matrix updates code and add something compute heavy between input and output, e.g. a number of matrix-matrix multiplications, here is some pseudo code for what I did:; ```c++; void computeResidual(size_t nVar,; size_t nDim,; const vector<Connectivity<SIMDLEN> >& connectivities,; const Matrix& coords,; const Matrix& phi,; const VectorOfMatrix& grad,; const Matrix& limiter,; RowMajorMatrix& residual,; SparseMatrix& matrix); {; using FltVec = Array<double,SIMDLEN>;. residual.setZero();; matrix.setDiagZero();. size_t color = 0;; for(const auto& connectivity : connectivities); {; #pragma omp parallel for schedule(dynamic,CHUNK_SIZE); for(size_t iEdge=0; iEdge<connectivity.size(); iEdge+=SIMDLEN); {; auto iPoint = connectivity.first_vec(iEdge);; auto jPoint = connectivity.second_vec(iEdge);. FltVec d_ij[MAXNDIM];; for(size_t iDim=0; iDim<nDim; ++iDim); d_ij[iDim] = (coords.getVec(jPoint,iDim)-coords.getVec(iPoint,iDim))*0.5;. FltVec phiL[MAXNVAR], phiR[MAXNVAR], flux[MAXNVAR],; blk_i[MAXNVAR*MAXNVAR],; blk_j[MAXNVAR*MAXNVAR];. for(size_t iVar=0; iVar<nVar; ++iVar); {; // Reconstruction goes here. flux[iVar] = (phiL[iVar]+phiR[iVar])*0.5;; }. // some silly way to make the Jacobians depend on the reconstruction; for(size_t iVar=0; iVar<nVar; ++iVar); for(size_t jVar=0; jVar<nVar; ++jVar); blk_j[iVar*nVar+jVar] = (phiL[iVar]*phiR[jVar]-phiL[jVar]*phiR[iVar])*0.5;. // the matrix-matrix multiplications; for(size_t i=0; i<WORKITERS; ++i) {; // blk_i = blk_j * blk_j; for(size_t k=0; k<nVar*nVar; ++k) blk_j[k] = blk_i[k];; }. ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-539177957:374,simpl,simplest,374,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-539177957,1,['simpl'],['simplest']
Usability,"This is obviously very good work and should make it much simpler to add new outputs etc. My main concern when first reviewing was performance (something no one seems to care about) but from the limited testing I did while merging this and CVariable there seems to be no big impact, I did not time anything though, if you have numbers to share please do.; Nevertheless if you can get away with using unordered_map instead of map it would be better. Possibly part of the reason everyone puts of reviewing this is that it is a major refactoring and yet there are no accompanying notes about the architecture the implementation choices etc. I absolutely guarantee you that is not how professional software is developed.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/724#issuecomment-534651933:57,simpl,simpler,57,https://su2code.github.io,https://github.com/su2code/SU2/pull/724#issuecomment-534651933,1,['simpl'],['simpler']
Usability,"This is simply the way how the cmd.exe shell works on Windows - file and folder names containing spaces or special characters must be quoted into `""` to be handled correctly.; The title says it all - *to make them [executables] run*. The patch prepends one `""` and appends one `""` to the command name. This could be refactored further to reduce repetition much more by putting the different executable file names into a map and have a single place to combine quote + executable + quote.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/332#issuecomment-321264218:8,simpl,simply,8,https://su2code.github.io,https://github.com/su2code/SU2/pull/332#issuecomment-321264218,1,['simpl'],['simply']
Usability,"This is very interesting, since I often find that I am commenting out most of the python regression script when debugging only a couple of tests locally. Can you estimate how much work this would be? Is it just a simple wrapping of what we already have? We would also have to make sure that Travis CI can handle it.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/462#issuecomment-342593274:213,simpl,simple,213,https://su2code.github.io,https://github.com/su2code/SU2/issues/462#issuecomment-342593274,1,['simpl'],['simple']
Usability,This issue has been paused until after v7.0.0,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-548021997:20,pause,paused,20,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-548021997,1,['pause'],['paused']
Usability,"This one is all set after a little more cleanup. I left some low-level changes to the EoS models for later. @CatarinaGarbacz @MarcoFossati : we can use a simple directory name, as you suggest. Let's just go with fluid/ since we also treat liquids with the incompressible solver. Bonus: adds a rotating frame calculation test and some extra error checks on CFL adapt params that should help avoid unreported problems with old configs.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1010#issuecomment-640170715:154,simpl,simple,154,https://su2code.github.io,https://github.com/su2code/SU2/pull/1010#issuecomment-640170715,1,['simpl'],['simple']
Usability,"Thomas,. That took some doing. I just learned more about git! I'll issue a new pull request shortly. Thanks for your interest. Ethan Alan",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/33#issuecomment-56592304:38,learn,learned,38,https://su2code.github.io,https://github.com/su2code/SU2/pull/33#issuecomment-56592304,1,['learn'],['learned']
Usability,"Those changes in option_structure.hpp were actually done to the main branch by somebody else. I forked from main, and merged develop. I can of course undo them, if you want (or rebase my commit on develop instead of merging).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/579#issuecomment-425754699:150,undo,undo,150,https://su2code.github.io,https://github.com/su2code/SU2/pull/579#issuecomment-425754699,1,['undo'],['undo']
Usability,"Those two cases are not part of the regression suite, and so they were probably not updated as some of the options were renamed.; You can have a look at the other turbomachinery examples (at least two of them are part of the regressions) it should be simple to adapt those options.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1086#issuecomment-706417999:251,simpl,simple,251,https://su2code.github.io,https://github.com/su2code/SU2/issues/1086#issuecomment-706417999,1,['simpl'],['simple']
Usability,"To be clear: I like the solver/, variable/, output/, etc. layout a lot, and I am simply suggesting that we move entirely to that layout (with cpp and hpp merged together in each of those folders) and merging the code in Common, SU2_CFD, and other modules into that structure too (in their own folders still, like geometry/ for example). To keep it organized you can simply make each of those directories a library in meson which all later get linked into the various binaries. The mains could live in the top level src/ directory if we keep it or a separate directory (open for me). Something like. ```; SU2/; src/; solver/; meson.build; solver_\*.cpp; solver_\*.hpp; variable/; meson.build; variable_\*.cpp; variable_\*.hpp; ...; ```. with or without the src/ directory in the root (could go either way). Might want to keep it or even name it cpp/ to differentiate from the python framework(s).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/583#issuecomment-630918578:6,clear,clear,6,https://su2code.github.io,https://github.com/su2code/SU2/issues/583#issuecomment-630918578,3,"['clear', 'simpl']","['clear', 'simply']"
Usability,"Todo list:; - [x] Make sure the code can handle arbitrary many species equtions. Especially the output has to be adapted. Note the MAXNVAR of the ScalarSolver has to adapted to that need as well. Make a suitable Testcase for that.; - [x] Implement weak inlet and outlet BC. The weak approach is used in the turb and mean flow and is most likely conservative opposed to the strong one. Here a simple switch will be put in place to compare both versions.; - [x] Consolidate nVar, nSpecies, ... variable to only use 1 consistently (The choice was `nSpecies` which was already introduced for NEMO and it just makes sense to use the same container); - [x] Make the numerous reviewers happy; - [x] Check inlet profiles for Species solver (have a testcase for that) See #1427 ; - [x] Create Objective functions of Surface avg quantities (Area and Massflow? prob. And a variance-style output to capture mixing); - [x] Avoid redundant operations (pre/post processings) during solver restarts. 156d0c5. What will be done in follow-up PR's:; - Viscous contributions for BC_inlet and outlet which are currently not used (also then for Turb-solver) https://github.com/su2code/SU2/pull/1388#discussion_r752384956; - Axissymmetric source term addtion and testing; - multi-component mixing from #1332 ; - gradient validation between DA and FD",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1388#issuecomment-935901996:392,simpl,simple,392,https://su2code.github.io,https://github.com/su2code/SU2/pull/1388#issuecomment-935901996,1,['simpl'],['simple']
Usability,"Tom, I would love to address both of these. Give me some time. I feel even in the current form, it is good. Do you have plans to merge this into master, so that people can use this to setup dev environment quickly. They can also create a basic config file quickly. . I will consider both of your ideas to make user experience better. Thanks for your support. ; Krishna",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/172#issuecomment-126133647:310,user experience,user experience,310,https://su2code.github.io,https://github.com/su2code/SU2/pull/172#issuecomment-126133647,1,['user experience'],['user experience']
Usability,"True. I was thinking more from the user point-of-view, to be sure people little little experience can use SU2 easier. Similar to something Tim has already started in the Docs page. The idea here is just to be sure new features are easily usable/accessible for people unfamiliar.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/799#issuecomment-541832531:238,usab,usable,238,https://su2code.github.io,https://github.com/su2code/SU2/pull/799#issuecomment-541832531,1,['usab'],['usable']
Usability,"Try v7.0.2. On Mon, 9 Mar 2020, 02:05 timjim333, <notifications@github.com> wrote:. > Hi,; >; > I've got an issue where on starting an SU2 6.2.0 Falcon case, the; > preprocessing steps run but then the output gets stuck at:; >; > ---------------------- Python Interface Preprocessing; > --------------------- Setting customized boundary conditions for zone 0; >; > - and remains frozen there until I kill the job.; >; > It seems to have happened for only 3 out of nearly 400 successful cases.; > They are all similar, running Euler at Mach 1.7, on 40 cores. They all have; > similar simple body, farfield, and and symmetry conditions.; >; > I'm not sure of the best way to diagnose this, so any guidance would be; > appreciated.; >; > Many thanks and kind regards,; > Tim; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/issues/907?email_source=notifications&email_token=AJCOXN63UWSSF6UABZZXXFLRGQ6EJA5CNFSM4LD6ZHGKYY3PNVWWK3TUL52HS4DFUVEXG43VMWVGG33NNVSW45C7NFSM4ITNPDMQ>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AJCOXN6R6JOEQCAYH7FKCLTRGQ6EJANCNFSM4LD6ZHGA>; > .; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/907#issuecomment-596654031:583,simpl,simple,583,https://su2code.github.io,https://github.com/su2code/SU2/issues/907#issuecomment-596654031,2,"['guid', 'simpl']","['guidance', 'simple']"
Usability,"Unfortunately, I have not been able to recreate this issue on my systems with the simple test case that you shared @yukaiweng. . @talbring or @EduardoMolina, if you have some time, could you give the attached toy problem a try on your machines? I ran for a couple of unsteady iterations and then restarted on the third iteration (successfully for me). I think we're just missing something simple... [ascii_restart_test.zip](https://github.com/su2code/SU2/files/1659029/ascii_restart_test.zip)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/477#issuecomment-360050851:82,simpl,simple,82,https://su2code.github.io,https://github.com/su2code/SU2/issues/477#issuecomment-360050851,2,['simpl'],['simple']
Usability,"Unfortunately, I wasn't able to get all of them. I fixed a majority of the calls but couldn't find workarounds all of them. There are 8 left in the following files: . `SU2_PY/change_version_number.py`: There's 2 in here. One is a complicated command with `grep` and pipes and the other is a simple `rm -rf`, but it isn't a security risk since there is no user input into that string. `SU2_PY/SU2/util/pyCppTap.py`: This is in the diff_routine and uses `tapenade`. I have no idea what this does so I didn't touch this one. `SU2/opt/server.py`: There are 4 `scp` calls that I didn't know how to replace. `SU2_PY/compute_polar.py`: There's one left in here which is a complicated `cat` call that I couldn't figure a workaround for. . If you have any suggestions for any of these, I can try and implement them. . Otherwise, once these tests pass, its good to merge.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/781#issuecomment-533590086:291,simpl,simple,291,https://su2code.github.io,https://github.com/su2code/SU2/pull/781#issuecomment-533590086,1,['simpl'],['simple']
Usability,"Unfortunately, I'm still a bit unsure of the math behind the averaging. I assumed, that the average of a new iteration calculates as follows:. avg(it) = (cumulativeWeight(it-1, it+1) * avg(it-1) + Weight(it, it+1)*Value(it)) / (cumulativeWeight(it-1,it+1)+Weight(it,it+1)). Translated into words:; At iteration `it` we define a window of width `it+1`.; The previous average is weighted with the integral of the window from 0 to it-1. The new value arriving at iteration it is weighted with the actual window weight. The weighted sum is then divided by the sum of the weights. For a rectangular window this seems to converge towards the right value, but for the hanning window it does not.; Probably the math behind it is simply wrong. Any idea what the proper weighting should look like?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1545#issuecomment-1039999787:721,simpl,simply,721,https://su2code.github.io,https://github.com/su2code/SU2/issues/1545#issuecomment-1039999787,1,['simpl'],['simply']
Usability,"Unfortunately, my example involves a swirler and nozzle for the; Navier-Stokes solver with Menter model, so the dataset is relatively large.; Let me check whether some older small Euler mesh exhibits the same message!; I will let you know! Thank you very much. On Mon, Oct 23, 2023 at 6:34 PM Pedro Gomes ***@***.***>; wrote:. > Is there a simple example to reproduce the issue?; >; > —; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/pull/2109#issuecomment-1776057496>, or; > unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AHGXZUV3DNRF3O55YAWT563YA3PETAVCNFSM6AAAAAA3QKLVDWVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMYTONZWGA2TONBZGY>; > .; > You are receiving this because you commented.Message ID:; > ***@***.***>; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/2109#issuecomment-1776143584:340,simpl,simple,340,https://su2code.github.io,https://github.com/su2code/SU2/pull/2109#issuecomment-1776143584,1,['simpl'],['simple']
Usability,"Update: This should be fixed in #2011, apologies this took so long to get round it in what is a very simple fix.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/857#issuecomment-1701148094:101,simpl,simple,101,https://su2code.github.io,https://github.com/su2code/SU2/issues/857#issuecomment-1701148094,1,['simpl'],['simple']
Usability,"Was playing around with the turbomachinery cases with the new multi-zone config. I like the new changes, makes it much clearer!. Just a remark, don't know if this is on purpose, but for the configuration parameter TURBOMACHINERY_KIND, you still need to supply them in the general configuration file for both zones (so in case of a two zone problem: TURBOMACHINERY_KIND = CENTRIFUGAL CENTRIFUGAL). Wouldnt it make more sense to have this per zone specified in the respective configuration file?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/715#issuecomment-514208185:119,clear,clearer,119,https://su2code.github.io,https://github.com/su2code/SU2/pull/715#issuecomment-514208185,1,['clear'],['clearer']
Usability,"We already require C++11 for some more advanced features, but it is always nice in my opinion to keep backward compatibility when possible. . However, this is not a deal breaker, I don't think, as most developers that want to use and add their own unit tests should have no problem with using C++11. If we can make it an optional dependency, to make sure the basic build still works simply, I think it could be ok.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-503685445:383,simpl,simply,383,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-503685445,1,['simpl'],['simply']
Usability,"We are wondering what the status with the merge request is. Am I supposed to do something more? is it just waiting for an additional review? . Additionally, we have many more proposed modifications, we have worked on, adding robustness to the existing turbulence models. It is expected, many of these changes will effect the test cases behaviour, are there any guidelines how to compile the code to run the full set of tests locally, or should I just open pull requests, and base upon the github test results? ; ; I am sorry if I may be asking the obvious, but I am new to contributing to open code..",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/2295#issuecomment-2219624152:361,guid,guidelines,361,https://su2code.github.io,https://github.com/su2code/SU2/pull/2295#issuecomment-2219624152,1,['guid'],['guidelines']
Usability,"We have a bit of documentation about this on the wiki here: https://github.com/su2code/SU2/wiki/Post-processing. Does this clear things up? Please let us know if this isn't adequate, and we can add more detail.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/268#issuecomment-213232801:123,clear,clear,123,https://su2code.github.io,https://github.com/su2code/SU2/issues/268#issuecomment-213232801,1,['clear'],['clear']
Usability,"We will merge this PR next in order to have enough time for testing and for you to solve conflicts (if you need any help to solve those, please contact me). Even if this PR is merged, please continue to give feedback on the usability. We will still continue to work on that. Refer to the user documentation in order to learn how to adapt your config files. Let me know if you have any questions.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/724#issuecomment-534522241:208,feedback,feedback,208,https://su2code.github.io,https://github.com/su2code/SU2/pull/724#issuecomment-534522241,3,"['feedback', 'learn', 'usab']","['feedback', 'learn', 'usability']"
Usability,"What advantages does meson provide over Cmake? I have experience with CMake, but not with meson. @talbring I'm not sure what you mean by ""the syntax is also not very comfortable and it has too many features which we actually don't need."". I recently did a survey of the some of the most popular open-source C++ libraries, both inside and outside and outside of scientific computing. The most popular build system was CMake (60% of the 15 open source libraries). If ""everyone else"" is using CMake, then why should we use meson? I'm not trying to be adversarial. I'm curious about why meson is better. Is the syntax simpler? Is meson more flexible? Is it more robust during changes? Is it faster?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/685#issuecomment-498827230:614,simpl,simpler,614,https://su2code.github.io,https://github.com/su2code/SU2/issues/685#issuecomment-498827230,1,['simpl'],['simpler']
Usability,"When I enter the ""shape_optimization.py -f unsteady_naca0012_opt.cfg"" in the commend the error is:; ```; Traceback (most recent call last):; File ""C:\Users\74351\Desktop\SU2\SU2\bin\test2\shape_optimization.py"", line 116, in <module>; main(); File ""C:\Users\74351\Desktop\SU2\SU2\bin\test2\shape_optimization.py"", line 34, in main; shape_optimization( options.filename ,; File ""C:\Users\74351\Desktop\SU2\SU2\bin\test2\shape_optimization.py"", line 51, in shape_optimization; config = SU2.io.Config(filename); File ""C:\Users\74351\Desktop\SU2\SU2\bin\SU2\io\config.py"", line 88, in __init__; super(Config,self).__init__(*args,**kwarg); File ""C:\Users\74351\Desktop\SU2\SU2\bin\SU2\util\ordered_bunch.py"", line 83, in __init__; super(OrderedBunch,self).__init__(*args,**kwarg); File ""C:\Users\74351\Desktop\SU2\SU2\bin\SU2\util\ordered_dict.py"", line 48, in __init__; self.__update(*args, **kwds); File ""C:\Users\74351\Desktop\SU2\SU2\bin\SU2\util\ordered_dict.py"", line 174, in update; for key, value in other:; TypeError: 'NoneType' object is not iterable; ```; When I enter the ""parallel_computation.py -f turb_naca0012.cfg -n NP in the commend the error is:; ```; Traceback (most recent call last):; File ""C:\Users\74351\Desktop\SU2\SU2\bin\parallel_computation.py"", line 110, in <module>; main(); File ""C:\Users\74351\Desktop\SU2\SU2\bin\parallel_computation.py"", line 53, in main; raise Exception(""No config file provided. Use -f flag""); Exception: No config file provided. Use -f flag; ```; Any solvers related to "".py"" cannot be executed, but I can run any cases with SU2_CFD. So I wonder if this situation is a problem with the Python Wrapper? . I will be very appreciated if I could get some feedback on this issue.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1567#issuecomment-1074910200:1700,feedback,feedback,1700,https://su2code.github.io,https://github.com/su2code/SU2/issues/1567#issuecomment-1074910200,1,['feedback'],['feedback']
Usability,Why not simply use clang-format and have a script to pass files/directories to have formatted? It provides more formatting options than just stripping trailing whitespaces and replacing tabs and does it in a consistent way.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/808#issuecomment-551451738:8,simpl,simply,8,https://su2code.github.io,https://github.com/su2code/SU2/pull/808#issuecomment-551451738,1,['simpl'],['simply']
Usability,"Writing a simple unit test is difficult, since SU2 both doesn't have unit tests and wasn't written with unit testing in mind. That being said, I've got a unit test that I'm happy with. Our group has put our own unit-testing framework into our fork of SU2, based off of Boost and automake testing. The unit test I created runs off of that framework. That means it won't run out-of-the-box on the develop branch of SU2. When I run the unit test with no changes to `CNumerics::GetViscousProjJacs`, I get that the residuals and Jacobians match to within 10 times the machine epsilon, aside from the [4][0] value of the Jacobians. There, the relative difference is of the order 1E-6. When I switch the two lines in `CNumerics::GetViscousProjJacs` for ideal gases to be negative, the tests run with no complaints. Ideal gas and generalized variants match to within 10 times machine epsilon. I'm uploading my test file just as an example, in case anyone wants to see what I've tested.; [viscous_ideal_vs_general.zip](https://github.com/su2code/SU2/files/2590517/viscous_ideal_vs_general.zip). As for comparison to some results from another code, I think that's a lot to ask. Getting a good comparison would depend on an understanding of how the ideal gas model, viscosity, numerics, and Jacobians are handled in the external code. Small differences would make the comparison completely invalid. I completely support testing and checking the changes I'm proposing. But comparison with an external code seems to provide a very low return on investment.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/609#issuecomment-439491945:10,simpl,simple,10,https://su2code.github.io,https://github.com/su2code/SU2/issues/609#issuecomment-439491945,1,['simpl'],['simple']
Usability,"YES! I am excited to try this out. I can probably test it on some of the other TMR cases (airfoils, flatplates). Will post the results when I get those done. . Side note, there was one issue that @bmunguia and I encountered when performing optimizations with adaptive CFL. Say the DIRECT simulation is run with adaptive CFL and is well converged (6 to 8 orders of residual reduction). When the discrete adjoint performs the one direct iteration to store the computational graph, it uses the initial CFL value, not the CFL that the adaptive CFL routine ended at. This results in the residuals being very high for that one iteration, which then affects the convergence of the discrete adjoint. . I will try to run an adjoint on one of these cases as well to see if the problem persists. Perhaps could be overcome with a simple additional field for CFL in the restart meta-data",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/790#issuecomment-531520526:818,simpl,simple,818,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-531520526,1,['simpl'],['simple']
Usability,"Yep, just an honest mistake. We'll fix it up. I know that things have been a little quiet in the repository lately, but there is a lot of motion happening behind the scenes as we prepare for the developers meeting next month (we have some exciting things in store). . Thanks for the patience, and I would also ask that, if folks in the community have some time, they please contribute to reviews. Expertise in the particular area is not required (I know it can seem intimidating, but don't be shy!), and it is a great way to learn the code and see what other folks are developing. The more input and discussion we have from various perspectives, the better.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/667#issuecomment-479973816:525,learn,learn,525,https://su2code.github.io,https://github.com/su2code/SU2/pull/667#issuecomment-479973816,1,['learn'],['learn']
Usability,"Yep, things seem to be passing just fine now, and it looks like things are coming along nicely for the turbomachinery features. Before we merge this in... I am a little concerned with the number of additions to solver_direct_mean.cpp related to the different switch statements and subroutines needed for the Riemann and non-reflecting BCs. Is there anything we can do to simplify things?. In addition, could you please clean up the spacing/style in those methods to match up with the other BCs (more comments are needed, indentation, variable declarations, etc.)? It would also be great to have a little more detail on how to use the new BCs in the descriptions in config_template.cfg. Thanks!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/207#issuecomment-152406337:371,simpl,simplify,371,https://su2code.github.io,https://github.com/su2code/SU2/pull/207#issuecomment-152406337,1,['simpl'],['simplify']
Usability,"Yes for MARKER_ROUGH, or MARKER_ROUGH_WALL to be clearer.; Or just WALL_ROUGHNESS as you have right now, since it would not really a marker, just the properties of markers (and I've seen some people on CFD online confused with similar naming e.g. MARKER_SHROUD). Regarding the MPI stuff, I had the following idea over lunch:; In CPhysicalGeometry::SetWallDistance we compute the closest distance, and in so doing we also get the mpi rank and markerID associated with the closest vertex.; So, before computing the wall distances you communicate the local marker ids and wall roughness's (via Allgather as you are doing now), with this info you can build a `unordered_map<pair<int,int>, su2double>` to map pairs of <rank,markerID> to the values of roughness.; Now when you loop over the points to compute the distances you can retrieve the roughness from this map instead of from config.; It's almost exactly the same as you have, but avoids using the config as a messenger between routines, and using a stl map should also make the code simpler. In the boundary conditions you can still get the marker roughness via the marker tag as you are doing now, and I guess the wall type (smooth / rough) can be inferred from having 0 (default) roughness (?); With the string+double list specification you also avoid having to specify 0 roughness and SMOOTH wall type for markers where you don't want to use this feature.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/877#issuecomment-630861158:49,clear,clearer,49,https://su2code.github.io,https://github.com/su2code/SU2/pull/877#issuecomment-630861158,2,"['clear', 'simpl']","['clearer', 'simpler']"
Usability,"Yes it definitely is confusing. Then we have to use set_ffd_design_var.py giving i,j,k which are not really 'units' in x,y,z. The website should be updated to show this. I am wondering how does SU2_DEF will determine the ""logic axis"". Won't a simple x,y,z approach have been simpler?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/977#issuecomment-626875076:243,simpl,simple,243,https://su2code.github.io,https://github.com/su2code/SU2/issues/977#issuecomment-626875076,2,['simpl'],"['simple', 'simpler']"
Usability,"Yes, I did not make that clear, the linear solver fraction of the time cannot be accelerated by this. But everything else can, from gradient/limiter computations to the Compute_Residual functions, as all those need to wait for data, it is however not very easy to measure how long that wait is compared to the rest of the computations.; In the 2015 joint work between Stanford and Intel they reported a 1.5x speed-up from this type of change for a case where the linear solver used 24% of the time. I do not know how heavy the CVariable infrastructure is now compared to then... We will see :)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/716#issuecomment-506768400:25,clear,clear,25,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-506768400,1,['clear'],['clear']
Usability,"Yes, nothing more from me on this. Once this is merged, the comparison in PR #1260 should become simpler too. I've just updated this branch with develop, we can merge once the regression tests pass again.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1174#issuecomment-827981242:97,simpl,simpler,97,https://su2code.github.io,https://github.com/su2code/SU2/pull/1174#issuecomment-827981242,1,['simpl'],['simpler']
Usability,"Yes, that is roughly what I mean. When I filed the issue, I was compiling in xcode, and it threw a bunch of warnings about implicit numeric casts. This is what the isssue was about. I'm off of develop and the moment, and don't have xcode setup, so I'm sorry I can't be more specific. I think they should all be unsigned long long. The memory overhead is trivial (8 bytes per node), and if we want the code to be usable in an exascale environment we don't want to limit ourselves to 4 billion node meshes.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/3#issuecomment-104354036:412,usab,usable,412,https://su2code.github.io,https://github.com/su2code/SU2/issues/3#issuecomment-104354036,1,['usab'],['usable']
Usability,"Yes, the GRAD_FLOW option has worked well for my simple application. I have not tried using it on other more complex problems or geometries.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/606#issuecomment-445429364:49,simpl,simple,49,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-445429364,1,['simpl'],['simple']
Usability,"Yet another doubt on the same subject: I just realized that SU2V7.31 (I; have not tested it on later SU2 releases) accepts imposing both adiabatic; walls plus isothermal boundary condition on some walls (when running Menter; model), but when I simply impose only isothermal conditions (leaving; commented out the adiabatic markers), I get the message: SU2 process; returned error '1'. Is there a workaround for this? Kind regards. On Thu, Sep 28, 2023 at 8:25 PM Pedro Gomes ***@***.***>; wrote:. > you are correct, there is a discussion on CFD-online about it. we impose 0; > heat flux, but report an ""apparent heat flux"" most codes will simply give; > you back the imposed heat flux value you specify, nevertheless there will; > probably be a temperature gradient close to the wall; >; > —; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/pull/2109#issuecomment-1740118992>, or; > unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AHGXZUUZNE6B63SH7XJLY2DX4YBMZANCNFSM6AAAAAA3QKLVDU>; > .; > You are receiving this because you commented.Message ID:; > ***@***.***>; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/2109#issuecomment-1775968391:244,simpl,simply,244,https://su2code.github.io,https://github.com/su2code/SU2/pull/2109#issuecomment-1775968391,2,['simpl'],['simply']
Usability,"Yikes. Thanks, @LaSerpe, for the heads up. There is clearly something wrong with SU2_SOL for many of the cases, although the compute portion is fine. We should get a test case set up for SU2_SOL, or at least try to catch these errors too. @fpalacios, can you please take a look at this problem when you have a moment? It seems to have shown up with the merging of feature_cte_cl. Just fyi for all: the Travis CI folks have generously granted extra time for our regression tests, up to 70 minutes now. This fixes the time-out issues in the short term, but there are a few strategies we should look at for caching or further decomposing our builds to keep under the time limits in the future as we keep growing.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/325#issuecomment-262118156:52,clear,clearly,52,https://su2code.github.io,https://github.com/su2code/SU2/pull/325#issuecomment-262118156,1,['clear'],['clearly']
Usability,"You are proposing the exact opposite of the conclusion of the paper:. ""From the above findings, it is **recommended that all three of these terms be included** when; running hypersonic, or even supersonic, turbulent flow simulations, especially for flows with; shock wave-induced separations."". And they clearly say this:; ""While the full inclusion of these terms does not always result in predictions that agree better; with DNS/experimental data, this is likely caused by the fact that their exclusion cancels out; effects of other flaws in the RANS models employed."". If your strategy is to get a better match with experiments by neglecting physics terms, then you should rethink your strategy.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1851#issuecomment-1520849562:304,clear,clearly,304,https://su2code.github.io,https://github.com/su2code/SU2/issues/1851#issuecomment-1520849562,1,['clear'],['clearly']
Usability,"You could modify `CWindowedAverage::addValue` to only ""push back"" more values if it detects a change in current time iteration, otherwise it simple overwrites the last value in the history.; Then you could get rid of the entire logic in `SetUpdate_Averages` simply making it true or false (less logic is the way for less bugs).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1259#issuecomment-817952886:141,simpl,simple,141,https://su2code.github.io,https://github.com/su2code/SU2/pull/1259#issuecomment-817952886,2,['simpl'],"['simple', 'simply']"
Usability,"You could try turning off or simplifying the contributions to the Jacobian for that type of boundary, see CNSSolver.ccp around line 550. For example, leaving only the `Jacobian_i[nDim+1][nDim+1]` or none.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1872#issuecomment-1370867223:29,simpl,simplifying,29,https://su2code.github.io,https://github.com/su2code/SU2/issues/1872#issuecomment-1370867223,1,['simpl'],['simplifying']
Usability,"You're right about that bug with vel_i_corr. Thanks for finding it, I'll submit a correction. Yes, it's possible to modify the config file so that your implementation works. But is this simply masking the problem of reduced stability? Do you expect the direct formulation to be less stable? And do the benefits of the direct formulation make the loss of stability worthwhile? If so, then I think you should change the config file. I hope this answers your question, I'm not sure if I understood it correctly. Regards,; Daniel",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/232#issuecomment-182655391:186,simpl,simply,186,https://su2code.github.io,https://github.com/su2code/SU2/pull/232#issuecomment-182655391,1,['simpl'],['simply']
Usability,"```diff; $ git --no-pager diff --cached ; diff --git a/meson.build b/meson.build; index ca86992ea..b68a03c52 100644; --- a/meson.build; +++ b/meson.build; @@ -1,15 +1,12 @@; project('SU2', 'c', 'cpp',; version: '7.5.1 ""Blackbird""',; + meson_version: '0.61.1',; license: 'LGPL2',; default_options: ['buildtype=release',; 'warning_level=0',; 'c_std=c99',; 'cpp_std=c++11']); ; -if meson.version() != '0.61.1'; - error('SU2 must be configured with the extended Meson script (./meson.py) in the SU2 root directory.'); -endif; -; pymod = import('python'); python = pymod.find_installation(); ; ```. I used this patch, and then ran the following:. ```; $ meson setup builddir --wipe; The Meson build system; Version: 1.0.1; Source dir: /tmp/SU2; Build dir: /tmp/SU2/builddir; Build type: native build. meson.build:1:0: ERROR: Meson version is 1.0.1 but project requires 0.61.1; ```. Using the >= comparison, it configures fine, and downloads a git submodule for mutationpp/coolprop on demand. From a hasty look around, it seems like the other git submodules are used as externals/ directories, not meson subprojects. Another project I know uses e.g. ```; if not fs.exists('submoduledir/README.md'); error('Missing the `submoduledir` submodule! Run `git submodule update --init` to fix this.'); endif; ```. for each submodule before it gets processed by meson. This is less automatic than wrapping it in meson.py, but does provide pretty clear directions... the sticking point is if people download tarballs. You currently point people to github's autogenerated archives, which is NOT sufficient as it doesn't have submodules included. I would actually suggest using `meson dist --include-subprojects --no-tests` to produce your own tarballs and attach them as additional releases artifacts. Meson *does* include submodules (whether or not they are subprojects) automatically to the tarball it creates.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1945#issuecomment-1451057434:1431,clear,clear,1431,https://su2code.github.io,https://github.com/su2code/SU2/issues/1945#issuecomment-1451057434,1,['clear'],['clear']
Usability,"anced programming may become an entrance barrier to new additions to the community. As I wrote in the preamble of #789:; ""But please participate even if you never heard of these topics, your opinion about readability and ""developability"" of the code is important! I think the code-style should be accessible to people starting a PhD (after they read a bit about C++...).""; I try to encapsulate and hide the tricky bits as much as possible to make the code as readable as possible, whether I am succeeding or not is for the community to decide, in all these PR's I've been pointing to the areas I think are trickier, if someone, anyone, feels they are absolutely incomprehensible please say something... either here, or trough slack, or by email (I think it shows in the commits) (I understand not everyone is keen on github exposure). > I'm aware that you have been doing very well at documenting the code and the various PRs, but I'd say we should try to find an strategy to ease the learning curve on potential new developers (maybe some developer tutorials? a collection of the comments/discussions on the PRs moved to the wiki? a list of links/useful resources?). I agree with documentation of broad design decisions, that is the intent of #789, and developer tutorials (how to implement a new X) once we are content with the restructurings, otherwise they will quickly go outdated... or actually...; We should probably first think about the answers to ""how to implement a new X"" and restructure/refactor as a function of that.; Based on previous efforts of maintaining wiki's updated while code is being developed, I much prefer this github style where you can clearly tell what version of the code the comments refer to. A collection of comments/discussions organized by topic and linked to a feature is somewhat what I had in mind when I opened a ""big PR"" (#824) with little branches such as this one, I can try to complete that with a list of links/useful resources, references as it were, goo",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/843#issuecomment-577684728:4580,learn,learning,4580,https://su2code.github.io,https://github.com/su2code/SU2/pull/843#issuecomment-577684728,1,['learn'],['learning']
Usability,"are mentioning is the same. I simply united the TIP, LOWER_SIDE and UPPER_SIDE under the marker tag WING. > The initial transient through the domain based on the initial values is unphysical to some extend and if e.g. 'steady state' results are the same for both code versions .... the problem is not that big. Although it differs quite a bit in the temporal evolution tbh; In the results (also in the mail) it looks a bit like it approaches a steady state for Cl and CD. So maybe 1000 timesteps will tell us a bit more 🤔. I guess they converge eventually to the same values. I tried to compare the same case but steady (I attach the summary). Results in this case are fairly similar and (in my opinion) raise no warnings.; [Summary_steady_6_0_1.txt](https://github.com/su2code/SU2/files/3906039/Summary_steady_6_0_1.txt); [Summary_steady_6_2_0.txt](https://github.com/su2code/SU2/files/3906010/Summary_steady_6_2_0.txt). Regarding the unsteady case, I'm aware that this test may have little physics behind (especially if comparing the first timesteps) but I wanted to investigate the reason :). Results are too different and I think these might be one of the reasons behind some discrepancies I'm encountering in my FSI framework. ; My framework for FSI features a restart from a steady solution at t=0 and an unsteady simulation with imposed boundary of the wing marker. The discrepancies in that case are huge and are clearly wrong. I went back to the root and found this weird behaviour comparing the two versions so I thought this might be one cause. > Another thing: There is no tag 6.0.2 😕 ... 6.0.1 and then 6.1.0.. Yep you are right, the version is definitely 6.0.1 as it can be seen from the Summaries: **I'm updating the issue.**. > And both versions are/were on the develop branches -> what exactly do you refer to here: config-files, code, mesh. Didn't quite understand you here. Let me know if you need any other info regarding the topic. Looking forward to hear from you!. Best,; Rocco",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/828#issuecomment-559850074:1751,clear,clearly,1751,https://su2code.github.io,https://github.com/su2code/SU2/issues/828#issuecomment-559850074,1,['clear'],['clearly']
Usability,"ares (indeed what I need now is a QR decomposition). And, as an added bonus, I think some other areas of the code could be simplified / optimized by adopting a dense matrix format, for example:; - This snipped from the viscous numerics refactoring`for (iDim = 0; iDim < nDim; iDim++) {; TauElem[iDim] = 0.0;; for (jDim = 0; jDim < nDim; jDim++); TauElem[iDim] += tau[iDim][jDim]*UnitNormal[jDim];; }` would simply become `TauElem=tau*UnitNormal`; - Cumbersome allocations like `tau_jacobian_i = new su2double* [nDim];; for (iDim = 0; iDim < nDim; iDim++) {; tau_jacobian_i[iDim] = new su2double [nVar];; }` become `Matrix tau_jacobian_i(nDim,nVar);` and the cleanup is dealt with by the destructor of the object automatically. Now to answer some questions.; @juanjosealonso @erangit LAPACK and BLAS are indeed the standard, so much so that most (all?) newer libraries will call their routines behind the scenes.; However they considerably simplify the user interface by encapsulating the aforementioned construction/destruction and by exposing natural ways of manipulating the matrices, e.g. access entire rows, columns, blocks, etc.; Another issue with using BLAS routines is that we then need to provide a portable version that can be differentiated with CoDi or to implement the exact differentiation (similar to what is done in the ""solve_b"" routines). @vdweide that is not an issue with Eigen because everything is templated and therefore compatible with any type or class that overloads the appropriate arithmetic operators.; I have used it for over 2 years and I can attest to its compatibility with AD tools (I've tried 3), and speed when linked with a BLAS library, their native implementations are also very good, peeking inside their code... you can tell they know what they are doing. P.S. I feel this post needs a disclaimer, I am not affiliated in any way to Eigen, my motivation is not to promote their work (but I obviously think they deserve it). I genuinely think adopting an algebr",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/643#issuecomment-459653772:1960,simpl,simplify,1960,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459653772,1,['simpl'],['simplify']
Usability,"atm that still sounds like magic to me,... I really should learn this github stuff. But I was more hoping some experienced coder would pick this up instead of my messing up the code.; Also I dont yet understand the way you guys work with branches instead of regular forked code...",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/688#issuecomment-495360476:59,learn,learn,59,https://su2code.github.io,https://github.com/su2code/SU2/issues/688#issuecomment-495360476,1,['learn'],['learn']
Usability,"aybe you refer to the develop code at the time where these tags were introduced. But maybe sth different. > I guess they converge eventually to the same values. I tried to compare the same case but steady (I attach the summary). Results in this case are fairly similar and (in my opinion) raise no warnings. That is good to hear. ; Luckily @cvencro (Thanks for that 👍 ) ran some tests and found that #740 (which rewrites Euler Wall boundaries for compressible and incompressible flows ... which was me btw) introduces the changes you see. The Euler wall for compressible is changed a bit in the way the boundary condition is enforced. Upon convergence both version should recover (close to) the same value. If the results in a steady state are the same/very-similar and if an unsteady simulation at low enough Reynolds-number converges to the same steady result (or oscillate in the same bounds) -> I would say it is simply some purely numerical effect based on the unphysical initialization and different treatment of the euler wall boundary. . 1 thing one could test additionally is to force a very high convergence in each physical timestep, i.e. usually one converges ~3 orders of magnitude in each ts -> now try converging until residual stalling in each ts. If the code versions get the same/closer results in the temporal evolution my euler wall boundary explanation would be quite reasonable.; Together with the long running unsteady simulation proposed above, I would feel more comfortable to judge. @cvencro (bringing the conversation to this place 😉 ) concerning the pitching case: the `if (dynamic_grid)` statements in the 'old' version are not necessary as that is handled by the numerics class. In the new version an appropriate 'reflected state' is constructed and the numerics container is called to compute the residual. Before, the code of one numerics ->ComputeResidual Routine was simply copied and slightly modified. But of course there is always room for errors 🐛 . Cheers, Tobi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/828#issuecomment-562621057:2218,simpl,simply,2218,https://su2code.github.io,https://github.com/su2code/SU2/issues/828#issuecomment-562621057,1,['simpl'],['simply']
Usability,"ble-multilib --disable-werror --enable-checking=release --enable-default-pie --enable-default-ssp --enable-cet=auto gdc_include_dir=/usr/include/dlang/gdc; Thread model: posix; gcc version 9.2.1 20200130 (Arch Linux 9.2.1+20200130-2) ; ```; I did what you suggested and here is how my meson.build file looks.; ```; # If custom mpi mode is enabled, include and library pathes for MPI have to be set manually to env variables; if get_option('custom-mpi'); mpi_dep = []; mpi = true; # Otherwise they are automatically determined; else; mpi_dep = [dependency('mpich', required : get_option('with-mpi'))]; # mpi_dep = [dependency('mpi', language:'c', required : get_option('with-mpi')),; # dependency('mpi', language:'cpp', required : get_option('with-mpi'))]; #if mpi_dep[0].found() or mpi_dep[1].found(); # mpi = true; #endif; endif; ```; My SU2 build was successful but there were a couple of warnings.; Also, instead of 870 there were only 772 files in total. Is that okay?; ```; slimshady@arch-linux-hp-probook-g3-450: SU2HOME$ ./ninja -C build install; ninja: Entering directory `build'; [756/772] Generating 'SU2_PY/pySU2/_pysu2.so.p/pySU2.cxx'.; ../SU2_PY/pySU2/../../Common/include/mpi_structure.hpp:348: Warning 325: Nested struct not currently supported (Status ignored); [760/772] Generating 'SU2_PY/pySU2/_pysu2ad.so.p/pySU2ad.cxx'.; ../SU2_PY/pySU2/../../Common/include/mpi_structure.hpp:348: Warning 325: Nested struct not currently supported (Status ignored); [771/772] Installing files.; .; .; ```; Here is the [entire output for `./ninja`](https://github.com/su2code/SU2/files/4672490/ninja_build_mpich.log). Even though the build was successful, SU2 does not seem to run properly. It displays the same thing ""NP"" (`mpirun -n NP ...`) number of times. And the console prints the output in chunks, like 57 iterations suddenly ""NP"" times, then a pause, then 57-119 ""NP"" times and so on. You can see the [logfile here](https://github.com/su2code/SU2/files/4672491/mpirun_SU2_CFD_error.log).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1000#issuecomment-633139474:2869,pause,pause,2869,https://su2code.github.io,https://github.com/su2code/SU2/issues/1000#issuecomment-633139474,1,['pause'],['pause']
Usability,"c` we resolve 4/8 row/column pairs into 1D indexes, while this calculation is vectorized, it seems to be less optimizable by compilers, for example this; ```c++; for(size_t iDim=0; iDim<nDim; ++iDim); phiL += grad.getVec(iPoint,iVar,iDim)*d_ij[iDim];; ```; gets compiled into this monstrosity; ```asm; .L13:; vpmuludq ymm0, ymm4, ymm1; vmovq xmm15, rax; vmovapd ymm6, ymm11; mov rdx, rax; vpbroadcastq ymm15, xmm15; sal rdx, 5; add rax, 1; vpaddq ymm0, ymm0, ymm2; vpsllq ymm0, ymm0, 32; vpaddq ymm0, ymm5, ymm0; vmovdqa YMMWORD PTR [rbp-240], ymm0; vpaddq ymm0, ymm3, ymm0; vmovdqa YMMWORD PTR [rbp-208], ymm0; vpaddq ymm0, ymm15, ymm0; vmovdqa YMMWORD PTR [rbp-176], ymm0; vgatherqpd ymm15, QWORD PTR [rdi+ymm0*8], ymm6; vmovapd ymm0, YMMWORD PTR [rsi+rdx]; vfmadd213pd ymm0, ymm15, YMMWORD PTR [rbp-336]; vmovapd YMMWORD PTR [rbp-336], ymm0; cmp rbx, rax; jne .L13; ```; the meat of which is `vgatherqpd` (`getVec`) and `vfmadd213pd` fused-multiply-add to update `phiL`, everything else is integer arithmetic which in the scalar version gets factored out of the inner loop so that the resulting assembly looks much simpler:; ```asm; .L15:; vmovsd xmm5, QWORD PTR [rsp-40+rax*8]; vfmadd231sd xmm0, xmm5, QWORD PTR [r15+rax*8]; add rax, 1; cmp rcx, rax; jne .L15; ```; I think the reason for this is that there are plenty of integer registers (64bit) to keep memory locations (rsp, rax, r15 in the above) but there are only 16 ymm registers (256bit). In any case we need to give the compiler a hand, the calculation we need is; `index = iPoint*nVar*nDim + iVar*nDim + iDim` where iPoint is an array of ints; Note that as we loop by nDim and then by nVar all we need is to compute `iPoint*nVar*nDim` outside the loops and then add 1 on each access (which is more or less what the compiler does for the scalar code), in other words we need an **iterator**, something silly like; ```c++; template<size_t VecLen, size_t Incr = VecLen>; class GatherIterator; {; private:; using IntVec = Array<size_t,VecLe",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-535977206:10256,simpl,simpler,10256,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206,1,['simpl'],['simpler']
Usability,"doc/libs/1_70_0/libs/test/doc/html/index.html>.; > This provides a convenient set of macros for instatiating tests, grouping; > tests into suites, and running checks. This choice was based on what is; > available in our development setup.; >; > We have integrated our unit tests into our Travis CI regression testing.; > Every time we push commits or submit a pull request, the unit tests are run; > and checked.; > What is my vision for unit testing in SU2?; >; > I am *not* proposing that we start trying to get 100% code coverage with; > pre-existing code. That would not provide a good return on investment.; >; > Instead, I see people adding unit tests as they write new code and as they; > find bugs. For each new behavior added to SU2, tests are first added to; > document the related existing behavior. These tests serve to check that the; > existing behavior isn't damaged by the new code. Then new tests are added; > to prove that the new behavior is working correctly. For bug fixes, the; > process is simpler. A test is added to confirm that something is not; > behaving as expected. Then the code is fixed to make the test pass.; > What frameworks are available?; >; > For a unit testing framework, here are the most popular options, with the; > following pros and cons:; > Roll-your-own; >; > - Requires no external dependencies; > - The most flexible option; > - Involves the most work to setup; > - Will lack some of the more advances features of mature unit-testing; > frameworks.; >; > Boost Test; >; > - Can be header only, statically linked, or dynamically linked; > - If statically or dynamically linked, then Boost is not very; > lightweight; > - Easy to add if you're already using Boost; >; > Google Test; >; > - Most common unit-testing framework; > - Can be easily combined with Google's powerful GMock mocking library; > - Compiling and linking can be somewhat painful; >; > Catch2; >; > - Used by FEniCS; > - Makes unit tests easily readable with lots of syntactic sugar.;",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499278427:5298,simpl,simpler,5298,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427,1,['simpl'],['simpler']
Usability,"dweide; >(...) @bmunguia and @EduardoMolina, what type of application did you have in mind for PETSc? The only thing I can think of is a full Newton solver. And no matter how much I like PETSc, @juanjosealonso and @erangit have a point here. Looks like I start to belong to the group of old conservatives as well.... >@economon ; >(...) If you really would like to give PETSc a shot, I recommend talking with @anilvar who had an interface for connecting it to SU2 in one of our branches. >@pcarruscag; >(...) being able to use PETSc or HYPRE would be interesting as it would give us access to AMG, and @talbring 's branch feature_template_linear_solver would make such an integration compatible with AD. (...). >@EduardoMolina; >(...) When Brian (@bmunguia ) and I mentioned PETSc, it was an idea to try a different Newton-Krylov (with preconditioner) library in order to improve the convergence of SU2.; Since the slow convergence of the SU2-FV is the main feedback that I received from other users from industry and academia, I think it worth try an external library and evaluate the performance. (...). >@pcarruscag ; >(...) That is something I am also interested in as for some of my structural cases the current linear solvers simply do not converge. (...). >@economon ; >I would add one practical comment for consideration: it is worth checking whether the main restriction we have is related to approximations in the Jacobian that limit the effective CFL we can use or whether the convergence of the linear solver itself is a problem (speed or complete lack of convergence). A quick test without resorting to another library is to increase the fill-in for ILU-preconditioned GMRES, which is very expensive/slow but should converge difficult problems, and to check how high we can take the CFL when allowing each nonlinear iteration to converge to a tight tolerance in the linear solver, say 1e-14 (you can output the linear solver residuals to verify convergence). If we can take the CFL higher",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/648#issuecomment-460853218:2821,feedback,feedback,2821,https://su2code.github.io,https://github.com/su2code/SU2/issues/648#issuecomment-460853218,1,['feedback'],['feedback']
Usability,"ed the linear solvers stay the same and routines that are light see more speedup than their arithmetic-intensive friends.; What is surprising to me is how intensive the convective residuals appear to be with only a 7% improvement, so surprising in fact, I do not think the above paints the full picture. Maybe the outlet bandwidth bottleneck (into the Jacobian matrix) is more important.; To put that do the test I switched to Euler-explicit time marching and repeated the measurements:; ![image](https://user-images.githubusercontent.com/38071223/63293351-d8010b80-c2bf-11e9-8135-2502eac1128e.png); Better, but not by much, which means upwind and viscous residuals computations might gain a lot from vectorization (SIMD). And like @economon mentioned even more if they are somehow fused together.; It also means the writes to CSysMatrix are relatively expensive, I think there are two-three reasons for it.; - We do a linear search on each Add/SubtractBlock - This could be replaced by a map.; - The Jacobian contributions are first written into a temporary block - Interleaving the writes with the computation could help mask latency.; - That temporary is not stored contiguously - Which makes it hard to vectorize the writes to CSysMatrix. **So what do I think should be tackled next?**; Hybrid parallelism (wait what?!) from messing about with this case (and more refined versions) it is clear the MG puts some limits on how many cores can be used before it stops being able to produce coarse grids, both in number and quality. Going to an MPI+Threads strategy would move that limit by one order of magnitude, giving us some robustness and performance for folks hoping to rely on strong scaling. I think I'll break it off here and keep my thoughts about SIMD and hybrid parallel for a later occasion (I have to do some ""real"" PhD work for a while) but please, if anyone has ideias, comments, corrections, suggestions, similar ongoing developments (specially)... I am all ears/eyes. Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/716#issuecomment-522730951:5345,clear,clear,5345,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-522730951,1,['clear'],['clear']
Usability,"en new tests are added; > to prove that the new behavior is working correctly. For bug fixes, the; > process is simpler. A test is added to confirm that something is not; > behaving as expected. Then the code is fixed to make the test pass.; > What frameworks are available?; >; > For a unit testing framework, here are the most popular options, with the; > following pros and cons:; > Roll-your-own; >; > - Requires no external dependencies; > - The most flexible option; > - Involves the most work to setup; > - Will lack some of the more advances features of mature unit-testing; > frameworks.; >; > Boost Test; >; > - Can be header only, statically linked, or dynamically linked; > - If statically or dynamically linked, then Boost is not very; > lightweight; > - Easy to add if you're already using Boost; >; > Google Test; >; > - Most common unit-testing framework; > - Can be easily combined with Google's powerful GMock mocking library; > - Compiling and linking can be somewhat painful; >; > Catch2; >; > - Used by FEniCS; > - Makes unit tests easily readable with lots of syntactic sugar.; > - Has a very simple syntax; > - Is header-only; > - Requires C++11 compilation; > - Not as feature rich as Google Test or Boost Test; >; > Questions; >; > - How do developers feel about adding unit tests to SU2?; > - If a unit-testing framework were added to SU2, would you actually; > use it?; > - Do developers have a preference (or experience with) any of the unit; > testing frameworks?; > - Should unit tests be expected when submitting PRs?; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/issues/698?email_source=notifications&email_token=AA5FFRG5U3Z55N4W2XWQED3PY3LJ5A5CNFSM4HTDQXQKYY3PNVWWK3TUL52HS4DFUVEXG43VMWVGG33NNVSW45C7NFSM4GXUGGLA>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AA5FFRHOPE2MUJ2Z5RRV4HTPY3LJ5ANCNFSM4HTDQXQA>; > .; >; >; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/698#issuecomment-499278427:6301,simpl,simple,6301,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427,1,['simpl'],['simple']
Usability,"eps for unsteady problems.; * Loop over the number of pseudo-time steps for implicit time integration schemes; (DT_STEPPING_1ST and DT_STEPPING_2ND). For other cases this loop is 1.; * Loop over the number of disciplines involved; Call iterate for each of the disciplines.; In iterate:; * Loop over the (Runge-Kutta) stages; * Loop over the zones of a single discipline; Compute spatial residual.; Update the state vector.; * End loop over the zones of a single discipline.; Exchange halo data. This includes the halo data between zones of a single discipline.; * End loop over the (Runge-Kutta) stages; * End loop over the disciplines; * End loop over the pseudo time steps.; * End loop over the number of iterations, or time steps for unsteady problems. The weakness of this approach is that it still does not work when one would like to employ multi-stage time integration schemes for an unsteady, multi-disciplinary problem (does not work for the current implementation either), but maybe this is something we simply have to accept. The alternative is that all the details of the different time integration schemes have to be moved to the driver classes, which is highly undesirable, I think. The structure above implies that the iteration_container and the integration_container should be defined per discipline and not per zone anymore. The geometry_container and solver_container should still be defined per zone. Well, I suppose this leaves plenty of room for discussion, so I would say to continue the online discussion a bit further, such that things become a bit clearer how to tackle this issue. After that having a telecon would be good to iron out the details. Regards,. Edwin. —; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/437#issuecomment-328368371>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADpSxHiNAbZtzVEvIm0XDsNvQmZ6lrwwks5shEHjgaJpZM4PQ90s>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/437#issuecomment-328403160:3735,clear,clearer,3735,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328403160,1,['clear'],['clearer']
Usability,"fiers that can later allow for a generality of approaches. We can make a distinction between wall functions and wall models, but this is subject to discussion…in essence both are performing similar duties, but people should express their opinions. With that said, how about a boolean such as USE_WALL_FUNCTIONS / USE_WALL_MODEL (YES or NO) with an optional argument WALL_FUNCTION_TYPE / WALL_MODEL_TYPE that can taken one of many pre-specified values that can be added as these options are developed and tested? Certainly options like STANDARD_WALL_FUNCTION, ADAPTIVE_WALL_FUNCTION, SCALABLE_WALL_FUNCTION, compressible and incompressible versions, and even EQUILIBRIUM_WALL_MODEL and NONEQUILIBRIUM_WALL_MODEL are things that are likely to be in the code in the near future. Thoughts?. Juan. On Sep 5, 2017, at 2:27 PM, Thomas D. Economon <notifications@github.com<mailto:notifications@github.com>> wrote:. @petebachant<https://github.com/petebachant>: the paper that I linked earlier on this thread had some fairly simple examples similar to the one you propose.. different flat plates and so on with varying y^+. You can likely reuse the grid(s) in the TestCases repo. @vdweide<https://github.com/vdweide>: it was very simple in this first implementation. It checks for a single boolean for whether or not to apply wall functions (WALL_FUNCTIONS= YES or NO, https://github.com/su2code/SU2/blob/43b8a4015c4b09b01d78e4243d32011c663c2b70/SU2_CFD/src/solver_direct_mean.cpp#L15339), and then assumes they should be applied to all no-slip walls (heat flux or isothermal, https://github.com/su2code/SU2/blob/43b8a4015c4b09b01d78e4243d32011c663c2b70/SU2_CFD/src/solver_direct_mean.cpp#L16653). This could of course be made more specific for individual markers using a config structure like MARKER_MONITORING to list them, or by making a dedicated BC type for it potentially. —; You are receiving this because you commented.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/399#issuecomment-327313634:1203,simpl,simple,1203,https://su2code.github.io,https://github.com/su2code/SU2/issues/399#issuecomment-327313634,1,['simpl'],['simple']
Usability,"formance, here is the effect of color group size on the execution time of the scalar code on one thread:; ![image](https://user-images.githubusercontent.com/38071223/64686801-2e0d3d00-d481-11e9-82a0-c56e5554cd83.png); The hassle-free option of not sorting by color ""never"" recovers the performance of the base algorithm, things are even worse for the SIMD version where even at group size of 8192 with re-sorting the slowdown is 14%. Running the edge-loop version on 4 cores (8192 group + sorting) we get speedups (relative to reference) of **1.98** and **2.04** for the scalar and SIMD versions respectively (yes I quadruple checked).; If you are keeping track of the number two things should surprise you, the first is that there is no difference between scalar and SIMD now (the vector instruction are still there though), the second is that 4 cores give only a 2x speedup. The reason for both is: the implementation is very memory-bound, and so throwing more compute at it, either in the form of more cores or more lanes, does not help much. This is the 4 core summary:. | Code | Edge | Edge, SIMD on vars | Point | Point, SIMD on points |; | ---- | ---- | ---- | ---- | ---- |; | **Speed** | 2.0 | 2.0 | 3.8 | 2.8 |. I think the point-based versions scale better because they are a bit less memory-bound as they write to the gradient sequentially and they have a bit more compute due to the duplicated computations. **Conclusion**; Computing gradients via point-loops allows simpler and more generic SIMD and SPMD strategies, the resulting implementation seems to do better in the bandwidth-starved conditions typical of modern hardware (3 or more cores per memory channel). However, additional adjacency information is required to support point-based loops. Next I will talk about limiters, almost all concepts are introduced so it will be shorter (promise). As a little appetizer let me tell you we can recover the extra memory and we could be looking at a 2.7x speedup for gradients+limiters.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-530328194:15283,simpl,simpler,15283,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530328194,1,['simpl'],['simpler']
Usability,"from the original `issue_simplified` singlezone solution with implicit Euler and CFL=1000. ; - similar to the `issue_simplified` multizone solution with implicit Euler and CFL=0.1. . Similarly, the TKE plots:; - `issue_simplified` singlezone implicit Euler CFL=1000; ![tke-simplified-singlezone-impliciteuler](https://user-images.githubusercontent.com/72806890/140887227-fc2ed584-53cf-413d-b5ad-18d1a12f5e4a.png); - `issue_simplified` singlezone explicit Euler CFL=0.1; ![tke-simplified-singlezone-expliciteuler](https://user-images.githubusercontent.com/72806890/140887289-0d8725a2-e51b-4704-bdae-a51b492949bf.png); (it is ""red"" throughout the domain, except for the wall marker); - `issue_simplified` multizone explicit Euler CFL=0.1: (similar image, ""red"" everywhere except wall). **Thus, the difference in solutions observed above is due to the choice of implicit vs. explicit Euler and CFL, and not due to problems regarding the interface.**. Am I doing something wrong in the explicit Euler [cfg file](https://seafile.rlp.net/d/bb0fbb16eb414263b642/files/?p=%2Fsinglezone-simplfied-expliciteuler-cfl01.cfg&dl=1), whose diff to the [SU2/TestCases/rans/naca0012/turb_NACA0012_sst.cfg](https://github.com/su2code/SU2/blob/v7.2.0/TestCases/rans/naca0012/turb_NACA0012_sst.cfg) is as follows?. 27c27; < RESTART_SOL= NO; ---; > RESTART_SOL= YES; 45c45; < REYNOLDS_NUMBER= 1.0E6; ---; > REYNOLDS_NUMBER= 6.0E6; 70c70; < MARKER_HEATFLUX= ( circle, 0.0 ); ---; > MARKER_HEATFLUX= ( airfoil, 0.0 ); 76c76; < MARKER_PLOTTING= ( circle ); ---; > MARKER_PLOTTING= ( airfoil ); 79c79; < MARKER_MONITORING= ( circle ); ---; > MARKER_MONITORING= ( airfoil ); 88c88; < CFL_NUMBER= 0.1; ---; > CFL_NUMBER= 1000.0; 101c101; < ITER= 9999900; ---; > ITER= 99999; 162c162; < TIME_DISCRE_FLOW= EULER_EXPLICIT; ---; > TIME_DISCRE_FLOW= EULER_IMPLICIT; 177c177; < TIME_DISCRE_TURB= EULER_EXPLICIT; ---; > TIME_DISCRE_TURB= EULER_IMPLICIT; 203c203; < MESH_FILENAME= singlezone.su2; ---; > MESH_FILENAME= n0012_225-65.su2",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1414#issuecomment-963921195:2643,simpl,simplfied-expliciteuler-,2643,https://su2code.github.io,https://github.com/su2code/SU2/issues/1414#issuecomment-963921195,1,['simpl'],['simplfied-expliciteuler-']
Usability,"gy terms? I'm talking about terms like:. ![molecular and turbulent diffusion of tke](https://latex.codecogs.com/gif.latex?\left(&space;\mu&space;&plus;&space;\frac{\mu_t}{\sigma_k}\right)\frac{\partial&space;k}{\partial&space;x_j}). This term is listed both in Wilcox's ""Turbulence Modeling for CFD"" book and the [NASA TMR website](https://turbmodels.larc.nasa.gov/implementrans.html). NASA's page basically just copies what Wilcox states, and then says ""This expression in the energy equation is also sometimes neglected."". Rumsey clarified his position in a [2009 report](https://ntrs.nasa.gov/archive/nasa/casi.ntrs.nasa.gov/20090015399.pdf), saying that ""when considering high Mach number compressible boundary layer flows using k-omega models, the conservation of total energy should be configured to include the contribution of the turbulent kinetic energy k... It is sometimes common practice to ignore these effects, which is certainly justified when k is signficantly smaller than the square of the mean velocity."" . But he also states: ""Note that in CFL3D, the turbulence models are decoupled from the mean flow equations, k is *not* included in the definition of the total energy, and the diffusion of k does not appear in the mean flow energy equation for its models tested here."" He also omitted the 2/3 \rho k term in both the production and the turbulent stress tensor, and found that it made little difference even for M=10 wall-bounded flows. SU2's version of SST is in a weird spot right now, where it's using the turbulent kinetic energy in some places but not others. It's using it here:. + Total energy definition; + Production of turbulent kinetic energy; + RANS evolution equations; + Eddy viscosity definition. But not here:. + Molecular and turbulent diffusion of turbulent kinetic energy in the total energy conservation equation; + Isotropic part of the turbulent stress tensor. Is there any rationale behind this split, aside from simply stating that ""this seems to work?""",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/797#issuecomment-548886007:2122,simpl,simply,2122,https://su2code.github.io,https://github.com/su2code/SU2/issues/797#issuecomment-548886007,1,['simpl'],['simply']
Usability,"he preconditioner and solving the linear system.; Linear algebra routines called within this section have _worksharing_ constructs instead of _parallel_ ones, i.e. the work is distributed by however many threads arrive to that routine. This also makes the routines safe to call in serial.; The only ""dangerous"" things to do in parallel are to: manage memory for a shared object (multiple threads call `new` but there is only one shared pointer on which to call `delete`); writing to the same memory locations concurrently.; I tried to make the first issue debugable by asserting that the initialization routines of CSysMatrix and CSysVector are only called by the master thread.; For the second issue I made the associated classes as const-correct as possible, that should at least make someone think twice before changing a member variable of those classes. The risk is still there for input variables as an algorithm development aspect... For example `MatrixVectorProductTransposed` cannot be made thread-parallel as simply/naively as its normal counterpart. ### Communication Model; The MPI + Threads communication model is very simple, currently only the master thread calls MPI routines (including `Error`), this requires thread barriers before and after the communication to make sure the correct values are passed and _seen_ by all threads.; We can test other alternatives in the future but at the moment this does not seem to be a significant bottleneck.; _Worksharing_ constructs have implicit barriers at completion, for CSysVector routines I used `nowait` modifiers, it is safe to call those routines in sequence since the loop sizes, and static work scheduling specifications are identical.; However, routines that access a CSysVector in a different way, should have an explicit barrier before using the vector (or risk having undefined behaviour). You will see these barriers on entry to matrix-vector product, and every `ComputeXXXPreconditioner` (if you don't, let me know xD). I think",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/830#issuecomment-562646766:1597,simpl,simply,1597,https://su2code.github.io,https://github.com/su2code/SU2/pull/830#issuecomment-562646766,1,['simpl'],['simply']
Usability,"iVar, lim*(lim+2.0)/(lim*lim+lim+2.0));; }; }; }; ```; In terms of algorithm, for each point we find the min and max neighbor values and the min (negative) and max (positive) projections, those are then combined in a final `min(2, max/max, min/min)` to which the limiter function is applied (this would also be applicable to Venkatakrishnan-[Wang] limiters).; This is equivalent to the edge-loop, if statements are not required as due to cells being closed, if the positive projection is not zero, the negative one will also not be zero, therefore it is correct to always evaluate both ratios.; This algorithm only needs min and max neighbors as small local variables instead of large global ones due to the way those values are determined. This is where the memory from the extra adjacency information is recovered. Like @economon said, fusing the gradient kernel with the limiter kernel is trivial with these point loops, and I do not think it affects readability much since one can clearly tell ""what is what"" (I will not put it here but it really is a matter of copy paste), including the boundaries could be a bit more challenging, but I will give performance number nevertheless. **Performance summary**. | Code | Edge | Edge, SIMD on vars | Point | Point, SIMD on points |; | ---- | ---- | ---- | ---- | ---- |; | **Speed 1 core** | 1.0 | 1.75 | 1.25 | 2.0 |; | **Speed 4 cores** | 2.45 | 2.7 | 4.5 | 7.0 |. The basic point version does not lose to edge based because, contrary to gradients, it does not require duplication of computations while benefiting from sequential access to gradients.; Again the point-based implementation does really well in parallel, limiters are more compute intensive and so the scaling is almost perfect.; For reference, limiters are 1.9 times more expensive to compute than gradients with the reference edge version. With point loops, SIMD, and in parallel, gradients and limiters cost the same. If we consider the combined cost of gradients and limiters, and co",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-530593912:10014,clear,clearly,10014,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530593912,1,['clear'],['clearly']
Usability,"implified / optimized by adopting a dense matrix format, for example:; - This snipped from the viscous numerics refactoring`for (iDim = 0; iDim < nDim; iDim++) {; TauElem[iDim] = 0.0;; for (jDim = 0; jDim < nDim; jDim++); TauElem[iDim] += tau[iDim][jDim]*UnitNormal[jDim];; }` would simply become `TauElem=tau*UnitNormal`; - Cumbersome allocations like `tau_jacobian_i = new su2double* [nDim];; for (iDim = 0; iDim < nDim; iDim++) {; tau_jacobian_i[iDim] = new su2double [nVar];; }` become `Matrix tau_jacobian_i(nDim,nVar);` and the cleanup is dealt with by the destructor of the object automatically. Now to answer some questions.; @juanjosealonso @erangit LAPACK and BLAS are indeed the standard, so much so that most (all?) newer libraries will call their routines behind the scenes.; However they considerably simplify the user interface by encapsulating the aforementioned construction/destruction and by exposing natural ways of manipulating the matrices, e.g. access entire rows, columns, blocks, etc.; Another issue with using BLAS routines is that we then need to provide a portable version that can be differentiated with CoDi or to implement the exact differentiation (similar to what is done in the ""solve_b"" routines). @vdweide that is not an issue with Eigen because everything is templated and therefore compatible with any type or class that overloads the appropriate arithmetic operators.; I have used it for over 2 years and I can attest to its compatibility with AD tools (I've tried 3), and speed when linked with a BLAS library, their native implementations are also very good, peeking inside their code... you can tell they know what they are doing. P.S. I feel this post needs a disclaimer, I am not affiliated in any way to Eigen, my motivation is not to promote their work (but I obviously think they deserve it). I genuinely think adopting an algebra library (that is compatible with AD) would greatly simplify our work and further drop the entry barrier to new developers.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/643#issuecomment-459653772:3074,simpl,simplify,3074,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459653772,1,['simpl'],['simplify']
Usability,"in essence both are performing similar duties, but people should express their opinions. With that said, how about a boolean such as USE_WALL_FUNCTIONS / USE_WALL_MODEL (YES or NO) with an optional argument WALL_FUNCTION_TYPE / WALL_MODEL_TYPE that can taken one of many pre-specified values that can be added as these options are developed and tested? Certainly options like STANDARD_WALL_FUNCTION, ADAPTIVE_WALL_FUNCTION, SCALABLE_WALL_FUNCTION, compressible and incompressible versions, and even EQUILIBRIUM_WALL_MODEL and NONEQUILIBRIUM_WALL_MODEL are things that are likely to be in the code in the near future. Thoughts?. Juan. On Sep 5, 2017, at 2:27 PM, Thomas D. Economon <notifications@github.com<mailto:notifications@github.com>> wrote:. @petebachant<https://github.com/petebachant>: the paper that I linked earlier on this thread had some fairly simple examples similar to the one you propose.. different flat plates and so on with varying y^+. You can likely reuse the grid(s) in the TestCases repo. @vdweide<https://github.com/vdweide>: it was very simple in this first implementation. It checks for a single boolean for whether or not to apply wall functions (WALL_FUNCTIONS= YES or NO, https://github.com/su2code/SU2/blob/43b8a4015c4b09b01d78e4243d32011c663c2b70/SU2_CFD/src/solver_direct_mean.cpp#L15339), and then assumes they should be applied to all no-slip walls (heat flux or isothermal, https://github.com/su2code/SU2/blob/43b8a4015c4b09b01d78e4243d32011c663c2b70/SU2_CFD/src/solver_direct_mean.cpp#L16653). This could of course be made more specific for individual markers using a config structure like MARKER_MONITORING to list them, or by making a dedicated BC type for it potentially. —; You are receiving this because you commented.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/399#issuecomment-327308587>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADpSxJUhyEBSuSzHV1a7BZM_Frxbtb5sks5sfbzUgaJpZM4NvG6w>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/399#issuecomment-327313634:1408,simpl,simple,1408,https://su2code.github.io,https://github.com/su2code/SU2/issues/399#issuecomment-327313634,1,['simpl'],['simple']
Usability,"inf| -inf| 0.000000| 2.232692| -inf|; | 1| -3.281025| -inf| -inf| 0.000000| 3.198384| -inf|; ...; | 9531740| -11.999999| -inf| -inf| -0.006045| 1.258662| -inf|; | 9531741| -12.000000| -inf| -inf| -0.006045| 1.258662| -inf|; | 9531742| -12.000000| -inf| -inf| -0.006045| 1.258662| -inf|; ; ----------------------------- Solver Exit -------------------------------; All convergence criteria satisfied.; +-----------------------------------------------------------------------+; | Convergence Field | Value | Criterion | Converged |; +-----------------------------------------------------------------------+; | rms[Rho]| -12| < -12| Yes|; +-----------------------------------------------------------------------+. The density plot is; - different from the original `issue_simplified` singlezone solution with implicit Euler and CFL=1000. ; - similar to the `issue_simplified` multizone solution with implicit Euler and CFL=0.1. . Similarly, the TKE plots:; - `issue_simplified` singlezone implicit Euler CFL=1000; ![tke-simplified-singlezone-impliciteuler](https://user-images.githubusercontent.com/72806890/140887227-fc2ed584-53cf-413d-b5ad-18d1a12f5e4a.png); - `issue_simplified` singlezone explicit Euler CFL=0.1; ![tke-simplified-singlezone-expliciteuler](https://user-images.githubusercontent.com/72806890/140887289-0d8725a2-e51b-4704-bdae-a51b492949bf.png); (it is ""red"" throughout the domain, except for the wall marker); - `issue_simplified` multizone explicit Euler CFL=0.1: (similar image, ""red"" everywhere except wall). **Thus, the difference in solutions observed above is due to the choice of implicit vs. explicit Euler and CFL, and not due to problems regarding the interface.**. Am I doing something wrong in the explicit Euler [cfg file](https://seafile.rlp.net/d/bb0fbb16eb414263b642/files/?p=%2Fsinglezone-simplfied-expliciteuler-cfl01.cfg&dl=1), whose diff to the [SU2/TestCases/rans/naca0012/turb_NACA0012_sst.cfg](https://github.com/su2code/SU2/blob/v7.2.0/TestCases/rans/naca0012/",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/1414#issuecomment-963921195:1838,simpl,simplified-singlezone-impliciteuler,1838,https://su2code.github.io,https://github.com/su2code/SU2/issues/1414#issuecomment-963921195,1,['simpl'],['simplified-singlezone-impliciteuler']
Usability,"ion, the polymorphic overhead will be reduced to a single call (ComputeResidual), all auxiliary functions (like the ones that live in CNumerics) will be forcefully inlined, no useless copies of data (no more numerics->SetBlaBla).; - Compile time nDim/nVar, which will: a) avoid heap allocations; b) allow effective loop-unrolling (also during the writes to CSysMatrix).; - Allow low-overhead composition, e.g. have one CRoe for Euler and one CRoeVisc for NS to fuse convective and viscous residuals (without copy pasting code).; - A lot more readable, those cryptic V_i[iDim+1] need to go (somehow...). To achieve all this, the ""CNewNumerics"" will work as a template (obvs) decorator/visitor.; A visitor in the sense that the solver calls the numerics and gives it (read-only) access to all its data, the object pulls whatever it needs directly and there is no need for numerics->SetBlaBla.; A template decorator in the sense that the class can be augmented simply by inheriting from another, along the lines of `class CRoeVisc : public CRoe, public CVisc` (to allow fusing residual and Jacobian contributions).; All this needs to be done with templates for the ""minimal indirection"" requirement. Which means for each numerical method we will have 4 explicit template instantiations (Euler2D, Euler3D, (RA)NS2D, (RA)NS3D) but in the end these are still polymorphic objects that will be instantiated by some factory function (i.e. it will look clean, especially because I will not port all methods in one go xD). The template machinery to support this is actually not too crazy:; ```c++; #include <array>; #include <cmath>. // An example type to use instead of the container that stores solution data for all vertices.; struct SolutionContainer; {; std::array<double,3> velocity;; std::array<double,3> areaVector;; };. using ResultType = double;. // We want classes with this interface.; class VirtualInterface; {; public:; virtual ResultType Compute(const SolutionContainer&) const = 0;; };. // The Co",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-622941617:1476,simpl,simply,1476,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-622941617,1,['simpl'],['simply']
Usability,"ither. Some settings which are kinda optimal:; - Mach 0.6, AoA 2 degrees;; - SST (1st order);; - CFL 20 (higher and residuals would limit-cycle (regardless of linear solver settings); - Roe;; - MUSCL - Green-Gauss and Venkat-Wang;; - FGMRES + LU_SGS to 0.05 residual (about 3 iters on avg.);; - 2 levels of MG (1,1,2 iterations, all zeros for other stuff and 0.7 damping both ways);. The case is light on the linear solver and therefore stands to benefit the most from better data layout. Conversely, applications that can take higher CFL / or use central schemes will not benefit as much. **Running this from scratch to residual of 10^-8 on a couple of Xeon E5-2650v4 (24c total) shows a speedup of 1.4 and just over 10% lower memory usage.**; Those numbers will be better for an equivalent 2D case since the ratio of useful data to pointers and vtables is lower. After a celebratory dance I attempted to profile the code using [Perf](https://en.wikipedia.org/wiki/Perf_(Linux)) which I ""learned how to use"" from [a YouTube video](https://www.youtube.com/watch?v=nXaxk27zwlk&t=2052s).; In a nutshell compile the code as usual but with the `-fno-omit-frame-pointer` cxx flag (so perf can figure out the name of the functions, debug symbols are not required).; Run `perf record -g [command]` where command can be your usual `mpirun...` (I did not recompile my mpi with the aforementioned flag), for 2-3 minutes for hundreds of MB of record (hence the 500k mesh...).; Run `perf report -g ""fractal,0.5,caller""`, this will show % of time spent in a function relative to its caller and you can expand each function to see what are its children, grandchildren, etc. Like so:; ![image](https://user-images.githubusercontent.com/38071223/63290949-725e5080-c2ba-11e9-90aa-ffc834e726db.png); How cool is that!! Pro-tip hit ""a"" to look at some assembly, honestly sliced bread has nothing on perf. NOTE: By and large Perf is not an intrusive tool, as such the accuracy of the measurements is limited i.e. it is pr",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/716#issuecomment-522730951:2187,learn,learned,2187,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-522730951,1,['learn'],['learned']
Usability,"ix updates without colouring by setting only the off-diagonal coefficients and then setting the diagonal entries to the column sum.; It turns out that this is worse (by about 10%), maybe if the matrix were symmetric (row sum) but a column sum accesses blocks very far apart. Also we want to interleave compute and load/stores as much as possible to allow the CPU pipelining magic to mask the latency of the latter (even if it looks like you can only write the block after it is computed, CPU's have all kinds of buffers that allow the next loop iteration to begin while data is in flight). **Therefore colouring is the way to go.**. _Note: With vectorized numerics we insert blocks for 4 or 8 edges into the matrix at a time, the data for those inserts will be in a slightly weird format, which will make `SparseMatrix::updateBlocks` a bit harder on the eye, more on that later._. ## MUSCL Reconstruction; The MUSCL reconstruction, characteristic of upwind schemes, is the simplest building block to show the (negative) implications of storing the data as structures of arrays (SoA) on the performance of some operations.; Here is the most basic numerics you can think of, reconstruct and average (the dummy matrix loop was to benchmark the writes this is to benchmark the reads); ```c++; void computeResidual(size_t nVar,; size_t nDim,; const vector<size_t>& colorStart,; const vector<size_t>& edgeIdx,; const vector<pair<size_t,size_t> >& connectivity,; const Matrix& coords,; const Matrix& phi,; const VectorOfMatrix& grad,; const Matrix& limiter,; Matrix& residual); {; residual.setZero();. for(size_t color=0; color<colorStart.size()-1; ++color); #pragma omp parallel for schedule(dynamic,CHUNK_SIZE); for(size_t k=colorStart[color]; k<colorStart[color+1]; ++k); {; size_t iEdge = edgeIdx[k];; size_t iPoint = connectivity[iEdge].first;; size_t jPoint = connectivity[iEdge].second;. double d_ij[MAXNDIM];; for(size_t iDim=0; iDim<nDim; ++iDim); d_ij[iDim] = 0.5*(coords(jPoint,iDim)-coords(iPoint",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-535977206:5680,simpl,simplest,5680,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206,1,['simpl'],['simplest']
Usability,"looks like there is an array overflow in solver_structure.cpp (line 2347). ` ; while (getline (solution_file, text_line) ) {; istringstream point_line(text_line);; ; /*--- Retrieve local index. If this node from the restart file lives; on a different processor, the value of iPoint_Local will be -1, as; initialized above. Otherwise, the local index for this node on the; current processor will be returned and used to instantiate the vars. ---*/; ; iPoint_Local = Global2Local[iPoint_Global];; if (iPoint_Local >= 0) {; ; /*--- The PointID is not stored --*/; //cout << iPoint_Local << endl;; point_line >> index;; ; /*--- Store the solution (starting with node coordinates) --*/; ; for (iField = 0; iField < nVar; iField++); point_line >> Solution[iField];; ; node[iPoint_Local]->SetSolution(Solution);; ; ; }; iPoint_Global++;; }; ` . I had a brief look at it and seems the issue can be solved by simply adding the condition ""&& iPoint_Global < geometry[iZone]->GetnPointDomain()"" to the outer while loop, but I'm not completely sure this is the best way to fix the code.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/325#issuecomment-262186418:900,simpl,simply,900,https://su2code.github.io,https://github.com/su2code/SU2/pull/325#issuecomment-262186418,1,['simpl'],['simply']
Usability,"m_j = phiMax(jPoint,iVar);. const double eps = numeric_limits<double>::epsilon();. if(proj_i <= 0.0); {; lim_i = phiMin(iPoint,iVar);; proj_i = min(proj_i, -eps);; }. if(proj_j <= 0.0); {; lim_j = phiMin(jPoint,iVar);; proj_j = min(proj_j, -eps);; }. lim_i = (lim_i-phi(iPoint,iVar))/proj_i;; limiter(iPoint,iVar) = min(limiter(iPoint,iVar), lim_i);. lim_j = (lim_j-phi(jPoint,iVar))/proj_j;; limiter(jPoint,iVar) = min(limiter(jPoint,iVar), lim_j);; }; }. for(size_t iPoint=0; iPoint<nPoint; ++iPoint); {; for(size_t iVar=0; iVar<nVar; ++iVar); {; double lim = limiter(iPoint,iVar);; limiter(iPoint,iVar) = lim*(lim+2)/(lim*lim+lim+2);; }; }; }; ```; Something in the code above is a bit different from the implementation in SU2, namely:; ```C++; double lim_i = phiMax(iPoint,iVar);; if(proj_i <= 0.0) {; lim_i = phiMin(iPoint,iVar);; proj_i = min(proj_i, -eps);; }; ```; This is the bit of code that selects the right delta based on the sign of the projection and avoids division by zero, this less readable version does the same with one branch instead of three, simplifying ""if"" statements is essential for vectorization, so to make the comparison fair I used the same strategy in the scalar code. To make this post shorter I will show the SIMD and parallel version of the code right away. Trying to process multiple edges instead of multiple variables has all the problems I mentioned for the gradients, so again we use the trick of templating on the number of variables.; ```C++; template<size_t nVar>; void computeLimiters_impl(size_t nPoint,; size_t nDim,; const vector<size_t>& colorStart,; const vector<size_t>& edgeIdx,; const vector<pair<size_t,size_t> >& connectivity,; const Matrix& coords,; const Matrix& phi,; const VectorOfMatrix& grad,; Matrix& phiMax,; Matrix& phiMin,; Matrix& limiter); {; // initialize; #pragma omp parallel for schedule(dynamic,TARGET_CHUNK_SIZE); for(size_t iPoint=0; iPoint<nPoint; ++iPoint); {; #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); {; phiM",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-530593912:3108,simpl,simplifying,3108,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530593912,1,['simpl'],['simplifying']
Usability,"ogramming may become an entrance barrier to new additions to the community. As I wrote in the preamble of #789:; ""But please participate even if you never heard of these topics, your opinion about readability and ""developability"" of the code is important! I think the code-style should be accessible to people starting a PhD (after they read a bit about C++...).""; I try to encapsulate and hide the tricky bits as much as possible to make the code as readable as possible, whether I am succeeding or not is for the community to decide, in all these PR's I've been pointing to the areas I think are trickier, if someone, anyone, feels they are absolutely incomprehensible please say something... either here, or trough slack, or by email (I think it shows in the commits) (I understand not everyone is keen on github exposure). > I'm aware that you have been doing very well at documenting the code and the various PRs, but I'd say we should try to find an strategy to ease the learning curve on potential new developers (maybe some developer tutorials? a collection of the comments/discussions on the PRs moved to the wiki? a list of links/useful resources?). I agree with documentation of broad design decisions, that is the intent of #789, and developer tutorials (how to implement a new X) once we are content with the restructurings, otherwise they will quickly go outdated... or actually...; We should probably first think about the answers to ""how to implement a new X"" and restructure/refactor as a function of that.; Based on previous efforts of maintaining wiki's updated while code is being developed, I much prefer this github style where you can clearly tell what version of the code the comments refer to. A collection of comments/discussions organized by topic and linked to a feature is somewhat what I had in mind when I opened a ""big PR"" (#824) with little branches such as this one, I can try to complete that with a list of links/useful resources, references as it were, good idea!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/843#issuecomment-577684728:5261,clear,clearly,5261,https://su2code.github.io,https://github.com/su2code/SU2/pull/843#issuecomment-577684728,1,['clear'],['clearly']
Usability,"output classes, we should find a common level of abstraction for all the different physical problems we might want to have. Right now there isn't even a unified way of specifying the kind of problem for each zone (what is fluid, what is solid etc) and the kind of coupling. This might also affect the actual implementation/restructuring since we somehow have to decide what driver we have to instantiate and so on. Hopefully we can gather all the people involved to have a discussion on that. Since we have a lot of people working in their branches on multizone problems we should tackle that better sooner than later. As Edwin already suggested, maybe it is a good idea to put some people in charge of organizing some of the bigger structural changes. Furthermore in case some people don't know, we have a slack channel for the dev team. I think that makes it easier to communicate, arrange meetings, discuss problems and ask questions. In case you need an invite, let me know, everybody who wants to contribute is welcome. Thanks for the discussion, I still think that communication is the key of success !. Tim. On Sep 13, 2017 10:30 AM, Edwin van der Weide <notifications@github.com> wrote:. Hi Tom,. Sounds like a plan then to have a look at CIntegration to see what we can do to generalize the time integration. I definitely want to help with this, but I don't think I am the appropriate person to take the lead, because I simply don't have a good overview of all the multi-physics options. Tom, are you willing to take the lead for this?. Furthermore, it is good to have other people involved as well, preferably with detailed knowledge of the different disciplines. Any volunteers?. Thanks,. Edwin. —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/437#issuecomment-329096830>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AEtI5MkXdqhqPPMuaDziLuDRzWCJfYwrks5sh5KagaJpZM4PQ90s>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/437#issuecomment-329146567:1471,simpl,simply,1471,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-329146567,1,['simpl'],['simply']
Usability,"p, which was occurring even with smaller meshes (7 million cells). The solution to (2) appears to be to change `geometry->node[iPoint]->GetnNeighbor()` to `geometry->node[iPoint]->GetnPoint()` at line 3759 of CEulerSolver.cpp, in the `CEulerSolver::SetUpwind_Ducros_Sensor()` method. I made this change locally, and attempted to run on our large mesh. Issue (2) seems to be fixed, but we still run into issue (1). I have now gone through the read restart routines, and have found a potential issue:. For reference, the restart file for our large mesh with averaging data included consists of:; 39 fields * 75,107,967 points = 2,929,210,713 variable values (which is larger than `INT_MAX`). Beginning at line 3931 of CSolver.cpp, in method `CSolver::Read_SU2_Restart_Binary(...)`, we have the following:. ```; int *blocklen = new int[geometry->GetnPointDomain()];; int *displace = new int[geometry->GetnPointDomain()];; int counter = 0;; for (iPoint_Global = 0; iPoint_Global < geometry->GetGlobal_nPointDomain(); iPoint_Global++ ) {; if (geometry->GetGlobal_to_Local_Point(iPoint_Global) > -1) {; blocklen[counter] = nFields;; displace[counter] = iPoint_Global*nFields;; counter++;; }; }; MPI_Type_indexed(geometry->GetnPointDomain(), blocklen, displace, MPI_DOUBLE, &filetype);; ```; The problem here is that for our case, where `iPoint_Global` can get up to 75,107,967 and `nFields` = 39, the value assigned to `displace[counter]` in the loop can over-run `INT_MAX`. This would result in potential garbage / incorrect displace values being passed to `MPI_Type_indexed(...)`. Unfortunately, simply changing `displace` to a `long int *` won't work, as the expected argument type for `MPI_Type_indexed(...)` is `int`. It may be that, given the limitations of MPI here, reading such large restart information requires the restart file to be read serially by one rank, and the data split and broadcast to the other ranks?. I am not an MPI expert, so there may be another way to do this. Thoughts?. -Paul",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/949#issuecomment-622026420:1909,simpl,simply,1909,https://su2code.github.io,https://github.com/su2code/SU2/issues/949#issuecomment-622026420,1,['simpl'],['simply']
Usability,"ple dataset, I have run some; variations on the jobs, and my findings were:; (Please note that *all* ""markers"" I have mentioned in the next items refer; to solid walls in the mesh, using the RANS solver); 1- When I impose HEATFLUX=0 *and* ISOTHERMAL=290 Kelvin, for the same; markers, there are no complaints from SU2. It shows that SU2 ignores the; imposition of HEATFLUX=0, in this case.; 2- Just setting ISOTHERMAL=290 Kelvin (using all of the same markers as in; (item 1), above), without any HEATFLUX setting, then SU2 produces the same; results as in (item1).; 3- When some markers are set with HEATFLUX=0 and the rest of them are set; with ISOTHERMAL=290 Kelvin (so that each wall marker in the mesh is; referenced), there are no complaints from SU2, and the job goes as expected.; 4-The error message mentioned earlier, appears when one or more solid wall; markers *is not marked* concerning HEATFLUX or ISOTHERMAL; .; My conclusion then is that the error message appeared when I mistakenly; have not included a wall marker (assigning it as a HEATFLUX or an; ISOTHERMAL marker!); Does it make sense?; Kind regards,. On Mon, Oct 23, 2023 at 7:48 PM Jairo Cavalcante ***@***.***>; wrote:. > Unfortunately, my example involves a swirler and nozzle for the; > Navier-Stokes solver with Menter model, so the dataset is relatively large.; > Let me check whether some older small Euler mesh exhibits the same message!; > I will let you know! Thank you very much.; >; > On Mon, Oct 23, 2023 at 6:34 PM Pedro Gomes ***@***.***>; > wrote:; >; >> Is there a simple example to reproduce the issue?; >>; >> —; >> Reply to this email directly, view it on GitHub; >> <https://github.com/su2code/SU2/pull/2109#issuecomment-1776057496>, or; >> unsubscribe; >> <https://github.com/notifications/unsubscribe-auth/AHGXZUV3DNRF3O55YAWT563YA3PETAVCNFSM6AAAAAA3QKLVDWVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMYTONZWGA2TONBZGY>; >> .; >> You are receiving this because you commented.Message ID:; >> ***@***.***>; >>; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/2109#issuecomment-1777018035:1595,simpl,simple,1595,https://su2code.github.io,https://github.com/su2code/SU2/pull/2109#issuecomment-1777018035,1,['simpl'],['simple']
Usability,"ratio, and mask the latency of those operations by being able to start computing as soon as the first element of data is available. **What elements should we try to process simultaneously?**; The choice is between multiple geometric primitives (edges/points) or multiple solution primitives (variables). The latter sounds like a sensible idea until we get to areas of the code where different primitives require different treatment, that and the fact that the number of variables might not fit evenly in the number of lanes can lead to very tricky and non-generic code. Nevertheless if the same code were to be applied to e.g. 4 solution variables, this strategy would likely perform better as it avoids the pesky gather/scatter operations.; Processing multiple geometric primitives can make full utilization of whatever register size (important on GPU's), the code is just as readable (as I hope to show), but gather/scatter cannot be avoided. ### Intro to SPMD; This one is simpler, in a nutshell multiple threads operate on the sub domain of an MPI rank.; The typical implementation has each thread executing a chunk of an edge or cell loop. **Why should we care about SPMD?**; Reduce the communication overhead resulting from domain decomposition and improve load balancing, important for strong scaling.; Some algorithms are more efficient that way, e.g. the ADT (as mentioned by Edwin), the current MG also seems to work better on fewer partitions, and additive versions of preconditioners like the ILU or LU-SGS lose effectiveness with number of partitions.; Optimum hardware utilization, for routines that are bandwidth-bound it may be beneficial to use all threads available, while for compute-bound or ""algorithm-bound"" ones this may not be the case. **Relation with algorithms**; A typical edge loop reads from 2 locations and writes to 2 locations (gather / scatter access pattern, not to be confused with the instructions) processing multiple edges at the same time can therefore result i",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-529662724:2888,simpl,simpler,2888,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-529662724,1,['simpl'],['simpler']
Usability,"rding the Test Cases and Tutorial files. I; apologize if this is the wrong place or this has been discussed already,; but still will give it a try:; - Test cases folder from SU2/su2code repository shall be moved to the; SU2/TestCases repository. Rationale: this makes one repository to store the; test case *.cfg files and mesh files.; - There shall be a TestCases/Mesh folder to store all the meshes needed for; Test Cases files, without subdivisions for RANS, Euler etc subfolders.; Considering that multiple test cases use the same mesh and all the mesh; files are distinct, this solution generates one place to store all the mesh; files. Should a user perform a test case, he/she will find the mesh by name; referenced in the *.cfg file instead searching thru multiple folders. This; will also help avoiding unnecessary copies of mesh files.; - The same should be done for Tutorial files: Tutorial/Mesh folder for; storing meshes (duplicating these few files from TestCases/Mesh should not; be a problem IMO, but will really help a new user to get up to speed with; SU2); - I have no clear opinion on where the Tutorial files folder should be; stored. But considering moving written tutorials to main repository i think; that tutorial files should also be stored in main SU2/su2code repository. Best regards and Happy New Year; Jędrzej. 2017-12-30 23:45 GMT+01:00 Tim Albring <notifications@github.com>:. > What do you think of moving the written tutorials also to the main; > repository ? Then we can have links in the wiki to the markdown files like; > this (the link will be much shorter if the files are in the master branch):; > https://github.com/su2code/SU2/blob/0e36facc031aaf6b411fd30a0aab80; > 29ebe325d8/Tutorials/Inviscid_Bump/Inviscid_Bump.md; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/pull/485#issuecomment-354572803>, or mute; > the thread; > <https://github.co",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/485#issuecomment-354736415:1591,clear,clear,1591,https://su2code.github.io,https://github.com/su2code/SU2/pull/485#issuecomment-354736415,1,['clear'],['clear']
Usability,"ses CMake to find system libraries and compilers (MKL, Mutationpp, MPI and Python currently). No longer need to specify paths to compilers/libraries if they are in standard locations. In addition, compile flags can be modified from CMake. There is no need to use preconfigure.py anymore since downloading/unpacking is handled by CMake and is system-agnostic. At the moment, all library targets are static but that could be easily changed to be configurable from CMake. The installation directory is ${CMAKE_PREFIX_PATH}/bin. Similarly to autotools, some build options are disabled if built with Codi forward/reverse datatypes or without MPI. Note that SWIG fails to compile pySU2ad with Nothing known about namespace 'medi' in Common/include/mpi_structure.hpp:57 without -includeall SWIG option but then it takes forever to generate the wrapper (more than 15 minutes on my machine, stopped early). I suggest removing using namespace declarations and either importing used symbols explicitly with using or prepending namespace name, clang-tidy warns against them by default and it makes the code clearer. SU2 CMake options are:. * Build modules:; * SU2_BUILD_CFD: ON|OFF; * SU2_BUILD_DEF: ON|OFF, disabled when building with Codi; * SU2_BUILD_DOT: ON|OFF, disabled when building with Codi forward; * SU2_BUILD_GEO: ON|OFF, disabled when building with Codi; * SU2_BUILD_MSH: ON|OFF, disabled when building with Codi; * SU2_BUILD_PY_WRAPPER: ON|OFF, disabled when building with Codi forward; * SU2_BUILD_SOL: ON|OFF, disabled when building with Codi; * Enable modules:; * SU2_ENABLE_CGNS:; * SU2_CGNS_CPPFLAGS: flags to pass when compiling CGNS; * SU2_ENABLE_CODI: no|forward|reverse; * SU2_CODI_CPPFLAGS: flags to pass to SU2 modules when compiling with Codi; * SU2_ENABLE_METIS: ON|OFF; * SU2_METIS_CPPFLAGS: flags to pass when compiling Metis; * SU2_ENABLE_MKL: ON|OFF; * SU2_ENABLE_MPI: ON|OFF; * SU2_ENABLE_MUTATIONPP: ON|OFF; * SU2_ENABLE_PARMETIS: ON|OFF, only available when SU2_ENABLE_MPI is ON",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/814#issuecomment-552242380:1671,clear,clearer,1671,https://su2code.github.io,https://github.com/su2code/SU2/pull/814#issuecomment-552242380,1,['clear'],['clearer']
Usability,"shell = false doesn't seem to work in this particular case (symbolic linking) but it might in others. There seem more secure ways to run commands but they need case by case treatment. As in the solution for a `cp` command is different from a `ln -s` command. . We can also replace the `os.system` calls with other python functions (for example `os.symlink` for symbolic linking). . Either way, it wont be a simple search and replace. There seem to be about 25 `os.system` calls across the python scripts. Let me try and replace them.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/781#issuecomment-533410018:407,simpl,simple,407,https://su2code.github.io,https://github.com/su2code/SU2/pull/781#issuecomment-533410018,1,['simpl'],['simple']
Usability,"te well as shown below. I haven't finished calculating for all design variables, but I think it is enough. ![Comparison_gradient](https://user-images.githubusercontent.com/18245846/129564585-d7812108-d315-4606-83d9-e39a8c9403b3.png). In terms of flow field, the capture below is from the current develop branch. The boundary between structured grid and unstructured gird is a nearfield boundary. An object is above this capture and pressure wave propagates from there. Since this grid is inclined by Mach angle, pressure distribution on the nearfield should be fairly similar to the region above but this capture shows some strange pressure disturbance. Limiter: VAN_ALBADA_EDGE; ![NF_before](https://user-images.githubusercontent.com/18245846/129564639-030fe1b7-7e50-4bb1-9951-21f5ea27bb52.png). Limiter: VENKATAKRISHNAN_WANG; ![NF_before_VEN](https://user-images.githubusercontent.com/18245846/129568934-137681db-04db-40f1-819f-7bcc8c7e0d88.png). The capture below is from the branch with this PR. The issue I mentioned above does not exist. Limiter: VAN_ALBADA_EDGE; ![NF_after](https://user-images.githubusercontent.com/18245846/129564659-cec5a848-1b0b-4051-8298-e3d383dacc6d.png). I think the residuals for direct solver will be different like the adjoint if you run it for some hundreds more iterations (currently, the test case has only 20 iterations). However, since the nearfield boundary is a bit far from an object, it takes some iterations for pressure waves to reach the nearfield boundary. This PR also solves an issue with VENKATAKRISHNAN_WANG limiter. It seems to be much easier for convergence than VAN_ALBADA_EDGE, so it is fairly useful. I still have a gradient un-match issue with my bigger mesh but I believe it is coming from something else. > I'm sorry that you had to spend time fixing that MPI code... But at least we found out we could clean all this obsolete code. Yeah, I noticed it had been deleted. It's OK. It was still a good opportunity for me to learn how MPI works.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/1351#issuecomment-899498618:2450,learn,learn,2450,https://su2code.github.io,https://github.com/su2code/SU2/pull/1351#issuecomment-899498618,1,['learn'],['learn']
Usability,"thing to do. So let’s indeed do something like what Tom suggests (in the spirit of MARKER_MONITORING) so that one can control which markers get wall functions applied. If a list of markers is not specified in the config file, the default behavior should be that all no-slip walls get wall function BCs. If a list of markers is specified, then those and only those markers listed get wall function Bfs (with the others getting integration to the wall treatment). Now, what you point out in the second half of your message is the ultimate in flexibility: not only specifying wall functions in a subset of the no-slip wall markers, but also allowing for different kinds of wall functions to be used in those markers. I imagine that this would be a seldom used capability…but someone out there might have the need. I guess it does not seem to me that the coding of the most flexible logic is that much more complicated, so we may as well do that. If you guys think it is too complicated, the advertised options in the config file can allow some simpler behavior. My two cents,. Juan. On Sep 5, 2017, at 9:58 PM, Edwin van der Weide <notifications@github.com<mailto:notifications@github.com>> wrote:. Juan,. I think that having the flexibility to apply wall functions on only a subset of the viscous wall boundaries would be useful. E.g., if you are interested in a wing, you can apply integration to the wall there, but apply wall functions on the fuselage. My preference would be to have a dedicated BC type for that, i.e. Tom's second suggestion. Apart from this, we can have the different wall model types as a single input parameter, i.e. you apply the same wall model type for all viscous boundaries. Or would you like to have the flexibility to specify this as well per individual marker?. Edwin. —; You are receiving this because you commented.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/399#issuecomment-327374728>, or mute the thread<https://github.co",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/399#issuecomment-327377108:1371,simpl,simpler,1371,https://su2code.github.io,https://github.com/su2code/SU2/issues/399#issuecomment-327377108,1,['simpl'],['simpler']
Usability,"this is a very nice contribution.. we’re working on the regressions and will pull this in once we have everything straightened out (and this branch passes). In the meantime, you got me thinking: the scale, rotate, translate options might be confusing now if a user doesn’t know whether to include the markers or not. Perhaps this is a chance for separating some of the “design” options from “mesh” options. One way I could see us do this is by moving the implementation I had just committed for the “volume” scale, rotate, and translate options over into the SU2_MSH executable, which might be a more logical home for it. However, this would require adding an extra set of config options for reading in a scale/rotate/translate options for SU2_MSH. The nice thing here is that we keep the intent separate, i.e., only design variables are listed with the other design variables while the mesh transformations are elsewhere. A different, possibly simpler way would be to just create separate names for these two types in the list of available options so that there is no ambiguity. Any thoughts?. On Aug 16, 2015, at 9:21 AM, Heather Kline <notifications@github.com<mailto:notifications@github.com>> wrote:. Some illustrative images/output in case my description was hard to understand:; [image]https://cloud.githubusercontent.com/assets/5167760/9294050/52a764b2-440f-11e5-8681-b68318da0ce7.png. SU2_DEF output when only ""airfoil"" marker included:. ------------------------- Surface grid deformation ----------------------; Performing the deformation of the surface grid. ----------------------- Volumetric grid deformation ---------------------; Performing the deformation of the volumetric grid. # FGMRES residual history. # Residual tolerance target = 4.14044e-11. # Initial residual norm = 15.8102. ```; 0 1; 50 2.17385e-06; 100 1.08998e-10; ```. # FGMRES final (true) residual:. # Iteration = 105: |res|/|res0| = 3.50764e-11. Non-linear iter.: 1/1. Linear iter.: 105. Min. area: 4.1019e-08. Error: ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/187#issuecomment-132065067:997,simpl,simpler,997,https://su2code.github.io,https://github.com/su2code/SU2/pull/187#issuecomment-132065067,1,['simpl'],['simpler']
Usability,"trix.subBlock(jPoint, jPoint, blk_j);; matrix.subBlock(jPoint, iPoint, blk_i);; }; }; ```; This and a few more memory reads is why we can't have nice things, i.e. massive speedups with vectorization. Believe it or not this loop sets ~75% of the maximum speed at which the residual edge loop can run (bandwidth bottleneck).; Don't be sad though, we can make a few things about it better:; - We can store the blocks we insert contiguously so the writes can be vectorized (this would be done using a container so that we still have `(i,j)` access syntax);; - On each insertion we have to first look for the block by traversing the `colInd` (column index) array, we can instead map the diagonal blocks to the corresponding points and the off-diagonal blocks to the edge (remember we insert ""by the edge"").; - We can fuse numerics (possibly using the [decorator](https://en.wikipedia.org/wiki/Decorator_pattern) pattern) so that we write to the matrix only once per iteration, which means we only need to clear the diagonal blocks and not the entire matrix because we can **set** the off-diagonals instead of **updating** them. Assuming these modification our dummy loop becomes; ```c++; void testLoop2(const vector<size_t>& colorStart,; const vector<size_t>& edgeIdx,; const vector<pair<size_t,size_t> >& connectivity,; const double* blk_i, const double* blk_j,; SparseMatrix& matrix); {; matrix.setDiagZero();. for(size_t color=0; color<colorStart.size()-1; ++color); #pragma omp parallel for schedule(dynamic,CHUNK_SIZE); for(size_t k=colorStart[color]; k<colorStart[color+1]; ++k); {; size_t iEdge = edgeIdx[k];; size_t iPoint = connectivity[iEdge].first;; size_t jPoint = connectivity[iEdge].second;. matrix.updateBlocks(iEdge, iPoint, jPoint, blk_i, blk_j);; }; }; ```; where; ```c++; STRONGINLINE void SparseMatrix::updateBlocks(size_t edge,; size_t row, size_t col, const double* blk_i, const double* blk_j); {; size_t bii = diagMap[row], bij = edgeMap[edge].first,; bjj = diagMap[col], bji = edgeM",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-535977206:3122,clear,clear,3122,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206,1,['clear'],['clear']
Usability,"uch lower level, namely where the spatial residual is computed. At least, this should be the case for the fluid dynamics part. I don't know whether this is also the case for other disciplines, like structures. What about the following high level structure?. - Loop over the number of iterations, or time steps for unsteady problems.; - Loop over the number of pseudo-time steps for implicit time integration schemes; (DT_STEPPING_1ST and DT_STEPPING_2ND). For other cases this loop is 1.; - Loop over the number of disciplines involved; Call iterate for each of the disciplines.; In iterate: ; - Loop over the (Runge-Kutta) stages; - Loop over the zones of a single discipline; Compute spatial residual.; Update the state vector.; - End loop over the zones of a single discipline.; Exchange halo data. This includes the halo data between zones of a single discipline.; - End loop over the (Runge-Kutta) stages ; - End loop over the disciplines; - End loop over the pseudo time steps.; - End loop over the number of iterations, or time steps for unsteady problems. The weakness of this approach is that it still does not work when one would like to employ multi-stage time integration schemes for an unsteady, multi-disciplinary problem (does not work for the current implementation either), but maybe this is something we simply have to accept. The alternative is that all the details of the different time integration schemes have to be moved to the driver classes, which is highly undesirable, I think. The structure above implies that the iteration_container and the integration_container should be defined per discipline and not per zone anymore. The geometry_container and solver_container should still be defined per zone. Well, I suppose this leaves plenty of room for discussion, so I would say to continue the online discussion a bit further, such that things become a bit clearer how to tackle this issue. After that having a telecon would be good to iron out the details. . Regards,. Edwin",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/437#issuecomment-328368371:1666,simpl,simply,1666,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328368371,2,"['clear', 'simpl']","['clearer', 'simply']"
Usability,"uctures. What about the following high level structure?. * Loop over the number of iterations, or time steps for unsteady problems.; * Loop over the number of pseudo-time steps for implicit time integration schemes; (DT_STEPPING_1ST and DT_STEPPING_2ND). For other cases this loop is 1.; * Loop over the number of disciplines involved; Call iterate for each of the disciplines.; In iterate:; * Loop over the (Runge-Kutta) stages; * Loop over the zones of a single discipline; Compute spatial residual.; Update the state vector.; * End loop over the zones of a single discipline.; Exchange halo data. This includes the halo data between zones of a single discipline.; * End loop over the (Runge-Kutta) stages; * End loop over the disciplines; * End loop over the pseudo time steps.; * End loop over the number of iterations, or time steps for unsteady problems. The weakness of this approach is that it still does not work when one would like to employ multi-stage time integration schemes for an unsteady, multi-disciplinary problem (does not work for the current implementation either), but maybe this is something we simply have to accept. The alternative is that all the details of the different time integration schemes have to be moved to the driver classes, which is highly undesirable, I think. The structure above implies that the iteration_container and the integration_container should be defined per discipline and not per zone anymore. The geometry_container and solver_container should still be defined per zone. Well, I suppose this leaves plenty of room for discussion, so I would say to continue the online discussion a bit further, such that things become a bit clearer how to tackle this issue. After that having a telecon would be good to iron out the details. Regards,. Edwin. —; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/437#issuecomment-328368371>, or mute the thread<",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/437#issuecomment-328403160:3175,simpl,simply,3175,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328403160,1,['simpl'],['simply']
Usability,"when you've installed python packages in two different locations. This could be due to installing some python packages in a system directory (e.g. `/usr/lib/`) and some in a user directory (e.g. `~/.local/`). SU2's build process is set to automatically detect the default package location, but it's not equipped to handle multiple package locations. There are some hardcoded includes, but these only work for python 2.7. I don't consider this a bug *per se* because multiple python package directories is not a standard use case. #### The symptoms. When building SU2 with the python wrapper you'll see the following error during the swig build:; ```; <install directory>/../SU2_PY/pySU2/pySU2.i:64: Error: Unable to find 'mpi4py/mpi4py.i'; ```; But mpi4py is indeed installed on your system and it's on your python path, as confirmed by opening a python terminal and running `import mpi4py`. #### The easiest workaround. Switch to a [virtualenv](https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/). This will ensure that all of your python packages are stored in single location. #### Alternate workaround. In this method, you change the hardcoded includes to match mpi4py's package location. First I figure out where my mpi4py is installed. I start a terminal session of python using the python environment I want to use (in this case, it's python 3.6), and then run:; ```; from mpi4py import MPI; MPI; ```. Since I have mpi4py installed on your system and it's on my python path, I see something like:; ```; <module 'mpi4py.MPI' from '/home/clarkpede/.local/lib/python3.6/site-packages/mpi4py/MPI.cpython-34m.so'>; ```. The `/home/clarkpede/.local/lib/python3.6/` directory is where my mpi4py package is installed. But the swig compile command includes `/home/clarkpede/.local/lib/python2.7/`. That's not the right directory! So first I find the hardcoded paths of the makefile by running (on a bash terminal):; ```; grep -rn python2\.7 SU2_PY/ ; ```; On my system, t",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/722#issuecomment-515693590:1105,guid,guides,1105,https://su2code.github.io,https://github.com/su2code/SU2/issues/722#issuecomment-515693590,1,['guid'],['guides']
Usability,"you are correct, there is a discussion on CFD-online about it. we impose 0 heat flux, but report an ""apparent heat flux"" most codes will simply give you back the imposed heat flux value you specify, nevertheless there will probably be a temperature gradient close to the wall",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/pull/2109#issuecomment-1740118992:137,simpl,simply,137,https://su2code.github.io,https://github.com/su2code/SU2/pull/2109#issuecomment-1740118992,1,['simpl'],['simply']
Usability,"ze_t iPoint = connectivity[iEdge].first;; size_t jPoint = connectivity[iEdge].second;. // i to j vector; double d_ij[3] = {0.0, 0.0, 0.0};. for(size_t iDim=0; iDim<nDim; ++iDim); d_ij[iDim] = 0.5*(coords(jPoint,iDim)-coords(iPoint,iDim));. // projections; double proj_i[nVar], proj_j[nVar];. #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); proj_i[iVar] = proj_j[iVar] = 0.0;. for(size_t iDim=0; iDim<nDim; ++iDim); {; #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); {; proj_i[iVar] += d_ij[iDim]*grad(iPoint,iVar,iDim);; proj_j[iVar] -= d_ij[iDim]*grad(jPoint,iVar,iDim);; }; }. // choose the ""right"" delta based on sign of projection; // and avoid division by zero; double lim_i[nVar], lim_j[nVar];. #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); {; lim_i[iVar] = phiMax(iPoint,iVar);; lim_j[iVar] = phiMax(jPoint,iVar);; }. const double eps = numeric_limits<double>::epsilon();. // very simple if's are required to get vectorization; // trough vector comparisons and masked blends; #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); {; if(proj_i[iVar] <= 0.0); {; lim_i[iVar] = phiMin(iPoint,iVar);; proj_i[iVar] = min(proj_i[iVar], -eps);; }. if(proj_j[iVar] <= 0.0); {; lim_j[iVar] = phiMin(jPoint,iVar);; proj_j[iVar] = min(proj_j[iVar], -eps);; }; }. #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); {; lim_i[iVar] = (lim_i[iVar]-phi(iPoint,iVar))/proj_i[iVar];; limiter(iPoint,iVar) = min(limiter(iPoint,iVar), lim_i[iVar]);. lim_j[iVar] = (lim_j[iVar]-phi(jPoint,iVar))/proj_j[iVar];; limiter(jPoint,iVar) = min(limiter(jPoint,iVar), lim_j[iVar]);; }; }. #pragma omp parallel for schedule(dynamic,TARGET_CHUNK_SIZE); for(size_t iPoint=0; iPoint<nPoint; ++iPoint); {; #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); {; double lim = limiter(iPoint,iVar);; limiter(iPoint,iVar) = lim*(lim+2)/(lim*lim+lim+2);; }; }; }; ```; Again to keep things short here is the parallel and SIMD point-loop version (like for gradients it is very similar to the",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://github.com/su2code/SU2/issues/789#issuecomment-530593912:6356,simpl,simple,6356,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530593912,1,['simpl'],['simple']
