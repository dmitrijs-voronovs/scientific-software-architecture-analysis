quality_attribute,keyword,matched_word,sentence,source,author,repo,version,wiki,url
Usability,simpl,simple,"> I would just say `ImportError: cannot import module 'pyspark'. Please see the Spark documentation for installation instructions.`. Why referring to pip or conda? Probably people prefer apt, dnf, pacman, whatever? I'd keep it simple :). Alright, latest commit uses this wording :+1:",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/7705#issuecomment-810153069
Modifiability,variab,variable,"TLOOP=4 xrdcp root://eospublic.cern.ch//eos/opendata/cms/derived-data/AOD2NanoAODOutreachTool/Run2012BC_DoubleMuParked_Muons.root .; [784MB/2.09GB][ 36%][==================> ][11.04MB/s]; ```; ```; $ ps aux | grep xrdcp; vpadulan 2875 14.5 0.4 698364 77920 pts/0 Sl+ 12:15 0:03 xrdcp root://eospublic.cern.ch//eos/opendata/cms/derived-data/AOD2NanoAODOutreachTool/Run2012BC_DoubleMuParked_Muons.root .; $ ps hH p 2875 | wc -l; 10; ```; ### XRD_PARALLELEVTLOOP=1; This should use 1 thread, I see 7; ```; $ XRD_PARALLELEVTLOOP=1 xrdcp root://eospublic.cern.ch//eos/opendata/cms/derived-data/AOD2NanoAODOutreachTool/Run2012BC_DoubleMuParked_Muons.root .; [184MB/2.09GB][ 8%][====> ][10.82MB/s]; ```. ```; $ ps aux | grep xrdcp; vpadulan 3000 20.0 0.2 608092 46488 pts/0 Sl+ 12:18 0:00 xrdcp root://eospublic.cern.ch//eos/opendata/cms/derived-data/AOD2NanoAODOutreachTool/Run2012BC_DoubleMuParked_Muons.root .; $ ps hH p 3000 | wc -l; 7; ```. ### XRD_WORKERTHREADS=1 XRD_PARALLELEVTLOOP=1; I have found another environment variable in the xrootd docs https://xrootd.slac.stanford.edu/doc/xrdcl-docs/xrdcldocs.pdf described as ""Number of threads processing user callbacks."" with default value 3 . Setting both variables to 1 leads to 5 threads. ```; $ XRD_WORKERTHREADS=1 XRD_PARALLELEVTLOOP=1 xrdcp root://eospublic.cern.ch//eos/opendata/cms/derived-data/AOD2NanoAODOutreachTool/Run2012BC_DoubleMuParked_Muons.root .; [192MB/2.09GB][ 8%][====> ][10.67MB/s]; ```. ```; $ ps aux | grep xrdcp; vpadulan 3036 17.3 0.2 460628 48240 pts/0 Sl+ 12:21 0:00 xrdcp root://eospublic.cern.ch//eos/opendata/cms/derived-data/AOD2NanoAODOutreachTool/Run2012BC_DoubleMuParked_Muons.root .; $ ps hH p 3036 | wc -l; 5; ```. So for now:; 1. Setting XRD_PARALLELEVTLOOP=1 makes the xrdcp process use 7 thread, of which 3 are explicable by the default value of XRD_WORKERTHREADS, 1 is the event loop, but I still can't reason about the other 3 threads.; 2. The two variables seem to be independently adding threads to the `xrd",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/7709#issuecomment-847752725
Testability,test,tests,"First simple tests:. ### XRD_PARALLELEVTLOOP=4; In theory this should use 4 threads, but there are 10 instead; ```; $ XRD_PARALLELEVTLOOP=4 xrdcp root://eospublic.cern.ch//eos/opendata/cms/derived-data/AOD2NanoAODOutreachTool/Run2012BC_DoubleMuParked_Muons.root .; [784MB/2.09GB][ 36%][==================> ][11.04MB/s]; ```; ```; $ ps aux | grep xrdcp; vpadulan 2875 14.5 0.4 698364 77920 pts/0 Sl+ 12:15 0:03 xrdcp root://eospublic.cern.ch//eos/opendata/cms/derived-data/AOD2NanoAODOutreachTool/Run2012BC_DoubleMuParked_Muons.root .; $ ps hH p 2875 | wc -l; 10; ```; ### XRD_PARALLELEVTLOOP=1; This should use 1 thread, I see 7; ```; $ XRD_PARALLELEVTLOOP=1 xrdcp root://eospublic.cern.ch//eos/opendata/cms/derived-data/AOD2NanoAODOutreachTool/Run2012BC_DoubleMuParked_Muons.root .; [184MB/2.09GB][ 8%][====> ][10.82MB/s]; ```. ```; $ ps aux | grep xrdcp; vpadulan 3000 20.0 0.2 608092 46488 pts/0 Sl+ 12:18 0:00 xrdcp root://eospublic.cern.ch//eos/opendata/cms/derived-data/AOD2NanoAODOutreachTool/Run2012BC_DoubleMuParked_Muons.root .; $ ps hH p 3000 | wc -l; 7; ```. ### XRD_WORKERTHREADS=1 XRD_PARALLELEVTLOOP=1; I have found another environment variable in the xrootd docs https://xrootd.slac.stanford.edu/doc/xrdcl-docs/xrdcldocs.pdf described as ""Number of threads processing user callbacks."" with default value 3 . Setting both variables to 1 leads to 5 threads. ```; $ XRD_WORKERTHREADS=1 XRD_PARALLELEVTLOOP=1 xrdcp root://eospublic.cern.ch//eos/opendata/cms/derived-data/AOD2NanoAODOutreachTool/Run2012BC_DoubleMuParked_Muons.root .; [192MB/2.09GB][ 8%][====> ][10.67MB/s]; ```. ```; $ ps aux | grep xrdcp; vpadulan 3036 17.3 0.2 460628 48240 pts/0 Sl+ 12:21 0:00 xrdcp root://eospublic.cern.ch//eos/opendata/cms/derived-data/AOD2NanoAODOutreachTool/Run2012BC_DoubleMuParked_Muons.root .; $ ps hH p 3036 | wc -l; 5; ```. So for now:; 1. Setting XRD_PARALLELEVTLOOP=1 makes the xrdcp process use 7 thread, of which 3 are explicable by the default value of XRD_WORKERTHREADS, 1 is the event ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/7709#issuecomment-847752725
Usability,simpl,simple,"First simple tests:. ### XRD_PARALLELEVTLOOP=4; In theory this should use 4 threads, but there are 10 instead; ```; $ XRD_PARALLELEVTLOOP=4 xrdcp root://eospublic.cern.ch//eos/opendata/cms/derived-data/AOD2NanoAODOutreachTool/Run2012BC_DoubleMuParked_Muons.root .; [784MB/2.09GB][ 36%][==================> ][11.04MB/s]; ```; ```; $ ps aux | grep xrdcp; vpadulan 2875 14.5 0.4 698364 77920 pts/0 Sl+ 12:15 0:03 xrdcp root://eospublic.cern.ch//eos/opendata/cms/derived-data/AOD2NanoAODOutreachTool/Run2012BC_DoubleMuParked_Muons.root .; $ ps hH p 2875 | wc -l; 10; ```; ### XRD_PARALLELEVTLOOP=1; This should use 1 thread, I see 7; ```; $ XRD_PARALLELEVTLOOP=1 xrdcp root://eospublic.cern.ch//eos/opendata/cms/derived-data/AOD2NanoAODOutreachTool/Run2012BC_DoubleMuParked_Muons.root .; [184MB/2.09GB][ 8%][====> ][10.82MB/s]; ```. ```; $ ps aux | grep xrdcp; vpadulan 3000 20.0 0.2 608092 46488 pts/0 Sl+ 12:18 0:00 xrdcp root://eospublic.cern.ch//eos/opendata/cms/derived-data/AOD2NanoAODOutreachTool/Run2012BC_DoubleMuParked_Muons.root .; $ ps hH p 3000 | wc -l; 7; ```. ### XRD_WORKERTHREADS=1 XRD_PARALLELEVTLOOP=1; I have found another environment variable in the xrootd docs https://xrootd.slac.stanford.edu/doc/xrdcl-docs/xrdcldocs.pdf described as ""Number of threads processing user callbacks."" with default value 3 . Setting both variables to 1 leads to 5 threads. ```; $ XRD_WORKERTHREADS=1 XRD_PARALLELEVTLOOP=1 xrdcp root://eospublic.cern.ch//eos/opendata/cms/derived-data/AOD2NanoAODOutreachTool/Run2012BC_DoubleMuParked_Muons.root .; [192MB/2.09GB][ 8%][====> ][10.67MB/s]; ```. ```; $ ps aux | grep xrdcp; vpadulan 3036 17.3 0.2 460628 48240 pts/0 Sl+ 12:21 0:00 xrdcp root://eospublic.cern.ch//eos/opendata/cms/derived-data/AOD2NanoAODOutreachTool/Run2012BC_DoubleMuParked_Muons.root .; $ ps hH p 3036 | wc -l; 5; ```. So for now:; 1. Setting XRD_PARALLELEVTLOOP=1 makes the xrdcp process use 7 thread, of which 3 are explicable by the default value of XRD_WORKERTHREADS, 1 is the event ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/7709#issuecomment-847752725
Usability,intuit,intuition,"Yes, @amadio , that was a nice intuition of yours. The comment also goes beyond this particular item and shows we really explored the topic in depth :) I am closing the issue.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/7709#issuecomment-1833892432
Usability,feedback,feedback,Thanks for the feedback!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/7711#issuecomment-828443447
Usability,undo,undo,"@pcanal, this is a bit of a pain for CMS as we have to put an ""undo commit"" on all our 6.24 and master branches, e.g.:; https://github.com/cms-sw/root/commit/425ac414ef564c1cdc5fa490967d95d63df3b8eb. We probably have several incarnation of this undo in various branches :(",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/7718#issuecomment-948087157
Testability,test,test,@pcanal. If it is any help I reference here a simple cmssw module [1]. When compile it with FWLite (built with root master) you can reproduce the crash. Below is the binary from the test module and the sample file:; test-bname-for.exe /eos/cms/store/group/phys_muon/dmytro/tmp/BPH-RunIIAutumn18DRPremix-00015.root. Crash is the line https://github.com/alja/OssTests/blob/root-test/BranchAddr/bin/test-bname-for.cc#L95. [1] https://github.com/alja/OssTests,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/7718#issuecomment-948203246
Usability,simpl,simple,@pcanal. If it is any help I reference here a simple cmssw module [1]. When compile it with FWLite (built with root master) you can reproduce the crash. Below is the binary from the test module and the sample file:; test-bname-for.exe /eos/cms/store/group/phys_muon/dmytro/tmp/BPH-RunIIAutumn18DRPremix-00015.root. Crash is the line https://github.com/alja/OssTests/blob/root-test/BranchAddr/bin/test-bname-for.cc#L95. [1] https://github.com/alja/OssTests,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/7718#issuecomment-948203246
Deployability,integrat,integration,What about including [this](https://root.cern/root/htmldoc/guides/users-guide/ROOTUsersGuide.html#numerical-integration) in the reference guide on [this page](https://root.cern/doc/master/group__Integration.html) ?. @lmoneta what do you think ?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/7740#issuecomment-810160931
Integrability,integrat,integration,What about including [this](https://root.cern/root/htmldoc/guides/users-guide/ROOTUsersGuide.html#numerical-integration) in the reference guide on [this page](https://root.cern/doc/master/group__Integration.html) ?. @lmoneta what do you think ?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/7740#issuecomment-810160931
Usability,guid,guides,What about including [this](https://root.cern/root/htmldoc/guides/users-guide/ROOTUsersGuide.html#numerical-integration) in the reference guide on [this page](https://root.cern/doc/master/group__Integration.html) ?. @lmoneta what do you think ?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/7740#issuecomment-810160931
Deployability,integrat,integration,"Hi, ; There is some documentation in the ROOT Users guide, see ; https://root.cern.ch/root/htmldoc/guides/users-guide/ROOTUsersGuide.html#numerical-integration. Maybe it is not too visible, and I agree @couet we should probably include in the DOxygen description of the Integration classes. ; We are also missing a tutorial on the INtegratorMultiDim and we should add one before closing this issue",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/7740#issuecomment-810332566
Integrability,integrat,integration,"Hi, ; There is some documentation in the ROOT Users guide, see ; https://root.cern.ch/root/htmldoc/guides/users-guide/ROOTUsersGuide.html#numerical-integration. Maybe it is not too visible, and I agree @couet we should probably include in the DOxygen description of the Integration classes. ; We are also missing a tutorial on the INtegratorMultiDim and we should add one before closing this issue",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/7740#issuecomment-810332566
Usability,guid,guide,"Hi, ; There is some documentation in the ROOT Users guide, see ; https://root.cern.ch/root/htmldoc/guides/users-guide/ROOTUsersGuide.html#numerical-integration. Maybe it is not too visible, and I agree @couet we should probably include in the DOxygen description of the Integration classes. ; We are also missing a tutorial on the INtegratorMultiDim and we should add one before closing this issue",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/7740#issuecomment-810332566
Deployability,integrat,integration,"Hi @lmoneta @couet . I checked the [current documentation](https://root.cern.ch/root/htmldoc/guides/users-guide/MathLibraries.html#numerical-integration), and the point `15.8.3.1 Using ROOT::Math::IntegratorMultiDim` actually shows an example of the IntegratorMultiDim and the usage of different algorithms. . There is a typo, probably caused by copypasting: `Here is a code example on how to use the ROOT::Math::IntegratorOneDim class`, actually it is an example of `IntegratorMultiDim`",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/7740#issuecomment-1943742763
Integrability,integrat,integration,"Hi @lmoneta @couet . I checked the [current documentation](https://root.cern.ch/root/htmldoc/guides/users-guide/MathLibraries.html#numerical-integration), and the point `15.8.3.1 Using ROOT::Math::IntegratorMultiDim` actually shows an example of the IntegratorMultiDim and the usage of different algorithms. . There is a typo, probably caused by copypasting: `Here is a code example on how to use the ROOT::Math::IntegratorOneDim class`, actually it is an example of `IntegratorMultiDim`",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/7740#issuecomment-1943742763
Usability,guid,guides,"Hi @lmoneta @couet . I checked the [current documentation](https://root.cern.ch/root/htmldoc/guides/users-guide/MathLibraries.html#numerical-integration), and the point `15.8.3.1 Using ROOT::Math::IntegratorMultiDim` actually shows an example of the IntegratorMultiDim and the usage of different algorithms. . There is a typo, probably caused by copypasting: `Here is a code example on how to use the ROOT::Math::IntegratorOneDim class`, actually it is an example of `IntegratorMultiDim`",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/7740#issuecomment-1943742763
Deployability,update,updates,"Hi @etejedor, thanks for your comments!. Enric and I had a meeting that resulted in the following action items for me:. 1. Remove the `test_` prefix from the roofit pythonization test files; 2. Come up with a mechanism that uses all the functions defined in the RooFit pythonization proxy classes for the pythonization, not excluding magic functions (which are often pythonized); 3. Check if the pythonization abstraction in this PR also allows for pythonizations with the C API; 4. Introduce Doxygen documentation for RooFit pyROOT. In my recent updates, I addressed bullet points 1, 2, and 3. 1. Was trivial to address; 2. I use now a combination of `mro()` and `funcname in klass.__dict__` to check if a new member function was defined in the corresponding Python class or any of it's base classes (inspired by [this stackoverflow post](https://stackoverflow.com/questions/5253397/check-if-class-attribute-was-defined-or-derived-in-given-class)); 3. I made a relatively [simple test](https://github.com/root-project/root/commit/96d76be74f347eb36bd4d785d6689efebb17408b) to verify that if one updates the Python classes with the C API, this is propagated as a pythonization to the correct RooFit class.; Indeed, if you make the changes to the code in my test branch, then this code gives the expected behaviour (using pythonized version of `__getattr__`:; ```Python; import ROOT; a = ROOT.RooRealVar(""x"", ""x"", 0, 0, 10.); getattr(a, ""Hello""); ```. 4. For the documentation, I still have to do that later.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/7753#issuecomment-831297263
Testability,test,test,"Hi @etejedor, thanks for your comments!. Enric and I had a meeting that resulted in the following action items for me:. 1. Remove the `test_` prefix from the roofit pythonization test files; 2. Come up with a mechanism that uses all the functions defined in the RooFit pythonization proxy classes for the pythonization, not excluding magic functions (which are often pythonized); 3. Check if the pythonization abstraction in this PR also allows for pythonizations with the C API; 4. Introduce Doxygen documentation for RooFit pyROOT. In my recent updates, I addressed bullet points 1, 2, and 3. 1. Was trivial to address; 2. I use now a combination of `mro()` and `funcname in klass.__dict__` to check if a new member function was defined in the corresponding Python class or any of it's base classes (inspired by [this stackoverflow post](https://stackoverflow.com/questions/5253397/check-if-class-attribute-was-defined-or-derived-in-given-class)); 3. I made a relatively [simple test](https://github.com/root-project/root/commit/96d76be74f347eb36bd4d785d6689efebb17408b) to verify that if one updates the Python classes with the C API, this is propagated as a pythonization to the correct RooFit class.; Indeed, if you make the changes to the code in my test branch, then this code gives the expected behaviour (using pythonized version of `__getattr__`:; ```Python; import ROOT; a = ROOT.RooRealVar(""x"", ""x"", 0, 0, 10.); getattr(a, ""Hello""); ```. 4. For the documentation, I still have to do that later.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/7753#issuecomment-831297263
Usability,simpl,simple,"Hi @etejedor, thanks for your comments!. Enric and I had a meeting that resulted in the following action items for me:. 1. Remove the `test_` prefix from the roofit pythonization test files; 2. Come up with a mechanism that uses all the functions defined in the RooFit pythonization proxy classes for the pythonization, not excluding magic functions (which are often pythonized); 3. Check if the pythonization abstraction in this PR also allows for pythonizations with the C API; 4. Introduce Doxygen documentation for RooFit pyROOT. In my recent updates, I addressed bullet points 1, 2, and 3. 1. Was trivial to address; 2. I use now a combination of `mro()` and `funcname in klass.__dict__` to check if a new member function was defined in the corresponding Python class or any of it's base classes (inspired by [this stackoverflow post](https://stackoverflow.com/questions/5253397/check-if-class-attribute-was-defined-or-derived-in-given-class)); 3. I made a relatively [simple test](https://github.com/root-project/root/commit/96d76be74f347eb36bd4d785d6689efebb17408b) to verify that if one updates the Python classes with the C API, this is propagated as a pythonization to the correct RooFit class.; Indeed, if you make the changes to the code in my test branch, then this code gives the expected behaviour (using pythonized version of `__getattr__`:; ```Python; import ROOT; a = ROOT.RooRealVar(""x"", ""x"", 0, 0, 10.); getattr(a, ""Hello""); ```. 4. For the documentation, I still have to do that later.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/7753#issuecomment-831297263
Performance,load,load,"> probably due to filtering and skimming using a software that has the new persistency. CloneTree currently can only handle schema evolution if the 'fast' option is selected. For slow cloning it does not (yet?) deal well with the fact that the on-file and in-memory representation does not match (the reading part is 'sorta' fine but the writing part is confused because the cloned branches are (for now) the exact same as the input and thus we are now in the case were we attempt to write in a different format than the one in memory. The ""Info"" above are clear/exact that some data is lost because those field are no longer in memory (but they still have a branch for them on the output, so behavior will be strange). I am unclear why this leads to the behavior I have seen/reported but it might be linked. Thanks to your new file (that I can clone to a smaller if I make sure to load none of the pluto libraries), I seem to be back on track. thanks.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/7754#issuecomment-966525290
Usability,clear,clear,"> probably due to filtering and skimming using a software that has the new persistency. CloneTree currently can only handle schema evolution if the 'fast' option is selected. For slow cloning it does not (yet?) deal well with the fact that the on-file and in-memory representation does not match (the reading part is 'sorta' fine but the writing part is confused because the cloned branches are (for now) the exact same as the input and thus we are now in the case were we attempt to write in a different format than the one in memory. The ""Info"" above are clear/exact that some data is lost because those field are no longer in memory (but they still have a branch for them on the output, so behavior will be strange). I am unclear why this leads to the behavior I have seen/reported but it might be linked. Thanks to your new file (that I can clone to a smaller if I make sure to load none of the pluto libraries), I seem to be back on track. thanks.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/7754#issuecomment-966525290
Availability,ping,ping,"@vgvassilev In theory, everybody with commit access can review and approve patches. In practice Lang's commits didn't touch the instruction selection, and I'd really prefer to get feedback from an expert on this. I'll ping the patch probably tomorrow, people might have been off last week.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/7757#issuecomment-813881052
Deployability,patch,patches,"@vgvassilev In theory, everybody with commit access can review and approve patches. In practice Lang's commits didn't touch the instruction selection, and I'd really prefer to get feedback from an expert on this. I'll ping the patch probably tomorrow, people might have been off last week.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/7757#issuecomment-813881052
Security,access,access,"@vgvassilev In theory, everybody with commit access can review and approve patches. In practice Lang's commits didn't touch the instruction selection, and I'd really prefer to get feedback from an expert on this. I'll ping the patch probably tomorrow, people might have been off last week.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/7757#issuecomment-813881052
Usability,feedback,feedback,"@vgvassilev In theory, everybody with commit access can review and approve patches. In practice Lang's commits didn't touch the instruction selection, and I'd really prefer to get feedback from an expert on this. I'll ping the patch probably tomorrow, people might have been off last week.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/7757#issuecomment-813881052
Usability,feedback,feedback,"Hi @guitargeek , I have incorporated the comments that you had made earlier. it is unclear to me why why one of the travis CI build fails, please review the current version and provide us your feedback and suggestions.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/7766#issuecomment-814066020
Usability,feedback,feedback,"## DeepCode failed to analyze this pull request; Something went wrong despite trying multiple times, sorry about that.; Please comment this pull request with ""Retry DeepCode"" to manually retry, or [contact us](https://www.deepcode.ai/feedback?select=4&utm_source=gh_review) so that a human can look into the issue.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/7771#issuecomment-811770636
Performance,perform,performs,"Ha, that was again a nice rabbit hole. Here's a summary of what I found:; 1. We'll never run into problems with GCC's `libstdc++` since [version 4.5](https://gcc.gnu.org/gcc-4.5/changes.html): ""The default behavior for comparing typeinfo names has changed, so in `<typeinfo>`, `__GXX_MERGED_TYPEINFO_NAMES` now defaults to zero"", which means that `operator==` performs the string comparison in all cases.; 2. `libc++` by now has three different implementations: https://github.com/llvm/llvm-project/blob/066b8f2fc6d584635a017a0a15494ce4460744e3/libcxx/include/typeinfo#L120-L169 For all platforms except Windows and Apple M1, the library ""assume[s] the Itanium C++ ABI and use[s] the Unique implementation"". This may be fine for compiled programs where the linker can unify the `type_info`s, but not if the JIT emits a new copy. I have yet to find an example where this can go wrong, it would be great to have a test that fails if somebody attempts to ""simplify"" things. For this particular method however, the Itanium ABI mandates that the `std::type_info` objects of the checked types live in the run-time support library: https://itanium-cxx-abi.github.io/cxx-abi/abi.html#rtti-emission With exactly one object for those types, even `operator==` cannot mess up.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/7776#issuecomment-823939722
Testability,test,test,"Ha, that was again a nice rabbit hole. Here's a summary of what I found:; 1. We'll never run into problems with GCC's `libstdc++` since [version 4.5](https://gcc.gnu.org/gcc-4.5/changes.html): ""The default behavior for comparing typeinfo names has changed, so in `<typeinfo>`, `__GXX_MERGED_TYPEINFO_NAMES` now defaults to zero"", which means that `operator==` performs the string comparison in all cases.; 2. `libc++` by now has three different implementations: https://github.com/llvm/llvm-project/blob/066b8f2fc6d584635a017a0a15494ce4460744e3/libcxx/include/typeinfo#L120-L169 For all platforms except Windows and Apple M1, the library ""assume[s] the Itanium C++ ABI and use[s] the Unique implementation"". This may be fine for compiled programs where the linker can unify the `type_info`s, but not if the JIT emits a new copy. I have yet to find an example where this can go wrong, it would be great to have a test that fails if somebody attempts to ""simplify"" things. For this particular method however, the Itanium ABI mandates that the `std::type_info` objects of the checked types live in the run-time support library: https://itanium-cxx-abi.github.io/cxx-abi/abi.html#rtti-emission With exactly one object for those types, even `operator==` cannot mess up.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/7776#issuecomment-823939722
Usability,simpl,simplify,"Ha, that was again a nice rabbit hole. Here's a summary of what I found:; 1. We'll never run into problems with GCC's `libstdc++` since [version 4.5](https://gcc.gnu.org/gcc-4.5/changes.html): ""The default behavior for comparing typeinfo names has changed, so in `<typeinfo>`, `__GXX_MERGED_TYPEINFO_NAMES` now defaults to zero"", which means that `operator==` performs the string comparison in all cases.; 2. `libc++` by now has three different implementations: https://github.com/llvm/llvm-project/blob/066b8f2fc6d584635a017a0a15494ce4460744e3/libcxx/include/typeinfo#L120-L169 For all platforms except Windows and Apple M1, the library ""assume[s] the Itanium C++ ABI and use[s] the Unique implementation"". This may be fine for compiled programs where the linker can unify the `type_info`s, but not if the JIT emits a new copy. I have yet to find an example where this can go wrong, it would be great to have a test that fails if somebody attempts to ""simplify"" things. For this particular method however, the Itanium ABI mandates that the `std::type_info` objects of the checked types live in the run-time support library: https://itanium-cxx-abi.github.io/cxx-abi/abi.html#rtti-emission With exactly one object for those types, even `operator==` cannot mess up.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/7776#issuecomment-823939722
Testability,test,test,> Approving. Could you still open a new PR (probably on roottest) to explicitly test the multi library setups for both simple types and complex type. Thanks. Once more: There is nothing to test for complex types wrt `TDataType::GetType` - it's not handled anyway.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/7776#issuecomment-831409669
Usability,simpl,simple,> Approving. Could you still open a new PR (probably on roottest) to explicitly test the multi library setups for both simple types and complex type. Thanks. Once more: There is nothing to test for complex types wrt `TDataType::GetType` - it's not handled anyway.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/7776#issuecomment-831409669
Deployability,patch,patch,"Indeed, we don't guarantee ABI stability for patch releases. Most people cope (it has never been a huge issue) and it gives us the freedom to keep the LHC experiments working at a reasonable cost ;-) Patch level for us simply means ""it does not have new features, only bug fixes"".",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/7781#issuecomment-813669671
Usability,simpl,simply,"Indeed, we don't guarantee ABI stability for patch releases. Most people cope (it has never been a huge issue) and it gives us the freedom to keep the LHC experiments working at a reasonable cost ;-) Patch level for us simply means ""it does not have new features, only bug fixes"".",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/7781#issuecomment-813669671
Availability,error,error,"tes Compression= 1.00 *; *............................................................................*; ```; Result from rdf.Display()->Print():; ```; y | treefriend.y | ; 0 | 0 | ; 1 | 1 | ; 2 | 2 | ; 0 | 0 | ; 1 | 1 | ; 2 | 2 | ; 0 | 0 | ; 1 | 1 | ; 2 | 2 | ; ```. Everything still works, but we already see something missing in `TTree::Print`: only the information of the parent chain is printed!. ## Sub-case 2.2; If we don't give a name to the friend chain, then we're in a strange situation. Somehow magically I can do a Scan(y:treefriend1.y) that returns; Result from TTree:Scan(""y:treefriend1.y""):; ```; ************************************; * Row * y * treefrien *; ************************************; * 0 * 0 * 0 *; * 1 * 1 * 1 *; * 2 * 2 * 2 *; * 3 * 0 * 0 *; * 4 * 1 * 1 *; * 5 * 2 * 2 *; * 6 * 0 * 0 *; * 7 * 1 * 1 *; * 8 * 2 * 2 *; ************************************; ```; But a Scan(y:treefriend[23].y) returns the same error both times, still printing an empty ""treefrien"" column; ```; Error in <TTreeFormula::Compile>: Bad numerical expression : ""treefriend2.y""; ************************************; * Row * y * treefrien *; ************************************; * 0 * 0 * *; * 1 * 1 * *; * 2 * 2 * *; * 3 * 0 * *; * 4 * 1 * *; * 5 * 2 * *; * 6 * 0 * *; * 7 * 1 * *; * 8 * 2 * *; ************************************; ```; A very weird behaviour imho. Fortunately RDataFrame returns an error in any case if the friend chain does not have a name, which Enrico discussed many times in the comments and I now fully agree it's the best behaviour possible.; ```; terminate called after throwing an instance of 'std::runtime_error'; what(): Unknown column: treefriend.y; ```. # Case 3; Code to create the trees; ```cpp; void write_parent_tree(std::string_view filename, std::string_view treename); {; int x{};. TFile file{filename.data(), ""recreate""};; TTree tree{treename.data(), ""test friend trees""};; tree.Branch(""x"", &x, ""x/I"");. for (int i = 0; i < 9; i++); {; x = i;; tree.Fill(",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/7785#issuecomment-816500613
Modifiability,variab,variable,"***********************************; *Br 0 :y : y/I *; *Entries : 3 : Total Size= 556 bytes File Size = 87 *; *Baskets : 1 : Basket Size= 32000 bytes Compression= 1.00 *; *............................................................................*; ******************************************************************************; *Chain :treefriend: treefriend3.root *; ******************************************************************************; ******************************************************************************; *Tree :treefriend3: test friend trees *; *Entries : 3 : Total = 933 bytes File Size = 471 *; * : : Tree compression factor = 1.00 *; ******************************************************************************; *Br 0 :y : y/I *; *Entries : 3 : Total Size= 556 bytes File Size = 87 *; *Baskets : 1 : Basket Size= 32000 bytes Compression= 1.00 *; *............................................................................*; ```. ## Sub-case 3.1; If we call the friend variable ""treefriend.y"", we get; Result from TTree:Scan(""x:treefriend.y""):; ```; Error in <TTreeFormula::Compile>: Bad numerical expression : ""treefriend.y""; ************************************; * Row * x * treefrien *; ************************************; * 0 * 0 * *; * 1 * 1 * *; * 2 * 2 * *; * 3 * 3 * *; * 4 * 4 * *; * 5 * 5 * *; * 6 * 6 * *; * 7 * 7 * *; * 8 * 8 * *; ************************************; ```; Result from rdf.Display()->Print():; ```; Error in <TTreeReaderValueBase::CreateProxy()>: The branch treefriend.y is contained in a Friend TTree that is not directly attached to the main.; This is not yet supported by TTreeReader.; terminate called after throwing an instance of 'std::runtime_error'; what(): An error was encountered while processing the data. TTreeReader status code is: 6; Aborted (core dumped); ```; Which are both somewhat unexpected since the friend chain has a name and it should be easy to distinguish its entries from the main tree. I do like better the ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/7785#issuecomment-816500613
Testability,test,test,"; | 1 | 1 |; | 2 | 2 |; | 3 | 3 |; | 4 | 4 |; | 5 | 5 |; | 6 | 6 |; | 7 | 7 |; | 8 | 8 |. I can do that through:; 1. Two TTrees, each with 9 entries, each saved to one single file.; 2. Two TChains, each chain has 9 total entries, each chain is made of three files, each file has internally one TTree with 3 entries.; 3. One TTree with 9 entries saved to one file, plus one TChain with 9 total entries, three files each with a TTree with 3 entries. In each scenario I will create the datasets, read the files back, add one of the two datasets as a friend to the other. Finally, I will try to print the columns both with `TTree::Print` and rdf's `Display`. Plus, I will also use `TTree::Scan` to get more information on the internal structure of the tree and its friend. # Case 1; This is the code I use to recreate the scenario. ```cpp; void write_tree(std::string_view filename, std::string_view treename); {; int x{};. TFile file{filename.data(), ""recreate""};; TTree tree{treename.data(), ""test friend trees""};; tree.Branch(""x"", &x, ""x/I"");. for (int i = 0; i < 9; i++); {; x = i;; tree.Fill();; }; tree.Write();; }; ; int main(){; write_tree(""treeparent.root"", ""treeparent"");; write_tree(""treefriend.root"", ""treefriend"");; TFile parentfile{""treeparent.root"", ""read""};; TFile friendfile{""treefriend.root"", ""read""};. std::unique_ptr<TTree> parenttree{parentfile.Get<TTree>(""treeparent"")};; std::unique_ptr<TTree> friendtree{friendfile.Get<TTree>(""treefriend"")};. parenttree->AddFriend(friendtree.get());; parenttree->Scan(""x:treefriend.x"");; parenttree->Print(""all"");. ROOT::RDataFrame rdf{*parenttree};; auto display = rdf.Display("""");; std::cout << ""Result from rdf.Display()->Print():\n"";; display->Print();; }; ```. Result from TTree:Scan(""x:treefriend.x""):; ```; ************************************; * Row * x * treefrien *; ************************************; * 0 * 0 * 0 *; * 1 * 1 * 1 *; * 2 * 2 * 2 *; * 3 * 3 * 3 *; * 4 * 4 * 4 *; * 5 * 5 * 5 *; * 6 * 6 * 6 *; * 7 * 7 * 7 *; * 8 * 8 * 8",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/7785#issuecomment-816500613
Usability,simpl,simple,"Alright, thanks for all the details and clarifications. Let me try to bring this PR a conclusion.; The original question was: is it right, at least for the usecases of the function `GetFriendInfo`, to retrieve the name of any friend chain via the following?; ```; const auto *realName = chainFiles->First()->GetName();; ```; Let me try to make (simple) examples of tree/chain friends and how RDataFrame deals with them. Let's say my final goal is to have this dataset. | parent.x | friend.x |; |----------|----------|; | 0 | 0 |; | 1 | 1 |; | 2 | 2 |; | 3 | 3 |; | 4 | 4 |; | 5 | 5 |; | 6 | 6 |; | 7 | 7 |; | 8 | 8 |. I can do that through:; 1. Two TTrees, each with 9 entries, each saved to one single file.; 2. Two TChains, each chain has 9 total entries, each chain is made of three files, each file has internally one TTree with 3 entries.; 3. One TTree with 9 entries saved to one file, plus one TChain with 9 total entries, three files each with a TTree with 3 entries. In each scenario I will create the datasets, read the files back, add one of the two datasets as a friend to the other. Finally, I will try to print the columns both with `TTree::Print` and rdf's `Display`. Plus, I will also use `TTree::Scan` to get more information on the internal structure of the tree and its friend. # Case 1; This is the code I use to recreate the scenario. ```cpp; void write_tree(std::string_view filename, std::string_view treename); {; int x{};. TFile file{filename.data(), ""recreate""};; TTree tree{treename.data(), ""test friend trees""};; tree.Branch(""x"", &x, ""x/I"");. for (int i = 0; i < 9; i++); {; x = i;; tree.Fill();; }; tree.Write();; }; ; int main(){; write_tree(""treeparent.root"", ""treeparent"");; write_tree(""treefriend.root"", ""treefriend"");; TFile parentfile{""treeparent.root"", ""read""};; TFile friendfile{""treefriend.root"", ""read""};. std::unique_ptr<TTree> parenttree{parentfile.Get<TTree>(""treeparent"")};; std::unique_ptr<TTree> friendtree{friendfile.Get<TTree>(""treefriend"")};. parenttree",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/7785#issuecomment-816500613
Usability,learn,learned,MASSIVE thanks to @eguiraud and @pcanal for all the suggestions and inputs! I learned so much from this :smile:,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/7785#issuecomment-820202357
Usability,simpl,simple,"\\""\\"", float f=1.f) with arguments:"" << std::endl;; std::cout << ""a: "" << a << std::endl;; std::cout << ""b: "" << b << std::endl;; std::cout << ""c: "" << c << std::endl;; std::cout << ""d: "" << d << std::endl;; std::cout << ""e: "" << e << std::endl;; std::cout << ""f: "" << f << std::endl;; }; Simple(float a, float b, float c,float d=1.f) {; std::cout << ""Simple(float a, float b, float c,float d=1.f) with arguments:"" << std::endl;; std::cout << ""a: "" << a << std::endl;; std::cout << ""b: "" << b << std::endl;; std::cout << ""c: "" << c << std::endl;; std::cout << ""d: "" << d << std::endl;; }; };. class Minimal{; public:; Minimal(int a, float b, float c=1.0f) {; std::cout << ""Minimal(int a, float b, float c=1.0f) with arguments:"" << std::endl;; std::cout << ""a: "" << a << std::endl;; std::cout << ""b: "" << b << std::endl;; std::cout << ""c: "" << c << std::endl;; }; Minimal(float a, float b) {; std::cout << ""Minimal(float a, float b) with arguments:"" << std::endl;; std::cout << ""a: "" << a << std::endl;; std::cout << ""b: "" << b << std::endl;; }; };; '''; ). a = int(1); b = float(2.2); c = float(3.3); d = float(4.4). simple = cppyy.gbl.Simple(a, b, c, d); minimal = cppyy.gbl.Minimal(a, b); ```. The constructors in `Simple` mimic the constructors of `TColor`. The `Minimal` class should show the same issue with less constructor arguments. Passing an `int` as first argument is not enough to distinguish between these two constructors; ```; Minimal(int a, float b, float c=1.0f); Minimal(float a, float b); ```; This is the result of the script above; ```; (cppyy-venv) vpadulan@fedorathinkpad-T550 [~/Projects/rootcode/ROOT-GITHUB-7790]: pip freeze; cppyy==1.9.5; cppyy-backend==1.14.3; cppyy-cling==6.21.6; CPyCppyy==1.12.4; (cppyy-venv) vpadulan@fedorathinkpad-T550 [~/Projects/rootcode/ROOT-GITHUB-7790]: python cppyy_simple_reproducer.py ; Simple(float a, float b, float c,float d=1.f) with arguments:; a: 1; b: 2.2; c: 3.3; d: 4.4; Minimal(float a, float b) with arguments:; a: 1; b: 2.2; ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/7790#issuecomment-828426447
Usability,guid,guide,"> I would rather make only only canvas with the two plot next to each other for a better comparison and a better display on the reference guide. Other wise it looks like a good example. Okay, i'll do that.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/7801#issuecomment-815696117
Usability,simpl,simpler,"And what about something simpler and faster to execute (no need for a TGraph2D) moreover with this new version the peaks appears much better on the 3D view. ```; /// \file; /// \ingroup tutorial_graphics; /// \notebook; /// Plot the Amplitude of a Hydrogen Atom.; ///; /// Visualize the Amplitude of a Hydrogen Atom in the n = 2, l = 0, m = 0 state.; /// Demonstrates how TH2F can be used in Quantum Mechanics.; ///; /// \macro_image; /// \macro_code; ///; /// \author Advait Dhingra. #include <cmath>. double WaveFunction(double x, double y) {; double r = sqrt(x *x + y*y);. double w = (1/pow((4*sqrt(2*TMath::Pi())* 1), 1.5)) * (2 - (r / 1)*pow(TMath::E(), (-1 * r)/2)); // Wavefunction formula for psi 2,0,0. return w*w; // Amplitude. }. void schroedinger_hydrogen() {; TH2F *h2D = new TH2F(""Hydrogen Atom"",; ""#Psi^{2}_{200} i.e. n = 2, l = 0, m = 0; Position in x direction; Position in y direction"",; 200, -10, 10, 200, -10, 10);. for (float i = -10; i < 10; i += 0.01) {; for (float j = -10; j < 10; j += 0.01) {; h2D->Fill(i, j, WaveFunction(i, j));; }; }. gStyle->SetPalette(kCividis);; gStyle->SetOptStat(0);. TCanvas *c1 = new TCanvas(""c1"", ""Schroedinger's Hydrogen Atom"", 1500, 750);; c1->Divide(2, 1);. auto c1_1 = c1->cd(1);; c1_1->SetRightMargin(0.14);; h2D->GetXaxis()->SetLabelSize(0.03);; h2D->GetYaxis()->SetLabelSize(0.03);; h2D->GetZaxis()->SetLabelSize(0.03);; h2D->SetContour(50);; h2D->Draw(""colz"");. TLatex *l = new TLatex(-10, -12.43, ""The Electron is more likely to be found in the yellow areas and less likely to be found in the blue areas."");; l->SetTextFont(42);; l->SetTextSize(0.02);; l->Draw();. auto c1_2 = c1->cd(2);; c1_2->SetTheta(42.);. TH2D *h2Dc = (TH2D*)h2D->Clone();; h2Dc->SetTitle(""3D view of probability amplitude;;"");; h2Dc->Draw(""surf2"");; }; ```. If you agree I let you commit this new version. I made several cosmetics changes also.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/7801#issuecomment-816540524
Usability,simpl,simpler,"> And what about something simpler and faster to execute (no need for a TGraph2D) moreover with this new version the peaks appears much better on the 3D view. Ah yes, this looks much smoother, Thank you :D",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/7801#issuecomment-816567262
Usability,guid,guide,"> Do you mean the header of the Canvas? Because I tried this and it is unable to render the symbols. (See the top of the window). No I mean in the comments, the header of the macro, the markdown part, where you put the comments which will then appear on the web in the root reference guide. You add a comment saying ""The formula is ... bla bla ... "" then you put the formula like:; \f$ the_formula_in_Latex_format \f$",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/7801#issuecomment-816637869
Usability,guid,guide,"> > Do you mean the header of the Canvas? Because I tried this and it is unable to render the symbols. (See the top of the window); > ; > No I mean in the comments, the header of the macro, the markdown part, where you put the comments which will then appear on the web in the root reference guide. You add a comment saying ""The formula is ... bla bla ... "" then you put the formula like:; > \f$ the_formula_in_Latex_format \f$. Ohh ok. So I should remove the formula from the programm and add it to the markdown part?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/7801#issuecomment-816638539
Usability,guid,guide,"I tried the macro in the ref guide. It works nice. The formula shows nicely:. <img width=""996"" alt=""Screenshot 2021-04-09 at 16 07 57"" src=""https://user-images.githubusercontent.com/4697738/114192490-d5986d00-994d-11eb-9b78-76c062a039f0.png"">. To show better in the ref guide it is preferable to put the two plots vertically instead of horizontally. ; Therefore you should change the TCanvas and Divide lines to:. ```; TCanvas *c1 = new TCanvas(""c1"", ""Schroedinger's Hydrogen Atom"", 750, 1500);; c1->Divide(1, 2);; ```. That will be the last changes. After that we can merge it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/7801#issuecomment-816710642
Usability,guid,guide,"> To show better in the ref guide it is preferable to put the two plots vertically instead of horizontally.; > Therefore you should change the TCanvas and Divide lines to:; > ; > ```; > TCanvas *c1 = new TCanvas(""c1"", ""Schroedinger's Hydrogen Atom"", 750, 1500);; > c1->Divide(1, 2);; > ```; > ; > That will be the last changes. After that we can merge it. Okay, thank you for you help",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/7801#issuecomment-816712227
Deployability,install,installation,"@stwunsch : The machine running the installation of the reference guide is root-ubuntu-2004-2. I logged on this machine and simply tried (stupidly) to type ""pyspark"". I know nothing about this tool but surprisingly I got an answer saying it seems wrongly installed there ... Dod you have an idea about that ? what should be done ? A Python expert might know better. ```; sftnight@root-ubuntu-2004-2:~$ pyspark; Could not find valid SPARK_HOME while searching ['/home', '/usr/local/bin']. Did you install PySpark via a package manager such as pip or Conda? If so,; PySpark was not found in your Python environment. It is possible your; Python environment does not properly bind with your package manager. Please check your default 'python' and if you set PYSPARK_PYTHON and/or; PYSPARK_DRIVER_PYTHON environment variables, and see if you can import; PySpark, for example, 'python -c 'import pyspark'. If you cannot import, you can install by using the Python executable directly,; for example, 'python -m pip install pyspark [--user]'. Otherwise, you can also; explicitly set the Python executable, that has PySpark installed, to; PYSPARK_PYTHON or PYSPARK_DRIVER_PYTHON environment variables, for example,; 'PYSPARK_PYTHON=python3 pyspark'. /usr/local/bin/pyspark: line 24: /bin/load-spark-env.sh: No such file or directory; /usr/local/bin/pyspark: line 68: /bin/spark-submit: No such file or directory; sftnight@root-ubuntu-2004-2:~$ . ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/7802#issuecomment-822528404
Modifiability,variab,variables,"@stwunsch : The machine running the installation of the reference guide is root-ubuntu-2004-2. I logged on this machine and simply tried (stupidly) to type ""pyspark"". I know nothing about this tool but surprisingly I got an answer saying it seems wrongly installed there ... Dod you have an idea about that ? what should be done ? A Python expert might know better. ```; sftnight@root-ubuntu-2004-2:~$ pyspark; Could not find valid SPARK_HOME while searching ['/home', '/usr/local/bin']. Did you install PySpark via a package manager such as pip or Conda? If so,; PySpark was not found in your Python environment. It is possible your; Python environment does not properly bind with your package manager. Please check your default 'python' and if you set PYSPARK_PYTHON and/or; PYSPARK_DRIVER_PYTHON environment variables, and see if you can import; PySpark, for example, 'python -c 'import pyspark'. If you cannot import, you can install by using the Python executable directly,; for example, 'python -m pip install pyspark [--user]'. Otherwise, you can also; explicitly set the Python executable, that has PySpark installed, to; PYSPARK_PYTHON or PYSPARK_DRIVER_PYTHON environment variables, for example,; 'PYSPARK_PYTHON=python3 pyspark'. /usr/local/bin/pyspark: line 24: /bin/load-spark-env.sh: No such file or directory; /usr/local/bin/pyspark: line 68: /bin/spark-submit: No such file or directory; sftnight@root-ubuntu-2004-2:~$ . ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/7802#issuecomment-822528404
Performance,load,load-spark-env,"@stwunsch : The machine running the installation of the reference guide is root-ubuntu-2004-2. I logged on this machine and simply tried (stupidly) to type ""pyspark"". I know nothing about this tool but surprisingly I got an answer saying it seems wrongly installed there ... Dod you have an idea about that ? what should be done ? A Python expert might know better. ```; sftnight@root-ubuntu-2004-2:~$ pyspark; Could not find valid SPARK_HOME while searching ['/home', '/usr/local/bin']. Did you install PySpark via a package manager such as pip or Conda? If so,; PySpark was not found in your Python environment. It is possible your; Python environment does not properly bind with your package manager. Please check your default 'python' and if you set PYSPARK_PYTHON and/or; PYSPARK_DRIVER_PYTHON environment variables, and see if you can import; PySpark, for example, 'python -c 'import pyspark'. If you cannot import, you can install by using the Python executable directly,; for example, 'python -m pip install pyspark [--user]'. Otherwise, you can also; explicitly set the Python executable, that has PySpark installed, to; PYSPARK_PYTHON or PYSPARK_DRIVER_PYTHON environment variables, for example,; 'PYSPARK_PYTHON=python3 pyspark'. /usr/local/bin/pyspark: line 24: /bin/load-spark-env.sh: No such file or directory; /usr/local/bin/pyspark: line 68: /bin/spark-submit: No such file or directory; sftnight@root-ubuntu-2004-2:~$ . ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/7802#issuecomment-822528404
Testability,log,logged,"@stwunsch : The machine running the installation of the reference guide is root-ubuntu-2004-2. I logged on this machine and simply tried (stupidly) to type ""pyspark"". I know nothing about this tool but surprisingly I got an answer saying it seems wrongly installed there ... Dod you have an idea about that ? what should be done ? A Python expert might know better. ```; sftnight@root-ubuntu-2004-2:~$ pyspark; Could not find valid SPARK_HOME while searching ['/home', '/usr/local/bin']. Did you install PySpark via a package manager such as pip or Conda? If so,; PySpark was not found in your Python environment. It is possible your; Python environment does not properly bind with your package manager. Please check your default 'python' and if you set PYSPARK_PYTHON and/or; PYSPARK_DRIVER_PYTHON environment variables, and see if you can import; PySpark, for example, 'python -c 'import pyspark'. If you cannot import, you can install by using the Python executable directly,; for example, 'python -m pip install pyspark [--user]'. Otherwise, you can also; explicitly set the Python executable, that has PySpark installed, to; PYSPARK_PYTHON or PYSPARK_DRIVER_PYTHON environment variables, for example,; 'PYSPARK_PYTHON=python3 pyspark'. /usr/local/bin/pyspark: line 24: /bin/load-spark-env.sh: No such file or directory; /usr/local/bin/pyspark: line 68: /bin/spark-submit: No such file or directory; sftnight@root-ubuntu-2004-2:~$ . ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/7802#issuecomment-822528404
Usability,guid,guide,"@stwunsch : The machine running the installation of the reference guide is root-ubuntu-2004-2. I logged on this machine and simply tried (stupidly) to type ""pyspark"". I know nothing about this tool but surprisingly I got an answer saying it seems wrongly installed there ... Dod you have an idea about that ? what should be done ? A Python expert might know better. ```; sftnight@root-ubuntu-2004-2:~$ pyspark; Could not find valid SPARK_HOME while searching ['/home', '/usr/local/bin']. Did you install PySpark via a package manager such as pip or Conda? If so,; PySpark was not found in your Python environment. It is possible your; Python environment does not properly bind with your package manager. Please check your default 'python' and if you set PYSPARK_PYTHON and/or; PYSPARK_DRIVER_PYTHON environment variables, and see if you can import; PySpark, for example, 'python -c 'import pyspark'. If you cannot import, you can install by using the Python executable directly,; for example, 'python -m pip install pyspark [--user]'. Otherwise, you can also; explicitly set the Python executable, that has PySpark installed, to; PYSPARK_PYTHON or PYSPARK_DRIVER_PYTHON environment variables, for example,; 'PYSPARK_PYTHON=python3 pyspark'. /usr/local/bin/pyspark: line 24: /bin/load-spark-env.sh: No such file or directory; /usr/local/bin/pyspark: line 68: /bin/spark-submit: No such file or directory; sftnight@root-ubuntu-2004-2:~$ . ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/7802#issuecomment-822528404
Usability,feedback,feedback,"@couet That you for your feedback. I will add some documentation and move the folder to bin/graphics. My thought process was that this could potentially be better than TikZ, as this is built completely using ROOT components and it can be changed over time. This class is also quite easy for beginners to contribute to, which would encourage more people to contribute.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/7820#issuecomment-817615979
Usability,simpl,simple,"> > Thanks for the tips. I will try to do this. ; > ; > ; > ; > Of course any comments or criticism on what I suggested are welcome :-). Thanks. So if I understand correctly, instead of plotting the TLine, TArrow etc one adds them to the TFeynman object and then draws everything at once? I looked into the code for TLegend, and this is what I understand:. - The legend entries are added to a TList; - The Draw method takes an Option_p and appends it to the TPad. What is this option_p?. My apologies if these are simple questions",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/7820#issuecomment-818692727
Usability,simpl,simply,You do not have any Draw() method for the TFeynmanEntry. You have a Add() method which will add the new object in the list of object in TFeynman. So you need to have a Tlist in TFeynman holding the list of all the TFeynman entry buildingthe diagram. The Draw method of TFeynman will simply do AppendPad and will pout the whole diagram in the list of primates of the current pad (gPad) . TFeynmanEntry will have a Paint and the Paint method of TFeynman will call all the Paint of the TFeynmanEntry in the TList ... Really it is the same structure as TLegend.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/7820#issuecomment-819336796
Usability,guid,guide,"> Good Morning Mr. @couet . I just realized that the paint method of TFeynman is never being called. When I call the draw > > > method, do I want to run the paint method first before AppendPad`?. The Paint() method is called automatically for you when the Pad will be display. You do not need to call it. See the figure in TPad ref guide .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/7820#issuecomment-820332500
Usability,guid,guide,"> > Good Morning Mr. @couet . I just realized that the paint method of TFeynman is never being called. When I call the draw > > > method, do I want to run the paint method first before AppendPad`?; > ; > The Paint() method is called automatically for you when the Pad will be display. You do not need to call it. See the figure in TPad ref guide . Ah ok. And when I want to add a TFeynmanEntry to the TList, how can I do that?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/7820#issuecomment-820333544
Energy Efficiency,reduce,reduce,"> > I think almost everything is there now. I've tested it in both Ubuntu 20.04 LTS and Windows 10. Can we let @phsft-bot build it on other systems?; > ; > No, it is not, see my comments about the coordinates ... how do you define them ?. I added Doxygen comments on the parameters of the methods. The coordinates are like this:. For AddItem you provide x1, y1 which is the starting coordinate and x2, y2 which is the stopping coordinate and labelX and labelY whihc is where the label is. I'm trying to figure out a way where you don't need to set the coordinates, but that may take a while. For AddPair, you simply provide the x and y coordinate of the center of the arc. The labels are positioned automatically. For AddCurved, You also only provide the x and y coordinate of the center of the arc, along with phimin and phimax angles. I'm also trying to find a way to reduce the amount of parameters here (like in TikZ). The problem is that the main type of feynman Diagram, is one where you have the fermions at the left and right side, and a boson + virtual particles (in pairs) in the middle. If this were the only type of feynman diagram, I could do this easily, however sometimes there are other ""irregular"" diagrams, which would be harder to implement. Is there a way, where the particles can be positioned automatically, and then checked to make sure there is no overlapping?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/7820#issuecomment-829968031
Testability,test,tested,"> > I think almost everything is there now. I've tested it in both Ubuntu 20.04 LTS and Windows 10. Can we let @phsft-bot build it on other systems?; > ; > No, it is not, see my comments about the coordinates ... how do you define them ?. I added Doxygen comments on the parameters of the methods. The coordinates are like this:. For AddItem you provide x1, y1 which is the starting coordinate and x2, y2 which is the stopping coordinate and labelX and labelY whihc is where the label is. I'm trying to figure out a way where you don't need to set the coordinates, but that may take a while. For AddPair, you simply provide the x and y coordinate of the center of the arc. The labels are positioned automatically. For AddCurved, You also only provide the x and y coordinate of the center of the arc, along with phimin and phimax angles. I'm also trying to find a way to reduce the amount of parameters here (like in TikZ). The problem is that the main type of feynman Diagram, is one where you have the fermions at the left and right side, and a boson + virtual particles (in pairs) in the middle. If this were the only type of feynman diagram, I could do this easily, however sometimes there are other ""irregular"" diagrams, which would be harder to implement. Is there a way, where the particles can be positioned automatically, and then checked to make sure there is no overlapping?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/7820#issuecomment-829968031
Usability,simpl,simply,"> > I think almost everything is there now. I've tested it in both Ubuntu 20.04 LTS and Windows 10. Can we let @phsft-bot build it on other systems?; > ; > No, it is not, see my comments about the coordinates ... how do you define them ?. I added Doxygen comments on the parameters of the methods. The coordinates are like this:. For AddItem you provide x1, y1 which is the starting coordinate and x2, y2 which is the stopping coordinate and labelX and labelY whihc is where the label is. I'm trying to figure out a way where you don't need to set the coordinates, but that may take a while. For AddPair, you simply provide the x and y coordinate of the center of the arc. The labels are positioned automatically. For AddCurved, You also only provide the x and y coordinate of the center of the arc, along with phimin and phimax angles. I'm also trying to find a way to reduce the amount of parameters here (like in TikZ). The problem is that the main type of feynman Diagram, is one where you have the fermions at the left and right side, and a boson + virtual particles (in pairs) in the middle. If this were the only type of feynman diagram, I could do this easily, however sometimes there are other ""irregular"" diagrams, which would be harder to implement. Is there a way, where the particles can be positioned automatically, and then checked to make sure there is no overlapping?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/7820#issuecomment-829968031
Usability,clear,clearing,"Build failed on ROOT-fedora30/cxx14.; Running on root-fedora30-2.cern.ch:/home/sftnight/build/workspace/root-pullrequests-build; [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/114303/console).; ### Warnings:; - [2021-04-14T11:03:20.855Z] include/tbb/concurrent_hash_map.h:124:51: warning: void* memset(void*, int, size_t) clearing an object of type class tbb::interface5::internal::hash_map_base with no trivial copy-assignment; use value-initialization instead [-Wclass-memaccess] ; - [2021-04-14T11:10:29.086Z] include/tbb/concurrent_hash_map.h:124:51: warning: void* memset(void*, int, size_t) clearing an object of type class tbb::interface5::internal::hash_map_base with no trivial copy-assignment; use value-initialization instead [-Wclass-memaccess]",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/7870#issuecomment-819446975
Availability,failure,failures,"> Failure to meet that signature leads to an explosion of template instantiation failures with gcc. We should have better SFINAE code that provides clearer errors. > Show how to do a parallel for using Map()?. I think `Foreach` should be used for that, see my comment at #7872",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/7871#issuecomment-819540665
Usability,clear,clearer,"> Failure to meet that signature leads to an explosion of template instantiation failures with gcc. We should have better SFINAE code that provides clearer errors. > Show how to do a parallel for using Map()?. I think `Foreach` should be used for that, see my comment at #7872",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/7871#issuecomment-819540665
Usability,clear,cleared,"Should be cleared up. Using `depends_on :xcode if MacOS.version <= :catalina`, this gets the right paths and works. Will close here, and hopefully the PR will be merged soon in homebrew.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/7881#issuecomment-900729941
Usability,simpl,simple,"Thanks, @vgvassilev!!! Once the problem was identified as the issue with those paths, a very nice and simple solution became obvious.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/7881#issuecomment-900730523
Usability,clear,clearing,"Build failed on ROOT-fedora30/cxx14.; Running on root-fedora30-2.cern.ch:/home/sftnight/build/workspace/root-pullrequests-build; [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/114424/console).; ### Warnings:; - [2021-04-15T08:33:00.572Z] include/tbb/concurrent_hash_map.h:124:51: warning: void* memset(void*, int, size_t) clearing an object of type class tbb::interface5::internal::hash_map_base with no trivial copy-assignment; use value-initialization instead [-Wclass-memaccess] ; - [2021-04-15T08:40:21.736Z] include/tbb/concurrent_hash_map.h:124:51: warning: void* memset(void*, int, size_t) clearing an object of type class tbb::interface5::internal::hash_map_base with no trivial copy-assignment; use value-initialization instead [-Wclass-memaccess]",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/7884#issuecomment-820253733
Usability,feedback,feedback,After positive feedback from user I merging this PR,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/7885#issuecomment-841061484
Usability,simpl,simple,"Thank you for this PR.; Since we include <cmath> I agree we should use `std::sqrt` instead simple `sqrt` that is defined in <math>. We should probably change other similar files in the genvector package. . For this PR, it would be nice if you cleanup the commit history and squash the commits in a single one to have a cleaner history; Thank you. Lorenzo",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/7909#issuecomment-822312306
Usability,simpl,simple,"> Thank you for this PR.; > Since we include I agree we should use `std::sqrt` instead simple `sqrt` that is defined in; > ; > We should probably change other similar files in the genvector package.; > ; > For this PR, it would be nice if you cleanup the commit history and squash the commits in a single one to have a cleaner history; > Thank you; > ; > Lorenzo. Sure, will do.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/7909#issuecomment-822314822
Availability,error,error,"@Axel-Naumann @eguiraud One of my dataframe tests fails because of this:; ```; 27/155 Test #1500: roottest-root-dataframe-test_snapshot .........................***Failed 13.13 sec; ...; --- /srv/root/src/roottest/root/dataframe/test_snapshot.ref	Tue Mar 17 09:11:36 2020; +++ /srv/root/build/roottest/root/dataframe/test_snapshot.log	Fri Apr 23 09:56:40 2021; @@ -1,4 +1,5 @@; ; +cling::DynamicLibraryManager::loadLibrary():/srv/root/build/roottest/root/dataframe/par:cannotdynamicallyloadposition-independentexecutable; ----Nowwithatreeintherootdirectory; Branch:b1; Branch:b1_square. -- END OUTDIFF OUTPUT --; CMake Error at /srv/root/build/RootTestDriver.cmake:264 (message):; compare 'stdout' error: 1; ```; Somehow ROOT should address the case of binaries built with -fpie, as at least Gentoo has enabled that by default in GCC to improve security. Other distros may do the same in the future. See e.g. https://docs.fedoraproject.org/en-US/packaging-guidelines/#_pie",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/7936#issuecomment-825474655
Integrability,message,message,"@Axel-Naumann @eguiraud One of my dataframe tests fails because of this:; ```; 27/155 Test #1500: roottest-root-dataframe-test_snapshot .........................***Failed 13.13 sec; ...; --- /srv/root/src/roottest/root/dataframe/test_snapshot.ref	Tue Mar 17 09:11:36 2020; +++ /srv/root/build/roottest/root/dataframe/test_snapshot.log	Fri Apr 23 09:56:40 2021; @@ -1,4 +1,5 @@; ; +cling::DynamicLibraryManager::loadLibrary():/srv/root/build/roottest/root/dataframe/par:cannotdynamicallyloadposition-independentexecutable; ----Nowwithatreeintherootdirectory; Branch:b1; Branch:b1_square. -- END OUTDIFF OUTPUT --; CMake Error at /srv/root/build/RootTestDriver.cmake:264 (message):; compare 'stdout' error: 1; ```; Somehow ROOT should address the case of binaries built with -fpie, as at least Gentoo has enabled that by default in GCC to improve security. Other distros may do the same in the future. See e.g. https://docs.fedoraproject.org/en-US/packaging-guidelines/#_pie",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/7936#issuecomment-825474655
Performance,load,loadLibrary,"@Axel-Naumann @eguiraud One of my dataframe tests fails because of this:; ```; 27/155 Test #1500: roottest-root-dataframe-test_snapshot .........................***Failed 13.13 sec; ...; --- /srv/root/src/roottest/root/dataframe/test_snapshot.ref	Tue Mar 17 09:11:36 2020; +++ /srv/root/build/roottest/root/dataframe/test_snapshot.log	Fri Apr 23 09:56:40 2021; @@ -1,4 +1,5 @@; ; +cling::DynamicLibraryManager::loadLibrary():/srv/root/build/roottest/root/dataframe/par:cannotdynamicallyloadposition-independentexecutable; ----Nowwithatreeintherootdirectory; Branch:b1; Branch:b1_square. -- END OUTDIFF OUTPUT --; CMake Error at /srv/root/build/RootTestDriver.cmake:264 (message):; compare 'stdout' error: 1; ```; Somehow ROOT should address the case of binaries built with -fpie, as at least Gentoo has enabled that by default in GCC to improve security. Other distros may do the same in the future. See e.g. https://docs.fedoraproject.org/en-US/packaging-guidelines/#_pie",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/7936#issuecomment-825474655
Security,secur,security,"@Axel-Naumann @eguiraud One of my dataframe tests fails because of this:; ```; 27/155 Test #1500: roottest-root-dataframe-test_snapshot .........................***Failed 13.13 sec; ...; --- /srv/root/src/roottest/root/dataframe/test_snapshot.ref	Tue Mar 17 09:11:36 2020; +++ /srv/root/build/roottest/root/dataframe/test_snapshot.log	Fri Apr 23 09:56:40 2021; @@ -1,4 +1,5 @@; ; +cling::DynamicLibraryManager::loadLibrary():/srv/root/build/roottest/root/dataframe/par:cannotdynamicallyloadposition-independentexecutable; ----Nowwithatreeintherootdirectory; Branch:b1; Branch:b1_square. -- END OUTDIFF OUTPUT --; CMake Error at /srv/root/build/RootTestDriver.cmake:264 (message):; compare 'stdout' error: 1; ```; Somehow ROOT should address the case of binaries built with -fpie, as at least Gentoo has enabled that by default in GCC to improve security. Other distros may do the same in the future. See e.g. https://docs.fedoraproject.org/en-US/packaging-guidelines/#_pie",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/7936#issuecomment-825474655
Testability,test,tests,"@Axel-Naumann @eguiraud One of my dataframe tests fails because of this:; ```; 27/155 Test #1500: roottest-root-dataframe-test_snapshot .........................***Failed 13.13 sec; ...; --- /srv/root/src/roottest/root/dataframe/test_snapshot.ref	Tue Mar 17 09:11:36 2020; +++ /srv/root/build/roottest/root/dataframe/test_snapshot.log	Fri Apr 23 09:56:40 2021; @@ -1,4 +1,5 @@; ; +cling::DynamicLibraryManager::loadLibrary():/srv/root/build/roottest/root/dataframe/par:cannotdynamicallyloadposition-independentexecutable; ----Nowwithatreeintherootdirectory; Branch:b1; Branch:b1_square. -- END OUTDIFF OUTPUT --; CMake Error at /srv/root/build/RootTestDriver.cmake:264 (message):; compare 'stdout' error: 1; ```; Somehow ROOT should address the case of binaries built with -fpie, as at least Gentoo has enabled that by default in GCC to improve security. Other distros may do the same in the future. See e.g. https://docs.fedoraproject.org/en-US/packaging-guidelines/#_pie",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/7936#issuecomment-825474655
Usability,guid,guidelines,"@Axel-Naumann @eguiraud One of my dataframe tests fails because of this:; ```; 27/155 Test #1500: roottest-root-dataframe-test_snapshot .........................***Failed 13.13 sec; ...; --- /srv/root/src/roottest/root/dataframe/test_snapshot.ref	Tue Mar 17 09:11:36 2020; +++ /srv/root/build/roottest/root/dataframe/test_snapshot.log	Fri Apr 23 09:56:40 2021; @@ -1,4 +1,5 @@; ; +cling::DynamicLibraryManager::loadLibrary():/srv/root/build/roottest/root/dataframe/par:cannotdynamicallyloadposition-independentexecutable; ----Nowwithatreeintherootdirectory; Branch:b1; Branch:b1_square. -- END OUTDIFF OUTPUT --; CMake Error at /srv/root/build/RootTestDriver.cmake:264 (message):; compare 'stdout' error: 1; ```; Somehow ROOT should address the case of binaries built with -fpie, as at least Gentoo has enabled that by default in GCC to improve security. Other distros may do the same in the future. See e.g. https://docs.fedoraproject.org/en-US/packaging-guidelines/#_pie",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/7936#issuecomment-825474655
Testability,test,tests,"Build failed on ROOT-fedora32/default.; Running on root-fedora32-1.cern.ch:/home/sftnight/build/workspace/root-pullrequests-build; [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/115159/console).; ### Warnings:; - [2021-04-20T17:41:07.506Z] ginclude/tbb/concurrent_hash_map.h:131:76: warning: void* memset(void*, int, size_t) clearing an object of type struct tbb::interface5::internal::hash_map_base::bucket with no trivial copy-assignment; use value-initialization instead [-Wclass-memaccess] . ### Failing tests:; - [projectroot.roottest.root.meta.ROOT-7462.roottest_root_meta_ROOT_7462_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/115159/testReport/projectroot.roottest.root.meta/ROOT-7462/roottest_root_meta_ROOT_7462_make/); - [projectroot.roottest.root.io.uniquePointer.roottest_root_io_uniquePointer_simpleWriteRead](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/115159/testReport/projectroot.roottest.root.io/uniquePointer/roottest_root_io_uniquePointer_simpleWriteRead/); - [projectroot.roottest.root.io.uniquePointer.roottest_root_io_uniquePointer_simpleRead](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/115159/testReport/projectroot.roottest.root.io/uniquePointer/roottest_root_io_uniquePointer_simpleRead/)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/7942#issuecomment-823498058
Usability,clear,clearing,"Build failed on ROOT-fedora32/default.; Running on root-fedora32-1.cern.ch:/home/sftnight/build/workspace/root-pullrequests-build; [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/115159/console).; ### Warnings:; - [2021-04-20T17:41:07.506Z] ginclude/tbb/concurrent_hash_map.h:131:76: warning: void* memset(void*, int, size_t) clearing an object of type struct tbb::interface5::internal::hash_map_base::bucket with no trivial copy-assignment; use value-initialization instead [-Wclass-memaccess] . ### Failing tests:; - [projectroot.roottest.root.meta.ROOT-7462.roottest_root_meta_ROOT_7462_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/115159/testReport/projectroot.roottest.root.meta/ROOT-7462/roottest_root_meta_ROOT_7462_make/); - [projectroot.roottest.root.io.uniquePointer.roottest_root_io_uniquePointer_simpleWriteRead](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/115159/testReport/projectroot.roottest.root.io/uniquePointer/roottest_root_io_uniquePointer_simpleWriteRead/); - [projectroot.roottest.root.io.uniquePointer.roottest_root_io_uniquePointer_simpleRead](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/115159/testReport/projectroot.roottest.root.io/uniquePointer/roottest_root_io_uniquePointer_simpleRead/)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/7942#issuecomment-823498058
Testability,test,tests,"Build failed on ROOT-fedora32/default.; Running on root-fedora32-1.cern.ch:/home/sftnight/build/workspace/root-pullrequests-build; [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/115296/console).; ### Warnings:; - [2021-04-21T16:53:52.297Z] ginclude/tbb/concurrent_hash_map.h:131:76: warning: void* memset(void*, int, size_t) clearing an object of type struct tbb::interface5::internal::hash_map_base::bucket with no trivial copy-assignment; use value-initialization instead [-Wclass-memaccess] . ### Failing tests:; - [projectroot.roottest.root.meta.ROOT-7462.roottest_root_meta_ROOT_7462_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/115296/testReport/projectroot.roottest.root.meta/ROOT-7462/roottest_root_meta_ROOT_7462_make/); - [projectroot.roottest.root.io.uniquePointer.roottest_root_io_uniquePointer_simpleWriteRead](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/115296/testReport/projectroot.roottest.root.io/uniquePointer/roottest_root_io_uniquePointer_simpleWriteRead/); - [projectroot.roottest.root.io.uniquePointer.roottest_root_io_uniquePointer_simpleRead](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/115296/testReport/projectroot.roottest.root.io/uniquePointer/roottest_root_io_uniquePointer_simpleRead/)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/7942#issuecomment-824222731
Usability,clear,clearing,"Build failed on ROOT-fedora32/default.; Running on root-fedora32-1.cern.ch:/home/sftnight/build/workspace/root-pullrequests-build; [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/115296/console).; ### Warnings:; - [2021-04-21T16:53:52.297Z] ginclude/tbb/concurrent_hash_map.h:131:76: warning: void* memset(void*, int, size_t) clearing an object of type struct tbb::interface5::internal::hash_map_base::bucket with no trivial copy-assignment; use value-initialization instead [-Wclass-memaccess] . ### Failing tests:; - [projectroot.roottest.root.meta.ROOT-7462.roottest_root_meta_ROOT_7462_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/115296/testReport/projectroot.roottest.root.meta/ROOT-7462/roottest_root_meta_ROOT_7462_make/); - [projectroot.roottest.root.io.uniquePointer.roottest_root_io_uniquePointer_simpleWriteRead](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/115296/testReport/projectroot.roottest.root.io/uniquePointer/roottest_root_io_uniquePointer_simpleWriteRead/); - [projectroot.roottest.root.io.uniquePointer.roottest_root_io_uniquePointer_simpleRead](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/115296/testReport/projectroot.roottest.root.io/uniquePointer/roottest_root_io_uniquePointer_simpleRead/)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/7942#issuecomment-824222731
Testability,test,tests,"Build failed on ROOT-fedora32/default.; Running on root-fedora32-1.cern.ch:/home/sftnight/build/workspace/root-pullrequests-build; [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/115313/console).; ### Warnings:; - [2021-04-21T17:35:44.121Z] ginclude/tbb/concurrent_hash_map.h:131:76: warning: void* memset(void*, int, size_t) clearing an object of type struct tbb::interface5::internal::hash_map_base::bucket with no trivial copy-assignment; use value-initialization instead [-Wclass-memaccess] . ### Failing tests:; - [projectroot.roottest.root.meta.ROOT-7462.roottest_root_meta_ROOT_7462_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/115313/testReport/projectroot.roottest.root.meta/ROOT-7462/roottest_root_meta_ROOT_7462_make/); - [projectroot.roottest.root.io.uniquePointer.roottest_root_io_uniquePointer_simpleWriteRead](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/115313/testReport/projectroot.roottest.root.io/uniquePointer/roottest_root_io_uniquePointer_simpleWriteRead/); - [projectroot.roottest.root.io.uniquePointer.roottest_root_io_uniquePointer_simpleRead](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/115313/testReport/projectroot.roottest.root.io/uniquePointer/roottest_root_io_uniquePointer_simpleRead/)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/7942#issuecomment-824249820
Usability,clear,clearing,"Build failed on ROOT-fedora32/default.; Running on root-fedora32-1.cern.ch:/home/sftnight/build/workspace/root-pullrequests-build; [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/115313/console).; ### Warnings:; - [2021-04-21T17:35:44.121Z] ginclude/tbb/concurrent_hash_map.h:131:76: warning: void* memset(void*, int, size_t) clearing an object of type struct tbb::interface5::internal::hash_map_base::bucket with no trivial copy-assignment; use value-initialization instead [-Wclass-memaccess] . ### Failing tests:; - [projectroot.roottest.root.meta.ROOT-7462.roottest_root_meta_ROOT_7462_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/115313/testReport/projectroot.roottest.root.meta/ROOT-7462/roottest_root_meta_ROOT_7462_make/); - [projectroot.roottest.root.io.uniquePointer.roottest_root_io_uniquePointer_simpleWriteRead](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/115313/testReport/projectroot.roottest.root.io/uniquePointer/roottest_root_io_uniquePointer_simpleWriteRead/); - [projectroot.roottest.root.io.uniquePointer.roottest_root_io_uniquePointer_simpleRead](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/115313/testReport/projectroot.roottest.root.io/uniquePointer/roottest_root_io_uniquePointer_simpleRead/)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/7942#issuecomment-824249820
Testability,test,tests,"Build failed on ROOT-fedora32/default.; Running on root-fedora32-1.cern.ch:/home/sftnight/build/workspace/root-pullrequests-build; [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/115314/console).; ### Warnings:; - [2021-04-21T20:32:03.524Z] ginclude/tbb/concurrent_hash_map.h:131:76: warning: void* memset(void*, int, size_t) clearing an object of type struct tbb::interface5::internal::hash_map_base::bucket with no trivial copy-assignment; use value-initialization instead [-Wclass-memaccess] . ### Failing tests:; - [projectroot.roottest.root.meta.ROOT-7462.roottest_root_meta_ROOT_7462_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/115314/testReport/projectroot.roottest.root.meta/ROOT-7462/roottest_root_meta_ROOT_7462_make/); - [projectroot.roottest.root.io.uniquePointer.roottest_root_io_uniquePointer_simpleWriteRead](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/115314/testReport/projectroot.roottest.root.io/uniquePointer/roottest_root_io_uniquePointer_simpleWriteRead/); - [projectroot.roottest.root.io.uniquePointer.roottest_root_io_uniquePointer_simpleRead](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/115314/testReport/projectroot.roottest.root.io/uniquePointer/roottest_root_io_uniquePointer_simpleRead/)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/7942#issuecomment-824351593
Usability,clear,clearing,"Build failed on ROOT-fedora32/default.; Running on root-fedora32-1.cern.ch:/home/sftnight/build/workspace/root-pullrequests-build; [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/115314/console).; ### Warnings:; - [2021-04-21T20:32:03.524Z] ginclude/tbb/concurrent_hash_map.h:131:76: warning: void* memset(void*, int, size_t) clearing an object of type struct tbb::interface5::internal::hash_map_base::bucket with no trivial copy-assignment; use value-initialization instead [-Wclass-memaccess] . ### Failing tests:; - [projectroot.roottest.root.meta.ROOT-7462.roottest_root_meta_ROOT_7462_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/115314/testReport/projectroot.roottest.root.meta/ROOT-7462/roottest_root_meta_ROOT_7462_make/); - [projectroot.roottest.root.io.uniquePointer.roottest_root_io_uniquePointer_simpleWriteRead](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/115314/testReport/projectroot.roottest.root.io/uniquePointer/roottest_root_io_uniquePointer_simpleWriteRead/); - [projectroot.roottest.root.io.uniquePointer.roottest_root_io_uniquePointer_simpleRead](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/115314/testReport/projectroot.roottest.root.io/uniquePointer/roottest_root_io_uniquePointer_simpleRead/)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/7942#issuecomment-824351593
Testability,test,tests,"Build failed on ROOT-fedora32/default.; Running on root-fedora32-1.cern.ch:/home/sftnight/build/workspace/root-pullrequests-build; [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/115411/console).; ### Warnings:; - [2021-04-22T15:26:47.027Z] ginclude/tbb/concurrent_hash_map.h:131:76: warning: void* memset(void*, int, size_t) clearing an object of type struct tbb::interface5::internal::hash_map_base::bucket with no trivial copy-assignment; use value-initialization instead [-Wclass-memaccess] ; - [2021-04-22T15:28:51.056Z] math/unuran/unuran-1.8.0-root/src/methods/mvtdr_init.ch:886:17: warning: argument 1 value 18446744073709551608 exceeds maximum object size 9223372036854775807 [-Walloc-size-larger-than=] . ### Failing tests:; - [projectroot.roottest.root.io.uniquePointer.roottest_root_io_uniquePointer_simpleWriteRead](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/115411/testReport/projectroot.roottest.root.io/uniquePointer/roottest_root_io_uniquePointer_simpleWriteRead/); - [projectroot.roottest.root.io.uniquePointer.roottest_root_io_uniquePointer_simpleRead](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/115411/testReport/projectroot.roottest.root.io/uniquePointer/roottest_root_io_uniquePointer_simpleRead/); - [projectroot.roottest.root.meta.ROOT-7462.roottest_root_meta_ROOT_7462_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/115411/testReport/projectroot.roottest.root.meta/ROOT-7462/roottest_root_meta_ROOT_7462_make/)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/7942#issuecomment-824971382
Usability,clear,clearing,"Build failed on ROOT-fedora32/default.; Running on root-fedora32-1.cern.ch:/home/sftnight/build/workspace/root-pullrequests-build; [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/115411/console).; ### Warnings:; - [2021-04-22T15:26:47.027Z] ginclude/tbb/concurrent_hash_map.h:131:76: warning: void* memset(void*, int, size_t) clearing an object of type struct tbb::interface5::internal::hash_map_base::bucket with no trivial copy-assignment; use value-initialization instead [-Wclass-memaccess] ; - [2021-04-22T15:28:51.056Z] math/unuran/unuran-1.8.0-root/src/methods/mvtdr_init.ch:886:17: warning: argument 1 value 18446744073709551608 exceeds maximum object size 9223372036854775807 [-Walloc-size-larger-than=] . ### Failing tests:; - [projectroot.roottest.root.io.uniquePointer.roottest_root_io_uniquePointer_simpleWriteRead](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/115411/testReport/projectroot.roottest.root.io/uniquePointer/roottest_root_io_uniquePointer_simpleWriteRead/); - [projectroot.roottest.root.io.uniquePointer.roottest_root_io_uniquePointer_simpleRead](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/115411/testReport/projectroot.roottest.root.io/uniquePointer/roottest_root_io_uniquePointer_simpleRead/); - [projectroot.roottest.root.meta.ROOT-7462.roottest_root_meta_ROOT_7462_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/115411/testReport/projectroot.roottest.root.meta/ROOT-7462/roottest_root_meta_ROOT_7462_make/)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/7942#issuecomment-824971382
Testability,test,tests,"Build failed on ROOT-fedora32/default.; Running on root-fedora32-1.cern.ch:/home/sftnight/build/workspace/root-pullrequests-build; [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/115420/console).; ### Warnings:; - [2021-04-22T16:40:55.816Z] ginclude/tbb/concurrent_hash_map.h:131:76: warning: void* memset(void*, int, size_t) clearing an object of type struct tbb::interface5::internal::hash_map_base::bucket with no trivial copy-assignment; use value-initialization instead [-Wclass-memaccess] ; - [2021-04-22T16:41:34.121Z] math/unuran/unuran-1.8.0-root/src/methods/mvtdr_init.ch:886:17: warning: argument 1 value 18446744073709551608 exceeds maximum object size 9223372036854775807 [-Walloc-size-larger-than=] . ### Failing tests:; - [projectroot.roottest.root.meta.ROOT-7462.roottest_root_meta_ROOT_7462_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/115420/testReport/projectroot.roottest.root.meta/ROOT-7462/roottest_root_meta_ROOT_7462_make/); - [projectroot.roottest.root.io.uniquePointer.roottest_root_io_uniquePointer_simpleWriteRead](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/115420/testReport/projectroot.roottest.root.io/uniquePointer/roottest_root_io_uniquePointer_simpleWriteRead/); - [projectroot.roottest.root.io.uniquePointer.roottest_root_io_uniquePointer_simpleRead](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/115420/testReport/projectroot.roottest.root.io/uniquePointer/roottest_root_io_uniquePointer_simpleRead/)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/7942#issuecomment-825024680
Usability,clear,clearing,"Build failed on ROOT-fedora32/default.; Running on root-fedora32-1.cern.ch:/home/sftnight/build/workspace/root-pullrequests-build; [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/115420/console).; ### Warnings:; - [2021-04-22T16:40:55.816Z] ginclude/tbb/concurrent_hash_map.h:131:76: warning: void* memset(void*, int, size_t) clearing an object of type struct tbb::interface5::internal::hash_map_base::bucket with no trivial copy-assignment; use value-initialization instead [-Wclass-memaccess] ; - [2021-04-22T16:41:34.121Z] math/unuran/unuran-1.8.0-root/src/methods/mvtdr_init.ch:886:17: warning: argument 1 value 18446744073709551608 exceeds maximum object size 9223372036854775807 [-Walloc-size-larger-than=] . ### Failing tests:; - [projectroot.roottest.root.meta.ROOT-7462.roottest_root_meta_ROOT_7462_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/115420/testReport/projectroot.roottest.root.meta/ROOT-7462/roottest_root_meta_ROOT_7462_make/); - [projectroot.roottest.root.io.uniquePointer.roottest_root_io_uniquePointer_simpleWriteRead](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/115420/testReport/projectroot.roottest.root.io/uniquePointer/roottest_root_io_uniquePointer_simpleWriteRead/); - [projectroot.roottest.root.io.uniquePointer.roottest_root_io_uniquePointer_simpleRead](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/115420/testReport/projectroot.roottest.root.io/uniquePointer/roottest_root_io_uniquePointer_simpleRead/)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/7942#issuecomment-825024680
Testability,test,tests,"Build failed on ROOT-fedora32/default.; Running on root-fedora32-1.cern.ch:/home/sftnight/build/workspace/root-pullrequests-build; [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/117068/console).; ### Warnings:; - [2021-05-06T20:26:40.917Z] ginclude/tbb/concurrent_hash_map.h:131:76: warning: void* memset(void*, int, size_t) clearing an object of type struct tbb::interface5::internal::hash_map_base::bucket with no trivial copy-assignment; use value-initialization instead [-Wclass-memaccess] ; - [2021-05-06T20:28:24.470Z] math/unuran/unuran-1.8.0-root/src/methods/mvtdr_init.ch:886:17: warning: argument 1 value 18446744073709551608 exceeds maximum object size 9223372036854775807 [-Walloc-size-larger-than=] . ### Failing tests:; - [projectroot.roottest.root.meta.ROOT-7462.roottest_root_meta_ROOT_7462_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/117068/testReport/projectroot.roottest.root.meta/ROOT-7462/roottest_root_meta_ROOT_7462_make/); - [projectroot.roottest.root.io.uniquePointer.roottest_root_io_uniquePointer_simpleWriteRead](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/117068/testReport/projectroot.roottest.root.io/uniquePointer/roottest_root_io_uniquePointer_simpleWriteRead/); - [projectroot.roottest.root.io.uniquePointer.roottest_root_io_uniquePointer_simpleRead](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/117068/testReport/projectroot.roottest.root.io/uniquePointer/roottest_root_io_uniquePointer_simpleRead/)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/7942#issuecomment-833862493
Usability,clear,clearing,"Build failed on ROOT-fedora32/default.; Running on root-fedora32-1.cern.ch:/home/sftnight/build/workspace/root-pullrequests-build; [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/117068/console).; ### Warnings:; - [2021-05-06T20:26:40.917Z] ginclude/tbb/concurrent_hash_map.h:131:76: warning: void* memset(void*, int, size_t) clearing an object of type struct tbb::interface5::internal::hash_map_base::bucket with no trivial copy-assignment; use value-initialization instead [-Wclass-memaccess] ; - [2021-05-06T20:28:24.470Z] math/unuran/unuran-1.8.0-root/src/methods/mvtdr_init.ch:886:17: warning: argument 1 value 18446744073709551608 exceeds maximum object size 9223372036854775807 [-Walloc-size-larger-than=] . ### Failing tests:; - [projectroot.roottest.root.meta.ROOT-7462.roottest_root_meta_ROOT_7462_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/117068/testReport/projectroot.roottest.root.meta/ROOT-7462/roottest_root_meta_ROOT_7462_make/); - [projectroot.roottest.root.io.uniquePointer.roottest_root_io_uniquePointer_simpleWriteRead](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/117068/testReport/projectroot.roottest.root.io/uniquePointer/roottest_root_io_uniquePointer_simpleWriteRead/); - [projectroot.roottest.root.io.uniquePointer.roottest_root_io_uniquePointer_simpleRead](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/117068/testReport/projectroot.roottest.root.io/uniquePointer/roottest_root_io_uniquePointer_simpleRead/)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/7942#issuecomment-833862493
Availability,down,down,"This PR looks a big improvement in fixing #7890 and #7933. Here are some test results run on Ubuntu 20. - Test create/delete a RooArgSet, simple example shown in #7933. - with current mater (i.e. including #7904 and #7935): ; - Time to create/delete 10M RooArgSet : 125 sec; - Increase of Memory ~ 1 GB; - with master + this PR: ; - Time to create/delete 10M RooArgSet : 0.8 sec; - total memory increase + 25 Mb); - using 6.15 (before including current MemPoolForRooSets (-> #2866 ); - Time to create/delete 10M RooArgSet : 2.9 sec; - memory increase : 0 ; ; - Running RooStats toy generation + likelihood evaluation on Histfactory tutorial model using in totoal 300k toys: ; ```; StandardHypoTestInvDemo(""$ROOTSYS/tutorials/histfactory/results/example_combined_GaussExample_model.root"",""combined"",""ModelConfig"","""",""obsData"",0,0,true,2,0,5,100000); ```. - master : Time: 344 sec Memory : ~ 3.5 GB; - master + this PR : Time: 157 sec Memory: 570 Mb; - 6.15 Time: 197 sec Memory: 240 Mb; . Runing the master on MacOsX, I have observed a much smaller memory increase, but a much longer time spent with allocating/deallocating RooArgSet's when their total count increases.; This is not observed anymore after applying this PR. So in conclusion:. - this PR fixes the increase time spent in allocate/deallocate RooArgSet over time, which will slow down toys analysis when number of toys increase; - there is still some increase in memory usage, but it is much smaller than before.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/7954#issuecomment-824721395
Energy Efficiency,allocate,allocate,"This PR looks a big improvement in fixing #7890 and #7933. Here are some test results run on Ubuntu 20. - Test create/delete a RooArgSet, simple example shown in #7933. - with current mater (i.e. including #7904 and #7935): ; - Time to create/delete 10M RooArgSet : 125 sec; - Increase of Memory ~ 1 GB; - with master + this PR: ; - Time to create/delete 10M RooArgSet : 0.8 sec; - total memory increase + 25 Mb); - using 6.15 (before including current MemPoolForRooSets (-> #2866 ); - Time to create/delete 10M RooArgSet : 2.9 sec; - memory increase : 0 ; ; - Running RooStats toy generation + likelihood evaluation on Histfactory tutorial model using in totoal 300k toys: ; ```; StandardHypoTestInvDemo(""$ROOTSYS/tutorials/histfactory/results/example_combined_GaussExample_model.root"",""combined"",""ModelConfig"","""",""obsData"",0,0,true,2,0,5,100000); ```. - master : Time: 344 sec Memory : ~ 3.5 GB; - master + this PR : Time: 157 sec Memory: 570 Mb; - 6.15 Time: 197 sec Memory: 240 Mb; . Runing the master on MacOsX, I have observed a much smaller memory increase, but a much longer time spent with allocating/deallocating RooArgSet's when their total count increases.; This is not observed anymore after applying this PR. So in conclusion:. - this PR fixes the increase time spent in allocate/deallocate RooArgSet over time, which will slow down toys analysis when number of toys increase; - there is still some increase in memory usage, but it is much smaller than before.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/7954#issuecomment-824721395
Testability,test,test,"This PR looks a big improvement in fixing #7890 and #7933. Here are some test results run on Ubuntu 20. - Test create/delete a RooArgSet, simple example shown in #7933. - with current mater (i.e. including #7904 and #7935): ; - Time to create/delete 10M RooArgSet : 125 sec; - Increase of Memory ~ 1 GB; - with master + this PR: ; - Time to create/delete 10M RooArgSet : 0.8 sec; - total memory increase + 25 Mb); - using 6.15 (before including current MemPoolForRooSets (-> #2866 ); - Time to create/delete 10M RooArgSet : 2.9 sec; - memory increase : 0 ; ; - Running RooStats toy generation + likelihood evaluation on Histfactory tutorial model using in totoal 300k toys: ; ```; StandardHypoTestInvDemo(""$ROOTSYS/tutorials/histfactory/results/example_combined_GaussExample_model.root"",""combined"",""ModelConfig"","""",""obsData"",0,0,true,2,0,5,100000); ```. - master : Time: 344 sec Memory : ~ 3.5 GB; - master + this PR : Time: 157 sec Memory: 570 Mb; - 6.15 Time: 197 sec Memory: 240 Mb; . Runing the master on MacOsX, I have observed a much smaller memory increase, but a much longer time spent with allocating/deallocating RooArgSet's when their total count increases.; This is not observed anymore after applying this PR. So in conclusion:. - this PR fixes the increase time spent in allocate/deallocate RooArgSet over time, which will slow down toys analysis when number of toys increase; - there is still some increase in memory usage, but it is much smaller than before.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/7954#issuecomment-824721395
Usability,simpl,simple,"This PR looks a big improvement in fixing #7890 and #7933. Here are some test results run on Ubuntu 20. - Test create/delete a RooArgSet, simple example shown in #7933. - with current mater (i.e. including #7904 and #7935): ; - Time to create/delete 10M RooArgSet : 125 sec; - Increase of Memory ~ 1 GB; - with master + this PR: ; - Time to create/delete 10M RooArgSet : 0.8 sec; - total memory increase + 25 Mb); - using 6.15 (before including current MemPoolForRooSets (-> #2866 ); - Time to create/delete 10M RooArgSet : 2.9 sec; - memory increase : 0 ; ; - Running RooStats toy generation + likelihood evaluation on Histfactory tutorial model using in totoal 300k toys: ; ```; StandardHypoTestInvDemo(""$ROOTSYS/tutorials/histfactory/results/example_combined_GaussExample_model.root"",""combined"",""ModelConfig"","""",""obsData"",0,0,true,2,0,5,100000); ```. - master : Time: 344 sec Memory : ~ 3.5 GB; - master + this PR : Time: 157 sec Memory: 570 Mb; - 6.15 Time: 197 sec Memory: 240 Mb; . Runing the master on MacOsX, I have observed a much smaller memory increase, but a much longer time spent with allocating/deallocating RooArgSet's when their total count increases.; This is not observed anymore after applying this PR. So in conclusion:. - this PR fixes the increase time spent in allocate/deallocate RooArgSet over time, which will slow down toys analysis when number of toys increase; - there is still some increase in memory usage, but it is much smaller than before.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/7954#issuecomment-824721395
Deployability,release,release,"This is critical because we might load who knows what into the frameworks. But because the fix is rather intrusive, and the OP has a simple workaround, I'll *not* backport the fixes to our existing release branches.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/7955#issuecomment-856839812
Performance,load,load,"This is critical because we might load who knows what into the frameworks. But because the fix is rather intrusive, and the OP has a simple workaround, I'll *not* backport the fixes to our existing release branches.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/7955#issuecomment-856839812
Usability,simpl,simple,"This is critical because we might load who knows what into the frameworks. But because the fix is rather intrusive, and the OP has a simple workaround, I'll *not* backport the fixes to our existing release branches.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/7955#issuecomment-856839812
Energy Efficiency,efficient,efficient-parall,"We are really grateful for this feedback. The initial RHist prototype benefited a lot from it and became an even better base for the work that came after (see, e.g. https://indico.cern.ch/event/1403741/#1-thoughts-on-efficient-parall). I am marking this item as ""Won't fix"", but it should really be ""Thank you!"".",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/7971#issuecomment-2241265389
Usability,feedback,feedback,"We are really grateful for this feedback. The initial RHist prototype benefited a lot from it and became an even better base for the work that came after (see, e.g. https://indico.cern.ch/event/1403741/#1-thoughts-on-efficient-parall). I am marking this item as ""Won't fix"", but it should really be ""Thank you!"".",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/7971#issuecomment-2241265389
Usability,clear,clearing,"Build failed on ROOT-fedora30/cxx14.; Running on root-fedora30-2.cern.ch:/home/sftnight/build/workspace/root-pullrequests-build; [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/115423/console).; ### Warnings:; - [2021-04-22T18:04:52.119Z] include/tbb/concurrent_hash_map.h:124:51: warning: void* memset(void*, int, size_t) clearing an object of type class tbb::interface5::internal::hash_map_base with no trivial copy-assignment; use value-initialization instead [-Wclass-memaccess] ; - [2021-04-22T18:12:25.124Z] include/tbb/concurrent_hash_map.h:124:51: warning: void* memset(void*, int, size_t) clearing an object of type class tbb::interface5::internal::hash_map_base with no trivial copy-assignment; use value-initialization instead [-Wclass-memaccess]",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/7972#issuecomment-825088829
Testability,test,test,"I would feel *way* more confident if we had any test for this :-/ Would you be kind enough (and I really mean it...) to provide one? It's fairly simple, just copy `core/base/test/TNamedTests.cxx` to `core/base/test/TBitsTests.cxx` and use the usual `EXPECT_EQ` to check for the output to be what you'd expect. *Then* we can simplify things! :-) Let us know, please!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/7988#issuecomment-825759330
Usability,simpl,simple,"I would feel *way* more confident if we had any test for this :-/ Would you be kind enough (and I really mean it...) to provide one? It's fairly simple, just copy `core/base/test/TNamedTests.cxx` to `core/base/test/TBitsTests.cxx` and use the usual `EXPECT_EQ` to check for the output to be what you'd expect. *Then* we can simplify things! :-) Let us know, please!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/7988#issuecomment-825759330
Integrability,synchroniz,synchronize,"Dear Jonas. A huge thank you for your investigation on this, and kind explanation. Almost everything on what you explained is clear to me. But let me give you a tiny point where I don't completely understand. **About the <55 instead of <=55. You are right : I made a mistake there in my minimum example. But the principle of the comment stay. I made the fix in order to ""synchronize"" with the numerical values that you gave in your kind answer (I deduced that you made the fix). -->ok for that. **Case option_normalize_hist=1. Your comment : ""n_times_pdf_continuum->getVal()*bin_width=0.0181818 : here n_times_pdf_continuum is a RooAddPdf, which automatically normalizes itself. You create it from the continuum with 55 bins and bin width one, so I'd expect 1/55 which is indeed 0.0181818""; -->I disagree : my pdf is not just ""pdf_continuum"" : I put *n* times pdf_continuum where n is here the number of bkg : n=2200.; So I would expect that n times pdf should be 2200 * (1/55) = 40. **n_times_pdf_continuum is a RooAddPdf (with one element in the addition) with one parameter of yield, and one parameter of shape, so it is a extended pdf : n_bkg * times a pdf.**. **Case option_normalize_hist=0.; From your log, you changed a bit my code since in my code, I was putting, for the case not normalize :; if (option_normalize_hist); value_pdf=nb_events*pdf->getVal()*bin_width;; else; value_pdf=pdf->getVal()*bin_width;. But I understood your point (and it is clear)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/7991#issuecomment-826815525
Modifiability,extend,extended,"Dear Jonas. A huge thank you for your investigation on this, and kind explanation. Almost everything on what you explained is clear to me. But let me give you a tiny point where I don't completely understand. **About the <55 instead of <=55. You are right : I made a mistake there in my minimum example. But the principle of the comment stay. I made the fix in order to ""synchronize"" with the numerical values that you gave in your kind answer (I deduced that you made the fix). -->ok for that. **Case option_normalize_hist=1. Your comment : ""n_times_pdf_continuum->getVal()*bin_width=0.0181818 : here n_times_pdf_continuum is a RooAddPdf, which automatically normalizes itself. You create it from the continuum with 55 bins and bin width one, so I'd expect 1/55 which is indeed 0.0181818""; -->I disagree : my pdf is not just ""pdf_continuum"" : I put *n* times pdf_continuum where n is here the number of bkg : n=2200.; So I would expect that n times pdf should be 2200 * (1/55) = 40. **n_times_pdf_continuum is a RooAddPdf (with one element in the addition) with one parameter of yield, and one parameter of shape, so it is a extended pdf : n_bkg * times a pdf.**. **Case option_normalize_hist=0.; From your log, you changed a bit my code since in my code, I was putting, for the case not normalize :; if (option_normalize_hist); value_pdf=nb_events*pdf->getVal()*bin_width;; else; value_pdf=pdf->getVal()*bin_width;. But I understood your point (and it is clear)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/7991#issuecomment-826815525
Testability,log,log,"Dear Jonas. A huge thank you for your investigation on this, and kind explanation. Almost everything on what you explained is clear to me. But let me give you a tiny point where I don't completely understand. **About the <55 instead of <=55. You are right : I made a mistake there in my minimum example. But the principle of the comment stay. I made the fix in order to ""synchronize"" with the numerical values that you gave in your kind answer (I deduced that you made the fix). -->ok for that. **Case option_normalize_hist=1. Your comment : ""n_times_pdf_continuum->getVal()*bin_width=0.0181818 : here n_times_pdf_continuum is a RooAddPdf, which automatically normalizes itself. You create it from the continuum with 55 bins and bin width one, so I'd expect 1/55 which is indeed 0.0181818""; -->I disagree : my pdf is not just ""pdf_continuum"" : I put *n* times pdf_continuum where n is here the number of bkg : n=2200.; So I would expect that n times pdf should be 2200 * (1/55) = 40. **n_times_pdf_continuum is a RooAddPdf (with one element in the addition) with one parameter of yield, and one parameter of shape, so it is a extended pdf : n_bkg * times a pdf.**. **Case option_normalize_hist=0.; From your log, you changed a bit my code since in my code, I was putting, for the case not normalize :; if (option_normalize_hist); value_pdf=nb_events*pdf->getVal()*bin_width;; else; value_pdf=pdf->getVal()*bin_width;. But I understood your point (and it is clear)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/7991#issuecomment-826815525
Usability,clear,clear,"Dear Jonas. A huge thank you for your investigation on this, and kind explanation. Almost everything on what you explained is clear to me. But let me give you a tiny point where I don't completely understand. **About the <55 instead of <=55. You are right : I made a mistake there in my minimum example. But the principle of the comment stay. I made the fix in order to ""synchronize"" with the numerical values that you gave in your kind answer (I deduced that you made the fix). -->ok for that. **Case option_normalize_hist=1. Your comment : ""n_times_pdf_continuum->getVal()*bin_width=0.0181818 : here n_times_pdf_continuum is a RooAddPdf, which automatically normalizes itself. You create it from the continuum with 55 bins and bin width one, so I'd expect 1/55 which is indeed 0.0181818""; -->I disagree : my pdf is not just ""pdf_continuum"" : I put *n* times pdf_continuum where n is here the number of bkg : n=2200.; So I would expect that n times pdf should be 2200 * (1/55) = 40. **n_times_pdf_continuum is a RooAddPdf (with one element in the addition) with one parameter of yield, and one parameter of shape, so it is a extended pdf : n_bkg * times a pdf.**. **Case option_normalize_hist=0.; From your log, you changed a bit my code since in my code, I was putting, for the case not normalize :; if (option_normalize_hist); value_pdf=nb_events*pdf->getVal()*bin_width;; else; value_pdf=pdf->getVal()*bin_width;. But I understood your point (and it is clear)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/7991#issuecomment-826815525
Usability,clear,clear,"Jonas : thank you very much for your generous help. You are my hero for root/roofit. Everything is clear. Unfortunately, from this discussion, it seems that I found a mistake (in some specific cases) in the way roofit is computing the nll as provided by class RooFitResult and by RooAbsPdf->createNLL.; (since I am able to reproduce the value by hand if I do a *mistake on purpose* in the formula.). ->I will prepare the minimum possible program to try to prove it (maybe there is a cartesian explanation) and will create a new github entry.; Thank you",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/7991#issuecomment-827087008
Usability,clear,clearing,"Build failed on ROOT-fedora30/cxx14.; Running on root-fedora30-2.cern.ch:/home/sftnight/build/workspace/root-pullrequests-build; [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/115591/console).; ### Warnings:; - [2021-04-26T09:53:09.957Z] include/tbb/concurrent_hash_map.h:124:51: warning: void* memset(void*, int, size_t) clearing an object of type class tbb::interface5::internal::hash_map_base with no trivial copy-assignment; use value-initialization instead [-Wclass-memaccess] ; - [2021-04-26T09:59:59.673Z] include/tbb/concurrent_hash_map.h:124:51: warning: void* memset(void*, int, size_t) clearing an object of type class tbb::interface5::internal::hash_map_base with no trivial copy-assignment; use value-initialization instead [-Wclass-memaccess]",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/7994#issuecomment-826711414
Usability,guid,guide,This is fixed by https://github.com/root-project/root/pull/7951 . Just wait the ref guide is rebuild. It is building now.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/7996#issuecomment-826896706
Usability,feedback,feedback,"I would really like if we can do something about this, as also `nixpkgs` uses by default the `build` directory in the sources for building :slightly_smiling_face:. Does anyone have feedback on my suggestion?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8031#issuecomment-2142432497
Usability,clear,clear,"OK, I thought. > Another version of this will be reintroduced in llvm upstream. was clear enough. Thanks for the review!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8044#issuecomment-831916158
Performance,concurren,concurrentfill,"Many of the tests in the list above were renamed in master, but they all succceed:; ```; 1027/1220 Test #1028: tutorial-v7-histops.cxx ............................................. Passed 6.00 sec; 1029/1220 Test #1031: tutorial-v7-simple.cxx .............................................. Passed 8.82 sec; 1033/1220 Test #1026: tutorial-v7-concurrentfill.cxx ...................................... Passed 20.39 sec; 1034/1220 Test #1036: tutorial-rcanvas-rframe.cxx ......................................... Passed 2.93 sec; 1035/1220 Test #1037: tutorial-rcanvas-rh1.cxx ............................................ Passed 2.91 sec; 1037/1220 Test #1038: tutorial-rcanvas-rh1_large.cxx ...................................... Passed 3.14 sec; 1039/1220 Test #1040: tutorial-rcanvas-rh2.cxx ............................................ Passed 4.41 sec; 1040/1220 Test #1041: tutorial-rcanvas-rh2_colz.cxx ....................................... Passed 4.62 sec; 1041/1220 Test #1042: tutorial-rcanvas-rh2_large.cxx ...................................... Passed 4.85 sec; 1042/1220 Test #1045: tutorial-rcanvas-rlegend.cxx ........................................ Passed 2.46 sec; 1047/1220 Test #1034: tutorial-rcanvas-rcanvas_mt.cxx ..................................... Passed 25.33 sec; 1051/1220 Test #1043: tutorial-rcanvas-rh3.cxx ............................................ Passed 13.34 sec; 1053/1220 Test #1044: tutorial-rcanvas-rh3_large.cxx ...................................... Passed 13.14 sec; 1059/1220 Test #1056: tutorial-rcanvas-subpads.cxx ........................................ Passed 2.22 sec; 1066/1220 Test #1029: tutorial-v7-perf.cxx ................................................ Passed 55.03 sec; 1199/1220 Test #1030: tutorial-v7-perfcomp.cxx ............................................ Passed 105.92 sec; ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8073#issuecomment-1000999629
Testability,test,tests,"Many of the tests in the list above were renamed in master, but they all succceed:; ```; 1027/1220 Test #1028: tutorial-v7-histops.cxx ............................................. Passed 6.00 sec; 1029/1220 Test #1031: tutorial-v7-simple.cxx .............................................. Passed 8.82 sec; 1033/1220 Test #1026: tutorial-v7-concurrentfill.cxx ...................................... Passed 20.39 sec; 1034/1220 Test #1036: tutorial-rcanvas-rframe.cxx ......................................... Passed 2.93 sec; 1035/1220 Test #1037: tutorial-rcanvas-rh1.cxx ............................................ Passed 2.91 sec; 1037/1220 Test #1038: tutorial-rcanvas-rh1_large.cxx ...................................... Passed 3.14 sec; 1039/1220 Test #1040: tutorial-rcanvas-rh2.cxx ............................................ Passed 4.41 sec; 1040/1220 Test #1041: tutorial-rcanvas-rh2_colz.cxx ....................................... Passed 4.62 sec; 1041/1220 Test #1042: tutorial-rcanvas-rh2_large.cxx ...................................... Passed 4.85 sec; 1042/1220 Test #1045: tutorial-rcanvas-rlegend.cxx ........................................ Passed 2.46 sec; 1047/1220 Test #1034: tutorial-rcanvas-rcanvas_mt.cxx ..................................... Passed 25.33 sec; 1051/1220 Test #1043: tutorial-rcanvas-rh3.cxx ............................................ Passed 13.34 sec; 1053/1220 Test #1044: tutorial-rcanvas-rh3_large.cxx ...................................... Passed 13.14 sec; 1059/1220 Test #1056: tutorial-rcanvas-subpads.cxx ........................................ Passed 2.22 sec; 1066/1220 Test #1029: tutorial-v7-perf.cxx ................................................ Passed 55.03 sec; 1199/1220 Test #1030: tutorial-v7-perfcomp.cxx ............................................ Passed 105.92 sec; ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8073#issuecomment-1000999629
Usability,simpl,simple,"Many of the tests in the list above were renamed in master, but they all succceed:; ```; 1027/1220 Test #1028: tutorial-v7-histops.cxx ............................................. Passed 6.00 sec; 1029/1220 Test #1031: tutorial-v7-simple.cxx .............................................. Passed 8.82 sec; 1033/1220 Test #1026: tutorial-v7-concurrentfill.cxx ...................................... Passed 20.39 sec; 1034/1220 Test #1036: tutorial-rcanvas-rframe.cxx ......................................... Passed 2.93 sec; 1035/1220 Test #1037: tutorial-rcanvas-rh1.cxx ............................................ Passed 2.91 sec; 1037/1220 Test #1038: tutorial-rcanvas-rh1_large.cxx ...................................... Passed 3.14 sec; 1039/1220 Test #1040: tutorial-rcanvas-rh2.cxx ............................................ Passed 4.41 sec; 1040/1220 Test #1041: tutorial-rcanvas-rh2_colz.cxx ....................................... Passed 4.62 sec; 1041/1220 Test #1042: tutorial-rcanvas-rh2_large.cxx ...................................... Passed 4.85 sec; 1042/1220 Test #1045: tutorial-rcanvas-rlegend.cxx ........................................ Passed 2.46 sec; 1047/1220 Test #1034: tutorial-rcanvas-rcanvas_mt.cxx ..................................... Passed 25.33 sec; 1051/1220 Test #1043: tutorial-rcanvas-rh3.cxx ............................................ Passed 13.34 sec; 1053/1220 Test #1044: tutorial-rcanvas-rh3_large.cxx ...................................... Passed 13.14 sec; 1059/1220 Test #1056: tutorial-rcanvas-subpads.cxx ........................................ Passed 2.22 sec; 1066/1220 Test #1029: tutorial-v7-perf.cxx ................................................ Passed 55.03 sec; 1199/1220 Test #1030: tutorial-v7-perfcomp.cxx ............................................ Passed 105.92 sec; ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8073#issuecomment-1000999629
Testability,test,test,"> @guitargeek Maybe commit a comment on how to create the reference file above the test. Sorry that I didn't do that already. The way I did this was simply to open the v4 file with a newer ROOT version, use the copy constructor of RooDataHist and save the copied object. Is this the way that you would document, or is there an easier way?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8090#issuecomment-832034444
Usability,simpl,simply,"> @guitargeek Maybe commit a comment on how to create the reference file above the test. Sorry that I didn't do that already. The way I did this was simply to open the v4 file with a newer ROOT version, use the copy constructor of RooDataHist and save the copied object. Is this the way that you would document, or is there an easier way?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8090#issuecomment-832034444
Testability,test,test,"> The way I did this was simply to open the v4 file with a newer ROOT version, use the copy constructor of RooDataHist and save the copied object. Is this the way that you would document, or is there an easier way?. Ah, right. That will work. I thought you re-engineered that RooDataHist to document it in the style of:; https://github.com/root-project/root/blob/ef483dd32765470c702d72adf387d68663e28842/roofit/roofitcore/test/testProxiesAndCategories.cxx#L59-L80. In this case, it was probably this, but I don't remember:; https://github.com/root-project/root/blob/ef483dd32765470c702d72adf387d68663e28842/roofit/roofitcore/test/testRooDataHist.cxx#L242-L248",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8090#issuecomment-832043953
Usability,simpl,simply,"> The way I did this was simply to open the v4 file with a newer ROOT version, use the copy constructor of RooDataHist and save the copied object. Is this the way that you would document, or is there an easier way?. Ah, right. That will work. I thought you re-engineered that RooDataHist to document it in the style of:; https://github.com/root-project/root/blob/ef483dd32765470c702d72adf387d68663e28842/roofit/roofitcore/test/testProxiesAndCategories.cxx#L59-L80. In this case, it was probably this, but I don't remember:; https://github.com/root-project/root/blob/ef483dd32765470c702d72adf387d68663e28842/roofit/roofitcore/test/testRooDataHist.cxx#L242-L248",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8090#issuecomment-832043953
Deployability,continuous,continuous,"To separate those we have now, a simple way is to use this add-on: https://addons.mozilla.org/en-US/firefox/addon/grayscale-browsing/. It will show https://root.cern.ch/doc/master/classTColor.html in grayscale mode. ![image](https://user-images.githubusercontent.com/10653970/117177407-47d76280-add1-11eb-9081-9bac9d4b4bd5.png). You can immediately see that the color scale in rainbow is not continuous, which is then misleading for colour-blinded in a 2D plot (not so much in a 3D surf like this one). kCMYK is also not great because it's dark, then lighter, then half-dark again. Others like kAquamarine have almost no contrast, it would be almost impossible to see sth there. So that would be a quick way to separate them. The idea is that the grayscale should be as proportional as possible, and monotonously increasing or decreasing. Unless it is symmetrical, then it is fine to have white in the borders and black in the centre (for example for example an axis that goes between -40 degrees and + 40 degrees, the 0 has a meaning). I guess one could do something similar for just removing red, green or blue from the image using GIMP, but for the moment with just grayscale it would be already a step.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8098#issuecomment-832849033
Energy Efficiency,green,green,"To separate those we have now, a simple way is to use this add-on: https://addons.mozilla.org/en-US/firefox/addon/grayscale-browsing/. It will show https://root.cern.ch/doc/master/classTColor.html in grayscale mode. ![image](https://user-images.githubusercontent.com/10653970/117177407-47d76280-add1-11eb-9081-9bac9d4b4bd5.png). You can immediately see that the color scale in rainbow is not continuous, which is then misleading for colour-blinded in a 2D plot (not so much in a 3D surf like this one). kCMYK is also not great because it's dark, then lighter, then half-dark again. Others like kAquamarine have almost no contrast, it would be almost impossible to see sth there. So that would be a quick way to separate them. The idea is that the grayscale should be as proportional as possible, and monotonously increasing or decreasing. Unless it is symmetrical, then it is fine to have white in the borders and black in the centre (for example for example an axis that goes between -40 degrees and + 40 degrees, the 0 has a meaning). I guess one could do something similar for just removing red, green or blue from the image using GIMP, but for the moment with just grayscale it would be already a step.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8098#issuecomment-832849033
Usability,simpl,simple,"To separate those we have now, a simple way is to use this add-on: https://addons.mozilla.org/en-US/firefox/addon/grayscale-browsing/. It will show https://root.cern.ch/doc/master/classTColor.html in grayscale mode. ![image](https://user-images.githubusercontent.com/10653970/117177407-47d76280-add1-11eb-9081-9bac9d4b4bd5.png). You can immediately see that the color scale in rainbow is not continuous, which is then misleading for colour-blinded in a 2D plot (not so much in a 3D surf like this one). kCMYK is also not great because it's dark, then lighter, then half-dark again. Others like kAquamarine have almost no contrast, it would be almost impossible to see sth there. So that would be a quick way to separate them. The idea is that the grayscale should be as proportional as possible, and monotonously increasing or decreasing. Unless it is symmetrical, then it is fine to have white in the borders and black in the centre (for example for example an axis that goes between -40 degrees and + 40 degrees, the 0 has a meaning). I guess one could do something similar for just removing red, green or blue from the image using GIMP, but for the moment with just grayscale it would be already a step.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8098#issuecomment-832849033
Availability,down,downloads,"Concerning the ScientificColourMaps, more than having 'all of them', it would be useful to have them in a 'classified manner', clearly identified in the TColor documentation. Or maybe have one of each type. - Centric value type (only use when symmetric bin contents) + ""Inverted variant""; - Sequential type (usual case) + ""Inverted variant""; - Discrete variants; Here the full description: https://www.nature.com/articles/s41467-020-19160-7/figures/6. Another option I was thinking was that one could follow the approach of ""Themes"" used in many programs to define their color set. If a user downloads some themes from ScientificColourMaps and puts them in $HOME/.config/root/color-palettes/. then gStyle->SetPalette(""batlow"") would automatically load that one, if existing, using something like the script I posted above. This would make it pretty flexible.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8098#issuecomment-832859001
Modifiability,config,config,"Concerning the ScientificColourMaps, more than having 'all of them', it would be useful to have them in a 'classified manner', clearly identified in the TColor documentation. Or maybe have one of each type. - Centric value type (only use when symmetric bin contents) + ""Inverted variant""; - Sequential type (usual case) + ""Inverted variant""; - Discrete variants; Here the full description: https://www.nature.com/articles/s41467-020-19160-7/figures/6. Another option I was thinking was that one could follow the approach of ""Themes"" used in many programs to define their color set. If a user downloads some themes from ScientificColourMaps and puts them in $HOME/.config/root/color-palettes/. then gStyle->SetPalette(""batlow"") would automatically load that one, if existing, using something like the script I posted above. This would make it pretty flexible.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8098#issuecomment-832859001
Performance,load,load,"Concerning the ScientificColourMaps, more than having 'all of them', it would be useful to have them in a 'classified manner', clearly identified in the TColor documentation. Or maybe have one of each type. - Centric value type (only use when symmetric bin contents) + ""Inverted variant""; - Sequential type (usual case) + ""Inverted variant""; - Discrete variants; Here the full description: https://www.nature.com/articles/s41467-020-19160-7/figures/6. Another option I was thinking was that one could follow the approach of ""Themes"" used in many programs to define their color set. If a user downloads some themes from ScientificColourMaps and puts them in $HOME/.config/root/color-palettes/. then gStyle->SetPalette(""batlow"") would automatically load that one, if existing, using something like the script I posted above. This would make it pretty flexible.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8098#issuecomment-832859001
Usability,clear,clearly,"Concerning the ScientificColourMaps, more than having 'all of them', it would be useful to have them in a 'classified manner', clearly identified in the TColor documentation. Or maybe have one of each type. - Centric value type (only use when symmetric bin contents) + ""Inverted variant""; - Sequential type (usual case) + ""Inverted variant""; - Discrete variants; Here the full description: https://www.nature.com/articles/s41467-020-19160-7/figures/6. Another option I was thinking was that one could follow the approach of ""Themes"" used in many programs to define their color set. If a user downloads some themes from ScientificColourMaps and puts them in $HOME/.config/root/color-palettes/. then gStyle->SetPalette(""batlow"") would automatically load that one, if existing, using something like the script I posted above. This would make it pretty flexible.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8098#issuecomment-832859001
Availability,down,download,"This example would need to be modified before being put in tutorials:. 1. It should be formatted the proper way. See for instance [this one](https://github.com/root-project/root/blob/master/tutorials/graphics/arrows.C). The header should be formatted that way with a proper author name at the end.; 2. The description of the macro should be more than just a brief. May be some explanation about the site it refers to would help. In particular the download link should be to ScientificColourMaps7.zip I guess.; 3. You are using a TTree do read the .txt file. Why not, but that might be a bit ""too much"" just to read an ascii file of 3 columns. A standard C/C++ ASCII file reading is enough.; 4. The files have already 255 colors. So you do not need CreateGradientColorTable to interpolate the colors simply build the palette with the colors you read.; 5. Yes a static function in TColor would be also a possibiblity but the same comments apply.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8098#issuecomment-968998294
Usability,simpl,simply,"This example would need to be modified before being put in tutorials:. 1. It should be formatted the proper way. See for instance [this one](https://github.com/root-project/root/blob/master/tutorials/graphics/arrows.C). The header should be formatted that way with a proper author name at the end.; 2. The description of the macro should be more than just a brief. May be some explanation about the site it refers to would help. In particular the download link should be to ScientificColourMaps7.zip I guess.; 3. You are using a TTree do read the .txt file. Why not, but that might be a bit ""too much"" just to read an ascii file of 3 columns. A standard C/C++ ASCII file reading is enough.; 4. The files have already 255 colors. So you do not need CreateGradientColorTable to interpolate the colors simply build the palette with the colors you read.; 5. Yes a static function in TColor would be also a possibiblity but the same comments apply.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8098#issuecomment-968998294
Availability,avail,available,"Hi @ynikitenko, thanks for the request! There are several reasons for not supporting PyPy. PyROOT, which is building on top of cppyy, is very deeply connected to the CPython implementation of CPyCppyy. Just like the CPython version of cppyy, PyROOT consists of a Python module and a compiled CPython extension (`libROOTPythonization`). And you can't use CPython extensions in PyPy. So to support PyPy, we would have to rewrite [all this code](https://github.com/root-project/root/tree/master/bindings/pyroot/pythonizations/src), and work closely with the cppyy team to make sure it's PyPy implementation also provides the interfaces that PyROOT expects. That would be a *huge* amount of work with no usecase to justify it. And there are so many alternative of fast analysis frameworks that people are trying out right now: RDataFrame, NumPy, numba, awkward arrays, etc. And let's not forget that pypy has it's limitations! It only supports a restricted subset of Python, and it would require large efforts to port PyROOT to this. One final point: the future of PyPy development is not very clear. Right now, they don't support Python 3.11 yet, for example. Builds are only available for [Python 3.9 and Python 3.10](https://www.pypy.org/download_advanced.html). So investing in PyPy compatibility is also risky because of that. Imagine we would spend half a year trying to support it, and then PyPy would not be maintained anymore :(. I'll therefore close this issue as ""not planned"". tldr; the HEP community is gravitation towards other C++ native of jit-based Python packages to speed up analysis, and at this point investing in pypy is not worth it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8110#issuecomment-2148504771
Integrability,interface,interfaces,"Hi @ynikitenko, thanks for the request! There are several reasons for not supporting PyPy. PyROOT, which is building on top of cppyy, is very deeply connected to the CPython implementation of CPyCppyy. Just like the CPython version of cppyy, PyROOT consists of a Python module and a compiled CPython extension (`libROOTPythonization`). And you can't use CPython extensions in PyPy. So to support PyPy, we would have to rewrite [all this code](https://github.com/root-project/root/tree/master/bindings/pyroot/pythonizations/src), and work closely with the cppyy team to make sure it's PyPy implementation also provides the interfaces that PyROOT expects. That would be a *huge* amount of work with no usecase to justify it. And there are so many alternative of fast analysis frameworks that people are trying out right now: RDataFrame, NumPy, numba, awkward arrays, etc. And let's not forget that pypy has it's limitations! It only supports a restricted subset of Python, and it would require large efforts to port PyROOT to this. One final point: the future of PyPy development is not very clear. Right now, they don't support Python 3.11 yet, for example. Builds are only available for [Python 3.9 and Python 3.10](https://www.pypy.org/download_advanced.html). So investing in PyPy compatibility is also risky because of that. Imagine we would spend half a year trying to support it, and then PyPy would not be maintained anymore :(. I'll therefore close this issue as ""not planned"". tldr; the HEP community is gravitation towards other C++ native of jit-based Python packages to speed up analysis, and at this point investing in pypy is not worth it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8110#issuecomment-2148504771
Modifiability,rewrite,rewrite,"Hi @ynikitenko, thanks for the request! There are several reasons for not supporting PyPy. PyROOT, which is building on top of cppyy, is very deeply connected to the CPython implementation of CPyCppyy. Just like the CPython version of cppyy, PyROOT consists of a Python module and a compiled CPython extension (`libROOTPythonization`). And you can't use CPython extensions in PyPy. So to support PyPy, we would have to rewrite [all this code](https://github.com/root-project/root/tree/master/bindings/pyroot/pythonizations/src), and work closely with the cppyy team to make sure it's PyPy implementation also provides the interfaces that PyROOT expects. That would be a *huge* amount of work with no usecase to justify it. And there are so many alternative of fast analysis frameworks that people are trying out right now: RDataFrame, NumPy, numba, awkward arrays, etc. And let's not forget that pypy has it's limitations! It only supports a restricted subset of Python, and it would require large efforts to port PyROOT to this. One final point: the future of PyPy development is not very clear. Right now, they don't support Python 3.11 yet, for example. Builds are only available for [Python 3.9 and Python 3.10](https://www.pypy.org/download_advanced.html). So investing in PyPy compatibility is also risky because of that. Imagine we would spend half a year trying to support it, and then PyPy would not be maintained anymore :(. I'll therefore close this issue as ""not planned"". tldr; the HEP community is gravitation towards other C++ native of jit-based Python packages to speed up analysis, and at this point investing in pypy is not worth it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8110#issuecomment-2148504771
Safety,risk,risky,"Hi @ynikitenko, thanks for the request! There are several reasons for not supporting PyPy. PyROOT, which is building on top of cppyy, is very deeply connected to the CPython implementation of CPyCppyy. Just like the CPython version of cppyy, PyROOT consists of a Python module and a compiled CPython extension (`libROOTPythonization`). And you can't use CPython extensions in PyPy. So to support PyPy, we would have to rewrite [all this code](https://github.com/root-project/root/tree/master/bindings/pyroot/pythonizations/src), and work closely with the cppyy team to make sure it's PyPy implementation also provides the interfaces that PyROOT expects. That would be a *huge* amount of work with no usecase to justify it. And there are so many alternative of fast analysis frameworks that people are trying out right now: RDataFrame, NumPy, numba, awkward arrays, etc. And let's not forget that pypy has it's limitations! It only supports a restricted subset of Python, and it would require large efforts to port PyROOT to this. One final point: the future of PyPy development is not very clear. Right now, they don't support Python 3.11 yet, for example. Builds are only available for [Python 3.9 and Python 3.10](https://www.pypy.org/download_advanced.html). So investing in PyPy compatibility is also risky because of that. Imagine we would spend half a year trying to support it, and then PyPy would not be maintained anymore :(. I'll therefore close this issue as ""not planned"". tldr; the HEP community is gravitation towards other C++ native of jit-based Python packages to speed up analysis, and at this point investing in pypy is not worth it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8110#issuecomment-2148504771
Usability,clear,clear,"Hi @ynikitenko, thanks for the request! There are several reasons for not supporting PyPy. PyROOT, which is building on top of cppyy, is very deeply connected to the CPython implementation of CPyCppyy. Just like the CPython version of cppyy, PyROOT consists of a Python module and a compiled CPython extension (`libROOTPythonization`). And you can't use CPython extensions in PyPy. So to support PyPy, we would have to rewrite [all this code](https://github.com/root-project/root/tree/master/bindings/pyroot/pythonizations/src), and work closely with the cppyy team to make sure it's PyPy implementation also provides the interfaces that PyROOT expects. That would be a *huge* amount of work with no usecase to justify it. And there are so many alternative of fast analysis frameworks that people are trying out right now: RDataFrame, NumPy, numba, awkward arrays, etc. And let's not forget that pypy has it's limitations! It only supports a restricted subset of Python, and it would require large efforts to port PyROOT to this. One final point: the future of PyPy development is not very clear. Right now, they don't support Python 3.11 yet, for example. Builds are only available for [Python 3.9 and Python 3.10](https://www.pypy.org/download_advanced.html). So investing in PyPy compatibility is also risky because of that. Imagine we would spend half a year trying to support it, and then PyPy would not be maintained anymore :(. I'll therefore close this issue as ""not planned"". tldr; the HEP community is gravitation towards other C++ native of jit-based Python packages to speed up analysis, and at this point investing in pypy is not worth it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8110#issuecomment-2148504771
Modifiability,inherit,inherit,"Thanks for the comment! I agree that it's not clear how meaningful `weightError` is for RooDataSet, but still the only two classes that derive from RooAbsData are RooDataHist and RooDataSet. Both of them reimplement `weightError` in a non-trivial way. Or are you thinking about some user classes that might inherit from `RooAbsData`? In that case they would not compile because not all purely virtual functions are implemented. But I'd argue that this a good thing, because then the user is made aware that `weightError` should be implemented with a dummy value. Actually, it can even be dangerous that we choose this dummy value ourselves (why zero and not `nan` for example?). I think purely virtual functions are safer than ""dummy functions"", and they are also more self-documenting because we know that every inheriting class will be overloading this function.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8137#issuecomment-838795380
Safety,safe,safer,"Thanks for the comment! I agree that it's not clear how meaningful `weightError` is for RooDataSet, but still the only two classes that derive from RooAbsData are RooDataHist and RooDataSet. Both of them reimplement `weightError` in a non-trivial way. Or are you thinking about some user classes that might inherit from `RooAbsData`? In that case they would not compile because not all purely virtual functions are implemented. But I'd argue that this a good thing, because then the user is made aware that `weightError` should be implemented with a dummy value. Actually, it can even be dangerous that we choose this dummy value ourselves (why zero and not `nan` for example?). I think purely virtual functions are safer than ""dummy functions"", and they are also more self-documenting because we know that every inheriting class will be overloading this function.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8137#issuecomment-838795380
Usability,clear,clear,"Thanks for the comment! I agree that it's not clear how meaningful `weightError` is for RooDataSet, but still the only two classes that derive from RooAbsData are RooDataHist and RooDataSet. Both of them reimplement `weightError` in a non-trivial way. Or are you thinking about some user classes that might inherit from `RooAbsData`? In that case they would not compile because not all purely virtual functions are implemented. But I'd argue that this a good thing, because then the user is made aware that `weightError` should be implemented with a dummy value. Actually, it can even be dangerous that we choose this dummy value ourselves (why zero and not `nan` for example?). I think purely virtual functions are safer than ""dummy functions"", and they are also more self-documenting because we know that every inheriting class will be overloading this function.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8137#issuecomment-838795380
Usability,feedback,feedback,@lmoneta any feedback on the PR ?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8143#issuecomment-946555747
Deployability,release,releases,"Dear @etejedor ; I have no local built of ROOT - it is too heavy for me - I am always rely on LCG releases or nightlies. ; The problem appeared not earlier than a week ago. There was a few days break in tests of my project, ; and restarting tests after this pause, couple of days ago, I've observed this behaviour.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8152#issuecomment-839744359
Testability,test,tests,"Dear @etejedor ; I have no local built of ROOT - it is too heavy for me - I am always rely on LCG releases or nightlies. ; The problem appeared not earlier than a week ago. There was a few days break in tests of my project, ; and restarting tests after this pause, couple of days ago, I've observed this behaviour.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8152#issuecomment-839744359
Usability,pause,pause,"Dear @etejedor ; I have no local built of ROOT - it is too heavy for me - I am always rely on LCG releases or nightlies. ; The problem appeared not earlier than a week ago. There was a few days break in tests of my project, ; and restarting tests after this pause, couple of days ago, I've observed this behaviour.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8152#issuecomment-839744359
Usability,learn,learned,"> @hahnjo thanks a lot, I wanted to ask if TBB_USE_CAPTURED_EXCEPTION is limited to particular version of TBB?. My understanding is that `TBB_USE_CAPTURED_EXCEPTION` is the fallback if TBB cannot determine that it can properly forward exceptions from the workers. In my setup, this happens with the packaged version TBB 2018 on CentOS 8 when compiling with Clang (because that advertises compatibility with GCC 4.2.1 and only 2019.U4 learned to ignore this).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8169#issuecomment-842963722
Security,access,access,"Hi Will!. We try to bring the behavior of the `RooAbsCollection`s closer to the STL containers like [std::vector](https://en.cppreference.com/w/cpp/container/vector). This means that `operator[]` should simply access an element as quickly as possible without any bounds checking for no overhead. That's why it changed from 6.24 to master. Only the `at()` member should do the bounds checking. I still have some work to do here because its behavior is inconsistent with `std::vector` (it returns a `nullptr` if the bounds check fails). So bringing the element-accessing behavior closer to Python behavior would unfortunately bring us further away from the STL behavior, and I would advise against the suggested change. However, I would agree that on the pyROOT side, the `RooAbsCollections` should behave more pythonic and we should absolutely implement a pythonization to support element access from the back with negative indices!. Is that a fair compromise? Did you intend to use the negative indices in C++?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8174#issuecomment-842217657
Usability,simpl,simply,"Hi Will!. We try to bring the behavior of the `RooAbsCollection`s closer to the STL containers like [std::vector](https://en.cppreference.com/w/cpp/container/vector). This means that `operator[]` should simply access an element as quickly as possible without any bounds checking for no overhead. That's why it changed from 6.24 to master. Only the `at()` member should do the bounds checking. I still have some work to do here because its behavior is inconsistent with `std::vector` (it returns a `nullptr` if the bounds check fails). So bringing the element-accessing behavior closer to Python behavior would unfortunately bring us further away from the STL behavior, and I would advise against the suggested change. However, I would agree that on the pyROOT side, the `RooAbsCollections` should behave more pythonic and we should absolutely implement a pythonization to support element access from the back with negative indices!. Is that a fair compromise? Did you intend to use the negative indices in C++?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8174#issuecomment-842217657
Safety,avoid,avoid,"> I take it from the warnings that I might have to add the other FindObject method (that accepts a TObject pointer) to satisfy the builds? Please confirm and I can do this. Exactly. Something like `auto ptr = dynamic_cast<const RooAbsArg*>; return ptr ? find(*ptr) : nullptr;` should do it. Could you include a one-line doxygen-readable comment (`///`) to avoid having two undocumented functions? Also note that `find(RooAbsArg&)` will find objects with the same name, not necessarily with the same pointer. You should decide with @guitargeek if that's actually desired when called from the Python side. In a second sentence, you should document whether that function will find objects with the same name (= equivalent objects as far as RooFit is concerned) or if it should only find the exact same object.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8177#issuecomment-841335386
Usability,undo,undocumented,"> I take it from the warnings that I might have to add the other FindObject method (that accepts a TObject pointer) to satisfy the builds? Please confirm and I can do this. Exactly. Something like `auto ptr = dynamic_cast<const RooAbsArg*>; return ptr ? find(*ptr) : nullptr;` should do it. Could you include a one-line doxygen-readable comment (`///`) to avoid having two undocumented functions? Also note that `find(RooAbsArg&)` will find objects with the same name, not necessarily with the same pointer. You should decide with @guitargeek if that's actually desired when called from the Python side. In a second sentence, you should document whether that function will find objects with the same name (= equivalent objects as far as RooFit is concerned) or if it should only find the exact same object.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8177#issuecomment-841335386
Safety,avoid,avoid,"> > I take it from the warnings that I might have to add the other FindObject method (that accepts a TObject pointer) to satisfy the builds? Please confirm and I can do this.; > ; > Exactly. Something like `auto ptr = dynamic_cast<const RooAbsArg*>; return ptr ? find(*ptr) : nullptr;` should do it.; > ; > Could you include a one-line doxygen-readable comment (`///`) to avoid having two undocumented functions? Also note that `find(RooAbsArg&)` will find objects with the same name, not necessarily with the same pointer. You should decide with @guitargeek if that's actually desired when called from the Python side. In a second sentence, you should document whether that function will find objects with the same name (= equivalent objects as far as RooFit is concerned) or if it should only find the exact same object. Indeed I thought about having `auto arg = dynamic_cast<const RooAbsArg*>(obj); return (arg && containsInstance(*arg)) ? obj : nullptr;` but given the 'find' method matches by name I think for consistency the FindObject should behave the same for these classes, unless there is some additional benefit to FindObject(obj) returning obj??",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8177#issuecomment-841340893
Usability,undo,undocumented,"> > I take it from the warnings that I might have to add the other FindObject method (that accepts a TObject pointer) to satisfy the builds? Please confirm and I can do this.; > ; > Exactly. Something like `auto ptr = dynamic_cast<const RooAbsArg*>; return ptr ? find(*ptr) : nullptr;` should do it.; > ; > Could you include a one-line doxygen-readable comment (`///`) to avoid having two undocumented functions? Also note that `find(RooAbsArg&)` will find objects with the same name, not necessarily with the same pointer. You should decide with @guitargeek if that's actually desired when called from the Python side. In a second sentence, you should document whether that function will find objects with the same name (= equivalent objects as far as RooFit is concerned) or if it should only find the exact same object. Indeed I thought about having `auto arg = dynamic_cast<const RooAbsArg*>(obj); return (arg && containsInstance(*arg)) ? obj : nullptr;` but given the 'find' method matches by name I think for consistency the FindObject should behave the same for these classes, unless there is some additional benefit to FindObject(obj) returning obj??",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8177#issuecomment-841340893
Usability,guid,guide,This looks like an inconsistency in your build. I don't know how to reproduce this. If you have a step-by-step guide on how to end up with this breakage please let us know and re-open this ticket!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8178#issuecomment-848621017
Usability,simpl,simple,"I convert into draft, while simple member name change does not work.; Also increase of class version does not help.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8181#issuecomment-842273434
Usability,feedback,feedback,"## DeepCode failed to analyze this pull request; Something went wrong despite trying multiple times, sorry about that.; Please comment this pull request with ""Retry DeepCode"" to manually retry, or [contact us](https://www.deepcode.ai/feedback?select=4&utm_source=gh_review) so that a human can look into the issue.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8192#issuecomment-842960413
Usability,feedback,feedback,"The current idea is the following: . 1. For algorithms using only pdf: ; ```; TUnuranContDist dist(pdf); ; ```; 2. For algorithm using pdf + its derivative: ; ```; TUnuranContDist dist(pdf, &dpdf); ; ```; 3. For algorithms using pdf + derivative + pdf: ; ```; TUnuranContDist dist(pdf, &dpdf); ; dist.SetCdf(cdf);; ```; 4. For algorithms using only the cdf: ; ```; TUnuranContDist dist(); ; dist.SetCdf(cdf);; ```. I agree cases 3 and 4 are not very nice, also in case 4 one is forced to have the input functions cloned. ; I would prefer to not change the existing constructor for not breaking the backward compatibility. ; What about adding a constructor like this one: ; ```; TUnuranContDist dist(const ROOT::Math::IGenFunction * pdf, ; ROOT::Math::IGenFunction * dpdf, ; ROOT::Math::GenFunction * cpdf, bool isLogPdf = false, bool copyFunc = false); ; ```; and similar for the TF1 case ? . Thank you for the feedback !",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8196#issuecomment-849462802
Integrability,wrap,wrapping,"A possible implementation, that could go in some ROOT::Math classes:. ```; #include <bitset>; #include <cmath>; #include <array>; #include <set>; #include <iostream>. using std::bitset;; using std::array;; using std::vector;; using std::set;; using std::cout;; using std::endl;. /**; * @brief Generation of pseudo-random bits using a linear feedback shift register (LFSR), until a register value is repeated (or maxPeriod is reached); * @tparam k the length of the LFSR, or the order of the monic polynomial PRBS-k (last exponent); * @tparam nTaps the number of taps; * @param start the start value of the LFSR; * @param taps the taps that will be XOR-ed to calculate the new bit. They are the exponents of the monic polynomial. Ordering is unimportant.; * @param wrapping if true, allow wrapping until maxPeriod or start is reached; * @param verbose if true, print the lfsr and new bit on each step; * @note Shift direction of the register is to the left <<, the newBit is set at bit position 0 (right); * @return the array of pseudo random bits, or an empty array if input was incorrect; * @see https://en.wikipedia.org/wiki/Monic_polynomial; * @see https://en.wikipedia.org/wiki/Linear-feedback_shift_register; * @see https://en.wikipedia.org/wiki/Pseudorandom_binary_sequence; */; template <size_t k, size_t nTaps>; vector<bool>; LFSR(const bitset<k> start, const array<uint16_t, nTaps> taps, const bool wrapping = false, const bool verbose = false); {; vector<bool> result;; //Sanity-checks; if(taps.size()<2); {; cerr << ""At least two taps are needed"" << endl;; return result;; }; for(auto tap : taps); {; if(tap > k); {; cerr << ""Out of range tap "" << tap << endl;; return result;; }; }; if(start.none()); {; cerr << ""A non-zero start value is needed"" << endl;; return result;; }. const uint32_t maxPeriod = pow(2,k) - 1;; result.reserve(maxPeriod);. set<uint32_t> lfsrHistory;; bitset<k> lfsr(start);; uint32_t i = 0;; do; {; // XOR of all the tapped bits. We use -1 because an exponent N in t",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8199#issuecomment-843369054
Usability,feedback,feedback,"A possible implementation, that could go in some ROOT::Math classes:. ```; #include <bitset>; #include <cmath>; #include <array>; #include <set>; #include <iostream>. using std::bitset;; using std::array;; using std::vector;; using std::set;; using std::cout;; using std::endl;. /**; * @brief Generation of pseudo-random bits using a linear feedback shift register (LFSR), until a register value is repeated (or maxPeriod is reached); * @tparam k the length of the LFSR, or the order of the monic polynomial PRBS-k (last exponent); * @tparam nTaps the number of taps; * @param start the start value of the LFSR; * @param taps the taps that will be XOR-ed to calculate the new bit. They are the exponents of the monic polynomial. Ordering is unimportant.; * @param wrapping if true, allow wrapping until maxPeriod or start is reached; * @param verbose if true, print the lfsr and new bit on each step; * @note Shift direction of the register is to the left <<, the newBit is set at bit position 0 (right); * @return the array of pseudo random bits, or an empty array if input was incorrect; * @see https://en.wikipedia.org/wiki/Monic_polynomial; * @see https://en.wikipedia.org/wiki/Linear-feedback_shift_register; * @see https://en.wikipedia.org/wiki/Pseudorandom_binary_sequence; */; template <size_t k, size_t nTaps>; vector<bool>; LFSR(const bitset<k> start, const array<uint16_t, nTaps> taps, const bool wrapping = false, const bool verbose = false); {; vector<bool> result;; //Sanity-checks; if(taps.size()<2); {; cerr << ""At least two taps are needed"" << endl;; return result;; }; for(auto tap : taps); {; if(tap > k); {; cerr << ""Out of range tap "" << tap << endl;; return result;; }; }; if(start.none()); {; cerr << ""A non-zero start value is needed"" << endl;; return result;; }. const uint32_t maxPeriod = pow(2,k) - 1;; result.reserve(maxPeriod);. set<uint32_t> lfsrHistory;; bitset<k> lfsr(start);; uint32_t i = 0;; do; {; // XOR of all the tapped bits. We use -1 because an exponent N in t",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8199#issuecomment-843369054
Integrability,interface,interface,uild failed on ROOT-fedora31/noimt.; Running on root-fedora-31-2.cern.ch:/home/sftnight/build/workspace/root-pullrequests-build; [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118088/console).; ### Failing tests:; - [projectroot.roottest.cling.specialobj.roottest_cling_specialobj_runf02](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118088/testReport/projectroot.roottest.cling/specialobj/roottest_cling_specialobj_runf02/); - [projectroot.roottest.root.meta.roottest_root_meta_runnamespace_auto](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118088/testReport/projectroot.roottest.root/meta/roottest_root_meta_runnamespace_auto/); - [projectroot.roottest.root.io.clones.roottest_root_io_clones_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118088/testReport/projectroot.roottest.root.io/clones/roottest_root_io_clones_make/); - [projectroot.roottest.root.io.interface.roottest_root_io_interface_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118088/testReport/projectroot.roottest.root.io/interface/roottest_root_io_interface_make/); - [projectroot.roottest.root.meta.ROOT-7462.roottest_root_meta_ROOT_7462_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118088/testReport/projectroot.roottest.root.meta/ROOT-7462/roottest_root_meta_ROOT_7462_make/); - [projectroot.roottest.root.meta.tclass.roottest_root_meta_tclass_execDuplicate](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118088/testReport/projectroot.roottest.root.meta/tclass/roottest_root_meta_tclass_execDuplicate/); - [projectroot.roottest.root.selector.simple.roottest_root_selector_simple_runtestLoadingSelector](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118088/testReport/projectroot.roottest.root.selector/simple/roottest_root_selector_simple_runtestLoadingSelector/); - [proj,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8204#issuecomment-844244254
Testability,test,tests,Build failed on ROOT-fedora31/noimt.; Running on root-fedora-31-2.cern.ch:/home/sftnight/build/workspace/root-pullrequests-build; [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118088/console).; ### Failing tests:; - [projectroot.roottest.cling.specialobj.roottest_cling_specialobj_runf02](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118088/testReport/projectroot.roottest.cling/specialobj/roottest_cling_specialobj_runf02/); - [projectroot.roottest.root.meta.roottest_root_meta_runnamespace_auto](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118088/testReport/projectroot.roottest.root/meta/roottest_root_meta_runnamespace_auto/); - [projectroot.roottest.root.io.clones.roottest_root_io_clones_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118088/testReport/projectroot.roottest.root.io/clones/roottest_root_io_clones_make/); - [projectroot.roottest.root.io.interface.roottest_root_io_interface_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118088/testReport/projectroot.roottest.root.io/interface/roottest_root_io_interface_make/); - [projectroot.roottest.root.meta.ROOT-7462.roottest_root_meta_ROOT_7462_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118088/testReport/projectroot.roottest.root.meta/ROOT-7462/roottest_root_meta_ROOT_7462_make/); - [projectroot.roottest.root.meta.tclass.roottest_root_meta_tclass_execDuplicate](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118088/testReport/projectroot.roottest.root.meta/tclass/roottest_root_meta_tclass_execDuplicate/); - [projectroot.roottest.root.selector.simple.roottest_root_selector_simple_runtestLoadingSelector](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118088/testReport/projectroot.roottest.root.selector/simple/roottest_root_selector_simple_runtestLoadingSelector/); - [proj,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8204#issuecomment-844244254
Usability,simpl,simple,# Failing tests:; - [projectroot.roottest.cling.specialobj.roottest_cling_specialobj_runf02](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118088/testReport/projectroot.roottest.cling/specialobj/roottest_cling_specialobj_runf02/); - [projectroot.roottest.root.meta.roottest_root_meta_runnamespace_auto](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118088/testReport/projectroot.roottest.root/meta/roottest_root_meta_runnamespace_auto/); - [projectroot.roottest.root.io.clones.roottest_root_io_clones_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118088/testReport/projectroot.roottest.root.io/clones/roottest_root_io_clones_make/); - [projectroot.roottest.root.io.interface.roottest_root_io_interface_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118088/testReport/projectroot.roottest.root.io/interface/roottest_root_io_interface_make/); - [projectroot.roottest.root.meta.ROOT-7462.roottest_root_meta_ROOT_7462_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118088/testReport/projectroot.roottest.root.meta/ROOT-7462/roottest_root_meta_ROOT_7462_make/); - [projectroot.roottest.root.meta.tclass.roottest_root_meta_tclass_execDuplicate](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118088/testReport/projectroot.roottest.root.meta/tclass/roottest_root_meta_tclass_execDuplicate/); - [projectroot.roottest.root.selector.simple.roottest_root_selector_simple_runtestLoadingSelector](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118088/testReport/projectroot.roottest.root.selector/simple/roottest_root_selector_simple_runtestLoadingSelector/); - [projectroot.roottest.root.treeformula.stl.roottest_root_treeformula_stl_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118088/testReport/projectroot.roottest.root.treeformula/stl/roottest_root_treeformula_stl_make/),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8204#issuecomment-844244254
Integrability,interface,interface,Build failed on ROOT-fedora30/cxx14.; Running on root-fedora30-2.cern.ch:/home/sftnight/build/workspace/root-pullrequests-build; [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118087/console).; ### Failing tests:; - [projectroot.roottest.cling.specialobj.roottest_cling_specialobj_runf02](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118087/testReport/projectroot.roottest.cling/specialobj/roottest_cling_specialobj_runf02/); - [projectroot.roottest.root.meta.roottest_root_meta_runnamespace_auto](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118087/testReport/projectroot.roottest.root/meta/roottest_root_meta_runnamespace_auto/); - [projectroot.roottest.root.io.clones.roottest_root_io_clones_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118087/testReport/projectroot.roottest.root.io/clones/roottest_root_io_clones_make/); - [projectroot.roottest.root.io.interface.roottest_root_io_interface_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118087/testReport/projectroot.roottest.root.io/interface/roottest_root_io_interface_make/); - [projectroot.roottest.root.meta.ROOT-7462.roottest_root_meta_ROOT_7462_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118087/testReport/projectroot.roottest.root.meta/ROOT-7462/roottest_root_meta_ROOT_7462_make/); - [projectroot.roottest.root.meta.tclass.roottest_root_meta_tclass_execDuplicate](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118087/testReport/projectroot.roottest.root.meta/tclass/roottest_root_meta_tclass_execDuplicate/); - [projectroot.roottest.root.selector.simple.roottest_root_selector_simple_runtestLoadingSelector](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118087/testReport/projectroot.roottest.root.selector/simple/roottest_root_selector_simple_runtestLoadingSelector/); - [proj,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8204#issuecomment-844250497
Testability,test,tests,Build failed on ROOT-fedora30/cxx14.; Running on root-fedora30-2.cern.ch:/home/sftnight/build/workspace/root-pullrequests-build; [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118087/console).; ### Failing tests:; - [projectroot.roottest.cling.specialobj.roottest_cling_specialobj_runf02](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118087/testReport/projectroot.roottest.cling/specialobj/roottest_cling_specialobj_runf02/); - [projectroot.roottest.root.meta.roottest_root_meta_runnamespace_auto](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118087/testReport/projectroot.roottest.root/meta/roottest_root_meta_runnamespace_auto/); - [projectroot.roottest.root.io.clones.roottest_root_io_clones_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118087/testReport/projectroot.roottest.root.io/clones/roottest_root_io_clones_make/); - [projectroot.roottest.root.io.interface.roottest_root_io_interface_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118087/testReport/projectroot.roottest.root.io/interface/roottest_root_io_interface_make/); - [projectroot.roottest.root.meta.ROOT-7462.roottest_root_meta_ROOT_7462_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118087/testReport/projectroot.roottest.root.meta/ROOT-7462/roottest_root_meta_ROOT_7462_make/); - [projectroot.roottest.root.meta.tclass.roottest_root_meta_tclass_execDuplicate](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118087/testReport/projectroot.roottest.root.meta/tclass/roottest_root_meta_tclass_execDuplicate/); - [projectroot.roottest.root.selector.simple.roottest_root_selector_simple_runtestLoadingSelector](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118087/testReport/projectroot.roottest.root.selector/simple/roottest_root_selector_simple_runtestLoadingSelector/); - [proje,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8204#issuecomment-844250497
Usability,simpl,simple,# Failing tests:; - [projectroot.roottest.cling.specialobj.roottest_cling_specialobj_runf02](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118087/testReport/projectroot.roottest.cling/specialobj/roottest_cling_specialobj_runf02/); - [projectroot.roottest.root.meta.roottest_root_meta_runnamespace_auto](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118087/testReport/projectroot.roottest.root/meta/roottest_root_meta_runnamespace_auto/); - [projectroot.roottest.root.io.clones.roottest_root_io_clones_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118087/testReport/projectroot.roottest.root.io/clones/roottest_root_io_clones_make/); - [projectroot.roottest.root.io.interface.roottest_root_io_interface_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118087/testReport/projectroot.roottest.root.io/interface/roottest_root_io_interface_make/); - [projectroot.roottest.root.meta.ROOT-7462.roottest_root_meta_ROOT_7462_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118087/testReport/projectroot.roottest.root.meta/ROOT-7462/roottest_root_meta_ROOT_7462_make/); - [projectroot.roottest.root.meta.tclass.roottest_root_meta_tclass_execDuplicate](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118087/testReport/projectroot.roottest.root.meta/tclass/roottest_root_meta_tclass_execDuplicate/); - [projectroot.roottest.root.selector.simple.roottest_root_selector_simple_runtestLoadingSelector](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118087/testReport/projectroot.roottest.root.selector/simple/roottest_root_selector_simple_runtestLoadingSelector/); - [projectroot.roottest.root.treeformula.stl.roottest_root_treeformula_stl_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118087/testReport/projectroot.roottest.root.treeformula/stl/roottest_root_treeformula_stl_make/),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8204#issuecomment-844250497
Integrability,interface,interface,roottest.cling.specialobj.roottest_cling_specialobj_runf02](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118086/testReport/projectroot.roottest.cling/specialobj/roottest_cling_specialobj_runf02/); - [projectroot.roottest.root.meta.roottest_root_meta_runnamespace_auto](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118086/testReport/projectroot.roottest.root/meta/roottest_root_meta_runnamespace_auto/); - [projectroot.roottest.root.io.clones.roottest_root_io_clones_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118086/testReport/projectroot.roottest.root.io/clones/roottest_root_io_clones_make/); - [projectroot.roottest.root.io.datamodelevolution.roottest_root_io_datamodelevolution_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118086/testReport/projectroot.roottest.root.io/datamodelevolution/roottest_root_io_datamodelevolution_make/); - [projectroot.roottest.root.io.interface.roottest_root_io_interface_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118086/testReport/projectroot.roottest.root.io/interface/roottest_root_io_interface_make/); - [projectroot.roottest.root.meta.ROOT-7462.roottest_root_meta_ROOT_7462_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118086/testReport/projectroot.roottest.root.meta/ROOT-7462/roottest_root_meta_ROOT_7462_make/); - [projectroot.roottest.root.meta.tclass.roottest_root_meta_tclass_execDuplicate](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118086/testReport/projectroot.roottest.root.meta/tclass/roottest_root_meta_tclass_execDuplicate/); - [projectroot.roottest.root.selector.simple.roottest_root_selector_simple_runtestLoadingSelector](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118086/testReport/projectroot.roottest.root.selector/simple/roottest_root_selector_simple_runtestLoadingSelector/); - [proj,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8204#issuecomment-844253147
Performance,perform,performance-,Build failed on ROOT-performance-centos8-multicore/default.; Running on olbdw-01.cern.ch:/data/sftnight/workspace/root-pullrequests-build; [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118086/console).; ### Failing tests:; - [projectroot.roottest.cling.specialobj.roottest_cling_specialobj_runf02](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118086/testReport/projectroot.roottest.cling/specialobj/roottest_cling_specialobj_runf02/); - [projectroot.roottest.root.meta.roottest_root_meta_runnamespace_auto](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118086/testReport/projectroot.roottest.root/meta/roottest_root_meta_runnamespace_auto/); - [projectroot.roottest.root.io.clones.roottest_root_io_clones_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118086/testReport/projectroot.roottest.root.io/clones/roottest_root_io_clones_make/); - [projectroot.roottest.root.io.datamodelevolution.roottest_root_io_datamodelevolution_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118086/testReport/projectroot.roottest.root.io/datamodelevolution/roottest_root_io_datamodelevolution_make/); - [projectroot.roottest.root.io.interface.roottest_root_io_interface_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118086/testReport/projectroot.roottest.root.io/interface/roottest_root_io_interface_make/); - [projectroot.roottest.root.meta.ROOT-7462.roottest_root_meta_ROOT_7462_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118086/testReport/projectroot.roottest.root.meta/ROOT-7462/roottest_root_meta_ROOT_7462_make/); - [projectroot.roottest.root.meta.tclass.roottest_root_meta_tclass_execDuplicate](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118086/testReport/projectroot.roottest.root.meta/tclass/roottest_root_meta_tclass_execDuplicate/); - [project,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8204#issuecomment-844253147
Testability,test,tests,Build failed on ROOT-performance-centos8-multicore/default.; Running on olbdw-01.cern.ch:/data/sftnight/workspace/root-pullrequests-build; [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118086/console).; ### Failing tests:; - [projectroot.roottest.cling.specialobj.roottest_cling_specialobj_runf02](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118086/testReport/projectroot.roottest.cling/specialobj/roottest_cling_specialobj_runf02/); - [projectroot.roottest.root.meta.roottest_root_meta_runnamespace_auto](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118086/testReport/projectroot.roottest.root/meta/roottest_root_meta_runnamespace_auto/); - [projectroot.roottest.root.io.clones.roottest_root_io_clones_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118086/testReport/projectroot.roottest.root.io/clones/roottest_root_io_clones_make/); - [projectroot.roottest.root.io.datamodelevolution.roottest_root_io_datamodelevolution_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118086/testReport/projectroot.roottest.root.io/datamodelevolution/roottest_root_io_datamodelevolution_make/); - [projectroot.roottest.root.io.interface.roottest_root_io_interface_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118086/testReport/projectroot.roottest.root.io/interface/roottest_root_io_interface_make/); - [projectroot.roottest.root.meta.ROOT-7462.roottest_root_meta_ROOT_7462_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118086/testReport/projectroot.roottest.root.meta/ROOT-7462/roottest_root_meta_ROOT_7462_make/); - [projectroot.roottest.root.meta.tclass.roottest_root_meta_tclass_execDuplicate](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118086/testReport/projectroot.roottest.root.meta/tclass/roottest_root_meta_tclass_execDuplicate/); - [project,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8204#issuecomment-844253147
Usability,simpl,simple,ttest.root.meta.roottest_root_meta_runnamespace_auto](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118086/testReport/projectroot.roottest.root/meta/roottest_root_meta_runnamespace_auto/); - [projectroot.roottest.root.io.clones.roottest_root_io_clones_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118086/testReport/projectroot.roottest.root.io/clones/roottest_root_io_clones_make/); - [projectroot.roottest.root.io.datamodelevolution.roottest_root_io_datamodelevolution_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118086/testReport/projectroot.roottest.root.io/datamodelevolution/roottest_root_io_datamodelevolution_make/); - [projectroot.roottest.root.io.interface.roottest_root_io_interface_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118086/testReport/projectroot.roottest.root.io/interface/roottest_root_io_interface_make/); - [projectroot.roottest.root.meta.ROOT-7462.roottest_root_meta_ROOT_7462_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118086/testReport/projectroot.roottest.root.meta/ROOT-7462/roottest_root_meta_ROOT_7462_make/); - [projectroot.roottest.root.meta.tclass.roottest_root_meta_tclass_execDuplicate](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118086/testReport/projectroot.roottest.root.meta/tclass/roottest_root_meta_tclass_execDuplicate/); - [projectroot.roottest.root.selector.simple.roottest_root_selector_simple_runtestLoadingSelector](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118086/testReport/projectroot.roottest.root.selector/simple/roottest_root_selector_simple_runtestLoadingSelector/); - [projectroot.roottest.root.treeformula.stl.roottest_root_treeformula_stl_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118086/testReport/projectroot.roottest.root.treeformula/stl/roottest_root_treeformula_stl_make/),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8204#issuecomment-844253147
Integrability,interface,interface,Build failed on ROOT-ubuntu16/nortcxxmod.; Running on sft-ubuntu-1604-1.cern.ch:/build/workspace/root-pullrequests-build; [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118089/console).; ### Failing tests:; - [projectroot.roottest.cling.specialobj.roottest_cling_specialobj_runf02](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118089/testReport/projectroot.roottest.cling/specialobj/roottest_cling_specialobj_runf02/); - [projectroot.roottest.root.meta.roottest_root_meta_runnamespace_auto](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118089/testReport/projectroot.roottest.root/meta/roottest_root_meta_runnamespace_auto/); - [projectroot.roottest.root.io.clones.roottest_root_io_clones_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118089/testReport/projectroot.roottest.root.io/clones/roottest_root_io_clones_make/); - [projectroot.roottest.root.io.interface.roottest_root_io_interface_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118089/testReport/projectroot.roottest.root.io/interface/roottest_root_io_interface_make/); - [projectroot.roottest.root.meta.ROOT-7462.roottest_root_meta_ROOT_7462_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118089/testReport/projectroot.roottest.root.meta/ROOT-7462/roottest_root_meta_ROOT_7462_make/); - [projectroot.roottest.root.meta.tclass.roottest_root_meta_tclass_execDuplicate](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118089/testReport/projectroot.roottest.root.meta/tclass/roottest_root_meta_tclass_execDuplicate/); - [projectroot.roottest.root.selector.simple.roottest_root_selector_simple_runtestLoadingSelector](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118089/testReport/projectroot.roottest.root.selector/simple/roottest_root_selector_simple_runtestLoadingSelector/); - [projectroot.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8204#issuecomment-844261645
Testability,test,tests,Build failed on ROOT-ubuntu16/nortcxxmod.; Running on sft-ubuntu-1604-1.cern.ch:/build/workspace/root-pullrequests-build; [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118089/console).; ### Failing tests:; - [projectroot.roottest.cling.specialobj.roottest_cling_specialobj_runf02](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118089/testReport/projectroot.roottest.cling/specialobj/roottest_cling_specialobj_runf02/); - [projectroot.roottest.root.meta.roottest_root_meta_runnamespace_auto](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118089/testReport/projectroot.roottest.root/meta/roottest_root_meta_runnamespace_auto/); - [projectroot.roottest.root.io.clones.roottest_root_io_clones_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118089/testReport/projectroot.roottest.root.io/clones/roottest_root_io_clones_make/); - [projectroot.roottest.root.io.interface.roottest_root_io_interface_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118089/testReport/projectroot.roottest.root.io/interface/roottest_root_io_interface_make/); - [projectroot.roottest.root.meta.ROOT-7462.roottest_root_meta_ROOT_7462_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118089/testReport/projectroot.roottest.root.meta/ROOT-7462/roottest_root_meta_ROOT_7462_make/); - [projectroot.roottest.root.meta.tclass.roottest_root_meta_tclass_execDuplicate](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118089/testReport/projectroot.roottest.root.meta/tclass/roottest_root_meta_tclass_execDuplicate/); - [projectroot.roottest.root.selector.simple.roottest_root_selector_simple_runtestLoadingSelector](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118089/testReport/projectroot.roottest.root.selector/simple/roottest_root_selector_simple_runtestLoadingSelector/); - [projectroot.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8204#issuecomment-844261645
Usability,simpl,simple,# Failing tests:; - [projectroot.roottest.cling.specialobj.roottest_cling_specialobj_runf02](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118089/testReport/projectroot.roottest.cling/specialobj/roottest_cling_specialobj_runf02/); - [projectroot.roottest.root.meta.roottest_root_meta_runnamespace_auto](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118089/testReport/projectroot.roottest.root/meta/roottest_root_meta_runnamespace_auto/); - [projectroot.roottest.root.io.clones.roottest_root_io_clones_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118089/testReport/projectroot.roottest.root.io/clones/roottest_root_io_clones_make/); - [projectroot.roottest.root.io.interface.roottest_root_io_interface_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118089/testReport/projectroot.roottest.root.io/interface/roottest_root_io_interface_make/); - [projectroot.roottest.root.meta.ROOT-7462.roottest_root_meta_ROOT_7462_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118089/testReport/projectroot.roottest.root.meta/ROOT-7462/roottest_root_meta_ROOT_7462_make/); - [projectroot.roottest.root.meta.tclass.roottest_root_meta_tclass_execDuplicate](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118089/testReport/projectroot.roottest.root.meta/tclass/roottest_root_meta_tclass_execDuplicate/); - [projectroot.roottest.root.selector.simple.roottest_root_selector_simple_runtestLoadingSelector](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118089/testReport/projectroot.roottest.root.selector/simple/roottest_root_selector_simple_runtestLoadingSelector/); - [projectroot.roottest.root.treeformula.stl.roottest_root_treeformula_stl_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/118089/testReport/projectroot.roottest.root.treeformula/stl/roottest_root_treeformula_stl_make/),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8204#issuecomment-844261645
Usability,learn,learned,Thank you everyone for your tips. I have learned a bunch of new concepts. The last two commits have added those changes. I am very grateful for the help I have been getting. Thank you everyone.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8225#issuecomment-858035785
Deployability,update,update,"Unrelated note. > auto view = ntuple->GetView<float>(""double"");; > modelA->MakeField<std::int32_t>(""int"", 42);. We strive/want to have the name of the column to be usable identifiers (so that they can be used in reading code as-if they actually were identifier (See TTree::Draw syntax and RDataFrame). Could you (likely in a separate/new PR) update the test/example to not use just the datatype as column names?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8227#issuecomment-846080791
Testability,test,test,"Unrelated note. > auto view = ntuple->GetView<float>(""double"");; > modelA->MakeField<std::int32_t>(""int"", 42);. We strive/want to have the name of the column to be usable identifiers (so that they can be used in reading code as-if they actually were identifier (See TTree::Draw syntax and RDataFrame). Could you (likely in a separate/new PR) update the test/example to not use just the datatype as column names?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8227#issuecomment-846080791
Usability,usab,usable,"Unrelated note. > auto view = ntuple->GetView<float>(""double"");; > modelA->MakeField<std::int32_t>(""int"", 42);. We strive/want to have the name of the column to be usable identifiers (so that they can be used in reading code as-if they actually were identifier (See TTree::Draw syntax and RDataFrame). Could you (likely in a separate/new PR) update the test/example to not use just the datatype as column names?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8227#issuecomment-846080791
Usability,usab,usable,"> We strive/want to have the name of the column to be usable identifiers. Thank you Philippe, I've just pushed a new commit for this.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8227#issuecomment-846119670
Usability,guid,guide,"We have this standard tutorial: https://root.cern/doc/master/canvas2_8C.html; Without your change, the axis titles appear as you see on the reference guide online.; With your change, all the titles disappear",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8235#issuecomment-847886843
Energy Efficiency,reduce,reduced,"> We have this standard tutorial: https://root.cern/doc/master/canvas2_8C.html; > Without your change the axis titles appear as you see on the reference guide online.; > With your change all the titles disappear. Ok I've just run this demo, thanks for pointing me to it, and yes I confirm with my fix the titles disappear. But that was only because an offset of ""5"" was now too big, so I reduced it to ""1"" and they reappear. But I see now that the way they reappear for the x-axis is great but for the y-axis they depended on the height of the pad, so I concede that the fix as it stands isn't going to giver desirable behaviour. I think what I was trying to achieve here was a title offset that scales sensibly with the label offset, so that you dont have to tune the title offset for each pad size you work with. For example, if I take the histogram from the example and plot it to its own canvas in current ROOT, suddenly the offset of 5 is way too big and the titles disappear. I tried the following which seems to work well. ```; charheight /= (gPad->GetWh()*((x1==x0) ? gPad->GetAbsWNDC() : gPad->GetAbsHNDC()));; ```. With this change, and making the titleoffsets in the example=1, things look pretty, and also if I plot the histogram to its own canvas the same offsets then things still look good. . See the attached screenshot. The plots on the left are existing ROOT and note the title offsets are 5 in both cases, so ok for top left but no good for bottom left. But with the line above in TGAxis, title offset of 1 in both cases looks pretty reasonable to me. But I appreciate this is a change in behaviour that may be undesirable. I dunno, what are your thoughts?; ![Screenshot 2021-05-25 at 15 41 38](https://user-images.githubusercontent.com/18280829/119517952-fb4bcb00-bd6f-11eb-86fc-7829ba2c4191.png)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8235#issuecomment-847929734
Integrability,depend,depended,"> We have this standard tutorial: https://root.cern/doc/master/canvas2_8C.html; > Without your change the axis titles appear as you see on the reference guide online.; > With your change all the titles disappear. Ok I've just run this demo, thanks for pointing me to it, and yes I confirm with my fix the titles disappear. But that was only because an offset of ""5"" was now too big, so I reduced it to ""1"" and they reappear. But I see now that the way they reappear for the x-axis is great but for the y-axis they depended on the height of the pad, so I concede that the fix as it stands isn't going to giver desirable behaviour. I think what I was trying to achieve here was a title offset that scales sensibly with the label offset, so that you dont have to tune the title offset for each pad size you work with. For example, if I take the histogram from the example and plot it to its own canvas in current ROOT, suddenly the offset of 5 is way too big and the titles disappear. I tried the following which seems to work well. ```; charheight /= (gPad->GetWh()*((x1==x0) ? gPad->GetAbsWNDC() : gPad->GetAbsHNDC()));; ```. With this change, and making the titleoffsets in the example=1, things look pretty, and also if I plot the histogram to its own canvas the same offsets then things still look good. . See the attached screenshot. The plots on the left are existing ROOT and note the title offsets are 5 in both cases, so ok for top left but no good for bottom left. But with the line above in TGAxis, title offset of 1 in both cases looks pretty reasonable to me. But I appreciate this is a change in behaviour that may be undesirable. I dunno, what are your thoughts?; ![Screenshot 2021-05-25 at 15 41 38](https://user-images.githubusercontent.com/18280829/119517952-fb4bcb00-bd6f-11eb-86fc-7829ba2c4191.png)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8235#issuecomment-847929734
Performance,tune,tune,"> We have this standard tutorial: https://root.cern/doc/master/canvas2_8C.html; > Without your change the axis titles appear as you see on the reference guide online.; > With your change all the titles disappear. Ok I've just run this demo, thanks for pointing me to it, and yes I confirm with my fix the titles disappear. But that was only because an offset of ""5"" was now too big, so I reduced it to ""1"" and they reappear. But I see now that the way they reappear for the x-axis is great but for the y-axis they depended on the height of the pad, so I concede that the fix as it stands isn't going to giver desirable behaviour. I think what I was trying to achieve here was a title offset that scales sensibly with the label offset, so that you dont have to tune the title offset for each pad size you work with. For example, if I take the histogram from the example and plot it to its own canvas in current ROOT, suddenly the offset of 5 is way too big and the titles disappear. I tried the following which seems to work well. ```; charheight /= (gPad->GetWh()*((x1==x0) ? gPad->GetAbsWNDC() : gPad->GetAbsHNDC()));; ```. With this change, and making the titleoffsets in the example=1, things look pretty, and also if I plot the histogram to its own canvas the same offsets then things still look good. . See the attached screenshot. The plots on the left are existing ROOT and note the title offsets are 5 in both cases, so ok for top left but no good for bottom left. But with the line above in TGAxis, title offset of 1 in both cases looks pretty reasonable to me. But I appreciate this is a change in behaviour that may be undesirable. I dunno, what are your thoughts?; ![Screenshot 2021-05-25 at 15 41 38](https://user-images.githubusercontent.com/18280829/119517952-fb4bcb00-bd6f-11eb-86fc-7829ba2c4191.png)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8235#issuecomment-847929734
Usability,guid,guide,"> We have this standard tutorial: https://root.cern/doc/master/canvas2_8C.html; > Without your change the axis titles appear as you see on the reference guide online.; > With your change all the titles disappear. Ok I've just run this demo, thanks for pointing me to it, and yes I confirm with my fix the titles disappear. But that was only because an offset of ""5"" was now too big, so I reduced it to ""1"" and they reappear. But I see now that the way they reappear for the x-axis is great but for the y-axis they depended on the height of the pad, so I concede that the fix as it stands isn't going to giver desirable behaviour. I think what I was trying to achieve here was a title offset that scales sensibly with the label offset, so that you dont have to tune the title offset for each pad size you work with. For example, if I take the histogram from the example and plot it to its own canvas in current ROOT, suddenly the offset of 5 is way too big and the titles disappear. I tried the following which seems to work well. ```; charheight /= (gPad->GetWh()*((x1==x0) ? gPad->GetAbsWNDC() : gPad->GetAbsHNDC()));; ```. With this change, and making the titleoffsets in the example=1, things look pretty, and also if I plot the histogram to its own canvas the same offsets then things still look good. . See the attached screenshot. The plots on the left are existing ROOT and note the title offsets are 5 in both cases, so ok for top left but no good for bottom left. But with the line above in TGAxis, title offset of 1 in both cases looks pretty reasonable to me. But I appreciate this is a change in behaviour that may be undesirable. I dunno, what are your thoughts?; ![Screenshot 2021-05-25 at 15 41 38](https://user-images.githubusercontent.com/18280829/119517952-fb4bcb00-bd6f-11eb-86fc-7829ba2c4191.png)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8235#issuecomment-847929734
Usability,feedback,feedback,any feedback on this PR ?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8265#issuecomment-946554582
Deployability,install,installation,"Hi,; thank you very much, that you spend time on this!. I do not understand some things:; * In the Doc the packages that do need internet access are usually named - this does not seem to be correct; * Furthermore, all packages that need internet access should be turned off in installation by default - they are not; * I think it is a difference if a system is cut off from the internet by a firewall, or if a system has no network (maybe that's why cmake does not detect it properly?); * I do not understand why I have to make -Dsuchalognoption to make a simple basic installation. If you can't put out that packages from the default installation and if cmake can't detect that there is not valid connection and if you do not want to make an extra option please: write a chapter in the docs what you have to do in case you want to compile on a local system. Thanks; Georg",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8292#issuecomment-864610580
Safety,detect,detect,"Hi,; thank you very much, that you spend time on this!. I do not understand some things:; * In the Doc the packages that do need internet access are usually named - this does not seem to be correct; * Furthermore, all packages that need internet access should be turned off in installation by default - they are not; * I think it is a difference if a system is cut off from the internet by a firewall, or if a system has no network (maybe that's why cmake does not detect it properly?); * I do not understand why I have to make -Dsuchalognoption to make a simple basic installation. If you can't put out that packages from the default installation and if cmake can't detect that there is not valid connection and if you do not want to make an extra option please: write a chapter in the docs what you have to do in case you want to compile on a local system. Thanks; Georg",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8292#issuecomment-864610580
Security,access,access,"Hi,; thank you very much, that you spend time on this!. I do not understand some things:; * In the Doc the packages that do need internet access are usually named - this does not seem to be correct; * Furthermore, all packages that need internet access should be turned off in installation by default - they are not; * I think it is a difference if a system is cut off from the internet by a firewall, or if a system has no network (maybe that's why cmake does not detect it properly?); * I do not understand why I have to make -Dsuchalognoption to make a simple basic installation. If you can't put out that packages from the default installation and if cmake can't detect that there is not valid connection and if you do not want to make an extra option please: write a chapter in the docs what you have to do in case you want to compile on a local system. Thanks; Georg",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8292#issuecomment-864610580
Usability,simpl,simple,"Hi,; thank you very much, that you spend time on this!. I do not understand some things:; * In the Doc the packages that do need internet access are usually named - this does not seem to be correct; * Furthermore, all packages that need internet access should be turned off in installation by default - they are not; * I think it is a difference if a system is cut off from the internet by a firewall, or if a system has no network (maybe that's why cmake does not detect it properly?); * I do not understand why I have to make -Dsuchalognoption to make a simple basic installation. If you can't put out that packages from the default installation and if cmake can't detect that there is not valid connection and if you do not want to make an extra option please: write a chapter in the docs what you have to do in case you want to compile on a local system. Thanks; Georg",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8292#issuecomment-864610580
Testability,test,testfile,or simply delete the testfile on the server :-),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8292#issuecomment-872039777
Usability,simpl,simply,or simply delete the testfile on the server :-),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8292#issuecomment-872039777
Usability,feedback,feedback,"@pamputt Cool, thanks for the feedback!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8292#issuecomment-880610339
Usability,simpl,simple,"as for simple; using struct instead of class should focus on the issue; ```; struct xy_t{; double x;; double y;; ClassDef(xy_t,1);; };; ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8295#issuecomment-851783548
Availability,error,error,"Discussed and checked the problem with @pcanal . The root cause is that `TTree::CopyAddresses` has an implicit assumption that the input and output branches are of the same kind, while in this case we have a `TBranchElement` in input and a simple `TBranch` in output. In particular, `TBranchElement::SetAddress` would apply a correction to the wrong offset returned by `TBranchElement::GetAddress`, but `TBranch::SetAddress` does not. This bug is absolutely terrible: if the input dataset consists of multiple trees, starting from the second tree data members of types that were saved as TBranchElements are written out wrongly by Snapshot. The plan is the following:. 1. add a check in `TTree::CopyAddresses` that input and output branches are of the same kind, print an error otherwise; 2. refactor `Snapshot` so that instead of relying on `TChain::AddClone` and `TTree::CopyAddresses` to update the addresses of the output branches we instead reset the branches manually based on the addresses provided by TTreeReaderValue access -- we'll use the `TNotify` mechanism to reset the branches every time TChain switches input tree",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8295#issuecomment-852277296
Deployability,update,update,"Discussed and checked the problem with @pcanal . The root cause is that `TTree::CopyAddresses` has an implicit assumption that the input and output branches are of the same kind, while in this case we have a `TBranchElement` in input and a simple `TBranch` in output. In particular, `TBranchElement::SetAddress` would apply a correction to the wrong offset returned by `TBranchElement::GetAddress`, but `TBranch::SetAddress` does not. This bug is absolutely terrible: if the input dataset consists of multiple trees, starting from the second tree data members of types that were saved as TBranchElements are written out wrongly by Snapshot. The plan is the following:. 1. add a check in `TTree::CopyAddresses` that input and output branches are of the same kind, print an error otherwise; 2. refactor `Snapshot` so that instead of relying on `TChain::AddClone` and `TTree::CopyAddresses` to update the addresses of the output branches we instead reset the branches manually based on the addresses provided by TTreeReaderValue access -- we'll use the `TNotify` mechanism to reset the branches every time TChain switches input tree",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8295#issuecomment-852277296
Modifiability,refactor,refactor,"Discussed and checked the problem with @pcanal . The root cause is that `TTree::CopyAddresses` has an implicit assumption that the input and output branches are of the same kind, while in this case we have a `TBranchElement` in input and a simple `TBranch` in output. In particular, `TBranchElement::SetAddress` would apply a correction to the wrong offset returned by `TBranchElement::GetAddress`, but `TBranch::SetAddress` does not. This bug is absolutely terrible: if the input dataset consists of multiple trees, starting from the second tree data members of types that were saved as TBranchElements are written out wrongly by Snapshot. The plan is the following:. 1. add a check in `TTree::CopyAddresses` that input and output branches are of the same kind, print an error otherwise; 2. refactor `Snapshot` so that instead of relying on `TChain::AddClone` and `TTree::CopyAddresses` to update the addresses of the output branches we instead reset the branches manually based on the addresses provided by TTreeReaderValue access -- we'll use the `TNotify` mechanism to reset the branches every time TChain switches input tree",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8295#issuecomment-852277296
Security,access,access,"Discussed and checked the problem with @pcanal . The root cause is that `TTree::CopyAddresses` has an implicit assumption that the input and output branches are of the same kind, while in this case we have a `TBranchElement` in input and a simple `TBranch` in output. In particular, `TBranchElement::SetAddress` would apply a correction to the wrong offset returned by `TBranchElement::GetAddress`, but `TBranch::SetAddress` does not. This bug is absolutely terrible: if the input dataset consists of multiple trees, starting from the second tree data members of types that were saved as TBranchElements are written out wrongly by Snapshot. The plan is the following:. 1. add a check in `TTree::CopyAddresses` that input and output branches are of the same kind, print an error otherwise; 2. refactor `Snapshot` so that instead of relying on `TChain::AddClone` and `TTree::CopyAddresses` to update the addresses of the output branches we instead reset the branches manually based on the addresses provided by TTreeReaderValue access -- we'll use the `TNotify` mechanism to reset the branches every time TChain switches input tree",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8295#issuecomment-852277296
Usability,simpl,simple,"Discussed and checked the problem with @pcanal . The root cause is that `TTree::CopyAddresses` has an implicit assumption that the input and output branches are of the same kind, while in this case we have a `TBranchElement` in input and a simple `TBranch` in output. In particular, `TBranchElement::SetAddress` would apply a correction to the wrong offset returned by `TBranchElement::GetAddress`, but `TBranch::SetAddress` does not. This bug is absolutely terrible: if the input dataset consists of multiple trees, starting from the second tree data members of types that were saved as TBranchElements are written out wrongly by Snapshot. The plan is the following:. 1. add a check in `TTree::CopyAddresses` that input and output branches are of the same kind, print an error otherwise; 2. refactor `Snapshot` so that instead of relying on `TChain::AddClone` and `TTree::CopyAddresses` to update the addresses of the output branches we instead reset the branches manually based on the addresses provided by TTreeReaderValue access -- we'll use the `TNotify` mechanism to reset the branches every time TChain switches input tree",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8295#issuecomment-852277296
Usability,feedback,feedback,"## DeepCode failed to analyze this pull request; Something went wrong despite trying multiple times, sorry about that.; Please comment this pull request with ""Retry DeepCode"" to manually retry, or [contact us](https://www.deepcode.ai/feedback?select=4&utm_source=gh_review) so that a human can look into the issue.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8301#issuecomment-851918877
Usability,feedback,feedback,"## DeepCode failed to analyze this pull request; Something went wrong despite trying multiple times, sorry about that.; Please comment this pull request with ""Retry DeepCode"" to manually retry, or [contact us](https://www.deepcode.ai/feedback?select=4&utm_source=gh_review) so that a human can look into the issue.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8303#issuecomment-852018288
Availability,error,error,"As @jalopezg-git mentioned, bool(foo) appears as a declaration (bool foo). The following simple C++ code also fails to compile with a re-declaration error and I think that should be the expected behavior.; ```C++; #include<iostream>; int main() {; int i = 54;; bool(i);; }; ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8304#issuecomment-1943877354
Usability,simpl,simple,"As @jalopezg-git mentioned, bool(foo) appears as a declaration (bool foo). The following simple C++ code also fails to compile with a re-declaration error and I think that should be the expected behavior.; ```C++; #include<iostream>; int main() {; int i = 54;; bool(i);; }; ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8304#issuecomment-1943877354
Usability,usab,usable,"Actually, I tried moving the target_include_directories after and it doesn't work. Either that was broken by some more recent commit or it didn't work before, but we didn't notice any problem. Something that needs to be debugged, because I did try to make the properties be usable even when the target_include_directories command is added later. Maybe it's something that only works within ROOT?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8308#issuecomment-856013049
Availability,avail,available,"I was rather hoping that we could evolve `ROOT_GENERATE_DICTIONARY`, at least the version that we make available to users, so that it would be simpler to use.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8308#issuecomment-856211883
Modifiability,evolve,evolve,"I was rather hoping that we could evolve `ROOT_GENERATE_DICTIONARY`, at least the version that we make available to users, so that it would be simpler to use.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8308#issuecomment-856211883
Usability,simpl,simpler,"I was rather hoping that we could evolve `ROOT_GENERATE_DICTIONARY`, at least the version that we make available to users, so that it would be simpler to use.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8308#issuecomment-856211883
Usability,clear,clear,"> Evolve == break for current users. Not _necessarily_, right?. It shouldn't be a breaking change to e.g. have `ROOT_GENERATE_DICTIONARY` automatically call the appropriate `configure_file` or `target_include_directory`..?. P.S.; just so we are clear, I'm not suggesting to break anything for users :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8308#issuecomment-856227664
Performance,multi-thread,multi-threading,"Hi, some comments/questions:. 1. I guess the behavior of `TTaskGroup` should mimic what `TThreadExecutor` does, e.g. it should use the task arena if it exists, and it should construct one if it doesn't. What's the rationale for doing things independently of ROOT's task arena? Does this mean users might see more cores used than they expect in some cases?; 2. Are you ok with silently do nothing if R__IMT is undefined? Would it be better to print a warning?; 3. Can we also have a way to disable RNTuple's multi-threading even if implicit MT is enabled, like TTree has?. P.S.; this stuff is always tricky to reason about for me, sorry if i'm missing obvious stuff. the rationale behind my question is that we should not have N different multi-threading behaviors for N components (because then we can't reason about how these components interact with each other because there are too many possibilities), we should not surprisingly use more cores than users might expect (and we should play well with the TBB settings of frameworks such as CMSSW, but it's not clear to me how we do that now, actually)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8334#issuecomment-854489805
Usability,clear,clear,"Hi, some comments/questions:. 1. I guess the behavior of `TTaskGroup` should mimic what `TThreadExecutor` does, e.g. it should use the task arena if it exists, and it should construct one if it doesn't. What's the rationale for doing things independently of ROOT's task arena? Does this mean users might see more cores used than they expect in some cases?; 2. Are you ok with silently do nothing if R__IMT is undefined? Would it be better to print a warning?; 3. Can we also have a way to disable RNTuple's multi-threading even if implicit MT is enabled, like TTree has?. P.S.; this stuff is always tricky to reason about for me, sorry if i'm missing obvious stuff. the rationale behind my question is that we should not have N different multi-threading behaviors for N components (because then we can't reason about how these components interact with each other because there are too many possibilities), we should not surprisingly use more cores than users might expect (and we should play well with the TBB settings of frameworks such as CMSSW, but it's not clear to me how we do that now, actually)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8334#issuecomment-854489805
Performance,perform,perform,"Hi Enrico, thank you very much for taking a look. > 1. I guess the behavior of TTaskGroup should mimic what TThreadExecutor does, e.g. it should use the task arena if it exists, and it should construct one if it doesn't. What's the rationale for doing things independently of ROOT's task arena? Does this mean users might see more cores used than they expect in some cases?. I believe this change only removes an unnecessary restriction on when `TTaskGroup` can be used (i.e. after looking through the implementation, I don't think having IMT globally enabled is a precondition for the use of `TTaskGroup` and test benchmarks using this implementation seem to perform the same). > 2. Are you ok with silently do nothing if R__IMT is undefined? Would it be better to print a warning?. Thank you, yes, a warning would probably be better. > 3. Can we also have a way to disable RNTuple's multi-threading even if implicit MT is enabled, like TTree has?. Yes, this makes sense to me. It will probably need a big warning in the docs about when to call it and/or some graceful shutdown logic. Even if this PR doesn't make it that method might be valuable by itself. > the rationale behind my question is that we should not have N different multi-threading behaviors for N components. I completely agree, it is very nice to be able to say ""if you want multithreading, call `EnableImplicitMT` and you're done"". > and we should play well with the TBB settings of frameworks such as CMSSW, but it's not clear to me how we do that now, actually. For the RNTuple NanoAOD project, we were hoping to plug in the CMSSW tbb instance with `RPageStorage::SetTaskScheduler` (for both page sink and source): https://github.com/root-project/root/blob/a9c61d56afd70b74425779f330a4ec2cc581bb0b/tree/ntuple/v7/inc/ROOT/RPageStorage.hxx#L136. by implementing a derived `RTaskScheduler` on the CMSSW side so they have control over task isolation etc. ; https://github.com/root-project/root/blob/4118c0cb6db03998ae77f56f57cc372ac",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8334#issuecomment-854977563
Testability,test,test,"Hi Enrico, thank you very much for taking a look. > 1. I guess the behavior of TTaskGroup should mimic what TThreadExecutor does, e.g. it should use the task arena if it exists, and it should construct one if it doesn't. What's the rationale for doing things independently of ROOT's task arena? Does this mean users might see more cores used than they expect in some cases?. I believe this change only removes an unnecessary restriction on when `TTaskGroup` can be used (i.e. after looking through the implementation, I don't think having IMT globally enabled is a precondition for the use of `TTaskGroup` and test benchmarks using this implementation seem to perform the same). > 2. Are you ok with silently do nothing if R__IMT is undefined? Would it be better to print a warning?. Thank you, yes, a warning would probably be better. > 3. Can we also have a way to disable RNTuple's multi-threading even if implicit MT is enabled, like TTree has?. Yes, this makes sense to me. It will probably need a big warning in the docs about when to call it and/or some graceful shutdown logic. Even if this PR doesn't make it that method might be valuable by itself. > the rationale behind my question is that we should not have N different multi-threading behaviors for N components. I completely agree, it is very nice to be able to say ""if you want multithreading, call `EnableImplicitMT` and you're done"". > and we should play well with the TBB settings of frameworks such as CMSSW, but it's not clear to me how we do that now, actually. For the RNTuple NanoAOD project, we were hoping to plug in the CMSSW tbb instance with `RPageStorage::SetTaskScheduler` (for both page sink and source): https://github.com/root-project/root/blob/a9c61d56afd70b74425779f330a4ec2cc581bb0b/tree/ntuple/v7/inc/ROOT/RPageStorage.hxx#L136. by implementing a derived `RTaskScheduler` on the CMSSW side so they have control over task isolation etc. ; https://github.com/root-project/root/blob/4118c0cb6db03998ae77f56f57cc372ac",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8334#issuecomment-854977563
Usability,clear,clear,"guess the behavior of TTaskGroup should mimic what TThreadExecutor does, e.g. it should use the task arena if it exists, and it should construct one if it doesn't. What's the rationale for doing things independently of ROOT's task arena? Does this mean users might see more cores used than they expect in some cases?. I believe this change only removes an unnecessary restriction on when `TTaskGroup` can be used (i.e. after looking through the implementation, I don't think having IMT globally enabled is a precondition for the use of `TTaskGroup` and test benchmarks using this implementation seem to perform the same). > 2. Are you ok with silently do nothing if R__IMT is undefined? Would it be better to print a warning?. Thank you, yes, a warning would probably be better. > 3. Can we also have a way to disable RNTuple's multi-threading even if implicit MT is enabled, like TTree has?. Yes, this makes sense to me. It will probably need a big warning in the docs about when to call it and/or some graceful shutdown logic. Even if this PR doesn't make it that method might be valuable by itself. > the rationale behind my question is that we should not have N different multi-threading behaviors for N components. I completely agree, it is very nice to be able to say ""if you want multithreading, call `EnableImplicitMT` and you're done"". > and we should play well with the TBB settings of frameworks such as CMSSW, but it's not clear to me how we do that now, actually. For the RNTuple NanoAOD project, we were hoping to plug in the CMSSW tbb instance with `RPageStorage::SetTaskScheduler` (for both page sink and source): https://github.com/root-project/root/blob/a9c61d56afd70b74425779f330a4ec2cc581bb0b/tree/ntuple/v7/inc/ROOT/RPageStorage.hxx#L136. by implementing a derived `RTaskScheduler` on the CMSSW side so they have control over task isolation etc. ; https://github.com/root-project/root/blob/4118c0cb6db03998ae77f56f57cc372ac150c9df/tree/ntuple/v7/inc/ROOT/RPageStorage.hxx#L66-L76",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8334#issuecomment-854977563
Usability,simpl,simpler,"> What about replacing them with a free alternative?. Yes, I think it will be simpler",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8357#issuecomment-946590814
Integrability,rout,routine,"> I am seeing a similar issue with TSystem.h, TSeqCollection *fTimers{nullptr}; //List of timers. I think we should tackle this in a separate PR. The simplest solution though is to always create the fTimers (i.e. move its creation to the constructor or init routine) and to mark it as a 'thread safe' collection:; ```; fTimers->UseRWLock();; ```; thanks.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8379#issuecomment-857765612
Safety,safe,safe,"> I am seeing a similar issue with TSystem.h, TSeqCollection *fTimers{nullptr}; //List of timers. I think we should tackle this in a separate PR. The simplest solution though is to always create the fTimers (i.e. move its creation to the constructor or init routine) and to mark it as a 'thread safe' collection:; ```; fTimers->UseRWLock();; ```; thanks.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8379#issuecomment-857765612
Usability,simpl,simplest,"> I am seeing a similar issue with TSystem.h, TSeqCollection *fTimers{nullptr}; //List of timers. I think we should tackle this in a separate PR. The simplest solution though is to always create the fTimers (i.e. move its creation to the constructor or init routine) and to mark it as a 'thread safe' collection:; ```; fTimers->UseRWLock();; ```; thanks.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8379#issuecomment-857765612
Deployability,upgrade,upgraded,"> The simplest solution though is to always create the fTimers . Also I noted that TOrdCollection (the type of fTimes at the moment) has not been upgraded yet to support ```UseRWLock()``` (it will silently ignore it), so we will need to also change the type to ```TList```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8379#issuecomment-857772652
Usability,simpl,simplest,"> The simplest solution though is to always create the fTimers . Also I noted that TOrdCollection (the type of fTimes at the moment) has not been upgraded yet to support ```UseRWLock()``` (it will silently ignore it), so we will need to also change the type to ```TList```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8379#issuecomment-857772652
Deployability,configurat,configuration,"Thanks @amadio for the extensive input! Let me address it point by point:. First: the current choice for ""built-in only"". The built-in is there for two reasons: 1) as a dependency, obviously, but 2) also because the full source is needed to build `zmq::ppoll`. `ppoll` was written as an extension to libzmq itself. In the ideal world, I would have committed this back to libzmq (which they are open to, and which I'll do later, see https://github.com/zeromq/libzmq/issues/4220), but haven't had time yet. The interim solution is to just ship it with ROOT, but this requires (part of) the libzmq source to build against. We can do this in two ways: a) just include the necessary libzmq files or b) get them externally on the fly. I actually went with option a) first. However, when people started trying out this branch on their machines, it turned out that the `conda` libzmq build (which I was using in my dev setup) had a more favorable configuration than for instance most Linux native builds, especially because those native builds lack CMake configuration files. That latter fact made me decide to just make the built-in dependency the default; this way I wouldn't have to figure out how to best detect libzmq on each platform (or find / cobble together a good and freely licensed FindZeroMQ.cmake, but the general feeling around the ZeroMQ community is that this is a waste of effort, because the CMake config files that come along with libzmq itself already solve this finding problem; it's just unfortunate that the Linux distro's won't include them...). So in the end, because of time constraints, I made the choice to prioritize other things over putting a lot of effort into this dependency which will probably end up different in the near future anyway (because of the ppoll PR, which will make things a lot easier on the ROOT side). So, long story, I hope it is clear. Do you think that given this (temporary) situation, the choice for built-in only is acceptable?. Then about the RooFitZ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8385#issuecomment-870411730
Integrability,depend,dependency,"Thanks @amadio for the extensive input! Let me address it point by point:. First: the current choice for ""built-in only"". The built-in is there for two reasons: 1) as a dependency, obviously, but 2) also because the full source is needed to build `zmq::ppoll`. `ppoll` was written as an extension to libzmq itself. In the ideal world, I would have committed this back to libzmq (which they are open to, and which I'll do later, see https://github.com/zeromq/libzmq/issues/4220), but haven't had time yet. The interim solution is to just ship it with ROOT, but this requires (part of) the libzmq source to build against. We can do this in two ways: a) just include the necessary libzmq files or b) get them externally on the fly. I actually went with option a) first. However, when people started trying out this branch on their machines, it turned out that the `conda` libzmq build (which I was using in my dev setup) had a more favorable configuration than for instance most Linux native builds, especially because those native builds lack CMake configuration files. That latter fact made me decide to just make the built-in dependency the default; this way I wouldn't have to figure out how to best detect libzmq on each platform (or find / cobble together a good and freely licensed FindZeroMQ.cmake, but the general feeling around the ZeroMQ community is that this is a waste of effort, because the CMake config files that come along with libzmq itself already solve this finding problem; it's just unfortunate that the Linux distro's won't include them...). So in the end, because of time constraints, I made the choice to prioritize other things over putting a lot of effort into this dependency which will probably end up different in the near future anyway (because of the ppoll PR, which will make things a lot easier on the ROOT side). So, long story, I hope it is clear. Do you think that given this (temporary) situation, the choice for built-in only is acceptable?. Then about the RooFitZ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8385#issuecomment-870411730
Modifiability,config,configuration,"Thanks @amadio for the extensive input! Let me address it point by point:. First: the current choice for ""built-in only"". The built-in is there for two reasons: 1) as a dependency, obviously, but 2) also because the full source is needed to build `zmq::ppoll`. `ppoll` was written as an extension to libzmq itself. In the ideal world, I would have committed this back to libzmq (which they are open to, and which I'll do later, see https://github.com/zeromq/libzmq/issues/4220), but haven't had time yet. The interim solution is to just ship it with ROOT, but this requires (part of) the libzmq source to build against. We can do this in two ways: a) just include the necessary libzmq files or b) get them externally on the fly. I actually went with option a) first. However, when people started trying out this branch on their machines, it turned out that the `conda` libzmq build (which I was using in my dev setup) had a more favorable configuration than for instance most Linux native builds, especially because those native builds lack CMake configuration files. That latter fact made me decide to just make the built-in dependency the default; this way I wouldn't have to figure out how to best detect libzmq on each platform (or find / cobble together a good and freely licensed FindZeroMQ.cmake, but the general feeling around the ZeroMQ community is that this is a waste of effort, because the CMake config files that come along with libzmq itself already solve this finding problem; it's just unfortunate that the Linux distro's won't include them...). So in the end, because of time constraints, I made the choice to prioritize other things over putting a lot of effort into this dependency which will probably end up different in the near future anyway (because of the ppoll PR, which will make things a lot easier on the ROOT side). So, long story, I hope it is clear. Do you think that given this (temporary) situation, the choice for built-in only is acceptable?. Then about the RooFitZ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8385#issuecomment-870411730
Safety,detect,detect,"bviously, but 2) also because the full source is needed to build `zmq::ppoll`. `ppoll` was written as an extension to libzmq itself. In the ideal world, I would have committed this back to libzmq (which they are open to, and which I'll do later, see https://github.com/zeromq/libzmq/issues/4220), but haven't had time yet. The interim solution is to just ship it with ROOT, but this requires (part of) the libzmq source to build against. We can do this in two ways: a) just include the necessary libzmq files or b) get them externally on the fly. I actually went with option a) first. However, when people started trying out this branch on their machines, it turned out that the `conda` libzmq build (which I was using in my dev setup) had a more favorable configuration than for instance most Linux native builds, especially because those native builds lack CMake configuration files. That latter fact made me decide to just make the built-in dependency the default; this way I wouldn't have to figure out how to best detect libzmq on each platform (or find / cobble together a good and freely licensed FindZeroMQ.cmake, but the general feeling around the ZeroMQ community is that this is a waste of effort, because the CMake config files that come along with libzmq itself already solve this finding problem; it's just unfortunate that the Linux distro's won't include them...). So in the end, because of time constraints, I made the choice to prioritize other things over putting a lot of effort into this dependency which will probably end up different in the near future anyway (because of the ppoll PR, which will make things a lot easier on the ROOT side). So, long story, I hope it is clear. Do you think that given this (temporary) situation, the choice for built-in only is acceptable?. Then about the RooFitZMQ option: agreed, I should add an option for that. The only catch is that this PR is part of a bigger series and the ""real"" end-product that should be optional in my opinion is Roo",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8385#issuecomment-870411730
Usability,clear,clear,"onda` libzmq build (which I was using in my dev setup) had a more favorable configuration than for instance most Linux native builds, especially because those native builds lack CMake configuration files. That latter fact made me decide to just make the built-in dependency the default; this way I wouldn't have to figure out how to best detect libzmq on each platform (or find / cobble together a good and freely licensed FindZeroMQ.cmake, but the general feeling around the ZeroMQ community is that this is a waste of effort, because the CMake config files that come along with libzmq itself already solve this finding problem; it's just unfortunate that the Linux distro's won't include them...). So in the end, because of time constraints, I made the choice to prioritize other things over putting a lot of effort into this dependency which will probably end up different in the near future anyway (because of the ppoll PR, which will make things a lot easier on the ROOT side). So, long story, I hope it is clear. Do you think that given this (temporary) situation, the choice for built-in only is acceptable?. Then about the RooFitZMQ option: agreed, I should add an option for that. The only catch is that this PR is part of a bigger series and the ""real"" end-product that should be optional in my opinion is RooFit::MultiProcess, so I wanted to wait with such an option until that PR (hopefully I'll be able to submit that one today). In this PR, RooFitZMQ is not used for anything and later on it will just be a library for RooFit::MultiProcess as well, so there would typically not really be a point for a user to want to build RooFitZMQ but not RooFit::MultiProcess. Do you think in this situation it makes sense to add the option for RooFitZMQ already or should I just do it for RooFit::MultiProcess? So, this option (say `-Droofit_multiprocess=ON`) would activate both RooFit::MultiProcess and RooFitZMQ, and also builtin_zeromq. I think that fail-on-missing is only relevant in case the",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8385#issuecomment-870411730
Deployability,patch,patching,"That's right, I could (and did) use a system libzmq, except to build the ppoll file, I need to include a few headers from the libzmq source which are not distributed with Linux packages. Previously, I had included those headers with RooFitZMQ. I ripped them out again, because with the built-in they became unnecessary. Edit: indeed, patching is probably not the right word, it's an addition, but it uses libzmq internal headers. Hope I'm making myself clear, sorry for the confusion.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8385#issuecomment-870471097
Usability,clear,clear,"That's right, I could (and did) use a system libzmq, except to build the ppoll file, I need to include a few headers from the libzmq source which are not distributed with Linux packages. Previously, I had included those headers with RooFitZMQ. I ripped them out again, because with the built-in they became unnecessary. Edit: indeed, patching is probably not the right word, it's an addition, but it uses libzmq internal headers. Hope I'm making myself clear, sorry for the confusion.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8385#issuecomment-870471097
Integrability,depend,depend,"I agree, that is the best way to go in theory. In practice, I'm dealing with time constraints that will make this challenging. The timeline for including `ppoll` into libzmq would be a liability, because even though I'm not worried it will not be accepted (it is actually quite a simple addition, especially in the way that [a libzmq maintainer suggests here](https://github.com/zeromq/libzmq/issues/4220)), delaying this PR to wait for that one will probably result in extra merging efforts for the later RooFit PRs that depend on this one. In any case, if this is the way we must go (and I can totally understand that you would want it this way), I will do my best to split up the other PRs as much as possible, so that those can be merged independently asap and merging conflicts will hopefully be minimized.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8385#issuecomment-870483338
Usability,simpl,simple,"I agree, that is the best way to go in theory. In practice, I'm dealing with time constraints that will make this challenging. The timeline for including `ppoll` into libzmq would be a liability, because even though I'm not worried it will not be accepted (it is actually quite a simple addition, especially in the way that [a libzmq maintainer suggests here](https://github.com/zeromq/libzmq/issues/4220)), delaying this PR to wait for that one will probably result in extra merging efforts for the later RooFit PRs that depend on this one. In any case, if this is the way we must go (and I can totally understand that you would want it this way), I will do my best to split up the other PRs as much as possible, so that those can be merged independently asap and merging conflicts will hopefully be minimized.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8385#issuecomment-870483338
Availability,reliab,reliably,"ou can then adapt RooFitZMQ to that in a new pull request.; ; > Then about the RooFitZMQ option: agreed, I should add an option for that. The only catch is that this PR is part of a bigger series and the ""real"" end-product that should be optional in my opinion is RooFit::MultiProcess, so I wanted to wait with such an option until that PR (hopefully I'll be able to submit that one today). In this PR, RooFitZMQ is not used for anything and later on it will just be a library for RooFit::MultiProcess as well, so there would typically not really be a point for a user to want to build RooFitZMQ but not RooFit::MultiProcess. Do you think in this situation it makes sense to add the option for RooFitZMQ already or should I just do it for RooFit::MultiProcess? So, this option (say `-Droofit_multiprocess=ON`) would activate both RooFit::MultiProcess and RooFitZMQ, and also builtin_zeromq. If RooFitZMQ only makes sense as a support library for RooFit::MultiProcess, it's better to put them together in a single pull request. It will be much easier to ensure everything works together that way.; ; > I think that fail-on-missing is only relevant in case there would be a non built-in option as well, right?. That is not what users generally think. They want `fail-on-missing` to work reliably and make configuration fail if a dependency cannot be met with system packages. The only exceptions to this rule should be LLVM/Clang.; ; > Finally, about git history: makes sense. I can do some reordering before merging. Otherwise, just squashing everything would make sense to me as well. The two independent things here are basically 1) the zmq builtin and 2) RooFitZMQ itself. These could indeed just be two commits, but since nothing really depends on RooFitZMQ at this point, including it with the libzmq builtin in one commit I think would give a clean history as well. Ok, as long as it's possible to use a vanilla zeromq, and the builtin addition is the last commit in the series, it should be ok.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8385#issuecomment-870570029
Deployability,patch,patched,"> So, long story, I hope it is clear. Do you think that given this (temporary) situation, the choice for built-in only is acceptable?. Sorry, but no, this is not acceptable if you ask me. In fact, the need for a patched zeromq raises a big red flag as that may make it not possible to ever use a system version of zeromq if your pull request gets stuck. I agree with Axel that the right course of action is to add the needed functionality to zeromq directly first, then add this work to ROOT. I don't think that time constraints should be used as a way to get hackish code into ROOT. Alternatively, if your addition is really independent to zeromq, you could just add it to the RooFitZMQ library instead, so that you can use the system version of zeromq as is. If in a later version they add your new functionality, you can then adapt RooFitZMQ to that in a new pull request.; ; > Then about the RooFitZMQ option: agreed, I should add an option for that. The only catch is that this PR is part of a bigger series and the ""real"" end-product that should be optional in my opinion is RooFit::MultiProcess, so I wanted to wait with such an option until that PR (hopefully I'll be able to submit that one today). In this PR, RooFitZMQ is not used for anything and later on it will just be a library for RooFit::MultiProcess as well, so there would typically not really be a point for a user to want to build RooFitZMQ but not RooFit::MultiProcess. Do you think in this situation it makes sense to add the option for RooFitZMQ already or should I just do it for RooFit::MultiProcess? So, this option (say `-Droofit_multiprocess=ON`) would activate both RooFit::MultiProcess and RooFitZMQ, and also builtin_zeromq. If RooFitZMQ only makes sense as a support library for RooFit::MultiProcess, it's better to put them together in a single pull request. It will be much easier to ensure everything works together that way.; ; > I think that fail-on-missing is only relevant in case there would be a non built-in",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8385#issuecomment-870570029
Energy Efficiency,adapt,adapt,"> So, long story, I hope it is clear. Do you think that given this (temporary) situation, the choice for built-in only is acceptable?. Sorry, but no, this is not acceptable if you ask me. In fact, the need for a patched zeromq raises a big red flag as that may make it not possible to ever use a system version of zeromq if your pull request gets stuck. I agree with Axel that the right course of action is to add the needed functionality to zeromq directly first, then add this work to ROOT. I don't think that time constraints should be used as a way to get hackish code into ROOT. Alternatively, if your addition is really independent to zeromq, you could just add it to the RooFitZMQ library instead, so that you can use the system version of zeromq as is. If in a later version they add your new functionality, you can then adapt RooFitZMQ to that in a new pull request.; ; > Then about the RooFitZMQ option: agreed, I should add an option for that. The only catch is that this PR is part of a bigger series and the ""real"" end-product that should be optional in my opinion is RooFit::MultiProcess, so I wanted to wait with such an option until that PR (hopefully I'll be able to submit that one today). In this PR, RooFitZMQ is not used for anything and later on it will just be a library for RooFit::MultiProcess as well, so there would typically not really be a point for a user to want to build RooFitZMQ but not RooFit::MultiProcess. Do you think in this situation it makes sense to add the option for RooFitZMQ already or should I just do it for RooFit::MultiProcess? So, this option (say `-Droofit_multiprocess=ON`) would activate both RooFit::MultiProcess and RooFitZMQ, and also builtin_zeromq. If RooFitZMQ only makes sense as a support library for RooFit::MultiProcess, it's better to put them together in a single pull request. It will be much easier to ensure everything works together that way.; ; > I think that fail-on-missing is only relevant in case there would be a non built-in",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8385#issuecomment-870570029
Integrability,depend,dependency,"ou can then adapt RooFitZMQ to that in a new pull request.; ; > Then about the RooFitZMQ option: agreed, I should add an option for that. The only catch is that this PR is part of a bigger series and the ""real"" end-product that should be optional in my opinion is RooFit::MultiProcess, so I wanted to wait with such an option until that PR (hopefully I'll be able to submit that one today). In this PR, RooFitZMQ is not used for anything and later on it will just be a library for RooFit::MultiProcess as well, so there would typically not really be a point for a user to want to build RooFitZMQ but not RooFit::MultiProcess. Do you think in this situation it makes sense to add the option for RooFitZMQ already or should I just do it for RooFit::MultiProcess? So, this option (say `-Droofit_multiprocess=ON`) would activate both RooFit::MultiProcess and RooFitZMQ, and also builtin_zeromq. If RooFitZMQ only makes sense as a support library for RooFit::MultiProcess, it's better to put them together in a single pull request. It will be much easier to ensure everything works together that way.; ; > I think that fail-on-missing is only relevant in case there would be a non built-in option as well, right?. That is not what users generally think. They want `fail-on-missing` to work reliably and make configuration fail if a dependency cannot be met with system packages. The only exceptions to this rule should be LLVM/Clang.; ; > Finally, about git history: makes sense. I can do some reordering before merging. Otherwise, just squashing everything would make sense to me as well. The two independent things here are basically 1) the zmq builtin and 2) RooFitZMQ itself. These could indeed just be two commits, but since nothing really depends on RooFitZMQ at this point, including it with the libzmq builtin in one commit I think would give a clean history as well. Ok, as long as it's possible to use a vanilla zeromq, and the builtin addition is the last commit in the series, it should be ok.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8385#issuecomment-870570029
Modifiability,adapt,adapt,"> So, long story, I hope it is clear. Do you think that given this (temporary) situation, the choice for built-in only is acceptable?. Sorry, but no, this is not acceptable if you ask me. In fact, the need for a patched zeromq raises a big red flag as that may make it not possible to ever use a system version of zeromq if your pull request gets stuck. I agree with Axel that the right course of action is to add the needed functionality to zeromq directly first, then add this work to ROOT. I don't think that time constraints should be used as a way to get hackish code into ROOT. Alternatively, if your addition is really independent to zeromq, you could just add it to the RooFitZMQ library instead, so that you can use the system version of zeromq as is. If in a later version they add your new functionality, you can then adapt RooFitZMQ to that in a new pull request.; ; > Then about the RooFitZMQ option: agreed, I should add an option for that. The only catch is that this PR is part of a bigger series and the ""real"" end-product that should be optional in my opinion is RooFit::MultiProcess, so I wanted to wait with such an option until that PR (hopefully I'll be able to submit that one today). In this PR, RooFitZMQ is not used for anything and later on it will just be a library for RooFit::MultiProcess as well, so there would typically not really be a point for a user to want to build RooFitZMQ but not RooFit::MultiProcess. Do you think in this situation it makes sense to add the option for RooFitZMQ already or should I just do it for RooFit::MultiProcess? So, this option (say `-Droofit_multiprocess=ON`) would activate both RooFit::MultiProcess and RooFitZMQ, and also builtin_zeromq. If RooFitZMQ only makes sense as a support library for RooFit::MultiProcess, it's better to put them together in a single pull request. It will be much easier to ensure everything works together that way.; ; > I think that fail-on-missing is only relevant in case there would be a non built-in",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8385#issuecomment-870570029
Usability,clear,clear,"> So, long story, I hope it is clear. Do you think that given this (temporary) situation, the choice for built-in only is acceptable?. Sorry, but no, this is not acceptable if you ask me. In fact, the need for a patched zeromq raises a big red flag as that may make it not possible to ever use a system version of zeromq if your pull request gets stuck. I agree with Axel that the right course of action is to add the needed functionality to zeromq directly first, then add this work to ROOT. I don't think that time constraints should be used as a way to get hackish code into ROOT. Alternatively, if your addition is really independent to zeromq, you could just add it to the RooFitZMQ library instead, so that you can use the system version of zeromq as is. If in a later version they add your new functionality, you can then adapt RooFitZMQ to that in a new pull request.; ; > Then about the RooFitZMQ option: agreed, I should add an option for that. The only catch is that this PR is part of a bigger series and the ""real"" end-product that should be optional in my opinion is RooFit::MultiProcess, so I wanted to wait with such an option until that PR (hopefully I'll be able to submit that one today). In this PR, RooFitZMQ is not used for anything and later on it will just be a library for RooFit::MultiProcess as well, so there would typically not really be a point for a user to want to build RooFitZMQ but not RooFit::MultiProcess. Do you think in this situation it makes sense to add the option for RooFitZMQ already or should I just do it for RooFit::MultiProcess? So, this option (say `-Droofit_multiprocess=ON`) would activate both RooFit::MultiProcess and RooFitZMQ, and also builtin_zeromq. If RooFitZMQ only makes sense as a support library for RooFit::MultiProcess, it's better to put them together in a single pull request. It will be much easier to ensure everything works together that way.; ; > I think that fail-on-missing is only relevant in case there would be a non built-in",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8385#issuecomment-870570029
Testability,test,test,Hi - this is breaking some more or less urgent ATLAS analyses - if there is any guidance as to what we could test that'd be much appreciated. Thanks!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8387#issuecomment-861315969
Usability,guid,guidance,Hi - this is breaking some more or less urgent ATLAS analyses - if there is any guidance as to what we could test that'd be much appreciated. Thanks!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8387#issuecomment-861315969
Usability,simpl,simply,"@pcanal I have thought of a ""solution"". If we remove the default value, set `event` to 0 in the method itself and simply warn the user that he/she has not provided a value for `event`, the user will know and other classes that rely on the default value of 0 still work.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8425#issuecomment-861618831
Availability,error,error,> `!entry == true` if `entry == 0`: `0` is fals-y in C++. Ohh I didn't know that. Then maybe one could simply check if entry is undefined. Or does that cause the same error?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8425#issuecomment-861667463
Usability,simpl,simply,> `!entry == true` if `entry == 0`: `0` is fals-y in C++. Ohh I didn't know that. Then maybe one could simply check if entry is undefined. Or does that cause the same error?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8425#issuecomment-861667463
Usability,learn,learn,> Thank you very much!. Thank you for your help. I learn something new with every PR :D,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8425#issuecomment-865182237
Safety,avoid,avoid,"Final note: In the commits left on the branch there was a ""merge"" commit, we want to avoid them. When updating your branch with the content of the master branch, please use 'git rebase' rather than `git merge`. Also we tend to prefer to simplify the history by keeping only the effective commits. [For example, in this case, you could (have done)/do `git rebase -i` to remove the commit that was reverse and its reversal :)]. For this PR, I effectively handled these changes by doing a ""merge and squash"" but this works out only for PR that have one effective commit (the case here).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8425#issuecomment-865184527
Usability,simpl,simplify,"Final note: In the commits left on the branch there was a ""merge"" commit, we want to avoid them. When updating your branch with the content of the master branch, please use 'git rebase' rather than `git merge`. Also we tend to prefer to simplify the history by keeping only the effective commits. [For example, in this case, you could (have done)/do `git rebase -i` to remove the commit that was reverse and its reversal :)]. For this PR, I effectively handled these changes by doing a ""merge and squash"" but this works out only for PR that have one effective commit (the case here).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8425#issuecomment-865184527
Safety,avoid,avoid,"> Final note: In the commits left on the branch there was a ""merge"" commit, we want to avoid them. When updating your branch with the content of the master branch, please use 'git rebase' rather than `git merge`. Also we tend to prefer to simplify the history by keeping only the effective commits. [For example, in this case, you could (have done)/do `git rebase -i` to remove the commit that was reverse and its reversal :)].; > ; > For this PR, I effectively handled these changes by doing a ""merge and squash"" but this works out only for PR that have one effective commit (the case here). Ah ok. I recently learned what rebase -i is, so I'll use that next time. Thanks for the tip",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8425#issuecomment-865186362
Usability,simpl,simplify,"> Final note: In the commits left on the branch there was a ""merge"" commit, we want to avoid them. When updating your branch with the content of the master branch, please use 'git rebase' rather than `git merge`. Also we tend to prefer to simplify the history by keeping only the effective commits. [For example, in this case, you could (have done)/do `git rebase -i` to remove the commit that was reverse and its reversal :)].; > ; > For this PR, I effectively handled these changes by doing a ""merge and squash"" but this works out only for PR that have one effective commit (the case here). Ah ok. I recently learned what rebase -i is, so I'll use that next time. Thanks for the tip",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8425#issuecomment-865186362
Usability,learn,learn,Very nice! Interactive rebase is awesome once you learn how to use it! ,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8426#issuecomment-862436129
Usability,learn,learn,"> Very nice! Interactive rebase is awesome once you learn how to use it!. Yeah, it is. Feels like I've been living under a rock hehe",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8426#issuecomment-862436434
Usability,learn,learning,"> Yes they need to be fixed. I could tell you - but what I'd recommend (look, we're teaching you here :-) ) is to copy the warning text, search the Internet, and pick the most helpful posting on StackOverflow: that'll explain you what to do. And it's a key pattern to become a successful developer, it's how all of us fix our warnings. Ahh hehe. Okay, I'll try to fix it :D . Thanks for the learning opportunity",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8426#issuecomment-862486337
Usability,usab,usable,"@eguiraud while i agree with you, my thinking actually was also along having a common code base and also ""a la python"" usage: while there is the option of having an executable doing ""import module, run main function"" one can also do ""python -m module module_args"". so, my proposal was from a point of view of code (common code base, maybe also usable programatically in macros, as part maybe of some generic ROOT toolbox) and the second point of view was of actual usage where maybe `root -verb verb_args` could be easier and clearer to use than `root[verb] args` .. but in the end my proposal was more on the lines of ""wouldn't you (devs) be interested in such a usage/point of view ?"" ; and getting back to python: yes, it is exactly (also) a swiss-army knife like python :) and beside some bash script that i converted to python, i started to see a point of/play with having root scripts (with root in shebang ;) )",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8447#issuecomment-862518127
Testability,test,test,"> Hi @VanyaBelyaev , do you think the fact that you are using RooFit through PyROOT is relevant? Would you be able to test in pure C++ ?. Dear @eguiraud; I am not using RooFit througt C++ . It would be expremently difficult or even impossible for me to conver tmy python stuff into C++.; Note that for simple models I have no problems.; It happens only for multidimensional multicomponent model, when I draw projecton; - first draw data set with `Invisible` flag ; - draw fit components; - draw data with normal vizibility ; ; And it segfaults at the second step. ; The relevant part of the stack is here: . ```. The lines below might hint at the cause of the crash.; You may get help by asking at the ROOT forum https://root.cern.ch/forum; Only if you are really convinced it is a bug in ROOT then please submit a; report at https://root.cern.ch/bugs Please post the ENTIRE stack trace; from above as an attachment in addition to anything else; that might help us fixing this issue.; ===========================================================; #7 0x00007f36325eec01 in (anonymous namespace)::removeCommon(std::vector<RooAbsArg*, std::allocator<RooAbsArg*> >&, std::__ROOT::span<RooAbsArg* const>) () from /cvmfs/sft-nightlies.cern.ch/lcg/nightlies/dev3/Fri/ROOT/HEAD/x86_64-centos7-gcc9-opt/lib/libRooFitCore.so; #8 0x00007f36325f2568 in RooProdPdf::factorizeProduct(RooArgSet const&, RooArgSet const&, RooLinkedList&, RooLinkedList&, RooLinkedList&, RooLinkedList&, RooLinkedList&) const () from /cvmfs/sft-nightlies.cern.ch/lcg/nightlies/dev3/Fri/ROOT/HEAD/x86_64-centos7-gcc9-opt/lib/libRooFitCore.so; #9 0x00007f36325f94b9 in RooProdPdf::getPartIntList(RooArgSet const*, RooArgSet const*, char const*) const () from /cvmfs/sft-nightlies.cern.ch/lcg/nightlies/dev3/Fri/ROOT/HEAD/x86_64-centos7-gcc9-opt/lib/libRooFitCore.so; #10 0x00007f36325fd52e in RooProdPdf::getAnalyticalIntegralWN(RooArgSet&, RooArgSet&, RooArgSet const*, char const*) const () from /cvmfs/sft-nightlies.cern.ch/lcg/nightli",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8474#issuecomment-864062658
Usability,simpl,simple,"> Hi @VanyaBelyaev , do you think the fact that you are using RooFit through PyROOT is relevant? Would you be able to test in pure C++ ?. Dear @eguiraud; I am not using RooFit througt C++ . It would be expremently difficult or even impossible for me to conver tmy python stuff into C++.; Note that for simple models I have no problems.; It happens only for multidimensional multicomponent model, when I draw projecton; - first draw data set with `Invisible` flag ; - draw fit components; - draw data with normal vizibility ; ; And it segfaults at the second step. ; The relevant part of the stack is here: . ```. The lines below might hint at the cause of the crash.; You may get help by asking at the ROOT forum https://root.cern.ch/forum; Only if you are really convinced it is a bug in ROOT then please submit a; report at https://root.cern.ch/bugs Please post the ENTIRE stack trace; from above as an attachment in addition to anything else; that might help us fixing this issue.; ===========================================================; #7 0x00007f36325eec01 in (anonymous namespace)::removeCommon(std::vector<RooAbsArg*, std::allocator<RooAbsArg*> >&, std::__ROOT::span<RooAbsArg* const>) () from /cvmfs/sft-nightlies.cern.ch/lcg/nightlies/dev3/Fri/ROOT/HEAD/x86_64-centos7-gcc9-opt/lib/libRooFitCore.so; #8 0x00007f36325f2568 in RooProdPdf::factorizeProduct(RooArgSet const&, RooArgSet const&, RooLinkedList&, RooLinkedList&, RooLinkedList&, RooLinkedList&, RooLinkedList&) const () from /cvmfs/sft-nightlies.cern.ch/lcg/nightlies/dev3/Fri/ROOT/HEAD/x86_64-centos7-gcc9-opt/lib/libRooFitCore.so; #9 0x00007f36325f94b9 in RooProdPdf::getPartIntList(RooArgSet const*, RooArgSet const*, char const*) const () from /cvmfs/sft-nightlies.cern.ch/lcg/nightlies/dev3/Fri/ROOT/HEAD/x86_64-centos7-gcc9-opt/lib/libRooFitCore.so; #10 0x00007f36325fd52e in RooProdPdf::getAnalyticalIntegralWN(RooArgSet&, RooArgSet&, RooArgSet const*, char const*) const () from /cvmfs/sft-nightlies.cern.ch/lcg/nightli",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8474#issuecomment-864062658
Usability,guid,guidelines,"Hi @VanyaBelyaev, yes the stack trace with a debug build is indeed helpful because of the line numbers. Seeing that `RooProdPdf::factorizeProduct` is involved, I am sure that the recently merged PR https://github.com/root-project/root/pull/7907 causes your problem. No need for a C++ producer then, this problem has nothing to do with pyROOT. But even knowing that, I don't know enough about the problem to solve it. Do you mind sharing your RooFit code that produces the problem? Even better of course with the data, but I understand if you can't share it because of the guidelines of your experiment. But even without the data, seeing the RooFit model would be super helpful for me to understand how the RooProdPdf enters the game. Thanks!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8474#issuecomment-864089572
Testability,test,test,"Dear Jonas @guitargeek . my PDF is just a simple 3D functon in each dimenstion is is just a Gaussian + linear polynomial. In total one has 8 components: SSS + SSB + SBS + BSS + SBB + BSB + BBS + BBB . Creation of the function is done via my ostap project. https://github.com/OstapHEP/ostap ; You can see the actual (failing) test code in ; https://github.com/OstapHEP/ostap/blob/master/ostap/fitting/tests/test_fitting_components_3D.py; It does not rely any external data - all data is produced internally ; It is a bit more complicated that is actually needed, since the initial purpose of this particular test fiel was to see the change of the fit resutls with addion ""additional"" components mixed to the the base line model. ; But it relies on ""external"" project https://github.com/OstapHEP/ostap . cheers, Vanya. P.S. I'll provide the stack with debug build tomorrow",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8474#issuecomment-864243565
Usability,simpl,simple,"Dear Jonas @guitargeek . my PDF is just a simple 3D functon in each dimenstion is is just a Gaussian + linear polynomial. In total one has 8 components: SSS + SSB + SBS + BSS + SBB + BSB + BBS + BBB . Creation of the function is done via my ostap project. https://github.com/OstapHEP/ostap ; You can see the actual (failing) test code in ; https://github.com/OstapHEP/ostap/blob/master/ostap/fitting/tests/test_fitting_components_3D.py; It does not rely any external data - all data is produced internally ; It is a bit more complicated that is actually needed, since the initial purpose of this particular test fiel was to see the change of the fit resutls with addion ""additional"" components mixed to the the base line model. ; But it relies on ""external"" project https://github.com/OstapHEP/ostap . cheers, Vanya. P.S. I'll provide the stack with debug build tomorrow",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8474#issuecomment-864243565
Deployability,patch,patch,"Hi, the patch will be applied in a matter of days. Possibly even on Monday because it is a simple change.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8474#issuecomment-864414030
Usability,simpl,simple,"Hi, the patch will be applied in a matter of days. Possibly even on Monday because it is a simple change.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8474#issuecomment-864414030
Usability,feedback,feedback,"Hallo Jonas,. thanks a lot for the feedback! My initial interest was to measure the speed of the new implementation. . I have now checked Section 2.3 of [your paper](https://arxiv.org/pdf/2106.02504.pdf) and I have missed this important point! I will add this to my code. . Thanks for the review.; Jirka",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8504#issuecomment-866145966
Usability,guid,guide,"I see some parameters in these header files are commented but not in the doxygen format. I can improve that to make the comments appear in the reference guide. But when the documentation is completely missing, an expert for these classes is needed. I think @lmoneta should be able to add the missing doc or ask somebody who knows about it to improve the documentation.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8507#issuecomment-865994950
Deployability,continuous,continuous,"Thanks, Philippe. I added that information to the old thread on the forum. I also found what you were saying in the manual (so it is present somewhere in the documentation, though I usually read the reference guide).; About my initial feature request: I think this is a continuous wish of users to have a vector for ints (and other types) when you have a vector for doubles. So it's up to you whether you add this support or not (me personally no longer need that).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8517#issuecomment-867417636
Usability,guid,guide,"Thanks, Philippe. I added that information to the old thread on the forum. I also found what you were saying in the manual (so it is present somewhere in the documentation, though I usually read the reference guide).; About my initial feature request: I think this is a continuous wish of users to have a vector for ints (and other types) when you have a vector for doubles. So it's up to you whether you add this support or not (me personally no longer need that).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8517#issuecomment-867417636
Usability,simpl,simple,"It seems to be a doxygen issue. I submitted an issue, with a simple reproducer, in the doxygen repository: ; https://github.com/doxygen/doxygen/issues/8620",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8533#issuecomment-868348530
Usability,feedback,feedback,"Hi @guitargeek @lmoneta @dpiparo,; I would really benefit if this feature were merged, as I need it for my project. Any feedback to my observations on https://github.com/root-project/root/pull/8546#issuecomment-1814425550 ?; Thanks in advance.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8546#issuecomment-1895306674
Usability,simpl,simply,"@hageboeck Thanks for the extensive review! I will implement some changes based on that and @guitargeek's comments today. In the meantime, perhaps it would be useful to check out #8596 as well. That PR introduces the second concrete MinimizerFcn. Possibly, seeing `RooAbsMinimizerFcn` ""in action"" through that new class (`RooGradMinimizerFcn`) will shed a different light on the design choices for this abstract class. Basically, we previously just had two classes, `RooMinimizerFcn` and `RooGradMinimizerFcn` (and then later on **another** one, which will be introduced in another PR this week) with tons of code duplication. `RooAbsMinimizerFcn` simply factors that stuff out into one class.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8569#issuecomment-874002788
Usability,clear,clear,Just coming back to the issue. It is not clear to me whether we can close it as clarified or if some feature is still needed. @ferdymercury could you chime in?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8582#issuecomment-1925302611
Usability,feedback,feedback,OK closing then - thanks for the feedback @mxxo and @eguiraud . @eguiraud let me know if there's some other action you'd like me to do!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8587#issuecomment-873050997
Integrability,depend,depending,"Hi Patrick, thanks for the explanation, things make more sense for me now! Interesting that you also experimented with making the full RooAbsMinimizer templated. I agree that making the RooAbsMinimizer a templated class is not the best solution, but I still think we can even avoid the templated constructor, making the code more clear and reducing compile time/binary size. You already have this nice `FcnMode` enum class which I think is great because enum class is typesafe while enum is not. Taking this enum, you could have a RooMinimizer constructor with the signature:; ```; RooMinimizer(RooAbsReal &function, FcnMode fcnMode);; ```; Then depending on `fcnMode`, you can create the correct function instance. You would not even have to check for the `logic_error`, because with the enum class is is ensured that the value is either `classic` or `gradient`. You would just need a little helper struct to make the `RooMinimizer::create()` function work, something to translate from the function class to the FcnMode:. ```C++; class RooMinimizer { ; ; ... ; private: ; ; template <typename MinimizerFcn ; struct GetFcnMode { ; static const FcnMode value = FcnMode::classic; ; }; ; ; ... ; ; } ; ; ; template<> ; struct RooMinimizer::GetFcnMode<RooGradMinimizerFcn> { ; static const FcnMode value = FcnMode::gradient; ; }; ; ; ; // static function ; template <typename MinimizerFcn> ; std::unique_ptr<RooMinimizer> RooMinimizer::create(RooAbsReal &function) { ; return std::make_unique<RooMinimizer>(function, GetFcnMode<MinimizerFcn>::value); ; } ; ```. Would this approach also work with your upcoming developments?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8596#issuecomment-879770741
Safety,avoid,avoid,"Hi Patrick, thanks for the explanation, things make more sense for me now! Interesting that you also experimented with making the full RooAbsMinimizer templated. I agree that making the RooAbsMinimizer a templated class is not the best solution, but I still think we can even avoid the templated constructor, making the code more clear and reducing compile time/binary size. You already have this nice `FcnMode` enum class which I think is great because enum class is typesafe while enum is not. Taking this enum, you could have a RooMinimizer constructor with the signature:; ```; RooMinimizer(RooAbsReal &function, FcnMode fcnMode);; ```; Then depending on `fcnMode`, you can create the correct function instance. You would not even have to check for the `logic_error`, because with the enum class is is ensured that the value is either `classic` or `gradient`. You would just need a little helper struct to make the `RooMinimizer::create()` function work, something to translate from the function class to the FcnMode:. ```C++; class RooMinimizer { ; ; ... ; private: ; ; template <typename MinimizerFcn ; struct GetFcnMode { ; static const FcnMode value = FcnMode::classic; ; }; ; ; ... ; ; } ; ; ; template<> ; struct RooMinimizer::GetFcnMode<RooGradMinimizerFcn> { ; static const FcnMode value = FcnMode::gradient; ; }; ; ; ; // static function ; template <typename MinimizerFcn> ; std::unique_ptr<RooMinimizer> RooMinimizer::create(RooAbsReal &function) { ; return std::make_unique<RooMinimizer>(function, GetFcnMode<MinimizerFcn>::value); ; } ; ```. Would this approach also work with your upcoming developments?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8596#issuecomment-879770741
Usability,clear,clear,"Hi Patrick, thanks for the explanation, things make more sense for me now! Interesting that you also experimented with making the full RooAbsMinimizer templated. I agree that making the RooAbsMinimizer a templated class is not the best solution, but I still think we can even avoid the templated constructor, making the code more clear and reducing compile time/binary size. You already have this nice `FcnMode` enum class which I think is great because enum class is typesafe while enum is not. Taking this enum, you could have a RooMinimizer constructor with the signature:; ```; RooMinimizer(RooAbsReal &function, FcnMode fcnMode);; ```; Then depending on `fcnMode`, you can create the correct function instance. You would not even have to check for the `logic_error`, because with the enum class is is ensured that the value is either `classic` or `gradient`. You would just need a little helper struct to make the `RooMinimizer::create()` function work, something to translate from the function class to the FcnMode:. ```C++; class RooMinimizer { ; ; ... ; private: ; ; template <typename MinimizerFcn ; struct GetFcnMode { ; static const FcnMode value = FcnMode::classic; ; }; ; ; ... ; ; } ; ; ; template<> ; struct RooMinimizer::GetFcnMode<RooGradMinimizerFcn> { ; static const FcnMode value = FcnMode::gradient; ; }; ; ; ; // static function ; template <typename MinimizerFcn> ; std::unique_ptr<RooMinimizer> RooMinimizer::create(RooAbsReal &function) { ; return std::make_unique<RooMinimizer>(function, GetFcnMode<MinimizerFcn>::value); ; } ; ```. Would this approach also work with your upcoming developments?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8596#issuecomment-879770741
Usability,simpl,simply,So commenting that line cures the problem with your initial macro . Now I need to understand why that line was put there and why it changes the axis attributes of your histogram ! ... I invite @osschar to this discussion as he is the author of this code (https://github.com/root-project/root/blob/master/graf3d/gl/src/TGLAxisPainter.cxx#L574) . I am temped to simply comment the line but that's weird as fAxis is [a member of TGLAxisPainterBox](https://github.com/root-project/root/blob/aa21d63ca3a1f4cdb2b559e4cb1c2c2d7eb65f34/graf3d/gl/inc/TGLAxisPainter.h#L145) and that should not affect the axis of your TH2F ... That's a real puzzle ...,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8618#issuecomment-875425406
Usability,clear,clearly,"I see, ... so that's clearly a bug in that case, the 3D viewer should not change the axis attributes silently ...; I am in favour to remove that line ..",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8618#issuecomment-875477436
Usability,simpl,simple,"I got a similar warning when using `RDataFrame` in Python, presumably due to the same problem:. I'm using ROOT 6.24.02 with gcc10, compiled w/ C++ 17 standard. Here's a reproducer:; ```python; #!/usr/bin/env python. import ROOT. # Let's create a simple dataframe with ten rows and two columns; df = ROOT.RDataFrame(10) \; .Define(""x"", ""(int)rdfentry_"") \; .Define(""y"", ""1.f/(1.f+rdfentry_)""). npy = df.AsNumpy(); ``` . The warnings are:; ```; input_line_49:10:7: warning: ignoring return value of function declared with 'nodiscard' attribute [-Wunused-result]; ((const vector<int>*)obj)->empty();; ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~; input_line_56:10:7: warning: ignoring return value of function declared with 'nodiscard' attribute [-Wunused-result]; ((const vector<float>*)obj)->empty();; ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~; ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8622#issuecomment-889485521
Deployability,integrat,integrated,"Thanks, @egpbos and @jspaaks ! Validation succeeds now. > suggest to add a GitHub Actions workflow. AFAICT we need this to be integrated with our release workflow. Once that's a GH Action we can also migrate the `CITATION.cff` generation and validation there. I *think* it's fairly hard to break the file given that it's generated by a script; I also dislike the pile of dependencies of `cffconvert` for a simple thing like validation, IMO it's too heavy to add it to the script producing `CITATION.cff`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8626#issuecomment-876311455
Integrability,integrat,integrated,"Thanks, @egpbos and @jspaaks ! Validation succeeds now. > suggest to add a GitHub Actions workflow. AFAICT we need this to be integrated with our release workflow. Once that's a GH Action we can also migrate the `CITATION.cff` generation and validation there. I *think* it's fairly hard to break the file given that it's generated by a script; I also dislike the pile of dependencies of `cffconvert` for a simple thing like validation, IMO it's too heavy to add it to the script producing `CITATION.cff`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8626#issuecomment-876311455
Security,validat,validation,"Thanks, @egpbos and @jspaaks ! Validation succeeds now. > suggest to add a GitHub Actions workflow. AFAICT we need this to be integrated with our release workflow. Once that's a GH Action we can also migrate the `CITATION.cff` generation and validation there. I *think* it's fairly hard to break the file given that it's generated by a script; I also dislike the pile of dependencies of `cffconvert` for a simple thing like validation, IMO it's too heavy to add it to the script producing `CITATION.cff`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8626#issuecomment-876311455
Usability,simpl,simple,"Thanks, @egpbos and @jspaaks ! Validation succeeds now. > suggest to add a GitHub Actions workflow. AFAICT we need this to be integrated with our release workflow. Once that's a GH Action we can also migrate the `CITATION.cff` generation and validation there. I *think* it's fairly hard to break the file given that it's generated by a script; I also dislike the pile of dependencies of `cffconvert` for a simple thing like validation, IMO it's too heavy to add it to the script producing `CITATION.cff`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8626#issuecomment-876311455
Availability,fault,fault,"> I don't think ROOT is at fault here for relying on this feature of CMake. As described in the blob post by a CMake maintainer (emphasis is mine):. > Even if find_package() were only redefined once though, it would still be relying on **undocumented** CMake behavior which may be modified or removed completely in a future version. Reliance on such behavior should be discouraged and as the above discussion shows, the technique is not safe to use in general. It's mostly sad that vcpkg did the same trick, making ROOT incompatible with it. Given the circumstances I think this cannot be fixed at the moment, since neither ROOT nor vcpkg can easily change and I also don't expect CMake to make such behavior defined and allow overriding build-ins multiple times. So I guess we need to close this is won't-fix?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8633#issuecomment-898355331
Safety,safe,safe,"> I don't think ROOT is at fault here for relying on this feature of CMake. As described in the blob post by a CMake maintainer (emphasis is mine):. > Even if find_package() were only redefined once though, it would still be relying on **undocumented** CMake behavior which may be modified or removed completely in a future version. Reliance on such behavior should be discouraged and as the above discussion shows, the technique is not safe to use in general. It's mostly sad that vcpkg did the same trick, making ROOT incompatible with it. Given the circumstances I think this cannot be fixed at the moment, since neither ROOT nor vcpkg can easily change and I also don't expect CMake to make such behavior defined and allow overriding build-ins multiple times. So I guess we need to close this is won't-fix?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8633#issuecomment-898355331
Usability,undo,undocumented,"> I don't think ROOT is at fault here for relying on this feature of CMake. As described in the blob post by a CMake maintainer (emphasis is mine):. > Even if find_package() were only redefined once though, it would still be relying on **undocumented** CMake behavior which may be modified or removed completely in a future version. Reliance on such behavior should be discouraged and as the above discussion shows, the technique is not safe to use in general. It's mostly sad that vcpkg did the same trick, making ROOT incompatible with it. Given the circumstances I think this cannot be fixed at the moment, since neither ROOT nor vcpkg can easily change and I also don't expect CMake to make such behavior defined and allow overriding build-ins multiple times. So I guess we need to close this is won't-fix?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8633#issuecomment-898355331
Integrability,depend,dependencies,"Here is a relevant [issue](https://gitlab.kitware.com/cmake/cmake/-/issues/17735) where this is discussed more in depth. One of the [comments](https://gitlab.kitware.com/cmake/cmake/-/issues/17735#note_487572) in this issue explains the rationale behind overriding `find_package` quite well. If there is a better solution that can work the way the current solution does (i.e. works also for LLVM without having to change its calls to `find_package(ZLIB)`, for example), we can implement it. However, so far I have not found a another way to do it. Maybe now that the required version of CMake is newer than 3.11, we may be able to improve things by using the [FetchContent](https://cmake.org/cmake/help/latest/module/FetchContent.html) module. It may also be possible to use [CMAKE_DISABLE_FIND_\<PackageName\>](https://cmake.org/cmake/help/v3.10/variable/CMAKE_DISABLE_FIND_PACKAGE_PackageName.html) to skip checking for packages if that doesn't force packages to be considered not found when `<PackageName_FOUND>` is then also set by hand. The reality, though, is that CMake still kinda sucks for managing optionally bundled dependencies like ROOT wants to support. As for the undocumented nature of the feature, it's sad but, like the [CDash test measurements](https://cmake.org/cmake/help/latest/command/ctest_test.html?#additional-test-measurements) that were undocumented for a long time, if you offer it, people will try to use it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8633#issuecomment-898406007
Modifiability,variab,variable,"Here is a relevant [issue](https://gitlab.kitware.com/cmake/cmake/-/issues/17735) where this is discussed more in depth. One of the [comments](https://gitlab.kitware.com/cmake/cmake/-/issues/17735#note_487572) in this issue explains the rationale behind overriding `find_package` quite well. If there is a better solution that can work the way the current solution does (i.e. works also for LLVM without having to change its calls to `find_package(ZLIB)`, for example), we can implement it. However, so far I have not found a another way to do it. Maybe now that the required version of CMake is newer than 3.11, we may be able to improve things by using the [FetchContent](https://cmake.org/cmake/help/latest/module/FetchContent.html) module. It may also be possible to use [CMAKE_DISABLE_FIND_\<PackageName\>](https://cmake.org/cmake/help/v3.10/variable/CMAKE_DISABLE_FIND_PACKAGE_PackageName.html) to skip checking for packages if that doesn't force packages to be considered not found when `<PackageName_FOUND>` is then also set by hand. The reality, though, is that CMake still kinda sucks for managing optionally bundled dependencies like ROOT wants to support. As for the undocumented nature of the feature, it's sad but, like the [CDash test measurements](https://cmake.org/cmake/help/latest/command/ctest_test.html?#additional-test-measurements) that were undocumented for a long time, if you offer it, people will try to use it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8633#issuecomment-898406007
Testability,test,test,"Here is a relevant [issue](https://gitlab.kitware.com/cmake/cmake/-/issues/17735) where this is discussed more in depth. One of the [comments](https://gitlab.kitware.com/cmake/cmake/-/issues/17735#note_487572) in this issue explains the rationale behind overriding `find_package` quite well. If there is a better solution that can work the way the current solution does (i.e. works also for LLVM without having to change its calls to `find_package(ZLIB)`, for example), we can implement it. However, so far I have not found a another way to do it. Maybe now that the required version of CMake is newer than 3.11, we may be able to improve things by using the [FetchContent](https://cmake.org/cmake/help/latest/module/FetchContent.html) module. It may also be possible to use [CMAKE_DISABLE_FIND_\<PackageName\>](https://cmake.org/cmake/help/v3.10/variable/CMAKE_DISABLE_FIND_PACKAGE_PackageName.html) to skip checking for packages if that doesn't force packages to be considered not found when `<PackageName_FOUND>` is then also set by hand. The reality, though, is that CMake still kinda sucks for managing optionally bundled dependencies like ROOT wants to support. As for the undocumented nature of the feature, it's sad but, like the [CDash test measurements](https://cmake.org/cmake/help/latest/command/ctest_test.html?#additional-test-measurements) that were undocumented for a long time, if you offer it, people will try to use it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8633#issuecomment-898406007
Usability,undo,undocumented,"Here is a relevant [issue](https://gitlab.kitware.com/cmake/cmake/-/issues/17735) where this is discussed more in depth. One of the [comments](https://gitlab.kitware.com/cmake/cmake/-/issues/17735#note_487572) in this issue explains the rationale behind overriding `find_package` quite well. If there is a better solution that can work the way the current solution does (i.e. works also for LLVM without having to change its calls to `find_package(ZLIB)`, for example), we can implement it. However, so far I have not found a another way to do it. Maybe now that the required version of CMake is newer than 3.11, we may be able to improve things by using the [FetchContent](https://cmake.org/cmake/help/latest/module/FetchContent.html) module. It may also be possible to use [CMAKE_DISABLE_FIND_\<PackageName\>](https://cmake.org/cmake/help/v3.10/variable/CMAKE_DISABLE_FIND_PACKAGE_PackageName.html) to skip checking for packages if that doesn't force packages to be considered not found when `<PackageName_FOUND>` is then also set by hand. The reality, though, is that CMake still kinda sucks for managing optionally bundled dependencies like ROOT wants to support. As for the undocumented nature of the feature, it's sad but, like the [CDash test measurements](https://cmake.org/cmake/help/latest/command/ctest_test.html?#additional-test-measurements) that were undocumented for a long time, if you offer it, people will try to use it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8633#issuecomment-898406007
Deployability,update,update,"> Profiles of RNTuple benchmarks (`iotools/cms, lhcb`) showed ~10-20% of; > total runtime is due to allocations in `RPageSource::UnsealPage`. @mxxo @jblomer This work will be resumed soon as we suspect that not reusing addresses is affecting RDMA data transfers (which has an impact on the measured throughput in the DAOS backend). Specifically, we need to confirm that not reusing addresses that appear in the IOVs array in `daos_obj_{fetch,update}()` is related to a higher overhead due to RDMA MR registration. Therefore, this PR might actually have some other side benefits besides reducing memory allocations and heap fragmentation.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8634#issuecomment-1300054951
Performance,throughput,throughput,"> Profiles of RNTuple benchmarks (`iotools/cms, lhcb`) showed ~10-20% of; > total runtime is due to allocations in `RPageSource::UnsealPage`. @mxxo @jblomer This work will be resumed soon as we suspect that not reusing addresses is affecting RDMA data transfers (which has an impact on the measured throughput in the DAOS backend). Specifically, we need to confirm that not reusing addresses that appear in the IOVs array in `daos_obj_{fetch,update}()` is related to a higher overhead due to RDMA MR registration. Therefore, this PR might actually have some other side benefits besides reducing memory allocations and heap fragmentation.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8634#issuecomment-1300054951
Testability,benchmark,benchmarks,"> Profiles of RNTuple benchmarks (`iotools/cms, lhcb`) showed ~10-20% of; > total runtime is due to allocations in `RPageSource::UnsealPage`. @mxxo @jblomer This work will be resumed soon as we suspect that not reusing addresses is affecting RDMA data transfers (which has an impact on the measured throughput in the DAOS backend). Specifically, we need to confirm that not reusing addresses that appear in the IOVs array in `daos_obj_{fetch,update}()` is related to a higher overhead due to RDMA MR registration. Therefore, this PR might actually have some other side benefits besides reducing memory allocations and heap fragmentation.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8634#issuecomment-1300054951
Usability,resume,resumed,"> Profiles of RNTuple benchmarks (`iotools/cms, lhcb`) showed ~10-20% of; > total runtime is due to allocations in `RPageSource::UnsealPage`. @mxxo @jblomer This work will be resumed soon as we suspect that not reusing addresses is affecting RDMA data transfers (which has an impact on the measured throughput in the DAOS backend). Specifically, we need to confirm that not reusing addresses that appear in the IOVs array in `daos_obj_{fetch,update}()` is related to a higher overhead due to RDMA MR registration. Therefore, this PR might actually have some other side benefits besides reducing memory allocations and heap fragmentation.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8634#issuecomment-1300054951
Deployability,update,update,"> @mxxo @jblomer This work will be resumed soon as we suspect that not reusing addresses is affecting RDMA data transfers (which has an impact on the measured throughput in the DAOS backend). Specifically, we need to confirm that not reusing addresses that appear in the IOVs array in `daos_obj_{fetch,update}()` is related to a higher overhead due to RDMA MR registration. Also, as discussed with @jblomer, this is a separate problem that will be addressed in a separate PR if need be (CC: also FYI, @glmiotto :-)).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8634#issuecomment-1424850942
Performance,throughput,throughput,"> @mxxo @jblomer This work will be resumed soon as we suspect that not reusing addresses is affecting RDMA data transfers (which has an impact on the measured throughput in the DAOS backend). Specifically, we need to confirm that not reusing addresses that appear in the IOVs array in `daos_obj_{fetch,update}()` is related to a higher overhead due to RDMA MR registration. Also, as discussed with @jblomer, this is a separate problem that will be addressed in a separate PR if need be (CC: also FYI, @glmiotto :-)).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8634#issuecomment-1424850942
Usability,resume,resumed,"> @mxxo @jblomer This work will be resumed soon as we suspect that not reusing addresses is affecting RDMA data transfers (which has an impact on the measured throughput in the DAOS backend). Specifically, we need to confirm that not reusing addresses that appear in the IOVs array in `daos_obj_{fetch,update}()` is related to a higher overhead due to RDMA MR registration. Also, as discussed with @jblomer, this is a separate problem that will be addressed in a separate PR if need be (CC: also FYI, @glmiotto :-)).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8634#issuecomment-1424850942
Availability,down,downsides,"Regarding the titular issue, I have been thinking about it for a bit and I don't think we can do much better than what @pieterdavid already implemented. Solutions considered:. 1. Implicitly converting `TClonesArrays` to `RVecs` would be a) backward-incompatible and b) a silent perf degradation, as it requires a copy. Moreover, if we did this I don't see a migration path that doesn't require that users revise all their TClonesArrays-related logic; 2. Adding a `TClonesArrays2RVec` helper function: it would require a copy (or it would have to return a clunky `RVec<T*>`). It is also trivial to implement for users that need it and don't mind the downsides.; 3. Adding a RDF toggle to tweak ""read TClonesArrays as RVecs"" or not: requires adding a bunch of extra logic to the column-reading mechanism for a feature that might end up being mostly unused (modern data models don't use TClonesArrays), and it would require the extra copy (i.e. silent performance degradation). The best seems to be 3, but feature toggles complicate internals and are typically not easy to discover (might end up mostly unused). It seems simpler to ask users to explicitly do the conversion in a `Redefine` if they need/want to. Sorry I could not come up with something nice :confused: . I will close this in a few days unless people have something against it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8644#issuecomment-883552286
Deployability,toggle,toggle,"Regarding the titular issue, I have been thinking about it for a bit and I don't think we can do much better than what @pieterdavid already implemented. Solutions considered:. 1. Implicitly converting `TClonesArrays` to `RVecs` would be a) backward-incompatible and b) a silent perf degradation, as it requires a copy. Moreover, if we did this I don't see a migration path that doesn't require that users revise all their TClonesArrays-related logic; 2. Adding a `TClonesArrays2RVec` helper function: it would require a copy (or it would have to return a clunky `RVec<T*>`). It is also trivial to implement for users that need it and don't mind the downsides.; 3. Adding a RDF toggle to tweak ""read TClonesArrays as RVecs"" or not: requires adding a bunch of extra logic to the column-reading mechanism for a feature that might end up being mostly unused (modern data models don't use TClonesArrays), and it would require the extra copy (i.e. silent performance degradation). The best seems to be 3, but feature toggles complicate internals and are typically not easy to discover (might end up mostly unused). It seems simpler to ask users to explicitly do the conversion in a `Redefine` if they need/want to. Sorry I could not come up with something nice :confused: . I will close this in a few days unless people have something against it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8644#issuecomment-883552286
Performance,perform,performance,"Regarding the titular issue, I have been thinking about it for a bit and I don't think we can do much better than what @pieterdavid already implemented. Solutions considered:. 1. Implicitly converting `TClonesArrays` to `RVecs` would be a) backward-incompatible and b) a silent perf degradation, as it requires a copy. Moreover, if we did this I don't see a migration path that doesn't require that users revise all their TClonesArrays-related logic; 2. Adding a `TClonesArrays2RVec` helper function: it would require a copy (or it would have to return a clunky `RVec<T*>`). It is also trivial to implement for users that need it and don't mind the downsides.; 3. Adding a RDF toggle to tweak ""read TClonesArrays as RVecs"" or not: requires adding a bunch of extra logic to the column-reading mechanism for a feature that might end up being mostly unused (modern data models don't use TClonesArrays), and it would require the extra copy (i.e. silent performance degradation). The best seems to be 3, but feature toggles complicate internals and are typically not easy to discover (might end up mostly unused). It seems simpler to ask users to explicitly do the conversion in a `Redefine` if they need/want to. Sorry I could not come up with something nice :confused: . I will close this in a few days unless people have something against it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8644#issuecomment-883552286
Testability,log,logic,"Regarding the titular issue, I have been thinking about it for a bit and I don't think we can do much better than what @pieterdavid already implemented. Solutions considered:. 1. Implicitly converting `TClonesArrays` to `RVecs` would be a) backward-incompatible and b) a silent perf degradation, as it requires a copy. Moreover, if we did this I don't see a migration path that doesn't require that users revise all their TClonesArrays-related logic; 2. Adding a `TClonesArrays2RVec` helper function: it would require a copy (or it would have to return a clunky `RVec<T*>`). It is also trivial to implement for users that need it and don't mind the downsides.; 3. Adding a RDF toggle to tweak ""read TClonesArrays as RVecs"" or not: requires adding a bunch of extra logic to the column-reading mechanism for a feature that might end up being mostly unused (modern data models don't use TClonesArrays), and it would require the extra copy (i.e. silent performance degradation). The best seems to be 3, but feature toggles complicate internals and are typically not easy to discover (might end up mostly unused). It seems simpler to ask users to explicitly do the conversion in a `Redefine` if they need/want to. Sorry I could not come up with something nice :confused: . I will close this in a few days unless people have something against it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8644#issuecomment-883552286
Usability,simpl,simpler,"Regarding the titular issue, I have been thinking about it for a bit and I don't think we can do much better than what @pieterdavid already implemented. Solutions considered:. 1. Implicitly converting `TClonesArrays` to `RVecs` would be a) backward-incompatible and b) a silent perf degradation, as it requires a copy. Moreover, if we did this I don't see a migration path that doesn't require that users revise all their TClonesArrays-related logic; 2. Adding a `TClonesArrays2RVec` helper function: it would require a copy (or it would have to return a clunky `RVec<T*>`). It is also trivial to implement for users that need it and don't mind the downsides.; 3. Adding a RDF toggle to tweak ""read TClonesArrays as RVecs"" or not: requires adding a bunch of extra logic to the column-reading mechanism for a feature that might end up being mostly unused (modern data models don't use TClonesArrays), and it would require the extra copy (i.e. silent performance degradation). The best seems to be 3, but feature toggles complicate internals and are typically not easy to discover (might end up mostly unused). It seems simpler to ask users to explicitly do the conversion in a `Redefine` if they need/want to. Sorry I could not come up with something nice :confused: . I will close this in a few days unless people have something against it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8644#issuecomment-883552286
Availability,redundant,redundant,"> I understand this will be simplified when we can pass a configuration object to RDataFrame where we specify the range. When reading trees/chains, I'm not sure the configuration object will allow anything more than what we can already do with TEntryLists?. IIUC the redundant info is that `globalend = globalstart + (localends - localstarts).sum()` (i.e. we could avoid passing `globalend`). However: do you still need `globalstart` and `globalend` at all when using TEntryLists?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8646#issuecomment-895318380
Deployability,configurat,configuration,"> I understand this will be simplified when we can pass a configuration object to RDataFrame where we specify the range. When reading trees/chains, I'm not sure the configuration object will allow anything more than what we can already do with TEntryLists?. IIUC the redundant info is that `globalend = globalstart + (localends - localstarts).sum()` (i.e. we could avoid passing `globalend`). However: do you still need `globalstart` and `globalend` at all when using TEntryLists?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8646#issuecomment-895318380
Modifiability,config,configuration,"> I understand this will be simplified when we can pass a configuration object to RDataFrame where we specify the range. When reading trees/chains, I'm not sure the configuration object will allow anything more than what we can already do with TEntryLists?. IIUC the redundant info is that `globalend = globalstart + (localends - localstarts).sum()` (i.e. we could avoid passing `globalend`). However: do you still need `globalstart` and `globalend` at all when using TEntryLists?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8646#issuecomment-895318380
Safety,redund,redundant,"> I understand this will be simplified when we can pass a configuration object to RDataFrame where we specify the range. When reading trees/chains, I'm not sure the configuration object will allow anything more than what we can already do with TEntryLists?. IIUC the redundant info is that `globalend = globalstart + (localends - localstarts).sum()` (i.e. we could avoid passing `globalend`). However: do you still need `globalstart` and `globalend` at all when using TEntryLists?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8646#issuecomment-895318380
Usability,simpl,simplified,"> I understand this will be simplified when we can pass a configuration object to RDataFrame where we specify the range. When reading trees/chains, I'm not sure the configuration object will allow anything more than what we can already do with TEntryLists?. IIUC the redundant info is that `globalend = globalstart + (localends - localstarts).sum()` (i.e. we could avoid passing `globalend`). However: do you still need `globalstart` and `globalend` at all when using TEntryLists?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8646#issuecomment-895318380
Usability,simpl,simplification,"> you can calculate them from globalstart, globalend, filelist, treesnentries. yes if you pass all files and all tree entries. currently iirc we are only passing the file names and the tree entries for the files and trees that will be actually touched by the task. otoh i'm still thinking that `globalstart` and `globalend` could go away, what do we need them for?. EDIT: ah we use them for the call to `SetCacheEntryRange`, and they are not really global but they are relative to the task-specific chain uhm....it feels like some simplification is possible, if they are relative to the task-specific chain can't they be calculated from the rest?. EDIT 2: Ideally the call to `SetCacheEntryRange` should not be needed at all, `TTreeProcessorMT` and `TTreeReader` should take care of it...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8646#issuecomment-895350585
Usability,simpl,simplification,"> EDIT: ah we use them for the call to SetCacheEntryRange, and they are not really global but they are relative to the task-specific chain uhm....it feels like some simplification is possible, if they are relative to the task-specific chain can't they be calculated from the rest?. Yes exactly, they are not global global, but global to the local partial chain that the task needs to process. That's why I say you just strictly need `globalstart, globalend, filelist, treesnentries`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8646#issuecomment-895362702
Usability,progress bar,progress bar,"> ```c++; > auto progbar = ROOT::RDF::MakeProgressBar(df, everyNEvents, nEvents); // last 2 args are optional; > ```. Although the ProgressBar won't be a progress bar when we don't know the number of events ...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8675#issuecomment-880514090
Security,access,access,"> Tell me though: An RDF (= RNode I think?) doesn't take callbacks. I need a `RResultPtr`, correct? Do I have to attach a dummy result or did I miss something?. OK, I had a look, and it would actually be amazing if I could get access to the LoopManager, because then I could just register the callback using `RLoopManager::RegisterCallback` (cannot link to docs because undocumented functions don't get an anchor in doxygen, any more  ).; I don't see a way to get to the [LoopManager](https://root.cern.ch/doc/master/classROOT_1_1Detail_1_1RDF_1_1RLoopManager.html), though. ... and it would be cool because I wouldn't need to throw away the payload of the resultptr, because I'm not using it anyway.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8675#issuecomment-880524867
Usability,undo,undocumented,"> Tell me though: An RDF (= RNode I think?) doesn't take callbacks. I need a `RResultPtr`, correct? Do I have to attach a dummy result or did I miss something?. OK, I had a look, and it would actually be amazing if I could get access to the LoopManager, because then I could just register the callback using `RLoopManager::RegisterCallback` (cannot link to docs because undocumented functions don't get an anchor in doxygen, any more  ).; I don't see a way to get to the [LoopManager](https://root.cern.ch/doc/master/classROOT_1_1Detail_1_1RDF_1_1RLoopManager.html), though. ... and it would be cool because I wouldn't need to throw away the payload of the resultptr, because I'm not using it anyway.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8675#issuecomment-880524867
Integrability,interface,interface,"> Although the ProgressBar won't be a progress bar when we don't know the number of events ... You're right, better name pending (`AddProgressIndicator`?). > It would actually be amazing if I could get access to the LoopManager, because then I could just register the callback using RLoopManager::RegisterCallback. Yes that's a great idea, there are actually several advantages:. - as you mention, in the callback you wouldn't have to discard a partially evaluated result anymore; - `AddProgressIndicator` wouldn't need to return anything, it can just do what it says without users having to deal with the returned object; - probably the biggest: we wouldn't have to do any magic to make sure that the method is called _on the head node_ (because if you call it on a `Filter`, now you are updating the progress bar every N _filtered_ entries) . Now -- of course we don't just expose the `RLoopManager` to _anyone_, but we trust you, so you can add a `ROOT::Internal::ExtractLoopManager` function as a friend of `RInterface` that just returns `interface.fLoopManager`?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8675#issuecomment-880538021
Security,access,access,"> Although the ProgressBar won't be a progress bar when we don't know the number of events ... You're right, better name pending (`AddProgressIndicator`?). > It would actually be amazing if I could get access to the LoopManager, because then I could just register the callback using RLoopManager::RegisterCallback. Yes that's a great idea, there are actually several advantages:. - as you mention, in the callback you wouldn't have to discard a partially evaluated result anymore; - `AddProgressIndicator` wouldn't need to return anything, it can just do what it says without users having to deal with the returned object; - probably the biggest: we wouldn't have to do any magic to make sure that the method is called _on the head node_ (because if you call it on a `Filter`, now you are updating the progress bar every N _filtered_ entries) . Now -- of course we don't just expose the `RLoopManager` to _anyone_, but we trust you, so you can add a `ROOT::Internal::ExtractLoopManager` function as a friend of `RInterface` that just returns `interface.fLoopManager`?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8675#issuecomment-880538021
Usability,progress bar,progress bar,"> Although the ProgressBar won't be a progress bar when we don't know the number of events ... You're right, better name pending (`AddProgressIndicator`?). > It would actually be amazing if I could get access to the LoopManager, because then I could just register the callback using RLoopManager::RegisterCallback. Yes that's a great idea, there are actually several advantages:. - as you mention, in the callback you wouldn't have to discard a partially evaluated result anymore; - `AddProgressIndicator` wouldn't need to return anything, it can just do what it says without users having to deal with the returned object; - probably the biggest: we wouldn't have to do any magic to make sure that the method is called _on the head node_ (because if you call it on a `Filter`, now you are updating the progress bar every N _filtered_ entries) . Now -- of course we don't just expose the `RLoopManager` to _anyone_, but we trust you, so you can add a `ROOT::Internal::ExtractLoopManager` function as a friend of `RInterface` that just returns `interface.fLoopManager`?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8675#issuecomment-880538021
Deployability,update,update,"(as per the discussion above, this will not get merged as is because we rather prefer an implementation that can estimate the remaining number of entries/time without having to check all input files beforehand, but the logic to create and update the progress bar, including colors, windows support etc. is still directly re-usable and super useful)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8675#issuecomment-880833581
Testability,log,logic,"(as per the discussion above, this will not get merged as is because we rather prefer an implementation that can estimate the remaining number of entries/time without having to check all input files beforehand, but the logic to create and update the progress bar, including colors, windows support etc. is still directly re-usable and super useful)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8675#issuecomment-880833581
Usability,progress bar,progress bar,"(as per the discussion above, this will not get merged as is because we rather prefer an implementation that can estimate the remaining number of entries/time without having to check all input files beforehand, but the logic to create and update the progress bar, including colors, windows support etc. is still directly re-usable and super useful)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8675#issuecomment-880833581
Usability,feedback,feedback,@couet any feedback on this PR?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8681#issuecomment-946557019
Performance,cache,cache,"I had a look ant it seems very nice. About the discrepancy between `REntry::Get` and `RNTupleModel::MakeField`, one may argue that `MakeField` might return a raw pointer too as the memory of the field is owned by the model. OTOH, while it's kind of easy to keep track of the lifetime of an `REntry` (I get it, I use it, I drop it), it seems more difficult to keep track of `RNTupleModel` lifetime, which is bound to the lifetime of `RNTupleWriter`.; Using raw pointers from `MakeField` is fine if we assume that the writer of the code only accesses the fields within the scope of `RNTupleWriter` (but the fields are accessible before the writer is created... more confusing). My personal opinion is that the `CreateEntry` way is the best option for the single thread case too:; - I define a model; - create a writer based on the model; - get the *buffer* (`REntry`) to write to (one per thread, for example, even if I have only one thread); - commit the *buffer* to the writer. In this way I own the `REntry`, but it has a layout in memory that is directly understood by the serialization process without the need of extra copies. We can also think of a way of constructing the writer from an *inlined* model, without the need for repeated calls to `MakeField`. Something like:; ```cpp; auto ntuple = RNTupleWriter::Recreate({; Field<std::uint32_t>(""id""),; Field<std::vector<float>>(""vpx""),; Field<std::vector<float>>(""vpy""),; Field<std::vector<float>>(""vpz""); }, ""NTuple"", kNTupleFileName);. auto entry = ntuple->CreateEntry();; // cache the pointer for faster access in single thread,; // but I could use TLS (or a framework equivalent) for multithreading; auto& vpx = *entry->Get<std::vector<float>>(""vpx"");; for(auto& event: all_events) {; vpx.clear();; vpx.push_back(42.);; ntuple->Fill(entry); // I would prefer ntuple->Write(entry) but it's a matter of taste; }; ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8688#issuecomment-883396155
Security,access,accesses,"I had a look ant it seems very nice. About the discrepancy between `REntry::Get` and `RNTupleModel::MakeField`, one may argue that `MakeField` might return a raw pointer too as the memory of the field is owned by the model. OTOH, while it's kind of easy to keep track of the lifetime of an `REntry` (I get it, I use it, I drop it), it seems more difficult to keep track of `RNTupleModel` lifetime, which is bound to the lifetime of `RNTupleWriter`.; Using raw pointers from `MakeField` is fine if we assume that the writer of the code only accesses the fields within the scope of `RNTupleWriter` (but the fields are accessible before the writer is created... more confusing). My personal opinion is that the `CreateEntry` way is the best option for the single thread case too:; - I define a model; - create a writer based on the model; - get the *buffer* (`REntry`) to write to (one per thread, for example, even if I have only one thread); - commit the *buffer* to the writer. In this way I own the `REntry`, but it has a layout in memory that is directly understood by the serialization process without the need of extra copies. We can also think of a way of constructing the writer from an *inlined* model, without the need for repeated calls to `MakeField`. Something like:; ```cpp; auto ntuple = RNTupleWriter::Recreate({; Field<std::uint32_t>(""id""),; Field<std::vector<float>>(""vpx""),; Field<std::vector<float>>(""vpy""),; Field<std::vector<float>>(""vpz""); }, ""NTuple"", kNTupleFileName);. auto entry = ntuple->CreateEntry();; // cache the pointer for faster access in single thread,; // but I could use TLS (or a framework equivalent) for multithreading; auto& vpx = *entry->Get<std::vector<float>>(""vpx"");; for(auto& event: all_events) {; vpx.clear();; vpx.push_back(42.);; ntuple->Fill(entry); // I would prefer ntuple->Write(entry) but it's a matter of taste; }; ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8688#issuecomment-883396155
Usability,clear,clear,"I had a look ant it seems very nice. About the discrepancy between `REntry::Get` and `RNTupleModel::MakeField`, one may argue that `MakeField` might return a raw pointer too as the memory of the field is owned by the model. OTOH, while it's kind of easy to keep track of the lifetime of an `REntry` (I get it, I use it, I drop it), it seems more difficult to keep track of `RNTupleModel` lifetime, which is bound to the lifetime of `RNTupleWriter`.; Using raw pointers from `MakeField` is fine if we assume that the writer of the code only accesses the fields within the scope of `RNTupleWriter` (but the fields are accessible before the writer is created... more confusing). My personal opinion is that the `CreateEntry` way is the best option for the single thread case too:; - I define a model; - create a writer based on the model; - get the *buffer* (`REntry`) to write to (one per thread, for example, even if I have only one thread); - commit the *buffer* to the writer. In this way I own the `REntry`, but it has a layout in memory that is directly understood by the serialization process without the need of extra copies. We can also think of a way of constructing the writer from an *inlined* model, without the need for repeated calls to `MakeField`. Something like:; ```cpp; auto ntuple = RNTupleWriter::Recreate({; Field<std::uint32_t>(""id""),; Field<std::vector<float>>(""vpx""),; Field<std::vector<float>>(""vpy""),; Field<std::vector<float>>(""vpz""); }, ""NTuple"", kNTupleFileName);. auto entry = ntuple->CreateEntry();; // cache the pointer for faster access in single thread,; // but I could use TLS (or a framework equivalent) for multithreading; auto& vpx = *entry->Get<std::vector<float>>(""vpx"");; for(auto& event: all_events) {; vpx.clear();; vpx.push_back(42.);; ntuple->Fill(entry); // I would prefer ntuple->Write(entry) but it's a matter of taste; }; ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8688#issuecomment-883396155
Usability,simpl,simpler,"@Axel-Naumann, @couet pointed out that my read file was basically a simpler version of h1draw.C and that it would be better to just clarify some things in that file.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8699#issuecomment-884186832
Deployability,integrat,integrate,"@hageboeck thanks for another Herculean reviewing effort :) Your comments make total sense; indeed, all the copy-pasted stuff still has to be merged with all the modernization and optimization work that was done in the past two years. I will go through as much of your suggestions as I can before I will be on leave after tomorrow for three weeks. After that, if anyone else has time to work on some of the issues, I'd of course welcome the help. As you know, my time on the project is running out, so I probably won't have time to integrate everything. For instance, Manos' mini computation library I have only learned about in the last few months and don't know it in enough detail to make any kind of sensible estimate of how to do it, let alone how much time this would take. Let's discuss detailed plans in our meeting at 14:00 today.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700#issuecomment-884045031
Integrability,integrat,integrate,"@hageboeck thanks for another Herculean reviewing effort :) Your comments make total sense; indeed, all the copy-pasted stuff still has to be merged with all the modernization and optimization work that was done in the past two years. I will go through as much of your suggestions as I can before I will be on leave after tomorrow for three weeks. After that, if anyone else has time to work on some of the issues, I'd of course welcome the help. As you know, my time on the project is running out, so I probably won't have time to integrate everything. For instance, Manos' mini computation library I have only learned about in the last few months and don't know it in enough detail to make any kind of sensible estimate of how to do it, let alone how much time this would take. Let's discuss detailed plans in our meeting at 14:00 today.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700#issuecomment-884045031
Performance,optimiz,optimization,"@hageboeck thanks for another Herculean reviewing effort :) Your comments make total sense; indeed, all the copy-pasted stuff still has to be merged with all the modernization and optimization work that was done in the past two years. I will go through as much of your suggestions as I can before I will be on leave after tomorrow for three weeks. After that, if anyone else has time to work on some of the issues, I'd of course welcome the help. As you know, my time on the project is running out, so I probably won't have time to integrate everything. For instance, Manos' mini computation library I have only learned about in the last few months and don't know it in enough detail to make any kind of sensible estimate of how to do it, let alone how much time this would take. Let's discuss detailed plans in our meeting at 14:00 today.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700#issuecomment-884045031
Usability,learn,learned,"@hageboeck thanks for another Herculean reviewing effort :) Your comments make total sense; indeed, all the copy-pasted stuff still has to be merged with all the modernization and optimization work that was done in the past two years. I will go through as much of your suggestions as I can before I will be on leave after tomorrow for three weeks. After that, if anyone else has time to work on some of the issues, I'd of course welcome the help. As you know, my time on the project is running out, so I probably won't have time to integrate everything. For instance, Manos' mini computation library I have only learned about in the last few months and don't know it in enough detail to make any kind of sensible estimate of how to do it, let alone how much time this would take. Let's discuss detailed plans in our meeting at 14:00 today.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700#issuecomment-884045031
Deployability,configurat,configuration,"Remaining points and questions arising from @hageboeck's review:. 1. https://github.com/root-project/root/pull/8700#discussion_r672508683 Should RooRealL have I/O? It is currently disabled by setting ClassDef version to 0.; 2. https://github.com/root-project/root/pull/8700#discussion_r672509759 RooFit naming convention puts underscores in front of member names. This is discouraged, since underscore prefix is reserved for C++ implementations. I introduced some new members with underscore suffix instead, which is also common practice e.g. in the Google C++ guidelines. I think this is not something we should spend too much time on now, but maybe good to keep in mind for the future.; 3. https://github.com/root-project/root/pull/8700#discussion_r672519457 The configuration parameters (GlobalObservables etc.): should we unify them or keep like this?; 4. https://github.com/root-project/root/pull/8700#discussion_r672538377 This should be checked by Wouter. In addition, some other remaining questions:; 1. `testRooRealL.getValRooAddition` fails because it doesn't know `RooFormulaVar`... I'm not sure what this means, but I vaguely remember that (I think) @hageboeck and @cburgard were talking about this, so I was hoping you may be able to help me out with fixing that test.; 2. In an ideal world I would have liked to add a serial implementation of the `LikelihoodGradientWrapper` class. Probably, we can reuse a lot of `RooGradMinimizerFcn` for this and it should be rather straightforward. However, this will take time. The advantage would be that we could add a test to this PR that covers all that is added, basically by just running a minimization. Note that I do have such a full-coverage test, but only for the MultiProcess minimization, where I implemented `LikelihoodGradientWrapper` in the parallel `LikelihoodGradientJob` class. So this test will come in ""PR 7"" (see overview). So, up for discussion, two choices: A: add (probably mostly useless except for testing this PR) ""Likelih",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700#issuecomment-915217168
Integrability,integrat,integration,"the Google C++ guidelines. I think this is not something we should spend too much time on now, but maybe good to keep in mind for the future.; 3. https://github.com/root-project/root/pull/8700#discussion_r672519457 The configuration parameters (GlobalObservables etc.): should we unify them or keep like this?; 4. https://github.com/root-project/root/pull/8700#discussion_r672538377 This should be checked by Wouter. In addition, some other remaining questions:; 1. `testRooRealL.getValRooAddition` fails because it doesn't know `RooFormulaVar`... I'm not sure what this means, but I vaguely remember that (I think) @hageboeck and @cburgard were talking about this, so I was hoping you may be able to help me out with fixing that test.; 2. In an ideal world I would have liked to add a serial implementation of the `LikelihoodGradientWrapper` class. Probably, we can reuse a lot of `RooGradMinimizerFcn` for this and it should be rather straightforward. However, this will take time. The advantage would be that we could add a test to this PR that covers all that is added, basically by just running a minimization. Note that I do have such a full-coverage test, but only for the MultiProcess minimization, where I implemented `LikelihoodGradientWrapper` in the parallel `LikelihoodGradientJob` class. So this test will come in ""PR 7"" (see overview). So, up for discussion, two choices: A: add (probably mostly useless except for testing this PR) ""LikelihoodGradientSerial"" class (based on RooGradMinimizerFcn) so we can add an integration test in this PR; B: wait for the integration test in PR 7.; 3. Does everybody like the RooNLLVar statics?; 4. Offset in the new TestStatistics classes can easily include the RooSubsidiaryL term as well, unlike with RooAbsTestStatistic, where the RooConstraintSum was a separate class that would not be included in the offset. I have now implemented a legacy mode to get bit-wise equal results, but is the new ""full"" mode a good idea at all? Does it make sense?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700#issuecomment-915217168
Modifiability,config,configuration,"Remaining points and questions arising from @hageboeck's review:. 1. https://github.com/root-project/root/pull/8700#discussion_r672508683 Should RooRealL have I/O? It is currently disabled by setting ClassDef version to 0.; 2. https://github.com/root-project/root/pull/8700#discussion_r672509759 RooFit naming convention puts underscores in front of member names. This is discouraged, since underscore prefix is reserved for C++ implementations. I introduced some new members with underscore suffix instead, which is also common practice e.g. in the Google C++ guidelines. I think this is not something we should spend too much time on now, but maybe good to keep in mind for the future.; 3. https://github.com/root-project/root/pull/8700#discussion_r672519457 The configuration parameters (GlobalObservables etc.): should we unify them or keep like this?; 4. https://github.com/root-project/root/pull/8700#discussion_r672538377 This should be checked by Wouter. In addition, some other remaining questions:; 1. `testRooRealL.getValRooAddition` fails because it doesn't know `RooFormulaVar`... I'm not sure what this means, but I vaguely remember that (I think) @hageboeck and @cburgard were talking about this, so I was hoping you may be able to help me out with fixing that test.; 2. In an ideal world I would have liked to add a serial implementation of the `LikelihoodGradientWrapper` class. Probably, we can reuse a lot of `RooGradMinimizerFcn` for this and it should be rather straightforward. However, this will take time. The advantage would be that we could add a test to this PR that covers all that is added, basically by just running a minimization. Note that I do have such a full-coverage test, but only for the MultiProcess minimization, where I implemented `LikelihoodGradientWrapper` in the parallel `LikelihoodGradientJob` class. So this test will come in ""PR 7"" (see overview). So, up for discussion, two choices: A: add (probably mostly useless except for testing this PR) ""Likelih",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700#issuecomment-915217168
Testability,test,testRooRealL,"nd questions arising from @hageboeck's review:. 1. https://github.com/root-project/root/pull/8700#discussion_r672508683 Should RooRealL have I/O? It is currently disabled by setting ClassDef version to 0.; 2. https://github.com/root-project/root/pull/8700#discussion_r672509759 RooFit naming convention puts underscores in front of member names. This is discouraged, since underscore prefix is reserved for C++ implementations. I introduced some new members with underscore suffix instead, which is also common practice e.g. in the Google C++ guidelines. I think this is not something we should spend too much time on now, but maybe good to keep in mind for the future.; 3. https://github.com/root-project/root/pull/8700#discussion_r672519457 The configuration parameters (GlobalObservables etc.): should we unify them or keep like this?; 4. https://github.com/root-project/root/pull/8700#discussion_r672538377 This should be checked by Wouter. In addition, some other remaining questions:; 1. `testRooRealL.getValRooAddition` fails because it doesn't know `RooFormulaVar`... I'm not sure what this means, but I vaguely remember that (I think) @hageboeck and @cburgard were talking about this, so I was hoping you may be able to help me out with fixing that test.; 2. In an ideal world I would have liked to add a serial implementation of the `LikelihoodGradientWrapper` class. Probably, we can reuse a lot of `RooGradMinimizerFcn` for this and it should be rather straightforward. However, this will take time. The advantage would be that we could add a test to this PR that covers all that is added, basically by just running a minimization. Note that I do have such a full-coverage test, but only for the MultiProcess minimization, where I implemented `LikelihoodGradientWrapper` in the parallel `LikelihoodGradientJob` class. So this test will come in ""PR 7"" (see overview). So, up for discussion, two choices: A: add (probably mostly useless except for testing this PR) ""LikelihoodGradientSerial""",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700#issuecomment-915217168
Usability,guid,guidelines,"Remaining points and questions arising from @hageboeck's review:. 1. https://github.com/root-project/root/pull/8700#discussion_r672508683 Should RooRealL have I/O? It is currently disabled by setting ClassDef version to 0.; 2. https://github.com/root-project/root/pull/8700#discussion_r672509759 RooFit naming convention puts underscores in front of member names. This is discouraged, since underscore prefix is reserved for C++ implementations. I introduced some new members with underscore suffix instead, which is also common practice e.g. in the Google C++ guidelines. I think this is not something we should spend too much time on now, but maybe good to keep in mind for the future.; 3. https://github.com/root-project/root/pull/8700#discussion_r672519457 The configuration parameters (GlobalObservables etc.): should we unify them or keep like this?; 4. https://github.com/root-project/root/pull/8700#discussion_r672538377 This should be checked by Wouter. In addition, some other remaining questions:; 1. `testRooRealL.getValRooAddition` fails because it doesn't know `RooFormulaVar`... I'm not sure what this means, but I vaguely remember that (I think) @hageboeck and @cburgard were talking about this, so I was hoping you may be able to help me out with fixing that test.; 2. In an ideal world I would have liked to add a serial implementation of the `LikelihoodGradientWrapper` class. Probably, we can reuse a lot of `RooGradMinimizerFcn` for this and it should be rather straightforward. However, this will take time. The advantage would be that we could add a test to this PR that covers all that is added, basically by just running a minimization. Note that I do have such a full-coverage test, but only for the MultiProcess minimization, where I implemented `LikelihoodGradientWrapper` in the parallel `LikelihoodGradientJob` class. So this test will come in ""PR 7"" (see overview). So, up for discussion, two choices: A: add (probably mostly useless except for testing this PR) ""Likelih",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700#issuecomment-915217168
Safety,predict,prediction,"In reply to: https://github.com/root-project/root/pull/8703#issuecomment-920044106. > You mean keeping the average of the last $x$ MB written per column? . Not quite, I meant simply an overall average, i.e. simply keeping `total_number_of_bytes` and `total_number_of_compressed_bytes` for each column and then average compression ration is a simple division. But ... actually ... closer to the original proposal is simply the ""total_number_of_bytes_in_all_flushed_clusters"" and ""corresponding_compressed_size"" (i.e. a per RNtuple running total). However this makes me thing of another (potential more noticeable) instability. If there is 2 columns; column A with an constant/average compression ration of 100 and column B with a constant/average compression ration of 1 (or 1.1 :) ) but both columns are collections. If for most of the entries (for more proposal) or only the last cluster (for the PR's proposal), column A has a lot of data and column B has very little data, then the compression ration use for prediction will be 100 (ish). If suddenly the cardinality flip/flop and column A has very little data but column B has a lot of data, then the compression ration of that cluster will be 1 but it would still contains `100 * target_cluster_size_in_compressed_bytes`, namely in this case 100 times larger (on disk) than any other cluster. Obviously this is an extreme example but it points to the benefit of using `per column` compression ratio rather than overall compression ratio (whether it is whole-ntuple or last (few) clusters). The cost for implementation seems to be that after each `Fill`, each column would have to increment a (global-per-RNtuple) counter with `data_written / estimated_compression_ratio` which:; * for collection column should be a small over-head; * for single value column should be a large over-head. however conversely, an accurate estimate is ""only important"" for collection column, so maybe an hybrid solution is a workable compromise?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8703#issuecomment-920229853
Usability,simpl,simply,"In reply to: https://github.com/root-project/root/pull/8703#issuecomment-920044106. > You mean keeping the average of the last $x$ MB written per column? . Not quite, I meant simply an overall average, i.e. simply keeping `total_number_of_bytes` and `total_number_of_compressed_bytes` for each column and then average compression ration is a simple division. But ... actually ... closer to the original proposal is simply the ""total_number_of_bytes_in_all_flushed_clusters"" and ""corresponding_compressed_size"" (i.e. a per RNtuple running total). However this makes me thing of another (potential more noticeable) instability. If there is 2 columns; column A with an constant/average compression ration of 100 and column B with a constant/average compression ration of 1 (or 1.1 :) ) but both columns are collections. If for most of the entries (for more proposal) or only the last cluster (for the PR's proposal), column A has a lot of data and column B has very little data, then the compression ration use for prediction will be 100 (ish). If suddenly the cardinality flip/flop and column A has very little data but column B has a lot of data, then the compression ration of that cluster will be 1 but it would still contains `100 * target_cluster_size_in_compressed_bytes`, namely in this case 100 times larger (on disk) than any other cluster. Obviously this is an extreme example but it points to the benefit of using `per column` compression ratio rather than overall compression ratio (whether it is whole-ntuple or last (few) clusters). The cost for implementation seems to be that after each `Fill`, each column would have to increment a (global-per-RNtuple) counter with `data_written / estimated_compression_ratio` which:; * for collection column should be a small over-head; * for single value column should be a large over-head. however conversely, an accurate estimate is ""only important"" for collection column, so maybe an hybrid solution is a workable compromise?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8703#issuecomment-920229853
Deployability,release,release,"If it helps: I know at least that for instance the [JuliaPlots/Plots](https://github.com/JuliaPlots/Plots.jl) project simply uses a `.zenodo.json` file in their repo which should be automatically parsed, according to [REST API subsection](https://developers.zenodo.org/#add-metadata-to-your-github-repository-release), whenever a new release is created.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8706#issuecomment-914136123
Usability,simpl,simply,"If it helps: I know at least that for instance the [JuliaPlots/Plots](https://github.com/JuliaPlots/Plots.jl) project simply uses a `.zenodo.json` file in their repo which should be automatically parsed, according to [REST API subsection](https://developers.zenodo.org/#add-metadata-to-your-github-repository-release), whenever a new release is created.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8706#issuecomment-914136123
Safety,timeout,timeouts,"> > @grasph please fork also [roottest](https://github.com/root-project/roottest) to prevent timeouts on the Windows build nodes. Thanks; > ; > Done. Do I need to create a branch with the same name ?. Thanks. And no, simply forking is good enough",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8717#issuecomment-885523144
Usability,simpl,simply,"> > @grasph please fork also [roottest](https://github.com/root-project/roottest) to prevent timeouts on the Windows build nodes. Thanks; > ; > Done. Do I need to create a branch with the same name ?. Thanks. And no, simply forking is good enough",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8717#issuecomment-885523144
Deployability,patch,patch,"Thanks for the patch, Advait!. My thoughts: If the function is added to ROOT as is, I'd implement it in the header and simply `return a==b`. The C/C++ cast from `bool` to `int` is effectively a Kronecker Delta. That said, I'm not sure if the function as such does in practice what users expect. Floating point values are hardly ever exactly equal, but usually one tests for them to be equal within +/ epsilon. I'll assign to @lmoneta.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8719#issuecomment-886443983
Testability,test,tests,"Thanks for the patch, Advait!. My thoughts: If the function is added to ROOT as is, I'd implement it in the header and simply `return a==b`. The C/C++ cast from `bool` to `int` is effectively a Kronecker Delta. That said, I'm not sure if the function as such does in practice what users expect. Floating point values are hardly ever exactly equal, but usually one tests for them to be equal within +/ epsilon. I'll assign to @lmoneta.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8719#issuecomment-886443983
Usability,simpl,simply,"Thanks for the patch, Advait!. My thoughts: If the function is added to ROOT as is, I'd implement it in the header and simply `return a==b`. The C/C++ cast from `bool` to `int` is effectively a Kronecker Delta. That said, I'm not sure if the function as such does in practice what users expect. Floating point values are hardly ever exactly equal, but usually one tests for them to be equal within +/ epsilon. I'll assign to @lmoneta.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8719#issuecomment-886443983
Deployability,patch,patch,"> Thanks for the patch, Advait!; > ; > My thoughts: If the function is added to ROOT as is, I'd implement it in the header and simply `return a==b`. The C/C++ cast from `bool` to `int` is effectively a Kronecker Delta.; > ; > That said, I'm not sure if the function as such does in practice what users expect. Floating point values are hardly ever exactly equal, but usually one tests for them to be equal within +/ epsilon.; > ; > I'll assign to @lmoneta. Ahh yes , I see what you mean.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8719#issuecomment-886482916
Testability,test,tests,"> Thanks for the patch, Advait!; > ; > My thoughts: If the function is added to ROOT as is, I'd implement it in the header and simply `return a==b`. The C/C++ cast from `bool` to `int` is effectively a Kronecker Delta.; > ; > That said, I'm not sure if the function as such does in practice what users expect. Floating point values are hardly ever exactly equal, but usually one tests for them to be equal within +/ epsilon.; > ; > I'll assign to @lmoneta. Ahh yes , I see what you mean.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8719#issuecomment-886482916
Usability,simpl,simply,"> Thanks for the patch, Advait!; > ; > My thoughts: If the function is added to ROOT as is, I'd implement it in the header and simply `return a==b`. The C/C++ cast from `bool` to `int` is effectively a Kronecker Delta.; > ; > That said, I'm not sure if the function as such does in practice what users expect. Floating point values are hardly ever exactly equal, but usually one tests for them to be equal within +/ epsilon.; > ; > I'll assign to @lmoneta. Ahh yes , I see what you mean.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8719#issuecomment-886482916
Usability,simpl,simple,"> I don't think it's good enough. Some header files have to be found by ROOT, and there are quite a few more packages than those two IIRC... Yeah, this wont be as simple as I thought it would be  . I'll come up with a solution.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8732#issuecomment-886601097
Modifiability,variab,variable,"One solution for a general derivative function could be to simply pass ""Function->Derivative(x)"" in the second TF1. But there still needs to be a way to differentiate with respect to any variable.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8735#issuecomment-887360425
Usability,simpl,simply,"One solution for a general derivative function could be to simply pass ""Function->Derivative(x)"" in the second TF1. But there still needs to be a way to differentiate with respect to any variable.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8735#issuecomment-887360425
Availability,failure,failures,"The test failures report the file created during the test does not exist, but this node ran the test fine https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/124359/testReport/projectroot.tree.tree/test/gtest_tree_tree_test_entrylist_enterrange/ . Probably using the same filename for multiple tests leads to a recreation/deletion of the file that is then not usable by the new test?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8740#issuecomment-895859603
Testability,test,test,"The test failures report the file created during the test does not exist, but this node ran the test fine https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/124359/testReport/projectroot.tree.tree/test/gtest_tree_tree_test_entrylist_enterrange/ . Probably using the same filename for multiple tests leads to a recreation/deletion of the file that is then not usable by the new test?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8740#issuecomment-895859603
Usability,usab,usable,"The test failures report the file created during the test does not exist, but this node ran the test fine https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/124359/testReport/projectroot.tree.tree/test/gtest_tree_tree_test_entrylist_enterrange/ . Probably using the same filename for multiple tests leads to a recreation/deletion of the file that is then not usable by the new test?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8740#issuecomment-895859603
Energy Efficiency,reduce,reduce,"> Is it possible to disable the Internet connection with an option during the cmake (and later build) phase?. Well, no, you can simply unplug (or disable) the internet connection. You can also use the `-Dminimal=ON` flag to reduce the number of packages",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8742#issuecomment-887583333
Usability,simpl,simply,"> Is it possible to disable the Internet connection with an option during the cmake (and later build) phase?. Well, no, you can simply unplug (or disable) the internet connection. You can also use the `-Dminimal=ON` flag to reduce the number of packages",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8742#issuecomment-887583333
Availability,error,errors,"> Well, no, you can simply unplug (or disable) the internet connection. Not really a good idea. I tried to run cmake for windows, but got some errors here as well, unfortunately stopping my attempts to build ROOT and especially to build the documentation.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8742#issuecomment-887610171
Usability,simpl,simply,"> Well, no, you can simply unplug (or disable) the internet connection. Not really a good idea. I tried to run cmake for windows, but got some errors here as well, unfortunately stopping my attempts to build ROOT and especially to build the documentation.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8742#issuecomment-887610171
Usability,simpl,simply,You can simply disable `imt` (`-Dimt=OFF`) and `builtin_tbb` (-D`builtin_tbb=OFF`).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8742#issuecomment-888087500
Testability,test,testing,"It's actually an _array_ ds, not the arrow ds :smile: it's a simple datasource used for testing",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8754#issuecomment-888908741
Usability,simpl,simple,"It's actually an _array_ ds, not the arrow ds :smile: it's a simple datasource used for testing",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8754#issuecomment-888908741
Usability,guid,guide,"Hello @guitargeek @couet , I'd like to contribute to this repository. Can you guide me in going about this issue?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8758#issuecomment-973032294
Deployability,release,release,"A workaround has been introduced in xrootd and will be part of xrootd-5.3.1 release. See above referenced issue in xrootd repo. Similar workaround has already been there for XrdCl::File destruction that is also happening after libXrdCl has been unloaded. @Axel-Naumann do you think it's worth introducing something like TROOT::CleanupLeftovers() and call it from TApplication::Terminate() just before calling gSystem->Exit()? The same function can still be called from ~TROOT for cases when TApplication is not instantiated ... and if it is called beforehand, the lists will simply be empty at ~TROOT time.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8767#issuecomment-889666524
Usability,simpl,simply,"A workaround has been introduced in xrootd and will be part of xrootd-5.3.1 release. See above referenced issue in xrootd repo. Similar workaround has already been there for XrdCl::File destruction that is also happening after libXrdCl has been unloaded. @Axel-Naumann do you think it's worth introducing something like TROOT::CleanupLeftovers() and call it from TApplication::Terminate() just before calling gSystem->Exit()? The same function can still be called from ~TROOT for cases when TApplication is not instantiated ... and if it is called beforehand, the lists will simply be empty at ~TROOT time.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8767#issuecomment-889666524
Safety,avoid,avoid,"Humm .. the files are ""Closed"" but not deleted .. the comment relevant comment from `TROOT.cxx:1086` is:; ```; // Now were done, clear the list but do not delete the objects as; // they have been moved to the list of closed objects and must be; // deleted from there in order to avoid a double delete from a; // use objects (on the interpreter stack).; ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8767#issuecomment-890403157
Usability,clear,clear,"Humm .. the files are ""Closed"" but not deleted .. the comment relevant comment from `TROOT.cxx:1086` is:; ```; // Now were done, clear the list but do not delete the objects as; // they have been moved to the list of closed objects and must be; // deleted from there in order to avoid a double delete from a; // use objects (on the interpreter stack).; ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8767#issuecomment-890403157
Performance,load,loaded,"""You"" was Axel and Philippe + whoever is doing TXNetNG these days :) ; Michal (main developer of XrdCl) and I assumed the crash happens because libXrdCl was already unloaded, see xrootd issue: xrootd/xrootd#1487. Now, you say the library is still loaded ... then it's probably more likely that destruction ob XrdCl global objects has already happened or was in progress (I just learned c++ is rather relaxed about how this is allowed to happen). @simonmichal ... what do you think?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8767#issuecomment-892009554
Usability,learn,learned,"""You"" was Axel and Philippe + whoever is doing TXNetNG these days :) ; Michal (main developer of XrdCl) and I assumed the crash happens because libXrdCl was already unloaded, see xrootd issue: xrootd/xrootd#1487. Now, you say the library is still loaded ... then it's probably more likely that destruction ob XrdCl global objects has already happened or was in progress (I just learned c++ is rather relaxed about how this is allowed to happen). @simonmichal ... what do you think?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8767#issuecomment-892009554
Performance,load,loaded,"Sorry guys I've been on holidays :-) good to see that this is solved :-). > ""You"" was Axel and Philippe + whoever is doing TXNetNG these days :); > Michal (main developer of XrdCl) and I assumed the crash happens because libXrdCl was already unloaded, see xrootd issue: [xrootd/xrootd#1487](https://github.com/xrootd/xrootd/issues/1487); > ; > Now, you say the library is still loaded ... then it's probably more likely that destruction ob XrdCl global objects has already happened or was in progress (I just learned c++ is rather relaxed about how this is allowed to happen).; > ; > @simonmichal ... what do you think?. we use a nifty counter to protect against static-destruction-order-fiasco so in principle if the `libXrdCl` has not been unloaded it should not crash",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8767#issuecomment-895029183
Usability,learn,learned,"Sorry guys I've been on holidays :-) good to see that this is solved :-). > ""You"" was Axel and Philippe + whoever is doing TXNetNG these days :); > Michal (main developer of XrdCl) and I assumed the crash happens because libXrdCl was already unloaded, see xrootd issue: [xrootd/xrootd#1487](https://github.com/xrootd/xrootd/issues/1487); > ; > Now, you say the library is still loaded ... then it's probably more likely that destruction ob XrdCl global objects has already happened or was in progress (I just learned c++ is rather relaxed about how this is allowed to happen).; > ; > @simonmichal ... what do you think?. we use a nifty counter to protect against static-destruction-order-fiasco so in principle if the `libXrdCl` has not been unloaded it should not crash",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8767#issuecomment-895029183
Testability,assert,assert,"Hi @hageboeck, thanks for the feedback!. Okay, I now took the time to hopefully get this range casting also work for the TCollections, so we don't have duplicate code. Actually, there was an `assert` also in the old [TRangeStaticCast implementation](https://github.com/root-project/root/blob/master/core/cont/inc/TCollection.h#L355)! So to stay consistent with TRangeStaticCast, I had to bring the `assert` in so that change request is also addressed now :) And we can also use the existing unit test in `testTypedIteration.cxx`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8769#issuecomment-891218910
Usability,feedback,feedback,"Hi @hageboeck, thanks for the feedback!. Okay, I now took the time to hopefully get this range casting also work for the TCollections, so we don't have duplicate code. Actually, there was an `assert` also in the old [TRangeStaticCast implementation](https://github.com/root-project/root/blob/master/core/cont/inc/TCollection.h#L355)! So to stay consistent with TRangeStaticCast, I had to bring the `assert` in so that change request is also addressed now :) And we can also use the existing unit test in `testTypedIteration.cxx`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8769#issuecomment-891218910
Availability,error,errors,"Hii @guitargeek ! ; cmake output shows these errors while generating cache ; ```; `system runtime library file does not exist:; 2> [CMake] 'MSVC_REDIST_DIR-NOTFOUND/x64/Microsoft.VC142.CRT/msvcp140.dll'`; ```; ```; system runtime library file does not exist:; 2> [CMake] 'MSVC_REDIST_DIR-NOTFOUND/x64/Microsoft.VC142.CRT/vcruntime140.dll'; ```; ```; system runtime library file does not exist:; 2> [CMake] 'MSVC_REDIST_DIR-NOTFOUND/x64/Microsoft.VC142.CRT/concrt140.dll'; ```; and while building ; `error : 'LZMA/src/LZMA/lib/liblzma.lib', needed by 'bin/Core.dll'` . Sadly I don't have any other system apart from this one, but I will try to reach my university's Linux system once my exams get over (which ends in Feb 3rd week ) and hopefully by that time there will be relaxation in covid guidelines . Until then I guess I will try to build this in my windows. ; Thanks for replying to my queries.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8777#issuecomment-1029050145
Performance,cache,cache,"Hii @guitargeek ! ; cmake output shows these errors while generating cache ; ```; `system runtime library file does not exist:; 2> [CMake] 'MSVC_REDIST_DIR-NOTFOUND/x64/Microsoft.VC142.CRT/msvcp140.dll'`; ```; ```; system runtime library file does not exist:; 2> [CMake] 'MSVC_REDIST_DIR-NOTFOUND/x64/Microsoft.VC142.CRT/vcruntime140.dll'; ```; ```; system runtime library file does not exist:; 2> [CMake] 'MSVC_REDIST_DIR-NOTFOUND/x64/Microsoft.VC142.CRT/concrt140.dll'; ```; and while building ; `error : 'LZMA/src/LZMA/lib/liblzma.lib', needed by 'bin/Core.dll'` . Sadly I don't have any other system apart from this one, but I will try to reach my university's Linux system once my exams get over (which ends in Feb 3rd week ) and hopefully by that time there will be relaxation in covid guidelines . Until then I guess I will try to build this in my windows. ; Thanks for replying to my queries.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8777#issuecomment-1029050145
Usability,guid,guidelines,"Hii @guitargeek ! ; cmake output shows these errors while generating cache ; ```; `system runtime library file does not exist:; 2> [CMake] 'MSVC_REDIST_DIR-NOTFOUND/x64/Microsoft.VC142.CRT/msvcp140.dll'`; ```; ```; system runtime library file does not exist:; 2> [CMake] 'MSVC_REDIST_DIR-NOTFOUND/x64/Microsoft.VC142.CRT/vcruntime140.dll'; ```; ```; system runtime library file does not exist:; 2> [CMake] 'MSVC_REDIST_DIR-NOTFOUND/x64/Microsoft.VC142.CRT/concrt140.dll'; ```; and while building ; `error : 'LZMA/src/LZMA/lib/liblzma.lib', needed by 'bin/Core.dll'` . Sadly I don't have any other system apart from this one, but I will try to reach my university's Linux system once my exams get over (which ends in Feb 3rd week ) and hopefully by that time there will be relaxation in covid guidelines . Until then I guess I will try to build this in my windows. ; Thanks for replying to my queries.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8777#issuecomment-1029050145
Usability,simpl,simple,"Hi @Axel-Naumann ,. This is very simple, but seems to be unmerged and 6-24-04 still has this bug. Best regards,. Andrii",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8778#issuecomment-948526134
Usability,guid,guide,"So what you need is `GENERATE_QHP` enabled in Doxyfile while generating the reference guide , right ? Have you tried it ? does the result doxygen produces is what you need ?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8781#issuecomment-901257232
Usability,guid,guide,Sorry for my ignorance but this .qch file contains what ? I guess it cannot be the whole reference guide ? that would be a huge file ... Is it references to the guide on the web ? in that case I do not understand your statement in your first post when you said: _which is also great if you don't have internet connection_,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8781#issuecomment-901747042
Usability,guid,guide,"It is a compressed qt help file, stored locally. Yes, it is potentially a very large file. (Could be enabled via cmake flag). It contains all the html info of the guide.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8781#issuecomment-901748882
Usability,guid,guide,We do not use cmake to build the reference guide. It is a separated Makefile.; Yes that file might be huge. How are managed the pictures ? they are somehow included in it ?; I will try what is suggested in your insa-lyon link,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8781#issuecomment-901752118
Usability,guid,guide,I have modified the following entries in Doxyfile:; ```; GENERATE_QHP = YES ; QCH_FILE = ROOT.qch ; QHP_NAMESPACE = ROOT.Project; QHG_LOCATION = /Users/couet/Qt/6.1.2/macos/bin/qhelpgenerator; ```; I regenerated the hist part of the reference guide on my local machine.; I was expecting the file `ROOT.qch` will appear somewhere . But it does not.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8781#issuecomment-902760247
Availability,avail,available,"Ok, I found the issue why qhelpgenerator is failing, it is due to:. ```; /opt/root_src/documentation/doxygen/mainpage.md:4: warning: found subsubsection command outside of subsection context!; /opt/root_src/documentation/doxygen/mainpage.md:10: warning: found subsubsection command outside of subsection context!; /opt/root_src/documentation/doxygen/mainpage.md:18: warning: found subsubsection command outside of subsection context!; ```. If I change in `mainpage.md` to:; ```; \mainpage %ROOT Reference Documentation. # Introduction; Welcome to %ROOT!. This is the reference manual of the ROOT software tooklit.; You can find in the [reference documentation page](https://root.cern/reference/) pointers to reference manuals for all %ROOT versions. ## Other types of documentation:. - [ROOT Primer](https://root.cern/primer/).; - [ROOT Introductory Course](https://github.com/root-project/training/tree/master/BasicCourse).; - A rich set of %ROOT [tutorials and code examples](https://root.cern/doc/master/group__Tutorials.html) are offered to developers to exercise specific functionality.; - A general [Manual](https://root.cern/manual/) is provided for a more in depth explanation of concepts and functionality available in the %ROOT system.; - A number of topical [User Guides and Manuals](https://root.cern/topical/) for various components of the system. ## Provide your feedback; If you have suggestions about how to improve this documentation, you can let us know:. - With a [PR](https://github.com/root-project/root); - On the [ROOT Forum](https://root-forum.cern.ch); - On [our tracker](https://github.com/root-project/root/issues); ```; then `ROOT.qch` is correctly generated.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8781#issuecomment-910397486
Usability,feedback,feedback,"Ok, I found the issue why qhelpgenerator is failing, it is due to:. ```; /opt/root_src/documentation/doxygen/mainpage.md:4: warning: found subsubsection command outside of subsection context!; /opt/root_src/documentation/doxygen/mainpage.md:10: warning: found subsubsection command outside of subsection context!; /opt/root_src/documentation/doxygen/mainpage.md:18: warning: found subsubsection command outside of subsection context!; ```. If I change in `mainpage.md` to:; ```; \mainpage %ROOT Reference Documentation. # Introduction; Welcome to %ROOT!. This is the reference manual of the ROOT software tooklit.; You can find in the [reference documentation page](https://root.cern/reference/) pointers to reference manuals for all %ROOT versions. ## Other types of documentation:. - [ROOT Primer](https://root.cern/primer/).; - [ROOT Introductory Course](https://github.com/root-project/training/tree/master/BasicCourse).; - A rich set of %ROOT [tutorials and code examples](https://root.cern/doc/master/group__Tutorials.html) are offered to developers to exercise specific functionality.; - A general [Manual](https://root.cern/manual/) is provided for a more in depth explanation of concepts and functionality available in the %ROOT system.; - A number of topical [User Guides and Manuals](https://root.cern/topical/) for various components of the system. ## Provide your feedback; If you have suggestions about how to improve this documentation, you can let us know:. - With a [PR](https://github.com/root-project/root); - On the [ROOT Forum](https://root-forum.cern.ch); - On [our tracker](https://github.com/root-project/root/issues); ```; then `ROOT.qch` is correctly generated.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8781#issuecomment-910397486
Usability,guid,guide,"> The `###` to `#` or `##`. It complains that there is a `subsubsection` with no parent 'section'. Ah ok ... but that looks ugly (I tried) the headers are far too big. I guess we never use ""#"" only in the root ref guide. So fixing the main page might be not enough . The same problem might show with other pages. For instance here: https://github.com/root-project/root/blob/8a63f78a3f910b3bb8b7758a5af06a80d09e567f/hist/hist/src/TH1.cxx#L139",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8781#issuecomment-910444480
Usability,guid,guide,@ferdymercury thanks to let me know. See the bottom of https://root.cern/doc/master/ . 1.9.3 is already the doxygen version used to build the ROOT reference guide. So we can close this issue ?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8781#issuecomment-1008843828
Deployability,install,install,"Ok, I did the apt install as you suggested (with the admin account) and I now get:; ```; $ qhelpgenerator; Missing input file name. Usage:. qhelpgenerator <file> [options]. -o <output-file> Generates a Qt compressed help; called <output-file> (*.qch) for the; Qt help project <file> (*.qhp).; Generates a Qt help collection; called <output-file> (*.qhc) for the; Qt help collection project <file> (*.qhcp).; If this option is not specified; a default name will be used; (*.qch for *.qhp and *.qhc for *.qhcp).; -c Checks whether all links in HTML files; point to files in this help project.; -s Suppresses status messages.; -v Displays the version of ; qhelpgenerator. ```; So I guess it is installed ... should I relaunch the ref guide build ?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8781#issuecomment-1009987639
Integrability,message,messages,"Ok, I did the apt install as you suggested (with the admin account) and I now get:; ```; $ qhelpgenerator; Missing input file name. Usage:. qhelpgenerator <file> [options]. -o <output-file> Generates a Qt compressed help; called <output-file> (*.qch) for the; Qt help project <file> (*.qhp).; Generates a Qt help collection; called <output-file> (*.qhc) for the; Qt help collection project <file> (*.qhcp).; If this option is not specified; a default name will be used; (*.qch for *.qhp and *.qhc for *.qhcp).; -c Checks whether all links in HTML files; point to files in this help project.; -s Suppresses status messages.; -v Displays the version of ; qhelpgenerator. ```; So I guess it is installed ... should I relaunch the ref guide build ?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8781#issuecomment-1009987639
Usability,guid,guide,"Ok, I did the apt install as you suggested (with the admin account) and I now get:; ```; $ qhelpgenerator; Missing input file name. Usage:. qhelpgenerator <file> [options]. -o <output-file> Generates a Qt compressed help; called <output-file> (*.qch) for the; Qt help project <file> (*.qhp).; Generates a Qt help collection; called <output-file> (*.qhc) for the; Qt help collection project <file> (*.qhcp).; If this option is not specified; a default name will be used; (*.qch for *.qhp and *.qhc for *.qhcp).; -c Checks whether all links in HTML files; point to files in this help project.; -s Suppresses status messages.; -v Displays the version of ; qhelpgenerator. ```; So I guess it is installed ... should I relaunch the ref guide build ?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8781#issuecomment-1009987639
Usability,guid,guide,Indeed the ref-guide build for 6.24 did not start yet (looking for an executor) ; https://lcgapp-services.cern.ch/root-jenkins/view/ROOT/job/root-makedoc-v624/; so it should be fine.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8781#issuecomment-1009992846
Deployability,install,installed,Master ref guide was rebuilt before qhelpgenerator was installed maybe?. ![image](https://user-images.githubusercontent.com/10653970/149124427-a8355b4c-2202-4da3-9f0e-cd220f3a1d60.png),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8781#issuecomment-1010898506
Usability,guid,guide,Master ref guide was rebuilt before qhelpgenerator was installed maybe?. ![image](https://user-images.githubusercontent.com/10653970/149124427-a8355b4c-2202-4da3-9f0e-cd220f3a1d60.png),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8781#issuecomment-1010898506
Availability,error,error,"Yes, that's to be expected because of the error in the command:; `qhelpgenerator index.qhp`. I checked locally and I am seeing the same error. It seems the index.qhp file is corrupted here because of a mismatch in section opening and closing tags:; ```. <toc>; <section title=""ROOT master"" ref=""index.html"">; <section title=""ROOT Reference Documentation"" ref=""index.html"">; <section title=""Introduction"" ref=""index.html#autotoc_md0"" />; <section title=""Manuals"" ref=""index.html#autotoc_md1"" />; <section title=""Tutorials and courses"" ref=""index.html#autotoc_md2"" />; <section title=""Provide your feedback"" ref=""index.html#autotoc_md3"" />; </section>; </section>; </section>; <section title=""Tutorials"" ref=""group__Tutorials.html"" />; ```; I guess I will have to file another bug report in doxygen :s",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8781#issuecomment-1011056200
Usability,feedback,feedback,"Yes, that's to be expected because of the error in the command:; `qhelpgenerator index.qhp`. I checked locally and I am seeing the same error. It seems the index.qhp file is corrupted here because of a mismatch in section opening and closing tags:; ```. <toc>; <section title=""ROOT master"" ref=""index.html"">; <section title=""ROOT Reference Documentation"" ref=""index.html"">; <section title=""Introduction"" ref=""index.html#autotoc_md0"" />; <section title=""Manuals"" ref=""index.html#autotoc_md1"" />; <section title=""Tutorials and courses"" ref=""index.html#autotoc_md2"" />; <section title=""Provide your feedback"" ref=""index.html#autotoc_md3"" />; </section>; </section>; </section>; <section title=""Tutorials"" ref=""group__Tutorials.html"" />; ```; I guess I will have to file another bug report in doxygen :s",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8781#issuecomment-1011056200
Usability,undo,undocumented,"Yep, but it seems that this issue is still buggy in master. They suggest a workaround, but not sure... ```; QUICK FIXES FOR USERS:. If you personally encounter this ""Error in line 4595: Opening and ending tag; mismatch."", and you just want to fix that issue, then the solution is to; either make sure that all your enums are documented or that they are; appropriately hidden (nested in an undocumented class, or nested in a; filtered-out namespace (e.g., ""detail"")). This is what I did, it fixed all; my issues.; ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8781#issuecomment-1011076618
Deployability,update,update,"> They have the same name. We would probably ""just"" need to also tag roottest as `latest_stable`, and update the tag whenever we update root.git's `latest_stable`. That is one of the possible solutions. The other is to add additional code in `CMakeLists.txt` to checkout the corresponding branch of `roottest`, if `latest-stable` has been checked out in the `root` repository, i.e. something similar to; ```; $ git for-each-ref --points-at=latest-stable^2 --format='%(refname:short)'; v6-24-06; ```; And then checkout `v6-24-06` in `roottest`, which is what `latest-stable` points to. For the sake of a simpler release procedure, I vote for this option given that it should only require 3 additional lines in `CMakeLists.txt`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8783#issuecomment-925104676
Usability,simpl,simpler,"> They have the same name. We would probably ""just"" need to also tag roottest as `latest_stable`, and update the tag whenever we update root.git's `latest_stable`. That is one of the possible solutions. The other is to add additional code in `CMakeLists.txt` to checkout the corresponding branch of `roottest`, if `latest-stable` has been checked out in the `root` repository, i.e. something similar to; ```; $ git for-each-ref --points-at=latest-stable^2 --format='%(refname:short)'; v6-24-06; ```; And then checkout `v6-24-06` in `roottest`, which is what `latest-stable` points to. For the sake of a simpler release procedure, I vote for this option given that it should only require 3 additional lines in `CMakeLists.txt`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8783#issuecomment-925104676
Testability,test,test,"@hahnjo Thanks for the comment! I can move it there, but do I really need to derive from TRandomEngine? The parent methods are for double Rndm(), which does not seem very useful to me.; This generator is a binary register generator, so rather a quite different structure, and it is not intended to be used as a normal generator, but rather as a test scenario or helper math functions for electronics testing. It also is inherently templated, etc. It returns an array rather than just a number Rndm(). See https://github.com/root-project/root/pull/8798/files#diff-2e848ceefaff2e24c9b2970fb86a8da1d3d00603fc4f48f920421e603198fab2. Wrt tests, I will 'copy' the mentioned tutorial as 'test' once it's clear where this class should go. Thanks for the review!! :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8798#issuecomment-2078772470
Usability,clear,clear,"@hahnjo Thanks for the comment! I can move it there, but do I really need to derive from TRandomEngine? The parent methods are for double Rndm(), which does not seem very useful to me.; This generator is a binary register generator, so rather a quite different structure, and it is not intended to be used as a normal generator, but rather as a test scenario or helper math functions for electronics testing. It also is inherently templated, etc. It returns an array rather than just a number Rndm(). See https://github.com/root-project/root/pull/8798/files#diff-2e848ceefaff2e24c9b2970fb86a8da1d3d00603fc4f48f920421e603198fab2. Wrt tests, I will 'copy' the mentioned tutorial as 'test' once it's clear where this class should go. Thanks for the review!! :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8798#issuecomment-2078772470
Performance,perform,performance,> Did you make any performance studies?. I wanted to see with rootbench. I did a simple `root hsimple.C` comparison where I neither expected nor saw noticeable differences.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8804#issuecomment-893758696
Usability,simpl,simple,> Did you make any performance studies?. I wanted to see with rootbench. I did a simple `root hsimple.C` comparison where I neither expected nor saw noticeable differences.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8804#issuecomment-893758696
Usability,simpl,simple,"About naming: although `std::strtok` does a simple string splitting, tokenization is often understood as a more complex operation than string splitting, involving some lexing, see e.g. https://docs.python.org/3/library/tokenize.html (vs the simple Python string split mentioned above) and https://github.com/ArashPartow/lexertk . I would suggest to just call this `Split`, if other people share this ""tokenizing sounds more complex than just splitting"" feeling.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8807#issuecomment-895069093
Integrability,depend,depend,"Even simpler reproducer, that doesn't depend on `TObject` at all (sorry for the noise); ```py; import ROOT. ROOT.gInterpreter.Declare(; '''; class A {};; class B: public A {};; class C: public B {};. void myfunc(const B &b){; std::cout << ""B"" << std::endl;; }. void myfunc(const C &c){; std::cout << ""c"" << std::endl;; }. '''). ROOT.myfunc(ROOT.B()); ROOT.myfunc(ROOT.C()); ```. output:; ```; B; B; ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8817#issuecomment-896106638
Usability,simpl,simpler,"Even simpler reproducer, that doesn't depend on `TObject` at all (sorry for the noise); ```py; import ROOT. ROOT.gInterpreter.Declare(; '''; class A {};; class B: public A {};; class C: public B {};. void myfunc(const B &b){; std::cout << ""B"" << std::endl;; }. void myfunc(const C &c){; std::cout << ""c"" << std::endl;; }. '''). ROOT.myfunc(ROOT.B()); ROOT.myfunc(ROOT.C()); ```. output:; ```; B; B; ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8817#issuecomment-896106638
Modifiability,inherit,inheritance,"After some investigation, it seems this issue is due to the priority level assigned to the two overloads. Specifically, the logic at https://github.com/root-project/root/blob/896940ef8c0936ad394a1cf6b98d1d8fbaabbfff/bindings/pyroot/cppyy/CPyCppyy/src/CPPMethod.cxx#L408-L412. seems to aim at assigning higher priority to class types that have a deeper inheritance chain. In the reproducer above, this should translate to class `B` having priority 1 (because it has 1 base class `A`) and class `C` having priority 2 (because it has 2 base classes `A,B`). The function this logic relies on ([GetNumBases](https://github.com/root-project/root/blob/87a998d48803bc207288d90038e60ff148827664/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/src/clingwrapper.cxx#L1212)) in turn calls [TClass::GetListOfBases](https://github.com/root-project/root/blob/87a998d48803bc207288d90038e60ff148827664/core/meta/src/TClass.cxx#L3620) which does not return all the bases in the full inheritance chain of the class, rather just the direct bases of a class. So in this case:; ```; >>> import ROOT; >>> ROOT.gInterpreter.Declare(; ... '''; ... class A {};; ... class B: public A {};; ... class C: public B {};; ... '''); True; >>> c = ROOT.TClass.GetClass(""C""); >>> b = ROOT.TClass.GetClass(""B""); >>> len(c.GetListOfBases()); 1; >>> len(b.GetListOfBases()); 1; ```. In this case, if TClass:GetListOfBases returned a list of size 2 for class `C`, the correct overload would get assigned a higher priority and thus would be chosen at runtime. There is no clear general solution, but it is worth highlighting the cause of the issue",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8817#issuecomment-897023454
Testability,log,logic,"After some investigation, it seems this issue is due to the priority level assigned to the two overloads. Specifically, the logic at https://github.com/root-project/root/blob/896940ef8c0936ad394a1cf6b98d1d8fbaabbfff/bindings/pyroot/cppyy/CPyCppyy/src/CPPMethod.cxx#L408-L412. seems to aim at assigning higher priority to class types that have a deeper inheritance chain. In the reproducer above, this should translate to class `B` having priority 1 (because it has 1 base class `A`) and class `C` having priority 2 (because it has 2 base classes `A,B`). The function this logic relies on ([GetNumBases](https://github.com/root-project/root/blob/87a998d48803bc207288d90038e60ff148827664/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/src/clingwrapper.cxx#L1212)) in turn calls [TClass::GetListOfBases](https://github.com/root-project/root/blob/87a998d48803bc207288d90038e60ff148827664/core/meta/src/TClass.cxx#L3620) which does not return all the bases in the full inheritance chain of the class, rather just the direct bases of a class. So in this case:; ```; >>> import ROOT; >>> ROOT.gInterpreter.Declare(; ... '''; ... class A {};; ... class B: public A {};; ... class C: public B {};; ... '''); True; >>> c = ROOT.TClass.GetClass(""C""); >>> b = ROOT.TClass.GetClass(""B""); >>> len(c.GetListOfBases()); 1; >>> len(b.GetListOfBases()); 1; ```. In this case, if TClass:GetListOfBases returned a list of size 2 for class `C`, the correct overload would get assigned a higher priority and thus would be chosen at runtime. There is no clear general solution, but it is worth highlighting the cause of the issue",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8817#issuecomment-897023454
Usability,clear,clear,"After some investigation, it seems this issue is due to the priority level assigned to the two overloads. Specifically, the logic at https://github.com/root-project/root/blob/896940ef8c0936ad394a1cf6b98d1d8fbaabbfff/bindings/pyroot/cppyy/CPyCppyy/src/CPPMethod.cxx#L408-L412. seems to aim at assigning higher priority to class types that have a deeper inheritance chain. In the reproducer above, this should translate to class `B` having priority 1 (because it has 1 base class `A`) and class `C` having priority 2 (because it has 2 base classes `A,B`). The function this logic relies on ([GetNumBases](https://github.com/root-project/root/blob/87a998d48803bc207288d90038e60ff148827664/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/src/clingwrapper.cxx#L1212)) in turn calls [TClass::GetListOfBases](https://github.com/root-project/root/blob/87a998d48803bc207288d90038e60ff148827664/core/meta/src/TClass.cxx#L3620) which does not return all the bases in the full inheritance chain of the class, rather just the direct bases of a class. So in this case:; ```; >>> import ROOT; >>> ROOT.gInterpreter.Declare(; ... '''; ... class A {};; ... class B: public A {};; ... class C: public B {};; ... '''); True; >>> c = ROOT.TClass.GetClass(""C""); >>> b = ROOT.TClass.GetClass(""B""); >>> len(c.GetListOfBases()); 1; >>> len(b.GetListOfBases()); 1; ```. In this case, if TClass:GetListOfBases returned a list of size 2 for class `C`, the correct overload would get assigned a higher priority and thus would be chosen at runtime. There is no clear general solution, but it is worth highlighting the cause of the issue",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8817#issuecomment-897023454
Usability,feedback,feedback,"## DeepCode failed to analyze this pull request; Something went wrong despite trying multiple times, sorry about that.; Please comment this pull request with ""Retry DeepCode"" to manually retry, or [contact us](https://www.deepcode.ai/feedback?select=4&utm_source=gh_review) so that a human can look into the issue.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8827#issuecomment-895853494
Deployability,update,update,"The fix is 'simple':; ```; diff --git a/core/metacling/src/TCling.cxx b/core/metacling/src/TCling.cxx; index 7fe65825ea..656396ffcd 100644; --- a/core/metacling/src/TCling.cxx; +++ b/core/metacling/src/TCling.cxx; @@ -6646,9 +6646,13 @@ void TCling::RefreshClassInfo(TClass *cl, const clang::NamedDecl *def, bool alia; cl->ResetCaches();; TClass::RemoveClassDeclId(cci->GetDeclId());; if (def) {; - // It's a tag decl, not a namespace decl.; - cci->Init(*cci->GetType());; - TClass::AddClassToDeclIdMap(cci->GetDeclId(), cl);; + if (cci->GetType()) {; + // It's a tag decl, not a namespace decl.; + cci->Init(*cci->GetType());; + TClass::AddClassToDeclIdMap(cci->GetDeclId(), cl);; + } else {; + Error(""RefreshClassInfo"", ""Should not need to update the classInfo a non type decl: %s"", oldDef->getNameAsString().c_str());; + }; }; }; } else if (!cl->TestBit(TClass::kLoading) && !cl->fHasRootPcmInfo) {; ```; ```; root [0] namespace std { namespace Detail {} }; root [1] auto c = TClass::GetClass(""Detail""); (TClass *) 0x12ef3d7b0; root [2] namespace Detail {}; Error in <TInterpreter::RefreshClassInfo>: Should not need to update the classInfo a non type decl: Detail; ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8828#issuecomment-2372486833
Usability,simpl,simple,"The fix is 'simple':; ```; diff --git a/core/metacling/src/TCling.cxx b/core/metacling/src/TCling.cxx; index 7fe65825ea..656396ffcd 100644; --- a/core/metacling/src/TCling.cxx; +++ b/core/metacling/src/TCling.cxx; @@ -6646,9 +6646,13 @@ void TCling::RefreshClassInfo(TClass *cl, const clang::NamedDecl *def, bool alia; cl->ResetCaches();; TClass::RemoveClassDeclId(cci->GetDeclId());; if (def) {; - // It's a tag decl, not a namespace decl.; - cci->Init(*cci->GetType());; - TClass::AddClassToDeclIdMap(cci->GetDeclId(), cl);; + if (cci->GetType()) {; + // It's a tag decl, not a namespace decl.; + cci->Init(*cci->GetType());; + TClass::AddClassToDeclIdMap(cci->GetDeclId(), cl);; + } else {; + Error(""RefreshClassInfo"", ""Should not need to update the classInfo a non type decl: %s"", oldDef->getNameAsString().c_str());; + }; }; }; } else if (!cl->TestBit(TClass::kLoading) && !cl->fHasRootPcmInfo) {; ```; ```; root [0] namespace std { namespace Detail {} }; root [1] auto c = TClass::GetClass(""Detail""); (TClass *) 0x12ef3d7b0; root [2] namespace Detail {}; Error in <TInterpreter::RefreshClassInfo>: Should not need to update the classInfo a non type decl: Detail; ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8828#issuecomment-2372486833
Usability,simpl,simple,"> The fix is 'simple':. Well yes, see https://github.com/root-project/root/pull/9089 and discussion",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8828#issuecomment-2373131937
Usability,simpl,simply,"Actually, I found the old behaviour of root just ignoring unknown options extremely useful.; It allowed users to simply add their own command line options and parsing them in `.rootlogon.C`; A simple example I have been using for 15+ years:; ```; 	int argc = gApplication->Argc();; 	char** argv = gApplication->Argv();; 	for (int i=1; i<argc; i++) {; 		TString arg = argv[i];; 		if (arg == ""--browser"") {; 			new TBrowser();; 		}; 	}; ```. I can see the the arguments for the recent change, nevertheless I would very much like to keep the old behaviour.; My suggestion would be to add a command line option `--ignore-unknown`, after which all unknown options are ignored.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8850#issuecomment-1079188278
Performance,load,load,"Yes, I know about rootbrowse. The TBrowser was just the simplest example I have. It's not the only custom command line option I'm using, I also use this to manipulate gStyle, load .so files, etc. . Of course I am fully aware that my complaint feels a lot like https://xkcd.com/1172/...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8850#issuecomment-1079234719
Usability,simpl,simplest,"Yes, I know about rootbrowse. The TBrowser was just the simplest example I have. It's not the only custom command line option I'm using, I also use this to manipulate gStyle, load .so files, etc. . Of course I am fully aware that my complaint feels a lot like https://xkcd.com/1172/...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8850#issuecomment-1079234719
Testability,test,test,Errors above were due to some options unrecognized by `root` were actually necessary for other callables in the test. Last commit moves the check to `TRint` and also now checks if there are multiple unrecognized options issued by the user:. ```; $ root --random -z --nonexistingoption; root: unrecognized option '--random'; root: unrecognized option '-z'; root: unrecognized option '--nonexistingoption'; Try 'root --help' for more information.; ```. Also changed to using `std::cerr` for simplicity. Before merging we can discuss the correct output stream,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8868#issuecomment-902501605
Usability,simpl,simplicity,Errors above were due to some options unrecognized by `root` were actually necessary for other callables in the test. Last commit moves the check to `TRint` and also now checks if there are multiple unrecognized options issued by the user:. ```; $ root --random -z --nonexistingoption; root: unrecognized option '--random'; root: unrecognized option '-z'; root: unrecognized option '--nonexistingoption'; Try 'root --help' for more information.; ```. Also changed to using `std::cerr` for simplicity. Before merging we can discuss the correct output stream,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8868#issuecomment-902501605
Performance,perform,perform,This looks like a nasty mix of runtime reflection information and IO (we use TEmulatedTuple to abstract from implementation details of the tuple class in the stl to perform IO in a simple way). @pcanal would you be able to suggest a path to improve the current situation?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8875#issuecomment-2076689182
Usability,simpl,simple,This looks like a nasty mix of runtime reflection information and IO (we use TEmulatedTuple to abstract from implementation details of the tuple class in the stl to perform IO in a simple way). @pcanal would you be able to suggest a path to improve the current situation?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8875#issuecomment-2076689182
Usability,feedback,feedback,"## DeepCode failed to analyze this pull request; Something went wrong despite trying multiple times, sorry about that.; Please comment this pull request with ""Retry DeepCode"" to manually retry, or [contact us](https://www.deepcode.ai/feedback?select=4&utm_source=gh_review) so that a human can look into the issue.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8884#issuecomment-903637323
Availability,error,error,`curl -v https://github.com:443/root-project/root/raw/master/tutorials/dataframe/df017_vecOpsHEP.root -o file.root` show the problem. `github.com` server supports `HTTP 2` while `TWebFile` uses `HTTP 1.1`. Therefore `github.com` simply refuses first request with 400 error. Not sure if there is easy way to support `HTTP 2` with `TWebFile`,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8890#issuecomment-911515928
Usability,simpl,simply,`curl -v https://github.com:443/root-project/root/raw/master/tutorials/dataframe/df017_vecOpsHEP.root -o file.root` show the problem. `github.com` server supports `HTTP 2` while `TWebFile` uses `HTTP 1.1`. Therefore `github.com` simply refuses first request with 400 error. Not sure if there is easy way to support `HTTP 2` with `TWebFile`,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8890#issuecomment-911515928
Usability,simpl,simplest,"Problem here is that `Describe` defined in `tree/dataframe/inc/ROOT/RDF/RInterface.hxx` returns a string. The simplest solution is to call `print(df.Describe())` to format properly the string. ""Fixing"" the desired output would change the existing usage of `Describe()` - returned type change from string to void and printing inside of the Describe. This is what is going on:; ```python; def foo(): # returns string; return ""a\nb"". def bar(): # void; print(""a\nb""). foo() # this is our case, giving excplicitly ""a\nb""; bar() # this is good; print(foo()) # this is good; ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8893#issuecomment-1006570773
Deployability,update,updates,"Hi @Axel-Naumann ,. no, I was running just from home directory. But, let me have a look if 1) this behaviour will be seen after the recent updates of root in EPEL; 2)if I'm able to provide a simple reproducer. Best regards,. Andrii",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8904#issuecomment-908272636
Usability,simpl,simple,"Hi @Axel-Naumann ,. no, I was running just from home directory. But, let me have a look if 1) this behaviour will be seen after the recent updates of root in EPEL; 2)if I'm able to provide a simple reproducer. Best regards,. Andrii",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8904#issuecomment-908272636
Testability,test,test,Following Philippe's suggestion for the test (thanks!) it's clear that the current logic is not enough.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8934#issuecomment-908960572
Usability,clear,clear,Following Philippe's suggestion for the test (thanks!) it's clear that the current logic is not enough.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8934#issuecomment-908960572
Modifiability,config,configure,"Thanks for the feedback. Just as a suggestion, I think it would still be possible to migrate from that Makefile to a CMakeLists.txt. That way, one could configure via the command line what part of the docs to build, instead of having to modify the makeinput.sh script, which in turn modifies the git source directory, which brings us back to https://github.com/root-project/root/issues/8947",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8950#issuecomment-934484956
Usability,feedback,feedback,"Thanks for the feedback. Just as a suggestion, I think it would still be possible to migrate from that Makefile to a CMakeLists.txt. That way, one could configure via the command line what part of the docs to build, instead of having to modify the makeinput.sh script, which in turn modifies the git source directory, which brings us back to https://github.com/root-project/root/issues/8947",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8950#issuecomment-934484956
Usability,guid,guide,I am now looking at #8947. I am modifying the `Makefile` to left a clean source directory after build. `makeinput.sh` should be modified only temporarily by developers to make only part of the doc in order to speed the build when working on a specific part of the reference guide. This script is not only a static list. At the end is added the pieces of doc build by `xtract_docstrings.py`; and `print_roofit_pyz_doctrings.py`. But it is true that if one modifies (even temporarily) `makeinput.sh` then it will appears in `git status`. I am not should how a `cmake` approach will fix that.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8950#issuecomment-934492893
Usability,simpl,simple,Yes but the list of folders does not follow the classes naming .... You may need more something like `-DENABLE_HIST` .... but then is the `hist` folder we have `hist` and `histpainter` subfolders which might be enabled separately ... and this is a simple example there is much more complex structures for which we need a precise picking which is done by `makeinput.sh`,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8950#issuecomment-934499934
Deployability,integrat,integrating,"@MarkusFrankATcernch ; it's all clear now, nothing is missing. with the ROOT changes should be integrating fine.; thank you :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8955#issuecomment-915152676
Integrability,integrat,integrating,"@MarkusFrankATcernch ; it's all clear now, nothing is missing. with the ROOT changes should be integrating fine.; thank you :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8955#issuecomment-915152676
Usability,clear,clear,"@MarkusFrankATcernch ; it's all clear now, nothing is missing. with the ROOT changes should be integrating fine.; thank you :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8955#issuecomment-915152676
Usability,simpl,simplified,"> You see that after deleting the dataset gives exactly the same memory as after having created the dataset, so there is a problem, isn't it ?!?. I'm not convinced by this yet because I don't completely understand the output at this point. Yes, you are right, memory doesn't decrease, but starting from the third toy it also doesn't *increase* when `generate()` is called, right? So these numbers don't make sense to me to begin with, and I would rather not conclude that there is a memory leak based on . But anyway, I managed to convince myself by generating many more toys, and observing a steady memory increase over time. I did this with a simplified version of your reproducer:; ```C++; void Minimum2(); {; using namespace RooFit;; using namespace RooStats;. ProcInfo_t procinfo;; const float toMB = 1.f / 1024.f;. std::unique_ptr<TFile> f_ws{TFile::Open(""WS-YY-resonant_500_For_Comb.root"", ""READ"")};. auto *ws = f_ws->Get<RooWorkspace>(""combWS"");; auto *mc = static_cast<ModelConfig *>(ws->obj(""ModelConfig""));; auto *pdf = static_cast<RooSimultaneous *>(mc->GetPdf());. for (std::size_t index_toy = 1; index_toy < 500; index_toy++) {. const RooArgSet *Observables = (RooArgSet *)mc->GetObservables();; std::vector<std::unique_ptr<RooDataSet>> toyDatas;; std::map<string, RooDataSet *> toyDataMap;. RooCategory channellist{""channellist"", ""channellist""};. // generate each category; for (auto const &item : pdf->indexCat()) {; channellist.defineType(item.first.c_str());; RooAbsPdf *pdftmp = pdf->getPdf(item.first.c_str());. RooArgSet obstmp;; pdftmp->getObservables(Observables, obstmp);. toyDatas.emplace_back(static_cast<RooDataSet *>(pdftmp->generate(obstmp, Extended())));; toyDataMap[item.first.c_str()] = toyDatas.back().get();; }. RooRealVar wt(""wt"", ""wt"", 1);; RooDataSet toyData{""toyData"", """", {*Observables, wt}, Index(channellist), Import(toyDataMap), WeightVar(wt)};. if (index_toy % 10 == 0) {; gSystem->GetProcInfo(&procinfo);; std::cout << index_toy << "": "" << procinfo.fMemResi",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984#issuecomment-1387712730
Deployability,release,releases,"Hello @philippe554 ,; Indeed, we changed this behaviour a few releases ago, IIRC the reason was that the progressive output implementation had some problems, so we opted for capturing the output and releasing it only at the end, even at the expense of not covering cases such a progress bar.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8989#issuecomment-919060975
Usability,progress bar,progress bar,"Hello @philippe554 ,; Indeed, we changed this behaviour a few releases ago, IIRC the reason was that the progressive output implementation had some problems, so we opted for capturing the output and releasing it only at the end, even at the expense of not covering cases such a progress bar.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8989#issuecomment-919060975
Usability,undo,undoes,@Linev The first(2cf3535) and the last commit(3262d53) should be deleted. The last commit undoes the first. I could make an new PR if you think it is necessary.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9005#issuecomment-920572223
Usability,undo,undoes,"> The last commit undoes the first. I could make an new PR if you think it is necessary. Yes, please create new PR, removing these commits",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9005#issuecomment-922042561
Deployability,patch,patch,"Actually it worked for you because you centred the X title. In the previous macro, remove the X title centring and go to log scale in Y and you will get the problem you discovered. So that's not a regression. The bug fix simply revealed a problem (?) which was hidden by the bug generated by the X title centring. To make it short, with a ROOT version without the patch, try:; ```; {; auto c1 = new TCanvas(""c1"",""multigraph"",700,500);; c1->SetGrid();; auto *mg = new TMultiGraph();; std::vector<double> x1;; std::vector<double> sig1;; std::vector<double> sig2;; for (double E=1e-4;E<2e7;E*=1.1) {; x1.push_back(E);; sig1.push_back(10*pow(E,-0.1));; sig2.push_back(15*pow(E,-0.15));; }; auto g1 = new TGraph(x1.size(), x1.data(), sig1.data());; mg->Add(g1);; auto g2 = new TGraph(x1.size(), x1.data(), sig2.data());; mg->Add(g2);; mg->SetTitle(""; E (eV);#sigma (b)"");; mg->Draw(""AL"");; gPad->Update();; c1->SetLogy();; }; ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9011#issuecomment-957859532
Testability,log,log,"Actually it worked for you because you centred the X title. In the previous macro, remove the X title centring and go to log scale in Y and you will get the problem you discovered. So that's not a regression. The bug fix simply revealed a problem (?) which was hidden by the bug generated by the X title centring. To make it short, with a ROOT version without the patch, try:; ```; {; auto c1 = new TCanvas(""c1"",""multigraph"",700,500);; c1->SetGrid();; auto *mg = new TMultiGraph();; std::vector<double> x1;; std::vector<double> sig1;; std::vector<double> sig2;; for (double E=1e-4;E<2e7;E*=1.1) {; x1.push_back(E);; sig1.push_back(10*pow(E,-0.1));; sig2.push_back(15*pow(E,-0.15));; }; auto g1 = new TGraph(x1.size(), x1.data(), sig1.data());; mg->Add(g1);; auto g2 = new TGraph(x1.size(), x1.data(), sig2.data());; mg->Add(g2);; mg->SetTitle(""; E (eV);#sigma (b)"");; mg->Draw(""AL"");; gPad->Update();; c1->SetLogy();; }; ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9011#issuecomment-957859532
Usability,simpl,simply,"Actually it worked for you because you centred the X title. In the previous macro, remove the X title centring and go to log scale in Y and you will get the problem you discovered. So that's not a regression. The bug fix simply revealed a problem (?) which was hidden by the bug generated by the X title centring. To make it short, with a ROOT version without the patch, try:; ```; {; auto c1 = new TCanvas(""c1"",""multigraph"",700,500);; c1->SetGrid();; auto *mg = new TMultiGraph();; std::vector<double> x1;; std::vector<double> sig1;; std::vector<double> sig2;; for (double E=1e-4;E<2e7;E*=1.1) {; x1.push_back(E);; sig1.push_back(10*pow(E,-0.1));; sig2.push_back(15*pow(E,-0.15));; }; auto g1 = new TGraph(x1.size(), x1.data(), sig1.data());; mg->Add(g1);; auto g2 = new TGraph(x1.size(), x1.data(), sig2.data());; mg->Add(g2);; mg->SetTitle(""; E (eV);#sigma (b)"");; mg->Draw(""AL"");; gPad->Update();; c1->SetLogy();; }; ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9011#issuecomment-957859532
Availability,avail,available,"@jblomer : thanks a lot for your comments, I will address them shortly!; ; >One thing I'd like to discuss before merging is how we can unit test the code. If there is a stable, publicly available XRootD >service with test data, we can use the RRawFileDavix unit test as a blueprint. Otherwise, given that we have access to the xrootd >library, perhaps we can spawn a simple ad-hoc server in another thread. Well, I think one nice thing that we could do is to have an XRootD server with an HTTP plugin exporting same files with both root and HTTP protocols. Then we could simply run all the tests you currently have for the `RRawFileDavix` also for `RRawFileNetXNG`. If you have some stress tests we could even use them to benchmark the two protocols.; Could we use `root.cern.ch` to do this? Otherwise, I can create a small testing service, I would need to see what machine I can get.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012#issuecomment-922713482
Integrability,protocol,protocols,"@jblomer : thanks a lot for your comments, I will address them shortly!; ; >One thing I'd like to discuss before merging is how we can unit test the code. If there is a stable, publicly available XRootD >service with test data, we can use the RRawFileDavix unit test as a blueprint. Otherwise, given that we have access to the xrootd >library, perhaps we can spawn a simple ad-hoc server in another thread. Well, I think one nice thing that we could do is to have an XRootD server with an HTTP plugin exporting same files with both root and HTTP protocols. Then we could simply run all the tests you currently have for the `RRawFileDavix` also for `RRawFileNetXNG`. If you have some stress tests we could even use them to benchmark the two protocols.; Could we use `root.cern.ch` to do this? Otherwise, I can create a small testing service, I would need to see what machine I can get.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012#issuecomment-922713482
Modifiability,plugin,plugin,"@jblomer : thanks a lot for your comments, I will address them shortly!; ; >One thing I'd like to discuss before merging is how we can unit test the code. If there is a stable, publicly available XRootD >service with test data, we can use the RRawFileDavix unit test as a blueprint. Otherwise, given that we have access to the xrootd >library, perhaps we can spawn a simple ad-hoc server in another thread. Well, I think one nice thing that we could do is to have an XRootD server with an HTTP plugin exporting same files with both root and HTTP protocols. Then we could simply run all the tests you currently have for the `RRawFileDavix` also for `RRawFileNetXNG`. If you have some stress tests we could even use them to benchmark the two protocols.; Could we use `root.cern.ch` to do this? Otherwise, I can create a small testing service, I would need to see what machine I can get.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012#issuecomment-922713482
Security,access,access,"@jblomer : thanks a lot for your comments, I will address them shortly!; ; >One thing I'd like to discuss before merging is how we can unit test the code. If there is a stable, publicly available XRootD >service with test data, we can use the RRawFileDavix unit test as a blueprint. Otherwise, given that we have access to the xrootd >library, perhaps we can spawn a simple ad-hoc server in another thread. Well, I think one nice thing that we could do is to have an XRootD server with an HTTP plugin exporting same files with both root and HTTP protocols. Then we could simply run all the tests you currently have for the `RRawFileDavix` also for `RRawFileNetXNG`. If you have some stress tests we could even use them to benchmark the two protocols.; Could we use `root.cern.ch` to do this? Otherwise, I can create a small testing service, I would need to see what machine I can get.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012#issuecomment-922713482
Testability,test,test,"@jblomer : thanks a lot for your comments, I will address them shortly!; ; >One thing I'd like to discuss before merging is how we can unit test the code. If there is a stable, publicly available XRootD >service with test data, we can use the RRawFileDavix unit test as a blueprint. Otherwise, given that we have access to the xrootd >library, perhaps we can spawn a simple ad-hoc server in another thread. Well, I think one nice thing that we could do is to have an XRootD server with an HTTP plugin exporting same files with both root and HTTP protocols. Then we could simply run all the tests you currently have for the `RRawFileDavix` also for `RRawFileNetXNG`. If you have some stress tests we could even use them to benchmark the two protocols.; Could we use `root.cern.ch` to do this? Otherwise, I can create a small testing service, I would need to see what machine I can get.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012#issuecomment-922713482
Usability,simpl,simple,"@jblomer : thanks a lot for your comments, I will address them shortly!; ; >One thing I'd like to discuss before merging is how we can unit test the code. If there is a stable, publicly available XRootD >service with test data, we can use the RRawFileDavix unit test as a blueprint. Otherwise, given that we have access to the xrootd >library, perhaps we can spawn a simple ad-hoc server in another thread. Well, I think one nice thing that we could do is to have an XRootD server with an HTTP plugin exporting same files with both root and HTTP protocols. Then we could simply run all the tests you currently have for the `RRawFileDavix` also for `RRawFileNetXNG`. If you have some stress tests we could even use them to benchmark the two protocols.; Could we use `root.cern.ch` to do this? Otherwise, I can create a small testing service, I would need to see what machine I can get.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012#issuecomment-922713482
Usability,simpl,simply,- It looks good. Thanks.; - I think for THistPainter::PaintErrors() it is simply missing.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9015#issuecomment-923867560
Usability,simpl,simply,> * It looks good. Thanks.; > * I think for THistPainter::PaintErrors() it is simply missing. Now the offsets are also implemented for THistPainter::PaintErrors().,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9015#issuecomment-923877185
Usability,clear,clear,The `Histo1D` case comes from a pythonization that replaces the original proxy method by a Python function. Perhaps the same pythonization could take care of forwarding to the original method when possible. What is not clear is why `Count` and `Report` do not print docs.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9023#issuecomment-925569986
Energy Efficiency,efficient,efficient,"rging, but the logical steps seem to be equivalent to me. Or I also might be misinterpreting your proposal. No, the approaches are different. In the approach without `RDataFrame::Merge` I save twice the modified trees with the new column added, so the whole thing is slower than the second approach where the looping and saving can be done only once. . > ; > ## Current possible approaches; > If you need to process a dataset with RDF and need to concatenate parts of it, the current best approach is to use the `RDataFrame(TTree &tree)` constructor after having created the correct tree with all the information you need. If for example you need to concatenate vertically 2 or more TTrees (i.e. if all have the same schema with column `a` and you want to append values of the same column into a single entity), than you can create a TChain and add all the trees to it. If you need horizontal concatenation (i.e. the trees have different schema but same number of entries) you can use friends pattern (e.g. `tree.AddFriend`). This has the big advantage that you don't need to merge any of the files/trees together and thus you also don't need to save them again before creating the RDF object. At the same time, once you do create the RDF object with this; concatenated dataset, you will still be able to call `Snapshot` and get practically a ""merged"" dataset in your output file. OK, I agree with this and this is a third approach what you propose. The trees can be added as a chain to the `RDataFrame`, the chain can get branches added with `Define` and then `Snapshot` would make a merged version. This would probably mean looping and saving only once and it is efficient. However what if we have 3 trees in the brach and we need a branch `index` whose value is `1` for the first tree `2` for the second and `3` for the third. How would we do that with `Define`? Stuff like:. ```python; df = df.Define('index', 'GetTreeNumber() + 1'); ```. would not work, right?. Cheers. > ; > Cheers,; > Vincenzo",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030#issuecomment-927331768
Integrability,interface,interface,"Dear @vepadulano . Thanks for your reply. > Dear @acampove,; > Thanks contacting us. We should probably wait for @eguiraud for a final answer, but I'd like to give my two cents about this.; > ; > > Instances of RDataFrame objects are meant to be treated like trees.; > ; > I am curious about this first sentence. I have never got this impression, neither reading docs / toying with tutorials or doing more complex analyses with RDF. the first line of the [RDF docs](https://root.cern/doc/master/classROOT_1_1RDataFrame.html) says `ROOT's RDataFrame offers a high level interface for analyses of data stored in TTree, CSV's and other data formats. `. Just by the fact that I can read and process other formats than TTree I would say that in general RDF is not meant to be treated like a TTree. Otherwise I would also have to say that RDF is meant to be treated like a CSV file or something similar. I did not refer to the documentation but to how people would actually use this class. 99% of people do not read CSV files with ROOT and `RDataFrame` will be mostly used to interact in a simple and quick way with trees. > ; > > there should be a function that allows us to merge them; > ; > If I have to think about this function you propose, I don't see it going much further than the example you already have above. Since RDataFrame **is not** the dataset itself, but just an interface to it, it still needs to open the file where the dataset is contained and read data from it. Thus, merging two RDF objects would still involve ` opening each file and saving them. Then loading them again and merging, then saving again` as you say above. Or at least the loading, merging and saving again part, if we consider that the part of your example where you create two files from scratch and save data into them with RDF could also just have been opening already existing files written by some other application before the merging. In fact the solution you provide follows exactly these steps:; > ; > ```pytho",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030#issuecomment-927331768
Performance,load,loading,"tored in TTree, CSV's and other data formats. `. Just by the fact that I can read and process other formats than TTree I would say that in general RDF is not meant to be treated like a TTree. Otherwise I would also have to say that RDF is meant to be treated like a CSV file or something similar. I did not refer to the documentation but to how people would actually use this class. 99% of people do not read CSV files with ROOT and `RDataFrame` will be mostly used to interact in a simple and quick way with trees. > ; > > there should be a function that allows us to merge them; > ; > If I have to think about this function you propose, I don't see it going much further than the example you already have above. Since RDataFrame **is not** the dataset itself, but just an interface to it, it still needs to open the file where the dataset is contained and read data from it. Thus, merging two RDF objects would still involve ` opening each file and saving them. Then loading them again and merging, then saving again` as you say above. Or at least the loading, merging and saving again part, if we consider that the part of your example where you create two files from scratch and save data into them with RDF could also just have been opening already existing files written by some other application before the merging. In fact the solution you provide follows exactly these steps:; > ; > ```python; > # Opening files and loading pre-existing datasets; > df_1=ROOT.RDataFrame('tree', file_path_1); > df_2=ROOT.RDataFrame('tree', file_path_2); > ; > # creating new columns in the datasets; > df_1=df_1.Define('identity', '+1'); > df_2=df_2.Define('identity', '+2'); > ; > # Merging the datasets in memory; > df_3 = df_1.Merge(df_2); > # Opening a new file and save the merged dataset into the new file; > df_3.Snapshot('tree', 'file.root'); > ```; > ; > I admit that I might not be able to see some internal optimizations that RDF might do while merging, but the logical steps seem to be equivalent",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030#issuecomment-927331768
Testability,log,logical,"volve ` opening each file and saving them. Then loading them again and merging, then saving again` as you say above. Or at least the loading, merging and saving again part, if we consider that the part of your example where you create two files from scratch and save data into them with RDF could also just have been opening already existing files written by some other application before the merging. In fact the solution you provide follows exactly these steps:; > ; > ```python; > # Opening files and loading pre-existing datasets; > df_1=ROOT.RDataFrame('tree', file_path_1); > df_2=ROOT.RDataFrame('tree', file_path_2); > ; > # creating new columns in the datasets; > df_1=df_1.Define('identity', '+1'); > df_2=df_2.Define('identity', '+2'); > ; > # Merging the datasets in memory; > df_3 = df_1.Merge(df_2); > # Opening a new file and save the merged dataset into the new file; > df_3.Snapshot('tree', 'file.root'); > ```; > ; > I admit that I might not be able to see some internal optimizations that RDF might do while merging, but the logical steps seem to be equivalent to me. Or I also might be misinterpreting your proposal. No, the approaches are different. In the approach without `RDataFrame::Merge` I save twice the modified trees with the new column added, so the whole thing is slower than the second approach where the looping and saving can be done only once. . > ; > ## Current possible approaches; > If you need to process a dataset with RDF and need to concatenate parts of it, the current best approach is to use the `RDataFrame(TTree &tree)` constructor after having created the correct tree with all the information you need. If for example you need to concatenate vertically 2 or more TTrees (i.e. if all have the same schema with column `a` and you want to append values of the same column into a single entity), than you can create a TChain and add all the trees to it. If you need horizontal concatenation (i.e. the trees have different schema but same number of entries",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030#issuecomment-927331768
Usability,simpl,simple,"@acampove,; > Thanks contacting us. We should probably wait for @eguiraud for a final answer, but I'd like to give my two cents about this.; > ; > > Instances of RDataFrame objects are meant to be treated like trees.; > ; > I am curious about this first sentence. I have never got this impression, neither reading docs / toying with tutorials or doing more complex analyses with RDF. the first line of the [RDF docs](https://root.cern/doc/master/classROOT_1_1RDataFrame.html) says `ROOT's RDataFrame offers a high level interface for analyses of data stored in TTree, CSV's and other data formats. `. Just by the fact that I can read and process other formats than TTree I would say that in general RDF is not meant to be treated like a TTree. Otherwise I would also have to say that RDF is meant to be treated like a CSV file or something similar. I did not refer to the documentation but to how people would actually use this class. 99% of people do not read CSV files with ROOT and `RDataFrame` will be mostly used to interact in a simple and quick way with trees. > ; > > there should be a function that allows us to merge them; > ; > If I have to think about this function you propose, I don't see it going much further than the example you already have above. Since RDataFrame **is not** the dataset itself, but just an interface to it, it still needs to open the file where the dataset is contained and read data from it. Thus, merging two RDF objects would still involve ` opening each file and saving them. Then loading them again and merging, then saving again` as you say above. Or at least the loading, merging and saving again part, if we consider that the part of your example where you create two files from scratch and save data into them with RDF could also just have been opening already existing files written by some other application before the merging. In fact the solution you provide follows exactly these steps:; > ; > ```python; > # Opening files and loading pre-existing dat",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030#issuecomment-927331768
Integrability,depend,depending,"How would we do that with Define?. Is it not possible to store these indexes in the trees when they are produced? If not, currently you have three possible solutions that I can think of:. - calculate the index from the value of `rdfentry_`, knowing how many entries are in each tree and their ordering inside the TChain; - store some unique identifier in each tree when it's produced (even a timestamp works, and although it's not elegant you don't have to worry about having that same value stored in each event because it will compress almost perfectly, occupying very little extra space on disk). With that unique identifier per tree you can build another tree that serves as a lookup table between id and index. It will have two branches, `id` and `index`, with the first taking the values of the ids of each tree and the second being an index from 0 to nTrees-1. Then you can use `TTree::BuildIndex` and `TChain::AddFriend` to add that lookup table tree as a friend of the original chain and thanks to `BuildIndex` the correct value of `index` will be returned for each event depending on the value of `id` in the original chain. More info at https://root.cern/manual/trees/#indexing-trees; - do a pass on each input tree to calculate whatever other quantities you need to calculate (let's call these trees `aux1`, `aux2` etc.), then make a TChain out of the original trees, another TChain out of the `aux` trees, and then add the second chain as a friend of the first (effectively creating a single large ""virtual"" TTree with everything in it). The simplest solution: with the upcoming `DefinePerSample` method you can solve this more easily, but the feature will only be merged in ROOT master in a few days ([PR here](https://github.com/root-project/root/pull/8841)). With `DefinePerSample` you could write something like this:. ```cpp; df.DefinePerSample(""index"", ""GetIndex(rdfsampleinfo_.AsString())""); ```. where `rdfsampleinfo_.AsString()` will be of the form `<filename>/<treename>`. I exp",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030#issuecomment-929346153
Usability,simpl,simply,"Hi,; assuming that simply producing a single tree to begin with is impossible, I would also recommend to go with a TChain for post-processing. > what if we have 3 trees in the brach and we need a branch index whose value is 1 for the first tree 2 for the second and 3 for the third. How would we do that with Define?. Is it not possible to store these indexes in the trees when they are produced? If not, currently you have three possible solutions that I can think of:. - calculate the index from the value of `rdfentry_`, knowing how many entries are in each tree and their ordering inside the TChain; - store some unique identifier in each tree when it's produced (even a timestamp works, and although it's not elegant you don't have to worry about having that same value stored in each event because it will compress almost perfectly, occupying very little extra space on disk). With that unique identifier per tree you can build another tree that serves as a lookup table between id and index. It will have two branches, `id` and `index`, with the first taking the values of the ids of each tree and the second being an index from 0 to nTrees-1. Then you can use `TTree::BuildIndex` and `TChain::AddFriend` to add that lookup table tree as a friend of the original chain and thanks to `BuildIndex` the correct value of `index` will be returned for each event depending on the value of `id` in the original chain. More info at https://root.cern/manual/trees/#indexing-trees; - do a pass on each input tree to calculate whatever other quantities you need to calculate (let's call these trees `aux1`, `aux2` etc.), then make a TChain out of the original trees, another TChain out of the `aux` trees, and then add the second chain as a friend of the first (effectively creating a single large ""virtual"" TTree with everything in it). The simplest solution: with the upcoming `DefinePerSample` method you can solve this more easily, but the feature will only be merged in ROOT master in a few days ([PR",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030#issuecomment-929346153
Availability,alive,alive," ch_data.AddFriend(treename, idfilepath). df = ROOT.RDataFrame(ch_data). return (df, ch_data); #------------------------------------------; def test():; #----------------------; #Make input; #----------------------; index = 0 ; l_tp_file = [] ; for val in range(0, 100, 10):; filepath = make_data(val); l_tp_file.append((index, filepath)); index+=1; #----------------------; #Merge; #----------------------; df, _ = get_df(l_tp_file, 'tree', id_column='id'); df.Display(['a', 'id'], -1).Print(); #df.Snapshot('tree', 'file.root'); #------------------------------------------; test(); ```. I will add `get_df` to my personal library. The approach seems safe and clean enough, however the return value needs to include the chain (i.e. _) because otherwise I get a crash. Which seems to indicate that the chain's reference is not kept inside the dataframe. So once the function returns, the chain is removed by the garbage collector and the dataframe does not have anything to save (the script above is self contained and you can try it yourself). That should not be right, if I tell the dataframe to use the chain, the chain should be kept alive by the dataframe. > ; > The simplest solution: with the upcoming `DefinePerSample` method you can solve this more easily, but the feature will only be merged in ROOT master in a few days ([PR here](https://github.com/root-project/root/pull/8841)). With `DefinePerSample` you could write something like this:; > ; > ```c++; > df.DefinePerSample(""index"", ""GetIndex(rdfsampleinfo_.AsString())""); > ```; > ; > where `rdfsampleinfo_.AsString()` will be of the form `<filename>/<treename>`. I expect to merge this feature in master today or tomorrow. So we would have to create a `GetIndex` function to extract from the ""filename/treename"" the index? Yes, that would make my code far simpler. However it might take months until that is available through CVMFS. In any case, the simpler our code gets, the better, fewer places for bugs to hide. Cheers and thanks.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030#issuecomment-932494638
Integrability,depend,depending,"e grid. We do need to postprocess these ntuples anyway, so the idea is to slip in a small function to add this index. ; > ; > * calculate the index from the value of `rdfentry_`, knowing how many entries are in each tree and their ordering inside the TChain. It is dangerous and requires adding too many lines of code. > * store some unique identifier in each tree when it's produced (even a timestamp works, and although it's not elegant you don't have to worry about having that same value stored in each event because it will compress almost perfectly, occupying very little extra space on disk). With that unique identifier per tree you can build another tree that serves as a lookup table between id and index. It will have two branches, `id` and `index`, with the first taking the values of the ids of each tree and the second being an index from 0 to nTrees-1. Then you can use `TTree::BuildIndex` and `TChain::AddFriend` to add that lookup table tree as a friend of the original chain and thanks to `BuildIndex` the correct value of `index` will be returned for each event depending on the value of `id` in the original chain. More info at https://root.cern/manual/trees/#indexing-trees. We would have to run again all the jobs in the grid to store a unique ID. However the name of the file identifies it, so we deduce the index with the filename. The rest of the solution is close to what I did below.; ; > * do a pass on each input tree to calculate whatever other quantities you need to calculate (let's call these trees `aux1`, `aux2` etc.), then make a TChain out of the original trees, another TChain out of the `aux` trees, and then add the second chain as a friend of the first (effectively creating a single large ""virtual"" TTree with everything in it). OK, that is closer to what we need, I managed to get the code below to add these indexes in a slightly different way from what you said (or maybe the same if I misunderstood you), i.e. using chains and friend trees:. ```python; im",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030#issuecomment-932494638
Safety,safe,safe,"yDataFrame({id_column: arr_id}); df_id.Snapshot(treename, idfilepath). ch_data = ROOT.TChain(treename, '') ; for _, filepath in l_tp_file:; ch_data.Add(filepath). size_ch = ch_data.GetEntries(); size_id = arr_id.size. if size_ch != size_id:; print('Different id and chain sizes: {}/{}'.format(size_id, size_ch)); raise. ch_data.AddFriend(treename, idfilepath). df = ROOT.RDataFrame(ch_data). return (df, ch_data); #------------------------------------------; def test():; #----------------------; #Make input; #----------------------; index = 0 ; l_tp_file = [] ; for val in range(0, 100, 10):; filepath = make_data(val); l_tp_file.append((index, filepath)); index+=1; #----------------------; #Merge; #----------------------; df, _ = get_df(l_tp_file, 'tree', id_column='id'); df.Display(['a', 'id'], -1).Print(); #df.Snapshot('tree', 'file.root'); #------------------------------------------; test(); ```. I will add `get_df` to my personal library. The approach seems safe and clean enough, however the return value needs to include the chain (i.e. _) because otherwise I get a crash. Which seems to indicate that the chain's reference is not kept inside the dataframe. So once the function returns, the chain is removed by the garbage collector and the dataframe does not have anything to save (the script above is self contained and you can try it yourself). That should not be right, if I tell the dataframe to use the chain, the chain should be kept alive by the dataframe. > ; > The simplest solution: with the upcoming `DefinePerSample` method you can solve this more easily, but the feature will only be merged in ROOT master in a few days ([PR here](https://github.com/root-project/root/pull/8841)). With `DefinePerSample` you could write something like this:; > ; > ```c++; > df.DefinePerSample(""index"", ""GetIndex(rdfsampleinfo_.AsString())""); > ```; > ; > where `rdfsampleinfo_.AsString()` will be of the form `<filename>/<treename>`. I expect to merge this feature in master today or to",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030#issuecomment-932494638
Testability,test,test,"r(val); filepath = '/tmp/file_{}.root'.format(val). df=ROOT.RDataFrame(2); df=df.Define('a', val); df.Snapshot('tree', filepath). return filepath; #------------------------------------------; def get_df(l_tp_file, treename, id_column='index'):; l_index = []; for index, filepath in l_tp_file:; df=ROOT.RDataFrame(treename, filepath); nentries = df.Count().GetValue(); l_index += nentries * [index]. arr_id = numpy.array(l_index). idfilepath = '/tmp/file_id.root'; df_id = ROOT.RDF.MakeNumpyDataFrame({id_column: arr_id}); df_id.Snapshot(treename, idfilepath). ch_data = ROOT.TChain(treename, '') ; for _, filepath in l_tp_file:; ch_data.Add(filepath). size_ch = ch_data.GetEntries(); size_id = arr_id.size. if size_ch != size_id:; print('Different id and chain sizes: {}/{}'.format(size_id, size_ch)); raise. ch_data.AddFriend(treename, idfilepath). df = ROOT.RDataFrame(ch_data). return (df, ch_data); #------------------------------------------; def test():; #----------------------; #Make input; #----------------------; index = 0 ; l_tp_file = [] ; for val in range(0, 100, 10):; filepath = make_data(val); l_tp_file.append((index, filepath)); index+=1; #----------------------; #Merge; #----------------------; df, _ = get_df(l_tp_file, 'tree', id_column='id'); df.Display(['a', 'id'], -1).Print(); #df.Snapshot('tree', 'file.root'); #------------------------------------------; test(); ```. I will add `get_df` to my personal library. The approach seems safe and clean enough, however the return value needs to include the chain (i.e. _) because otherwise I get a crash. Which seems to indicate that the chain's reference is not kept inside the dataframe. So once the function returns, the chain is removed by the garbage collector and the dataframe does not have anything to save (the script above is self contained and you can try it yourself). That should not be right, if I tell the dataframe to use the chain, the chain should be kept alive by the dataframe. > ; > The simplest solution: wi",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030#issuecomment-932494638
Usability,simpl,simply,"Hi,. > Hi, assuming that simply producing a single tree to begin with is impossible, I would also recommend to go with a TChain for post-processing. These trees are produced from jobs in the grid, it is not possible to produce a single file.; > ; > > what if we have 3 trees in the brach and we need a branch index whose value is 1 for the first tree 2 for the second and 3 for the third. How would we do that with Define?; > ; > Is it not possible to store these indexes in the trees when they are produced? If not, currently you have three possible solutions that I can think of:. It is possible to do that. However those trees do not have those indexes and in order to add them we would need to rerun hundreds of jobs in the grid. We do need to postprocess these ntuples anyway, so the idea is to slip in a small function to add this index. ; > ; > * calculate the index from the value of `rdfentry_`, knowing how many entries are in each tree and their ordering inside the TChain. It is dangerous and requires adding too many lines of code. > * store some unique identifier in each tree when it's produced (even a timestamp works, and although it's not elegant you don't have to worry about having that same value stored in each event because it will compress almost perfectly, occupying very little extra space on disk). With that unique identifier per tree you can build another tree that serves as a lookup table between id and index. It will have two branches, `id` and `index`, with the first taking the values of the ids of each tree and the second being an index from 0 to nTrees-1. Then you can use `TTree::BuildIndex` and `TChain::AddFriend` to add that lookup table tree as a friend of the original chain and thanks to `BuildIndex` the correct value of `index` will be returned for each event depending on the value of `id` in the original chain. More info at https://root.cern/manual/trees/#indexing-trees. We would have to run again all the jobs in the grid to store a unique ID. Howev",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030#issuecomment-932494638
Integrability,depend,depending,"I have not yet tried building llvm. Will try later this week. nvc++ has an implementation for std::par which allows seamless execution of both CPUs and NVIDIA GPUs (depending on a compile time flag). This could be a huge win for GPU portability (once other manufactures create the AMD/Intel backends), and allows much simpler user access to GPUs without having to learn CUDA (or hip, dpc++, etc). I was trying to compile some parts of a project with gcc and the bits that use std::par with nvc++, but immediately got some runtime segfaults at startup, so tried to compile the whole thing (including ROOT) with nvc++.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9036#issuecomment-933532217
Modifiability,portab,portability,"I have not yet tried building llvm. Will try later this week. nvc++ has an implementation for std::par which allows seamless execution of both CPUs and NVIDIA GPUs (depending on a compile time flag). This could be a huge win for GPU portability (once other manufactures create the AMD/Intel backends), and allows much simpler user access to GPUs without having to learn CUDA (or hip, dpc++, etc). I was trying to compile some parts of a project with gcc and the bits that use std::par with nvc++, but immediately got some runtime segfaults at startup, so tried to compile the whole thing (including ROOT) with nvc++.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9036#issuecomment-933532217
Security,access,access,"I have not yet tried building llvm. Will try later this week. nvc++ has an implementation for std::par which allows seamless execution of both CPUs and NVIDIA GPUs (depending on a compile time flag). This could be a huge win for GPU portability (once other manufactures create the AMD/Intel backends), and allows much simpler user access to GPUs without having to learn CUDA (or hip, dpc++, etc). I was trying to compile some parts of a project with gcc and the bits that use std::par with nvc++, but immediately got some runtime segfaults at startup, so tried to compile the whole thing (including ROOT) with nvc++.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9036#issuecomment-933532217
Usability,simpl,simpler,"I have not yet tried building llvm. Will try later this week. nvc++ has an implementation for std::par which allows seamless execution of both CPUs and NVIDIA GPUs (depending on a compile time flag). This could be a huge win for GPU portability (once other manufactures create the AMD/Intel backends), and allows much simpler user access to GPUs without having to learn CUDA (or hip, dpc++, etc). I was trying to compile some parts of a project with gcc and the bits that use std::par with nvc++, but immediately got some runtime segfaults at startup, so tried to compile the whole thing (including ROOT) with nvc++.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9036#issuecomment-933532217
Testability,test,tests,"Build failed on ROOT-fedora34/default.; Running on root-fedora34-1.cern.ch:/home/sftnight/build/workspace/root-pullrequests-build; [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/126763/console).; ### Warnings:; - [2021-10-04T15:57:57.930Z] /home/sftnight/build/workspace/root-pullrequests-build/build/ginclude/tbb/concurrent_hash_map.h:131:24: warning: void* memset(void*, int, size_t) clearing an object of type struct tbb::interface5::internal::hash_map_base::bucket with no trivial copy-assignment; use value-initialization instead [-Wclass-memaccess] . ### Failing tests:; - [projectroot.roottest.root.io.uniquePointer.roottest_root_io_uniquePointer_simpleWriteRead](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/126763/testReport/projectroot.roottest.root.io/uniquePointer/roottest_root_io_uniquePointer_simpleWriteRead/); - [projectroot.roottest.root.io.uniquePointer.roottest_root_io_uniquePointer_simpleRead](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/126763/testReport/projectroot.roottest.root.io/uniquePointer/roottest_root_io_uniquePointer_simpleRead/); - [projectroot.roottest.root.meta.MakeProject.roottest_root_meta_MakeProject_runaliceesd](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/126763/testReport/projectroot.roottest.root.meta/MakeProject/roottest_root_meta_MakeProject_runaliceesd/); - [projectroot.roottest.root.meta.ROOT-7462.roottest_root_meta_ROOT_7462_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/126763/testReport/projectroot.roottest.root.meta/ROOT-7462/roottest_root_meta_ROOT_7462_make/)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9066#issuecomment-933646782
Usability,clear,clearing,"Build failed on ROOT-fedora34/default.; Running on root-fedora34-1.cern.ch:/home/sftnight/build/workspace/root-pullrequests-build; [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/126763/console).; ### Warnings:; - [2021-10-04T15:57:57.930Z] /home/sftnight/build/workspace/root-pullrequests-build/build/ginclude/tbb/concurrent_hash_map.h:131:24: warning: void* memset(void*, int, size_t) clearing an object of type struct tbb::interface5::internal::hash_map_base::bucket with no trivial copy-assignment; use value-initialization instead [-Wclass-memaccess] . ### Failing tests:; - [projectroot.roottest.root.io.uniquePointer.roottest_root_io_uniquePointer_simpleWriteRead](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/126763/testReport/projectroot.roottest.root.io/uniquePointer/roottest_root_io_uniquePointer_simpleWriteRead/); - [projectroot.roottest.root.io.uniquePointer.roottest_root_io_uniquePointer_simpleRead](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/126763/testReport/projectroot.roottest.root.io/uniquePointer/roottest_root_io_uniquePointer_simpleRead/); - [projectroot.roottest.root.meta.MakeProject.roottest_root_meta_MakeProject_runaliceesd](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/126763/testReport/projectroot.roottest.root.meta/MakeProject/roottest_root_meta_MakeProject_runaliceesd/); - [projectroot.roottest.root.meta.ROOT-7462.roottest_root_meta_ROOT_7462_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/126763/testReport/projectroot.roottest.root.meta/ROOT-7462/roottest_root_meta_ROOT_7462_make/)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9066#issuecomment-933646782
Testability,test,tests,"Build failed on windows10/cxx14.; Running on null:C:\build\workspace\root-pullrequests-build; [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/126788/console).; ### Warnings:; - [2021-10-05T07:51:00.677Z] ghprbPullLongDescription=Should fix the following compilation warnings with `gcc 11` and the current `builtin_tbb`:\r\n```\r\nIn file included from ginclude/tbb/tbb.h:48,\r\n from /home/vpadulan/Programs/rootproject/root/core/imt/src/TThreadExecutor.cxx:10:\r\nginclude/tbb/concurrent_hash_map.h: In constructor 'tbb::interface5::internal::hash_map_base::hash_map_base()':\r\nginclude/tbb/concurrent_hash_map.h:131:24: warning: 'void* memset(void*, int, size_t)' clearing an object of type 'struct tbb::interface5::internal::hash_map_base::bucket' with no trivial copy-assignment; use value-initialization instead [-Wclass-memaccess]\r\n 131 | std::memset(my_embedded_segment, 0, sizeof(my_embedded_segment));\r\n | ~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\nginclude/tbb/concurrent_hash_map.h:93:16: note: 'struct tbb::interface5::internal::hash_map_base::bucket' declared here\r\n 93 | struct bucket : tbb::internal::no_copy {\r\n | ^~~~~~\r\n```\r\n . ### Failing tests:; - [projectroot.roottest.python.function.roottest_python_function_function](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/126788/testReport/projectroot.roottest.python/function/roottest_python_function_function/)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9067#issuecomment-934265717
Usability,clear,clearing,"Build failed on windows10/cxx14.; Running on null:C:\build\workspace\root-pullrequests-build; [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/126788/console).; ### Warnings:; - [2021-10-05T07:51:00.677Z] ghprbPullLongDescription=Should fix the following compilation warnings with `gcc 11` and the current `builtin_tbb`:\r\n```\r\nIn file included from ginclude/tbb/tbb.h:48,\r\n from /home/vpadulan/Programs/rootproject/root/core/imt/src/TThreadExecutor.cxx:10:\r\nginclude/tbb/concurrent_hash_map.h: In constructor 'tbb::interface5::internal::hash_map_base::hash_map_base()':\r\nginclude/tbb/concurrent_hash_map.h:131:24: warning: 'void* memset(void*, int, size_t)' clearing an object of type 'struct tbb::interface5::internal::hash_map_base::bucket' with no trivial copy-assignment; use value-initialization instead [-Wclass-memaccess]\r\n 131 | std::memset(my_embedded_segment, 0, sizeof(my_embedded_segment));\r\n | ~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\nginclude/tbb/concurrent_hash_map.h:93:16: note: 'struct tbb::interface5::internal::hash_map_base::bucket' declared here\r\n 93 | struct bucket : tbb::internal::no_copy {\r\n | ^~~~~~\r\n```\r\n . ### Failing tests:; - [projectroot.roottest.python.function.roottest_python_function_function](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/126788/testReport/projectroot.roottest.python/function/roottest_python_function_function/)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9067#issuecomment-934265717
Availability,failure,failures,"@egpbos Given my [comment](https://github.com/root-project/root/pull/8385#issuecomment-870570029) in your previous merge request, I am quite disappointed to learn that this has been merged as enabled by default when it depends on a yet unreleased version of ZeroMQ. This, for example, has caused failures in pretty much all the LCG builds today: https://cdash.cern.ch/index.php?project=LCGSoft&date=2021-11-29. Please disable `roofit_multiprocess` by default and re-enable it only when a *released version* of ZeroMQ has the functionality you need, adding the proper version in your call to `find_package()`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078#issuecomment-981617370
Deployability,release,released,"@egpbos Given my [comment](https://github.com/root-project/root/pull/8385#issuecomment-870570029) in your previous merge request, I am quite disappointed to learn that this has been merged as enabled by default when it depends on a yet unreleased version of ZeroMQ. This, for example, has caused failures in pretty much all the LCG builds today: https://cdash.cern.ch/index.php?project=LCGSoft&date=2021-11-29. Please disable `roofit_multiprocess` by default and re-enable it only when a *released version* of ZeroMQ has the functionality you need, adding the proper version in your call to `find_package()`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078#issuecomment-981617370
Integrability,depend,depends,"@egpbos Given my [comment](https://github.com/root-project/root/pull/8385#issuecomment-870570029) in your previous merge request, I am quite disappointed to learn that this has been merged as enabled by default when it depends on a yet unreleased version of ZeroMQ. This, for example, has caused failures in pretty much all the LCG builds today: https://cdash.cern.ch/index.php?project=LCGSoft&date=2021-11-29. Please disable `roofit_multiprocess` by default and re-enable it only when a *released version* of ZeroMQ has the functionality you need, adding the proper version in your call to `find_package()`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078#issuecomment-981617370
Usability,learn,learn,"@egpbos Given my [comment](https://github.com/root-project/root/pull/8385#issuecomment-870570029) in your previous merge request, I am quite disappointed to learn that this has been merged as enabled by default when it depends on a yet unreleased version of ZeroMQ. This, for example, has caused failures in pretty much all the LCG builds today: https://cdash.cern.ch/index.php?project=LCGSoft&date=2021-11-29. Please disable `roofit_multiprocess` by default and re-enable it only when a *released version* of ZeroMQ has the functionality you need, adding the proper version in your call to `find_package()`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078#issuecomment-981617370
Availability,error,error,"The compilation error seems to be due to a mismatch between the toolchain that was used to compile ROOT and the toolchain you are using to compile your program (e.g. different glibc version). I don't know enough about nixOS to suggest a fix. The massif output shows little memory usage (`mem_heap_B=72938`). Can you try using `root.exe` instead of `root` as the command? By removing one layer of indirection we might help massif see things properly (but of course if we can run on a compiled program rather than through the interpreter it makes everything simpler). Cheers,; Enrico",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9087#issuecomment-951644988
Usability,simpl,simpler,"The compilation error seems to be due to a mismatch between the toolchain that was used to compile ROOT and the toolchain you are using to compile your program (e.g. different glibc version). I don't know enough about nixOS to suggest a fix. The massif output shows little memory usage (`mem_heap_B=72938`). Can you try using `root.exe` instead of `root` as the command? By removing one layer of indirection we might help massif see things properly (but of course if we can run on a compiled program rather than through the interpreter it makes everything simpler). Cheers,; Enrico",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9087#issuecomment-951644988
Availability,error,error,"> After the discussion at #8828 I have the impression that this shouldn't get merged. We might want to have an `Error()` call or similar instead. @hahnjo what's your opinion?. Yes, I wasn't sure either. I think Cling shouldn't crash (fixed for now with #9093), but because of the ambiguity of `std::ns` and `::ns`, I agree it would be more ""user-friendly"" to directly error out if a user tries to define a namespace that exists below `std::`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9089#issuecomment-950711308
Usability,user-friendly,user-friendly,"> After the discussion at #8828 I have the impression that this shouldn't get merged. We might want to have an `Error()` call or similar instead. @hahnjo what's your opinion?. Yes, I wasn't sure either. I think Cling shouldn't crash (fixed for now with #9093), but because of the ambiguity of `std::ns` and `::ns`, I agree it would be more ""user-friendly"" to directly error out if a user tries to define a namespace that exists below `std::`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9089#issuecomment-950711308
Availability,error,error,"@dudarboh the friend tree has less entries than the main tree. I think that's what's causing the problem. We should definitely have better diagnostics for this (i.e. give you a clear error message rather than the error you see), but this is not a supported usecase. . I could not reproduce the issue when truncating the tree in `test_default.root` to the same amount of entries as the friend. Can you?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9106#issuecomment-944297935
Integrability,message,message,"@dudarboh the friend tree has less entries than the main tree. I think that's what's causing the problem. We should definitely have better diagnostics for this (i.e. give you a clear error message rather than the error you see), but this is not a supported usecase. . I could not reproduce the issue when truncating the tree in `test_default.root` to the same amount of entries as the friend. Can you?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9106#issuecomment-944297935
Usability,clear,clear,"@dudarboh the friend tree has less entries than the main tree. I think that's what's causing the problem. We should definitely have better diagnostics for this (i.e. give you a clear error message rather than the error you see), but this is not a supported usecase. . I could not reproduce the issue when truncating the tree in `test_default.root` to the same amount of entries as the friend. Can you?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9106#issuecomment-944297935
Availability,error,error,"> @SClarkPhysics that's also with friends and multi-threading, and disappearing if you don't use friends or turn off multi-threading (or both)?. No, my issue seems a bit different and I am still investigating to see when it happens. I am **not** using multiprocessing or friends but am still getting the error "" Error in <TCollectionLessSTLReader::GetCP()>: Read error in TBranchProxy. ""; Not exactly sure how to recreate the error yet so I need to do some investigating on my own, but it definitely doesn't happen on every file I run over and it seems that it may be related to one of the custom cpp functions I am using to define a new column. Can report back when I learn a bit more",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9106#issuecomment-944305281
Performance,multi-thread,multi-threading,"> @SClarkPhysics that's also with friends and multi-threading, and disappearing if you don't use friends or turn off multi-threading (or both)?. No, my issue seems a bit different and I am still investigating to see when it happens. I am **not** using multiprocessing or friends but am still getting the error "" Error in <TCollectionLessSTLReader::GetCP()>: Read error in TBranchProxy. ""; Not exactly sure how to recreate the error yet so I need to do some investigating on my own, but it definitely doesn't happen on every file I run over and it seems that it may be related to one of the custom cpp functions I am using to define a new column. Can report back when I learn a bit more",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9106#issuecomment-944305281
Usability,learn,learn,"> @SClarkPhysics that's also with friends and multi-threading, and disappearing if you don't use friends or turn off multi-threading (or both)?. No, my issue seems a bit different and I am still investigating to see when it happens. I am **not** using multiprocessing or friends but am still getting the error "" Error in <TCollectionLessSTLReader::GetCP()>: Read error in TBranchProxy. ""; Not exactly sure how to recreate the error yet so I need to do some investigating on my own, but it definitely doesn't happen on every file I run over and it seems that it may be related to one of the custom cpp functions I am using to define a new column. Can report back when I learn a bit more",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9106#issuecomment-944305281
Usability,simpl,simply,"Okay, having (`---`) between the lines looks good. Now for the left-most column, naively I can simply count rows. Alternatively, I can store the length of the longest collection, say 3. And then my left column would contain [0,1,2,0,1,2,0,1,2,0...]. Which alternative would be more useful in your opinion?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9116#issuecomment-944081398
Usability,clear,clear,"I like this decorator and I'm planning to use it wherever I can. I would have preferred a pattern rather than a prefix, but you made your point clear and I think I can work with what you propose. About the `name` argument, if inside the code you invoke the user function as `fn(klass, name=name)` then it becomes a user choice whether to use it or not.; In any case I'm not convinced that bare class name is very useful, I feel I would be more interested in the fully qualified name... and actually in all places you use `name` is for a class in the global namespace, and the only time you have to deal with a class in a namespace (`std::string`) you have to use `klass.__cpp_name__`, so if you change `name` to be the fully qualified version you can *fix* the only exception. Also, I'm not too much in favor of suggesting people to use *private* data members of a Python class, even if we know that it's always there (for the moment).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9128#issuecomment-957360673
Usability,clear,clear,"The last comments from @pikacic and @eguiraud have been addressed, namely:; - Possibility to define pythonizor functions with either one parameter (class proxy) or two parameters (class proxy and fully-qualified name of the class).; - Support for immediate pythonizations of classes that have already been used at the time of the registration of a pythonization.; - Prevent confusion with `is_prefix=True` not matching classes in nested namespaces. Now a separate parameter for the namespace exists to make it clear that pythonizors are applied to a certain namespace (default is global namespace), e.g.:; ```python; @pythonization(""RVec<"", ns=""ROOT::VecOps"", is_prefix=True); def pythonizor_RVec(klass, name):; ...; ```. Note that multiple `@pythonization` decorators can be stacked if a pythonizor targets classes in multiple namespaces:; ```python; @pythonization(""A""); @pythonization(""B"", ns=""NS""); def pythonizor_for_A_and_NS_B(klass):; ...; ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9128#issuecomment-982514902
Availability,error,error,"I see that this is a bug leading unwanted behaviour for TTree itself. However, I *think* we should be able to apply a fix from the RDF side.; * The TTreeProcessorMT, and hence for RDF with EnableImplicitMT solution is very clear: in fact when we have friends, we will be creating the clusters globally, and hence we will be calling `GetFriendEntries` defined in TTreeProcessorMT.cxx. We can error out whenever there is a friend with less entries than the main chain. Clearly, the check would not require opening extra files. Additional benefit ==> this is checked before the event loop.; * For single threaded cases, it is not so obvious, but there are 2 steps that could be done:; 	* Teach the RLoopManager to always understand the fFriendInfo (which was introduced by the RDatasetSpec) from InteralTreeUtils.; 	* Once that is done, GetEntries(friend_chain_name) after the event loop ==> user pays the cost of (maybe erroring for) short friends in the end.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9137#issuecomment-1173061495
Usability,clear,clear,"I see that this is a bug leading unwanted behaviour for TTree itself. However, I *think* we should be able to apply a fix from the RDF side.; * The TTreeProcessorMT, and hence for RDF with EnableImplicitMT solution is very clear: in fact when we have friends, we will be creating the clusters globally, and hence we will be calling `GetFriendEntries` defined in TTreeProcessorMT.cxx. We can error out whenever there is a friend with less entries than the main chain. Clearly, the check would not require opening extra files. Additional benefit ==> this is checked before the event loop.; * For single threaded cases, it is not so obvious, but there are 2 steps that could be done:; 	* Teach the RLoopManager to always understand the fFriendInfo (which was introduced by the RDatasetSpec) from InteralTreeUtils.; 	* Once that is done, GetEntries(friend_chain_name) after the event loop ==> user pays the cost of (maybe erroring for) short friends in the end.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9137#issuecomment-1173061495
Safety,avoid,avoid,"> My general comment is that I would try to avoid doing a plain copy of code that is somewhere else.; > ; > I checked `rootx/src/rootx.cxx` and it not only parses `--notebook`, but also several other options such as `-b`, `-l`, etc. This makes me wonder: is `rootx/src/rootx.cxx` the right place to parse options or it's not?; > ; > Also, is there a place where options are parsed no matter the platform? If yes, we should put there the code for `--notebook`, shouldn't we?. `rootx` is used to create the `root` executable, which then may call `root.exe`. One cannot do that on Windows, we can only have one root executable, which is `root.exe`. Now, if someone find another, better solution, fine with me. As I said, this is the simplest and less intrusive solution.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9142#issuecomment-946778407
Usability,simpl,simplest,"> My general comment is that I would try to avoid doing a plain copy of code that is somewhere else.; > ; > I checked `rootx/src/rootx.cxx` and it not only parses `--notebook`, but also several other options such as `-b`, `-l`, etc. This makes me wonder: is `rootx/src/rootx.cxx` the right place to parse options or it's not?; > ; > Also, is there a place where options are parsed no matter the platform? If yes, we should put there the code for `--notebook`, shouldn't we?. `rootx` is used to create the `root` executable, which then may call `root.exe`. One cannot do that on Windows, we can only have one root executable, which is `root.exe`. Now, if someone find another, better solution, fine with me. As I said, this is the simplest and less intrusive solution.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9142#issuecomment-946778407
Safety,safe,safe,"The code in TTree is known to not be ""exception safe"" (it was written before exceptions were usable in practice), so it should never throw any exception . But also it should not interfere and should not change the return value of GetEntry. If I understood correctly and just catching the exception is changing the return value, could you confirm that it does so ""also"" in C++?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9154#issuecomment-951163261
Usability,usab,usable,"The code in TTree is known to not be ""exception safe"" (it was written before exceptions were usable in practice), so it should never throw any exception . But also it should not interfere and should not change the return value of GetEntry. If I understood correctly and just catching the exception is changing the return value, could you confirm that it does so ""also"" in C++?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9154#issuecomment-951163261
Usability,feedback,feedback,@guitargeek any feedback on this one? Shall I rebase and run clang-format? Thanks in advance!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9156#issuecomment-1812203134
Testability,test,tests,"Hi! No that's alright, we don't enforce the formatting of old code. Also a rebase is not necessary, since the tests all passed and the PR would merge fine. Just a note: probably the PR was unattended for so long because the usecase for this feature was not clear (or you needed it in your project?). Now that we have it, we might as well merge it, but for the future try to focus more on addressing concrete use needs or improving the ROOT developer experience (like you did in many other PRs).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9156#issuecomment-1812443312
Usability,clear,clear,"Hi! No that's alright, we don't enforce the formatting of old code. Also a rebase is not necessary, since the tests all passed and the PR would merge fine. Just a note: probably the PR was unattended for so long because the usecase for this feature was not clear (or you needed it in your project?). Now that we have it, we might as well merge it, but for the future try to focus more on addressing concrete use needs or improving the ROOT developer experience (like you did in many other PRs).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9156#issuecomment-1812443312
Testability,test,tests,"> Hi! No that's alright, we don't enforce the formatting of old code. Also a rebase is not necessary, since the tests all passed and the PR would merge fine.; > ; > Just a note: probably the PR was unattended for so long because the usecase for this feature was not clear (or you needed it in your project?). Now that we have it, we might as well merge it, but for the future try to focus more on addressing concrete use needs or improving the ROOT developer experience (like you did in many other PRs). Thanks for the feedback!. It was a feature needed for my project. Because it took long, I used a workaround with a TGLabel class, so I did not insist much either, but for the future I will make it more clear what the usecase is :). Cheers.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9156#issuecomment-1812527084
Usability,clear,clear,"> Hi! No that's alright, we don't enforce the formatting of old code. Also a rebase is not necessary, since the tests all passed and the PR would merge fine.; > ; > Just a note: probably the PR was unattended for so long because the usecase for this feature was not clear (or you needed it in your project?). Now that we have it, we might as well merge it, but for the future try to focus more on addressing concrete use needs or improving the ROOT developer experience (like you did in many other PRs). Thanks for the feedback!. It was a feature needed for my project. Because it took long, I used a workaround with a TGLabel class, so I did not insist much either, but for the future I will make it more clear what the usecase is :). Cheers.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9156#issuecomment-1812527084
Usability,feedback,feedback,"Thanks for the clarification!. Speaking of needs, I still need https://github.com/root-project/root/pull/8546 for my project, which deals with huge amounts of integer waveforms, but after two years I closed it because I was getting no more feedback / responses. (I am happy to reopen it once there is someone able to review it.)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9156#issuecomment-1813907124
Usability,clear,clearing,"Build failed on ROOT-ubuntu2004/soversion.; Running on root-ubuntu-2004-3.cern.ch:/home/sftnight/build/workspace/root-pullrequests-build; [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/127729/console).; ### Warnings:; - [2021-10-21T13:48:06.579Z] include/tbb/concurrent_hash_map.h:124:51: warning: void* memset(void*, int, size_t) clearing an object of type class tbb::interface5::internal::hash_map_base with no trivial copy-assignment; use value-initialization instead [-Wclass-memaccess] ; - [2021-10-21T13:54:54.096Z] include/tbb/concurrent_hash_map.h:124:51: warning: void* memset(void*, int, size_t) clearing an object of type class tbb::interface5::internal::hash_map_base with no trivial copy-assignment; use value-initialization instead [-Wclass-memaccess]",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9157#issuecomment-948660830
Usability,simpl,simple,"To be more complete here is a reproducer:; ```; void ratioplot2() {; gStyle->SetOptStat(0);; auto c1 = new TCanvas(""c1"", ""fit residual simple"");; auto h1 = new TH1D(""h1"", ""h1"", 50, -5, 5);; h1->FillRandom(""gaus"", 2000);; h1->Fit(""gaus"", ""0"");; h1->GetXaxis()->SetTitle(""x"");; auto rp1 = new TRatioPlot(h1);; rp1->Draw();; rp1->GetLowerRefYaxis()->SetTitle(""ratio"");; rp1->GetLowerRefYaxis()->SetNdivisions(2); // the number of divisions is not changed on the Y axis lower plot.; rp1->GetUpperRefYaxis()->SetTitle(""entries"");; }; ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9172#issuecomment-949697288
Modifiability,variab,variables,"Hi @guitargeek , I have some local example which I run to see if the Taylor expansion works fine. (simply Taylor expanding a RooFormulaVar around different points). I would like your inputs on the following items,; - What do you want to have as an unit test ? ; - Shall we also have a tutorial in place ?; - the anaytical integral for a polynomial can be written. I am unsure if the analyticalIntegral fully applies to a function of many variables, let me know how we can ; proceed here. :); ; Cheers,; Rahul",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9184#issuecomment-951725716
Testability,test,test,"Hi @guitargeek , I have some local example which I run to see if the Taylor expansion works fine. (simply Taylor expanding a RooFormulaVar around different points). I would like your inputs on the following items,; - What do you want to have as an unit test ? ; - Shall we also have a tutorial in place ?; - the anaytical integral for a polynomial can be written. I am unsure if the analyticalIntegral fully applies to a function of many variables, let me know how we can ; proceed here. :); ; Cheers,; Rahul",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9184#issuecomment-951725716
Usability,simpl,simply,"Hi @guitargeek , I have some local example which I run to see if the Taylor expansion works fine. (simply Taylor expanding a RooFormulaVar around different points). I would like your inputs on the following items,; - What do you want to have as an unit test ? ; - Shall we also have a tutorial in place ?; - the anaytical integral for a polynomial can be written. I am unsure if the analyticalIntegral fully applies to a function of many variables, let me know how we can ; proceed here. :); ; Cheers,; Rahul",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9184#issuecomment-951725716
Usability,simpl,simple,I will commit a simple fix for this,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9189#issuecomment-964344546
Usability,simpl,simplifying,"I have spent some time simplifying the reproducer significantly. This code snippet it enough to reproduce the memory leak:; ```C++; #include ""RooRealVar.h"". #include ""TSystem.h"". void reproducer(); {; ProcInfo_t pinfo;; for(std::size_t i = 0; i < 10000; ++i) {. RooRealVar x(""x"",""x"",0);; RooRealVar y(x);. if(i % 500 == 0) {; gSystem->GetProcInfo(&pinfo);; std::cout << i << "" memory usage "" << pinfo.fMemResident; << "" "" << pinfo.fMemVirtual << std::endl;; }. }; }; ```; For the memory increase to happen, it is important that both `RooRealVars` are defined in the loop. Now that we have a simple reproduced, I will continue to investigate the problem later. This problem with the RooRealVar seems so general that we probably solve a ton of RooFit issues at once if we solve this problem here!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9196#issuecomment-964117041
Usability,simpl,simple,"Ater merging https://github.com/root-project/root/pull/8324, I verified that the memory increase as reported in this PR is gone. Both with the code from the initial post and also with the simple reproducer that I wrote.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9196#issuecomment-1092547617
Performance,multi-thread,multi-threading,"@eguiraud Thank you for your detailed response!. I currently create some TDirectories representing different stages of seloctions, and write histograms into it. For some reason, I would like to have TTree output also in some of the stages, and for that I need to use the `Snapshot` method. The way I had thought of (haven't tested yet, sorry) would be creating all the directories first and close the file, snapshotting to that file (not sure if the sub-directory could be, specified), and then open it for histogram writing. I have little knowledge about multi-threading, and was just (navely) looking for an RDataFrame anology of creating a TTree inside a TDirectory. It simply seemed strange to have to close the file and reopen. If feasible, it would be great if the (official) way to create a snapshot and to store into a certain sub-directory of a TFile, along with the multi-threading consideration, could be documented, so that users switching from the imperative pattern would be easier to understand.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9225#issuecomment-958037006
Testability,test,tested,"@eguiraud Thank you for your detailed response!. I currently create some TDirectories representing different stages of seloctions, and write histograms into it. For some reason, I would like to have TTree output also in some of the stages, and for that I need to use the `Snapshot` method. The way I had thought of (haven't tested yet, sorry) would be creating all the directories first and close the file, snapshotting to that file (not sure if the sub-directory could be, specified), and then open it for histogram writing. I have little knowledge about multi-threading, and was just (navely) looking for an RDataFrame anology of creating a TTree inside a TDirectory. It simply seemed strange to have to close the file and reopen. If feasible, it would be great if the (official) way to create a snapshot and to store into a certain sub-directory of a TFile, along with the multi-threading consideration, could be documented, so that users switching from the imperative pattern would be easier to understand.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9225#issuecomment-958037006
Usability,simpl,simply,"@eguiraud Thank you for your detailed response!. I currently create some TDirectories representing different stages of seloctions, and write histograms into it. For some reason, I would like to have TTree output also in some of the stages, and for that I need to use the `Snapshot` method. The way I had thought of (haven't tested yet, sorry) would be creating all the directories first and close the file, snapshotting to that file (not sure if the sub-directory could be, specified), and then open it for histogram writing. I have little knowledge about multi-threading, and was just (navely) looking for an RDataFrame anology of creating a TTree inside a TDirectory. It simply seemed strange to have to close the file and reopen. If feasible, it would be great if the (official) way to create a snapshot and to store into a certain sub-directory of a TFile, along with the multi-threading consideration, could be documented, so that users switching from the imperative pattern would be easier to understand.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9225#issuecomment-958037006
Usability,learn,learn,Sorry to hear that. It would still be great to learn possible workaround to make my project step forward.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9240#issuecomment-964801950
Deployability,patch,patching,"I've had similar issues with the Snap build, where ACliC remembers its build environment which doesn't exist in the runtime environment. As a remedy I've taken to patching `root/build/unix/compiledata.sh`, adding a segment which runs `sed` and clears up the unwanted extra include directories. Maybe something similar could work in your use case as a workaround. [Example here](https://github.com/MrCarroll/root-snap/blob/main/snap/local/patches/ROOT/ACliC.patch)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9243#issuecomment-963063640
Usability,clear,clears,"I've had similar issues with the Snap build, where ACliC remembers its build environment which doesn't exist in the runtime environment. As a remedy I've taken to patching `root/build/unix/compiledata.sh`, adding a segment which runs `sed` and clears up the unwanted extra include directories. Maybe something similar could work in your use case as a workaround. [Example here](https://github.com/MrCarroll/root-snap/blob/main/snap/local/patches/ROOT/ACliC.patch)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9243#issuecomment-963063640
Usability,simpl,simple,[reproducer_9252.tar.gz](https://github.com/root-project/root/files/7488905/reproducer_9252.tar.gz). Adding a simple reproducer of the failing case. See README in the tar file for instruction.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9252#issuecomment-962218564
Availability,error,error-conflicting-types-alpine-linux,"Next problem is that musl [apparently](https://www.gnu.org/software/gnulib/manual/html_node/fpu_005fcontrol_002eh.html) does not provide `fpu_control.h`. According to this [forum post](https://root-forum.cern.ch/t/compiling-error-conflicting-types-alpine-linux/28193/3), nothing from this file is in fact used and thus it should be possible to remove the include - based on the `fpu_control.h` [source code](https://code.woboq.org/userspace/glibc/sysdeps/x86/fpu_control.h.html) and a simple `grep`, this should hold for all ROOT components, except `math/mathcore/src/triangle.c`, which uses `_FPU_SETCW` at line 4888. I am not familiar with what `fpu_control.h` does (apparently it has something to do with float precision), but according to [this](https://sourceforge.net/p/jamvm/patches/6/), it should be replaceable by a standard `fenv.h` header file, which I suggest to do (I have not tested it yet, but I will).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9253#issuecomment-963066852
Deployability,patch,patches,"Next problem is that musl [apparently](https://www.gnu.org/software/gnulib/manual/html_node/fpu_005fcontrol_002eh.html) does not provide `fpu_control.h`. According to this [forum post](https://root-forum.cern.ch/t/compiling-error-conflicting-types-alpine-linux/28193/3), nothing from this file is in fact used and thus it should be possible to remove the include - based on the `fpu_control.h` [source code](https://code.woboq.org/userspace/glibc/sysdeps/x86/fpu_control.h.html) and a simple `grep`, this should hold for all ROOT components, except `math/mathcore/src/triangle.c`, which uses `_FPU_SETCW` at line 4888. I am not familiar with what `fpu_control.h` does (apparently it has something to do with float precision), but according to [this](https://sourceforge.net/p/jamvm/patches/6/), it should be replaceable by a standard `fenv.h` header file, which I suggest to do (I have not tested it yet, but I will).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9253#issuecomment-963066852
Testability,test,tested,"Next problem is that musl [apparently](https://www.gnu.org/software/gnulib/manual/html_node/fpu_005fcontrol_002eh.html) does not provide `fpu_control.h`. According to this [forum post](https://root-forum.cern.ch/t/compiling-error-conflicting-types-alpine-linux/28193/3), nothing from this file is in fact used and thus it should be possible to remove the include - based on the `fpu_control.h` [source code](https://code.woboq.org/userspace/glibc/sysdeps/x86/fpu_control.h.html) and a simple `grep`, this should hold for all ROOT components, except `math/mathcore/src/triangle.c`, which uses `_FPU_SETCW` at line 4888. I am not familiar with what `fpu_control.h` does (apparently it has something to do with float precision), but according to [this](https://sourceforge.net/p/jamvm/patches/6/), it should be replaceable by a standard `fenv.h` header file, which I suggest to do (I have not tested it yet, but I will).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9253#issuecomment-963066852
Usability,simpl,simple,"Next problem is that musl [apparently](https://www.gnu.org/software/gnulib/manual/html_node/fpu_005fcontrol_002eh.html) does not provide `fpu_control.h`. According to this [forum post](https://root-forum.cern.ch/t/compiling-error-conflicting-types-alpine-linux/28193/3), nothing from this file is in fact used and thus it should be possible to remove the include - based on the `fpu_control.h` [source code](https://code.woboq.org/userspace/glibc/sysdeps/x86/fpu_control.h.html) and a simple `grep`, this should hold for all ROOT components, except `math/mathcore/src/triangle.c`, which uses `_FPU_SETCW` at line 4888. I am not familiar with what `fpu_control.h` does (apparently it has something to do with float precision), but according to [this](https://sourceforge.net/p/jamvm/patches/6/), it should be replaceable by a standard `fenv.h` header file, which I suggest to do (I have not tested it yet, but I will).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9253#issuecomment-963066852
Availability,error,error,"06/core/cont/inc -I/builddir/root-6.24.06/core/thread/inc -I/builddir/root-6.24.06/core/textinput/inc -I/b; uilddir/root-6.24.06/core/gui/inc -I/builddir/root-6.24.06/core/foundation/inc -I/builddir/root-6.24.06/build/ginclude -DNDEBUG -fstack-clash-protection -D_FORTIFY_SOURCE=2 -mtune=generic -O2; -fdiagnostics-color=always -std=c++14 -Wno-implicit-fallthrough -Wno-noexcept-type -pipe -Wshadow -Wall -W -Woverloaded-virtual -fsigned-char -pthread -DNDEBUG -fPIC -std=c++14 -MD -MT cor; e/unix/CMakeFiles/Unix.dir/src/TUnixSystem.cxx.o -MF core/unix/CMakeFiles/Unix.dir/src/TUnixSystem.cxx.o.d -o core/unix/CMakeFiles/Unix.dir/src/TUnixSystem.cxx.o -c /builddir/root-6.24.06/cor; e/unix/src/TUnixSystem.cxx ; /builddir/root-6.24.06/core/unix/src/TUnixSystem.cxx: In member function 'virtual TInetAddress TUnixSystem::GetSockName(int)':; /builddir/root-6.24.06/core/unix/src/TUnixSystem.cxx:3085:33: error: invalid conversion from 'int*' to 'socklen_t*' {aka 'unsigned int*'} [-fpermissive]; 3085 | if (getsockname(sock, &addr, &len) == -1) { ; | ^~~~ ; | | ; | int* ; In file included from /builddir/root-6.24.06/core/unix/src/TUnixSystem.cxx:101: ; /usr/include/sys/socket.h:338:52: note: initializing argument 3 of 'int getsockname(int, sockaddr*, socklen_t*)'; 338 | int getsockname (int, struct sockaddr *__restrict, socklen_t *__restrict);; | ^~~~~~~~~~~~~~~~~~~~~; /builddir/root-6.24.06/core/unix/src/TUnixSystem.cxx: In member function 'virtual TInetAddress TUnixSystem::GetPeerName(int)':; /builddir/root-6.24.06/core/unix/src/TUnixSystem.cxx:3121:33: error: invalid conversion from 'int*' to 'socklen_t*' {aka 'unsigned int*'} [-fpermissive]; 3121 | if (getpeername(sock, &addr, &len) == -1) { ; | ^~~~ ; | | ; | int* ; In file included from /builddir/root-6.24.06/core/unix/src/TUnixSystem.cxx:101: ; /usr/include/sys/socket.h:339:52: note: initializing argument 3 of 'int getpeername(int, sockaddr*, socklen_t*)'; 339 | int getpeername (int, struct sockaddr *__restrict, socklen_t *__r",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9253#issuecomment-963600314
Integrability,interface,interfaces,"TCP_NODELAY, (char*)val, &optlen) == -1) {; | ^~~~~~~; | |; | int*; In file included from /builddir/root-6.24.06/core/unix/src/TUnixSystem.cxx:101:; /usr/include/sys/socket.h:348:50: note: initializing argument 5 of 'int getsockopt(int, int, int, void*, socklen_t*)'; 348 | int getsockopt (int, int, int, void *__restrict, socklen_t *__restrict);; | ^~~~~~~~~~~~~~~~~~~~~; ```; is the next error. The problem stems from the fact, that the condition for using `socklen_t` is (among others) glibc:; ```c; #if (defined(R__AIX) && !defined(_AIX43)) || \; (defined(R__SUNGCC3) && !defined(__arch64__)); # define USE_SIZE_T; #elif defined(R__GLIBC) || defined(R__FBSD) || \; (defined(R__SUNGCC3) && defined(__arch64__)) || \; defined(R__OBSD) || defined(MAC_OS_X_VERSION_10_4) || \; (defined(R__AIX) && defined(_AIX43)) || \; (defined(R__SOLARIS) && defined(_SOCKLEN_T)); # define USE_SOCKLEN_T; #endif; ```; [Here](https://pubs.opengroup.org/onlinepubs/9699919799/xrat/V4_xsh_chap02.html#tag_22_02_10_06) is some context:; > All socklen_t types were originally (in BSD UNIX) of type int. During the development of POSIX.1-2017, it was decided to change all buffer lengths to size_t, which appears at face value to make sense. When dual mode 32/64-bit systems came along, this choice unnecessarily complicated system interfaces because size_t (with long) was a different size under ILP32 and LP64 models. Reverting to int would have happened except that some implementations had already shipped 64-bit-only interfaces. The compromise was a type which could be defined to be any size by the implementation: socklen_t. I am not sure how to approach this, because the standardization of `socklen_t` seems fairly recent, but in the long run, avoiding this whole types dance altogether and simply using explicit `socklen_t` seems to make most sense and will make for a simpler code. I will appreciate any comments, especially regarding any compatibility issues this might cause - else I will add this to the PR.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9253#issuecomment-963600314
Safety,avoid,avoiding,"TCP_NODELAY, (char*)val, &optlen) == -1) {; | ^~~~~~~; | |; | int*; In file included from /builddir/root-6.24.06/core/unix/src/TUnixSystem.cxx:101:; /usr/include/sys/socket.h:348:50: note: initializing argument 5 of 'int getsockopt(int, int, int, void*, socklen_t*)'; 348 | int getsockopt (int, int, int, void *__restrict, socklen_t *__restrict);; | ^~~~~~~~~~~~~~~~~~~~~; ```; is the next error. The problem stems from the fact, that the condition for using `socklen_t` is (among others) glibc:; ```c; #if (defined(R__AIX) && !defined(_AIX43)) || \; (defined(R__SUNGCC3) && !defined(__arch64__)); # define USE_SIZE_T; #elif defined(R__GLIBC) || defined(R__FBSD) || \; (defined(R__SUNGCC3) && defined(__arch64__)) || \; defined(R__OBSD) || defined(MAC_OS_X_VERSION_10_4) || \; (defined(R__AIX) && defined(_AIX43)) || \; (defined(R__SOLARIS) && defined(_SOCKLEN_T)); # define USE_SOCKLEN_T; #endif; ```; [Here](https://pubs.opengroup.org/onlinepubs/9699919799/xrat/V4_xsh_chap02.html#tag_22_02_10_06) is some context:; > All socklen_t types were originally (in BSD UNIX) of type int. During the development of POSIX.1-2017, it was decided to change all buffer lengths to size_t, which appears at face value to make sense. When dual mode 32/64-bit systems came along, this choice unnecessarily complicated system interfaces because size_t (with long) was a different size under ILP32 and LP64 models. Reverting to int would have happened except that some implementations had already shipped 64-bit-only interfaces. The compromise was a type which could be defined to be any size by the implementation: socklen_t. I am not sure how to approach this, because the standardization of `socklen_t` seems fairly recent, but in the long run, avoiding this whole types dance altogether and simply using explicit `socklen_t` seems to make most sense and will make for a simpler code. I will appreciate any comments, especially regarding any compatibility issues this might cause - else I will add this to the PR.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9253#issuecomment-963600314
Usability,simpl,simply,"TCP_NODELAY, (char*)val, &optlen) == -1) {; | ^~~~~~~; | |; | int*; In file included from /builddir/root-6.24.06/core/unix/src/TUnixSystem.cxx:101:; /usr/include/sys/socket.h:348:50: note: initializing argument 5 of 'int getsockopt(int, int, int, void*, socklen_t*)'; 348 | int getsockopt (int, int, int, void *__restrict, socklen_t *__restrict);; | ^~~~~~~~~~~~~~~~~~~~~; ```; is the next error. The problem stems from the fact, that the condition for using `socklen_t` is (among others) glibc:; ```c; #if (defined(R__AIX) && !defined(_AIX43)) || \; (defined(R__SUNGCC3) && !defined(__arch64__)); # define USE_SIZE_T; #elif defined(R__GLIBC) || defined(R__FBSD) || \; (defined(R__SUNGCC3) && defined(__arch64__)) || \; defined(R__OBSD) || defined(MAC_OS_X_VERSION_10_4) || \; (defined(R__AIX) && defined(_AIX43)) || \; (defined(R__SOLARIS) && defined(_SOCKLEN_T)); # define USE_SOCKLEN_T; #endif; ```; [Here](https://pubs.opengroup.org/onlinepubs/9699919799/xrat/V4_xsh_chap02.html#tag_22_02_10_06) is some context:; > All socklen_t types were originally (in BSD UNIX) of type int. During the development of POSIX.1-2017, it was decided to change all buffer lengths to size_t, which appears at face value to make sense. When dual mode 32/64-bit systems came along, this choice unnecessarily complicated system interfaces because size_t (with long) was a different size under ILP32 and LP64 models. Reverting to int would have happened except that some implementations had already shipped 64-bit-only interfaces. The compromise was a type which could be defined to be any size by the implementation: socklen_t. I am not sure how to approach this, because the standardization of `socklen_t` seems fairly recent, but in the long run, avoiding this whole types dance altogether and simply using explicit `socklen_t` seems to make most sense and will make for a simpler code. I will appreciate any comments, especially regarding any compatibility issues this might cause - else I will add this to the PR.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9253#issuecomment-963600314
Availability,avail,available,"> `root [1] auto firstTwo2 = Take(v, 2);`. This resolves correctly to `ROOT::VecOps::Take()` after a `using namespace ROOT::VecOps;`, which is what appears in the example referenced above. Thus, the following works:; ```c++; root [0] ROOT::VecOps::RVec v{2., 3., 1.};; root [1] using namespace ROOT::VecOps;; root [2] auto firstTwo = Take(v, 2); (ROOT::VecOps::RVec<double> &) { 2.0000000, 3.0000000 }; ```. I cannot tell whether the names in `ROOT::VecOps` were directly available for unqualified lookup in the past. @Axel-Naumann? . Anyways, I agree that the interpreter should be more clear about unresolved names (instead of partially dumping the AST). I can dedicate some spare cycles in the first week of December for that.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9261#issuecomment-966475070
Usability,clear,clear,"> `root [1] auto firstTwo2 = Take(v, 2);`. This resolves correctly to `ROOT::VecOps::Take()` after a `using namespace ROOT::VecOps;`, which is what appears in the example referenced above. Thus, the following works:; ```c++; root [0] ROOT::VecOps::RVec v{2., 3., 1.};; root [1] using namespace ROOT::VecOps;; root [2] auto firstTwo = Take(v, 2); (ROOT::VecOps::RVec<double> &) { 2.0000000, 3.0000000 }; ```. I cannot tell whether the names in `ROOT::VecOps` were directly available for unqualified lookup in the past. @Axel-Naumann? . Anyways, I agree that the interpreter should be more clear about unresolved names (instead of partially dumping the AST). I can dedicate some spare cycles in the first week of December for that.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9261#issuecomment-966475070
Usability,simpl,simple,"I put `gPad->Modified(); gPad->Update()` in all possible places and none of them worked. I guess for the time being we keep that a ""feature"" as the workaround is simple: it is enough to zoom on the X top Axis.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9263#issuecomment-967029745
Integrability,depend,depend,"I'm a little confused as the same tests seems to have been quoted as `passed` and `failed` in the same log. I struggle to find the exact definition of each test as well. I looked through the relevant files, but the structure is not clear to me. Also, last time when I spoke with @amadio about the future of ROOT, he said you guys discussed making sure people outside of CERN can contribute. Unfortunately, I had to use my CERN login to see the test logs. I also don't know how to replicate the tests in my environment. Do they depend on files hosted somewhere? Could you give me some docs to read so I can find my way around?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9271#issuecomment-967115318
Testability,test,tests,"I'm a little confused as the same tests seems to have been quoted as `passed` and `failed` in the same log. I struggle to find the exact definition of each test as well. I looked through the relevant files, but the structure is not clear to me. Also, last time when I spoke with @amadio about the future of ROOT, he said you guys discussed making sure people outside of CERN can contribute. Unfortunately, I had to use my CERN login to see the test logs. I also don't know how to replicate the tests in my environment. Do they depend on files hosted somewhere? Could you give me some docs to read so I can find my way around?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9271#issuecomment-967115318
Usability,clear,clear,"I'm a little confused as the same tests seems to have been quoted as `passed` and `failed` in the same log. I struggle to find the exact definition of each test as well. I looked through the relevant files, but the structure is not clear to me. Also, last time when I spoke with @amadio about the future of ROOT, he said you guys discussed making sure people outside of CERN can contribute. Unfortunately, I had to use my CERN login to see the test logs. I also don't know how to replicate the tests in my environment. Do they depend on files hosted somewhere? Could you give me some docs to read so I can find my way around?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9271#issuecomment-967115318
Availability,failure,failures,"> I'm a little confused as the same tests seems to have been quoted as `passed` and `failed` in the same log. I struggle to find the exact definition of each test as well. I looked through the relevant files, but the structure is not clear to me. Which one exactly? I see from the logs that the interpreted stress test exits with code 1, so there's something going on. The node that has the high number of failures is probably a nullptr deref or similar. > Also, last time when I spoke with @amadio about the future of ROOT, he said you guys discussed making sure people outside of CERN can contribute. Unfortunately, I had to use my CERN login to see the test logs. I also don't know how to replicate the tests in my environment. Do they depend on files hosted somewhere? Could you give me some docs to read so I can find my way around?. Yes, I agree that it's not great to have jenkins behind a CERN login, but I guess this has to be done to secure the instance. The tests should be self-consistent, i.e. bring their own files. Try `ctest -R stressHistFactory -V` to see what's going on locally on your machine (i.e. see invocation and which files are used etc). If the test isn't there, you might have to activate `-Dtesting=ON` or `-Dhistfactory=ON` (which requires `-Dxml=ON`) in cmake.; Does the test pass locally?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9271#issuecomment-968052222
Integrability,depend,depend,"> I'm a little confused as the same tests seems to have been quoted as `passed` and `failed` in the same log. I struggle to find the exact definition of each test as well. I looked through the relevant files, but the structure is not clear to me. Which one exactly? I see from the logs that the interpreted stress test exits with code 1, so there's something going on. The node that has the high number of failures is probably a nullptr deref or similar. > Also, last time when I spoke with @amadio about the future of ROOT, he said you guys discussed making sure people outside of CERN can contribute. Unfortunately, I had to use my CERN login to see the test logs. I also don't know how to replicate the tests in my environment. Do they depend on files hosted somewhere? Could you give me some docs to read so I can find my way around?. Yes, I agree that it's not great to have jenkins behind a CERN login, but I guess this has to be done to secure the instance. The tests should be self-consistent, i.e. bring their own files. Try `ctest -R stressHistFactory -V` to see what's going on locally on your machine (i.e. see invocation and which files are used etc). If the test isn't there, you might have to activate `-Dtesting=ON` or `-Dhistfactory=ON` (which requires `-Dxml=ON`) in cmake.; Does the test pass locally?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9271#issuecomment-968052222
Security,secur,secure,"> I'm a little confused as the same tests seems to have been quoted as `passed` and `failed` in the same log. I struggle to find the exact definition of each test as well. I looked through the relevant files, but the structure is not clear to me. Which one exactly? I see from the logs that the interpreted stress test exits with code 1, so there's something going on. The node that has the high number of failures is probably a nullptr deref or similar. > Also, last time when I spoke with @amadio about the future of ROOT, he said you guys discussed making sure people outside of CERN can contribute. Unfortunately, I had to use my CERN login to see the test logs. I also don't know how to replicate the tests in my environment. Do they depend on files hosted somewhere? Could you give me some docs to read so I can find my way around?. Yes, I agree that it's not great to have jenkins behind a CERN login, but I guess this has to be done to secure the instance. The tests should be self-consistent, i.e. bring their own files. Try `ctest -R stressHistFactory -V` to see what's going on locally on your machine (i.e. see invocation and which files are used etc). If the test isn't there, you might have to activate `-Dtesting=ON` or `-Dhistfactory=ON` (which requires `-Dxml=ON`) in cmake.; Does the test pass locally?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9271#issuecomment-968052222
Testability,test,tests,"> I'm a little confused as the same tests seems to have been quoted as `passed` and `failed` in the same log. I struggle to find the exact definition of each test as well. I looked through the relevant files, but the structure is not clear to me. Which one exactly? I see from the logs that the interpreted stress test exits with code 1, so there's something going on. The node that has the high number of failures is probably a nullptr deref or similar. > Also, last time when I spoke with @amadio about the future of ROOT, he said you guys discussed making sure people outside of CERN can contribute. Unfortunately, I had to use my CERN login to see the test logs. I also don't know how to replicate the tests in my environment. Do they depend on files hosted somewhere? Could you give me some docs to read so I can find my way around?. Yes, I agree that it's not great to have jenkins behind a CERN login, but I guess this has to be done to secure the instance. The tests should be self-consistent, i.e. bring their own files. Try `ctest -R stressHistFactory -V` to see what's going on locally on your machine (i.e. see invocation and which files are used etc). If the test isn't there, you might have to activate `-Dtesting=ON` or `-Dhistfactory=ON` (which requires `-Dxml=ON`) in cmake.; Does the test pass locally?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9271#issuecomment-968052222
Usability,clear,clear,"> I'm a little confused as the same tests seems to have been quoted as `passed` and `failed` in the same log. I struggle to find the exact definition of each test as well. I looked through the relevant files, but the structure is not clear to me. Which one exactly? I see from the logs that the interpreted stress test exits with code 1, so there's something going on. The node that has the high number of failures is probably a nullptr deref or similar. > Also, last time when I spoke with @amadio about the future of ROOT, he said you guys discussed making sure people outside of CERN can contribute. Unfortunately, I had to use my CERN login to see the test logs. I also don't know how to replicate the tests in my environment. Do they depend on files hosted somewhere? Could you give me some docs to read so I can find my way around?. Yes, I agree that it's not great to have jenkins behind a CERN login, but I guess this has to be done to secure the instance. The tests should be self-consistent, i.e. bring their own files. Try `ctest -R stressHistFactory -V` to see what's going on locally on your machine (i.e. see invocation and which files are used etc). If the test isn't there, you might have to activate `-Dtesting=ON` or `-Dhistfactory=ON` (which requires `-Dxml=ON`) in cmake.; Does the test pass locally?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9271#issuecomment-968052222
Deployability,update,update,Just undo-ed the update.; Hope that nothing breaks.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9286#issuecomment-970839284
Usability,undo,undo-ed,Just undo-ed the update.; Hope that nothing breaks.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9286#issuecomment-970839284
Security,expose,exposed,"@vgvassilev do you object to me merging? I'd want to see this exposed to users earlier rather than later, to hear feedback before we tag v6.26. I have opened an issue https://github.com/root-project/root/issues/9312 to keep track.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9301#issuecomment-972998223
Usability,feedback,feedback,"@vgvassilev do you object to me merging? I'd want to see this exposed to users earlier rather than later, to hear feedback before we tag v6.26. I have opened an issue https://github.com/root-project/root/issues/9312 to keep track.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9301#issuecomment-972998223
Performance,perform,performance,"> @vgvassilev do you object to me merging? I'd want to see this exposed to users earlier rather than later, to hear feedback before we tag v6.26. I have opened an issue #9312 to keep track. No objections. What I'd like to understand is how much code regressed. But also, is the performance benefit significant outside of RDF. Both probably require more field testing... I suspect that for many cases we will be okay. There will be a number of regressed cases. What is unclear is how many are going to be the significantly improved cases. I believe for RDF we control the environment and compile even with -O2.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9301#issuecomment-973325971
Security,expose,exposed,"> @vgvassilev do you object to me merging? I'd want to see this exposed to users earlier rather than later, to hear feedback before we tag v6.26. I have opened an issue #9312 to keep track. No objections. What I'd like to understand is how much code regressed. But also, is the performance benefit significant outside of RDF. Both probably require more field testing... I suspect that for many cases we will be okay. There will be a number of regressed cases. What is unclear is how many are going to be the significantly improved cases. I believe for RDF we control the environment and compile even with -O2.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9301#issuecomment-973325971
Testability,test,testing,"> @vgvassilev do you object to me merging? I'd want to see this exposed to users earlier rather than later, to hear feedback before we tag v6.26. I have opened an issue #9312 to keep track. No objections. What I'd like to understand is how much code regressed. But also, is the performance benefit significant outside of RDF. Both probably require more field testing... I suspect that for many cases we will be okay. There will be a number of regressed cases. What is unclear is how many are going to be the significantly improved cases. I believe for RDF we control the environment and compile even with -O2.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9301#issuecomment-973325971
Usability,feedback,feedback,"> @vgvassilev do you object to me merging? I'd want to see this exposed to users earlier rather than later, to hear feedback before we tag v6.26. I have opened an issue #9312 to keep track. No objections. What I'd like to understand is how much code regressed. But also, is the performance benefit significant outside of RDF. Both probably require more field testing... I suspect that for many cases we will be okay. There will be a number of regressed cases. What is unclear is how many are going to be the significantly improved cases. I believe for RDF we control the environment and compile even with -O2.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9301#issuecomment-973325971
Usability,simpl,simple,"Yes, it is same problem. Actually, solution is very simple and I implement it with JSROOT. ; One can copy it to the C++",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9364#issuecomment-1012969310
Testability,test,testio,"A similar warning is also provoked in the simpler case below, so it's not only related to STL stuff:. ```cpp; #include ""TFile.h"". class TestBase {};. class Test : public TestBase {};. void testio() {. Test t;. TFile *fout = TFile::Open(""test.root"", ""RECREATE"");. fout->WriteObjectAny(&t, TClass::GetClass<Test>(), ""t"");; }; ```. ```; root -l testio.cpp ; root [0] ; Processing testio.cpp...; Warning in <TStreamerInfo::Build>: Test: base class TestBase has no streamer or dictionary it will not be saved; root [1] .q; ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9371#issuecomment-997463726
Usability,simpl,simpler,"A similar warning is also provoked in the simpler case below, so it's not only related to STL stuff:. ```cpp; #include ""TFile.h"". class TestBase {};. class Test : public TestBase {};. void testio() {. Test t;. TFile *fout = TFile::Open(""test.root"", ""RECREATE"");. fout->WriteObjectAny(&t, TClass::GetClass<Test>(), ""t"");; }; ```. ```; root -l testio.cpp ; root [0] ; Processing testio.cpp...; Warning in <TStreamerInfo::Build>: Test: base class TestBase has no streamer or dictionary it will not be saved; root [1] .q; ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9371#issuecomment-997463726
Usability,clear,clear,"And for this I think the problem is ""just"" the checks on ```TClass::IsLoaded()``` at. https://github.com/root-project/root/blob/702e1ee22ce472508d0ab2de7f51b85e6613b55d/io/io/src/TStreamerInfo.cxx#L384; https://github.com/root-project/root/blob/702e1ee22ce472508d0ab2de7f51b85e6613b55d/io/io/src/TStreamerInfo.cxx#L580; https://github.com/root-project/root/blob/702e1ee22ce472508d0ab2de7f51b85e6613b55d/io/io/src/TStreamerInfo.cxx#L592. Since the state of the TClass object is ```kInterpreted``` in this case. Not sure what the best solution here is. On the one hand being able to persist interpreted classes is extremely useful (especially for the case of templates which are only instantiated from PyROOT), but it's also clear that one can shoot themselves in the foot here if the interpreted class changes in a way that breaks the IO.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9371#issuecomment-997467808
Deployability,release,release,"@olifre this was an oversight so it does not appear in the release notes. I totally agree that we should avoid wasting other people time trying to debug the same thing, but the release notes of 6.20 may not be the first place people look, in particular since this affects several versions. I was thinking to put a short description of the incompatibility and fix in the reference guide of [TGeoMaterial](https://root.cern/doc/master/classTGeoMaterial.html) since this is the class where the users will actually see the different behaviour. What do you think?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9383#issuecomment-987815314
Safety,avoid,avoid,"@olifre this was an oversight so it does not appear in the release notes. I totally agree that we should avoid wasting other people time trying to debug the same thing, but the release notes of 6.20 may not be the first place people look, in particular since this affects several versions. I was thinking to put a short description of the incompatibility and fix in the reference guide of [TGeoMaterial](https://root.cern/doc/master/classTGeoMaterial.html) since this is the class where the users will actually see the different behaviour. What do you think?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9383#issuecomment-987815314
Usability,guid,guide,"@olifre this was an oversight so it does not appear in the release notes. I totally agree that we should avoid wasting other people time trying to debug the same thing, but the release notes of 6.20 may not be the first place people look, in particular since this affects several versions. I was thinking to put a short description of the incompatibility and fix in the reference guide of [TGeoMaterial](https://root.cern/doc/master/classTGeoMaterial.html) since this is the class where the users will actually see the different behaviour. What do you think?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9383#issuecomment-987815314
Deployability,release,released,"Thanks for the quick feedback!. I've tried with `client.wait_for_workers(1)` before creating the RDF, but it doesn't have the expected effect: it just waits forever after printing `DEBUG:Starting job: 12241446.0` (debugging activated with `import logging; logging.basicConfig(format='%(levelname)s:%(message)s', level=logging.DEBUG)`). I can see the job in `condor_q` come and go, but the blocking call is never released for some reason (note that I'm not a Dask expert by any means). I'll try again once #9431 is merged; in particular I'm interested in using Dask's [adaptive worker management](https://jobqueue.dask.org/en/latest/advanced-tips-and-tricks.html#how-to-handle-job-queueing-system-walltime-killing-workers), so that the exact number of submitted jobs is not fixed a priori but automatically adapts to the workload...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9429#issuecomment-992593304
Energy Efficiency,adapt,adaptive,"Thanks for the quick feedback!. I've tried with `client.wait_for_workers(1)` before creating the RDF, but it doesn't have the expected effect: it just waits forever after printing `DEBUG:Starting job: 12241446.0` (debugging activated with `import logging; logging.basicConfig(format='%(levelname)s:%(message)s', level=logging.DEBUG)`). I can see the job in `condor_q` come and go, but the blocking call is never released for some reason (note that I'm not a Dask expert by any means). I'll try again once #9431 is merged; in particular I'm interested in using Dask's [adaptive worker management](https://jobqueue.dask.org/en/latest/advanced-tips-and-tricks.html#how-to-handle-job-queueing-system-walltime-killing-workers), so that the exact number of submitted jobs is not fixed a priori but automatically adapts to the workload...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9429#issuecomment-992593304
Integrability,message,message,"Thanks for the quick feedback!. I've tried with `client.wait_for_workers(1)` before creating the RDF, but it doesn't have the expected effect: it just waits forever after printing `DEBUG:Starting job: 12241446.0` (debugging activated with `import logging; logging.basicConfig(format='%(levelname)s:%(message)s', level=logging.DEBUG)`). I can see the job in `condor_q` come and go, but the blocking call is never released for some reason (note that I'm not a Dask expert by any means). I'll try again once #9431 is merged; in particular I'm interested in using Dask's [adaptive worker management](https://jobqueue.dask.org/en/latest/advanced-tips-and-tricks.html#how-to-handle-job-queueing-system-walltime-killing-workers), so that the exact number of submitted jobs is not fixed a priori but automatically adapts to the workload...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9429#issuecomment-992593304
Modifiability,adapt,adaptive,"Thanks for the quick feedback!. I've tried with `client.wait_for_workers(1)` before creating the RDF, but it doesn't have the expected effect: it just waits forever after printing `DEBUG:Starting job: 12241446.0` (debugging activated with `import logging; logging.basicConfig(format='%(levelname)s:%(message)s', level=logging.DEBUG)`). I can see the job in `condor_q` come and go, but the blocking call is never released for some reason (note that I'm not a Dask expert by any means). I'll try again once #9431 is merged; in particular I'm interested in using Dask's [adaptive worker management](https://jobqueue.dask.org/en/latest/advanced-tips-and-tricks.html#how-to-handle-job-queueing-system-walltime-killing-workers), so that the exact number of submitted jobs is not fixed a priori but automatically adapts to the workload...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9429#issuecomment-992593304
Performance,queue,queueing-system-walltime-killing-workers,"Thanks for the quick feedback!. I've tried with `client.wait_for_workers(1)` before creating the RDF, but it doesn't have the expected effect: it just waits forever after printing `DEBUG:Starting job: 12241446.0` (debugging activated with `import logging; logging.basicConfig(format='%(levelname)s:%(message)s', level=logging.DEBUG)`). I can see the job in `condor_q` come and go, but the blocking call is never released for some reason (note that I'm not a Dask expert by any means). I'll try again once #9431 is merged; in particular I'm interested in using Dask's [adaptive worker management](https://jobqueue.dask.org/en/latest/advanced-tips-and-tricks.html#how-to-handle-job-queueing-system-walltime-killing-workers), so that the exact number of submitted jobs is not fixed a priori but automatically adapts to the workload...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9429#issuecomment-992593304
Testability,log,logging,"Thanks for the quick feedback!. I've tried with `client.wait_for_workers(1)` before creating the RDF, but it doesn't have the expected effect: it just waits forever after printing `DEBUG:Starting job: 12241446.0` (debugging activated with `import logging; logging.basicConfig(format='%(levelname)s:%(message)s', level=logging.DEBUG)`). I can see the job in `condor_q` come and go, but the blocking call is never released for some reason (note that I'm not a Dask expert by any means). I'll try again once #9431 is merged; in particular I'm interested in using Dask's [adaptive worker management](https://jobqueue.dask.org/en/latest/advanced-tips-and-tricks.html#how-to-handle-job-queueing-system-walltime-killing-workers), so that the exact number of submitted jobs is not fixed a priori but automatically adapts to the workload...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9429#issuecomment-992593304
Usability,feedback,feedback,"Thanks for the quick feedback!. I've tried with `client.wait_for_workers(1)` before creating the RDF, but it doesn't have the expected effect: it just waits forever after printing `DEBUG:Starting job: 12241446.0` (debugging activated with `import logging; logging.basicConfig(format='%(levelname)s:%(message)s', level=logging.DEBUG)`). I can see the job in `condor_q` come and go, but the blocking call is never released for some reason (note that I'm not a Dask expert by any means). I'll try again once #9431 is merged; in particular I'm interested in using Dask's [adaptive worker management](https://jobqueue.dask.org/en/latest/advanced-tips-and-tricks.html#how-to-handle-job-queueing-system-walltime-killing-workers), so that the exact number of submitted jobs is not fixed a priori but automatically adapts to the workload...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9429#issuecomment-992593304
Energy Efficiency,schedul,scheduler,"The fact that `wait_for_workers` waits forever looks to me like the Dask job is never actually started. You should double check that a simple Dask application with the same config but doing something else unrelated to RDF is working. Let's see, something like this should suffice (inspired by the dask [docs](https://examples.dask.org/delayed.html) and your reproducer):; ```python; import time; import random. from dask import delayed; from dask.distributed import Client; from dask_jobqueue import HTCondorCluster. cluster = HTCondorCluster(cores=1, processes=1, memory=""1GB"", disk=""0.1GB"", job_extra={""jobflavour"": ""espresso""}); cluster.scale(jobs=1); client = Client(cluster). # Try with and without this; client.wait_for_workers(1). def inc(x):; time.sleep(random.random()); return x + 1. def dec(x):; time.sleep(random.random()); return x - 1. def add(x, y):; time.sleep(random.random()); return x + y. inc = delayed(inc); dec = delayed(dec); add = delayed(add). x = inc(1); y = dec(2); z = add(x, y). print(f""Result is: {z.compute()}""); ```. Coming back to RDF, the `npartitions` parameter corresponds to how many distributed tasks will be sent to the Dask scheduler. Supposing you know something about how many resources you have or the layout of your ROOT dataset, you could set this manually in the RDataFrame constructor like; ```python; df = RDataFrame(""treename"",""filename.root"",daskclient=client,npartitions=NPARTITIONS); ``` ; A good parallelisation can often be obtained when the number of partitions is roughly 3x the amount of cores you can use.; UPDATE:. > in particular I'm interested in using Dask's adaptive worker management, so that the exact number of submitted jobs is not fixed a priori but automatically adapts to the workload... Sounds good, then the `npartitions` parameter could be adjusted based on how many TTree clusters you have in your dataset. Roughly one task every 4-5 clusters should be a good starting point.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9429#issuecomment-992602348
Modifiability,config,config,"The fact that `wait_for_workers` waits forever looks to me like the Dask job is never actually started. You should double check that a simple Dask application with the same config but doing something else unrelated to RDF is working. Let's see, something like this should suffice (inspired by the dask [docs](https://examples.dask.org/delayed.html) and your reproducer):; ```python; import time; import random. from dask import delayed; from dask.distributed import Client; from dask_jobqueue import HTCondorCluster. cluster = HTCondorCluster(cores=1, processes=1, memory=""1GB"", disk=""0.1GB"", job_extra={""jobflavour"": ""espresso""}); cluster.scale(jobs=1); client = Client(cluster). # Try with and without this; client.wait_for_workers(1). def inc(x):; time.sleep(random.random()); return x + 1. def dec(x):; time.sleep(random.random()); return x - 1. def add(x, y):; time.sleep(random.random()); return x + y. inc = delayed(inc); dec = delayed(dec); add = delayed(add). x = inc(1); y = dec(2); z = add(x, y). print(f""Result is: {z.compute()}""); ```. Coming back to RDF, the `npartitions` parameter corresponds to how many distributed tasks will be sent to the Dask scheduler. Supposing you know something about how many resources you have or the layout of your ROOT dataset, you could set this manually in the RDataFrame constructor like; ```python; df = RDataFrame(""treename"",""filename.root"",daskclient=client,npartitions=NPARTITIONS); ``` ; A good parallelisation can often be obtained when the number of partitions is roughly 3x the amount of cores you can use.; UPDATE:. > in particular I'm interested in using Dask's adaptive worker management, so that the exact number of submitted jobs is not fixed a priori but automatically adapts to the workload... Sounds good, then the `npartitions` parameter could be adjusted based on how many TTree clusters you have in your dataset. Roughly one task every 4-5 clusters should be a good starting point.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9429#issuecomment-992602348
Usability,simpl,simple,"The fact that `wait_for_workers` waits forever looks to me like the Dask job is never actually started. You should double check that a simple Dask application with the same config but doing something else unrelated to RDF is working. Let's see, something like this should suffice (inspired by the dask [docs](https://examples.dask.org/delayed.html) and your reproducer):; ```python; import time; import random. from dask import delayed; from dask.distributed import Client; from dask_jobqueue import HTCondorCluster. cluster = HTCondorCluster(cores=1, processes=1, memory=""1GB"", disk=""0.1GB"", job_extra={""jobflavour"": ""espresso""}); cluster.scale(jobs=1); client = Client(cluster). # Try with and without this; client.wait_for_workers(1). def inc(x):; time.sleep(random.random()); return x + 1. def dec(x):; time.sleep(random.random()); return x - 1. def add(x, y):; time.sleep(random.random()); return x + y. inc = delayed(inc); dec = delayed(dec); add = delayed(add). x = inc(1); y = dec(2); z = add(x, y). print(f""Result is: {z.compute()}""); ```. Coming back to RDF, the `npartitions` parameter corresponds to how many distributed tasks will be sent to the Dask scheduler. Supposing you know something about how many resources you have or the layout of your ROOT dataset, you could set this manually in the RDataFrame constructor like; ```python; df = RDataFrame(""treename"",""filename.root"",daskclient=client,npartitions=NPARTITIONS); ``` ; A good parallelisation can often be obtained when the number of partitions is roughly 3x the amount of cores you can use.; UPDATE:. > in particular I'm interested in using Dask's adaptive worker management, so that the exact number of submitted jobs is not fixed a priori but automatically adapts to the workload... Sounds good, then the `npartitions` parameter could be adjusted based on how many TTree clusters you have in your dataset. Roughly one task every 4-5 clusters should be a good starting point.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9429#issuecomment-992602348
Deployability,configurat,configuration,"Thanks for all the insights! We are still learning how to cope with all the different interfaces. It is possible that at some point all this extra configuration will be collected in a single place to make it easier for new users to activate from distributed RDataFrame directly. It would be amazing if you could try again your reproducer with the next nightlies if you have time, thank you so much :smile: !; Let's continue the discussion in private for other topics",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9429#issuecomment-993713171
Integrability,interface,interfaces,"Thanks for all the insights! We are still learning how to cope with all the different interfaces. It is possible that at some point all this extra configuration will be collected in a single place to make it easier for new users to activate from distributed RDataFrame directly. It would be amazing if you could try again your reproducer with the next nightlies if you have time, thank you so much :smile: !; Let's continue the discussion in private for other topics",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9429#issuecomment-993713171
Modifiability,config,configuration,"Thanks for all the insights! We are still learning how to cope with all the different interfaces. It is possible that at some point all this extra configuration will be collected in a single place to make it easier for new users to activate from distributed RDataFrame directly. It would be amazing if you could try again your reproducer with the next nightlies if you have time, thank you so much :smile: !; Let's continue the discussion in private for other topics",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9429#issuecomment-993713171
Usability,learn,learning,"Thanks for all the insights! We are still learning how to cope with all the different interfaces. It is possible that at some point all this extra configuration will be collected in a single place to make it easier for new users to activate from distributed RDataFrame directly. It would be amazing if you could try again your reproducer with the next nightlies if you have time, thank you so much :smile: !; Let's continue the discussion in private for other topics",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9429#issuecomment-993713171
Usability,simpl,simplifications,"I support this kind of simplifications: deprecating genreflex is an option. Before discussing that in detail, the advantages of the rootcling only approaches should be listed carefully. Users such as CMS and LHCb will have to migrate away of genreflex.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9448#issuecomment-1925410790
Deployability,patch,patch,"Ivan and I took a look and it looks like the culprit is `cling` getting static initialization wrong (e.g. calling a static initializer multiple times instead of once, even in a single-thread program). Unfortunately I didn't manage to disentangle the issue from RDF. The simplest way to reproduce is to add this patch to ROOT master (47f66c57ca):. ```diff; diff --git a/tree/dataframe/inc/ROOT/RDF/GraphNode.hxx b/tree/dataframe/inc/ROOT/RDF/GraphNode.hxx; index 9548c4adf0..3e39c80f33 100644; --- a/tree/dataframe/inc/ROOT/RDF/GraphNode.hxx; +++ b/tree/dataframe/inc/ROOT/RDF/GraphNode.hxx; @@ -57,6 +57,7 @@ private:; static unsigned int &GetStaticGlobalCounter(); {; static unsigned int sGlobalCounter = 1;; + printf(""static global counter:%u\n"", sGlobalCounter);; return sGlobalCounter;; }. @@ -68,7 +69,11 @@ public:; ////////////////////////////////////////////////////////////////////////////; /// \brief Resets the counter.; /// This is not strictly needed but guarantees that two consecutive request to the graph return the same result.; - static void ClearCounter() { GraphNode::GetStaticGlobalCounter() = 1; }; + static void ClearCounter(); + {; + printf(""setting counter to 1\n"");; + GraphNode::GetStaticGlobalCounter() = 1;; + }. ////////////////////////////////////////////////////////////////////////////; /// \brief Appends a node on the head of the current node; ```. and execute the following code (adapted from Ivan's repro above):. ```cpp; // repro.cpp; #include <ROOT/RDFHelpers.hxx>; #include <ROOT/RDataFrame.hxx>. void repro() {; ROOT::RDataFrame rd1(1);; auto branch1_1 = rd1.Define(""one"", ""1"").Count();; auto branch1_2 = rd1.Define(""two"", ""2"").Count();; ROOT::RDF::SaveGraph(rd1);; }. #ifndef __CLING__; int main() { repro(); }; #endif; ```. Running through the interpreter:. ```; $ root -l -b -q repro.cpp. Processing repro.cpp...; setting counter to 1; static global counter:1; static global counter:1; static global counter:1 // one again!? this counter is always increased",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9474#issuecomment-998846312
Energy Efficiency,adapt,adapted,"e/dataframe/inc/ROOT/RDF/GraphNode.hxx; index 9548c4adf0..3e39c80f33 100644; --- a/tree/dataframe/inc/ROOT/RDF/GraphNode.hxx; +++ b/tree/dataframe/inc/ROOT/RDF/GraphNode.hxx; @@ -57,6 +57,7 @@ private:; static unsigned int &GetStaticGlobalCounter(); {; static unsigned int sGlobalCounter = 1;; + printf(""static global counter:%u\n"", sGlobalCounter);; return sGlobalCounter;; }. @@ -68,7 +69,11 @@ public:; ////////////////////////////////////////////////////////////////////////////; /// \brief Resets the counter.; /// This is not strictly needed but guarantees that two consecutive request to the graph return the same result.; - static void ClearCounter() { GraphNode::GetStaticGlobalCounter() = 1; }; + static void ClearCounter(); + {; + printf(""setting counter to 1\n"");; + GraphNode::GetStaticGlobalCounter() = 1;; + }. ////////////////////////////////////////////////////////////////////////////; /// \brief Appends a node on the head of the current node; ```. and execute the following code (adapted from Ivan's repro above):. ```cpp; // repro.cpp; #include <ROOT/RDFHelpers.hxx>; #include <ROOT/RDataFrame.hxx>. void repro() {; ROOT::RDataFrame rd1(1);; auto branch1_1 = rd1.Define(""one"", ""1"").Count();; auto branch1_2 = rd1.Define(""two"", ""2"").Count();; ROOT::RDF::SaveGraph(rd1);; }. #ifndef __CLING__; int main() { repro(); }; #endif; ```. Running through the interpreter:. ```; $ root -l -b -q repro.cpp. Processing repro.cpp...; setting counter to 1; static global counter:1; static global counter:1; static global counter:1 // one again!? this counter is always increased; static global counter:2; static global counter:3; static global counter:2 // two again!?; static global counter:4; ```. the output is wrong and different from what we get in a compiled program:. ```; $ g++ -g -Wall -Wextra -Wpedantic -o repro repro.cpp $(root-config --cflags --libs) && ./repro; setting counter to 1; static global counter:1; static global counter:1; static global counter:2; static global counter",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9474#issuecomment-998846312
Modifiability,adapt,adapted,"e/dataframe/inc/ROOT/RDF/GraphNode.hxx; index 9548c4adf0..3e39c80f33 100644; --- a/tree/dataframe/inc/ROOT/RDF/GraphNode.hxx; +++ b/tree/dataframe/inc/ROOT/RDF/GraphNode.hxx; @@ -57,6 +57,7 @@ private:; static unsigned int &GetStaticGlobalCounter(); {; static unsigned int sGlobalCounter = 1;; + printf(""static global counter:%u\n"", sGlobalCounter);; return sGlobalCounter;; }. @@ -68,7 +69,11 @@ public:; ////////////////////////////////////////////////////////////////////////////; /// \brief Resets the counter.; /// This is not strictly needed but guarantees that two consecutive request to the graph return the same result.; - static void ClearCounter() { GraphNode::GetStaticGlobalCounter() = 1; }; + static void ClearCounter(); + {; + printf(""setting counter to 1\n"");; + GraphNode::GetStaticGlobalCounter() = 1;; + }. ////////////////////////////////////////////////////////////////////////////; /// \brief Appends a node on the head of the current node; ```. and execute the following code (adapted from Ivan's repro above):. ```cpp; // repro.cpp; #include <ROOT/RDFHelpers.hxx>; #include <ROOT/RDataFrame.hxx>. void repro() {; ROOT::RDataFrame rd1(1);; auto branch1_1 = rd1.Define(""one"", ""1"").Count();; auto branch1_2 = rd1.Define(""two"", ""2"").Count();; ROOT::RDF::SaveGraph(rd1);; }. #ifndef __CLING__; int main() { repro(); }; #endif; ```. Running through the interpreter:. ```; $ root -l -b -q repro.cpp. Processing repro.cpp...; setting counter to 1; static global counter:1; static global counter:1; static global counter:1 // one again!? this counter is always increased; static global counter:2; static global counter:3; static global counter:2 // two again!?; static global counter:4; ```. the output is wrong and different from what we get in a compiled program:. ```; $ g++ -g -Wall -Wextra -Wpedantic -o repro repro.cpp $(root-config --cflags --libs) && ./repro; setting counter to 1; static global counter:1; static global counter:1; static global counter:2; static global counter",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9474#issuecomment-998846312
Usability,simpl,simplest,"Ivan and I took a look and it looks like the culprit is `cling` getting static initialization wrong (e.g. calling a static initializer multiple times instead of once, even in a single-thread program). Unfortunately I didn't manage to disentangle the issue from RDF. The simplest way to reproduce is to add this patch to ROOT master (47f66c57ca):. ```diff; diff --git a/tree/dataframe/inc/ROOT/RDF/GraphNode.hxx b/tree/dataframe/inc/ROOT/RDF/GraphNode.hxx; index 9548c4adf0..3e39c80f33 100644; --- a/tree/dataframe/inc/ROOT/RDF/GraphNode.hxx; +++ b/tree/dataframe/inc/ROOT/RDF/GraphNode.hxx; @@ -57,6 +57,7 @@ private:; static unsigned int &GetStaticGlobalCounter(); {; static unsigned int sGlobalCounter = 1;; + printf(""static global counter:%u\n"", sGlobalCounter);; return sGlobalCounter;; }. @@ -68,7 +69,11 @@ public:; ////////////////////////////////////////////////////////////////////////////; /// \brief Resets the counter.; /// This is not strictly needed but guarantees that two consecutive request to the graph return the same result.; - static void ClearCounter() { GraphNode::GetStaticGlobalCounter() = 1; }; + static void ClearCounter(); + {; + printf(""setting counter to 1\n"");; + GraphNode::GetStaticGlobalCounter() = 1;; + }. ////////////////////////////////////////////////////////////////////////////; /// \brief Appends a node on the head of the current node; ```. and execute the following code (adapted from Ivan's repro above):. ```cpp; // repro.cpp; #include <ROOT/RDFHelpers.hxx>; #include <ROOT/RDataFrame.hxx>. void repro() {; ROOT::RDataFrame rd1(1);; auto branch1_1 = rd1.Define(""one"", ""1"").Count();; auto branch1_2 = rd1.Define(""two"", ""2"").Count();; ROOT::RDF::SaveGraph(rd1);; }. #ifndef __CLING__; int main() { repro(); }; #endif; ```. Running through the interpreter:. ```; $ root -l -b -q repro.cpp. Processing repro.cpp...; setting counter to 1; static global counter:1; static global counter:1; static global counter:1 // one again!? this counter is always increased",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9474#issuecomment-998846312
Availability,failure,failure,"I tested it locally and it seems to do the job now. If two processes get to the creation of the cache directory hierarchy precisely at the same time, it seems that there can still be a race there where one process fails to create the cache directory but it also doesn't see the full hierarchy already there. In that case there is no hard failure though: the process that fails to create the cache directory simply reads the file remotely rather than caching it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9479#issuecomment-1006504826
Performance,cache,cache,"I tested it locally and it seems to do the job now. If two processes get to the creation of the cache directory hierarchy precisely at the same time, it seems that there can still be a race there where one process fails to create the cache directory but it also doesn't see the full hierarchy already there. In that case there is no hard failure though: the process that fails to create the cache directory simply reads the file remotely rather than caching it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9479#issuecomment-1006504826
Testability,test,tested,"I tested it locally and it seems to do the job now. If two processes get to the creation of the cache directory hierarchy precisely at the same time, it seems that there can still be a race there where one process fails to create the cache directory but it also doesn't see the full hierarchy already there. In that case there is no hard failure though: the process that fails to create the cache directory simply reads the file remotely rather than caching it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9479#issuecomment-1006504826
Usability,simpl,simply,"I tested it locally and it seems to do the job now. If two processes get to the creation of the cache directory hierarchy precisely at the same time, it seems that there can still be a race there where one process fails to create the cache directory but it also doesn't see the full hierarchy already there. In that case there is no hard failure though: the process that fails to create the cache directory simply reads the file remotely rather than caching it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9479#issuecomment-1006504826
Integrability,interface,interface,"Hi @cburgard and @gartrog, thanks a lot for these developments! I have only a few comments inline. Besides that, please do a few things before we can merge (I would like to merge this as soon as possible, tomorrow or on Friday. If you have more you can always do a followup PR):. 1. You moved the `JSONInterface` to a public header now, so it's not a `RooFit::Detail` anymore (I understand now that the user needs the interface to implement custom importers/exporters). But still, it's an interface under heavy development and we need to make that clear to the user that they can't rely too much on the stability of this interface. Therefore, can you please change the namespace to `RooFit::Experimental`?; 2. Please give the PR a meaningful title, and the first commit a good commit message, optimally not only a title but also a body where you explain what you did. When merging, I will squash the commits and only the first commit message will be taken, so please consider that.; 3. Make sure that all C++ sources are formatted with `clang-format` and the python sources with `black --line-length=120`. Let me know when this is done, then we can ask the CI to test once again and then merge.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9482#issuecomment-1016939443
Testability,test,test,"Hi @cburgard and @gartrog, thanks a lot for these developments! I have only a few comments inline. Besides that, please do a few things before we can merge (I would like to merge this as soon as possible, tomorrow or on Friday. If you have more you can always do a followup PR):. 1. You moved the `JSONInterface` to a public header now, so it's not a `RooFit::Detail` anymore (I understand now that the user needs the interface to implement custom importers/exporters). But still, it's an interface under heavy development and we need to make that clear to the user that they can't rely too much on the stability of this interface. Therefore, can you please change the namespace to `RooFit::Experimental`?; 2. Please give the PR a meaningful title, and the first commit a good commit message, optimally not only a title but also a body where you explain what you did. When merging, I will squash the commits and only the first commit message will be taken, so please consider that.; 3. Make sure that all C++ sources are formatted with `clang-format` and the python sources with `black --line-length=120`. Let me know when this is done, then we can ask the CI to test once again and then merge.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9482#issuecomment-1016939443
Usability,clear,clear,"Hi @cburgard and @gartrog, thanks a lot for these developments! I have only a few comments inline. Besides that, please do a few things before we can merge (I would like to merge this as soon as possible, tomorrow or on Friday. If you have more you can always do a followup PR):. 1. You moved the `JSONInterface` to a public header now, so it's not a `RooFit::Detail` anymore (I understand now that the user needs the interface to implement custom importers/exporters). But still, it's an interface under heavy development and we need to make that clear to the user that they can't rely too much on the stability of this interface. Therefore, can you please change the namespace to `RooFit::Experimental`?; 2. Please give the PR a meaningful title, and the first commit a good commit message, optimally not only a title but also a body where you explain what you did. When merging, I will squash the commits and only the first commit message will be taken, so please consider that.; 3. Make sure that all C++ sources are formatted with `clang-format` and the python sources with `black --line-length=120`. Let me know when this is done, then we can ask the CI to test once again and then merge.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9482#issuecomment-1016939443
Safety,avoid,avoid,"Hi @acampove, thanks for reporting this issue!. I have opened a to avoid the overly-verbose printout in the unbinned case:; https://github.com/root-project/root/pull/14309. However, I would refrain from implementing a progress bar, because this makes the output more difficult to digest when reading log files from e.g. grid jobs. So while I agree it would be nice for interactive use, it would do more harm that good in batch jobs. One could maybe hack something that detects the context in which RooFit is used, but these hacks are usually fragile and I would prefer not to do it. I'll close this issue after merging the PR with the log in the unbinned case. If you *really* want this progress bar, feel free to open a new issue about this, but I'm afraid I can't justify giving that one a high priority. Thanks for your understanding!; Jonas",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9489#issuecomment-1881439092
Testability,log,log,"Hi @acampove, thanks for reporting this issue!. I have opened a to avoid the overly-verbose printout in the unbinned case:; https://github.com/root-project/root/pull/14309. However, I would refrain from implementing a progress bar, because this makes the output more difficult to digest when reading log files from e.g. grid jobs. So while I agree it would be nice for interactive use, it would do more harm that good in batch jobs. One could maybe hack something that detects the context in which RooFit is used, but these hacks are usually fragile and I would prefer not to do it. I'll close this issue after merging the PR with the log in the unbinned case. If you *really* want this progress bar, feel free to open a new issue about this, but I'm afraid I can't justify giving that one a high priority. Thanks for your understanding!; Jonas",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9489#issuecomment-1881439092
Usability,progress bar,progress bar,"Hi @acampove, thanks for reporting this issue!. I have opened a to avoid the overly-verbose printout in the unbinned case:; https://github.com/root-project/root/pull/14309. However, I would refrain from implementing a progress bar, because this makes the output more difficult to digest when reading log files from e.g. grid jobs. So while I agree it would be nice for interactive use, it would do more harm that good in batch jobs. One could maybe hack something that detects the context in which RooFit is used, but these hacks are usually fragile and I would prefer not to do it. I'll close this issue after merging the PR with the log in the unbinned case. If you *really* want this progress bar, feel free to open a new issue about this, but I'm afraid I can't justify giving that one a high priority. Thanks for your understanding!; Jonas",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9489#issuecomment-1881439092
Usability,clear,clear,"Diagnostic findings:. Parameters are not saved unless there is a constraint due to [this line](https://root.cern.ch/doc/v624/RooMCStudy_8cxx_source.html#l00197). The documentation makes no mention of the need for constraints, and the use case without constraints is clear. . *External* constraints do not work because of the [use](https://root.cern.ch/doc/v624/RooMCStudy_8cxx_source.html#l00189) of `RooAbsPdf::getAllConstraints`, which does not account for external constraints, to determine the existence of constraints.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9490#issuecomment-1003615961
Usability,feedback,feedback,"Thanks for the feedback. Could the function be overriden ?; ```; TGraph::SaveAs(...); {; if (std::ends_with("".csv"")); {; //do something; }; else; {; TObject::SaveAs(...);; }; }; ```. Or alternatively, in TObject::SaveAs, do the following:. ```; if ends_with('.csv') and ClassName() == ""TGraph""); {; ... do something; }; else; {; ...do what does now; }; ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9491#issuecomment-1058270647
Usability,simpl,simplest,"Yes the first approach might be the simplest.; In your example you separate value with tabs. I thought `.csv` meant ""comma separated value"" therefore should we better do:; ```; outfile << x[i] << "","" << y[i] << std::endl;. ```; ?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9491#issuecomment-1058992368
Usability,simpl,simple,"Indeed, as said on the forum it is quite simple to reproduce this option with the current ROOT. See the script and plot I posted on the forum. If that enough for you we can close this issue.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9505#issuecomment-1092679466
Deployability,patch,patch,"Updated. > It seems ok for me... I do not see how it could be more ""friendly""?. By *fiendly* I mean ""prevent damaging or changing the appearance of due to line break, especially when long strings are encountered"". In the original patch, it provided a general way (from `TVirtulaPS`) to specify different characters (aside from white spaces) to break the line at, and the option to drop the white space at which the line break happens to prevent additional white spaces from showing up in the image when cutting through a long sentence. In the updated patch, a customised `PrintFast` method is created inside `TSVG` that provides more customization (e.g. it's natural to cut between tags `><` in XML) in addition to features from the original patch, while keeping the `TVirtualPS` simple.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9518#issuecomment-1047616127
Usability,simpl,simple,"Updated. > It seems ok for me... I do not see how it could be more ""friendly""?. By *fiendly* I mean ""prevent damaging or changing the appearance of due to line break, especially when long strings are encountered"". In the original patch, it provided a general way (from `TVirtulaPS`) to specify different characters (aside from white spaces) to break the line at, and the option to drop the white space at which the line break happens to prevent additional white spaces from showing up in the image when cutting through a long sentence. In the updated patch, a customised `PrintFast` method is created inside `TSVG` that provides more customization (e.g. it's natural to cut between tags `><` in XML) in addition to features from the original patch, while keeping the `TVirtualPS` simple.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9518#issuecomment-1047616127
Usability,learn,learn,yes i will learn a bit about Root and get back to this issue; Thankyou for the guidance.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9546#issuecomment-1010928254
Deployability,release,release,"Result from `git-bisect` on LLVM/Clang between current `release/13.x` and `llvmorg-13-init`:; ```; git bisect start; # bad: [9d9efb1f67ff70e996b1cb7fa00e24b9121be226] [lld][CMake] Add LLD_DEFAULT_NOSTART_STOP_GC; git bisect bad 9d9efb1f67ff70e996b1cb7fa00e24b9121be226; # good: [5369517d20dd362a178a1b2d6c398d8898ee4620] Bump the trunk major version to 13; git bisect good 5369517d20dd362a178a1b2d6c398d8898ee4620; # bad: [711a473cd9e3c8e63ad3460d49fdab1545634dd2] Update testcase for D101333.; git bisect bad 711a473cd9e3c8e63ad3460d49fdab1545634dd2; # bad: [11b70b9e3a7458b5b78c30020b56e8ca563a4801] Revert ""[NPM][CGSCC] FunctionAnalysisManagerCGSCCProxy: do not clear immutable function passes""; git bisect bad 11b70b9e3a7458b5b78c30020b56e8ca563a4801; # good: [97ec8fa5bb07e3f5bf25ddcb216b545cd3d03b65] [Coverage] Store compilation dir separately in coverage mapping; git bisect good 97ec8fa5bb07e3f5bf25ddcb216b545cd3d03b65; # bad: [4096ae06f47af9db2c2550a2c34979edfbd91b8d] [lldb] Support DWARF-5 DW_FORM_line_strp (used by GCC); git bisect bad 4096ae06f47af9db2c2550a2c34979edfbd91b8d; # bad: [d65ddca83ff85c7345fe9a0f5a15750f01e38420] [ValueTracking] ComputeKnownBits - minimum leading/trailing zero bits in LSHR/SHL (PR44526); git bisect bad d65ddca83ff85c7345fe9a0f5a15750f01e38420; # good: [15a74b64dfa9bc1213cd582415f849b4dba51bad] [VPlan] Manage pairs of incoming (VPValue, VPBB) in VPWidenPHIRecipe.; git bisect good 15a74b64dfa9bc1213cd582415f849b4dba51bad; # good: [dd68f3cf2899c554cab7baf3ccdcd3f987d77736] [RISCV] Support insertion of misaligned subvectors; git bisect good dd68f3cf2899c554cab7baf3ccdcd3f987d77736; # good: [97a304cc8f949e40693d63b855b4b24bc81fa729] [scan-build-py] Add sarif-html support in scan-build-py; git bisect good 97a304cc8f949e40693d63b855b4b24bc81fa729; # bad: [0f279c7a5c34eaae797c325c18614def21eba921] Revert ""patch"" it wass my mistake inusing git; git bisect bad 0f279c7a5c34eaae797c325c18614def21eba921; # bad: [56d228a14e3631de157ae98dd61d21193e4502d",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9547#issuecomment-1011201311
Testability,test,testcase,"Result from `git-bisect` on LLVM/Clang between current `release/13.x` and `llvmorg-13-init`:; ```; git bisect start; # bad: [9d9efb1f67ff70e996b1cb7fa00e24b9121be226] [lld][CMake] Add LLD_DEFAULT_NOSTART_STOP_GC; git bisect bad 9d9efb1f67ff70e996b1cb7fa00e24b9121be226; # good: [5369517d20dd362a178a1b2d6c398d8898ee4620] Bump the trunk major version to 13; git bisect good 5369517d20dd362a178a1b2d6c398d8898ee4620; # bad: [711a473cd9e3c8e63ad3460d49fdab1545634dd2] Update testcase for D101333.; git bisect bad 711a473cd9e3c8e63ad3460d49fdab1545634dd2; # bad: [11b70b9e3a7458b5b78c30020b56e8ca563a4801] Revert ""[NPM][CGSCC] FunctionAnalysisManagerCGSCCProxy: do not clear immutable function passes""; git bisect bad 11b70b9e3a7458b5b78c30020b56e8ca563a4801; # good: [97ec8fa5bb07e3f5bf25ddcb216b545cd3d03b65] [Coverage] Store compilation dir separately in coverage mapping; git bisect good 97ec8fa5bb07e3f5bf25ddcb216b545cd3d03b65; # bad: [4096ae06f47af9db2c2550a2c34979edfbd91b8d] [lldb] Support DWARF-5 DW_FORM_line_strp (used by GCC); git bisect bad 4096ae06f47af9db2c2550a2c34979edfbd91b8d; # bad: [d65ddca83ff85c7345fe9a0f5a15750f01e38420] [ValueTracking] ComputeKnownBits - minimum leading/trailing zero bits in LSHR/SHL (PR44526); git bisect bad d65ddca83ff85c7345fe9a0f5a15750f01e38420; # good: [15a74b64dfa9bc1213cd582415f849b4dba51bad] [VPlan] Manage pairs of incoming (VPValue, VPBB) in VPWidenPHIRecipe.; git bisect good 15a74b64dfa9bc1213cd582415f849b4dba51bad; # good: [dd68f3cf2899c554cab7baf3ccdcd3f987d77736] [RISCV] Support insertion of misaligned subvectors; git bisect good dd68f3cf2899c554cab7baf3ccdcd3f987d77736; # good: [97a304cc8f949e40693d63b855b4b24bc81fa729] [scan-build-py] Add sarif-html support in scan-build-py; git bisect good 97a304cc8f949e40693d63b855b4b24bc81fa729; # bad: [0f279c7a5c34eaae797c325c18614def21eba921] Revert ""patch"" it wass my mistake inusing git; git bisect bad 0f279c7a5c34eaae797c325c18614def21eba921; # bad: [56d228a14e3631de157ae98dd61d21193e4502d",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9547#issuecomment-1011201311
Usability,clear,clear,"Result from `git-bisect` on LLVM/Clang between current `release/13.x` and `llvmorg-13-init`:; ```; git bisect start; # bad: [9d9efb1f67ff70e996b1cb7fa00e24b9121be226] [lld][CMake] Add LLD_DEFAULT_NOSTART_STOP_GC; git bisect bad 9d9efb1f67ff70e996b1cb7fa00e24b9121be226; # good: [5369517d20dd362a178a1b2d6c398d8898ee4620] Bump the trunk major version to 13; git bisect good 5369517d20dd362a178a1b2d6c398d8898ee4620; # bad: [711a473cd9e3c8e63ad3460d49fdab1545634dd2] Update testcase for D101333.; git bisect bad 711a473cd9e3c8e63ad3460d49fdab1545634dd2; # bad: [11b70b9e3a7458b5b78c30020b56e8ca563a4801] Revert ""[NPM][CGSCC] FunctionAnalysisManagerCGSCCProxy: do not clear immutable function passes""; git bisect bad 11b70b9e3a7458b5b78c30020b56e8ca563a4801; # good: [97ec8fa5bb07e3f5bf25ddcb216b545cd3d03b65] [Coverage] Store compilation dir separately in coverage mapping; git bisect good 97ec8fa5bb07e3f5bf25ddcb216b545cd3d03b65; # bad: [4096ae06f47af9db2c2550a2c34979edfbd91b8d] [lldb] Support DWARF-5 DW_FORM_line_strp (used by GCC); git bisect bad 4096ae06f47af9db2c2550a2c34979edfbd91b8d; # bad: [d65ddca83ff85c7345fe9a0f5a15750f01e38420] [ValueTracking] ComputeKnownBits - minimum leading/trailing zero bits in LSHR/SHL (PR44526); git bisect bad d65ddca83ff85c7345fe9a0f5a15750f01e38420; # good: [15a74b64dfa9bc1213cd582415f849b4dba51bad] [VPlan] Manage pairs of incoming (VPValue, VPBB) in VPWidenPHIRecipe.; git bisect good 15a74b64dfa9bc1213cd582415f849b4dba51bad; # good: [dd68f3cf2899c554cab7baf3ccdcd3f987d77736] [RISCV] Support insertion of misaligned subvectors; git bisect good dd68f3cf2899c554cab7baf3ccdcd3f987d77736; # good: [97a304cc8f949e40693d63b855b4b24bc81fa729] [scan-build-py] Add sarif-html support in scan-build-py; git bisect good 97a304cc8f949e40693d63b855b4b24bc81fa729; # bad: [0f279c7a5c34eaae797c325c18614def21eba921] Revert ""patch"" it wass my mistake inusing git; git bisect bad 0f279c7a5c34eaae797c325c18614def21eba921; # bad: [56d228a14e3631de157ae98dd61d21193e4502d",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9547#issuecomment-1011201311
Usability,feedback,feedback,"@smuzaffar, thanks a lot for the prompt feedback!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9592#issuecomment-1018284184
Deployability,patch,patches,"Any plan when this can be addressed, at least for v6-26-00-patches? The LCG nightlies are not very usable at the moment.; Can I suggest to revet the patch for v6-26-00-patches and re-port it when it is fixed on the master ?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9594#issuecomment-1017324188
Usability,usab,usable,"Any plan when this can be addressed, at least for v6-26-00-patches? The LCG nightlies are not very usable at the moment.; Can I suggest to revet the patch for v6-26-00-patches and re-port it when it is fixed on the master ?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9594#issuecomment-1017324188
Availability,down,downstream,"While ROOT master is now building successfully for us, there are some downstream packages that suffer from this change. They can probably be fixed by exporting the ROOT_INCLUDE_PATH, but to better understand where things go wrong I made a very simple repeater. I think on any centos7 with the sft cvmfs this should work; ```; source /cvmfs/sft-nightlies.cern.ch/lcg/nightlies/dev3/Fri/CMake/3.20.0/x86_64-centos7-gcc10-dbg/CMake-env.sh; source /cvmfs/sft-nightlies.cern.ch/lcg/nightlies/dev3/Fri/ROOT/HEAD/x86_64-centos7-gcc10-dbg/ROOT-env.sh. git clone https://gitlab.cern.ch/sailer/root_repeater.git; cd root_repeater; mkdir build; cd build. cmake -D nlohmann_json_DIR=$JSONMCPP__HOME/lib64/cmake/nlohmann_json \; -D Python_ROOT_DIR=$PYTHON__HOME \; -D Vc_DIR=$VC__HOME/lib/cmake/Vc \; ..; make; ./RunTest; ```. Just linking an executable to ROOTTPython (https://gitlab.cern.ch/sailer/root_repeater/-/blob/master/CMakeLists.txt#L17); leads to an error like this; ```; ./RunTest ; <<< cling interactive line includer >>>: fatal error: module file '/build/jenkins/workspace/lcg_nightly_pipeline/build/projects/ROOT-HEAD/src/ROOT-HEAD-build/lib/Vc.pcm' not found: module file not found; <<< cling interactive line includer >>>: note: imported by module 'MathCore' in '/cvmfs/sft-nightlies.cern.ch/lcg/nightlies/dev3/Fri/ROOT/HEAD/x86_64-centos7-gcc10-dbg/lib/MathCore.pcm'; Failed to load module MathCore; Failed to load module Hist; Failed to load module ROOTBrowsable; Failed to load module Unfold; Failed to load module RHTTPSniff; Failed to load module HistPainter; Failed to load module PyMVA; Failed to load module RHTTP; Failed to load module FitPanel; Failed to load module ProofDraw; Failed to load module Unuran; Failed to load module Quadp; Failed to load module Genetic; Failed to load module Eve; Failed to load module GeomPainter; Failed to load module TreeViewer; Failed to load module Physics; Failed to load module EG; Failed to load module Tree; Failed to load module HistFactory; Fai",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9594#issuecomment-1029801305
Integrability,message,message,"SPlot; Failed to load module Hbook; Failed to load module RooFit; Failed to load module RCsg; Failed to load module RooStats; Failed to load module RooFitRDataFrameHelpers; Failed to load module GeomBuilder; Failed to load module Proof; Failed to load module FITSIO; Failed to load module Ged; Failed to load module Recorder; Failed to load module FFTW; Failed to load module GuiBld; Failed to load module ROOTWebDisplay; Failed to load module RooFitCore; Failed to load module Gui; Failed to load module ROOTHistDraw; Failed to load module GX11TTF; Failed to load module ROOTTMVASofie; Failed to load module ProofPlayer; Failed to load module ASImage; Failed to load module MathMore; Failed to load module RooFitHS3; Failed to load module Foam; Failed to load module SpectrumPainter; Failed to load module Minuit2; Failed to load module MLP; Failed to load module ROOTDataFrame; Failed to load module GenVector; Failed to load module ROOTBrowserv7; Failed to load module Minuit; Failed to load module Graf3d; Failed to load module TMVA; Failed to load module ASImageGui; Failed to load module Graf; Failed to load module GX11; Failed to load module Gdml; Failed to load module ProofBench; Failed to load module MathCore; Failed to load module Gviz3d; Failed to load module WebGui6; Failed to load module ROOTHist; Failed to load module TreePlayer; Failed to load module ROOTFitPanelv7; Failed to load module Smatrix; Failed to load module SessionViewer; RunTest: /build/jenkins/workspace/lcg_nightly_pipeline/build/projects/ROOT-HEAD/src/ROOT/HEAD/interpreter/llvm/src/tools/clang/lib/Lex/Lexer.cpp:3940: bool clang::Lexer::LexTokenInternal(clang::Token&, bool): Assertion `Result.is(tok::eof) && ""Preprocessor did not set tok:eof""' failed.; Aborted (core dumped); ```; Even though Vc.pcm is sitting right next to MathCore.pcm; export ROOT_INCLUDE_PATH does solve this problem (see the other tests in the repeater), but at least to me this behaviour or at least the error message seems questionable.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9594#issuecomment-1029801305
Performance,load,load,o load module Unuran; Failed to load module Quadp; Failed to load module Genetic; Failed to load module Eve; Failed to load module GeomPainter; Failed to load module TreeViewer; Failed to load module Physics; Failed to load module EG; Failed to load module Tree; Failed to load module HistFactory; Failed to load module Spectrum; Failed to load module Matrix; Failed to load module Html; Failed to load module Hist; Failed to load module GuiHtml; Failed to load module Gpad; Failed to load module TMVAGui; Failed to load module Postscript; Failed to load module ROOTEve; Failed to load module RGL; Failed to load module Fumili; Failed to load module Geom; Failed to load module RooFitMore; Failed to load module X3d; Failed to load module SPlot; Failed to load module Hbook; Failed to load module RooFit; Failed to load module RCsg; Failed to load module RooStats; Failed to load module RooFitRDataFrameHelpers; Failed to load module GeomBuilder; Failed to load module Proof; Failed to load module FITSIO; Failed to load module Ged; Failed to load module Recorder; Failed to load module FFTW; Failed to load module GuiBld; Failed to load module ROOTWebDisplay; Failed to load module RooFitCore; Failed to load module Gui; Failed to load module ROOTHistDraw; Failed to load module GX11TTF; Failed to load module ROOTTMVASofie; Failed to load module ProofPlayer; Failed to load module ASImage; Failed to load module MathMore; Failed to load module RooFitHS3; Failed to load module Foam; Failed to load module SpectrumPainter; Failed to load module Minuit2; Failed to load module MLP; Failed to load module ROOTDataFrame; Failed to load module GenVector; Failed to load module ROOTBrowserv7; Failed to load module Minuit; Failed to load module Graf3d; Failed to load module TMVA; Failed to load module ASImageGui; Failed to load module Graf; Failed to load module GX11; Failed to load module Gdml; Failed to load module ProofBench; Failed to load module MathCore; Failed to load module Gviz3d; Failed to l,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9594#issuecomment-1029801305
Testability,test,tests,"SPlot; Failed to load module Hbook; Failed to load module RooFit; Failed to load module RCsg; Failed to load module RooStats; Failed to load module RooFitRDataFrameHelpers; Failed to load module GeomBuilder; Failed to load module Proof; Failed to load module FITSIO; Failed to load module Ged; Failed to load module Recorder; Failed to load module FFTW; Failed to load module GuiBld; Failed to load module ROOTWebDisplay; Failed to load module RooFitCore; Failed to load module Gui; Failed to load module ROOTHistDraw; Failed to load module GX11TTF; Failed to load module ROOTTMVASofie; Failed to load module ProofPlayer; Failed to load module ASImage; Failed to load module MathMore; Failed to load module RooFitHS3; Failed to load module Foam; Failed to load module SpectrumPainter; Failed to load module Minuit2; Failed to load module MLP; Failed to load module ROOTDataFrame; Failed to load module GenVector; Failed to load module ROOTBrowserv7; Failed to load module Minuit; Failed to load module Graf3d; Failed to load module TMVA; Failed to load module ASImageGui; Failed to load module Graf; Failed to load module GX11; Failed to load module Gdml; Failed to load module ProofBench; Failed to load module MathCore; Failed to load module Gviz3d; Failed to load module WebGui6; Failed to load module ROOTHist; Failed to load module TreePlayer; Failed to load module ROOTFitPanelv7; Failed to load module Smatrix; Failed to load module SessionViewer; RunTest: /build/jenkins/workspace/lcg_nightly_pipeline/build/projects/ROOT-HEAD/src/ROOT/HEAD/interpreter/llvm/src/tools/clang/lib/Lex/Lexer.cpp:3940: bool clang::Lexer::LexTokenInternal(clang::Token&, bool): Assertion `Result.is(tok::eof) && ""Preprocessor did not set tok:eof""' failed.; Aborted (core dumped); ```; Even though Vc.pcm is sitting right next to MathCore.pcm; export ROOT_INCLUDE_PATH does solve this problem (see the other tests in the repeater), but at least to me this behaviour or at least the error message seems questionable.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9594#issuecomment-1029801305
Usability,simpl,simple,"While ROOT master is now building successfully for us, there are some downstream packages that suffer from this change. They can probably be fixed by exporting the ROOT_INCLUDE_PATH, but to better understand where things go wrong I made a very simple repeater. I think on any centos7 with the sft cvmfs this should work; ```; source /cvmfs/sft-nightlies.cern.ch/lcg/nightlies/dev3/Fri/CMake/3.20.0/x86_64-centos7-gcc10-dbg/CMake-env.sh; source /cvmfs/sft-nightlies.cern.ch/lcg/nightlies/dev3/Fri/ROOT/HEAD/x86_64-centos7-gcc10-dbg/ROOT-env.sh. git clone https://gitlab.cern.ch/sailer/root_repeater.git; cd root_repeater; mkdir build; cd build. cmake -D nlohmann_json_DIR=$JSONMCPP__HOME/lib64/cmake/nlohmann_json \; -D Python_ROOT_DIR=$PYTHON__HOME \; -D Vc_DIR=$VC__HOME/lib/cmake/Vc \; ..; make; ./RunTest; ```. Just linking an executable to ROOTTPython (https://gitlab.cern.ch/sailer/root_repeater/-/blob/master/CMakeLists.txt#L17); leads to an error like this; ```; ./RunTest ; <<< cling interactive line includer >>>: fatal error: module file '/build/jenkins/workspace/lcg_nightly_pipeline/build/projects/ROOT-HEAD/src/ROOT-HEAD-build/lib/Vc.pcm' not found: module file not found; <<< cling interactive line includer >>>: note: imported by module 'MathCore' in '/cvmfs/sft-nightlies.cern.ch/lcg/nightlies/dev3/Fri/ROOT/HEAD/x86_64-centos7-gcc10-dbg/lib/MathCore.pcm'; Failed to load module MathCore; Failed to load module Hist; Failed to load module ROOTBrowsable; Failed to load module Unfold; Failed to load module RHTTPSniff; Failed to load module HistPainter; Failed to load module PyMVA; Failed to load module RHTTP; Failed to load module FitPanel; Failed to load module ProofDraw; Failed to load module Unuran; Failed to load module Quadp; Failed to load module Genetic; Failed to load module Eve; Failed to load module GeomPainter; Failed to load module TreeViewer; Failed to load module Physics; Failed to load module EG; Failed to load module Tree; Failed to load module HistFactory; Fai",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9594#issuecomment-1029801305
Usability,clear,clear,"Based on the discussion, it's not clear to me if there's anything left to be done. Can we close this? @vgvassilev",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9594#issuecomment-1850068597
Deployability,patch,patch,"I've added that patch and it does the trick. Thanks a lot!  Next time I have to put together a debug build I'll try to include the sources used to make it easier to understand. > But that's not surprising as we have not released that yet. Or would you expect this patch to be part of this Conda build? It is in master and v6-26-00-patches, not in v6-24. Which ROOT version does that clang correspond to?. The conda nightly build is trying to export the patches from http://root.cern/git/clang.git. It's currently using the commit corresponding to `ROOT-patches-rrelease_90` but nothing more recent has been pushed there as far as I can tell. I thought I'd checked against `interpreter/llvm/src/tools/clang/` for missing patches but clearly I missed this line. Is there any better way I can try to find the patches?. Assuming not I'll try to see if I can come up with a better way of trying to use the root sources to check the required patches now that the LLVM 9 move has settled and the diffs are more manageable.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9595#issuecomment-1022484732
Usability,clear,clearly,"I've added that patch and it does the trick. Thanks a lot!  Next time I have to put together a debug build I'll try to include the sources used to make it easier to understand. > But that's not surprising as we have not released that yet. Or would you expect this patch to be part of this Conda build? It is in master and v6-26-00-patches, not in v6-24. Which ROOT version does that clang correspond to?. The conda nightly build is trying to export the patches from http://root.cern/git/clang.git. It's currently using the commit corresponding to `ROOT-patches-rrelease_90` but nothing more recent has been pushed there as far as I can tell. I thought I'd checked against `interpreter/llvm/src/tools/clang/` for missing patches but clearly I missed this line. Is there any better way I can try to find the patches?. Assuming not I'll try to see if I can come up with a better way of trying to use the root sources to check the required patches now that the LLVM 9 move has settled and the diffs are more manageable.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9595#issuecomment-1022484732
Deployability,configurat,configuration,"This is kind of annoying, both locally and in Jenkins. Is it maybe as simple to solve as; ```diff; diff --git a/root/meta/MakeProject/CMakeLists.txt b/root/meta/MakeProject/CMakeLists.txt; index 308fa288..d090321f 100644; --- a/root/meta/MakeProject/CMakeLists.txt; +++ b/root/meta/MakeProject/CMakeLists.txt; @@ -1,4 +1,4 @@; -ROOTTEST_GENERATE_DICTIONARY(stl_makeproject_test stl_makeproject_test.h LINKDEF stl_makeproject_test_linkdef.h); +ROOTTEST_GENERATE_DICTIONARY(stl_makeproject_test stl_makeproject_test.h LINKDEF stl_makeproject_test_linkdef.h DEPENDS Hist) . if(ROOT_runtime_cxxmodules_FOUND); # FIXME: For C++ modules builds, module.modulemap is generated during configuration time; ```; ?. At least, this makes `ninja stl_makeproject_test` succeed on a freshly configured build for me :thinking:",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9600#issuecomment-1018559183
Modifiability,config,configuration,"This is kind of annoying, both locally and in Jenkins. Is it maybe as simple to solve as; ```diff; diff --git a/root/meta/MakeProject/CMakeLists.txt b/root/meta/MakeProject/CMakeLists.txt; index 308fa288..d090321f 100644; --- a/root/meta/MakeProject/CMakeLists.txt; +++ b/root/meta/MakeProject/CMakeLists.txt; @@ -1,4 +1,4 @@; -ROOTTEST_GENERATE_DICTIONARY(stl_makeproject_test stl_makeproject_test.h LINKDEF stl_makeproject_test_linkdef.h); +ROOTTEST_GENERATE_DICTIONARY(stl_makeproject_test stl_makeproject_test.h LINKDEF stl_makeproject_test_linkdef.h DEPENDS Hist) . if(ROOT_runtime_cxxmodules_FOUND); # FIXME: For C++ modules builds, module.modulemap is generated during configuration time; ```; ?. At least, this makes `ninja stl_makeproject_test` succeed on a freshly configured build for me :thinking:",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9600#issuecomment-1018559183
Usability,simpl,simple,"This is kind of annoying, both locally and in Jenkins. Is it maybe as simple to solve as; ```diff; diff --git a/root/meta/MakeProject/CMakeLists.txt b/root/meta/MakeProject/CMakeLists.txt; index 308fa288..d090321f 100644; --- a/root/meta/MakeProject/CMakeLists.txt; +++ b/root/meta/MakeProject/CMakeLists.txt; @@ -1,4 +1,4 @@; -ROOTTEST_GENERATE_DICTIONARY(stl_makeproject_test stl_makeproject_test.h LINKDEF stl_makeproject_test_linkdef.h); +ROOTTEST_GENERATE_DICTIONARY(stl_makeproject_test stl_makeproject_test.h LINKDEF stl_makeproject_test_linkdef.h DEPENDS Hist) . if(ROOT_runtime_cxxmodules_FOUND); # FIXME: For C++ modules builds, module.modulemap is generated during configuration time; ```; ?. At least, this makes `ninja stl_makeproject_test` succeed on a freshly configured build for me :thinking:",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9600#issuecomment-1018559183
Availability,error,errors,"I've seen those errors and I'll fix them. The only workaround for the time being is not to use `/permissive-` flag, unless you really need it, which is still not clear to me.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9607#issuecomment-1016287337
Usability,clear,clear,"I've seen those errors and I'll fix them. The only workaround for the time being is not to use `/permissive-` flag, unless you really need it, which is still not clear to me.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9607#issuecomment-1016287337
Integrability,interface,interface,"Thanks for your proposal! We won't need `std::shared_ptr<std::vector<Double_t>>` as datatype; `std::vector<Double_t>` would be enough as this allows cheap move operations. Then again, so does `Double_t *`. Did you consider simply implementing a move operator for `TGraph`?. We must avoid all backward incompatible interface changes. I didn't look in detail but the amount of code changes here suggests that this isn't the case for this draft?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9610#issuecomment-1056797487
Safety,avoid,avoid,"Thanks for your proposal! We won't need `std::shared_ptr<std::vector<Double_t>>` as datatype; `std::vector<Double_t>` would be enough as this allows cheap move operations. Then again, so does `Double_t *`. Did you consider simply implementing a move operator for `TGraph`?. We must avoid all backward incompatible interface changes. I didn't look in detail but the amount of code changes here suggests that this isn't the case for this draft?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9610#issuecomment-1056797487
Usability,simpl,simply,"Thanks for your proposal! We won't need `std::shared_ptr<std::vector<Double_t>>` as datatype; `std::vector<Double_t>` would be enough as this allows cheap move operations. Then again, so does `Double_t *`. Did you consider simply implementing a move operator for `TGraph`?. We must avoid all backward incompatible interface changes. I didn't look in detail but the amount of code changes here suggests that this isn't the case for this draft?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9610#issuecomment-1056797487
Usability,clear,clearly,"Thanks Enric!. > it also removes the part about AsRNode (to be discussed). how will users find out about the feature now? . > to be discussed too what to do with the section ""Distributed execution in Python"", I think it deserves to be outside of the PyROOT box, but perhaps we could rename it to just ""Distributed execution"". good for me (EDIT: as long as we still clearly state that it's Python-only). > The doxygen entry for MakeNumpyDataFrame comes from the function with that name that implements the pythonization. If we don't want it to appear in the reference guide with that name, we could rename it to e.g. MakeNumpyDataFrameImpl. Or we can surround it with `\cond`/`\endcond` doxygen commands. I don't have a preference.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9611#issuecomment-1016215896
Usability,clear,clearly,"> how will users find out about the feature now?. Indeed I wouldn't remove it, but we can discuss where we place it. What's the intended use case of `AsRNode`, pass an RDF object to C++ for further processing?. > good for me (EDIT: as long as we still clearly state that it's Python-only). Yes that's the case already in the current text.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9611#issuecomment-1016848413
Usability,feedback,feedback,Any further feedback on this PR ?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9629#issuecomment-1040393898
Availability,error,error,> I can't see the exact reason for clang-format error which is reported above. It simply fails for all PRs. No idea why,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9643#issuecomment-1017950333
Usability,simpl,simply,> I can't see the exact reason for clang-format error which is reported above. It simply fails for all PRs. No idea why,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9643#issuecomment-1017950333
Testability,log,log,"Something went wrong, it looks like you merged the master branch into your feature branch. We need to have one (or more) commit of yours on top of the master branch, like this:. ![image](https://user-images.githubusercontent.com/10999034/150794127-6b77d3bf-9a8d-4d8e-b697-134e1c51c426.png). Instead the current situation is:. ![image](https://user-images.githubusercontent.com/10999034/150794245-1d6abf5e-2011-43fa-b598-8bb4a55c4f35.png). Usually I use `git rebase --interactive` from the command line to fix these kind of issues, see e.g. https://www.sitepoint.com/git-interactive-rebase-guide/ . To display the state of the repository I use a custom git log command that basically runs `git log --graph --decorate --oneline --abbrev-commit`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9650#issuecomment-1020120699
Usability,guid,guide,"Something went wrong, it looks like you merged the master branch into your feature branch. We need to have one (or more) commit of yours on top of the master branch, like this:. ![image](https://user-images.githubusercontent.com/10999034/150794127-6b77d3bf-9a8d-4d8e-b697-134e1c51c426.png). Instead the current situation is:. ![image](https://user-images.githubusercontent.com/10999034/150794245-1d6abf5e-2011-43fa-b598-8bb4a55c4f35.png). Usually I use `git rebase --interactive` from the command line to fix these kind of issues, see e.g. https://www.sitepoint.com/git-interactive-rebase-guide/ . To display the state of the repository I use a custom git log command that basically runs `git log --graph --decorate --oneline --abbrev-commit`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9650#issuecomment-1020120699
Usability,feedback,feedback,any further feedback on this one? (I think I am not changing code in any part),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9654#issuecomment-1074169606
Usability,learn,learned,What Cling is really crashing on is the definition of `art::ensurePointer` or more precisely any function definition with a `try`-`catch` block as body (which I just learned is valid C++...). The problem can be seen with; ```c++; .rawInput; void f() try { } catch (...) { }; ```; (on the ROOT prompt),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9664#issuecomment-1020964451
Usability,learn,learned,"> What Cling is really crashing on is the definition of `art::ensurePointer` or more precisely any function definition with a `try`-`catch` block as body (which I just learned is valid C++...). The problem can be seen with; > ; > ```c++; > .rawInput; > void f() try { } catch (...) { }; > ```; > ; > (on the ROOT prompt). Yeah, that's a common pitfall, where the assumption that the function's body is a CompoundStmt is incorrect. I suspect the fix is trivial?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9664#issuecomment-1021074174
Usability,simpl,simply,"Bertrand,; In my mind, after PR #9669 merged, one simply can remove build/win directory from includes at all - also inside ROOT.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9671#issuecomment-1019956657
Usability,simpl,simply,"> Bertrand, In my mind, after PR #9669 merged, one simply can remove build/win directory from includes at all - also inside ROOT. Nope, it doesn't work. It would require more changes...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9671#issuecomment-1019957172
Usability,undo,undocumented,"One trick would be to set: WARN_NO_PARAMDOC to YES in the Doxyfile, to find all undocumented params",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9673#issuecomment-1020020820
Usability,undo,undocumented,"@ferdymercury ; > One trick would be to set: WARN_NO_PARAMDOC to YES in the Doxyfile, to find all undocumented params. That was not the point. This fixes properly document the class members (sorry ""parameters"" was not the right word) with the `///<` tag.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9673#issuecomment-1020117649
Deployability,update,updated,"Hi @lmoneta, thanks for the review! You are right, it's not a sustainable solution to duplicate the interfaces if we want to accept `std::string` more generally in RooFit. I have updated the PR with a new intermediate class that can be used for the interfaces. The intermediate class, `RooStringView`, is simply a wrapper around `const char*` that can also be constructed from a `std::string`. Note that this is different from `std::string_view`, which is not null-terminated and therefore needs a copy when turned into a `const char*`, so we couldn't use that in RooFit interfaces without introducing superfluous copies.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9747#issuecomment-1024992856
Energy Efficiency,sustainab,sustainable,"Hi @lmoneta, thanks for the review! You are right, it's not a sustainable solution to duplicate the interfaces if we want to accept `std::string` more generally in RooFit. I have updated the PR with a new intermediate class that can be used for the interfaces. The intermediate class, `RooStringView`, is simply a wrapper around `const char*` that can also be constructed from a `std::string`. Note that this is different from `std::string_view`, which is not null-terminated and therefore needs a copy when turned into a `const char*`, so we couldn't use that in RooFit interfaces without introducing superfluous copies.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9747#issuecomment-1024992856
Integrability,interface,interfaces,"Hi @lmoneta, thanks for the review! You are right, it's not a sustainable solution to duplicate the interfaces if we want to accept `std::string` more generally in RooFit. I have updated the PR with a new intermediate class that can be used for the interfaces. The intermediate class, `RooStringView`, is simply a wrapper around `const char*` that can also be constructed from a `std::string`. Note that this is different from `std::string_view`, which is not null-terminated and therefore needs a copy when turned into a `const char*`, so we couldn't use that in RooFit interfaces without introducing superfluous copies.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9747#issuecomment-1024992856
Usability,simpl,simply,"Hi @lmoneta, thanks for the review! You are right, it's not a sustainable solution to duplicate the interfaces if we want to accept `std::string` more generally in RooFit. I have updated the PR with a new intermediate class that can be used for the interfaces. The intermediate class, `RooStringView`, is simply a wrapper around `const char*` that can also be constructed from a `std::string`. Note that this is different from `std::string_view`, which is not null-terminated and therefore needs a copy when turned into a `const char*`, so we couldn't use that in RooFit interfaces without introducing superfluous copies.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9747#issuecomment-1024992856
Deployability,configurat,configuration,"In any case the `zoombox` for 1D is managed in `TPad.cxx`. I de-activated the alpha mode on Mac to be in the same configuration as yourself. But even with your example I do not see any artefact. May be you can deactivate the zoombox in `TPad::ExecuteEventAxis` and see if the artefact remains ? By the way if you do a simple drawing of a 1D histogram and try to zoom it, do you also see the artefact ?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9763#issuecomment-1026698105
Modifiability,config,configuration,"In any case the `zoombox` for 1D is managed in `TPad.cxx`. I de-activated the alpha mode on Mac to be in the same configuration as yourself. But even with your example I do not see any artefact. May be you can deactivate the zoombox in `TPad::ExecuteEventAxis` and see if the artefact remains ? By the way if you do a simple drawing of a 1D histogram and try to zoom it, do you also see the artefact ?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9763#issuecomment-1026698105
Usability,simpl,simple,"In any case the `zoombox` for 1D is managed in `TPad.cxx`. I de-activated the alpha mode on Mac to be in the same configuration as yourself. But even with your example I do not see any artefact. May be you can deactivate the zoombox in `TPad::ExecuteEventAxis` and see if the artefact remains ? By the way if you do a simple drawing of a 1D histogram and try to zoom it, do you also see the artefact ?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9763#issuecomment-1026698105
Usability,simpl,simple,"Yes, I see it with a simple 1D histogram, too, no need for secondary axes. But... Ok I found out the issue. I do see the artifact only if I call:; `c->SetFillStyle(0);`",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9763#issuecomment-1026887078
Usability,simpl,simple,"A more simple reproducer here shows the same effect on Ubuntu 18:; ```; TCanvas* c = new TCanvas(); TH1* h = new TH1F(""h"",""h"",100,0,10); c->SetFillStyle(0); h->Draw(); ```. ![image](https://user-images.githubusercontent.com/10653970/151991662-805da339-fd11-4490-9d08-631526798254.png)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9763#issuecomment-1026929100
Deployability,release,release,"> May be you can deactivate the zoombox in `TPad::ExecuteEventAxis` and see if the artifact remains ?. If I deactivate the 'removal' of the zoombox after button release, I get this on Ubuntu 20:; ![image](https://user-images.githubusercontent.com/10653970/151999027-9261c038-1725-42d9-bb89-4aa43333c7fd.png). I can move around with the zoombox, make it smaller, etc. and the artifact is still there. Touching on the canvas does not clear the artifacts, which surprises me!. ![image](https://user-images.githubusercontent.com/10653970/151999166-f26ae15b-53d9-4b9e-a08d-fe6afa784214.png). Only if I right click on the box, ""Delete"", the artifacts go away. (without having to click on the canvas)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9763#issuecomment-1027002365
Usability,clear,clear,"> May be you can deactivate the zoombox in `TPad::ExecuteEventAxis` and see if the artifact remains ?. If I deactivate the 'removal' of the zoombox after button release, I get this on Ubuntu 20:; ![image](https://user-images.githubusercontent.com/10653970/151999027-9261c038-1725-42d9-bb89-4aa43333c7fd.png). I can move around with the zoombox, make it smaller, etc. and the artifact is still there. Touching on the canvas does not clear the artifacts, which surprises me!. ![image](https://user-images.githubusercontent.com/10653970/151999166-f26ae15b-53d9-4b9e-a08d-fe6afa784214.png). Only if I right click on the box, ""Delete"", the artifacts go away. (without having to click on the canvas)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9763#issuecomment-1027002365
Usability,simpl,simply,"I don't think the issue is with `copy_if_different` - I bet you'd see the same behavior if you were to use `copy` instead. My guess is that this is caused by CMake determining that the `DEPENDENCY` is older than the target, thus no need to run the command. What happens if you simply remove the DEPENDENCY, such that `copy_if_different` (which should *not* look at filestamps) is run unconditionally?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9804#issuecomment-1029077291
Usability,simpl,simply,> What happens if you simply remove the DEPENDENCY. Then rule executed only once when target file is not exists.; Any following changes in source will have no effect,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9804#issuecomment-1029083072
Usability,simpl,simple,We completely agree and the above PR implements what you propose. Apologies for the long wait for such a simple thing!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9805#issuecomment-1600982681
Testability,test,test,"Can you add this to a super simple test, just to make sure we compile this case?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9818#issuecomment-1031394700
Usability,simpl,simple,"Can you add this to a super simple test, just to make sure we compile this case?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9818#issuecomment-1031394700
Usability,simpl,simply,"I have not completely understood why it crashed but that 's not ""simply"" because of the Drawing option. For instance if you move the `pad` creation and the `pad` Draw just before the `pad->cd() ` then it does not crash.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9869#issuecomment-1036281020
Usability,simpl,simpler,"Indeed, nothing to do with TF2. An even simpler reproducer is:; ```; void w(); {; auto c1 = new TCanvas();; auto pad = new TPad(""p"",""p"", 0.5, 0 , 1., 1);; pad->Draw();. auto h0 = new TH2F(""h0"",""h0"", 10, 0.02, 15, 10, -8, 8);; h0->Draw();. // pad ->cd(); // uncomment this line an it will crash. auto h1 = new TH2F(""h1"",""h1"", 10, 0.01, 14, 10, -10, 10);; h1->Draw(""same"");; }; ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9869#issuecomment-1036292700
Usability,simpl,simple,I have no idea either yet .. but we should start from my latest simple reproducer.; It is much simpler than the initial example.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9869#issuecomment-1036303797
Usability,clear,cleared,"I found in TH1::Draw(), line 3096. gPad->Clear();. If ""same"" not specified as draw option, pad is cleared.; Mean TPad object will be deleted. Not a nice feature, one always should draw histogram with care.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9869#issuecomment-1036371552
Integrability,interface,interface,"> I might be missing something, but I think the C++ logic can be simplified by removing RTypeErasedMergeables: we should be able to just return a RMergeableVariations<T> (cast to RMergeableValueBase, from which it could inherit) from RVariedAction::GetMergeableValue. What do you think?. My understanding is as follows: `RVariedAction::GetMergeableValue`'s signature is `std::unique_ptr<RMergeableValueBase> GetMergeableValue() const` . Inside the implementation of this function, I have no typename `T` with which I could construct internally a `std::vector<std::unique_ptr<RDFDetail::RMergeableValue<T>>>`. Thus, I need a struct that holds a `std::vector<std::unique_ptr<RDFDetail::RMergeableValueBase>>` (keep in mind that any subclass of `RActionImpl` defined in `ActionHelpers.hxx` has a method `std::unique_ptr<RMergeableValueBase> GetMergeableValue() const`, so inside `RVariedAction`'s `GetMergeableValue` I don't have any information about the concrete mergeable value type).; I would also just return a `std::vector<std::unique_ptr<RDFDetail::RMergeableValueBase>>` directly from this method, but then I would break the pattern of passing around unique ptrs to `RMergeableValueBase` and I would need to change the interface just for `RVariedAction`",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9942#issuecomment-1061744458
Modifiability,inherit,inherit,"> I might be missing something, but I think the C++ logic can be simplified by removing RTypeErasedMergeables: we should be able to just return a RMergeableVariations<T> (cast to RMergeableValueBase, from which it could inherit) from RVariedAction::GetMergeableValue. What do you think?. My understanding is as follows: `RVariedAction::GetMergeableValue`'s signature is `std::unique_ptr<RMergeableValueBase> GetMergeableValue() const` . Inside the implementation of this function, I have no typename `T` with which I could construct internally a `std::vector<std::unique_ptr<RDFDetail::RMergeableValue<T>>>`. Thus, I need a struct that holds a `std::vector<std::unique_ptr<RDFDetail::RMergeableValueBase>>` (keep in mind that any subclass of `RActionImpl` defined in `ActionHelpers.hxx` has a method `std::unique_ptr<RMergeableValueBase> GetMergeableValue() const`, so inside `RVariedAction`'s `GetMergeableValue` I don't have any information about the concrete mergeable value type).; I would also just return a `std::vector<std::unique_ptr<RDFDetail::RMergeableValueBase>>` directly from this method, but then I would break the pattern of passing around unique ptrs to `RMergeableValueBase` and I would need to change the interface just for `RVariedAction`",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9942#issuecomment-1061744458
Testability,log,logic,"> I might be missing something, but I think the C++ logic can be simplified by removing RTypeErasedMergeables: we should be able to just return a RMergeableVariations<T> (cast to RMergeableValueBase, from which it could inherit) from RVariedAction::GetMergeableValue. What do you think?. My understanding is as follows: `RVariedAction::GetMergeableValue`'s signature is `std::unique_ptr<RMergeableValueBase> GetMergeableValue() const` . Inside the implementation of this function, I have no typename `T` with which I could construct internally a `std::vector<std::unique_ptr<RDFDetail::RMergeableValue<T>>>`. Thus, I need a struct that holds a `std::vector<std::unique_ptr<RDFDetail::RMergeableValueBase>>` (keep in mind that any subclass of `RActionImpl` defined in `ActionHelpers.hxx` has a method `std::unique_ptr<RMergeableValueBase> GetMergeableValue() const`, so inside `RVariedAction`'s `GetMergeableValue` I don't have any information about the concrete mergeable value type).; I would also just return a `std::vector<std::unique_ptr<RDFDetail::RMergeableValueBase>>` directly from this method, but then I would break the pattern of passing around unique ptrs to `RMergeableValueBase` and I would need to change the interface just for `RVariedAction`",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9942#issuecomment-1061744458
Usability,simpl,simplified,"> I might be missing something, but I think the C++ logic can be simplified by removing RTypeErasedMergeables: we should be able to just return a RMergeableVariations<T> (cast to RMergeableValueBase, from which it could inherit) from RVariedAction::GetMergeableValue. What do you think?. My understanding is as follows: `RVariedAction::GetMergeableValue`'s signature is `std::unique_ptr<RMergeableValueBase> GetMergeableValue() const` . Inside the implementation of this function, I have no typename `T` with which I could construct internally a `std::vector<std::unique_ptr<RDFDetail::RMergeableValue<T>>>`. Thus, I need a struct that holds a `std::vector<std::unique_ptr<RDFDetail::RMergeableValueBase>>` (keep in mind that any subclass of `RActionImpl` defined in `ActionHelpers.hxx` has a method `std::unique_ptr<RMergeableValueBase> GetMergeableValue() const`, so inside `RVariedAction`'s `GetMergeableValue` I don't have any information about the concrete mergeable value type).; I would also just return a `std::vector<std::unique_ptr<RDFDetail::RMergeableValueBase>>` directly from this method, but then I would break the pattern of passing around unique ptrs to `RMergeableValueBase` and I would need to change the interface just for `RVariedAction`",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9942#issuecomment-1061744458
Usability,clear,clear,"I see, then how about the following. It's basically a rename of `RTypeErasedMergeables` to `RMergeableVariationsBase` so that the usage as a type-erased version of `RMergeableVariations<T>` is clear, plus it removes the duplication of `fValues`, `fNames` data members and it adds a converting constructor that substitutes the ""manual"" conversion that we currently do in `GetMergeableValue(RResultMap<T>)`: . ```cpp; class RMergeableVariationsBase : public RMergeableValueBase {; vector<string> fNames;; vector<unique_ptr<RMergeableValueBase>> fValues;; public:; RMergeableVariationsBase(vector<string> &&names, vector<unique_ptr<RMergeableValueBase> &&values);; };. template <typename T>; class RMergeableVariations : public RMergeableVariationsBase {; public:; RMergeableVariations(RMergeableVariationsBase &&b) : RMergeableVariationsBase(std::move(b.fNames), std::move(b.fValues)) {}; };. std::unique_ptr<RMergeableValueBase> RVariedAction::GetMergeableValue() const; {; // ...; return std::make_unique<RMergeableVariationsBase>(std::move(keys), std::move(values));; }; ```. That is not more code than we have now, and it should enable a much simpler `GetMergeableValue`:. ```cpp; template <typename T>; std::unique_ptr<RMergeableVariations<T>> GetMergeableValue(ROOT::RDF::Experimental::RResultMap<T> &rmap); {; if (!rmap.fAction->HasRun()); rmap.fLoopManager->Run(); // Prevents from using `const` specifier in parameter. auto mergeable = rmap.fAction->GetMergeableValue();; return std::make_unique<RMergeableVariations<T>>(std::move(*mergeable));; }; ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9942#issuecomment-1061811239
Availability,alive,alive,"After discussion, we decided to go back to the original simpler design for this PR, which effectively accounts for the following usecase: user wants to open a file, write some stuff to it or read objects and get information from them, in an ""encapsulated"" environment, finally closing the file. The ROOT objects attached to the file will be `None`ified at the end of the context, but they can be detached with the `SetDirectory` method. The other use case imagined, where a user wants to `cd` into some file to get objects from it and then let those objects survive while returning to the previous directory, is addressed by #10167 . Notably, that behaviour will keep the file alive, so that also the special objects like TTree and RNTuple can properly survive the `with` context",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9947#issuecomment-1072702588
Usability,simpl,simpler,"After discussion, we decided to go back to the original simpler design for this PR, which effectively accounts for the following usecase: user wants to open a file, write some stuff to it or read objects and get information from them, in an ""encapsulated"" environment, finally closing the file. The ROOT objects attached to the file will be `None`ified at the end of the context, but they can be detached with the `SetDirectory` method. The other use case imagined, where a user wants to `cd` into some file to get objects from it and then let those objects survive while returning to the previous directory, is addressed by #10167 . Notably, that behaviour will keep the file alive, so that also the special objects like TTree and RNTuple can properly survive the `with` context",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9947#issuecomment-1072702588
Usability,simpl,simple,"Well, I do not think we can rely on a given bash version just to get a pid .; Can we not have a more simple standard way to get a such identifier ?; or may be we can just have a counter ?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9966#issuecomment-1081606634
Usability,simpl,simple,"> Can we not have a more simple standard way to get a such identifier ?. I commited a fix, would you mind giving it a try ?. Thanks! :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9966#issuecomment-1081646859
Testability,test,test,"BTW, why doing this test ? we have something working with all bash versions, simply use it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9966#issuecomment-1081920556
Usability,simpl,simply,"BTW, why doing this test ? we have something working with all bash versions, simply use it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9966#issuecomment-1081920556
Testability,test,test,"> BTW, why doing this test ? we have something working with all bash versions, simply use it. good point. I just changed it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9966#issuecomment-1081930311
Usability,simpl,simply,"> BTW, why doing this test ? we have something working with all bash versions, simply use it. good point. I just changed it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9966#issuecomment-1081930311
Usability,clear,clear,"> Side question. If you try opening the Cmakelists with QtCreator, does it run well, too?. Well, that QtCreator is still a bit weird to me. I opened the `CMakeLists.txt` file from `documentation/doxygen` but then it is not clear at all what to do . I prefer to concentrate on debugging the batch way which will be the one used at the end. Note: I get this:; <img width=""1217"" alt=""Screenshot 2022-03-30 at 10 47 14"" src=""https://user-images.githubusercontent.com/4697738/160791054-b9f80406-79fe-4389-a8fc-a2d7410254ba.png"">",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9966#issuecomment-1082799915
Usability,clear,clear,"> but then it is not clear at all what to do. - Click on ""Configure Project"".; - After that, you can override the default DOCU_INPUT or DOCU_THREADS, or DOXYGEN_EXECUTABLE, as you consider. (under Projects, Build settings).; - Finally click on the Build icon (hammer).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9966#issuecomment-1083459839
Usability,clear,clear,@lmoneta the reason why this is not merged is not clear to me: could you clarify?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9968#issuecomment-2076533633
Integrability,interface,interfaces,"> @lmoneta the reason why this is not merged is not clear to me: could you clarify?. Ah, now I remember!. This would be a backwards incompatible change, because it changes the meaning of. ```c++; TVectorD{5};; ```; Before, this created a vector with 5 zero elements. With this PR, it will create a vector with a single 5!. This is way too backwards incompatible to be merged. @hageboeck maybe came to the same conclusion, and for that reason decided to not continue working on this PR anymore. Making it work in a backwards compatible way is probably not worth the effort for a legacy pre-STL class like `TVector`. I would instead suggest to change the interfaces of for example TGraph so that they can take initializer lists directly without going over the `TVectorT`. We can also wait for C++26 [1], which will introduce a `std::span` constructor from initializer list. Then we also have the option to use `std::span` in the interfaces to cover this usecase without losing generality: a TVectorT can probably be converted to a `std::span` too. [1] https://en.cppreference.com/w/cpp/container/span/span",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9968#issuecomment-2076889507
Usability,clear,clear,"> @lmoneta the reason why this is not merged is not clear to me: could you clarify?. Ah, now I remember!. This would be a backwards incompatible change, because it changes the meaning of. ```c++; TVectorD{5};; ```; Before, this created a vector with 5 zero elements. With this PR, it will create a vector with a single 5!. This is way too backwards incompatible to be merged. @hageboeck maybe came to the same conclusion, and for that reason decided to not continue working on this PR anymore. Making it work in a backwards compatible way is probably not worth the effort for a legacy pre-STL class like `TVector`. I would instead suggest to change the interfaces of for example TGraph so that they can take initializer lists directly without going over the `TVectorT`. We can also wait for C++26 [1], which will introduce a `std::span` constructor from initializer list. Then we also have the option to use `std::span` in the interfaces to cover this usecase without losing generality: a TVectorT can probably be converted to a `std::span` too. [1] https://en.cppreference.com/w/cpp/container/span/span",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9968#issuecomment-2076889507
Usability,responsiv,responsive,"> `core/clib/res/mmprivate.h` is ours. I'm relatively sure this also comes from somewhere, judging by the occurrences that I found with a quick web search ;-). > Could you have that ""survive"" in this / a PR and propose the other one upstream?. I've opened https://github.com/civetweb/civetweb/pull/1056 to upstream the fix into `civetweb`. My plan would be to wait a few days, the maintainer seems to be very responsive. If we cannot get it in, I'll back out the other fix to get that merged.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9969#issuecomment-1050635411
Deployability,update,updated,"> > Could you have that ""survive"" in this / a PR and propose the other one upstream?; > ; > I've opened [civetweb/civetweb#1056](https://github.com/civetweb/civetweb/pull/1056) to upstream the fix into `civetweb`. My plan would be to wait a few days, the maintainer seems to be very responsive. If we cannot get it in, I'll back out the other fix to get that merged. Merged on Friday, I've updated the PR to move the `#include` where I put it for upstream.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9969#issuecomment-1054112351
Usability,responsiv,responsive,"> > Could you have that ""survive"" in this / a PR and propose the other one upstream?; > ; > I've opened [civetweb/civetweb#1056](https://github.com/civetweb/civetweb/pull/1056) to upstream the fix into `civetweb`. My plan would be to wait a few days, the maintainer seems to be very responsive. If we cannot get it in, I'll back out the other fix to get that merged. Merged on Friday, I've updated the PR to move the `#include` where I put it for upstream.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9969#issuecomment-1054112351
Usability,clear,clearly,"> Could some text be added to explain why the subtraction was needed and is no longer needed? (i.e. It was clearly intentional and the reason it was there may or may not be relevant anymore). The subtraction was never needed, this was a way to cast a pointer into an integer via a `ptrdiff_t`. I can elaborate on this, but I'm not sure this really adds value to archeological investigations that might ever come across this...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9969#issuecomment-1060995959
Safety,avoid,avoid,"Hi @guitargeek, yeah that does sound like a good idea. The reason why I kept the GetName() just as the class name for now is that I wanted to avoid building the full name as a char* to not have to deal with messy c-string concatenation in a very simple function.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10043#issuecomment-1058334840
Usability,simpl,simple,"Hi @guitargeek, yeah that does sound like a good idea. The reason why I kept the GetName() just as the class name for now is that I wanted to avoid building the full name as a char* to not have to deal with messy c-string concatenation in a very simple function.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10043#issuecomment-1058334840
Deployability,update,updated,"I see you updated the old user's guide changing `documentation/users-guide/Cling.md` . The this guide is not supposed to be updated. It is frozen. You should changed the ""Manual"" on the web of the reference guide (doxygen).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10055#issuecomment-1060729822
Usability,guid,guide,"I see you updated the old user's guide changing `documentation/users-guide/Cling.md` . The this guide is not supposed to be updated. It is frozen. You should changed the ""Manual"" on the web of the reference guide (doxygen).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10055#issuecomment-1060729822
Usability,feedback,feedback,Thanks for the feedback. Reverted now.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10055#issuecomment-1060733471
Usability,guid,guide,"I see you also modified the primer. This guide as now 3 version. The one in the ROOT repo, the one on the web site and the Jupyter Notebook one which has its own repo. I think the idea will be to keep only one ie the Jupyter NB one.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10055#issuecomment-1066504266
Usability,guid,guide,"But did you add the '?' before each command, as in the example ?. The guide says:; `Use ? to get help on all raw interpreter commands`",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10056#issuecomment-1060855729
Usability,guid,guide,But why does the guide tell you to put those question marks then?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10056#issuecomment-1060858993
Usability,clear,clear,Can you suggest a PR and an expert of that part of ROOT will examine it ? Several things you mentioned here do not work or are not clear to me.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10065#issuecomment-1067013995
Modifiability,variab,variables,"@eguiraud concerning .O1, should i change in MetaSema ; (not yet implemented) --> (implemented only for 0 and 1 ?) -->changed; And should I add (not yet implemented) to .undo or .U ? --> it seems to work for me. Also, I see that '.include' is implemented, but not documented. Should I add it? --> added; .stats and .fileEx are documented but not sure what they do.; What else from the CINT table above should be added that has been lost during the translation?; For example, .g still prints global variables, but .l does no longer print local variables.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10065#issuecomment-1067891493
Usability,undo,undo,"@eguiraud concerning .O1, should i change in MetaSema ; (not yet implemented) --> (implemented only for 0 and 1 ?) -->changed; And should I add (not yet implemented) to .undo or .U ? --> it seems to work for me. Also, I see that '.include' is implemented, but not documented. Should I add it? --> added; .stats and .fileEx are documented but not sure what they do.; What else from the CINT table above should be added that has been lost during the translation?; For example, .g still prints global variables, but .l does no longer print local variables.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10065#issuecomment-1067891493
Usability,clear,clear,"This looks pretty good. One potential drawback (or maybe it is 'documented away') is that we now have 'more' possibility of the git tag and its RVersion.hxx to be out-of-sync. . Another thing that is not clear is whether (or not) we are losing the recording of the git commit in the ROOT banner:; ```; ------------------------------------------------------------------; | Welcome to ROOT 6.27/01 https://root.cern |; | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |; | Built for macosx64 on Feb 03 2022, 23:36:26 |; | From heads/pairOffset@v6-25-02-395-g873cf57666 |; | With Apple clang version 12.0.0 (clang-1200.0.32.29) |; | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |; ------------------------------------------------------------------; ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10077#issuecomment-1062072980
Availability,error,errors,"@Axel-Naumann Many thanks for the detailed and friendly reply! :+1: . > Do you have a proposal for the latter? We can add a new boolean constructor argument, `failOnUnknownArgs = false` which we set to `true` in ROOT. Indeed, I believe the additional constructor argument is best. ; The only other solution which comes to mind (if it would not be possible to add a parameter) would be to (once more) use magic numbers for the `numOptions` parameter (similar to how `TApplication` ignores `argc` and `argv` if `numOptions==-1`), but that is certainly not a design pattern leading to modern, readable code, so better not spread it more ;-). ; `failOnUnknownArgs` sounds like a great choice of name, it clarifies the intent clearly. . > It would be wonderful to have that as unit test in `core/rint/test` [...]. It seems this does already exist, and has a unit test checking that errors are producted by `TRint` if unrecognitzed options are encountered ;-). Still, it seems I lack sufficient experience with `gtest`, since I don't understand why (for example) `TRint` with unsupported arguments does not `Terminate()` the test  so it's unclear to me how to write a test checking that it does not actually try to `Terminate()` when provided with a to-be-added `failOnUnknownArgs = false`. . In pseudo-steps, I think possible changes / additions to the existing test in `core/rint/test/TRintTests.cxx` to cover the use case as completely as possible could be:; 1. The existing test should be changed to set `failOnUnknownArgs = true` (after that is implemented). ; 2. A second test could be added, not setting `failOnUnknownArgs` (i.e. the default of `false` is used). This test then needs to check that no `stderr` is produced, and `Terminate()` is not called (here I'm unsure how to do these with `gtest`). ; 3. A third test could try to do the following, for complete coverage of the use case:; i. Create a `TRint (let's name it `myApp for simplicity here)`, passing in supported and unsupported option",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10090#issuecomment-1064634456
Integrability,inject,inject,"ter (similar to how `TApplication` ignores `argc` and `argv` if `numOptions==-1`), but that is certainly not a design pattern leading to modern, readable code, so better not spread it more ;-). ; `failOnUnknownArgs` sounds like a great choice of name, it clarifies the intent clearly. . > It would be wonderful to have that as unit test in `core/rint/test` [...]. It seems this does already exist, and has a unit test checking that errors are producted by `TRint` if unrecognitzed options are encountered ;-). Still, it seems I lack sufficient experience with `gtest`, since I don't understand why (for example) `TRint` with unsupported arguments does not `Terminate()` the test  so it's unclear to me how to write a test checking that it does not actually try to `Terminate()` when provided with a to-be-added `failOnUnknownArgs = false`. . In pseudo-steps, I think possible changes / additions to the existing test in `core/rint/test/TRintTests.cxx` to cover the use case as completely as possible could be:; 1. The existing test should be changed to set `failOnUnknownArgs = true` (after that is implemented). ; 2. A second test could be added, not setting `failOnUnknownArgs` (i.e. the default of `false` is used). This test then needs to check that no `stderr` is produced, and `Terminate()` is not called (here I'm unsure how to do these with `gtest`). ; 3. A third test could try to do the following, for complete coverage of the use case:; i. Create a `TRint (let's name it `myApp for simplicity here)`, passing in supported and unsupported options. ; ii. Check the unsupported options are accessible via `myApp->Argv()`. ; iii. Call `myApp`->Run(kTRUE)`, inject `.q` via `stdin` and test that the execution flow returns to after that line. . Does that sound reasonable? ; Since I am slightly at a loss on how to solve these ideas within `gtest`, I would be fine with going the back and forth approach (learning more `gtest` along the way so I can better contribute tests in the future) ;-).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10090#issuecomment-1064634456
Security,access,accessible,"ter (similar to how `TApplication` ignores `argc` and `argv` if `numOptions==-1`), but that is certainly not a design pattern leading to modern, readable code, so better not spread it more ;-). ; `failOnUnknownArgs` sounds like a great choice of name, it clarifies the intent clearly. . > It would be wonderful to have that as unit test in `core/rint/test` [...]. It seems this does already exist, and has a unit test checking that errors are producted by `TRint` if unrecognitzed options are encountered ;-). Still, it seems I lack sufficient experience with `gtest`, since I don't understand why (for example) `TRint` with unsupported arguments does not `Terminate()` the test  so it's unclear to me how to write a test checking that it does not actually try to `Terminate()` when provided with a to-be-added `failOnUnknownArgs = false`. . In pseudo-steps, I think possible changes / additions to the existing test in `core/rint/test/TRintTests.cxx` to cover the use case as completely as possible could be:; 1. The existing test should be changed to set `failOnUnknownArgs = true` (after that is implemented). ; 2. A second test could be added, not setting `failOnUnknownArgs` (i.e. the default of `false` is used). This test then needs to check that no `stderr` is produced, and `Terminate()` is not called (here I'm unsure how to do these with `gtest`). ; 3. A third test could try to do the following, for complete coverage of the use case:; i. Create a `TRint (let's name it `myApp for simplicity here)`, passing in supported and unsupported options. ; ii. Check the unsupported options are accessible via `myApp->Argv()`. ; iii. Call `myApp`->Run(kTRUE)`, inject `.q` via `stdin` and test that the execution flow returns to after that line. . Does that sound reasonable? ; Since I am slightly at a loss on how to solve these ideas within `gtest`, I would be fine with going the back and forth approach (learning more `gtest` along the way so I can better contribute tests in the future) ;-).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10090#issuecomment-1064634456
Testability,test,test,"@Axel-Naumann Many thanks for the detailed and friendly reply! :+1: . > Do you have a proposal for the latter? We can add a new boolean constructor argument, `failOnUnknownArgs = false` which we set to `true` in ROOT. Indeed, I believe the additional constructor argument is best. ; The only other solution which comes to mind (if it would not be possible to add a parameter) would be to (once more) use magic numbers for the `numOptions` parameter (similar to how `TApplication` ignores `argc` and `argv` if `numOptions==-1`), but that is certainly not a design pattern leading to modern, readable code, so better not spread it more ;-). ; `failOnUnknownArgs` sounds like a great choice of name, it clarifies the intent clearly. . > It would be wonderful to have that as unit test in `core/rint/test` [...]. It seems this does already exist, and has a unit test checking that errors are producted by `TRint` if unrecognitzed options are encountered ;-). Still, it seems I lack sufficient experience with `gtest`, since I don't understand why (for example) `TRint` with unsupported arguments does not `Terminate()` the test  so it's unclear to me how to write a test checking that it does not actually try to `Terminate()` when provided with a to-be-added `failOnUnknownArgs = false`. . In pseudo-steps, I think possible changes / additions to the existing test in `core/rint/test/TRintTests.cxx` to cover the use case as completely as possible could be:; 1. The existing test should be changed to set `failOnUnknownArgs = true` (after that is implemented). ; 2. A second test could be added, not setting `failOnUnknownArgs` (i.e. the default of `false` is used). This test then needs to check that no `stderr` is produced, and `Terminate()` is not called (here I'm unsure how to do these with `gtest`). ; 3. A third test could try to do the following, for complete coverage of the use case:; i. Create a `TRint (let's name it `myApp for simplicity here)`, passing in supported and unsupported option",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10090#issuecomment-1064634456
Usability,clear,clearly,"@Axel-Naumann Many thanks for the detailed and friendly reply! :+1: . > Do you have a proposal for the latter? We can add a new boolean constructor argument, `failOnUnknownArgs = false` which we set to `true` in ROOT. Indeed, I believe the additional constructor argument is best. ; The only other solution which comes to mind (if it would not be possible to add a parameter) would be to (once more) use magic numbers for the `numOptions` parameter (similar to how `TApplication` ignores `argc` and `argv` if `numOptions==-1`), but that is certainly not a design pattern leading to modern, readable code, so better not spread it more ;-). ; `failOnUnknownArgs` sounds like a great choice of name, it clarifies the intent clearly. . > It would be wonderful to have that as unit test in `core/rint/test` [...]. It seems this does already exist, and has a unit test checking that errors are producted by `TRint` if unrecognitzed options are encountered ;-). Still, it seems I lack sufficient experience with `gtest`, since I don't understand why (for example) `TRint` with unsupported arguments does not `Terminate()` the test  so it's unclear to me how to write a test checking that it does not actually try to `Terminate()` when provided with a to-be-added `failOnUnknownArgs = false`. . In pseudo-steps, I think possible changes / additions to the existing test in `core/rint/test/TRintTests.cxx` to cover the use case as completely as possible could be:; 1. The existing test should be changed to set `failOnUnknownArgs = true` (after that is implemented). ; 2. A second test could be added, not setting `failOnUnknownArgs` (i.e. the default of `false` is used). This test then needs to check that no `stderr` is produced, and `Terminate()` is not called (here I'm unsure how to do these with `gtest`). ; 3. A third test could try to do the following, for complete coverage of the use case:; i. Create a `TRint (let's name it `myApp for simplicity here)`, passing in supported and unsupported option",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10090#issuecomment-1064634456
Usability,simpl,simpler,"I believe the difference between `Filter` (not working) and `Define` (working) is the overload that is picked. For `Filter` it picks (`columns` is an `std::initializer_list< std::string >`):; https://root.cern/doc/master/classROOT_1_1RDF_1_1RInterface.html#a66c60dde810b86a97fc01d1f7310a1b2. whereas for `Define` it picks (`columns` is an `std::vector<std::string>`):; https://root.cern/doc/master/classROOT_1_1RDF_1_1RInterface.html#a4698601205a55ac49279150d56fc904f. If instead of passing a Python list to `Filter` we pass an `std::vector`, it works. A simpler reproducer is then:; ```python; import ROOT; ROOT.gInterpreter.Declare(""""""; void foo (const std::initializer_list< std::string > &columns) {}; """"""); ROOT.foo([""x""]); ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10092#issuecomment-1065158302
Testability,test,test,It is great you add the support for overlapping range in DataRange. ; Can you also please convert the test you have above in a simple Google test that can be added in math/mathcore/test ? ; You can just replace the assert with EXPECT_EQ.; A simple example to look is this test: ; https://github.com/root-project/root/blob/master/hist/hist/test/test_TH1.cxx. Thank you for this contribution!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10101#issuecomment-1080810665
Usability,simpl,simple,It is great you add the support for overlapping range in DataRange. ; Can you also please convert the test you have above in a simple Google test that can be added in math/mathcore/test ? ; You can just replace the assert with EXPECT_EQ.; A simple example to look is this test: ; https://github.com/root-project/root/blob/master/hist/hist/test/test_TH1.cxx. Thank you for this contribution!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10101#issuecomment-1080810665
Usability,clear,clear,"I still have to investigate if it is used in user code, but I would like to deprecate it at some point if we know if it's not used. Then it's also clear that we don't have to implement handling string values in the BatchMode.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10106#issuecomment-1066843499
Availability,down,downwards,"qqqqqqq : abort process; .which [file] : show path of macro file; .![OS_command] : execute OS-specific shell command; .!root -? : print ROOT usage (CLI options); ```. ```; root [1] .? edit. ROOT terminal keyboard shortcuts (GNU-readline style).; ==============================================================================; Arrow_Left : move cursor left [Ctrl+B]; Arrow_Right : move cursor right [Ctrl+F] [Ctrl+G]; Home : move cursor to beginning of line [Ctrl+A]; End : move cursor to end of line [Ctrl+E]; Ctrl+Arrow_Left : jump to previous word [Esc,B] [Alt,B]; Ctrl+Arrow_Right : jump to next word [Esc,F] [Alt,F]; Backspace : delete previous character [Ctrl+H]; Del : delete next character [Ctrl+D]; Esc,Backspace : delete previous word [Ctrl+W] [Esc,Ctrl+H] [Alt+Backspace] [Esc,Del] [Esc,Ctrl+Del]; Ctrl+Del : delete next word [Esc,D] [Alt,D]; Ctrl+U : cut all characters between cursor and start of line; Ctrl+K : cut all characters between cursor and end of line; Ctrl+T : transpose characters; Esc,C : character to upper and jump to next word; Esc,L : word to lower case and jump to its end; Esc,U : word to upper case and jump to its end; Ctrl+Shift+C : copy clipboard content; Ctrl+Shift+V : paste clipboard content [Ctrl+Y] [Alt+Y]; Ins : toggle overwrite mode; Ctrl+_ : undo last keypress action; Tab : autocomplete command or print suggestions [Ctrl+I] [Esc,Tab]; Enter : execute command [Ctrl+J] [Ctrl+M]; Ctrl+L : clear prompt screen; Ctrl+D : quit ROOT (if empty line); Ctrl+C : send kSigInt interrupt signal; Ctrl+Z : send kSigStop pause job signal; Arrow_Down : navigate downwards in command history [Ctrl+N]; Arrow_Up : navigate upwards in command history [Ctrl+P]; Ctrl+R ; Ctrl+S : search command in your history by typing a string.; Use Backspace if you mistyped (but not arrows).; Press Ctrl+R (Ctrl+S) repeateadly to navigate matches in reverse (forward) order; Arrow_Right : after Ctrl+R (Ctrl+S), select current match of the history search; [Ctrl+O] [Enter] [Ctrl+J] [Ctr",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10121#issuecomment-1084927674
Deployability,toggle,toggle,"qqqqqqq : abort process; .which [file] : show path of macro file; .![OS_command] : execute OS-specific shell command; .!root -? : print ROOT usage (CLI options); ```. ```; root [1] .? edit. ROOT terminal keyboard shortcuts (GNU-readline style).; ==============================================================================; Arrow_Left : move cursor left [Ctrl+B]; Arrow_Right : move cursor right [Ctrl+F] [Ctrl+G]; Home : move cursor to beginning of line [Ctrl+A]; End : move cursor to end of line [Ctrl+E]; Ctrl+Arrow_Left : jump to previous word [Esc,B] [Alt,B]; Ctrl+Arrow_Right : jump to next word [Esc,F] [Alt,F]; Backspace : delete previous character [Ctrl+H]; Del : delete next character [Ctrl+D]; Esc,Backspace : delete previous word [Ctrl+W] [Esc,Ctrl+H] [Alt+Backspace] [Esc,Del] [Esc,Ctrl+Del]; Ctrl+Del : delete next word [Esc,D] [Alt,D]; Ctrl+U : cut all characters between cursor and start of line; Ctrl+K : cut all characters between cursor and end of line; Ctrl+T : transpose characters; Esc,C : character to upper and jump to next word; Esc,L : word to lower case and jump to its end; Esc,U : word to upper case and jump to its end; Ctrl+Shift+C : copy clipboard content; Ctrl+Shift+V : paste clipboard content [Ctrl+Y] [Alt+Y]; Ins : toggle overwrite mode; Ctrl+_ : undo last keypress action; Tab : autocomplete command or print suggestions [Ctrl+I] [Esc,Tab]; Enter : execute command [Ctrl+J] [Ctrl+M]; Ctrl+L : clear prompt screen; Ctrl+D : quit ROOT (if empty line); Ctrl+C : send kSigInt interrupt signal; Ctrl+Z : send kSigStop pause job signal; Arrow_Down : navigate downwards in command history [Ctrl+N]; Arrow_Up : navigate upwards in command history [Ctrl+P]; Ctrl+R ; Ctrl+S : search command in your history by typing a string.; Use Backspace if you mistyped (but not arrows).; Press Ctrl+R (Ctrl+S) repeateadly to navigate matches in reverse (forward) order; Arrow_Right : after Ctrl+R (Ctrl+S), select current match of the history search; [Ctrl+O] [Enter] [Ctrl+J] [Ctr",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10121#issuecomment-1084927674
Integrability,wrap,wrapping,"- Shows all include paths. If a path is given,; 				 adds the path to the include paths. .O <level>			- Sets the optimization level (0-3); 				 If no level is given, prints the current setting. .class <name>		- Prints out class <name> in a CINT-like style (one-level).; 				 If no name is given, prints out list of all classes. .Class <name>			- Prints out class <name> in a CINT-like style (all-levels).; 				 If no name is given, prints out list of all classes. .namespace			- Prints list of all known namespaces. .typedef <name>		- Prints out typedef <name> in a CINT-like style; 				 If no name is given, prints out list of all typedefs. .files			- Prints names of all included (parsed) files. .fileEx			- Prints out included (parsed) file statistics; 				 as well as a list of their names. .g <var>				- Prints out information about global variable; 				 'var' - if no name is given, print them all. .@ 				- Cancels and ignores the multiline input. .rawInput [0|1]		- Toggle wrapping and printing the; 				 execution results of the input. .dynamicExtensions [0|1]	- Toggles the use of the dynamic scopes; 				 and the late binding. .debug <level>		- Generates debug symbols (level is optional, 0 to disable). .printDebug [0|1]		- Toggles the printing of input's corresponding; 				 state changes. .storeState <filename>	- Store the interpreter's state to a given file. .compareState <filename>	- Compare the interpreter's state with the one; 				 saved in a given file. .stats [name]		- Show stats for internal data structures; 				 'ast' abstract syntax tree stats; 				 'asttree [filter]' abstract syntax tree layout; 				 'decl' dump ast declarations; 				 'undo' show undo stack. .T <filePath> <comment>	- Generate autoload map. .trace <repr> <id>		- Dump trace of requested respresentation; 				 (see .stats arguments for <repr>). .help			- Shows this information (also .?). .q				- Exit the program. ROOT special commands.; ================================================================",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10121#issuecomment-1084927674
Modifiability,variab,variable,"r; '>>'			- Appends to the given file. .undo [n]			- Unloads the last 'n' inputs lines. .U <filename>		- Unloads the given file. .(I|include) [path]		- Shows all include paths. If a path is given,; 				 adds the path to the include paths. .O <level>			- Sets the optimization level (0-3); 				 If no level is given, prints the current setting. .class <name>		- Prints out class <name> in a CINT-like style (one-level).; 				 If no name is given, prints out list of all classes. .Class <name>			- Prints out class <name> in a CINT-like style (all-levels).; 				 If no name is given, prints out list of all classes. .namespace			- Prints list of all known namespaces. .typedef <name>		- Prints out typedef <name> in a CINT-like style; 				 If no name is given, prints out list of all typedefs. .files			- Prints names of all included (parsed) files. .fileEx			- Prints out included (parsed) file statistics; 				 as well as a list of their names. .g <var>				- Prints out information about global variable; 				 'var' - if no name is given, print them all. .@ 				- Cancels and ignores the multiline input. .rawInput [0|1]		- Toggle wrapping and printing the; 				 execution results of the input. .dynamicExtensions [0|1]	- Toggles the use of the dynamic scopes; 				 and the late binding. .debug <level>		- Generates debug symbols (level is optional, 0 to disable). .printDebug [0|1]		- Toggles the printing of input's corresponding; 				 state changes. .storeState <filename>	- Store the interpreter's state to a given file. .compareState <filename>	- Compare the interpreter's state with the one; 				 saved in a given file. .stats [name]		- Show stats for internal data structures; 				 'ast' abstract syntax tree stats; 				 'asttree [filter]' abstract syntax tree layout; 				 'decl' dump ast declarations; 				 'undo' show undo stack. .T <filePath> <comment>	- Generate autoload map. .trace <repr> <id>		- Dump trace of requested respresentation; 				 (see .stats arguments for <repr>). .help			",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10121#issuecomment-1084927674
Performance,optimiz,optimization,"Current screenshot:. ```; root [0] .?. Cling (C/C++ interpreter) meta commands usage; All commands must be preceded by a '.', except; for the evaluation statement { }; ==============================================================================================; Syntax: .Command [arg0 arg1 ... argN]. .Tab				- Autocomplete or print suggestions. .L <filename>		- Load the given file or library. .(x|X) <filename>(args)	- Same as .L and runs a function with; 				 signature: ret_type filename(args). .> <filename>		- Redirect command to a given file; '>' or '1>'		- Redirects the stdout stream only; '2>'			- Redirects the stderr stream only; '&>' (or '2>&1')		- Redirects both stdout and stderr; '>>'			- Appends to the given file. .undo [n]			- Unloads the last 'n' inputs lines. .U <filename>		- Unloads the given file. .(I|include) [path]		- Shows all include paths. If a path is given,; 				 adds the path to the include paths. .O <level>			- Sets the optimization level (0-3); 				 If no level is given, prints the current setting. .class <name>		- Prints out class <name> in a CINT-like style (one-level).; 				 If no name is given, prints out list of all classes. .Class <name>			- Prints out class <name> in a CINT-like style (all-levels).; 				 If no name is given, prints out list of all classes. .namespace			- Prints list of all known namespaces. .typedef <name>		- Prints out typedef <name> in a CINT-like style; 				 If no name is given, prints out list of all typedefs. .files			- Prints names of all included (parsed) files. .fileEx			- Prints out included (parsed) file statistics; 				 as well as a list of their names. .g <var>				- Prints out information about global variable; 				 'var' - if no name is given, print them all. .@ 				- Cancels and ignores the multiline input. .rawInput [0|1]		- Toggle wrapping and printing the; 				 execution results of the input. .dynamicExtensions [0|1]	- Toggles the use of the dynamic scopes; 				 and the late binding. .debug <level>		- ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10121#issuecomment-1084927674
Safety,abort,abort,"- Shows this information (also .?). .q				- Exit the program. ROOT special commands.; ===============================================================================; .L <filename>[flags]: load the given file with optional flags like; + to compile or ++ to force recompile.; Type .? TSystem::CompileMacro for a list of all flags.; .(x|X) <filename>[flags](args) :; same as .L <filename>[flags] and runs then a function; with signature: ret_type filename(args).; .credits : show credits; .demo : launch GUI demo; .help Class::Member : open reference guide for that class member (or .?).; Specifying '::Member' is optional.; .help edit : show line editing shortcuts (or .?); .license : show license; .ls : list contents of current TDirectory; .pwd : show current TDirectory, pad and style; .quit (or .exit) : quit ROOT (long form of .q); .R [user@]host[:dir] [-l user] [-d dbg] [script] :; launch process in a remote host; .qqq : quit ROOT - mandatory; .qqqqq : exit process immediately; .qqqqqqq : abort process; .which [file] : show path of macro file; .![OS_command] : execute OS-specific shell command; .!root -? : print ROOT usage (CLI options); ```. ```; root [1] .? edit. ROOT terminal keyboard shortcuts (GNU-readline style).; ==============================================================================; Arrow_Left : move cursor left [Ctrl+B]; Arrow_Right : move cursor right [Ctrl+F] [Ctrl+G]; Home : move cursor to beginning of line [Ctrl+A]; End : move cursor to end of line [Ctrl+E]; Ctrl+Arrow_Left : jump to previous word [Esc,B] [Alt,B]; Ctrl+Arrow_Right : jump to next word [Esc,F] [Alt,F]; Backspace : delete previous character [Ctrl+H]; Del : delete next character [Ctrl+D]; Esc,Backspace : delete previous word [Ctrl+W] [Esc,Ctrl+H] [Alt+Backspace] [Esc,Del] [Esc,Ctrl+Del]; Ctrl+Del : delete next word [Esc,D] [Alt,D]; Ctrl+U : cut all characters between cursor and start of line; Ctrl+K : cut all characters between cursor and end of line; Ctrl+T : transpose characters; Esc,C :",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10121#issuecomment-1084927674
Usability,undo,undo,"Current screenshot:. ```; root [0] .?. Cling (C/C++ interpreter) meta commands usage; All commands must be preceded by a '.', except; for the evaluation statement { }; ==============================================================================================; Syntax: .Command [arg0 arg1 ... argN]. .Tab				- Autocomplete or print suggestions. .L <filename>		- Load the given file or library. .(x|X) <filename>(args)	- Same as .L and runs a function with; 				 signature: ret_type filename(args). .> <filename>		- Redirect command to a given file; '>' or '1>'		- Redirects the stdout stream only; '2>'			- Redirects the stderr stream only; '&>' (or '2>&1')		- Redirects both stdout and stderr; '>>'			- Appends to the given file. .undo [n]			- Unloads the last 'n' inputs lines. .U <filename>		- Unloads the given file. .(I|include) [path]		- Shows all include paths. If a path is given,; 				 adds the path to the include paths. .O <level>			- Sets the optimization level (0-3); 				 If no level is given, prints the current setting. .class <name>		- Prints out class <name> in a CINT-like style (one-level).; 				 If no name is given, prints out list of all classes. .Class <name>			- Prints out class <name> in a CINT-like style (all-levels).; 				 If no name is given, prints out list of all classes. .namespace			- Prints list of all known namespaces. .typedef <name>		- Prints out typedef <name> in a CINT-like style; 				 If no name is given, prints out list of all typedefs. .files			- Prints names of all included (parsed) files. .fileEx			- Prints out included (parsed) file statistics; 				 as well as a list of their names. .g <var>				- Prints out information about global variable; 				 'var' - if no name is given, print them all. .@ 				- Cancels and ignores the multiline input. .rawInput [0|1]		- Toggle wrapping and printing the; 				 execution results of the input. .dynamicExtensions [0|1]	- Toggles the use of the dynamic scopes; 				 and the late binding. .debug <level>		- ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10121#issuecomment-1084927674
Usability,feedback,feedback,Thank you @petruccs for opening this issue and the feedback. You are right that one needs to use`GetPaintedGraph` for this. I will improve the documentation and add a tutorial example.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10139#issuecomment-1072149923
Availability,error,error,"This works now fine on 6.28/04, it no longer crashes. ```; root -l; root [0] int x; (int) 0; root [1] .undo; root [2] x; (int) 0; root [3] .undo; root [4] .undo; root [5] x; input_line_12:2:3: error: use of undeclared identifier 'x'; (x); ^; Error in <HandleInterpreterException>: Error evaluating expression (x); Execution of your code was aborted.; root [6] x; input_line_14:2:3: error: use of undeclared identifier 'x'; (x); ^; Error in <HandleInterpreterException>: Error evaluating expression (x); Execution of your code was aborted.; root [7] int x; (int) 0; root [8] int x; (int) 0; root [9] x; (int) 0; root [10] x; (int) 0; root [11] x; (int) 0; root [12] x; (int) 0; root [13] .undo; root [14] x; (int) 0; root [15] .undo 5; root [16] x; input_line_23:2:3: error: use of undeclared identifier 'x'; (x); ^; Error in <HandleInterpreterException>: Error evaluating expression (x); Execution of your code was aborted.; root [17] .q; ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10178#issuecomment-1812233608
Safety,abort,aborted,"This works now fine on 6.28/04, it no longer crashes. ```; root -l; root [0] int x; (int) 0; root [1] .undo; root [2] x; (int) 0; root [3] .undo; root [4] .undo; root [5] x; input_line_12:2:3: error: use of undeclared identifier 'x'; (x); ^; Error in <HandleInterpreterException>: Error evaluating expression (x); Execution of your code was aborted.; root [6] x; input_line_14:2:3: error: use of undeclared identifier 'x'; (x); ^; Error in <HandleInterpreterException>: Error evaluating expression (x); Execution of your code was aborted.; root [7] int x; (int) 0; root [8] int x; (int) 0; root [9] x; (int) 0; root [10] x; (int) 0; root [11] x; (int) 0; root [12] x; (int) 0; root [13] .undo; root [14] x; (int) 0; root [15] .undo 5; root [16] x; input_line_23:2:3: error: use of undeclared identifier 'x'; (x); ^; Error in <HandleInterpreterException>: Error evaluating expression (x); Execution of your code was aborted.; root [17] .q; ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10178#issuecomment-1812233608
Usability,undo,undo,"This works now fine on 6.28/04, it no longer crashes. ```; root -l; root [0] int x; (int) 0; root [1] .undo; root [2] x; (int) 0; root [3] .undo; root [4] .undo; root [5] x; input_line_12:2:3: error: use of undeclared identifier 'x'; (x); ^; Error in <HandleInterpreterException>: Error evaluating expression (x); Execution of your code was aborted.; root [6] x; input_line_14:2:3: error: use of undeclared identifier 'x'; (x); ^; Error in <HandleInterpreterException>: Error evaluating expression (x); Execution of your code was aborted.; root [7] int x; (int) 0; root [8] int x; (int) 0; root [9] x; (int) 0; root [10] x; (int) 0; root [11] x; (int) 0; root [12] x; (int) 0; root [13] .undo; root [14] x; (int) 0; root [15] .undo 5; root [16] x; input_line_23:2:3: error: use of undeclared identifier 'x'; (x); ^; Error in <HandleInterpreterException>: Error evaluating expression (x); Execution of your code was aborted.; root [17] .q; ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10178#issuecomment-1812233608
Usability,clear,clear,"Actually, I think that the correct behavior should be to clear the undo history after accepting a new input line (which also follows what GNU-readline does).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10182#issuecomment-1073909757
Integrability,interface,interface,"handling system events; (C++ compiled) struct SysInfo_t //System information - OS, CPU, RAM.; (C++ compiled) struct CpuInfo_t //CPU load information.; (C++ compiled) struct MemInfo_t //Memory utilization information.; (C++ compiled) class TVirtualPad public:TObject public:TAttLine public:TAttFill public:TAttPad public:TQObject //Abstract base class for Pads and Canvases; (C++ compiled) class TPMERegexp protected:TPRegexp //Wrapper for Perl-like regular expression matching.; (C++ compiled) class TStringToken public:TString //String tokenizer using PCRE for finding next tokens.; (C++ compiled) class TClassGenerator public:TObject //interface for TClass generators; (C++ compiled) class TROOT public:TDirectory //Top level (or root) structure for all classes; (C++ compiled) class TVirtualStreamerInfo public:TNamed //Abstract Interface describing Streamer information for one class; (C++ compiled) class TStreamerElement public:TNamed //Base class for one element (data member) to be Streamed; (C++ compiled) class TVirtualFFT public:TObject //abstract interface for FFT calculations; (C++ compiled) class TVirtualPadEditor //Abstract interface for graphics pad editor; (C++ compiled) class TMethodArg public:TDictionary //Dictionary for a method argument; (C++ compiled) class TToggle public:TNamed //Facility for toggling datamembers on/off; (C++ compiled) class TVirtualPadPainter //Painter interface for pad.; (C++ compiled) class TVirtualGLPainter //Interface for OpenGL painter; (C++ compiled) class TVirtualGLManip //Interface for GL manipulator; (C++ compiled) class TGLManager public:TNamed //Interface for OpenGL manager; (C++ compiled) class TGLPaintDevice //Base class for GL widgets and GL off-screen rendering; (C++ compiled) class TGuiFactory public:TNamed //Abstract factory for GUI components; (C++ compiled) class TAttBBox //Helper for management of bounding-box information; (C++ compiled) class TDictAttributeMap public:TObject //Container for name/value pairs of TDictionar",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10191#issuecomment-1084824531
Modifiability,plugin,plugin," sprintf(char *string,char *format,arglist,...);; int fscanf(FILE *fp,char *format,arglist,...);; int scanf(char *format,arglist,...);; int sscanf(char *string,char *format,arglist,...);; (C++ compiled) class TClass public:TDictionary //Dictionary containing class information; (C++ compiled) class TBuffer public:TObject //Buffer base class used for serializing objects; (C++ compiled) class TMemberInspector //ABC for inspecting class data members; (C++ compiled) class TNamed public:TObject //The basis for a named object (name, title); (C++ compiled) class TVirtualPerfStats public:TObject //ABC for collecting PROOF statistics; (C++ compiled) class THashList public:TList //Doubly linked list with hashtable for lookup; (C++ compiled) class TFileInfo public:TNamed //Describes generic file info including meta data information; (C++ compiled) class TVirtualMonitoringWriter public:TNamed //ABC for Sending Monitoring Information; (C++ compiled) class TVirtualMonitoringReader public:TNamed //ABC for Reading Monitoring Information; (C++ compiled) class TObjectSpy public:TObject //Spy object pointer for deletion; (C++ compiled) class TObjectRefSpy public:TObject //Spy object reference for deletion; (C++ compiled) class TMethod public:TFunction //Dictionary for a class member function (method); (C++ compiled) class TQObject //Base class for object communication mechanism; (C++ compiled) class TFunction public:TDictionary //Dictionary for global function; (C++ compiled) class TPluginManager public:TObject //Manager for plugin handlers; (C++ compiled) class TPluginHandler public:TObject //Handler for plugin libraries; (C++ compiled) class TTask public:TNamed //Base class for tasks; (C++ compiled) class TQCommand public:TList public:TQObject //encapsulates the information for undo/redo a single action.; (C++ compiled) class TQUndoManager public:TQCommand //recorder of operations for undo and redo; (C++ compiled) class TSysEvtHandler public:TObject public:TQObject //ABC for handling ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10191#issuecomment-1084824531
Performance,load,load,"etion; (C++ compiled) class TObjectRefSpy public:TObject //Spy object reference for deletion; (C++ compiled) class TMethod public:TFunction //Dictionary for a class member function (method); (C++ compiled) class TQObject //Base class for object communication mechanism; (C++ compiled) class TFunction public:TDictionary //Dictionary for global function; (C++ compiled) class TPluginManager public:TObject //Manager for plugin handlers; (C++ compiled) class TPluginHandler public:TObject //Handler for plugin libraries; (C++ compiled) class TTask public:TNamed //Base class for tasks; (C++ compiled) class TQCommand public:TList public:TQObject //encapsulates the information for undo/redo a single action.; (C++ compiled) class TQUndoManager public:TQCommand //recorder of operations for undo and redo; (C++ compiled) class TSysEvtHandler public:TObject public:TQObject //ABC for handling system events; (C++ compiled) struct SysInfo_t //System information - OS, CPU, RAM.; (C++ compiled) struct CpuInfo_t //CPU load information.; (C++ compiled) struct MemInfo_t //Memory utilization information.; (C++ compiled) class TVirtualPad public:TObject public:TAttLine public:TAttFill public:TAttPad public:TQObject //Abstract base class for Pads and Canvases; (C++ compiled) class TPMERegexp protected:TPRegexp //Wrapper for Perl-like regular expression matching.; (C++ compiled) class TStringToken public:TString //String tokenizer using PCRE for finding next tokens.; (C++ compiled) class TClassGenerator public:TObject //interface for TClass generators; (C++ compiled) class TROOT public:TDirectory //Top level (or root) structure for all classes; (C++ compiled) class TVirtualStreamerInfo public:TNamed //Abstract Interface describing Streamer information for one class; (C++ compiled) class TStreamerElement public:TNamed //Base class for one element (data member) to be Streamed; (C++ compiled) class TVirtualFFT public:TObject //abstract interface for FFT calculations; (C++ compiled) class TVirtualP",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10191#issuecomment-1084824531
Security,hash,hashtable," sprintf(char *string,char *format,arglist,...);; int fscanf(FILE *fp,char *format,arglist,...);; int scanf(char *format,arglist,...);; int sscanf(char *string,char *format,arglist,...);; (C++ compiled) class TClass public:TDictionary //Dictionary containing class information; (C++ compiled) class TBuffer public:TObject //Buffer base class used for serializing objects; (C++ compiled) class TMemberInspector //ABC for inspecting class data members; (C++ compiled) class TNamed public:TObject //The basis for a named object (name, title); (C++ compiled) class TVirtualPerfStats public:TObject //ABC for collecting PROOF statistics; (C++ compiled) class THashList public:TList //Doubly linked list with hashtable for lookup; (C++ compiled) class TFileInfo public:TNamed //Describes generic file info including meta data information; (C++ compiled) class TVirtualMonitoringWriter public:TNamed //ABC for Sending Monitoring Information; (C++ compiled) class TVirtualMonitoringReader public:TNamed //ABC for Reading Monitoring Information; (C++ compiled) class TObjectSpy public:TObject //Spy object pointer for deletion; (C++ compiled) class TObjectRefSpy public:TObject //Spy object reference for deletion; (C++ compiled) class TMethod public:TFunction //Dictionary for a class member function (method); (C++ compiled) class TQObject //Base class for object communication mechanism; (C++ compiled) class TFunction public:TDictionary //Dictionary for global function; (C++ compiled) class TPluginManager public:TObject //Manager for plugin handlers; (C++ compiled) class TPluginHandler public:TObject //Handler for plugin libraries; (C++ compiled) class TTask public:TNamed //Base class for tasks; (C++ compiled) class TQCommand public:TList public:TQObject //encapsulates the information for undo/redo a single action.; (C++ compiled) class TQUndoManager public:TQCommand //recorder of operations for undo and redo; (C++ compiled) class TSysEvtHandler public:TObject public:TQObject //ABC for handling ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10191#issuecomment-1084824531
Usability,undo,undo," sprintf(char *string,char *format,arglist,...);; int fscanf(FILE *fp,char *format,arglist,...);; int scanf(char *format,arglist,...);; int sscanf(char *string,char *format,arglist,...);; (C++ compiled) class TClass public:TDictionary //Dictionary containing class information; (C++ compiled) class TBuffer public:TObject //Buffer base class used for serializing objects; (C++ compiled) class TMemberInspector //ABC for inspecting class data members; (C++ compiled) class TNamed public:TObject //The basis for a named object (name, title); (C++ compiled) class TVirtualPerfStats public:TObject //ABC for collecting PROOF statistics; (C++ compiled) class THashList public:TList //Doubly linked list with hashtable for lookup; (C++ compiled) class TFileInfo public:TNamed //Describes generic file info including meta data information; (C++ compiled) class TVirtualMonitoringWriter public:TNamed //ABC for Sending Monitoring Information; (C++ compiled) class TVirtualMonitoringReader public:TNamed //ABC for Reading Monitoring Information; (C++ compiled) class TObjectSpy public:TObject //Spy object pointer for deletion; (C++ compiled) class TObjectRefSpy public:TObject //Spy object reference for deletion; (C++ compiled) class TMethod public:TFunction //Dictionary for a class member function (method); (C++ compiled) class TQObject //Base class for object communication mechanism; (C++ compiled) class TFunction public:TDictionary //Dictionary for global function; (C++ compiled) class TPluginManager public:TObject //Manager for plugin handlers; (C++ compiled) class TPluginHandler public:TObject //Handler for plugin libraries; (C++ compiled) class TTask public:TNamed //Base class for tasks; (C++ compiled) class TQCommand public:TList public:TQObject //encapsulates the information for undo/redo a single action.; (C++ compiled) class TQUndoManager public:TQCommand //recorder of operations for undo and redo; (C++ compiled) class TSysEvtHandler public:TObject public:TQObject //ABC for handling ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10191#issuecomment-1084824531
Performance,optimiz,optimizer,"We intentionally keep macros ""illegal C++"": we have a C++ interpreter and we should benefit from this, removing parts of C++ not needed for interactive use, *especially* for tutorials. We find this simplifies the tutorials. We have exceptions for tutorials where we believe many uses will be compiled. . Being able to compile the tutorials isn't a benefit in and by itself. This PR here came out of https://github.com/root-project/root/pull/10004 which claims ""Precompiles C++ script to potentially speedup (slightly) documentation building"". If that's indeed correct then that's a bug in cling. cling must be as fast as compiled code (if using the same optimizer, the same clang version as cling links against etc). So I'd like to better understand the motivation of this?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10195#issuecomment-1075129814
Usability,simpl,simplifies,"We intentionally keep macros ""illegal C++"": we have a C++ interpreter and we should benefit from this, removing parts of C++ not needed for interactive use, *especially* for tutorials. We find this simplifies the tutorials. We have exceptions for tutorials where we believe many uses will be compiled. . Being able to compile the tutorials isn't a benefit in and by itself. This PR here came out of https://github.com/root-project/root/pull/10004 which claims ""Precompiles C++ script to potentially speedup (slightly) documentation building"". If that's indeed correct then that's a bug in cling. cling must be as fast as compiled code (if using the same optimizer, the same clang version as cling links against etc). So I'd like to better understand the motivation of this?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10195#issuecomment-1075129814
Deployability,integrat,integration,"It seems deeper problems exists. In my study, I need to sample a 3D multi-variate gaussian distribution. For comparison, I set correlation to zero, so that I can simply sample three independent variables. The results using unuran and the one using three indepent variables are incompatible, even with above mentioned dirty fix. Currently I switch to alternative methods, yet it might be useful to understand what is the problem. I think some unit test and integration test should be implemented.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10222#issuecomment-1079823051
Integrability,integrat,integration,"It seems deeper problems exists. In my study, I need to sample a 3D multi-variate gaussian distribution. For comparison, I set correlation to zero, so that I can simply sample three independent variables. The results using unuran and the one using three indepent variables are incompatible, even with above mentioned dirty fix. Currently I switch to alternative methods, yet it might be useful to understand what is the problem. I think some unit test and integration test should be implemented.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10222#issuecomment-1079823051
Modifiability,variab,variables,"It seems deeper problems exists. In my study, I need to sample a 3D multi-variate gaussian distribution. For comparison, I set correlation to zero, so that I can simply sample three independent variables. The results using unuran and the one using three indepent variables are incompatible, even with above mentioned dirty fix. Currently I switch to alternative methods, yet it might be useful to understand what is the problem. I think some unit test and integration test should be implemented.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10222#issuecomment-1079823051
Testability,test,test,"It seems deeper problems exists. In my study, I need to sample a 3D multi-variate gaussian distribution. For comparison, I set correlation to zero, so that I can simply sample three independent variables. The results using unuran and the one using three indepent variables are incompatible, even with above mentioned dirty fix. Currently I switch to alternative methods, yet it might be useful to understand what is the problem. I think some unit test and integration test should be implemented.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10222#issuecomment-1079823051
Usability,simpl,simply,"It seems deeper problems exists. In my study, I need to sample a 3D multi-variate gaussian distribution. For comparison, I set correlation to zero, so that I can simply sample three independent variables. The results using unuran and the one using three indepent variables are incompatible, even with above mentioned dirty fix. Currently I switch to alternative methods, yet it might be useful to understand what is the problem. I think some unit test and integration test should be implemented.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10222#issuecomment-1079823051
Usability,feedback,feedback,"Hi @klenze ,; thank you for the feedback, I tend to agree, my only doubt is that these days we don't expect the vast majority of users to have to compile ROOT from source, that's something for developers and contributors, who might want to checkout the full repo anyway.; Why do grad students working on their laptops have to compile ROOT from source?. (with that said, I think we would accept a PR that changes the commands as you suggest. Or maybe we can just mention it in a comment. There is a button the bottom-right of each page on our website which opens a new tab where you can suggest changes)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10238#issuecomment-1080355066
Usability,simpl,simply,"It seems this is not working because the part after the `?` is interpreted as a query string. However, I'm not sure when the `?` should be treated as a wildcard and when it should be treated as a query starter. Should `?` only be treated as _not_ a wildcard if the part after contains `=` characters for query parameters or a `#` for a tree name? In addition, some files can have `?` as part of the file name: what do we do in this case? Should we simply not allow `?` for wild carding anymore? This needs to be discussed before making changes. @pcanal what do you think?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10239#issuecomment-1940943807
Usability,simpl,simple,"One simple but maybe effective way to address this is the following strategy:. * if the `?` is followed exactly by `.root` or it is the last character in the string, then it's a wildcard; * Otherwise, it's a query, the most common usage is to start the beginning of a token to introduce the treename inside the file i.e. `filename?#treename` . @pcanal what do you think?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10239#issuecomment-1958992264
Usability,clear,clear,"Yes, documentation is not there.; Many settings are not RBrowser specific, but applied for all web widgets: canvases, geometry viewer, eve7, browser, fit panel.; Major settings are mentioned here:; https://root.cern/doc/master/classROOT_1_1Experimental_1_1RWebWindowsManager.html ; See CreateServer and ShowWindow methods. Chrome and Firefox browser are required for batch mode.; For normal interactive mode any modern web browser should do the job.; But in fact, most of them are just modifications of chrome - beside firefox. ; To be clear - old `Internet Explorer` is not ""modern"" browser and therefore not supported.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10259#issuecomment-1090486006
Safety,safe,safety,"> > Please also add a line with a comment explaining why `make_unique` is not used in that case, so that nobody will accidentally change it back and re-introduce the issue.; > ; > That doesn't help at all, you can introduce this issue in any place you use these `static constexpr`. We have to _understand_ `constexpr` and not add comments in one place where the issue popped up. On top, I'd argue that `std::make_unique` was wrong here anyway since it's relying on a temporary object + move semantics instead of just setting the address of the already constructed `std::unique_ptr`. Ok then let's use the `constexpr` correctly here. So with what @jalopezg-r00t said, the correct fix is to also add the definition even if it looks strange? If you go for that, please also add a comment explaining why the line is necessary so it is not accidentally removed because it looks superfluous. As for the `make_unique`, I think it's correct to use it there. According to the core guidelines [1], it is always preferred because it ""gives a more concise statement of the construction. It also ensures exception safety in complex expressions"". And moving a unique pointer is cheap, temporary `unique_ptr` are not a problem. [1] https://isocpp.github.io/CppCoreGuidelines/CppCoreGuidelines#Rr-make_unique",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10263#issuecomment-1081652232
Usability,guid,guidelines,"> > Please also add a line with a comment explaining why `make_unique` is not used in that case, so that nobody will accidentally change it back and re-introduce the issue.; > ; > That doesn't help at all, you can introduce this issue in any place you use these `static constexpr`. We have to _understand_ `constexpr` and not add comments in one place where the issue popped up. On top, I'd argue that `std::make_unique` was wrong here anyway since it's relying on a temporary object + move semantics instead of just setting the address of the already constructed `std::unique_ptr`. Ok then let's use the `constexpr` correctly here. So with what @jalopezg-r00t said, the correct fix is to also add the definition even if it looks strange? If you go for that, please also add a comment explaining why the line is necessary so it is not accidentally removed because it looks superfluous. As for the `make_unique`, I think it's correct to use it there. According to the core guidelines [1], it is always preferred because it ""gives a more concise statement of the construction. It also ensures exception safety in complex expressions"". And moving a unique pointer is cheap, temporary `unique_ptr` are not a problem. [1] https://isocpp.github.io/CppCoreGuidelines/CppCoreGuidelines#Rr-make_unique",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10263#issuecomment-1081652232
Safety,safe,safety,"> As for the `make_unique`, I think it's correct to use it there. According to the core guidelines [1], it is always preferred because it ""gives a more concise statement of the construction. It also ensures exception safety in complex expressions"". And moving a unique pointer is cheap, temporary `unique_ptr` are not a problem. This guideline entry talks about construction, ie `auto q = make_unique<Foo>(7);`. Here we already have `weightVar` constructed and want to assign to it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10263#issuecomment-1081654215
Usability,guid,guidelines,"> As for the `make_unique`, I think it's correct to use it there. According to the core guidelines [1], it is always preferred because it ""gives a more concise statement of the construction. It also ensures exception safety in complex expressions"". And moving a unique pointer is cheap, temporary `unique_ptr` are not a problem. This guideline entry talks about construction, ie `auto q = make_unique<Foo>(7);`. Here we already have `weightVar` constructed and want to assign to it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10263#issuecomment-1081654215
Usability,feedback,feedback,"Yes, it is not supported up to now.; In #10344 I implement exactly this feature.; In the settings dialog one can specify flag ""Append to canvas"", which does exactly the same as ""same"" draw option. Thanks for providing useful feedback!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10265#issuecomment-1090470674
Usability,simpl,simpler,"I am unable to reproduce the working case (with 819b4e321b), so I am missing something (i.e. probably part of the ATLAS software). > If it would help to produce a simpler reproducer workspace, I'm glad to help out by trying to build one. Could you please? :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10282#issuecomment-1085399125
Testability,test,test,"Alright, I'm building a simpler reproducer then! Good to have one anyway for a unit test. Strange, at least getting a pointer to the workspace works for me also without the ATLAS RooFit extensions (indeed, the workspace contains some custom ATLAS classes)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10282#issuecomment-1085634160
Usability,simpl,simpler,"Alright, I'm building a simpler reproducer then! Good to have one anyway for a unit test. Strange, at least getting a pointer to the workspace works for me also without the ATLAS RooFit extensions (indeed, the workspace contains some custom ATLAS classes)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10282#issuecomment-1085634160
Testability,test,tests,"That is not quite surprising as the problem is likely to do with some type of schema evolution (particularly sensitive to this set of change are map/multimap where the key or value is an enum). In addition to having a simpler example, you could consider trying out https://github.com/root-project/root/pull/10230 which contains all the fixes I have been making (and is currently passing all but one of the tests I have/examples).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10282#issuecomment-1086030662
Usability,simpl,simpler,"That is not quite surprising as the problem is likely to do with some type of schema evolution (particularly sensitive to this set of change are map/multimap where the key or value is an enum). In addition to having a simpler example, you could consider trying out https://github.com/root-project/root/pull/10230 which contains all the fixes I have been making (and is currently passing all but one of the tests I have/examples).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10282#issuecomment-1086030662
Performance,optimiz,optimized,"ot produce a simpler reproducer, but I noticed that we have also problematic workspaces that are about 6 times smaller (from the same repo linked above):; ```; auto f = TFile::Open(""toyws/WS-HGam-STXS_xs_toy.root"");; auto w = (RooWorkspace*)f->Get(""combWS"");; ```. With this one, I can reproduce the problem without messing around with the stack size limit. Also, your PR #10230 actually affects also this issue, but it does not resolve it. There is now a different crash with a different stack trace, that looks like there is interference of your changes with some `RooWorkspace::Streamer` hackery:; ```; #0 0x000015555276f34c in __pthread_kill_implementation () from /usr/lib/libc.so.6; #1 0x00001555527224b8 in raise () from /usr/lib/libc.so.6; #2 0x000015555270c534 in abort () from /usr/lib/libc.so.6; #3 0x000015555299e7ee in __gnu_cxx::__verbose_terminate_handler () at /usr/src/debug/gcc/libstdc++-v3/libsupc++/vterminate.cc:95; #4 0x00001555529aac4c in __cxxabiv1::__terminate (handler=<optimized out>); at /usr/src/debug/gcc/libstdc++-v3/libsupc++/eh_terminate.cc:48; #5 0x00001555529aacb9 in std::terminate () at /usr/src/debug/gcc/libstdc++-v3/libsupc++/eh_terminate.cc:58; #6 0x00001555529aba77 in __cxxabiv1::__cxa_deleted_virtual () at /usr/src/debug/gcc/libstdc++-v3/libsupc++/pure.cc:57; #7 0x0000155553413509 in RooWorkspace::Streamer (this=0x55555698ea60, R__b=...); at /home/rembserj/spaces/master/root/src/root/roofit/roofitcore/src/RooWorkspace.cxx:2591; #8 0x0000155554e2df7e in TKey::ReadObj (this=0x555556757fc0) at /home/rembserj/spaces/master/root/src/root/io/io/src/TKey.cxx:834; #9 0x0000155554df25e0 in TDirectoryFile::Get (this=0x5555556e2510, namecycle=<optimized out>); at /home/rembserj/spaces/master/root/src/root/io/io/src/TDirectoryFile.cxx:975; #10 0x0000555555555235 in repro () at repro.C:25; #11 0x00005555555551d9 in main () at /tmp/root-compile/repro/main.cpp:4; ```. Fortunately, the stack trace is shorter now! Does this tell you anything? Maybe your insig",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10282#issuecomment-1087909663
Safety,abort,abort,"Hi @pcanal! I could not produce a simpler reproducer, but I noticed that we have also problematic workspaces that are about 6 times smaller (from the same repo linked above):; ```; auto f = TFile::Open(""toyws/WS-HGam-STXS_xs_toy.root"");; auto w = (RooWorkspace*)f->Get(""combWS"");; ```. With this one, I can reproduce the problem without messing around with the stack size limit. Also, your PR #10230 actually affects also this issue, but it does not resolve it. There is now a different crash with a different stack trace, that looks like there is interference of your changes with some `RooWorkspace::Streamer` hackery:; ```; #0 0x000015555276f34c in __pthread_kill_implementation () from /usr/lib/libc.so.6; #1 0x00001555527224b8 in raise () from /usr/lib/libc.so.6; #2 0x000015555270c534 in abort () from /usr/lib/libc.so.6; #3 0x000015555299e7ee in __gnu_cxx::__verbose_terminate_handler () at /usr/src/debug/gcc/libstdc++-v3/libsupc++/vterminate.cc:95; #4 0x00001555529aac4c in __cxxabiv1::__terminate (handler=<optimized out>); at /usr/src/debug/gcc/libstdc++-v3/libsupc++/eh_terminate.cc:48; #5 0x00001555529aacb9 in std::terminate () at /usr/src/debug/gcc/libstdc++-v3/libsupc++/eh_terminate.cc:58; #6 0x00001555529aba77 in __cxxabiv1::__cxa_deleted_virtual () at /usr/src/debug/gcc/libstdc++-v3/libsupc++/pure.cc:57; #7 0x0000155553413509 in RooWorkspace::Streamer (this=0x55555698ea60, R__b=...); at /home/rembserj/spaces/master/root/src/root/roofit/roofitcore/src/RooWorkspace.cxx:2591; #8 0x0000155554e2df7e in TKey::ReadObj (this=0x555556757fc0) at /home/rembserj/spaces/master/root/src/root/io/io/src/TKey.cxx:834; #9 0x0000155554df25e0 in TDirectoryFile::Get (this=0x5555556e2510, namecycle=<optimized out>); at /home/rembserj/spaces/master/root/src/root/io/io/src/TDirectoryFile.cxx:975; #10 0x0000555555555235 in repro () at repro.C:25; #11 0x00005555555551d9 in main () at /tmp/root-compile/repro/main.cpp:4; ```. Fortunately, the stack trace is shorter now! Does this tell you anyth",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10282#issuecomment-1087909663
Usability,simpl,simpler,"Hi @pcanal! I could not produce a simpler reproducer, but I noticed that we have also problematic workspaces that are about 6 times smaller (from the same repo linked above):; ```; auto f = TFile::Open(""toyws/WS-HGam-STXS_xs_toy.root"");; auto w = (RooWorkspace*)f->Get(""combWS"");; ```. With this one, I can reproduce the problem without messing around with the stack size limit. Also, your PR #10230 actually affects also this issue, but it does not resolve it. There is now a different crash with a different stack trace, that looks like there is interference of your changes with some `RooWorkspace::Streamer` hackery:; ```; #0 0x000015555276f34c in __pthread_kill_implementation () from /usr/lib/libc.so.6; #1 0x00001555527224b8 in raise () from /usr/lib/libc.so.6; #2 0x000015555270c534 in abort () from /usr/lib/libc.so.6; #3 0x000015555299e7ee in __gnu_cxx::__verbose_terminate_handler () at /usr/src/debug/gcc/libstdc++-v3/libsupc++/vterminate.cc:95; #4 0x00001555529aac4c in __cxxabiv1::__terminate (handler=<optimized out>); at /usr/src/debug/gcc/libstdc++-v3/libsupc++/eh_terminate.cc:48; #5 0x00001555529aacb9 in std::terminate () at /usr/src/debug/gcc/libstdc++-v3/libsupc++/eh_terminate.cc:58; #6 0x00001555529aba77 in __cxxabiv1::__cxa_deleted_virtual () at /usr/src/debug/gcc/libstdc++-v3/libsupc++/pure.cc:57; #7 0x0000155553413509 in RooWorkspace::Streamer (this=0x55555698ea60, R__b=...); at /home/rembserj/spaces/master/root/src/root/roofit/roofitcore/src/RooWorkspace.cxx:2591; #8 0x0000155554e2df7e in TKey::ReadObj (this=0x555556757fc0) at /home/rembserj/spaces/master/root/src/root/io/io/src/TKey.cxx:834; #9 0x0000155554df25e0 in TDirectoryFile::Get (this=0x5555556e2510, namecycle=<optimized out>); at /home/rembserj/spaces/master/root/src/root/io/io/src/TDirectoryFile.cxx:975; #10 0x0000555555555235 in repro () at repro.C:25; #11 0x00005555555551d9 in main () at /tmp/root-compile/repro/main.cpp:4; ```. Fortunately, the stack trace is shorter now! Does this tell you anyth",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10282#issuecomment-1087909663
Availability,failure,failures,"> Now there are new failures associated with this change. Can you point me to one or two of those failures?. > https://github.com/root-project/root/commit/45c0f48f3c3c631d291e0a7a32fd1ba292e79160 fixed a bug in the template argument printing,. For up-streaming that, it probably would need to become a policy switch. If I understand correctly. 45c0f48f3c3c631d291e0a7a32fd1ba292e79160 : remove suffix in template parameter (However the fix seems counter-intuitive, I am not sure what that code change really does). https://github.com/root-project/root/commit/4417a2cd34effdc6ea59797c2d86b6ef8ca8717a : add default template parameter to the printing. Is `SuppressDefaultTemplateArgs` a new option? If it is not, is it new that it was set to true by default? (we always needed the default parameter to be printed ... and actually in most case, we 'worked' at making sure that all the component are explicitly included (with the right spelling, i.e. for 'opaque' typedef), (see Utils/AST.cpp and the partial desugaring). So, so far, my best guess (because I don't understand 'what' it really does) is that 45c0f48f3c3c631d291e0a7a32fd1ba292e79160 has the side effect of destroying/replacing the partial desugaring. I would have expected the change to be much closer to part that generate the (partial) output for this kind of type/value and/or to be an extension in the partial desugaring routines. (As a side note, I have a vague memory that we already solved a similar problem in the past but can not find (yet?) the solution (if any) in the repository)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10294#issuecomment-1136396468
Integrability,rout,routines,"> Now there are new failures associated with this change. Can you point me to one or two of those failures?. > https://github.com/root-project/root/commit/45c0f48f3c3c631d291e0a7a32fd1ba292e79160 fixed a bug in the template argument printing,. For up-streaming that, it probably would need to become a policy switch. If I understand correctly. 45c0f48f3c3c631d291e0a7a32fd1ba292e79160 : remove suffix in template parameter (However the fix seems counter-intuitive, I am not sure what that code change really does). https://github.com/root-project/root/commit/4417a2cd34effdc6ea59797c2d86b6ef8ca8717a : add default template parameter to the printing. Is `SuppressDefaultTemplateArgs` a new option? If it is not, is it new that it was set to true by default? (we always needed the default parameter to be printed ... and actually in most case, we 'worked' at making sure that all the component are explicitly included (with the right spelling, i.e. for 'opaque' typedef), (see Utils/AST.cpp and the partial desugaring). So, so far, my best guess (because I don't understand 'what' it really does) is that 45c0f48f3c3c631d291e0a7a32fd1ba292e79160 has the side effect of destroying/replacing the partial desugaring. I would have expected the change to be much closer to part that generate the (partial) output for this kind of type/value and/or to be an extension in the partial desugaring routines. (As a side note, I have a vague memory that we already solved a similar problem in the past but can not find (yet?) the solution (if any) in the repository)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10294#issuecomment-1136396468
Usability,intuit,intuitive,"> Now there are new failures associated with this change. Can you point me to one or two of those failures?. > https://github.com/root-project/root/commit/45c0f48f3c3c631d291e0a7a32fd1ba292e79160 fixed a bug in the template argument printing,. For up-streaming that, it probably would need to become a policy switch. If I understand correctly. 45c0f48f3c3c631d291e0a7a32fd1ba292e79160 : remove suffix in template parameter (However the fix seems counter-intuitive, I am not sure what that code change really does). https://github.com/root-project/root/commit/4417a2cd34effdc6ea59797c2d86b6ef8ca8717a : add default template parameter to the printing. Is `SuppressDefaultTemplateArgs` a new option? If it is not, is it new that it was set to true by default? (we always needed the default parameter to be printed ... and actually in most case, we 'worked' at making sure that all the component are explicitly included (with the right spelling, i.e. for 'opaque' typedef), (see Utils/AST.cpp and the partial desugaring). So, so far, my best guess (because I don't understand 'what' it really does) is that 45c0f48f3c3c631d291e0a7a32fd1ba292e79160 has the side effect of destroying/replacing the partial desugaring. I would have expected the change to be much closer to part that generate the (partial) output for this kind of type/value and/or to be an extension in the partial desugaring routines. (As a side note, I have a vague memory that we already solved a similar problem in the past but can not find (yet?) the solution (if any) in the repository)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10294#issuecomment-1136396468
Availability,failure,failures,"> > Now there are new failures associated with this change; > ; > Can you point me to one or two of those failures?; > ; > > [45c0f48](https://github.com/root-project/root/commit/45c0f48f3c3c631d291e0a7a32fd1ba292e79160) fixed a bug in the template argument printing,; > ; > For up-streaming that, it probably would need to become a policy switch.; > ; > If I understand correctly; > ; > [45c0f48](https://github.com/root-project/root/commit/45c0f48f3c3c631d291e0a7a32fd1ba292e79160) : remove suffix in template parameter (However the fix seems counter-intuitive, I am not sure what that code change really does). It is a long discussion, you can find more information [here](https://reviews.llvm.org/D77598#inline-1057607). The idea is when we print the values of integral types, we should print them as they were written. Here is an example where this does not happen https://godbolt.org/z/MGK5s734G so this patch should be easy to upstream. > ; > [4417a2c](https://github.com/root-project/root/commit/4417a2cd34effdc6ea59797c2d86b6ef8ca8717a) : add default template parameter to the printing. Is `SuppressDefaultTemplateArgs` a new option? If it is not, is it new that it was set to true by default? (we always needed the default parameter to be printed ... and actually in most case, we 'worked' at making sure that all the component are explicitly included (with the right spelling, i.e. for 'opaque' typedef), (see Utils/AST.cpp and the partial desugaring). That was my take as well but without this switch we get failures like this one https://github.com/root-project/root/pull/10294#issuecomment-1135181954. Here are more details from my local builds:. <details>. ```. diff -u ../root-release-master/./math/genvector/G__GenVector.cxx ../root-release-llvm13/./math/genvector/G__GenVector.cxx; --- ../root-release-master/./math/genvector/G__GenVector.cxx	2022-05-08 08:38:55.942037418 +0300; +++ ../root-release-llvm13/./math/genvector/G__GenVector.cxx	2022-05-08 09:17:42.965205197 +0300; @@ -2",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10294#issuecomment-1136423157
Deployability,patch,patch,"> > Now there are new failures associated with this change; > ; > Can you point me to one or two of those failures?; > ; > > [45c0f48](https://github.com/root-project/root/commit/45c0f48f3c3c631d291e0a7a32fd1ba292e79160) fixed a bug in the template argument printing,; > ; > For up-streaming that, it probably would need to become a policy switch.; > ; > If I understand correctly; > ; > [45c0f48](https://github.com/root-project/root/commit/45c0f48f3c3c631d291e0a7a32fd1ba292e79160) : remove suffix in template parameter (However the fix seems counter-intuitive, I am not sure what that code change really does). It is a long discussion, you can find more information [here](https://reviews.llvm.org/D77598#inline-1057607). The idea is when we print the values of integral types, we should print them as they were written. Here is an example where this does not happen https://godbolt.org/z/MGK5s734G so this patch should be easy to upstream. > ; > [4417a2c](https://github.com/root-project/root/commit/4417a2cd34effdc6ea59797c2d86b6ef8ca8717a) : add default template parameter to the printing. Is `SuppressDefaultTemplateArgs` a new option? If it is not, is it new that it was set to true by default? (we always needed the default parameter to be printed ... and actually in most case, we 'worked' at making sure that all the component are explicitly included (with the right spelling, i.e. for 'opaque' typedef), (see Utils/AST.cpp and the partial desugaring). That was my take as well but without this switch we get failures like this one https://github.com/root-project/root/pull/10294#issuecomment-1135181954. Here are more details from my local builds:. <details>. ```. diff -u ../root-release-master/./math/genvector/G__GenVector.cxx ../root-release-llvm13/./math/genvector/G__GenVector.cxx; --- ../root-release-master/./math/genvector/G__GenVector.cxx	2022-05-08 08:38:55.942037418 +0300; +++ ../root-release-llvm13/./math/genvector/G__GenVector.cxx	2022-05-08 09:17:42.965205197 +0300; @@ -2",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10294#issuecomment-1136423157
Integrability,rout,routines,"d: CMakeFiles/G__GenVector.dir/G__GenVector.cxx.o: previous definition here; /usr/local/bin/ld: error: CMakeFiles/G__GenVector32.dir/G__GenVector32.cxx.o: multiple definition of 'ROOT::GenerateInitInstance(ROOT::Math::LorentzVector<ROOT::Math::PxPyPzM4D<double> > const*)'; /usr/local/bin/ld: CMakeFiles/G__GenVector.dir/G__GenVector.cxx.o: previous definition here; /usr/local/bin/ld: error: CMakeFiles/G__GenVector32.dir/G__GenVector32.cxx.o: multiple definition of 'ROOT::GenerateInitInstance(ROOT::Math::PxPyPzE4D<double> const*)'; /usr/local/bin/ld: CMakeFiles/G__GenVector.dir/G__GenVector.cxx.o: previous definition here; /usr/local/bin/ld: error: CMakeFiles/G__GenVector32.dir/G__GenVector32.cxx.o: multiple definition of 'ROOT::GenerateInitInstance(ROOT::Math::PxPyPzM4D<double> const*)'; /usr/local/bin/ld: CMakeFiles/G__GenVector.dir/G__GenVector.cxx.o: previous definition here; collect2: error: ld returned 1 exit status; math/genvector/CMakeFiles/GenVector.dir/build.make:363: recipe for target 'lib/libGenVector.so' failed; make[2]: *** [lib/libGenVector.so] Error 1; CMakeFiles/Makefile2:41978: recipe for target 'math/genvector/CMakeFiles/GenVector.dir/all' failed; make[1]: *** [math/genvector/CMakeFiles/GenVector.dir/all] Error 2; Makefile:165: recipe for target 'all' failed; ```. </details>. > So, so far, my best guess (because I don't understand 'what' it really does) is that [45c0f48](https://github.com/root-project/root/commit/45c0f48f3c3c631d291e0a7a32fd1ba292e79160) has the side effect of destroying/replacing the partial desugaring.; > ; > I would have expected the change to be much closer to part that generate the (partial) output for this kind of type/value and/or to be an extension in the partial desugaring routines.; > ; > (As a side note, I have a vague memory that we already solved a similar problem in the past but can not find (yet?) the solution (if any) in the repository). I do not see how that is affecting the desugaring but I have not debugged this.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10294#issuecomment-1136423157
Modifiability,variab,variable,"athcLcLLorentzVectorlEROOTcLcLMathcLcLPxPyPzE4DlEDouble32_tgRsPgR);; -; - ::ROOT::Internal::TSchemaHelper* rule;; -; - // the io read rules; - std::vector<::ROOT::Internal::TSchemaHelper> readrules(3);; - rule = &readrules[0];; - rule->fSourceClass = ""ROOT::Math::LorentzVector<ROOT::Math::PxPyPzE4D<double> >"";; - rule->fTarget = """";; - rule->fVersion = ""[1-]"";; - rule = &readrules[1];; - rule->fSourceClass = ""ROOT::Math::LorentzVector<ROOT::Math::PxPyPzE4D<float> >"";; - rule->fTarget = """";; - rule->fVersion = ""[1-]"";; - rule = &readrules[2];; - rule->fSourceClass = ""ROOT::Math::LorentzVector<ROOT::Math::PxPyPzE4D<Float16_t> >"";; - rule->fTarget = """";; - rule->fVersion = ""[1-]"";; - instance.SetReadRules( readrules );; return &instance;; }; // Static variable to force the class initialization; @@ -1654,8 +1634,6 @@; static void deleteArray_ROOTcLcLMathcLcLLorentzVectorlEROOTcLcLMathcLcLPxPyPzM4DlEDouble32_tgRsPgR(void *p);; static void destruct_ROOTcLcLMathcLcLLorentzVectorlEROOTcLcLMathcLcLPxPyPzM4DlEDouble32_tgRsPgR(void *p);; ; - // Schema evolution read functions; -; // Function generating the singleton type initializer; static TGenericClassInfo *GenerateInitInstanceLocal(const ::ROOT::Math::LorentzVector<ROOT::Math::PxPyPzM4D<Double32_t> >*); {; @@ -1671,24 +1649,6 @@; instance.SetDelete(&delete_ROOTcLcLMathcLcLLorentzVectorlEROOTcLcLMathcLcLPxPyPzM4DlEDouble32_tgRsPgR);; instance.SetDeleteArray(&deleteArray_ROOTcLcLMathcLcLLorentzVectorlEROOTcLcLMathcLcLPxPyPzM4DlEDouble32_tgRsPgR);; instance.SetDestructor(&destruct_ROOTcLcLMathcLcLLorentzVectorlEROOTcLcLMathcLcLPxPyPzM4DlEDouble32_tgRsPgR);; -; - ::ROOT::Internal::TSchemaHelper* rule;; -; - // the io read rules; - std::vector<::ROOT::Internal::TSchemaHelper> readrules(3);; - rule = &readrules[0];; - rule->fSourceClass = ""ROOT::Math::LorentzVector<ROOT::Math::PxPyPzM4D<double> >"";; - rule->fTarget = """";; - rule->fVersion = ""[1-]"";; - rule = &readrules[1];; - rule->fSourceClass = ""ROOT::Math::LorentzVector<ROOT::M",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10294#issuecomment-1136423157
Usability,intuit,intuitive,"> > Now there are new failures associated with this change; > ; > Can you point me to one or two of those failures?; > ; > > [45c0f48](https://github.com/root-project/root/commit/45c0f48f3c3c631d291e0a7a32fd1ba292e79160) fixed a bug in the template argument printing,; > ; > For up-streaming that, it probably would need to become a policy switch.; > ; > If I understand correctly; > ; > [45c0f48](https://github.com/root-project/root/commit/45c0f48f3c3c631d291e0a7a32fd1ba292e79160) : remove suffix in template parameter (However the fix seems counter-intuitive, I am not sure what that code change really does). It is a long discussion, you can find more information [here](https://reviews.llvm.org/D77598#inline-1057607). The idea is when we print the values of integral types, we should print them as they were written. Here is an example where this does not happen https://godbolt.org/z/MGK5s734G so this patch should be easy to upstream. > ; > [4417a2c](https://github.com/root-project/root/commit/4417a2cd34effdc6ea59797c2d86b6ef8ca8717a) : add default template parameter to the printing. Is `SuppressDefaultTemplateArgs` a new option? If it is not, is it new that it was set to true by default? (we always needed the default parameter to be printed ... and actually in most case, we 'worked' at making sure that all the component are explicitly included (with the right spelling, i.e. for 'opaque' typedef), (see Utils/AST.cpp and the partial desugaring). That was my take as well but without this switch we get failures like this one https://github.com/root-project/root/pull/10294#issuecomment-1135181954. Here are more details from my local builds:. <details>. ```. diff -u ../root-release-master/./math/genvector/G__GenVector.cxx ../root-release-llvm13/./math/genvector/G__GenVector.cxx; --- ../root-release-master/./math/genvector/G__GenVector.cxx	2022-05-08 08:38:55.942037418 +0300; +++ ../root-release-llvm13/./math/genvector/G__GenVector.cxx	2022-05-08 09:17:42.965205197 +0300; @@ -2",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10294#issuecomment-1136423157
Usability,simpl,simpler,"In the end, the reason is much simpler: my fix for the dictionary build is simply too narrow. In fixing `GetNormalizedName` but not, for example, the `PrintingPolicy` in `GetPartiallyDesugaredNameWithScopeHandling`, ROOT internally disagrees on normalized class names and therefore doesn't find the IO rules stored in a `map` with the class name as key. Should be fixed with the next push.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10294#issuecomment-1137026344
Usability,simpl,simpler,"> In the end, the reason is much simpler: my fix for the dictionary build is simply too narrow. . Great :) Just for kicks, can you verify that the following trivial example works as expected:. ```; root [0] template <typename T, typename Q=const T> struct Example {};; root [1] TClass::GetClass(""Example<Double32_t>"")->GetName(); (const char *) ""Example<Double32_t,const Double32_t>""; root [2] TClass::GetClass(""Example<Double32_t,Float16_t>"")->GetName(); (const char *) ""Example<Double32_t,Float16_t>""; ```. Thanks,; Philippe. eg. Copy/paste this on the ROOT prompt:. ```; template <typename T, typename Q=const T> struct Example {};; TClass::GetClass(""Example<Double32_t>"")->GetName(); TClass::GetClass(""Example<Double32_t,Float16_t>"")->GetName(); ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10294#issuecomment-1137193958
Integrability,interface,interface, - [projectroot.roottest.cling.template.roottest_cling_template_runtemplatefriend](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146424/testReport/projectroot.roottest.cling/template/roottest_cling_template_runtemplatefriend/); - [projectroot.roottest.python.cpp.roottest_python_cpp_advanced](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146424/testReport/projectroot.roottest.python/cpp/roottest_python_cpp_advanced/); - [projectroot.roottest.root.aclic.load.roottest_root_aclic_load_reload](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146424/testReport/projectroot.roottest.root.aclic/load/roottest_root_aclic_load_reload/); - [projectroot.roottest.root.aclic.misc.roottest_root_aclic_misc_assertROOT7027](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146424/testReport/projectroot.roottest.root.aclic/misc/roottest_root_aclic_misc_assertROOT7027/); - [projectroot.roottest.root.io.interface.roottest_root_io_interface_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146424/testReport/projectroot.roottest.root.io/interface/roottest_root_io_interface_make/); - [projectroot.roottest.root.meta.callfunc.roottest_root_meta_callfunc_assertUnload_auto](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146424/testReport/projectroot.roottest.root.meta/callfunc/roottest_root_meta_callfunc_assertUnload_auto/); - [projectroot.roottest.root.meta.cmsUnload.roottest_root_meta_cmsUnload_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146424/testReport/projectroot.roottest.root.meta/cmsUnload/roottest_root_meta_cmsUnload_make/); - [projectroot.roottest.root.selector.simple.roottest_root_selector_simple_runtestLoadingSelector](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146424/testReport/projectroot.roottest.root.selector/simple/roottest_root_selector_simple_runtestLoadingSel,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10294#issuecomment-1143358479
Performance,load,load,quests-build/146424/console).; ### Failing tests:; - [projectroot.test.test_stressinterpreter](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146424/testReport/projectroot/test/test_stressinterpreter/); - [projectroot.roottest.cling.other.roottest_cling_other_checkMissingSymbolExitCode](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146424/testReport/projectroot.roottest.cling/other/roottest_cling_other_checkMissingSymbolExitCode/); - [projectroot.roottest.cling.template.roottest_cling_template_runtemplatefriend](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146424/testReport/projectroot.roottest.cling/template/roottest_cling_template_runtemplatefriend/); - [projectroot.roottest.python.cpp.roottest_python_cpp_advanced](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146424/testReport/projectroot.roottest.python/cpp/roottest_python_cpp_advanced/); - [projectroot.roottest.root.aclic.load.roottest_root_aclic_load_reload](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146424/testReport/projectroot.roottest.root.aclic/load/roottest_root_aclic_load_reload/); - [projectroot.roottest.root.aclic.misc.roottest_root_aclic_misc_assertROOT7027](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146424/testReport/projectroot.roottest.root.aclic/misc/roottest_root_aclic_misc_assertROOT7027/); - [projectroot.roottest.root.io.interface.roottest_root_io_interface_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146424/testReport/projectroot.roottest.root.io/interface/roottest_root_io_interface_make/); - [projectroot.roottest.root.meta.callfunc.roottest_root_meta_callfunc_assertUnload_auto](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146424/testReport/projectroot.roottest.root.meta/callfunc/roottest_root_meta_callfunc_assertUnload_auto/); - [projectroot.roottest.root.meta.cmsUnl,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10294#issuecomment-1143358479
Testability,test,tests,Build failed on ROOT-ubuntu16/nortcxxmod.; Running on sft-ubuntu-1604-2.cern.ch:/build/workspace/root-pullrequests-build; [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146424/console).; ### Failing tests:; - [projectroot.test.test_stressinterpreter](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146424/testReport/projectroot/test/test_stressinterpreter/); - [projectroot.roottest.cling.other.roottest_cling_other_checkMissingSymbolExitCode](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146424/testReport/projectroot.roottest.cling/other/roottest_cling_other_checkMissingSymbolExitCode/); - [projectroot.roottest.cling.template.roottest_cling_template_runtemplatefriend](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146424/testReport/projectroot.roottest.cling/template/roottest_cling_template_runtemplatefriend/); - [projectroot.roottest.python.cpp.roottest_python_cpp_advanced](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146424/testReport/projectroot.roottest.python/cpp/roottest_python_cpp_advanced/); - [projectroot.roottest.root.aclic.load.roottest_root_aclic_load_reload](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146424/testReport/projectroot.roottest.root.aclic/load/roottest_root_aclic_load_reload/); - [projectroot.roottest.root.aclic.misc.roottest_root_aclic_misc_assertROOT7027](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146424/testReport/projectroot.roottest.root.aclic/misc/roottest_root_aclic_misc_assertROOT7027/); - [projectroot.roottest.root.io.interface.roottest_root_io_interface_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146424/testReport/projectroot.roottest.root.io/interface/roottest_root_io_interface_make/); - [projectroot.roottest.root.meta.callfunc.roottest_root_meta_callfunc_assertUnload_auto](https://lcgapp-se,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10294#issuecomment-1143358479
Usability,simpl,simple,jectroot.roottest.cling.template.roottest_cling_template_runtemplatefriend](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146424/testReport/projectroot.roottest.cling/template/roottest_cling_template_runtemplatefriend/); - [projectroot.roottest.python.cpp.roottest_python_cpp_advanced](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146424/testReport/projectroot.roottest.python/cpp/roottest_python_cpp_advanced/); - [projectroot.roottest.root.aclic.load.roottest_root_aclic_load_reload](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146424/testReport/projectroot.roottest.root.aclic/load/roottest_root_aclic_load_reload/); - [projectroot.roottest.root.aclic.misc.roottest_root_aclic_misc_assertROOT7027](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146424/testReport/projectroot.roottest.root.aclic/misc/roottest_root_aclic_misc_assertROOT7027/); - [projectroot.roottest.root.io.interface.roottest_root_io_interface_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146424/testReport/projectroot.roottest.root.io/interface/roottest_root_io_interface_make/); - [projectroot.roottest.root.meta.callfunc.roottest_root_meta_callfunc_assertUnload_auto](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146424/testReport/projectroot.roottest.root.meta/callfunc/roottest_root_meta_callfunc_assertUnload_auto/); - [projectroot.roottest.root.meta.cmsUnload.roottest_root_meta_cmsUnload_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146424/testReport/projectroot.roottest.root.meta/cmsUnload/roottest_root_meta_cmsUnload_make/); - [projectroot.roottest.root.selector.simple.roottest_root_selector_simple_runtestLoadingSelector](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146424/testReport/projectroot.roottest.root.selector/simple/roottest_root_selector_simple_runtestLoadingSelector/),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10294#issuecomment-1143358479
Integrability,interface,interface, - [projectroot.roottest.cling.template.roottest_cling_template_runtemplatefriend](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146495/testReport/projectroot.roottest.cling/template/roottest_cling_template_runtemplatefriend/); - [projectroot.roottest.python.cpp.roottest_python_cpp_advanced](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146495/testReport/projectroot.roottest.python/cpp/roottest_python_cpp_advanced/); - [projectroot.roottest.root.aclic.load.roottest_root_aclic_load_reload](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146495/testReport/projectroot.roottest.root.aclic/load/roottest_root_aclic_load_reload/); - [projectroot.roottest.root.aclic.misc.roottest_root_aclic_misc_assertROOT7027](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146495/testReport/projectroot.roottest.root.aclic/misc/roottest_root_aclic_misc_assertROOT7027/); - [projectroot.roottest.root.io.interface.roottest_root_io_interface_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146495/testReport/projectroot.roottest.root.io/interface/roottest_root_io_interface_make/); - [projectroot.roottest.root.meta.callfunc.roottest_root_meta_callfunc_assertUnload_auto](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146495/testReport/projectroot.roottest.root.meta/callfunc/roottest_root_meta_callfunc_assertUnload_auto/); - [projectroot.roottest.root.meta.cmsUnload.roottest_root_meta_cmsUnload_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146495/testReport/projectroot.roottest.root.meta/cmsUnload/roottest_root_meta_cmsUnload_make/); - [projectroot.roottest.root.selector.simple.roottest_root_selector_simple_runtestLoadingSelector](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146495/testReport/projectroot.roottest.root.selector/simple/roottest_root_selector_simple_runtestLoadingSel,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10294#issuecomment-1143554468
Performance,load,load,quests-build/146495/console).; ### Failing tests:; - [projectroot.test.test_stressinterpreter](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146495/testReport/projectroot/test/test_stressinterpreter/); - [projectroot.roottest.cling.other.roottest_cling_other_checkMissingSymbolExitCode](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146495/testReport/projectroot.roottest.cling/other/roottest_cling_other_checkMissingSymbolExitCode/); - [projectroot.roottest.cling.template.roottest_cling_template_runtemplatefriend](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146495/testReport/projectroot.roottest.cling/template/roottest_cling_template_runtemplatefriend/); - [projectroot.roottest.python.cpp.roottest_python_cpp_advanced](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146495/testReport/projectroot.roottest.python/cpp/roottest_python_cpp_advanced/); - [projectroot.roottest.root.aclic.load.roottest_root_aclic_load_reload](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146495/testReport/projectroot.roottest.root.aclic/load/roottest_root_aclic_load_reload/); - [projectroot.roottest.root.aclic.misc.roottest_root_aclic_misc_assertROOT7027](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146495/testReport/projectroot.roottest.root.aclic/misc/roottest_root_aclic_misc_assertROOT7027/); - [projectroot.roottest.root.io.interface.roottest_root_io_interface_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146495/testReport/projectroot.roottest.root.io/interface/roottest_root_io_interface_make/); - [projectroot.roottest.root.meta.callfunc.roottest_root_meta_callfunc_assertUnload_auto](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146495/testReport/projectroot.roottest.root.meta/callfunc/roottest_root_meta_callfunc_assertUnload_auto/); - [projectroot.roottest.root.meta.cmsUnl,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10294#issuecomment-1143554468
Testability,test,tests,Build failed on ROOT-ubuntu16/nortcxxmod.; Running on sft-ubuntu-1604-2.cern.ch:/build/workspace/root-pullrequests-build; [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146495/console).; ### Failing tests:; - [projectroot.test.test_stressinterpreter](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146495/testReport/projectroot/test/test_stressinterpreter/); - [projectroot.roottest.cling.other.roottest_cling_other_checkMissingSymbolExitCode](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146495/testReport/projectroot.roottest.cling/other/roottest_cling_other_checkMissingSymbolExitCode/); - [projectroot.roottest.cling.template.roottest_cling_template_runtemplatefriend](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146495/testReport/projectroot.roottest.cling/template/roottest_cling_template_runtemplatefriend/); - [projectroot.roottest.python.cpp.roottest_python_cpp_advanced](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146495/testReport/projectroot.roottest.python/cpp/roottest_python_cpp_advanced/); - [projectroot.roottest.root.aclic.load.roottest_root_aclic_load_reload](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146495/testReport/projectroot.roottest.root.aclic/load/roottest_root_aclic_load_reload/); - [projectroot.roottest.root.aclic.misc.roottest_root_aclic_misc_assertROOT7027](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146495/testReport/projectroot.roottest.root.aclic/misc/roottest_root_aclic_misc_assertROOT7027/); - [projectroot.roottest.root.io.interface.roottest_root_io_interface_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146495/testReport/projectroot.roottest.root.io/interface/roottest_root_io_interface_make/); - [projectroot.roottest.root.meta.callfunc.roottest_root_meta_callfunc_assertUnload_auto](https://lcgapp-se,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10294#issuecomment-1143554468
Usability,simpl,simple,ttest.cling.template.roottest_cling_template_runtemplatefriend](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146495/testReport/projectroot.roottest.cling/template/roottest_cling_template_runtemplatefriend/); - [projectroot.roottest.python.cpp.roottest_python_cpp_advanced](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146495/testReport/projectroot.roottest.python/cpp/roottest_python_cpp_advanced/); - [projectroot.roottest.root.aclic.load.roottest_root_aclic_load_reload](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146495/testReport/projectroot.roottest.root.aclic/load/roottest_root_aclic_load_reload/); - [projectroot.roottest.root.aclic.misc.roottest_root_aclic_misc_assertROOT7027](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146495/testReport/projectroot.roottest.root.aclic/misc/roottest_root_aclic_misc_assertROOT7027/); - [projectroot.roottest.root.io.interface.roottest_root_io_interface_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146495/testReport/projectroot.roottest.root.io/interface/roottest_root_io_interface_make/); - [projectroot.roottest.root.meta.callfunc.roottest_root_meta_callfunc_assertUnload_auto](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146495/testReport/projectroot.roottest.root.meta/callfunc/roottest_root_meta_callfunc_assertUnload_auto/); - [projectroot.roottest.root.meta.cmsUnload.roottest_root_meta_cmsUnload_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146495/testReport/projectroot.roottest.root.meta/cmsUnload/roottest_root_meta_cmsUnload_make/); - [projectroot.roottest.root.selector.simple.roottest_root_selector_simple_runtestLoadingSelector](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146495/testReport/projectroot.roottest.root.selector/simple/roottest_root_selector_simple_runtestLoadingSelector/). And 1 more,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10294#issuecomment-1143554468
Integrability,interface,interface,est.cling.template.roottest_cling_template_runtemplatefriend](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146659/testReport/projectroot.roottest.cling/template/roottest_cling_template_runtemplatefriend/); - [projectroot.roottest.root.aclic.misc.roottest_root_aclic_misc_assertROOT7027](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146659/testReport/projectroot.roottest.root.aclic/misc/roottest_root_aclic_misc_assertROOT7027/); - [projectroot.roottest.root.aclic.load.roottest_root_aclic_load_reload](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146659/testReport/projectroot.roottest.root.aclic/load/roottest_root_aclic_load_reload/); - [projectroot.roottest.root.dataframe.roottest_root_dataframe_missingBranches](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146659/testReport/projectroot.roottest.root/dataframe/roottest_root_dataframe_missingBranches/); - [projectroot.roottest.python.cpp.roottest_python_cpp_advanced](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146659/testReport/projectroot.roottest.python/cpp/roottest_python_cpp_advanced/); - [projectroot.roottest.root.io.interface.roottest_root_io_interface_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146659/testReport/projectroot.roottest.root.io/interface/roottest_root_io_interface_make/); - [projectroot.roottest.root.meta.callfunc.roottest_root_meta_callfunc_assertUnload_auto](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146659/testReport/projectroot.roottest.root.meta/callfunc/roottest_root_meta_callfunc_assertUnload_auto/); - [projectroot.roottest.root.selector.simple.roottest_root_selector_simple_runtestLoadingSelector](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146659/testReport/projectroot.roottest.root.selector/simple/roottest_root_selector_simple_runtestLoadingSelector/). And 5 more,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10294#issuecomment-1144980019
Performance,perform,performance-,Build failed on ROOT-performance-centos8-multicore/default.; Running on olbdw-01.cern.ch:/data/sftnight/workspace/root-pullrequests-build; [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146659/console).; ### Warnings:; - [2022-06-02T14:49:09.186Z] Warning in &lt;CheckModuleValid&gt;: warning: Couldn't find in the following specified headers in the module Core: ; - [2022-06-02T14:49:29.255Z] Warning in &lt;CheckModuleValid&gt;: warning: Couldn't find in the following specified headers in the module Thread: . ### Failing tests:; - [projectroot.test.test_stressinterpreter](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146659/testReport/projectroot/test/test_stressinterpreter/); - [projectroot.roottest.cling.other.roottest_cling_other_checkMissingSymbolExitCode](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146659/testReport/projectroot.roottest.cling/other/roottest_cling_other_checkMissingSymbolExitCode/); - [projectroot.roottest.cling.template.roottest_cling_template_runtemplatefriend](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146659/testReport/projectroot.roottest.cling/template/roottest_cling_template_runtemplatefriend/); - [projectroot.roottest.root.aclic.misc.roottest_root_aclic_misc_assertROOT7027](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146659/testReport/projectroot.roottest.root.aclic/misc/roottest_root_aclic_misc_assertROOT7027/); - [projectroot.roottest.root.aclic.load.roottest_root_aclic_load_reload](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146659/testReport/projectroot.roottest.root.aclic/load/roottest_root_aclic_load_reload/); - [projectroot.roottest.root.dataframe.roottest_root_dataframe_missingBranches](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146659/testReport/projectroot.roottest.root/dataframe/roottest_root_dataframe_missingBra,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10294#issuecomment-1144980019
Testability,test,tests,Build failed on ROOT-performance-centos8-multicore/default.; Running on olbdw-01.cern.ch:/data/sftnight/workspace/root-pullrequests-build; [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146659/console).; ### Warnings:; - [2022-06-02T14:49:09.186Z] Warning in &lt;CheckModuleValid&gt;: warning: Couldn't find in the following specified headers in the module Core: ; - [2022-06-02T14:49:29.255Z] Warning in &lt;CheckModuleValid&gt;: warning: Couldn't find in the following specified headers in the module Thread: . ### Failing tests:; - [projectroot.test.test_stressinterpreter](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146659/testReport/projectroot/test/test_stressinterpreter/); - [projectroot.roottest.cling.other.roottest_cling_other_checkMissingSymbolExitCode](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146659/testReport/projectroot.roottest.cling/other/roottest_cling_other_checkMissingSymbolExitCode/); - [projectroot.roottest.cling.template.roottest_cling_template_runtemplatefriend](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146659/testReport/projectroot.roottest.cling/template/roottest_cling_template_runtemplatefriend/); - [projectroot.roottest.root.aclic.misc.roottest_root_aclic_misc_assertROOT7027](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146659/testReport/projectroot.roottest.root.aclic/misc/roottest_root_aclic_misc_assertROOT7027/); - [projectroot.roottest.root.aclic.load.roottest_root_aclic_load_reload](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146659/testReport/projectroot.roottest.root.aclic/load/roottest_root_aclic_load_reload/); - [projectroot.roottest.root.dataframe.roottest_root_dataframe_missingBranches](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146659/testReport/projectroot.roottest.root/dataframe/roottest_root_dataframe_missingBra,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10294#issuecomment-1144980019
Usability,simpl,simple,est.cling.template.roottest_cling_template_runtemplatefriend](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146659/testReport/projectroot.roottest.cling/template/roottest_cling_template_runtemplatefriend/); - [projectroot.roottest.root.aclic.misc.roottest_root_aclic_misc_assertROOT7027](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146659/testReport/projectroot.roottest.root.aclic/misc/roottest_root_aclic_misc_assertROOT7027/); - [projectroot.roottest.root.aclic.load.roottest_root_aclic_load_reload](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146659/testReport/projectroot.roottest.root.aclic/load/roottest_root_aclic_load_reload/); - [projectroot.roottest.root.dataframe.roottest_root_dataframe_missingBranches](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146659/testReport/projectroot.roottest.root/dataframe/roottest_root_dataframe_missingBranches/); - [projectroot.roottest.python.cpp.roottest_python_cpp_advanced](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146659/testReport/projectroot.roottest.python/cpp/roottest_python_cpp_advanced/); - [projectroot.roottest.root.io.interface.roottest_root_io_interface_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146659/testReport/projectroot.roottest.root.io/interface/roottest_root_io_interface_make/); - [projectroot.roottest.root.meta.callfunc.roottest_root_meta_callfunc_assertUnload_auto](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146659/testReport/projectroot.roottest.root.meta/callfunc/roottest_root_meta_callfunc_assertUnload_auto/); - [projectroot.roottest.root.selector.simple.roottest_root_selector_simple_runtestLoadingSelector](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146659/testReport/projectroot.roottest.root.selector/simple/roottest_root_selector_simple_runtestLoadingSelector/). And 5 more,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10294#issuecomment-1144980019
Integrability,interface,interface,ojectroot.roottest.cling.other.roottest_cling_other_checkMissingSymbolExitCode](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146660/testReport/projectroot.roottest.cling/other/roottest_cling_other_checkMissingSymbolExitCode/); - [projectroot.roottest.python.cpp.roottest_python_cpp_advanced](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146660/testReport/projectroot.roottest.python/cpp/roottest_python_cpp_advanced/); - [projectroot.roottest.root.aclic.load.roottest_root_aclic_load_reload](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146660/testReport/projectroot.roottest.root.aclic/load/roottest_root_aclic_load_reload/); - [projectroot.roottest.root.aclic.misc.roottest_root_aclic_misc_assertROOT7027](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146660/testReport/projectroot.roottest.root.aclic/misc/roottest_root_aclic_misc_assertROOT7027/); - [projectroot.roottest.root.io.interface.roottest_root_io_interface_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146660/testReport/projectroot.roottest.root.io/interface/roottest_root_io_interface_make/); - [projectroot.roottest.root.meta.callfunc.roottest_root_meta_callfunc_assertUnload_auto](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146660/testReport/projectroot.roottest.root.meta/callfunc/roottest_root_meta_callfunc_assertUnload_auto/); - [projectroot.roottest.root.meta.cmsUnload.roottest_root_meta_cmsUnload_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146660/testReport/projectroot.roottest.root.meta/cmsUnload/roottest_root_meta_cmsUnload_make/); - [projectroot.roottest.cling.template.roottest_cling_template_runtemplatefriend](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146660/testReport/projectroot.roottest.cling/template/roottest_cling_template_runtemplatefriend/); - [projectroot.roottest.r,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10294#issuecomment-1144990827
Performance,load,load,Build failed on ROOT-ubuntu16/nortcxxmod.; Running on sft-ubuntu-1604-1.cern.ch:/build/workspace/root-pullrequests-build; [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146660/console).; ### Failing tests:; - [projectroot.test.test_stressinterpreter](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146660/testReport/projectroot/test/test_stressinterpreter/); - [projectroot.roottest.cling.other.roottest_cling_other_checkMissingSymbolExitCode](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146660/testReport/projectroot.roottest.cling/other/roottest_cling_other_checkMissingSymbolExitCode/); - [projectroot.roottest.python.cpp.roottest_python_cpp_advanced](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146660/testReport/projectroot.roottest.python/cpp/roottest_python_cpp_advanced/); - [projectroot.roottest.root.aclic.load.roottest_root_aclic_load_reload](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146660/testReport/projectroot.roottest.root.aclic/load/roottest_root_aclic_load_reload/); - [projectroot.roottest.root.aclic.misc.roottest_root_aclic_misc_assertROOT7027](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146660/testReport/projectroot.roottest.root.aclic/misc/roottest_root_aclic_misc_assertROOT7027/); - [projectroot.roottest.root.io.interface.roottest_root_io_interface_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146660/testReport/projectroot.roottest.root.io/interface/roottest_root_io_interface_make/); - [projectroot.roottest.root.meta.callfunc.roottest_root_meta_callfunc_assertUnload_auto](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146660/testReport/projectroot.roottest.root.meta/callfunc/roottest_root_meta_callfunc_assertUnload_auto/); - [projectroot.roottest.root.meta.cmsUnload.roottest_root_meta_cmsUnload_make](https://lcga,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10294#issuecomment-1144990827
Testability,test,tests,Build failed on ROOT-ubuntu16/nortcxxmod.; Running on sft-ubuntu-1604-1.cern.ch:/build/workspace/root-pullrequests-build; [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146660/console).; ### Failing tests:; - [projectroot.test.test_stressinterpreter](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146660/testReport/projectroot/test/test_stressinterpreter/); - [projectroot.roottest.cling.other.roottest_cling_other_checkMissingSymbolExitCode](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146660/testReport/projectroot.roottest.cling/other/roottest_cling_other_checkMissingSymbolExitCode/); - [projectroot.roottest.python.cpp.roottest_python_cpp_advanced](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146660/testReport/projectroot.roottest.python/cpp/roottest_python_cpp_advanced/); - [projectroot.roottest.root.aclic.load.roottest_root_aclic_load_reload](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146660/testReport/projectroot.roottest.root.aclic/load/roottest_root_aclic_load_reload/); - [projectroot.roottest.root.aclic.misc.roottest_root_aclic_misc_assertROOT7027](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146660/testReport/projectroot.roottest.root.aclic/misc/roottest_root_aclic_misc_assertROOT7027/); - [projectroot.roottest.root.io.interface.roottest_root_io_interface_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146660/testReport/projectroot.roottest.root.io/interface/roottest_root_io_interface_make/); - [projectroot.roottest.root.meta.callfunc.roottest_root_meta_callfunc_assertUnload_auto](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146660/testReport/projectroot.roottest.root.meta/callfunc/roottest_root_meta_callfunc_assertUnload_auto/); - [projectroot.roottest.root.meta.cmsUnload.roottest_root_meta_cmsUnload_make](https://lcga,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10294#issuecomment-1144990827
Usability,simpl,simple,jectroot.roottest.python.cpp.roottest_python_cpp_advanced](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146660/testReport/projectroot.roottest.python/cpp/roottest_python_cpp_advanced/); - [projectroot.roottest.root.aclic.load.roottest_root_aclic_load_reload](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146660/testReport/projectroot.roottest.root.aclic/load/roottest_root_aclic_load_reload/); - [projectroot.roottest.root.aclic.misc.roottest_root_aclic_misc_assertROOT7027](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146660/testReport/projectroot.roottest.root.aclic/misc/roottest_root_aclic_misc_assertROOT7027/); - [projectroot.roottest.root.io.interface.roottest_root_io_interface_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146660/testReport/projectroot.roottest.root.io/interface/roottest_root_io_interface_make/); - [projectroot.roottest.root.meta.callfunc.roottest_root_meta_callfunc_assertUnload_auto](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146660/testReport/projectroot.roottest.root.meta/callfunc/roottest_root_meta_callfunc_assertUnload_auto/); - [projectroot.roottest.root.meta.cmsUnload.roottest_root_meta_cmsUnload_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146660/testReport/projectroot.roottest.root.meta/cmsUnload/roottest_root_meta_cmsUnload_make/); - [projectroot.roottest.cling.template.roottest_cling_template_runtemplatefriend](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146660/testReport/projectroot.roottest.cling/template/roottest_cling_template_runtemplatefriend/); - [projectroot.roottest.root.selector.simple.roottest_root_selector_simple_runtestLoadingSelector](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146660/testReport/projectroot.roottest.root.selector/simple/roottest_root_selector_simple_runtestLoadingSelector/),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10294#issuecomment-1144990827
Integrability,interface,interface,est.cling.template.roottest_cling_template_runtemplatefriend](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146675/testReport/projectroot.roottest.cling/template/roottest_cling_template_runtemplatefriend/); - [projectroot.roottest.root.aclic.misc.roottest_root_aclic_misc_assertROOT7027](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146675/testReport/projectroot.roottest.root.aclic/misc/roottest_root_aclic_misc_assertROOT7027/); - [projectroot.roottest.root.aclic.load.roottest_root_aclic_load_reload](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146675/testReport/projectroot.roottest.root.aclic/load/roottest_root_aclic_load_reload/); - [projectroot.roottest.root.dataframe.roottest_root_dataframe_missingBranches](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146675/testReport/projectroot.roottest.root/dataframe/roottest_root_dataframe_missingBranches/); - [projectroot.roottest.python.cpp.roottest_python_cpp_advanced](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146675/testReport/projectroot.roottest.python/cpp/roottest_python_cpp_advanced/); - [projectroot.roottest.root.io.interface.roottest_root_io_interface_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146675/testReport/projectroot.roottest.root.io/interface/roottest_root_io_interface_make/); - [projectroot.roottest.root.meta.callfunc.roottest_root_meta_callfunc_assertUnload_auto](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146675/testReport/projectroot.roottest.root.meta/callfunc/roottest_root_meta_callfunc_assertUnload_auto/); - [projectroot.roottest.root.selector.simple.roottest_root_selector_simple_runtestLoadingSelector](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146675/testReport/projectroot.roottest.root.selector/simple/roottest_root_selector_simple_runtestLoadingSelector/). And 5 more,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10294#issuecomment-1145207749
Performance,perform,performance-,Build failed on ROOT-performance-centos8-multicore/default.; Running on olbdw-01.cern.ch:/data/sftnight/workspace/root-pullrequests-build; [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146675/console).; ### Warnings:; - [2022-06-02T18:36:05.557Z] Warning in &lt;CheckModuleValid&gt;: warning: Couldn't find in the following specified headers in the module Core: ; - [2022-06-02T18:36:24.346Z] Warning in &lt;CheckModuleValid&gt;: warning: Couldn't find in the following specified headers in the module Thread: . ### Failing tests:; - [projectroot.test.test_stressinterpreter](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146675/testReport/projectroot/test/test_stressinterpreter/); - [projectroot.roottest.cling.other.roottest_cling_other_checkMissingSymbolExitCode](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146675/testReport/projectroot.roottest.cling/other/roottest_cling_other_checkMissingSymbolExitCode/); - [projectroot.roottest.cling.template.roottest_cling_template_runtemplatefriend](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146675/testReport/projectroot.roottest.cling/template/roottest_cling_template_runtemplatefriend/); - [projectroot.roottest.root.aclic.misc.roottest_root_aclic_misc_assertROOT7027](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146675/testReport/projectroot.roottest.root.aclic/misc/roottest_root_aclic_misc_assertROOT7027/); - [projectroot.roottest.root.aclic.load.roottest_root_aclic_load_reload](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146675/testReport/projectroot.roottest.root.aclic/load/roottest_root_aclic_load_reload/); - [projectroot.roottest.root.dataframe.roottest_root_dataframe_missingBranches](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146675/testReport/projectroot.roottest.root/dataframe/roottest_root_dataframe_missingBra,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10294#issuecomment-1145207749
Testability,test,tests,Build failed on ROOT-performance-centos8-multicore/default.; Running on olbdw-01.cern.ch:/data/sftnight/workspace/root-pullrequests-build; [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146675/console).; ### Warnings:; - [2022-06-02T18:36:05.557Z] Warning in &lt;CheckModuleValid&gt;: warning: Couldn't find in the following specified headers in the module Core: ; - [2022-06-02T18:36:24.346Z] Warning in &lt;CheckModuleValid&gt;: warning: Couldn't find in the following specified headers in the module Thread: . ### Failing tests:; - [projectroot.test.test_stressinterpreter](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146675/testReport/projectroot/test/test_stressinterpreter/); - [projectroot.roottest.cling.other.roottest_cling_other_checkMissingSymbolExitCode](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146675/testReport/projectroot.roottest.cling/other/roottest_cling_other_checkMissingSymbolExitCode/); - [projectroot.roottest.cling.template.roottest_cling_template_runtemplatefriend](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146675/testReport/projectroot.roottest.cling/template/roottest_cling_template_runtemplatefriend/); - [projectroot.roottest.root.aclic.misc.roottest_root_aclic_misc_assertROOT7027](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146675/testReport/projectroot.roottest.root.aclic/misc/roottest_root_aclic_misc_assertROOT7027/); - [projectroot.roottest.root.aclic.load.roottest_root_aclic_load_reload](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146675/testReport/projectroot.roottest.root.aclic/load/roottest_root_aclic_load_reload/); - [projectroot.roottest.root.dataframe.roottest_root_dataframe_missingBranches](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146675/testReport/projectroot.roottest.root/dataframe/roottest_root_dataframe_missingBra,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10294#issuecomment-1145207749
Usability,simpl,simple,est.cling.template.roottest_cling_template_runtemplatefriend](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146675/testReport/projectroot.roottest.cling/template/roottest_cling_template_runtemplatefriend/); - [projectroot.roottest.root.aclic.misc.roottest_root_aclic_misc_assertROOT7027](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146675/testReport/projectroot.roottest.root.aclic/misc/roottest_root_aclic_misc_assertROOT7027/); - [projectroot.roottest.root.aclic.load.roottest_root_aclic_load_reload](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146675/testReport/projectroot.roottest.root.aclic/load/roottest_root_aclic_load_reload/); - [projectroot.roottest.root.dataframe.roottest_root_dataframe_missingBranches](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146675/testReport/projectroot.roottest.root/dataframe/roottest_root_dataframe_missingBranches/); - [projectroot.roottest.python.cpp.roottest_python_cpp_advanced](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146675/testReport/projectroot.roottest.python/cpp/roottest_python_cpp_advanced/); - [projectroot.roottest.root.io.interface.roottest_root_io_interface_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146675/testReport/projectroot.roottest.root.io/interface/roottest_root_io_interface_make/); - [projectroot.roottest.root.meta.callfunc.roottest_root_meta_callfunc_assertUnload_auto](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146675/testReport/projectroot.roottest.root.meta/callfunc/roottest_root_meta_callfunc_assertUnload_auto/); - [projectroot.roottest.root.selector.simple.roottest_root_selector_simple_runtestLoadingSelector](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/146675/testReport/projectroot.roottest.root.selector/simple/roottest_root_selector_simple_runtestLoadingSelector/). And 5 more,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10294#issuecomment-1145207749
Integrability,interface,interface, - [projectroot.roottest.cling.template.roottest_cling_template_runtemplatefriend](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/147284/testReport/projectroot.roottest.cling/template/roottest_cling_template_runtemplatefriend/); - [projectroot.roottest.python.cpp.roottest_python_cpp_advanced](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/147284/testReport/projectroot.roottest.python/cpp/roottest_python_cpp_advanced/); - [projectroot.roottest.root.aclic.load.roottest_root_aclic_load_reload](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/147284/testReport/projectroot.roottest.root.aclic/load/roottest_root_aclic_load_reload/); - [projectroot.roottest.root.aclic.misc.roottest_root_aclic_misc_assertROOT7027](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/147284/testReport/projectroot.roottest.root.aclic/misc/roottest_root_aclic_misc_assertROOT7027/); - [projectroot.roottest.root.io.interface.roottest_root_io_interface_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/147284/testReport/projectroot.roottest.root.io/interface/roottest_root_io_interface_make/); - [projectroot.roottest.root.meta.callfunc.roottest_root_meta_callfunc_assertUnload_auto](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/147284/testReport/projectroot.roottest.root.meta/callfunc/roottest_root_meta_callfunc_assertUnload_auto/); - [projectroot.roottest.root.meta.cmsUnload.roottest_root_meta_cmsUnload_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/147284/testReport/projectroot.roottest.root.meta/cmsUnload/roottest_root_meta_cmsUnload_make/); - [projectroot.roottest.root.selector.simple.roottest_root_selector_simple_runtestLoadingSelector](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/147284/testReport/projectroot.roottest.root.selector/simple/roottest_root_selector_simple_runtestLoadingSel,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10294#issuecomment-1153748598
Performance,load,load,quests-build/147284/console).; ### Failing tests:; - [projectroot.test.test_stressinterpreter](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/147284/testReport/projectroot/test/test_stressinterpreter/); - [projectroot.roottest.cling.other.roottest_cling_other_checkMissingSymbolExitCode](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/147284/testReport/projectroot.roottest.cling/other/roottest_cling_other_checkMissingSymbolExitCode/); - [projectroot.roottest.cling.template.roottest_cling_template_runtemplatefriend](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/147284/testReport/projectroot.roottest.cling/template/roottest_cling_template_runtemplatefriend/); - [projectroot.roottest.python.cpp.roottest_python_cpp_advanced](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/147284/testReport/projectroot.roottest.python/cpp/roottest_python_cpp_advanced/); - [projectroot.roottest.root.aclic.load.roottest_root_aclic_load_reload](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/147284/testReport/projectroot.roottest.root.aclic/load/roottest_root_aclic_load_reload/); - [projectroot.roottest.root.aclic.misc.roottest_root_aclic_misc_assertROOT7027](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/147284/testReport/projectroot.roottest.root.aclic/misc/roottest_root_aclic_misc_assertROOT7027/); - [projectroot.roottest.root.io.interface.roottest_root_io_interface_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/147284/testReport/projectroot.roottest.root.io/interface/roottest_root_io_interface_make/); - [projectroot.roottest.root.meta.callfunc.roottest_root_meta_callfunc_assertUnload_auto](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/147284/testReport/projectroot.roottest.root.meta/callfunc/roottest_root_meta_callfunc_assertUnload_auto/); - [projectroot.roottest.root.meta.cmsUnl,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10294#issuecomment-1153748598
Testability,test,tests,Build failed on ROOT-ubuntu16/nortcxxmod.; Running on sft-ubuntu-1604-1.cern.ch:/build/workspace/root-pullrequests-build; [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/147284/console).; ### Failing tests:; - [projectroot.test.test_stressinterpreter](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/147284/testReport/projectroot/test/test_stressinterpreter/); - [projectroot.roottest.cling.other.roottest_cling_other_checkMissingSymbolExitCode](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/147284/testReport/projectroot.roottest.cling/other/roottest_cling_other_checkMissingSymbolExitCode/); - [projectroot.roottest.cling.template.roottest_cling_template_runtemplatefriend](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/147284/testReport/projectroot.roottest.cling/template/roottest_cling_template_runtemplatefriend/); - [projectroot.roottest.python.cpp.roottest_python_cpp_advanced](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/147284/testReport/projectroot.roottest.python/cpp/roottest_python_cpp_advanced/); - [projectroot.roottest.root.aclic.load.roottest_root_aclic_load_reload](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/147284/testReport/projectroot.roottest.root.aclic/load/roottest_root_aclic_load_reload/); - [projectroot.roottest.root.aclic.misc.roottest_root_aclic_misc_assertROOT7027](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/147284/testReport/projectroot.roottest.root.aclic/misc/roottest_root_aclic_misc_assertROOT7027/); - [projectroot.roottest.root.io.interface.roottest_root_io_interface_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/147284/testReport/projectroot.roottest.root.io/interface/roottest_root_io_interface_make/); - [projectroot.roottest.root.meta.callfunc.roottest_root_meta_callfunc_assertUnload_auto](https://lcgapp-se,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10294#issuecomment-1153748598
Usability,simpl,simple,jectroot.roottest.cling.template.roottest_cling_template_runtemplatefriend](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/147284/testReport/projectroot.roottest.cling/template/roottest_cling_template_runtemplatefriend/); - [projectroot.roottest.python.cpp.roottest_python_cpp_advanced](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/147284/testReport/projectroot.roottest.python/cpp/roottest_python_cpp_advanced/); - [projectroot.roottest.root.aclic.load.roottest_root_aclic_load_reload](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/147284/testReport/projectroot.roottest.root.aclic/load/roottest_root_aclic_load_reload/); - [projectroot.roottest.root.aclic.misc.roottest_root_aclic_misc_assertROOT7027](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/147284/testReport/projectroot.roottest.root.aclic/misc/roottest_root_aclic_misc_assertROOT7027/); - [projectroot.roottest.root.io.interface.roottest_root_io_interface_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/147284/testReport/projectroot.roottest.root.io/interface/roottest_root_io_interface_make/); - [projectroot.roottest.root.meta.callfunc.roottest_root_meta_callfunc_assertUnload_auto](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/147284/testReport/projectroot.roottest.root.meta/callfunc/roottest_root_meta_callfunc_assertUnload_auto/); - [projectroot.roottest.root.meta.cmsUnload.roottest_root_meta_cmsUnload_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/147284/testReport/projectroot.roottest.root.meta/cmsUnload/roottest_root_meta_cmsUnload_make/); - [projectroot.roottest.root.selector.simple.roottest_root_selector_simple_runtestLoadingSelector](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/147284/testReport/projectroot.roottest.root.selector/simple/roottest_root_selector_simple_runtestLoadingSelector/),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10294#issuecomment-1153748598
Availability,error,error,"@vgvassilev , this failed to build for cmssw externals e.g. `hepdata-lib` failed to build with [error](https://cmssdt.cern.ch/SDT/jenkins-artifacts/pull-request-integration/PR-6342e6/25491/external/py3-hepdata-lib/0.8.1-ec986c2493f655785ae2df5c3741f2df/log); ```; + pip3 install --no-clean --no-deps --no-index --no-build-isolation --no-cache-dir --disable-pip-version-check --user -v hepdata_lib-0.8.1.tar.gz; Using pip 22.0.4 from /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc10/external/py3-pip/22.0.4-84448601ef6fb03288e044db5008fd92/lib/python3.9/site-packages/pip (python 3.9); Processing ./hepdata_lib-0.8.1.tar.gz; Preparing metadata (setup.py): started; Running command python setup.py egg_info; input_line_1:1:2: fatal error: module 'libc' in AST file '/data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc10/lcg/root/6.27.01-fcb9eae806144b267f209fdf3fa8dc2e/lib/std.pcm' found in a different module map file (/data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc10/lcg/root/6.27.01-fcb9eae806144b267f209fdf3fa8dc2e/etc/cling/libc.modulemap) than when the importing AST file was built (/data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/BUILD/el8_amd64_gcc10/lcg/root/6.27.01-fcb9eae806144b267f209fdf3fa8dc2e/build/etc/cling/libc.modulemap); #include <new>; ^; input_line_1:1:2: note: imported by module 'std' in '/data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc10/lcg/root/6.27.01-fcb9eae806144b267f209fdf3fa8dc2e/lib/std.pcm'; Warning in cling::IncrementalParser::CheckABICompatibility():; Failed to extract C++ standard library version.; Replaced symbol atexit cannot be found in JIT!; Replaced symbol at_quick_exit cannot be found in JIT!; <<< cling interactive line includer >>>: fatal error: module file '/data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc10/lcg/root/6.27.01-fcb9eae806144b267f209fdf3fa8dc2e/lib/libc.pcm' is out of date and needs to be rebuilt",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10294#issuecomment-1154135015
Deployability,integrat,integration,"@vgvassilev , this failed to build for cmssw externals e.g. `hepdata-lib` failed to build with [error](https://cmssdt.cern.ch/SDT/jenkins-artifacts/pull-request-integration/PR-6342e6/25491/external/py3-hepdata-lib/0.8.1-ec986c2493f655785ae2df5c3741f2df/log); ```; + pip3 install --no-clean --no-deps --no-index --no-build-isolation --no-cache-dir --disable-pip-version-check --user -v hepdata_lib-0.8.1.tar.gz; Using pip 22.0.4 from /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc10/external/py3-pip/22.0.4-84448601ef6fb03288e044db5008fd92/lib/python3.9/site-packages/pip (python 3.9); Processing ./hepdata_lib-0.8.1.tar.gz; Preparing metadata (setup.py): started; Running command python setup.py egg_info; input_line_1:1:2: fatal error: module 'libc' in AST file '/data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc10/lcg/root/6.27.01-fcb9eae806144b267f209fdf3fa8dc2e/lib/std.pcm' found in a different module map file (/data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc10/lcg/root/6.27.01-fcb9eae806144b267f209fdf3fa8dc2e/etc/cling/libc.modulemap) than when the importing AST file was built (/data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/BUILD/el8_amd64_gcc10/lcg/root/6.27.01-fcb9eae806144b267f209fdf3fa8dc2e/build/etc/cling/libc.modulemap); #include <new>; ^; input_line_1:1:2: note: imported by module 'std' in '/data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc10/lcg/root/6.27.01-fcb9eae806144b267f209fdf3fa8dc2e/lib/std.pcm'; Warning in cling::IncrementalParser::CheckABICompatibility():; Failed to extract C++ standard library version.; Replaced symbol atexit cannot be found in JIT!; Replaced symbol at_quick_exit cannot be found in JIT!; <<< cling interactive line includer >>>: fatal error: module file '/data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc10/lcg/root/6.27.01-fcb9eae806144b267f209fdf3fa8dc2e/lib/libc.pcm' is out of date and needs to be rebuilt",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10294#issuecomment-1154135015
Integrability,integrat,integration,"@vgvassilev , this failed to build for cmssw externals e.g. `hepdata-lib` failed to build with [error](https://cmssdt.cern.ch/SDT/jenkins-artifacts/pull-request-integration/PR-6342e6/25491/external/py3-hepdata-lib/0.8.1-ec986c2493f655785ae2df5c3741f2df/log); ```; + pip3 install --no-clean --no-deps --no-index --no-build-isolation --no-cache-dir --disable-pip-version-check --user -v hepdata_lib-0.8.1.tar.gz; Using pip 22.0.4 from /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc10/external/py3-pip/22.0.4-84448601ef6fb03288e044db5008fd92/lib/python3.9/site-packages/pip (python 3.9); Processing ./hepdata_lib-0.8.1.tar.gz; Preparing metadata (setup.py): started; Running command python setup.py egg_info; input_line_1:1:2: fatal error: module 'libc' in AST file '/data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc10/lcg/root/6.27.01-fcb9eae806144b267f209fdf3fa8dc2e/lib/std.pcm' found in a different module map file (/data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc10/lcg/root/6.27.01-fcb9eae806144b267f209fdf3fa8dc2e/etc/cling/libc.modulemap) than when the importing AST file was built (/data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/BUILD/el8_amd64_gcc10/lcg/root/6.27.01-fcb9eae806144b267f209fdf3fa8dc2e/build/etc/cling/libc.modulemap); #include <new>; ^; input_line_1:1:2: note: imported by module 'std' in '/data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc10/lcg/root/6.27.01-fcb9eae806144b267f209fdf3fa8dc2e/lib/std.pcm'; Warning in cling::IncrementalParser::CheckABICompatibility():; Failed to extract C++ standard library version.; Replaced symbol atexit cannot be found in JIT!; Replaced symbol at_quick_exit cannot be found in JIT!; <<< cling interactive line includer >>>: fatal error: module file '/data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc10/lcg/root/6.27.01-fcb9eae806144b267f209fdf3fa8dc2e/lib/libc.pcm' is out of date and needs to be rebuilt",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10294#issuecomment-1154135015
Performance,cache,cache-dir,"@vgvassilev , this failed to build for cmssw externals e.g. `hepdata-lib` failed to build with [error](https://cmssdt.cern.ch/SDT/jenkins-artifacts/pull-request-integration/PR-6342e6/25491/external/py3-hepdata-lib/0.8.1-ec986c2493f655785ae2df5c3741f2df/log); ```; + pip3 install --no-clean --no-deps --no-index --no-build-isolation --no-cache-dir --disable-pip-version-check --user -v hepdata_lib-0.8.1.tar.gz; Using pip 22.0.4 from /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc10/external/py3-pip/22.0.4-84448601ef6fb03288e044db5008fd92/lib/python3.9/site-packages/pip (python 3.9); Processing ./hepdata_lib-0.8.1.tar.gz; Preparing metadata (setup.py): started; Running command python setup.py egg_info; input_line_1:1:2: fatal error: module 'libc' in AST file '/data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc10/lcg/root/6.27.01-fcb9eae806144b267f209fdf3fa8dc2e/lib/std.pcm' found in a different module map file (/data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc10/lcg/root/6.27.01-fcb9eae806144b267f209fdf3fa8dc2e/etc/cling/libc.modulemap) than when the importing AST file was built (/data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/BUILD/el8_amd64_gcc10/lcg/root/6.27.01-fcb9eae806144b267f209fdf3fa8dc2e/build/etc/cling/libc.modulemap); #include <new>; ^; input_line_1:1:2: note: imported by module 'std' in '/data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc10/lcg/root/6.27.01-fcb9eae806144b267f209fdf3fa8dc2e/lib/std.pcm'; Warning in cling::IncrementalParser::CheckABICompatibility():; Failed to extract C++ standard library version.; Replaced symbol atexit cannot be found in JIT!; Replaced symbol at_quick_exit cannot be found in JIT!; <<< cling interactive line includer >>>: fatal error: module file '/data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc10/lcg/root/6.27.01-fcb9eae806144b267f209fdf3fa8dc2e/lib/libc.pcm' is out of date and needs to be rebuilt",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10294#issuecomment-1154135015
Safety,avoid,avoids,"try *>() == &UFE && ""filename from getStatValue() refers to wrong file""' failed.; error: subprocess-exited-with-error; ;  python setup.py egg_info did not run successfully.;  exit code: -6; > See above for output.; ; note: This error originates from a subprocess, and is likely not a problem with pip.; full command: /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc10/external/python3/3.9.6-67e5cf5b4952101922f1d4c8474baa39/bin/python3 -c '; exec(compile('""'""''""'""''""'""'; # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py; #; # - It imports setuptools before invoking setup.py, to enable projects that directly; # import from `distutils.core` to work with newer packaging standards.; # - It provides a clear error message when setuptools is not installed.; # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so; # setuptools doesn'""'""'t think the script is `-c`. This avoids the following warning:; # manifest_maker: standard file '""'""'-c'""'""' not found"".; # - It generates a shim setup.py, for handling setup.cfg-only projects.; import os, sys, tokenize; ; try:; import setuptools; except ImportError as error:; print(; ""ERROR: Can not execute `setup.py` since setuptools is not available in ""; ""the build environment."",; file=sys.stderr,; ); sys.exit(1); ; __file__ = %r; sys.argv[0] = __file__; ; if os.path.exists(__file__):; filename = __file__; with tokenize.open(__file__) as f:; setup_py_code = f.read(); else:; filename = ""<auto-generated setuptools caller>""; setup_py_code = ""from setuptools import setup; setup()""; ; exec(compile(setup_py_code, filename, ""exec"")); '""'""''""'""''""'""' % ('""'""'.../py3-hepdata-lib/0.8.1-ec986c2493f655785ae2df5c3741f2df/cmsdist-tmp/pip-req-build-02hlcwf_/setup.py'""'""',), ""<pip-setuptools-caller>"", ""exec""))' egg_info --egg-base .../py3-hepdata-lib/0.8.1-ec986c2493f655785ae2df5c3741f2df/cmsdist-tmp/pip-pip-egg-info-pxqkc5sy; cwd: .../py3-hepdata-lib/0.8.1-ec986c2493f6",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10294#issuecomment-1154135015
Testability,log,log,"@vgvassilev , this failed to build for cmssw externals e.g. `hepdata-lib` failed to build with [error](https://cmssdt.cern.ch/SDT/jenkins-artifacts/pull-request-integration/PR-6342e6/25491/external/py3-hepdata-lib/0.8.1-ec986c2493f655785ae2df5c3741f2df/log); ```; + pip3 install --no-clean --no-deps --no-index --no-build-isolation --no-cache-dir --disable-pip-version-check --user -v hepdata_lib-0.8.1.tar.gz; Using pip 22.0.4 from /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc10/external/py3-pip/22.0.4-84448601ef6fb03288e044db5008fd92/lib/python3.9/site-packages/pip (python 3.9); Processing ./hepdata_lib-0.8.1.tar.gz; Preparing metadata (setup.py): started; Running command python setup.py egg_info; input_line_1:1:2: fatal error: module 'libc' in AST file '/data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc10/lcg/root/6.27.01-fcb9eae806144b267f209fdf3fa8dc2e/lib/std.pcm' found in a different module map file (/data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc10/lcg/root/6.27.01-fcb9eae806144b267f209fdf3fa8dc2e/etc/cling/libc.modulemap) than when the importing AST file was built (/data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/BUILD/el8_amd64_gcc10/lcg/root/6.27.01-fcb9eae806144b267f209fdf3fa8dc2e/build/etc/cling/libc.modulemap); #include <new>; ^; input_line_1:1:2: note: imported by module 'std' in '/data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc10/lcg/root/6.27.01-fcb9eae806144b267f209fdf3fa8dc2e/lib/std.pcm'; Warning in cling::IncrementalParser::CheckABICompatibility():; Failed to extract C++ standard library version.; Replaced symbol atexit cannot be found in JIT!; Replaced symbol at_quick_exit cannot be found in JIT!; <<< cling interactive line includer >>>: fatal error: module file '/data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc10/lcg/root/6.27.01-fcb9eae806144b267f209fdf3fa8dc2e/lib/libc.pcm' is out of date and needs to be rebuilt",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10294#issuecomment-1154135015
Usability,clear,clear,"../root-6.27.01/interpreter/llvm/src/tools/clang/lib/Basic/FileManager.cpp:301: llvm::Expected<clang::FileEntryRef> clang::FileManager::getFileRef(llvm::StringRef, bool, bool): Assertion `Redirection.second->V.get<FileEntry *>() == &UFE && ""filename from getStatValue() refers to wrong file""' failed.; error: subprocess-exited-with-error; ;  python setup.py egg_info did not run successfully.;  exit code: -6; > See above for output.; ; note: This error originates from a subprocess, and is likely not a problem with pip.; full command: /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc10/external/python3/3.9.6-67e5cf5b4952101922f1d4c8474baa39/bin/python3 -c '; exec(compile('""'""''""'""''""'""'; # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py; #; # - It imports setuptools before invoking setup.py, to enable projects that directly; # import from `distutils.core` to work with newer packaging standards.; # - It provides a clear error message when setuptools is not installed.; # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so; # setuptools doesn'""'""'t think the script is `-c`. This avoids the following warning:; # manifest_maker: standard file '""'""'-c'""'""' not found"".; # - It generates a shim setup.py, for handling setup.cfg-only projects.; import os, sys, tokenize; ; try:; import setuptools; except ImportError as error:; print(; ""ERROR: Can not execute `setup.py` since setuptools is not available in ""; ""the build environment."",; file=sys.stderr,; ); sys.exit(1); ; __file__ = %r; sys.argv[0] = __file__; ; if os.path.exists(__file__):; filename = __file__; with tokenize.open(__file__) as f:; setup_py_code = f.read(); else:; filename = ""<auto-generated setuptools caller>""; setup_py_code = ""from setuptools import setup; setup()""; ; exec(compile(setup_py_code, filename, ""exec"")); '""'""''""'""''""'""' % ('""'""'.../py3-hepdata-lib/0.8.1-ec986c2493f655785ae2df5c3741f2df/cmsdist-tmp/pip-req-build-02hl",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10294#issuecomment-1154135015
Performance,perform,performance-,Build failed on ROOT-performance-centos8-multicore/cxx17.; Running on olbdw-01.cern.ch:/data/sftnight/workspace/root-pullrequests-build; [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/149178/console).; ### Warnings:; - [2022-07-05T13:55:21.463Z] Warning in &lt;CheckModuleValid&gt;: warning: Couldn't find in the following specified headers in the module Core: ; - [2022-07-05T13:55:40.879Z] Warning in &lt;CheckModuleValid&gt;: warning: Couldn't find in the following specified headers in the module Thread: . ### Failing tests:; - [projectroot.roottest.cling.other.roottest_cling_other_checkMissingSymbolExitCode](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/149178/testReport/projectroot.roottest.cling/other/roottest_cling_other_checkMissingSymbolExitCode/); - [projectroot.roottest.cling.other.roottest_cling_other_assertDirWithParen](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/149178/testReport/projectroot.roottest.cling/other/roottest_cling_other_assertDirWithParen/); - [projectroot.roottest.cling.staticinit.ROOT-10426.roottest_cling_staticinit_ROOT_10426_ROOT_10426](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/149178/testReport/projectroot.roottest.cling.staticinit/ROOT-10426/roottest_cling_staticinit_ROOT_10426_ROOT_10426/); - [projectroot.roottest.python.cling.roottest_python_cling_api](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/149178/testReport/projectroot.roottest.python/cling/roottest_python_cling_api/); - [projectroot.roottest.python.cling.roottest_python_cling_class](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/149178/testReport/projectroot.roottest.python/cling/roottest_python_cling_class/); - [projectroot.roottest.python.cpp.roottest_python_cpp_advanced](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/149178/testReport/projectroot.roottest.python/cpp,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10294#issuecomment-1175116758
Testability,test,tests,Build failed on ROOT-performance-centos8-multicore/cxx17.; Running on olbdw-01.cern.ch:/data/sftnight/workspace/root-pullrequests-build; [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/149178/console).; ### Warnings:; - [2022-07-05T13:55:21.463Z] Warning in &lt;CheckModuleValid&gt;: warning: Couldn't find in the following specified headers in the module Core: ; - [2022-07-05T13:55:40.879Z] Warning in &lt;CheckModuleValid&gt;: warning: Couldn't find in the following specified headers in the module Thread: . ### Failing tests:; - [projectroot.roottest.cling.other.roottest_cling_other_checkMissingSymbolExitCode](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/149178/testReport/projectroot.roottest.cling/other/roottest_cling_other_checkMissingSymbolExitCode/); - [projectroot.roottest.cling.other.roottest_cling_other_assertDirWithParen](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/149178/testReport/projectroot.roottest.cling/other/roottest_cling_other_assertDirWithParen/); - [projectroot.roottest.cling.staticinit.ROOT-10426.roottest_cling_staticinit_ROOT_10426_ROOT_10426](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/149178/testReport/projectroot.roottest.cling.staticinit/ROOT-10426/roottest_cling_staticinit_ROOT_10426_ROOT_10426/); - [projectroot.roottest.python.cling.roottest_python_cling_api](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/149178/testReport/projectroot.roottest.python/cling/roottest_python_cling_api/); - [projectroot.roottest.python.cling.roottest_python_cling_class](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/149178/testReport/projectroot.roottest.python/cling/roottest_python_cling_class/); - [projectroot.roottest.python.cpp.roottest_python_cpp_advanced](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/149178/testReport/projectroot.roottest.python/cpp,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10294#issuecomment-1175116758
Usability,simpl,simple,oottest_cling_other_assertDirWithParen/); - [projectroot.roottest.cling.staticinit.ROOT-10426.roottest_cling_staticinit_ROOT_10426_ROOT_10426](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/149178/testReport/projectroot.roottest.cling.staticinit/ROOT-10426/roottest_cling_staticinit_ROOT_10426_ROOT_10426/); - [projectroot.roottest.python.cling.roottest_python_cling_api](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/149178/testReport/projectroot.roottest.python/cling/roottest_python_cling_api/); - [projectroot.roottest.python.cling.roottest_python_cling_class](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/149178/testReport/projectroot.roottest.python/cling/roottest_python_cling_class/); - [projectroot.roottest.python.cpp.roottest_python_cpp_advanced](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/149178/testReport/projectroot.roottest.python/cpp/roottest_python_cpp_advanced/); - [projectroot.roottest.root.meta.roottest_root_meta_execUnloading_auto](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/149178/testReport/projectroot.roottest.root/meta/roottest_root_meta_execUnloading_auto/); - [projectroot.roottest.root.aclic.load.roottest_root_aclic_load_reload](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/149178/testReport/projectroot.roottest.root.aclic/load/roottest_root_aclic_load_reload/); - [projectroot.roottest.root.selector.simple.roottest_root_selector_simple_runtestLoadingSelector](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/149178/testReport/projectroot.roottest.root.selector/simple/roottest_root_selector_simple_runtestLoadingSelector/); - [projectroot.roottest.root.tree.addresses.roottest_root_tree_addresses_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/149178/testReport/projectroot.roottest.root.tree/addresses/roottest_root_tree_addresses_make/),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10294#issuecomment-1175116758
Performance,load,load,Build failed on ROOT-ubuntu18.04/nortcxxmod.; Running on sft-ubuntu-1804-2.cern.ch:/build/workspace/root-pullrequests-build; [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/149179/console).; ### Failing tests:; - [projectroot.roottest.cling.other.roottest_cling_other_checkMissingSymbolExitCode](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/149179/testReport/projectroot.roottest.cling/other/roottest_cling_other_checkMissingSymbolExitCode/); - [projectroot.roottest.cling.other.roottest_cling_other_assertDirWithParen](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/149179/testReport/projectroot.roottest.cling/other/roottest_cling_other_assertDirWithParen/); - [projectroot.roottest.python.cpp.roottest_python_cpp_advanced](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/149179/testReport/projectroot.roottest.python/cpp/roottest_python_cpp_advanced/); - [projectroot.roottest.root.meta.roottest_root_meta_execUnloading_auto](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/149179/testReport/projectroot.roottest.root/meta/roottest_root_meta_execUnloading_auto/); - [projectroot.roottest.root.aclic.load.roottest_root_aclic_load_reload](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/149179/testReport/projectroot.roottest.root.aclic/load/roottest_root_aclic_load_reload/); - [projectroot.roottest.root.selector.simple.roottest_root_selector_simple_runtestLoadingSelector](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/149179/testReport/projectroot.roottest.root.selector/simple/roottest_root_selector_simple_runtestLoadingSelector/),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10294#issuecomment-1175130897
Testability,test,tests,Build failed on ROOT-ubuntu18.04/nortcxxmod.; Running on sft-ubuntu-1804-2.cern.ch:/build/workspace/root-pullrequests-build; [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/149179/console).; ### Failing tests:; - [projectroot.roottest.cling.other.roottest_cling_other_checkMissingSymbolExitCode](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/149179/testReport/projectroot.roottest.cling/other/roottest_cling_other_checkMissingSymbolExitCode/); - [projectroot.roottest.cling.other.roottest_cling_other_assertDirWithParen](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/149179/testReport/projectroot.roottest.cling/other/roottest_cling_other_assertDirWithParen/); - [projectroot.roottest.python.cpp.roottest_python_cpp_advanced](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/149179/testReport/projectroot.roottest.python/cpp/roottest_python_cpp_advanced/); - [projectroot.roottest.root.meta.roottest_root_meta_execUnloading_auto](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/149179/testReport/projectroot.roottest.root/meta/roottest_root_meta_execUnloading_auto/); - [projectroot.roottest.root.aclic.load.roottest_root_aclic_load_reload](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/149179/testReport/projectroot.roottest.root.aclic/load/roottest_root_aclic_load_reload/); - [projectroot.roottest.root.selector.simple.roottest_root_selector_simple_runtestLoadingSelector](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/149179/testReport/projectroot.roottest.root.selector/simple/roottest_root_selector_simple_runtestLoadingSelector/),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10294#issuecomment-1175130897
Usability,simpl,simple,Build failed on ROOT-ubuntu18.04/nortcxxmod.; Running on sft-ubuntu-1804-2.cern.ch:/build/workspace/root-pullrequests-build; [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/149179/console).; ### Failing tests:; - [projectroot.roottest.cling.other.roottest_cling_other_checkMissingSymbolExitCode](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/149179/testReport/projectroot.roottest.cling/other/roottest_cling_other_checkMissingSymbolExitCode/); - [projectroot.roottest.cling.other.roottest_cling_other_assertDirWithParen](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/149179/testReport/projectroot.roottest.cling/other/roottest_cling_other_assertDirWithParen/); - [projectroot.roottest.python.cpp.roottest_python_cpp_advanced](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/149179/testReport/projectroot.roottest.python/cpp/roottest_python_cpp_advanced/); - [projectroot.roottest.root.meta.roottest_root_meta_execUnloading_auto](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/149179/testReport/projectroot.roottest.root/meta/roottest_root_meta_execUnloading_auto/); - [projectroot.roottest.root.aclic.load.roottest_root_aclic_load_reload](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/149179/testReport/projectroot.roottest.root.aclic/load/roottest_root_aclic_load_reload/); - [projectroot.roottest.root.selector.simple.roottest_root_selector_simple_runtestLoadingSelector](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/149179/testReport/projectroot.roottest.root.selector/simple/roottest_root_selector_simple_runtestLoadingSelector/),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10294#issuecomment-1175130897
Testability,test,tests,Build failed on ROOT-ubuntu2004/python3.; Running on root-ubuntu-2004-1.cern.ch:/home/sftnight/build/workspace/root-pullrequests-build; [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/149180/console).; ### Warnings:; - [2022-07-05T14:28:36.238Z] Warning in &lt;CheckModuleValid&gt;: warning: Couldn't find in the following specified headers in the module Core: ; - [2022-07-05T14:29:07.480Z] Warning in &lt;CheckModuleValid&gt;: warning: Couldn't find in the following specified headers in the module Thread: . ### Failing tests:; - [projectroot.bindings.pyroot.pythonizations.test.pyunittests_pyroot_numbadeclare](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/149180/testReport/projectroot.bindings.pyroot.pythonizations/test/pyunittests_pyroot_numbadeclare/); - [projectroot.roottest.cling.staticinit.ROOT-10426.roottest_cling_staticinit_ROOT_10426_ROOT_10426](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/149180/testReport/projectroot.roottest.cling.staticinit/ROOT-10426/roottest_cling_staticinit_ROOT_10426_ROOT_10426/); - [projectroot.roottest.python.cling.roottest_python_cling_api](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/149180/testReport/projectroot.roottest.python/cling/roottest_python_cling_api/); - [projectroot.roottest.python.cling.roottest_python_cling_class](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/149180/testReport/projectroot.roottest.python/cling/roottest_python_cling_class/); - [projectroot.roottest.root.dataframe.roottest_root_dataframe_missingBranches](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/149180/testReport/projectroot.roottest.root/dataframe/roottest_root_dataframe_missingBranches/); - [projectroot.roottest.cling.other.roottest_cling_other_checkMissingSymbolExitCode](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/149180/testReport/projectr,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10294#issuecomment-1175163072
Usability,simpl,simple,t/ROOT-10426/roottest_cling_staticinit_ROOT_10426_ROOT_10426/); - [projectroot.roottest.python.cling.roottest_python_cling_api](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/149180/testReport/projectroot.roottest.python/cling/roottest_python_cling_api/); - [projectroot.roottest.python.cling.roottest_python_cling_class](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/149180/testReport/projectroot.roottest.python/cling/roottest_python_cling_class/); - [projectroot.roottest.root.dataframe.roottest_root_dataframe_missingBranches](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/149180/testReport/projectroot.roottest.root/dataframe/roottest_root_dataframe_missingBranches/); - [projectroot.roottest.cling.other.roottest_cling_other_checkMissingSymbolExitCode](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/149180/testReport/projectroot.roottest.cling/other/roottest_cling_other_checkMissingSymbolExitCode/); - [projectroot.roottest.cling.other.roottest_cling_other_assertDirWithParen](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/149180/testReport/projectroot.roottest.cling/other/roottest_cling_other_assertDirWithParen/); - [projectroot.roottest.python.cpp.roottest_python_cpp_advanced](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/149180/testReport/projectroot.roottest.python/cpp/roottest_python_cpp_advanced/); - [projectroot.roottest.root.meta.roottest_root_meta_execUnloading_auto](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/149180/testReport/projectroot.roottest.root/meta/roottest_root_meta_execUnloading_auto/); - [projectroot.roottest.root.selector.simple.roottest_root_selector_simple_runtestLoadingSelector](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/149180/testReport/projectroot.roottest.root.selector/simple/roottest_root_selector_simple_runtestLoadingSelector/),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10294#issuecomment-1175163072
Testability,test,tests,Build failed on ROOT-debian10-i386/soversion.; Running on pcepsft11.dyndns.cern.ch:/home/sftnight/build/workspace/root-pullrequests-build; [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/149177/console).; ### Warnings:; - [2022-07-05T22:47:30.183Z] Warning in &lt;CheckModuleValid&gt;: warning: Couldn't find in the following specified headers in the module Core: ; - [2022-07-05T22:48:01.949Z] Warning in &lt;CheckModuleValid&gt;: warning: Couldn't find in the following specified headers in the module Thread: . ### Failing tests:; - [projectroot.roottest.cling.other.roottest_cling_other_checkMissingSymbolExitCode](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/149177/testReport/projectroot.roottest.cling/other/roottest_cling_other_checkMissingSymbolExitCode/); - [projectroot.roottest.cling.other.roottest_cling_other_assertDirWithParen](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/149177/testReport/projectroot.roottest.cling/other/roottest_cling_other_assertDirWithParen/); - [projectroot.roottest.cling.staticinit.ROOT-10426.roottest_cling_staticinit_ROOT_10426_ROOT_10426](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/149177/testReport/projectroot.roottest.cling.staticinit/ROOT-10426/roottest_cling_staticinit_ROOT_10426_ROOT_10426/); - [projectroot.roottest.python.cling.roottest_python_cling_api](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/149177/testReport/projectroot.roottest.python/cling/roottest_python_cling_api/); - [projectroot.roottest.python.cling.roottest_python_cling_class](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/149177/testReport/projectroot.roottest.python/cling/roottest_python_cling_class/); - [projectroot.roottest.python.cpp.roottest_python_cpp_advanced](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/149177/testReport/projectroot.roottest.python/c,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10294#issuecomment-1175603018
Usability,simpl,simple,. ### Failing tests:; - [projectroot.roottest.cling.other.roottest_cling_other_checkMissingSymbolExitCode](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/149177/testReport/projectroot.roottest.cling/other/roottest_cling_other_checkMissingSymbolExitCode/); - [projectroot.roottest.cling.other.roottest_cling_other_assertDirWithParen](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/149177/testReport/projectroot.roottest.cling/other/roottest_cling_other_assertDirWithParen/); - [projectroot.roottest.cling.staticinit.ROOT-10426.roottest_cling_staticinit_ROOT_10426_ROOT_10426](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/149177/testReport/projectroot.roottest.cling.staticinit/ROOT-10426/roottest_cling_staticinit_ROOT_10426_ROOT_10426/); - [projectroot.roottest.python.cling.roottest_python_cling_api](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/149177/testReport/projectroot.roottest.python/cling/roottest_python_cling_api/); - [projectroot.roottest.python.cling.roottest_python_cling_class](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/149177/testReport/projectroot.roottest.python/cling/roottest_python_cling_class/); - [projectroot.roottest.python.cpp.roottest_python_cpp_advanced](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/149177/testReport/projectroot.roottest.python/cpp/roottest_python_cpp_advanced/); - [projectroot.roottest.root.meta.roottest_root_meta_execUnloading_auto](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/149177/testReport/projectroot.roottest.root/meta/roottest_root_meta_execUnloading_auto/); - [projectroot.roottest.root.selector.simple.roottest_root_selector_simple_runtestLoadingSelector](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/149177/testReport/projectroot.roottest.root.selector/simple/roottest_root_selector_simple_runtestLoadingSelector/),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10294#issuecomment-1175603018
Deployability,patch,patches-,"Thanks, @vgvassilev. Just to be clear, since I didn't find branches named `llvm13`, you mean these?. * https://github.com/vgvassilev/llvm/tree/cling-patches-llvm13; * https://github.com/vgvassilev/clang/tree/cling-patches-llvm13; * https://github.com/vgvassilev/cling/tree/cling-patches-llvm13",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10294#issuecomment-1186244868
Usability,clear,clear,"Thanks, @vgvassilev. Just to be clear, since I didn't find branches named `llvm13`, you mean these?. * https://github.com/vgvassilev/llvm/tree/cling-patches-llvm13; * https://github.com/vgvassilev/clang/tree/cling-patches-llvm13; * https://github.com/vgvassilev/cling/tree/cling-patches-llvm13",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10294#issuecomment-1186244868
Availability,down,down,"Ok, got it. I commented that out and have been proceeding to test things out. I've hit an issue when trying to embed cling into my project and I've boiled it down to the simplest test case I can here: https://github.com/jeaye/cling-linkage-error-test-case. Is this expected behavior? If so, how can I have cling be able to work with all of the (mangled) symbols which are in my program? I'm trying to use cling as an embedded JIT in my own language's compiler, so the goal is to be generating code on the fly which works with the existing runtime in the compiler. I can move this to a separate ticket if that's preferred.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10294#issuecomment-1192957714
Testability,test,test,"Ok, got it. I commented that out and have been proceeding to test things out. I've hit an issue when trying to embed cling into my project and I've boiled it down to the simplest test case I can here: https://github.com/jeaye/cling-linkage-error-test-case. Is this expected behavior? If so, how can I have cling be able to work with all of the (mangled) symbols which are in my program? I'm trying to use cling as an embedded JIT in my own language's compiler, so the goal is to be generating code on the fly which works with the existing runtime in the compiler. I can move this to a separate ticket if that's preferred.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10294#issuecomment-1192957714
Usability,simpl,simplest,"Ok, got it. I commented that out and have been proceeding to test things out. I've hit an issue when trying to embed cling into my project and I've boiled it down to the simplest test case I can here: https://github.com/jeaye/cling-linkage-error-test-case. Is this expected behavior? If so, how can I have cling be able to work with all of the (mangled) symbols which are in my program? I'm trying to use cling as an embedded JIT in my own language's compiler, so the goal is to be generating code on the fly which works with the existing runtime in the compiler. I can move this to a separate ticket if that's preferred.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10294#issuecomment-1192957714
Availability,down,down,"> Ok, got it. I commented that out and have been proceeding to test things out. I've hit an issue when trying to embed cling into my project and I've boiled it down to the simplest test case I can here: https://github.com/jeaye/cling-linkage-error-test-case; > ; > Is this expected behavior? If so, how can I have cling be able to work with all of the (mangled) symbols which are in my program? I'm trying to use cling as an embedded JIT in my own language's compiler, so the goal is to be generating code on the fly which works with the existing runtime in the compiler. I can move this to a separate ticket if that's preferred. You probably have compiled your code base with -fno-rtti (or exceptions) and you should pass that flag to cling as well.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10294#issuecomment-1193060626
Testability,test,test,"> Ok, got it. I commented that out and have been proceeding to test things out. I've hit an issue when trying to embed cling into my project and I've boiled it down to the simplest test case I can here: https://github.com/jeaye/cling-linkage-error-test-case; > ; > Is this expected behavior? If so, how can I have cling be able to work with all of the (mangled) symbols which are in my program? I'm trying to use cling as an embedded JIT in my own language's compiler, so the goal is to be generating code on the fly which works with the existing runtime in the compiler. I can move this to a separate ticket if that's preferred. You probably have compiled your code base with -fno-rtti (or exceptions) and you should pass that flag to cling as well.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10294#issuecomment-1193060626
Usability,simpl,simplest,"> Ok, got it. I commented that out and have been proceeding to test things out. I've hit an issue when trying to embed cling into my project and I've boiled it down to the simplest test case I can here: https://github.com/jeaye/cling-linkage-error-test-case; > ; > Is this expected behavior? If so, how can I have cling be able to work with all of the (mangled) symbols which are in my program? I'm trying to use cling as an embedded JIT in my own language's compiler, so the goal is to be generating code on the fly which works with the existing runtime in the compiler. I can move this to a separate ticket if that's preferred. You probably have compiled your code base with -fno-rtti (or exceptions) and you should pass that flag to cling as well.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10294#issuecomment-1193060626
Availability,down,down,"> > Ok, got it. I commented that out and have been proceeding to test things out. I've hit an issue when trying to embed cling into my project and I've boiled it down to the simplest test case I can here: https://github.com/jeaye/cling-linkage-error-test-case; > > Is this expected behavior? If so, how can I have cling be able to work with all of the (mangled) symbols which are in my program? I'm trying to use cling as an embedded JIT in my own language's compiler, so the goal is to be generating code on the fly which works with the existing runtime in the compiler. I can move this to a separate ticket if that's preferred.; > ; > You probably have compiled your code base with -fno-rtti (or exceptions) and you should pass that flag to cling as well. Unfortunately, the only flags I've passed are `-std=c++17`, `-I`, `-L`, and some `-l`. The full command is shown in the readme. Should this work automatically or do I need to do more to expose these symbols to clang?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10294#issuecomment-1193060988
Security,expose,expose,"> > Ok, got it. I commented that out and have been proceeding to test things out. I've hit an issue when trying to embed cling into my project and I've boiled it down to the simplest test case I can here: https://github.com/jeaye/cling-linkage-error-test-case; > > Is this expected behavior? If so, how can I have cling be able to work with all of the (mangled) symbols which are in my program? I'm trying to use cling as an embedded JIT in my own language's compiler, so the goal is to be generating code on the fly which works with the existing runtime in the compiler. I can move this to a separate ticket if that's preferred.; > ; > You probably have compiled your code base with -fno-rtti (or exceptions) and you should pass that flag to cling as well. Unfortunately, the only flags I've passed are `-std=c++17`, `-I`, `-L`, and some `-l`. The full command is shown in the readme. Should this work automatically or do I need to do more to expose these symbols to clang?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10294#issuecomment-1193060988
Testability,test,test,"> > Ok, got it. I commented that out and have been proceeding to test things out. I've hit an issue when trying to embed cling into my project and I've boiled it down to the simplest test case I can here: https://github.com/jeaye/cling-linkage-error-test-case; > > Is this expected behavior? If so, how can I have cling be able to work with all of the (mangled) symbols which are in my program? I'm trying to use cling as an embedded JIT in my own language's compiler, so the goal is to be generating code on the fly which works with the existing runtime in the compiler. I can move this to a separate ticket if that's preferred.; > ; > You probably have compiled your code base with -fno-rtti (or exceptions) and you should pass that flag to cling as well. Unfortunately, the only flags I've passed are `-std=c++17`, `-I`, `-L`, and some `-l`. The full command is shown in the readme. Should this work automatically or do I need to do more to expose these symbols to clang?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10294#issuecomment-1193060988
Usability,simpl,simplest,"> > Ok, got it. I commented that out and have been proceeding to test things out. I've hit an issue when trying to embed cling into my project and I've boiled it down to the simplest test case I can here: https://github.com/jeaye/cling-linkage-error-test-case; > > Is this expected behavior? If so, how can I have cling be able to work with all of the (mangled) symbols which are in my program? I'm trying to use cling as an embedded JIT in my own language's compiler, so the goal is to be generating code on the fly which works with the existing runtime in the compiler. I can move this to a separate ticket if that's preferred.; > ; > You probably have compiled your code base with -fno-rtti (or exceptions) and you should pass that flag to cling as well. Unfortunately, the only flags I've passed are `-std=c++17`, `-I`, `-L`, and some `-l`. The full command is shown in the readme. Should this work automatically or do I need to do more to expose these symbols to clang?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10294#issuecomment-1193060988
Availability,down,down,"> > > Ok, got it. I commented that out and have been proceeding to test things out. I've hit an issue when trying to embed cling into my project and I've boiled it down to the simplest test case I can here: https://github.com/jeaye/cling-linkage-error-test-case; > > > Is this expected behavior? If so, how can I have cling be able to work with all of the (mangled) symbols which are in my program? I'm trying to use cling as an embedded JIT in my own language's compiler, so the goal is to be generating code on the fly which works with the existing runtime in the compiler. I can move this to a separate ticket if that's preferred.; > > ; > > ; > > You probably have compiled your code base with -fno-rtti (or exceptions) and you should pass that flag to cling as well.; > ; > Unfortunately, the only flags I've passed are `-std=c++17`, `-I`, `-L`, and some `-l`. The full command is shown in the readme. Should this work automatically or do I need to do more to expose these symbols to clang?. Can you add to cling -fno-rtti? I dont think this can be done automatically it is not automatic for compilers as well.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10294#issuecomment-1193095859
Security,expose,expose,"> > > Ok, got it. I commented that out and have been proceeding to test things out. I've hit an issue when trying to embed cling into my project and I've boiled it down to the simplest test case I can here: https://github.com/jeaye/cling-linkage-error-test-case; > > > Is this expected behavior? If so, how can I have cling be able to work with all of the (mangled) symbols which are in my program? I'm trying to use cling as an embedded JIT in my own language's compiler, so the goal is to be generating code on the fly which works with the existing runtime in the compiler. I can move this to a separate ticket if that's preferred.; > > ; > > ; > > You probably have compiled your code base with -fno-rtti (or exceptions) and you should pass that flag to cling as well.; > ; > Unfortunately, the only flags I've passed are `-std=c++17`, `-I`, `-L`, and some `-l`. The full command is shown in the readme. Should this work automatically or do I need to do more to expose these symbols to clang?. Can you add to cling -fno-rtti? I dont think this can be done automatically it is not automatic for compilers as well.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10294#issuecomment-1193095859
Testability,test,test,"> > > Ok, got it. I commented that out and have been proceeding to test things out. I've hit an issue when trying to embed cling into my project and I've boiled it down to the simplest test case I can here: https://github.com/jeaye/cling-linkage-error-test-case; > > > Is this expected behavior? If so, how can I have cling be able to work with all of the (mangled) symbols which are in my program? I'm trying to use cling as an embedded JIT in my own language's compiler, so the goal is to be generating code on the fly which works with the existing runtime in the compiler. I can move this to a separate ticket if that's preferred.; > > ; > > ; > > You probably have compiled your code base with -fno-rtti (or exceptions) and you should pass that flag to cling as well.; > ; > Unfortunately, the only flags I've passed are `-std=c++17`, `-I`, `-L`, and some `-l`. The full command is shown in the readme. Should this work automatically or do I need to do more to expose these symbols to clang?. Can you add to cling -fno-rtti? I dont think this can be done automatically it is not automatic for compilers as well.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10294#issuecomment-1193095859
Usability,simpl,simplest,"> > > Ok, got it. I commented that out and have been proceeding to test things out. I've hit an issue when trying to embed cling into my project and I've boiled it down to the simplest test case I can here: https://github.com/jeaye/cling-linkage-error-test-case; > > > Is this expected behavior? If so, how can I have cling be able to work with all of the (mangled) symbols which are in my program? I'm trying to use cling as an embedded JIT in my own language's compiler, so the goal is to be generating code on the fly which works with the existing runtime in the compiler. I can move this to a separate ticket if that's preferred.; > > ; > > ; > > You probably have compiled your code base with -fno-rtti (or exceptions) and you should pass that flag to cling as well.; > ; > Unfortunately, the only flags I've passed are `-std=c++17`, `-I`, `-L`, and some `-l`. The full command is shown in the readme. Should this work automatically or do I need to do more to expose these symbols to clang?. Can you add to cling -fno-rtti? I dont think this can be done automatically it is not automatic for compilers as well.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10294#issuecomment-1193095859
Testability,test,tests,Build failed on ROOT-debian10-i386/soversion.; Running on pcepsft10.dyndns.cern.ch:/build/workspace/root-pullrequests-build; [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/154244/console).; ### Warnings:; - [2022-09-13T17:42:54.005Z] Warning in &lt;CheckModuleValid&gt;: warning: Couldn't find in the following specified headers in the module Core: ; - [2022-09-13T17:43:20.121Z] Warning in &lt;CheckModuleValid&gt;: warning: Couldn't find in the following specified headers in the module Thread: . ### Failing tests:; - [projectroot.test.test_stressmathcore_interpreted](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/154244/testReport/projectroot/test/test_stressmathcore_interpreted/); - [projectroot.roottest.cling.offset.roottest_cling_offset_interpreted](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/154244/testReport/projectroot.roottest.cling/offset/roottest_cling_offset_interpreted/); - [projectroot.roottest.cling.other.roottest_cling_other_execValuePrint](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/154244/testReport/projectroot.roottest.cling/other/roottest_cling_other_execValuePrint/); - [projectroot.roottest.root.meta.dictSelection.roottest_root_meta_dictSelection_execAtlasTest2](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/154244/testReport/projectroot.roottest.root.meta/dictSelection/roottest_root_meta_dictSelection_execAtlasTest2/); - [projectroot.roottest.root.selector.simple.roottest_root_selector_simple_runtestLoadingSelector](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/154244/testReport/projectroot.roottest.root.selector/simple/roottest_root_selector_simple_runtestLoadingSelector/); - [projectroot.roottest.root.tree.selector.roottest_root_tree_selector_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/154244/testReport/projectroot.roottest.root.tre,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10294#issuecomment-1245798559
Usability,simpl,simple,e Thread: . ### Failing tests:; - [projectroot.test.test_stressmathcore_interpreted](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/154244/testReport/projectroot/test/test_stressmathcore_interpreted/); - [projectroot.roottest.cling.offset.roottest_cling_offset_interpreted](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/154244/testReport/projectroot.roottest.cling/offset/roottest_cling_offset_interpreted/); - [projectroot.roottest.cling.other.roottest_cling_other_execValuePrint](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/154244/testReport/projectroot.roottest.cling/other/roottest_cling_other_execValuePrint/); - [projectroot.roottest.root.meta.dictSelection.roottest_root_meta_dictSelection_execAtlasTest2](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/154244/testReport/projectroot.roottest.root.meta/dictSelection/roottest_root_meta_dictSelection_execAtlasTest2/); - [projectroot.roottest.root.selector.simple.roottest_root_selector_simple_runtestLoadingSelector](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/154244/testReport/projectroot.roottest.root.selector/simple/roottest_root_selector_simple_runtestLoadingSelector/); - [projectroot.roottest.root.tree.selector.roottest_root_tree_selector_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/154244/testReport/projectroot.roottest.root.tree/selector/roottest_root_tree_selector_make/); - [projectroot.roottest.root.tree.reader.roottest_root_tree_reader_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/154244/testReport/projectroot.roottest.root.tree/reader/roottest_root_tree_reader_make/); - [projectroot.roottest.root.treeformula.stl.roottest_root_treeformula_stl_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/154244/testReport/projectroot.roottest.root.treeformula/stl/roottest_root_treeformula_stl_make/),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10294#issuecomment-1245798559
Testability,test,test,"Yeah, I wrote those docs :sweat_smile: but I am not sure they should say ""stored as 64 bit"". @pcanal I guess we can fix this test such that writing and reading back a `Long_t` leaf works correctly both on 32bit and 64bit architectures, but what happens when you write that data on a 64bit machine and read it on a 32bit machine or vice-versa?. @ellert in this test we really want to test `long int` support (see be6a62ee84317), so I think the appropriate fix would be to simply use a smaller value than the current `2^33` on 32bit machines, rather than switching to `long long`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10302#issuecomment-1091685848
Usability,simpl,simply,"Yeah, I wrote those docs :sweat_smile: but I am not sure they should say ""stored as 64 bit"". @pcanal I guess we can fix this test such that writing and reading back a `Long_t` leaf works correctly both on 32bit and 64bit architectures, but what happens when you write that data on a 64bit machine and read it on a 32bit machine or vice-versa?. @ellert in this test we really want to test `long int` support (see be6a62ee84317), so I think the appropriate fix would be to simply use a smaller value than the current `2^33` on 32bit machines, rather than switching to `long long`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10302#issuecomment-1091685848
Usability,simpl,simply,"> so I think the appropriate fix would be to simply use a smaller value than the current 2^33 on 32bit machines, rather than switching to long long. I agree.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10302#issuecomment-1092976574
Usability,clear,clear,"That is a good point that I overlooked. The case I was thinking of instead was the question of distinct files opened by distinct threads whose objects might reference the file. [In the case you describe, it is not clear how much it matters which of the TFile instance with the same uuid is being used when following a reference (as they are semantically equivalent] [Actually it might matter for lifetime issues ... ;( ]",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10318#issuecomment-1090957110
Availability,avail,available,"> AFAIK the new autoloading is not available for COFF?; > ; > Do we understand (as in reproduced and debugged) where the original issue is coming from? Let's _first_ do that and _then_ try to repair, please. We do have coff support in symbol resolution and it is default already: https://github.com/vgvassilev/cling/blob/329af99e47a39526df49c27abd10d3306fbc7c9b/lib/Interpreter/DynamicLibraryManagerSymbol.cpp#L933. I think there is a pretty clear explanation where this comes from in the commit history. We could not load `gRandom`. That was with the very old dyld-based approach to loading symbols. This PR checks if the new approach has the same problem.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10330#issuecomment-1089868124
Performance,load,load,"> AFAIK the new autoloading is not available for COFF?; > ; > Do we understand (as in reproduced and debugged) where the original issue is coming from? Let's _first_ do that and _then_ try to repair, please. We do have coff support in symbol resolution and it is default already: https://github.com/vgvassilev/cling/blob/329af99e47a39526df49c27abd10d3306fbc7c9b/lib/Interpreter/DynamicLibraryManagerSymbol.cpp#L933. I think there is a pretty clear explanation where this comes from in the commit history. We could not load `gRandom`. That was with the very old dyld-based approach to loading symbols. This PR checks if the new approach has the same problem.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10330#issuecomment-1089868124
Usability,clear,clear,"> AFAIK the new autoloading is not available for COFF?; > ; > Do we understand (as in reproduced and debugged) where the original issue is coming from? Let's _first_ do that and _then_ try to repair, please. We do have coff support in symbol resolution and it is default already: https://github.com/vgvassilev/cling/blob/329af99e47a39526df49c27abd10d3306fbc7c9b/lib/Interpreter/DynamicLibraryManagerSymbol.cpp#L933. I think there is a pretty clear explanation where this comes from in the commit history. We could not load `gRandom`. That was with the very old dyld-based approach to loading symbols. This PR checks if the new approach has the same problem.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10330#issuecomment-1089868124
Availability,failure,failure,"> I think there is a pretty clear explanation where this comes from in the commit history. We could not load `gRandom`. That was with the very old dyld-based approach to loading symbols. This PR checks if the new approach has the same problem. Note that:; - We can still not reproduce the issue; - With this change, I got the following test failure on Windows (not tested in our CI):; ```; 988: Processing C:/Users/sftnight/git/master/tutorials/rcanvas/symlog.cxx...; 988: IncrementalExecutor::executeFunction: symbol '_imp_?gRandom@@3PAVTRandom@@A' unresolved while linking function '_GLOBAL__sub_I_cling_module_5'!; 988: You are probably missing the definition of _imp_?gRandom@@3PAVTRandom@@A; 988: Maybe you need to load the corresponding shared library?; ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10330#issuecomment-1091405727
Performance,load,load,"> I think there is a pretty clear explanation where this comes from in the commit history. We could not load `gRandom`. That was with the very old dyld-based approach to loading symbols. This PR checks if the new approach has the same problem. Note that:; - We can still not reproduce the issue; - With this change, I got the following test failure on Windows (not tested in our CI):; ```; 988: Processing C:/Users/sftnight/git/master/tutorials/rcanvas/symlog.cxx...; 988: IncrementalExecutor::executeFunction: symbol '_imp_?gRandom@@3PAVTRandom@@A' unresolved while linking function '_GLOBAL__sub_I_cling_module_5'!; 988: You are probably missing the definition of _imp_?gRandom@@3PAVTRandom@@A; 988: Maybe you need to load the corresponding shared library?; ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10330#issuecomment-1091405727
Testability,test,test,"> I think there is a pretty clear explanation where this comes from in the commit history. We could not load `gRandom`. That was with the very old dyld-based approach to loading symbols. This PR checks if the new approach has the same problem. Note that:; - We can still not reproduce the issue; - With this change, I got the following test failure on Windows (not tested in our CI):; ```; 988: Processing C:/Users/sftnight/git/master/tutorials/rcanvas/symlog.cxx...; 988: IncrementalExecutor::executeFunction: symbol '_imp_?gRandom@@3PAVTRandom@@A' unresolved while linking function '_GLOBAL__sub_I_cling_module_5'!; 988: You are probably missing the definition of _imp_?gRandom@@3PAVTRandom@@A; 988: Maybe you need to load the corresponding shared library?; ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10330#issuecomment-1091405727
Usability,clear,clear,"> I think there is a pretty clear explanation where this comes from in the commit history. We could not load `gRandom`. That was with the very old dyld-based approach to loading symbols. This PR checks if the new approach has the same problem. Note that:; - We can still not reproduce the issue; - With this change, I got the following test failure on Windows (not tested in our CI):; ```; 988: Processing C:/Users/sftnight/git/master/tutorials/rcanvas/symlog.cxx...; 988: IncrementalExecutor::executeFunction: symbol '_imp_?gRandom@@3PAVTRandom@@A' unresolved while linking function '_GLOBAL__sub_I_cling_module_5'!; 988: You are probably missing the definition of _imp_?gRandom@@3PAVTRandom@@A; 988: Maybe you need to load the corresponding shared library?; ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10330#issuecomment-1091405727
Integrability,wrap,wrapper,"Thanks for the review @eguiraud , regarding :. > the _extra_args relay logic could be documented a bit better (I'm not sure MethodTemplateWrapper's init method needs to take extra_args as argument, but MethodTemplateGetter's docs should mention that the extra_args are passed when constructing the wrapper_class instance. I think this is already clear enough in the docs of `__get__` in `MethodTemplateGetter`:; ```; Returns:; instance of MethodTemplateWrapper subclass: contains a handle to; the original implementation of the method template that is; bound to `instance` and, possibly, some extra arguments to be; used when receiving a call.; ```; also `_extra_args` is documented as:; ```; _extra_args (tuple): extra arguments to be used by the wrapper object; when receiving a call.; ```; And the extra args need to be passed when constructing the getter, so they can be passed to the wrapper (the user that is pythonizing a class only deals with the getter).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10341#issuecomment-1094750476
Testability,log,logic,"Thanks for the review @eguiraud , regarding :. > the _extra_args relay logic could be documented a bit better (I'm not sure MethodTemplateWrapper's init method needs to take extra_args as argument, but MethodTemplateGetter's docs should mention that the extra_args are passed when constructing the wrapper_class instance. I think this is already clear enough in the docs of `__get__` in `MethodTemplateGetter`:; ```; Returns:; instance of MethodTemplateWrapper subclass: contains a handle to; the original implementation of the method template that is; bound to `instance` and, possibly, some extra arguments to be; used when receiving a call.; ```; also `_extra_args` is documented as:; ```; _extra_args (tuple): extra arguments to be used by the wrapper object; when receiving a call.; ```; And the extra args need to be passed when constructing the getter, so they can be passed to the wrapper (the user that is pythonizing a class only deals with the getter).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10341#issuecomment-1094750476
Usability,clear,clear,"Thanks for the review @eguiraud , regarding :. > the _extra_args relay logic could be documented a bit better (I'm not sure MethodTemplateWrapper's init method needs to take extra_args as argument, but MethodTemplateGetter's docs should mention that the extra_args are passed when constructing the wrapper_class instance. I think this is already clear enough in the docs of `__get__` in `MethodTemplateGetter`:; ```; Returns:; instance of MethodTemplateWrapper subclass: contains a handle to; the original implementation of the method template that is; bound to `instance` and, possibly, some extra arguments to be; used when receiving a call.; ```; also `_extra_args` is documented as:; ```; _extra_args (tuple): extra arguments to be used by the wrapper object; when receiving a call.; ```; And the extra args need to be passed when constructing the getter, so they can be passed to the wrapper (the user that is pythonizing a class only deals with the getter).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10341#issuecomment-1094750476
Integrability,wrap,wrapper,"> I think this is already clear enough. To the person that wrote the code i'm sure it is! :smile: Concretely maybe ""extra arguments to be used by the wrapper object when receiving a call."" could be e.g. ""extra arguments that will be forwarded to `_wrapper_class`'s init method""?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10341#issuecomment-1094768654
Usability,clear,clear,"> I think this is already clear enough. To the person that wrote the code i'm sure it is! :smile: Concretely maybe ""extra arguments to be used by the wrapper object when receiving a call."" could be e.g. ""extra arguments that will be forwarded to `_wrapper_class`'s init method""?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10341#issuecomment-1094768654
Testability,log,logic,"> I can imagine that we can make change this function to return a string and then call it when we called the `.gh` command?. Sounds great, as long as the 'stacktrace' logic does not clear it internally, once it has printed it to terminal before calling `.gh bug`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10366#issuecomment-1122636569
Usability,clear,clear,"> I can imagine that we can make change this function to return a string and then call it when we called the `.gh` command?. Sounds great, as long as the 'stacktrace' logic does not clear it internally, once it has printed it to terminal before calling `.gh bug`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10366#issuecomment-1122636569
Usability,feedback,feedback,Thanks for the feedback! Then it looks ready to me :),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10366#issuecomment-1219758325
Usability,clear,clear,"We are probably missing an I/O rule along the line of; ```; #pragma read sourceClass=""TNDArrayT<float>"" targetClass=""TNDArrayT<float>"" source=""Int_t fNumData; float *fData;"" target=""fData"" versions=""1"" code=""{ fData.clear(); for(int i = 0; i < onfile.fNumData; ++i) fData.push_back(onfile.fData[i]); }""; ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10382#issuecomment-1096759521
Usability,guid,guide,"Exactly, It looks like a bug in `nbconvert`. This polite the ref guide build.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10428#issuecomment-1105055702
Availability,error,erroring,"Hi, thanks for pointing out that this clipping is inconsistent with the TTree version! And thanks for the kind words!. I designed the numpy version to be consistent with filling a RooDataSet one-by-one with `RooDataSet::add()`, in which case the value is clipped. That's a general problem in RooFit, many ways to do the same thing and they behave inconsistently. However, I think both clipping and skipping can be very dangerous. I'm about to change the behavior to simply erroring out when the values are not in the range, with the possibility to manually change that behavior to skipping or clipping if desired. Like that, there are no bad surprises. Any thoughts on that?. This issue is related to https://github.com/root-project/root/issues/6937. Probably I will address them together in one PR.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10447#issuecomment-1110865265
Usability,simpl,simply,"Hi, thanks for pointing out that this clipping is inconsistent with the TTree version! And thanks for the kind words!. I designed the numpy version to be consistent with filling a RooDataSet one-by-one with `RooDataSet::add()`, in which case the value is clipped. That's a general problem in RooFit, many ways to do the same thing and they behave inconsistently. However, I think both clipping and skipping can be very dangerous. I'm about to change the behavior to simply erroring out when the values are not in the range, with the possibility to manually change that behavior to skipping or clipping if desired. Like that, there are no bad surprises. Any thoughts on that?. This issue is related to https://github.com/root-project/root/issues/6937. Probably I will address them together in one PR.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10447#issuecomment-1110865265
Availability,error,erroring,"> However, I think both clipping and skipping can be very dangerous. I'm about to change the behavior to simply erroring out when the values are not in the range, with the possibility to manually change that behavior to skipping or clipping if desired. Like that, there are no bad surprises. Any thoughts on that?. That sounds very reasonable. I would have intuitively assumed that the values are skipped, but if the clipping behavior also exists in the interface others might have assume that. Then it's probably best to force the users to decide.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10447#issuecomment-1110909383
Integrability,interface,interface,"> However, I think both clipping and skipping can be very dangerous. I'm about to change the behavior to simply erroring out when the values are not in the range, with the possibility to manually change that behavior to skipping or clipping if desired. Like that, there are no bad surprises. Any thoughts on that?. That sounds very reasonable. I would have intuitively assumed that the values are skipped, but if the clipping behavior also exists in the interface others might have assume that. Then it's probably best to force the users to decide.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10447#issuecomment-1110909383
Usability,simpl,simply,"> However, I think both clipping and skipping can be very dangerous. I'm about to change the behavior to simply erroring out when the values are not in the range, with the possibility to manually change that behavior to skipping or clipping if desired. Like that, there are no bad surprises. Any thoughts on that?. That sounds very reasonable. I would have intuitively assumed that the values are skipped, but if the clipping behavior also exists in the interface others might have assume that. Then it's probably best to force the users to decide.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10447#issuecomment-1110909383
Usability,clear,clearly,"No, I do not know. That's the bin center clearly. Why was it shifted? I do not know.; But it fixes the problem and other examples work too.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10480#issuecomment-1112122353
Testability,log,logging,"Actually, it's probably not a good idea to introduce this progress bar, because it will break the logging to files, which is done a lot in batch jobs. Hence, I close this PR, which is superseded by another PR:; * https://github.com/root-project/root/pull/14309",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10509#issuecomment-1881730104
Usability,progress bar,progress bar,"Actually, it's probably not a good idea to introduce this progress bar, because it will break the logging to files, which is done a lot in batch jobs. Hence, I close this PR, which is superseded by another PR:; * https://github.com/root-project/root/pull/14309",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10509#issuecomment-1881730104
Availability,error,error,"I've been able to get somewhere but now I need guidance. I created a `dict.modulemap` file:; ```; module dict {; header ""MyClass.h""; header ""OtherClass.h""; export *; }; ```; and the module-aware dictionary:; ```bash; $ ls; LinkDef.h MyClass.h OtherClass.h dict.modulemap; $ rootcling -cxxmodule -f dict.cpp MyClass.h OtherClass.h -moduleMapFile=dict.modulemap LinkDef.h; $ ls; LinkDef.h MyClass.h OtherClass.h dict.cpp dict.modulemap dict.pcm dict_rdict.pcm; $ g++ -shared -std=c++14 -fPIC -I$ROOTSYS/include dict.cpp -o libDict.so ; $ ls; LinkDef.h MyClass.h OtherClass.h dict.cpp dict.modulemap dict.pcm dict_rdict.pcm libDict.so; ```; but I cannot load the dictionary on the root shell:; ```; $ root; root [0] .L libDict.so ; Module dict not found.; ```; I put `$PWD` in `LD_LIBRARY_PATH` and `ROOT_INCLUDE_PATH` but the error is still there.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10512#issuecomment-1149766446
Performance,load,load,"I've been able to get somewhere but now I need guidance. I created a `dict.modulemap` file:; ```; module dict {; header ""MyClass.h""; header ""OtherClass.h""; export *; }; ```; and the module-aware dictionary:; ```bash; $ ls; LinkDef.h MyClass.h OtherClass.h dict.modulemap; $ rootcling -cxxmodule -f dict.cpp MyClass.h OtherClass.h -moduleMapFile=dict.modulemap LinkDef.h; $ ls; LinkDef.h MyClass.h OtherClass.h dict.cpp dict.modulemap dict.pcm dict_rdict.pcm; $ g++ -shared -std=c++14 -fPIC -I$ROOTSYS/include dict.cpp -o libDict.so ; $ ls; LinkDef.h MyClass.h OtherClass.h dict.cpp dict.modulemap dict.pcm dict_rdict.pcm libDict.so; ```; but I cannot load the dictionary on the root shell:; ```; $ root; root [0] .L libDict.so ; Module dict not found.; ```; I put `$PWD` in `LD_LIBRARY_PATH` and `ROOT_INCLUDE_PATH` but the error is still there.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10512#issuecomment-1149766446
Usability,guid,guidance,"I've been able to get somewhere but now I need guidance. I created a `dict.modulemap` file:; ```; module dict {; header ""MyClass.h""; header ""OtherClass.h""; export *; }; ```; and the module-aware dictionary:; ```bash; $ ls; LinkDef.h MyClass.h OtherClass.h dict.modulemap; $ rootcling -cxxmodule -f dict.cpp MyClass.h OtherClass.h -moduleMapFile=dict.modulemap LinkDef.h; $ ls; LinkDef.h MyClass.h OtherClass.h dict.cpp dict.modulemap dict.pcm dict_rdict.pcm; $ g++ -shared -std=c++14 -fPIC -I$ROOTSYS/include dict.cpp -o libDict.so ; $ ls; LinkDef.h MyClass.h OtherClass.h dict.cpp dict.modulemap dict.pcm dict_rdict.pcm libDict.so; ```; but I cannot load the dictionary on the root shell:; ```; $ root; root [0] .L libDict.so ; Module dict not found.; ```; I put `$PWD` in `LD_LIBRARY_PATH` and `ROOT_INCLUDE_PATH` but the error is still there.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10512#issuecomment-1149766446
Usability,feedback,feedback,"@dennisklein, thanks a lot for the quick feedback. @hahnjo, let's move forward with this then.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10529#issuecomment-1118610993
Usability,simpl,simple,"This is low priority, but I add more eyes to it: perhaps we can have a simple idea.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10535#issuecomment-1925606745
Usability,clear,clear,We have a clear path to deal with this behaviour.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10556#issuecomment-1968330234
Integrability,wrap,wrappers,"> We have a clear path to deal with this behaviour. Although there is a workaround, people hit by this bug will not necessarily know right away why their ROOT doesn't work and may waste their time trying to debug it. I think it's worth looking at a fix. It used to work before even with the compiler wrappers. Note also that the problem reported by @xkzl happens for a similar reason, but is not quite the same as the one reported here, as in https://github.com/root-project/root/issues/10556#issuecomment-1931464549 ccache is not involved.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10556#issuecomment-1968623162
Usability,clear,clear,"> We have a clear path to deal with this behaviour. Although there is a workaround, people hit by this bug will not necessarily know right away why their ROOT doesn't work and may waste their time trying to debug it. I think it's worth looking at a fix. It used to work before even with the compiler wrappers. Note also that the problem reported by @xkzl happens for a similar reason, but is not quite the same as the one reported here, as in https://github.com/root-project/root/issues/10556#issuecomment-1931464549 ccache is not involved.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10556#issuecomment-1968623162
Testability,benchmark,benchmark,"Hi @lmoneta and @hageboeck, thanks for the feedback!. I will open a PR in rootbench with a benchmark based on the hf001_example.C tutorial.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10562#issuecomment-1128075811
Usability,feedback,feedback,"Hi @lmoneta and @hageboeck, thanks for the feedback!. I will open a PR in rootbench with a benchmark based on the hf001_example.C tutorial.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10562#issuecomment-1128075811
Performance,cache,caches,"While the current behaviour is clearly a bug and needs to be fixed, I would also appreciate a workaround that I could use right now. Maybe there is some function/static method to call to clean up the global caches (if that is indeed a problem of caching).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10577#issuecomment-1126366016
Usability,clear,clearly,"While the current behaviour is clearly a bug and needs to be fixed, I would also appreciate a workaround that I could use right now. Maybe there is some function/static method to call to clean up the global caches (if that is indeed a problem of caching).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10577#issuecomment-1126366016
Performance,cache,caches,"Hi! I think the global caches are a bad idea, I'm still thinking of how to get rid of them without losing cache efficiency. For now, the workaround is to clear the global cache with:; ```C++; RooExpensiveObjectCache::instance().clearAll();; ```; Another solution is to use the RooWorkspace factory pattern to create your model, because then it uses a model local cache in the workspace that gets cleared when the workspace goes out of scope. Hope that helps for now!. edit 1: corrected ""mode local"" to ""model local""",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10577#issuecomment-1133924183
Usability,clear,clear,"Hi! I think the global caches are a bad idea, I'm still thinking of how to get rid of them without losing cache efficiency. For now, the workaround is to clear the global cache with:; ```C++; RooExpensiveObjectCache::instance().clearAll();; ```; Another solution is to use the RooWorkspace factory pattern to create your model, because then it uses a model local cache in the workspace that gets cleared when the workspace goes out of scope. Hope that helps for now!. edit 1: corrected ""mode local"" to ""model local""",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10577#issuecomment-1133924183
Usability,clear,clear,"> Thanks. Sounds like a good idea. Or maybe step and offset. (default 1 and 0). I prefer to set the ""start value"" it is more clear.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10588#issuecomment-1128913760
Usability,clear,clear,"Right, clear now. Thanks! This can be closed",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10640#issuecomment-1137195752
Usability,feedback,feedback,"Thanks. Would such a PR be likely to be accepted? I programmed other things involving histograms two years ago and did not get further feedback / revision (https://github.com/root-project/root/pull/8546) on how to proceed, thus I am not sure if I should embark in new PRs at the moment, until the others are solved.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10660#issuecomment-1464032410
Usability,intuit,intuitive,"`obj.ClassName()` is not only less verbose, but also doesn't require you to include `TClass.h`. Okay I see the point that one doesn't know if it is `obj.IsA()->GetName()` or `obj.Class()->GetName()`, but to be confused by this one needs to be a `TObject` expert why knows about the difference between `IsA()` and `Class()`. Without this prior knowledge, I think the behavior of `obj.ClassName()` to give the name of the derived class is very intuitive.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10670#issuecomment-1143539344
Availability,error,error,"@amadio , I have tested running the executable `tmva/sofie/test/emitFromONNX` on the machine directly. ; With the current master, I don't have the PCH dependency and I have : ; ```; sftnight@SFT-ubuntu-1804-2:/mnt/build/workspace/root-pullrequests-build/build/tmva/sofie/test$ rm ../../../etc/allDict.cxx.pch; sftnight@SFT-ubuntu-1804-2:/mnt/build/workspace/root-pullrequests-build/build/tmva/sofie/test$ ./emitFromONNX ; terminate called after throwing an instance of 'std::bad_alloc'; what(): std::bad_alloc; Aborted (core dumped); ```; with your PR I have instead: ; ```; sftnight@SFT-ubuntu-1804-3:/mnt/build/workspace/root-pullrequests-build/build/tmva/sofie/test$ ./emitFromONNX ; error: unable to read PCH file /mnt/build/workspace/root-pullrequests-build/build/etc//allDict.cxx.pch: 'No such file or directory'; fatal error: PCH file '/mnt/build/workspace/root-pullrequests-build/build/etc//allDict.cxx.pch' not found: module file not found; Segmentation fault (core dumped); ```. I think before merging, it would be nice to understand why after your changes in CMAKE affecting only libCore, a simple executable not using the ROOT I/O requires the PCH",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10690#issuecomment-1403728768
Integrability,depend,dependency,"@amadio , I have tested running the executable `tmva/sofie/test/emitFromONNX` on the machine directly. ; With the current master, I don't have the PCH dependency and I have : ; ```; sftnight@SFT-ubuntu-1804-2:/mnt/build/workspace/root-pullrequests-build/build/tmva/sofie/test$ rm ../../../etc/allDict.cxx.pch; sftnight@SFT-ubuntu-1804-2:/mnt/build/workspace/root-pullrequests-build/build/tmva/sofie/test$ ./emitFromONNX ; terminate called after throwing an instance of 'std::bad_alloc'; what(): std::bad_alloc; Aborted (core dumped); ```; with your PR I have instead: ; ```; sftnight@SFT-ubuntu-1804-3:/mnt/build/workspace/root-pullrequests-build/build/tmva/sofie/test$ ./emitFromONNX ; error: unable to read PCH file /mnt/build/workspace/root-pullrequests-build/build/etc//allDict.cxx.pch: 'No such file or directory'; fatal error: PCH file '/mnt/build/workspace/root-pullrequests-build/build/etc//allDict.cxx.pch' not found: module file not found; Segmentation fault (core dumped); ```. I think before merging, it would be nice to understand why after your changes in CMAKE affecting only libCore, a simple executable not using the ROOT I/O requires the PCH",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10690#issuecomment-1403728768
Testability,test,tested,"@amadio , I have tested running the executable `tmva/sofie/test/emitFromONNX` on the machine directly. ; With the current master, I don't have the PCH dependency and I have : ; ```; sftnight@SFT-ubuntu-1804-2:/mnt/build/workspace/root-pullrequests-build/build/tmva/sofie/test$ rm ../../../etc/allDict.cxx.pch; sftnight@SFT-ubuntu-1804-2:/mnt/build/workspace/root-pullrequests-build/build/tmva/sofie/test$ ./emitFromONNX ; terminate called after throwing an instance of 'std::bad_alloc'; what(): std::bad_alloc; Aborted (core dumped); ```; with your PR I have instead: ; ```; sftnight@SFT-ubuntu-1804-3:/mnt/build/workspace/root-pullrequests-build/build/tmva/sofie/test$ ./emitFromONNX ; error: unable to read PCH file /mnt/build/workspace/root-pullrequests-build/build/etc//allDict.cxx.pch: 'No such file or directory'; fatal error: PCH file '/mnt/build/workspace/root-pullrequests-build/build/etc//allDict.cxx.pch' not found: module file not found; Segmentation fault (core dumped); ```. I think before merging, it would be nice to understand why after your changes in CMAKE affecting only libCore, a simple executable not using the ROOT I/O requires the PCH",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10690#issuecomment-1403728768
Usability,simpl,simple,"@amadio , I have tested running the executable `tmva/sofie/test/emitFromONNX` on the machine directly. ; With the current master, I don't have the PCH dependency and I have : ; ```; sftnight@SFT-ubuntu-1804-2:/mnt/build/workspace/root-pullrequests-build/build/tmva/sofie/test$ rm ../../../etc/allDict.cxx.pch; sftnight@SFT-ubuntu-1804-2:/mnt/build/workspace/root-pullrequests-build/build/tmva/sofie/test$ ./emitFromONNX ; terminate called after throwing an instance of 'std::bad_alloc'; what(): std::bad_alloc; Aborted (core dumped); ```; with your PR I have instead: ; ```; sftnight@SFT-ubuntu-1804-3:/mnt/build/workspace/root-pullrequests-build/build/tmva/sofie/test$ ./emitFromONNX ; error: unable to read PCH file /mnt/build/workspace/root-pullrequests-build/build/etc//allDict.cxx.pch: 'No such file or directory'; fatal error: PCH file '/mnt/build/workspace/root-pullrequests-build/build/etc//allDict.cxx.pch' not found: module file not found; Segmentation fault (core dumped); ```. I think before merging, it would be nice to understand why after your changes in CMAKE affecting only libCore, a simple executable not using the ROOT I/O requires the PCH",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10690#issuecomment-1403728768
Availability,error,error,"@en. > Hi Ivan, thank you, I have some doubts about the changes:; > ; > * I don't think calling GetEntries more than once is actually expensive: the result is cached after the first call; > * the error message was listing the entry range in the usual start-inclusive/end-exclusive way (same as what happens in typical for loops), I'm not sure the patch is less ambiguous. Maybe we can say instead ""Start entry (X) must be lower than the available entries (Y). Ignoring entry range."".; > ; > Minor other thing, the commit message should use `[treereader]` insteadof `[DF]`. @eguiraud noted! This PR now only gives a clearer error message.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10705#issuecomment-1148590657
Deployability,patch,patch,"@en. > Hi Ivan, thank you, I have some doubts about the changes:; > ; > * I don't think calling GetEntries more than once is actually expensive: the result is cached after the first call; > * the error message was listing the entry range in the usual start-inclusive/end-exclusive way (same as what happens in typical for loops), I'm not sure the patch is less ambiguous. Maybe we can say instead ""Start entry (X) must be lower than the available entries (Y). Ignoring entry range."".; > ; > Minor other thing, the commit message should use `[treereader]` insteadof `[DF]`. @eguiraud noted! This PR now only gives a clearer error message.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10705#issuecomment-1148590657
Integrability,message,message,"@en. > Hi Ivan, thank you, I have some doubts about the changes:; > ; > * I don't think calling GetEntries more than once is actually expensive: the result is cached after the first call; > * the error message was listing the entry range in the usual start-inclusive/end-exclusive way (same as what happens in typical for loops), I'm not sure the patch is less ambiguous. Maybe we can say instead ""Start entry (X) must be lower than the available entries (Y). Ignoring entry range."".; > ; > Minor other thing, the commit message should use `[treereader]` insteadof `[DF]`. @eguiraud noted! This PR now only gives a clearer error message.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10705#issuecomment-1148590657
Performance,cache,cached,"@en. > Hi Ivan, thank you, I have some doubts about the changes:; > ; > * I don't think calling GetEntries more than once is actually expensive: the result is cached after the first call; > * the error message was listing the entry range in the usual start-inclusive/end-exclusive way (same as what happens in typical for loops), I'm not sure the patch is less ambiguous. Maybe we can say instead ""Start entry (X) must be lower than the available entries (Y). Ignoring entry range."".; > ; > Minor other thing, the commit message should use `[treereader]` insteadof `[DF]`. @eguiraud noted! This PR now only gives a clearer error message.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10705#issuecomment-1148590657
Usability,clear,clearer,"@en. > Hi Ivan, thank you, I have some doubts about the changes:; > ; > * I don't think calling GetEntries more than once is actually expensive: the result is cached after the first call; > * the error message was listing the entry range in the usual start-inclusive/end-exclusive way (same as what happens in typical for loops), I'm not sure the patch is less ambiguous. Maybe we can say instead ""Start entry (X) must be lower than the available entries (Y). Ignoring entry range."".; > ; > Minor other thing, the commit message should use `[treereader]` insteadof `[DF]`. @eguiraud noted! This PR now only gives a clearer error message.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10705#issuecomment-1148590657
Usability,feedback,feedback,"> Very nice! A few nits, in particular whole line comments in the code should use the `//` style (which makes it easier to comment blocks including comments with `/* */`).; > ; > I leave the final approval up to @jalopezg-r00t. Thanks for the feedback and suggestions, @jblomer! Block comments will be used more judiciously from now on :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10720#issuecomment-1152096497
Usability,feedback,feedback,"> Thanks! Very nice work, @glmiotto :slightly_smiling_face:!; > ; > I have added some comments that we have to address before merging. Great feedback @jalopezg-r00t, thanks as always! I'll get right on it",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10720#issuecomment-1152255768
Usability,simpl,simple,"Hi Bertrand, what's the stacktrace for df017_vecOpsHEP.py? it's a very simple tutorial, so if that doesn't work i'm thinking no RDF program should work",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10721#issuecomment-1151021014
Availability,error,error,"> Hi Bertrand, what's the stacktrace for df017_vecOpsHEP.py? it's a very simple tutorial, so if that doesn't work i'm thinking no RDF program should work. `error code: Exit code 0xc0000374`",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10721#issuecomment-1151028323
Usability,simpl,simple,"> Hi Bertrand, what's the stacktrace for df017_vecOpsHEP.py? it's a very simple tutorial, so if that doesn't work i'm thinking no RDF program should work. `error code: Exit code 0xc0000374`",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10721#issuecomment-1151028323
Usability,guid,guide,That's the user's guide... it is deprecated ... you should not use it.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10722#issuecomment-1151073680
Availability,error,error-in-thisroot-csh-during-installation,"> That's the user's guide... it is deprecated ... you should not use it. Hi, I am not using it, but forum users are doing, see https://root-forum.cern.ch/t/syntax-error-in-thisroot-csh-during-installation/50312/4?u=ferhue. So my suggestion is to put a big label on top informing anyone that it is deprecated. The results still appear when googling, so it seems useful to add some deprecated mark",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10722#issuecomment-1151136310
Deployability,install,installation,"> That's the user's guide... it is deprecated ... you should not use it. Hi, I am not using it, but forum users are doing, see https://root-forum.cern.ch/t/syntax-error-in-thisroot-csh-during-installation/50312/4?u=ferhue. So my suggestion is to put a big label on top informing anyone that it is deprecated. The results still appear when googling, so it seems useful to add some deprecated mark",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10722#issuecomment-1151136310
Usability,guid,guide,"> That's the user's guide... it is deprecated ... you should not use it. Hi, I am not using it, but forum users are doing, see https://root-forum.cern.ch/t/syntax-error-in-thisroot-csh-during-installation/50312/4?u=ferhue. So my suggestion is to put a big label on top informing anyone that it is deprecated. The results still appear when googling, so it seems useful to add some deprecated mark",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10722#issuecomment-1151136310
Usability,guid,guide,"> By the way, from the new ROOT website, I do not see what is the clicks-series leading to the Old Users Guide. Yes, it seems the problem arises mainly when googling. The first two results lead you to the deprecated users guide. ![image](https://user-images.githubusercontent.com/10653970/172875715-28ccea27-c989-4658-80e8-7ef7bcb437ea.png)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10722#issuecomment-1151216488
Usability,guid,guide,"> Yes, it seems the problem arises mainly when googling. The first two results lead you to the deprecated users guide. We need to watermark them in that case.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10722#issuecomment-1151221786
Usability,clear,clear,"Ok, thank you! It is clear now",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10740#issuecomment-1153930628
Integrability,rout,routine,"With the following changes; ```; diff --git a/bindings/pyroot/pythonizations/python/ROOT/__init__.py b/bindings/pyroot/pythonizations/python/ROOT/__init__.py; index 52d23a6fc3..790432eb3d 100644; --- a/bindings/pyroot/pythonizations/python/ROOT/__init__.py; +++ b/bindings/pyroot/pythonizations/python/ROOT/__init__.py; @@ -79,6 +79,7 @@ def cleanup():; # Hard teardown: run part of the gROOT shutdown sequence.; # Running it here ensures that it is done before any ROOT libraries; # are off-loaded, with unspecified order of static object destruction.; + print(""Calling EndOfProcessCleanups from __init__.py""); backend.gROOT.EndOfProcessCleanups(); ; atexit.register(cleanup); diff --git a/core/base/src/TApplication.cxx b/core/base/src/TApplication.cxx; index 8bdaa03f8d..9a02160611 100644; --- a/core/base/src/TApplication.cxx; +++ b/core/base/src/TApplication.cxx; @@ -86,6 +86,7 @@ static void CallEndOfProcessCleanups(); // set gROOT in its end-of-life mode which prevents executing code, like; // autoloading libraries (!) that is pointless ...; if (gROOT) {; + std::cout << ""Calling EndOfProcessCleanups from TApplication\n"";; gROOT->SetBit(kInvalidObject);; gROOT->EndOfProcessCleanups();; }; ```. I get this; ```; $: python -c ""import ROOT""; Calling EndOfProcessCleanups from __init__.py; $: python -c ""import ROOT; ROOT.TH1F""; Calling EndOfProcessCleanups from __init__.py; Calling EndOfProcessCleanups from TApplication; ```. i.e. it looks to me that as long as anything is done in the PyROOT application other than simply importing the module, the second cleanup routine is called at the end of the process (after the Python one). Either one of these should probably not be called",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10743#issuecomment-1154462514
Performance,load,loaded,"With the following changes; ```; diff --git a/bindings/pyroot/pythonizations/python/ROOT/__init__.py b/bindings/pyroot/pythonizations/python/ROOT/__init__.py; index 52d23a6fc3..790432eb3d 100644; --- a/bindings/pyroot/pythonizations/python/ROOT/__init__.py; +++ b/bindings/pyroot/pythonizations/python/ROOT/__init__.py; @@ -79,6 +79,7 @@ def cleanup():; # Hard teardown: run part of the gROOT shutdown sequence.; # Running it here ensures that it is done before any ROOT libraries; # are off-loaded, with unspecified order of static object destruction.; + print(""Calling EndOfProcessCleanups from __init__.py""); backend.gROOT.EndOfProcessCleanups(); ; atexit.register(cleanup); diff --git a/core/base/src/TApplication.cxx b/core/base/src/TApplication.cxx; index 8bdaa03f8d..9a02160611 100644; --- a/core/base/src/TApplication.cxx; +++ b/core/base/src/TApplication.cxx; @@ -86,6 +86,7 @@ static void CallEndOfProcessCleanups(); // set gROOT in its end-of-life mode which prevents executing code, like; // autoloading libraries (!) that is pointless ...; if (gROOT) {; + std::cout << ""Calling EndOfProcessCleanups from TApplication\n"";; gROOT->SetBit(kInvalidObject);; gROOT->EndOfProcessCleanups();; }; ```. I get this; ```; $: python -c ""import ROOT""; Calling EndOfProcessCleanups from __init__.py; $: python -c ""import ROOT; ROOT.TH1F""; Calling EndOfProcessCleanups from __init__.py; Calling EndOfProcessCleanups from TApplication; ```. i.e. it looks to me that as long as anything is done in the PyROOT application other than simply importing the module, the second cleanup routine is called at the end of the process (after the Python one). Either one of these should probably not be called",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10743#issuecomment-1154462514
Usability,simpl,simply,"With the following changes; ```; diff --git a/bindings/pyroot/pythonizations/python/ROOT/__init__.py b/bindings/pyroot/pythonizations/python/ROOT/__init__.py; index 52d23a6fc3..790432eb3d 100644; --- a/bindings/pyroot/pythonizations/python/ROOT/__init__.py; +++ b/bindings/pyroot/pythonizations/python/ROOT/__init__.py; @@ -79,6 +79,7 @@ def cleanup():; # Hard teardown: run part of the gROOT shutdown sequence.; # Running it here ensures that it is done before any ROOT libraries; # are off-loaded, with unspecified order of static object destruction.; + print(""Calling EndOfProcessCleanups from __init__.py""); backend.gROOT.EndOfProcessCleanups(); ; atexit.register(cleanup); diff --git a/core/base/src/TApplication.cxx b/core/base/src/TApplication.cxx; index 8bdaa03f8d..9a02160611 100644; --- a/core/base/src/TApplication.cxx; +++ b/core/base/src/TApplication.cxx; @@ -86,6 +86,7 @@ static void CallEndOfProcessCleanups(); // set gROOT in its end-of-life mode which prevents executing code, like; // autoloading libraries (!) that is pointless ...; if (gROOT) {; + std::cout << ""Calling EndOfProcessCleanups from TApplication\n"";; gROOT->SetBit(kInvalidObject);; gROOT->EndOfProcessCleanups();; }; ```. I get this; ```; $: python -c ""import ROOT""; Calling EndOfProcessCleanups from __init__.py; $: python -c ""import ROOT; ROOT.TH1F""; Calling EndOfProcessCleanups from __init__.py; Calling EndOfProcessCleanups from TApplication; ```. i.e. it looks to me that as long as anything is done in the PyROOT application other than simply importing the module, the second cleanup routine is called at the end of the process (after the Python one). Either one of these should probably not be called",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10743#issuecomment-1154462514
Modifiability,variab,variable,"It is old logic that `TBrowser` does not starts without `DISAPLAY` variable set or simply in batch mode.; One can solve this, but with some fine-tuning in ""normal"" `TBrowser`/`TBrowserImp` classes.; If @bellenot has nothing against it - I can propose PR.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10748#issuecomment-1159127875
Testability,log,logic,"It is old logic that `TBrowser` does not starts without `DISAPLAY` variable set or simply in batch mode.; One can solve this, but with some fine-tuning in ""normal"" `TBrowser`/`TBrowserImp` classes.; If @bellenot has nothing against it - I can propose PR.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10748#issuecomment-1159127875
Usability,simpl,simply,"It is old logic that `TBrowser` does not starts without `DISAPLAY` variable set or simply in batch mode.; One can solve this, but with some fine-tuning in ""normal"" `TBrowser`/`TBrowserImp` classes.; If @bellenot has nothing against it - I can propose PR.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10748#issuecomment-1159127875
Modifiability,variab,variable,"> It is old logic that `TBrowser` does not starts without `DISAPLAY` variable set or simply in batch mode. One can solve this, but with some fine-tuning in ""normal"" `TBrowser`/`TBrowserImp` classes. If @bellenot has nothing against it - I can propose PR. Thanks @linev ! Feel free to open a PR if you want ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10748#issuecomment-1159421157
Testability,log,logic,"> It is old logic that `TBrowser` does not starts without `DISAPLAY` variable set or simply in batch mode. One can solve this, but with some fine-tuning in ""normal"" `TBrowser`/`TBrowserImp` classes. If @bellenot has nothing against it - I can propose PR. Thanks @linev ! Feel free to open a PR if you want ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10748#issuecomment-1159421157
Usability,simpl,simply,"> It is old logic that `TBrowser` does not starts without `DISAPLAY` variable set or simply in batch mode. One can solve this, but with some fine-tuning in ""normal"" `TBrowser`/`TBrowserImp` classes. If @bellenot has nothing against it - I can propose PR. Thanks @linev ! Feel free to open a PR if you want ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10748#issuecomment-1159421157
Usability,simpl,simpler,"Thanks Vincenzo! I think the most important change in this PR is that PyROOT does not register the `EndOfProcessCleanups` call with _Python's_ atexit mechanism anymore, but it uses the classic handlers mechanism that `TApplication` already uses. And that means that now PyROOT objects will de deleted before `EndOfProcessCleanups` is called, which is an important change in behavior but I think it is the intended/correct behavior. I am not sure we need the combo `std::call_once` + `std::once_flag` data member, a static counter seems simpler and it does the job (unless we expect that TApplication and PyROOT could try to register the handler _concurrently_, but I can't imagine how that would happen). With this said I'm the least qualified person to decide on whether we want to go with this or not, I'll leave it to the other reviewers.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10753#issuecomment-1155283317
Usability,clear,cleared,"> Can we at least make EndOfProcessCleanups truly a no-op if it's not the first time it's been called? . Well, maybe, maybe not. If it is currently not a true no-op then it might be either. * (a bug) some list is not properly cleared; * (a feature) some items are added to the to-be-cleaned list between the 2 calls. > This should let Python call it before point (5) above, then when it's going to get called by the TApplication it won't bother RDF. . It *must* be called (by python) during point (1) (which maybe what you meant) and RDF should not be doing anything after (5) so it should *already* not bother RDF. But maybe I am missing something. I.e. is the second call to `EndOfProcessCleanups` a red-herring that 'just' looks suspicious and the problem is ""first call affecting RDF"" or is it really the 2nd call that is creating a problem.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10753#issuecomment-1155649950
Usability,simpl,simply,"@stephanlachnit I know you come from the Debian side, and I remember you have a private package of ROOT that builds successfully. Any idea what might go wrong on Ubuntu?. Otherwise I'm tempted to close this because it's basically not reproducible standalone, and I could simply argue it's a problem in the packaging system...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10777#issuecomment-1205188390
Deployability,release,release,"Hi Lorenzo, thank you for your feedback ! Do you know by any chance if this fix will be included in the next ROOT release? It is important for us to know if we should wait or implement some workaround in our project code.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10780#issuecomment-1160231233
Usability,feedback,feedback,"Hi Lorenzo, thank you for your feedback ! Do you know by any chance if this fix will be included in the next ROOT release? It is important for us to know if we should wait or implement some workaround in our project code.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10780#issuecomment-1160231233
Integrability,message,messages,@petrstepanov : Thank you for the contribution that now is merged!; I forgot to mention you that next time it would be better to merge together simple commits and have more meaningful commit log messages. ; Thanks again!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10780#issuecomment-1192647873
Testability,log,log,@petrstepanov : Thank you for the contribution that now is merged!; I forgot to mention you that next time it would be better to merge together simple commits and have more meaningful commit log messages. ; Thanks again!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10780#issuecomment-1192647873
Usability,simpl,simple,@petrstepanov : Thank you for the contribution that now is merged!; I forgot to mention you that next time it would be better to merge together simple commits and have more meaningful commit log messages. ; Thanks again!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10780#issuecomment-1192647873
Usability,simpl,simple,"A simple `interp.declare(""#pragma once"")` should be enough. The original case was a header that got embedded verbatim in a dictionary, through genreflex, iirc.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10826#issuecomment-1167247909
Usability,clear,clear,You can use `R` or `ATTRDUMP`. I just like the freedom we have of using more telling raw string delimiters than `R`. It's also not clear whether such a chance (from `ATTRDUMP` to `R`) is worth the churn.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10830#issuecomment-1168354018
Availability,avail,availability-swift,"> This should be ""upstreamable""; printing `int i [[deprecated(""reason\n"")]];` seems a valid test case. I doubt there's something I don't know, anyway by applying this patch, tests below in LLVM failed:; ```; Failed Tests (23): ; Clang :: AST/ast-dump-attr.cpp ; Clang :: AST/ast-dump-attr.m ; Clang :: AST/ast-dump-c-attr.c ; Clang :: AST/ast-dump-color.cpp ; Clang :: AST/ast-dump-wasm-attr-export.c ; Clang :: AST/ast-dump-wasm-attr-import.c ; Clang :: AST/ast-print-attr.c; Clang :: AST/attr-swift_attr.m; Clang :: AST/attr-swift_bridge.m; Clang :: AST/category-attribute.m; Clang :: AST/pragma-attribute-cxx-subject-match-rules.cpp; Clang :: AST/pragma-attribute-objc-subject-match-rules.m; Clang :: AST/pragma-multiple-attributes.cpp; Clang :: Misc/pragma-attribute-cxx.cpp; Clang :: Misc/pragma-attribute-objc.m; Clang :: Misc/pragma-attribute-strict-subjects.c; Clang :: OpenMP/assumes_codegen.cpp; Clang :: OpenMP/assumes_print.cpp; Clang :: OpenMP/assumes_template_print.cpp; Clang :: Sema/ast-print.c; Clang :: Sema/attr-availability-swift.c; Clang :: SemaCXX/cxx11-attr-print.cpp; Clang :: SemaTemplate/attributes.cpp; ```. A broken example like:; ```; /home/jun/dev/llvm-project/clang/test/AST/ast-print-attr.c:14:11: error: CHECK: expected string not found in input ; // CHECK: int fun_asm() asm(""test""); ; ^ ; <stdin>:3:46: note: scanning from here ; using C = int ((*))() __attribute__((cdecl)); ; ^ ; <stdin>:4:1: note: possible intended match here ; int fun_asm() asm(R""ATTRDUMP(test)ATTRDUMP""); ; ```. > You can use `R` or `ATTRDUMP`. I just like the freedom we have of using more telling raw string delimiters than `R`. It's also not clear whether such a chance (from `ATTRDUMP` to `R`) is worth the churn. So I guess if `R` is enough for ROOT, maybe we can drop `ATTRDUMP`?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10830#issuecomment-1168753106
Deployability,patch,patch,"> This should be ""upstreamable""; printing `int i [[deprecated(""reason\n"")]];` seems a valid test case. I doubt there's something I don't know, anyway by applying this patch, tests below in LLVM failed:; ```; Failed Tests (23): ; Clang :: AST/ast-dump-attr.cpp ; Clang :: AST/ast-dump-attr.m ; Clang :: AST/ast-dump-c-attr.c ; Clang :: AST/ast-dump-color.cpp ; Clang :: AST/ast-dump-wasm-attr-export.c ; Clang :: AST/ast-dump-wasm-attr-import.c ; Clang :: AST/ast-print-attr.c; Clang :: AST/attr-swift_attr.m; Clang :: AST/attr-swift_bridge.m; Clang :: AST/category-attribute.m; Clang :: AST/pragma-attribute-cxx-subject-match-rules.cpp; Clang :: AST/pragma-attribute-objc-subject-match-rules.m; Clang :: AST/pragma-multiple-attributes.cpp; Clang :: Misc/pragma-attribute-cxx.cpp; Clang :: Misc/pragma-attribute-objc.m; Clang :: Misc/pragma-attribute-strict-subjects.c; Clang :: OpenMP/assumes_codegen.cpp; Clang :: OpenMP/assumes_print.cpp; Clang :: OpenMP/assumes_template_print.cpp; Clang :: Sema/ast-print.c; Clang :: Sema/attr-availability-swift.c; Clang :: SemaCXX/cxx11-attr-print.cpp; Clang :: SemaTemplate/attributes.cpp; ```. A broken example like:; ```; /home/jun/dev/llvm-project/clang/test/AST/ast-print-attr.c:14:11: error: CHECK: expected string not found in input ; // CHECK: int fun_asm() asm(""test""); ; ^ ; <stdin>:3:46: note: scanning from here ; using C = int ((*))() __attribute__((cdecl)); ; ^ ; <stdin>:4:1: note: possible intended match here ; int fun_asm() asm(R""ATTRDUMP(test)ATTRDUMP""); ; ```. > You can use `R` or `ATTRDUMP`. I just like the freedom we have of using more telling raw string delimiters than `R`. It's also not clear whether such a chance (from `ATTRDUMP` to `R`) is worth the churn. So I guess if `R` is enough for ROOT, maybe we can drop `ATTRDUMP`?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10830#issuecomment-1168753106
Testability,test,test,"> This should be ""upstreamable""; printing `int i [[deprecated(""reason\n"")]];` seems a valid test case. I doubt there's something I don't know, anyway by applying this patch, tests below in LLVM failed:; ```; Failed Tests (23): ; Clang :: AST/ast-dump-attr.cpp ; Clang :: AST/ast-dump-attr.m ; Clang :: AST/ast-dump-c-attr.c ; Clang :: AST/ast-dump-color.cpp ; Clang :: AST/ast-dump-wasm-attr-export.c ; Clang :: AST/ast-dump-wasm-attr-import.c ; Clang :: AST/ast-print-attr.c; Clang :: AST/attr-swift_attr.m; Clang :: AST/attr-swift_bridge.m; Clang :: AST/category-attribute.m; Clang :: AST/pragma-attribute-cxx-subject-match-rules.cpp; Clang :: AST/pragma-attribute-objc-subject-match-rules.m; Clang :: AST/pragma-multiple-attributes.cpp; Clang :: Misc/pragma-attribute-cxx.cpp; Clang :: Misc/pragma-attribute-objc.m; Clang :: Misc/pragma-attribute-strict-subjects.c; Clang :: OpenMP/assumes_codegen.cpp; Clang :: OpenMP/assumes_print.cpp; Clang :: OpenMP/assumes_template_print.cpp; Clang :: Sema/ast-print.c; Clang :: Sema/attr-availability-swift.c; Clang :: SemaCXX/cxx11-attr-print.cpp; Clang :: SemaTemplate/attributes.cpp; ```. A broken example like:; ```; /home/jun/dev/llvm-project/clang/test/AST/ast-print-attr.c:14:11: error: CHECK: expected string not found in input ; // CHECK: int fun_asm() asm(""test""); ; ^ ; <stdin>:3:46: note: scanning from here ; using C = int ((*))() __attribute__((cdecl)); ; ^ ; <stdin>:4:1: note: possible intended match here ; int fun_asm() asm(R""ATTRDUMP(test)ATTRDUMP""); ; ```. > You can use `R` or `ATTRDUMP`. I just like the freedom we have of using more telling raw string delimiters than `R`. It's also not clear whether such a chance (from `ATTRDUMP` to `R`) is worth the churn. So I guess if `R` is enough for ROOT, maybe we can drop `ATTRDUMP`?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10830#issuecomment-1168753106
Usability,clear,clear,"> This should be ""upstreamable""; printing `int i [[deprecated(""reason\n"")]];` seems a valid test case. I doubt there's something I don't know, anyway by applying this patch, tests below in LLVM failed:; ```; Failed Tests (23): ; Clang :: AST/ast-dump-attr.cpp ; Clang :: AST/ast-dump-attr.m ; Clang :: AST/ast-dump-c-attr.c ; Clang :: AST/ast-dump-color.cpp ; Clang :: AST/ast-dump-wasm-attr-export.c ; Clang :: AST/ast-dump-wasm-attr-import.c ; Clang :: AST/ast-print-attr.c; Clang :: AST/attr-swift_attr.m; Clang :: AST/attr-swift_bridge.m; Clang :: AST/category-attribute.m; Clang :: AST/pragma-attribute-cxx-subject-match-rules.cpp; Clang :: AST/pragma-attribute-objc-subject-match-rules.m; Clang :: AST/pragma-multiple-attributes.cpp; Clang :: Misc/pragma-attribute-cxx.cpp; Clang :: Misc/pragma-attribute-objc.m; Clang :: Misc/pragma-attribute-strict-subjects.c; Clang :: OpenMP/assumes_codegen.cpp; Clang :: OpenMP/assumes_print.cpp; Clang :: OpenMP/assumes_template_print.cpp; Clang :: Sema/ast-print.c; Clang :: Sema/attr-availability-swift.c; Clang :: SemaCXX/cxx11-attr-print.cpp; Clang :: SemaTemplate/attributes.cpp; ```. A broken example like:; ```; /home/jun/dev/llvm-project/clang/test/AST/ast-print-attr.c:14:11: error: CHECK: expected string not found in input ; // CHECK: int fun_asm() asm(""test""); ; ^ ; <stdin>:3:46: note: scanning from here ; using C = int ((*))() __attribute__((cdecl)); ; ^ ; <stdin>:4:1: note: possible intended match here ; int fun_asm() asm(R""ATTRDUMP(test)ATTRDUMP""); ; ```. > You can use `R` or `ATTRDUMP`. I just like the freedom we have of using more telling raw string delimiters than `R`. It's also not clear whether such a chance (from `ATTRDUMP` to `R`) is worth the churn. So I guess if `R` is enough for ROOT, maybe we can drop `ATTRDUMP`?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10830#issuecomment-1168753106
Availability,reliab,reliably,"> Hi @AaronBallman !; > ; > > it isn't reliably maintained and bit rots nearly continually. If that wasn't the case, I'd have no concerns about continuing to carry the functionality in the compiler.; > ; > I understand that perception, but given this, do you prefer to improve the AST printing, remove it, or keep it ""rotten"" as you put it? We have significant coverage of it, and we can witness that it's doing a good job. I have two answers (sorry!). My preference is for someone to step up and maintain it because, as you point out, it can perform useful work that people are already using today and so it should be actively maintained. However, I don't have the time to commit to it myself, and code reviewers have never traditionally required patch authors to spend much effort on -ast-print support, so this maintenance isn't likely to happen without someone dedicating effort to it. If nobody steps up to maintain it, my personal preference would be to remove the feature, but it'd definitely require a community RFC to do so -- that gives everyone an opportunity to speak up about why it's critical to keep it (and hopefully drums up a volunteer to maintain it with more regularity). It's not at all clear to me how the community would react to such an RFC, and it's also not clear to me whether we'd need to do OTHER work to prep for removing the functionality (e.g., if ObjC modernization rewriting relies on -ast-print being ""good enough"", we might want to also rip out ObjC moderanization rewriting at the same time, which is another RFC, and so on). FWIW, I'd be happy to be a reviewer for any reviews maintaining or improving `-ast-print` behavior in community (not trying to apply pressure!). > We'd be happy to keep this change minimal, e.g. escape only what needs to be escaped rather than going all in on showing the original spelling of the source code. I think for something that minimal, the cost / benefit ration would be about right. That's just my opinion; your opinion is what",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10830#issuecomment-1171474521
Deployability,patch,patch,"> Hi @AaronBallman !; > ; > > it isn't reliably maintained and bit rots nearly continually. If that wasn't the case, I'd have no concerns about continuing to carry the functionality in the compiler.; > ; > I understand that perception, but given this, do you prefer to improve the AST printing, remove it, or keep it ""rotten"" as you put it? We have significant coverage of it, and we can witness that it's doing a good job. I have two answers (sorry!). My preference is for someone to step up and maintain it because, as you point out, it can perform useful work that people are already using today and so it should be actively maintained. However, I don't have the time to commit to it myself, and code reviewers have never traditionally required patch authors to spend much effort on -ast-print support, so this maintenance isn't likely to happen without someone dedicating effort to it. If nobody steps up to maintain it, my personal preference would be to remove the feature, but it'd definitely require a community RFC to do so -- that gives everyone an opportunity to speak up about why it's critical to keep it (and hopefully drums up a volunteer to maintain it with more regularity). It's not at all clear to me how the community would react to such an RFC, and it's also not clear to me whether we'd need to do OTHER work to prep for removing the functionality (e.g., if ObjC modernization rewriting relies on -ast-print being ""good enough"", we might want to also rip out ObjC moderanization rewriting at the same time, which is another RFC, and so on). FWIW, I'd be happy to be a reviewer for any reviews maintaining or improving `-ast-print` behavior in community (not trying to apply pressure!). > We'd be happy to keep this change minimal, e.g. escape only what needs to be escaped rather than going all in on showing the original spelling of the source code. I think for something that minimal, the cost / benefit ration would be about right. That's just my opinion; your opinion is what",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10830#issuecomment-1171474521
Performance,perform,perform,"> Hi @AaronBallman !; > ; > > it isn't reliably maintained and bit rots nearly continually. If that wasn't the case, I'd have no concerns about continuing to carry the functionality in the compiler.; > ; > I understand that perception, but given this, do you prefer to improve the AST printing, remove it, or keep it ""rotten"" as you put it? We have significant coverage of it, and we can witness that it's doing a good job. I have two answers (sorry!). My preference is for someone to step up and maintain it because, as you point out, it can perform useful work that people are already using today and so it should be actively maintained. However, I don't have the time to commit to it myself, and code reviewers have never traditionally required patch authors to spend much effort on -ast-print support, so this maintenance isn't likely to happen without someone dedicating effort to it. If nobody steps up to maintain it, my personal preference would be to remove the feature, but it'd definitely require a community RFC to do so -- that gives everyone an opportunity to speak up about why it's critical to keep it (and hopefully drums up a volunteer to maintain it with more regularity). It's not at all clear to me how the community would react to such an RFC, and it's also not clear to me whether we'd need to do OTHER work to prep for removing the functionality (e.g., if ObjC modernization rewriting relies on -ast-print being ""good enough"", we might want to also rip out ObjC moderanization rewriting at the same time, which is another RFC, and so on). FWIW, I'd be happy to be a reviewer for any reviews maintaining or improving `-ast-print` behavior in community (not trying to apply pressure!). > We'd be happy to keep this change minimal, e.g. escape only what needs to be escaped rather than going all in on showing the original spelling of the source code. I think for something that minimal, the cost / benefit ration would be about right. That's just my opinion; your opinion is what",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10830#issuecomment-1171474521
Usability,clear,clear,"ST printing, remove it, or keep it ""rotten"" as you put it? We have significant coverage of it, and we can witness that it's doing a good job. I have two answers (sorry!). My preference is for someone to step up and maintain it because, as you point out, it can perform useful work that people are already using today and so it should be actively maintained. However, I don't have the time to commit to it myself, and code reviewers have never traditionally required patch authors to spend much effort on -ast-print support, so this maintenance isn't likely to happen without someone dedicating effort to it. If nobody steps up to maintain it, my personal preference would be to remove the feature, but it'd definitely require a community RFC to do so -- that gives everyone an opportunity to speak up about why it's critical to keep it (and hopefully drums up a volunteer to maintain it with more regularity). It's not at all clear to me how the community would react to such an RFC, and it's also not clear to me whether we'd need to do OTHER work to prep for removing the functionality (e.g., if ObjC modernization rewriting relies on -ast-print being ""good enough"", we might want to also rip out ObjC moderanization rewriting at the same time, which is another RFC, and so on). FWIW, I'd be happy to be a reviewer for any reviews maintaining or improving `-ast-print` behavior in community (not trying to apply pressure!). > We'd be happy to keep this change minimal, e.g. escape only what needs to be escaped rather than going all in on showing the original spelling of the source code. I think for something that minimal, the cost / benefit ration would be about right. That's just my opinion; your opinion is what counts here!. In terms of the changes you need to make to keep -ast-print working for you, I guess I see two ways of going about it. You can either do just the `CreateImplicit()` modifications so that you can do special handling of raw string literals. That'd be the smallest chan",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10830#issuecomment-1171474521
Testability,test,tests,"Alright, thank you very much! That's very nice you chose ROOT to contribute to!. If you need any guidance on what you could help with, just ask me. Sometimes it's not easy to find the issues that are actually easy to work on, as the code is quite complex. Are you looking only Python-related issues, or would you also be interested in doing some C++ contributions to beef up your C++ skills and experience?. As for this PR, I'll merge it if the CI bot tests pass.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10853#issuecomment-1170576376
Usability,guid,guidance,"Alright, thank you very much! That's very nice you chose ROOT to contribute to!. If you need any guidance on what you could help with, just ask me. Sometimes it's not easy to find the issues that are actually easy to work on, as the code is quite complex. Are you looking only Python-related issues, or would you also be interested in doing some C++ contributions to beef up your C++ skills and experience?. As for this PR, I'll merge it if the CI bot tests pass.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10853#issuecomment-1170576376
Deployability,patch,patch,"Applied patch:; ```.diff; --- interpreter/llvm/src/tools/clang/lib/Serialization/ASTWriterDecl.cpp~	2023-01-06 05:04:43.000000000 -0600; +++ interpreter/llvm/src/tools/clang/lib/Serialization/ASTWriterDecl.cpp	2023-01-10 13:21:47.554190854 -0600; @@ -26,6 +26,8 @@; using namespace clang;; using namespace serialization;; ; +#include <cstdio>; +; //===----------------------------------------------------------------------===//; // Declaration serialization; //===----------------------------------------------------------------------===//; @@ -361,6 +363,8 @@; Record.push_back(D->isTopLevelDeclInObjCContainer());; Record.push_back(D->getAccess());; Record.push_back(D->isModulePrivate());; + D->dump();; + if (D->getOwningModule()) fprintf(stderr, ""D->getOwningModule()->Name=%s"", D->getOwningModule()->Name.c_str());; Record.push_back(Writer.getSubmoduleID(D->getOwningModule()));; ; // If this declaration injected a name into a context different from its; ```; with result:; ```ConsoleSession; <snip/>; LinkageSpecDecl 0xbf7b930 <<module-includes>:1:1, line:3:1> line:1:8 C; |-CXXRecordDecl 0xbf7b988 </usr/include/xlocale.h:27:9, line:39:1> line:27:16 in xlocale.h hidden struct __locale_struct definition; | |-DefinitionData pass_in_registers aggregate standard_layout trivially_copyable pod trivial literal; | | |-DefaultConstructor exists trivial needs_implicit; | | |-CopyConstructor simple trivial has_const_param needs_implicit implicit_has_const_param; | | |-MoveConstructor exists simple trivial needs_implicit; | | |-CopyAssignment simple trivial has_const_param needs_implicit implicit_has_const_param; | | |-MoveAssignment exists simple trivial needs_implicit; | | `-Destructor simple irrelevant trivial needs_implicit; | |-CXXRecordDecl 0xbf7bad0 <col:9, col:16> col:16 in xlocale.h hidden implicit struct __locale_struct; | |-CXXRecordDecl 0xbf7bb88 parent 0xbf3f498 <line:30:3, col:10> col:10 in xlocale.h hidden struct __locale_data; | |-FieldDecl 0xbf7be08 <col:3, col:37> col:2",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10861#issuecomment-1377744663
Energy Efficiency,green,greenc,"3, col:29> col:29 in xlocale.h hidden __ctype_b 'const unsigned short *'; | |-FieldDecl 0xbf7bf28 <line:34:3, col:14> col:14 in xlocale.h hidden __ctype_tolower 'const int *'; | |-FieldDecl 0xbf7bf98 <line:35:3, col:14> col:14 in xlocale.h hidden __ctype_toupper 'const int *'; | `-FieldDecl 0xbf7c098 <line:38:3, col:25> col:15 in xlocale.h hidden __names 'const char *[13]'; |-TypedefDecl 0xbf7c1c8 <line:27:1, line:39:4> col:4 in xlocale.h hidden referenced __locale_t 'struct __locale_struct *'; | `-PointerType 0xbf7c170 'struct __locale_struct *'; | `-ElaboratedType 0xbf7c100 'struct __locale_struct' sugar; | `-RecordType 0xbf7ba40 '__locale_struct'; | `-CXXRecord 0xbf7b988 '__locale_struct'; `-TypedefDecl 0xbf7c278 <line:42:1, col:20> col:20 in xlocale.h hidden locale_t '__locale_t':'struct __locale_struct *'; `-TypedefType 0xbf7c240 '__locale_t' sugar; |-Typedef 0xbf7c1c8 '__locale_t'; `-PointerType 0xbf7c170 'struct __locale_struct *'; `-ElaboratedType 0xbf7c100 'struct __locale_struct' sugar; `-RecordType 0xbf7ba40 '__locale_struct'; `-CXXRecord 0xbf7b988 '__locale_struct'; Mod=0; #0 0x0000000009107dda llvm::sys::PrintStackTrace(llvm::raw_ostream&, int) /scratch/greenc/test-products/root/v6_27_99f1/source/root-6.27.99/interpreter/llvm/src/lib/Support/Unix/Signals.inc:565:11; #1 0x0000000009107f8b PrintStackTraceSignalHandler(void*) /scratch/greenc/test-products/root/v6_27_99f1/source/root-6.27.99/interpreter/llvm/src/lib/Support/Unix/Signals.inc:632:1; #2 0x00000000091067b3 llvm::sys::RunSignalHandlers() /scratch/greenc/test-products/root/v6_27_99f1/source/root-6.27.99/interpreter/llvm/src/lib/Support/Signals.cpp:97:5; #3 0x00000000091085a5 SignalHandler(int) /scratch/greenc/test-products/root/v6_27_99f1/source/root-6.27.99/interpreter/llvm/src/lib/Support/Unix/Signals.inc:407:1; #4 0x00007f7e8feef630 __restore_rt sigaction.c:0:0; #5 0x00000000031e3995 std::__2::basic_string<char, std::__2::char_traits<char>, std::__2::allocator<char> >::__is_long() const /scrat",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10861#issuecomment-1377744663
Integrability,inject,injected,"Applied patch:; ```.diff; --- interpreter/llvm/src/tools/clang/lib/Serialization/ASTWriterDecl.cpp~	2023-01-06 05:04:43.000000000 -0600; +++ interpreter/llvm/src/tools/clang/lib/Serialization/ASTWriterDecl.cpp	2023-01-10 13:21:47.554190854 -0600; @@ -26,6 +26,8 @@; using namespace clang;; using namespace serialization;; ; +#include <cstdio>; +; //===----------------------------------------------------------------------===//; // Declaration serialization; //===----------------------------------------------------------------------===//; @@ -361,6 +363,8 @@; Record.push_back(D->isTopLevelDeclInObjCContainer());; Record.push_back(D->getAccess());; Record.push_back(D->isModulePrivate());; + D->dump();; + if (D->getOwningModule()) fprintf(stderr, ""D->getOwningModule()->Name=%s"", D->getOwningModule()->Name.c_str());; Record.push_back(Writer.getSubmoduleID(D->getOwningModule()));; ; // If this declaration injected a name into a context different from its; ```; with result:; ```ConsoleSession; <snip/>; LinkageSpecDecl 0xbf7b930 <<module-includes>:1:1, line:3:1> line:1:8 C; |-CXXRecordDecl 0xbf7b988 </usr/include/xlocale.h:27:9, line:39:1> line:27:16 in xlocale.h hidden struct __locale_struct definition; | |-DefinitionData pass_in_registers aggregate standard_layout trivially_copyable pod trivial literal; | | |-DefaultConstructor exists trivial needs_implicit; | | |-CopyConstructor simple trivial has_const_param needs_implicit implicit_has_const_param; | | |-MoveConstructor exists simple trivial needs_implicit; | | |-CopyAssignment simple trivial has_const_param needs_implicit implicit_has_const_param; | | |-MoveAssignment exists simple trivial needs_implicit; | | `-Destructor simple irrelevant trivial needs_implicit; | |-CXXRecordDecl 0xbf7bad0 <col:9, col:16> col:16 in xlocale.h hidden implicit struct __locale_struct; | |-CXXRecordDecl 0xbf7bb88 parent 0xbf3f498 <line:30:3, col:10> col:10 in xlocale.h hidden struct __locale_data; | |-FieldDecl 0xbf7be08 <col:3, col:37> col:2",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10861#issuecomment-1377744663
Security,inject,injected,"Applied patch:; ```.diff; --- interpreter/llvm/src/tools/clang/lib/Serialization/ASTWriterDecl.cpp~	2023-01-06 05:04:43.000000000 -0600; +++ interpreter/llvm/src/tools/clang/lib/Serialization/ASTWriterDecl.cpp	2023-01-10 13:21:47.554190854 -0600; @@ -26,6 +26,8 @@; using namespace clang;; using namespace serialization;; ; +#include <cstdio>; +; //===----------------------------------------------------------------------===//; // Declaration serialization; //===----------------------------------------------------------------------===//; @@ -361,6 +363,8 @@; Record.push_back(D->isTopLevelDeclInObjCContainer());; Record.push_back(D->getAccess());; Record.push_back(D->isModulePrivate());; + D->dump();; + if (D->getOwningModule()) fprintf(stderr, ""D->getOwningModule()->Name=%s"", D->getOwningModule()->Name.c_str());; Record.push_back(Writer.getSubmoduleID(D->getOwningModule()));; ; // If this declaration injected a name into a context different from its; ```; with result:; ```ConsoleSession; <snip/>; LinkageSpecDecl 0xbf7b930 <<module-includes>:1:1, line:3:1> line:1:8 C; |-CXXRecordDecl 0xbf7b988 </usr/include/xlocale.h:27:9, line:39:1> line:27:16 in xlocale.h hidden struct __locale_struct definition; | |-DefinitionData pass_in_registers aggregate standard_layout trivially_copyable pod trivial literal; | | |-DefaultConstructor exists trivial needs_implicit; | | |-CopyConstructor simple trivial has_const_param needs_implicit implicit_has_const_param; | | |-MoveConstructor exists simple trivial needs_implicit; | | |-CopyAssignment simple trivial has_const_param needs_implicit implicit_has_const_param; | | |-MoveAssignment exists simple trivial needs_implicit; | | `-Destructor simple irrelevant trivial needs_implicit; | |-CXXRecordDecl 0xbf7bad0 <col:9, col:16> col:16 in xlocale.h hidden implicit struct __locale_struct; | |-CXXRecordDecl 0xbf7bb88 parent 0xbf3f498 <line:30:3, col:10> col:10 in xlocale.h hidden struct __locale_data; | |-FieldDecl 0xbf7be08 <col:3, col:37> col:2",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10861#issuecomment-1377744663
Testability,test,test-products,"3, col:29> col:29 in xlocale.h hidden __ctype_b 'const unsigned short *'; | |-FieldDecl 0xbf7bf28 <line:34:3, col:14> col:14 in xlocale.h hidden __ctype_tolower 'const int *'; | |-FieldDecl 0xbf7bf98 <line:35:3, col:14> col:14 in xlocale.h hidden __ctype_toupper 'const int *'; | `-FieldDecl 0xbf7c098 <line:38:3, col:25> col:15 in xlocale.h hidden __names 'const char *[13]'; |-TypedefDecl 0xbf7c1c8 <line:27:1, line:39:4> col:4 in xlocale.h hidden referenced __locale_t 'struct __locale_struct *'; | `-PointerType 0xbf7c170 'struct __locale_struct *'; | `-ElaboratedType 0xbf7c100 'struct __locale_struct' sugar; | `-RecordType 0xbf7ba40 '__locale_struct'; | `-CXXRecord 0xbf7b988 '__locale_struct'; `-TypedefDecl 0xbf7c278 <line:42:1, col:20> col:20 in xlocale.h hidden locale_t '__locale_t':'struct __locale_struct *'; `-TypedefType 0xbf7c240 '__locale_t' sugar; |-Typedef 0xbf7c1c8 '__locale_t'; `-PointerType 0xbf7c170 'struct __locale_struct *'; `-ElaboratedType 0xbf7c100 'struct __locale_struct' sugar; `-RecordType 0xbf7ba40 '__locale_struct'; `-CXXRecord 0xbf7b988 '__locale_struct'; Mod=0; #0 0x0000000009107dda llvm::sys::PrintStackTrace(llvm::raw_ostream&, int) /scratch/greenc/test-products/root/v6_27_99f1/source/root-6.27.99/interpreter/llvm/src/lib/Support/Unix/Signals.inc:565:11; #1 0x0000000009107f8b PrintStackTraceSignalHandler(void*) /scratch/greenc/test-products/root/v6_27_99f1/source/root-6.27.99/interpreter/llvm/src/lib/Support/Unix/Signals.inc:632:1; #2 0x00000000091067b3 llvm::sys::RunSignalHandlers() /scratch/greenc/test-products/root/v6_27_99f1/source/root-6.27.99/interpreter/llvm/src/lib/Support/Signals.cpp:97:5; #3 0x00000000091085a5 SignalHandler(int) /scratch/greenc/test-products/root/v6_27_99f1/source/root-6.27.99/interpreter/llvm/src/lib/Support/Unix/Signals.inc:407:1; #4 0x00007f7e8feef630 __restore_rt sigaction.c:0:0; #5 0x00000000031e3995 std::__2::basic_string<char, std::__2::char_traits<char>, std::__2::allocator<char> >::__is_long() const /scrat",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10861#issuecomment-1377744663
Usability,simpl,simple,"-------------------------------------------------===//; @@ -361,6 +363,8 @@; Record.push_back(D->isTopLevelDeclInObjCContainer());; Record.push_back(D->getAccess());; Record.push_back(D->isModulePrivate());; + D->dump();; + if (D->getOwningModule()) fprintf(stderr, ""D->getOwningModule()->Name=%s"", D->getOwningModule()->Name.c_str());; Record.push_back(Writer.getSubmoduleID(D->getOwningModule()));; ; // If this declaration injected a name into a context different from its; ```; with result:; ```ConsoleSession; <snip/>; LinkageSpecDecl 0xbf7b930 <<module-includes>:1:1, line:3:1> line:1:8 C; |-CXXRecordDecl 0xbf7b988 </usr/include/xlocale.h:27:9, line:39:1> line:27:16 in xlocale.h hidden struct __locale_struct definition; | |-DefinitionData pass_in_registers aggregate standard_layout trivially_copyable pod trivial literal; | | |-DefaultConstructor exists trivial needs_implicit; | | |-CopyConstructor simple trivial has_const_param needs_implicit implicit_has_const_param; | | |-MoveConstructor exists simple trivial needs_implicit; | | |-CopyAssignment simple trivial has_const_param needs_implicit implicit_has_const_param; | | |-MoveAssignment exists simple trivial needs_implicit; | | `-Destructor simple irrelevant trivial needs_implicit; | |-CXXRecordDecl 0xbf7bad0 <col:9, col:16> col:16 in xlocale.h hidden implicit struct __locale_struct; | |-CXXRecordDecl 0xbf7bb88 parent 0xbf3f498 <line:30:3, col:10> col:10 in xlocale.h hidden struct __locale_data; | |-FieldDecl 0xbf7be08 <col:3, col:37> col:25 in xlocale.h hidden __locales 'struct __locale_data *[13]'; | |-FieldDecl 0xbf7beb8 <line:33:3, col:29> col:29 in xlocale.h hidden __ctype_b 'const unsigned short *'; | |-FieldDecl 0xbf7bf28 <line:34:3, col:14> col:14 in xlocale.h hidden __ctype_tolower 'const int *'; | |-FieldDecl 0xbf7bf98 <line:35:3, col:14> col:14 in xlocale.h hidden __ctype_toupper 'const int *'; | `-FieldDecl 0xbf7c098 <line:38:3, col:25> col:15 in xlocale.h hidden __names 'const char *[13]'; |-TypedefDec",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10861#issuecomment-1377744663
Energy Efficiency,green,greenc,"0; Submodule=stdio.h; Mod=AEED350; Submodule=stdlib.h; Mod=AEEBBD0; Submodule=signal.h; Mod=AEED350; Submodule=stdlib.h; Mod=AEEBBD0; Submodule=signal.h; Mod=AEED350; Submodule=stdlib.h; Mod=AEEBBD0; Submodule=signal.h; Mod=AEED350; Submodule=stdlib.h; Mod=AEEBBD0; Submodule=signal.h; Mod=AEED350; Submodule=stdlib.h; Mod=AEEBBD0; Submodule=signal.h; Mod=AEED350; Submodule=stdlib.h; Mod=AEEBBD0; Submodule=signal.h; Mod=AEED350; Submodule=stdlib.h; Mod=AEEBBD0; Submodule=signal.h; Mod=AEED350; Submodule=stdlib.h; Mod=AEEBBD0; Submodule=signal.h; Mod=AEED350; Submodule=stdlib.h; Mod=AEEBBD0; Submodule=signal.h; Mod=AEED350; Submodule=stdlib.h; Mod=AEEBBD0; Submodule=signal.h; Mod=AEED350; Submodule=stdlib.h; Mod=AEEBBD0; Submodule=signal.h; Mod=AEED350; Submodule=stdlib.h; LinkageSpecDecl 0xb598660 <<module-includes>:1:1, line:3:1> line:1:8 C; `-LinkageSpecDecl 0xb5986d8 </usr/include/sys/cdefs.h:99:24, line:100:22> line:99:31 in libc.string.h C; |-TypedefDecl 0xb598748 </scratch/greenc/test-products/root/v6_27_99f1/build/Linux64bit+3.10-2.17-c14-p3913-debug/etc/cling/lib/clang/13.0.0/include/stddef.h:46:1, col:23> col:23 in libc.string.h hidden referenced size_t 'unsigned long'; | `-BuiltinType 0xb55c390 'unsigned long'; |-FunctionDecl 0xb598af0 </usr/include/string.h:42:1, /usr/include/sys/cdefs.h:285:63> /usr/include/string.h:42:14 in libc.string.h hidden memcpy 'void *(void *__restrict, const void *__restrict, size_t) throw()' extern; | |-ParmVarDecl 0xb5987c0 <col:22, col:39> col:39 in libc.string.h hidden __dest 'void *__restrict'; | |-ParmVarDecl 0xb598878 <col:47, col:70> col:70 in libc.string.h hidden __src 'const void *__restrict'; | |-ParmVarDecl 0xb598918 <line:43:8, col:15> col:15 in libc.string.h hidden __n 'size_t':'unsigned long'; | |-NonNullAttr 0xb598ba8 </usr/include/sys/cdefs.h:285:44, /usr/include/string.h:43:44> 1 2; | `-BuiltinAttr 0xb598d10 <<invalid sloc>> Implicit 779; |-FunctionDecl 0xb599000 <line:46:1, /usr/include/sys/cdefs.h:285:63> /usr/i",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10861#issuecomment-1377827282
Testability,test,test-products,"0; Submodule=stdio.h; Mod=AEED350; Submodule=stdlib.h; Mod=AEEBBD0; Submodule=signal.h; Mod=AEED350; Submodule=stdlib.h; Mod=AEEBBD0; Submodule=signal.h; Mod=AEED350; Submodule=stdlib.h; Mod=AEEBBD0; Submodule=signal.h; Mod=AEED350; Submodule=stdlib.h; Mod=AEEBBD0; Submodule=signal.h; Mod=AEED350; Submodule=stdlib.h; Mod=AEEBBD0; Submodule=signal.h; Mod=AEED350; Submodule=stdlib.h; Mod=AEEBBD0; Submodule=signal.h; Mod=AEED350; Submodule=stdlib.h; Mod=AEEBBD0; Submodule=signal.h; Mod=AEED350; Submodule=stdlib.h; Mod=AEEBBD0; Submodule=signal.h; Mod=AEED350; Submodule=stdlib.h; Mod=AEEBBD0; Submodule=signal.h; Mod=AEED350; Submodule=stdlib.h; Mod=AEEBBD0; Submodule=signal.h; Mod=AEED350; Submodule=stdlib.h; Mod=AEEBBD0; Submodule=signal.h; Mod=AEED350; Submodule=stdlib.h; LinkageSpecDecl 0xb598660 <<module-includes>:1:1, line:3:1> line:1:8 C; `-LinkageSpecDecl 0xb5986d8 </usr/include/sys/cdefs.h:99:24, line:100:22> line:99:31 in libc.string.h C; |-TypedefDecl 0xb598748 </scratch/greenc/test-products/root/v6_27_99f1/build/Linux64bit+3.10-2.17-c14-p3913-debug/etc/cling/lib/clang/13.0.0/include/stddef.h:46:1, col:23> col:23 in libc.string.h hidden referenced size_t 'unsigned long'; | `-BuiltinType 0xb55c390 'unsigned long'; |-FunctionDecl 0xb598af0 </usr/include/string.h:42:1, /usr/include/sys/cdefs.h:285:63> /usr/include/string.h:42:14 in libc.string.h hidden memcpy 'void *(void *__restrict, const void *__restrict, size_t) throw()' extern; | |-ParmVarDecl 0xb5987c0 <col:22, col:39> col:39 in libc.string.h hidden __dest 'void *__restrict'; | |-ParmVarDecl 0xb598878 <col:47, col:70> col:70 in libc.string.h hidden __src 'const void *__restrict'; | |-ParmVarDecl 0xb598918 <line:43:8, col:15> col:15 in libc.string.h hidden __n 'size_t':'unsigned long'; | |-NonNullAttr 0xb598ba8 </usr/include/sys/cdefs.h:285:44, /usr/include/string.h:43:44> 1 2; | `-BuiltinAttr 0xb598d10 <<invalid sloc>> Implicit 779; |-FunctionDecl 0xb599000 <line:46:1, /usr/include/sys/cdefs.h:285:63> /usr/i",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10861#issuecomment-1377827282
Usability,simpl,simple,"de/string.h:150:15 in libc.string.h hidden strxfrm 'size_t (char *__restrict, const char *__restrict, size_t) throw()' extern; | |-ParmVarDecl 0xb5ea258 <col:24, col:41> col:41 in libc.string.h hidden __dest 'char *__restrict'; | |-ParmVarDecl 0xb5ea2e0 <line:151:10, col:33> col:33 in libc.string.h hidden __src 'const char *__restrict'; | |-ParmVarDecl 0xb5ea360 <col:40, col:47> col:47 in libc.string.h hidden __n 'size_t':'unsigned long'; | |-NonNullAttr 0xb5ea5d0 </usr/include/sys/cdefs.h:285:44, /usr/include/string.h:152:27> 2; | `-BuiltinAttr 0xb5ea6e0 <<invalid sloc>> Implicit 788; |-CXXRecordDecl 0xb5ea710 </usr/include/xlocale.h:27:9, line:39:1> line:27:16 in libc.xlocale.h hidden struct __locale_struct definition; | |-DefinitionData pass_in_registers aggregate standard_layout trivially_copyable pod trivial literal; | | |-DefaultConstructor exists trivial needs_implicit; | | |-CopyConstructor simple trivial has_const_param needs_implicit implicit_has_const_param; | | |-MoveConstructor exists simple trivial needs_implicit; | | |-CopyAssignment simple trivial has_const_param needs_implicit implicit_has_const_param; | | |-MoveAssignment exists simple trivial needs_implicit; | | `-Destructor simple irrelevant trivial needs_implicit; | |-CXXRecordDecl 0xb5ea850 <col:9, col:16> col:16 in libc.xlocale.h hidden implicit struct __locale_struct; | |-CXXRecordDecl 0xb5ea908 parent 0xb55c1c8 <line:30:3, col:10> col:10 in libc.xlocale.h hidden struct __locale_data; | |-FieldDecl 0xb5ebd48 <col:3, col:37> col:25 in libc.xlocale.h hidden __locales 'struct __locale_data *[13]'; | |-FieldDecl 0xb5ebdf8 <line:33:3, col:29> col:29 in libc.xlocale.h hidden __ctype_b 'const unsigned short *'; | |-FieldDecl 0xb5ebe68 <line:34:3, col:14> col:14 in libc.xlocale.h hidden __ctype_tolower 'const int *'; | |-FieldDecl 0xb5ebed8 <line:35:3, col:14> col:14 in libc.xlocale.h hidden __ctype_toupper 'const int *'; | `-FieldDecl 0xb5ebfd8 <line:38:3, col:25> col:15 in libc.xlocale.h hidden __na",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10861#issuecomment-1377827282
Usability,simpl,simply,Unfortunately simply removing `export std_config` as you suggest appears not to be sufficient with a build as described in https://github.com/root-project/root/issues/10861#issuecomment-1378895796. Trying to see if I can get more information...,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10861#issuecomment-1398569350
Availability,failure,failures,"The good news is that I have been able to reproduce your success with our build of 6.24/04 and 6.24/06. Unfortunately, I was also able to reproduce our failures with 6.28/00-rc1 in the same environment. I'd be grateful if you could turn your attention to investigating why the fix does not work for more recent ROOT source. BTW: in order to use Ninja, one needs simply to execute `setup ninja` before executing the CMake command.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10861#issuecomment-1401209723
Usability,simpl,simply,"The good news is that I have been able to reproduce your success with our build of 6.24/04 and 6.24/06. Unfortunately, I was also able to reproduce our failures with 6.28/00-rc1 in the same environment. I'd be grateful if you could turn your attention to investigating why the fix does not work for more recent ROOT source. BTW: in order to use Ninja, one needs simply to execute `setup ninja` before executing the CMake command.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10861#issuecomment-1401209723
Deployability,upgrade,upgrade,"@StephanTLavavej FYI, the upgrade of LLVM 13 is done, and this is now fixed in ROOT master (i.e. the workaround has been removed). Thanks again for your feedback!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10875#issuecomment-1346236983
Usability,feedback,feedback,"@StephanTLavavej FYI, the upgrade of LLVM 13 is done, and this is now fixed in ROOT master (i.e. the workaround has been removed). Thanks again for your feedback!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10875#issuecomment-1346236983
Testability,test,test,"Thanks for the review! No, there is no unit test for this IO rule, but I tested it locally. I don't think it's worth it to include a test for this simple IO rule, because such a test also always needs a file storing an object of the old class version, and I think it's not good to have too many binary files in the repository without strong reasons.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10909#issuecomment-1181836400
Usability,simpl,simple,"Thanks for the review! No, there is no unit test for this IO rule, but I tested it locally. I don't think it's worth it to include a test for this simple IO rule, because such a test also always needs a file storing an object of the old class version, and I think it's not good to have too many binary files in the repository without strong reasons.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10909#issuecomment-1181836400
Testability,test,test,"> Thanks for the review! No, there is no unit test for this IO rule, but I tested it locally.; > ; > I don't think it's worth it to include a test for this simple IO rule, because such a test also always needs a file storing an object of the old class version, and I think it's not good to have too many binary files in the repository without strong reasons. Actually, if I may @guitargeek :; Some of the biggest grievances some users had in RF's ""dormant time"" was a non-functioning schema evolution, which prevented users from moving to a newer ROOT version. You lose these users, as they have to disconnect from ROOT's evolution. Therefore, I strongly suggest having schema evolution tests in master. These files only consume a few kB, and they will never be altered.; This becomes even more important if a specific class version was in use for a long time, because the number of workspaces in the wild will scale with the time that a class version was in master.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10909#issuecomment-1181856704
Usability,simpl,simple,"> Thanks for the review! No, there is no unit test for this IO rule, but I tested it locally.; > ; > I don't think it's worth it to include a test for this simple IO rule, because such a test also always needs a file storing an object of the old class version, and I think it's not good to have too many binary files in the repository without strong reasons. Actually, if I may @guitargeek :; Some of the biggest grievances some users had in RF's ""dormant time"" was a non-functioning schema evolution, which prevented users from moving to a newer ROOT version. You lose these users, as they have to disconnect from ROOT's evolution. Therefore, I strongly suggest having schema evolution tests in master. These files only consume a few kB, and they will never be altered.; This becomes even more important if a specific class version was in use for a long time, because the number of workspaces in the wild will scale with the time that a class version was in master.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10909#issuecomment-1181856704
Availability,error,error,"Here's simpler reproducer for https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/154832/testReport/projectroot/runtutorials/tutorial_multicore_mp101_fillNtuples/ ; ```;  cat Demo.C; void Demo() {; auto X = ROOT::TSeqI(42);; } ; ```. The error message is:; ```. Processing Demo.C...; In module 'Core':; /home/jun/dev/root/Debug/include/ROOT/TSeq.hxx:67:10: error: instantiation of 'ROOT::TSeq<int>' is different in different modules; class TSeq {; ^; In module 'std' imported from input_line_1:1:; /usr/bin/../lib/gcc/x86_64-linux-gnu/11/../../../../include/c++/11/type_traits:1910:13: error: 'std::__make_signed_selector<int, true, false>::__type' from module 'std.type_traits' is not present in definition of 'std::__make_signed_selector<int, true, false>' provided earlier; using __type; ^; /usr/bin/../lib/gcc/x86_64-linux-gnu/11/../../../../include/c++/11/type_traits:1901:11: note: definition has no member '__type'; class __make_signed_selector;; ^; /usr/bin/../lib/gcc/x86_64-linux-gnu/11/../../../../include/c++/11/type_traits:1966:12: error: 'std::make_signed<int>' has different definitions in different modules; defined here; struct make_signed; ^; /usr/bin/../lib/gcc/x86_64-linux-gnu/11/../../../../include/c++/11/type_traits:1966:12: note: definition in module 'std.type_traits' is here; In module 'Core':; /home/jun/dev/root/Debug/include/ROOT/TSeq.hxx:79:7: error: multiple overloads of 'TSeq' instantiate to the same signature 'void (int)'; TSeq(T theEnd): fBegin(), fEnd(theEnd), fStep(1) {; ^; /home/jun/dev/root/Debug/Demo.C:2:12: note: in instantiation of template class 'ROOT::TSeq<int>' requested here; auto X = ROOT::TSeqI(42);; ^; /home/jun/dev/root/Debug/include/ROOT/TSeq.hxx:79:7: note: previous declaration is here; TSeq(T theEnd): fBegin(), fEnd(theEnd), fStep(1) {; ^; /home/jun/dev/root/Debug/include/ROOT/TSeq.hxx:82:7: error: multiple overloads of 'TSeq' instantiate to the same signature 'void (int, int, int)'; TSeq(T theBegin, T theEnd, T th",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10910#issuecomment-1253760320
Integrability,message,message,"Here's simpler reproducer for https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/154832/testReport/projectroot/runtutorials/tutorial_multicore_mp101_fillNtuples/ ; ```;  cat Demo.C; void Demo() {; auto X = ROOT::TSeqI(42);; } ; ```. The error message is:; ```. Processing Demo.C...; In module 'Core':; /home/jun/dev/root/Debug/include/ROOT/TSeq.hxx:67:10: error: instantiation of 'ROOT::TSeq<int>' is different in different modules; class TSeq {; ^; In module 'std' imported from input_line_1:1:; /usr/bin/../lib/gcc/x86_64-linux-gnu/11/../../../../include/c++/11/type_traits:1910:13: error: 'std::__make_signed_selector<int, true, false>::__type' from module 'std.type_traits' is not present in definition of 'std::__make_signed_selector<int, true, false>' provided earlier; using __type; ^; /usr/bin/../lib/gcc/x86_64-linux-gnu/11/../../../../include/c++/11/type_traits:1901:11: note: definition has no member '__type'; class __make_signed_selector;; ^; /usr/bin/../lib/gcc/x86_64-linux-gnu/11/../../../../include/c++/11/type_traits:1966:12: error: 'std::make_signed<int>' has different definitions in different modules; defined here; struct make_signed; ^; /usr/bin/../lib/gcc/x86_64-linux-gnu/11/../../../../include/c++/11/type_traits:1966:12: note: definition in module 'std.type_traits' is here; In module 'Core':; /home/jun/dev/root/Debug/include/ROOT/TSeq.hxx:79:7: error: multiple overloads of 'TSeq' instantiate to the same signature 'void (int)'; TSeq(T theEnd): fBegin(), fEnd(theEnd), fStep(1) {; ^; /home/jun/dev/root/Debug/Demo.C:2:12: note: in instantiation of template class 'ROOT::TSeq<int>' requested here; auto X = ROOT::TSeqI(42);; ^; /home/jun/dev/root/Debug/include/ROOT/TSeq.hxx:79:7: note: previous declaration is here; TSeq(T theEnd): fBegin(), fEnd(theEnd), fStep(1) {; ^; /home/jun/dev/root/Debug/include/ROOT/TSeq.hxx:82:7: error: multiple overloads of 'TSeq' instantiate to the same signature 'void (int, int, int)'; TSeq(T theBegin, T theEnd, T th",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10910#issuecomment-1253760320
Performance,load,loadModule,"(this=0x5555564e7640) at /home/jun/dev/root/interpreter/llvm/src/tools/clang/include/clang/AST/DeclCXX.h:833; #20 0x00007ffff07fa508 in clang::ASTReader::diagnoseOdrViolations (this=0x555555609330) at /home/jun/dev/root/interpreter/llvm/src/tools/clang/lib/Serialization/ASTReader.cpp:10053; #21 0x00007ffff0806ba3 in clang::ASTReader::FinishedDeserializing (this=0x555555609330) at /home/jun/dev/root/interpreter/llvm/src/tools/clang/lib/Serialization/ASTReader.cpp:12155; #22 0x00007ffff0811ffc in clang::ExternalASTSource::Deserializing::~Deserializing (this=0x7ffffffe27d8) at /home/jun/dev/root/interpreter/llvm/src/tools/clang/include/clang/AST/ExternalASTSource.h:89; #23 0x00007ffff07e3cc0 in clang::ASTReader::ReadAST (this=0x555555609330, FileName=..., Type=clang::serialization::MK_PrebuiltModule, ImportLoc=..., ClientLoadCapabilities=0, Imported=0x0); at /home/jun/dev/root/interpreter/llvm/src/tools/clang/lib/Serialization/ASTReader.cpp:4379; #24 0x00007ffff0495e2e in clang::CompilerInstance::loadModule (this=0x55555562fb60, ImportLoc=..., Path=..., Visibility=clang::Module::AllVisible, IsInclusionDirective=false); at /home/jun/dev/root/interpreter/llvm/src/tools/clang/lib/Frontend/CompilerInstance.cpp:1710; #25 0x00007ffff117e1dd in clang::Sema::ActOnModuleImport (this=0x5555556b5680, StartLoc=..., ExportLoc=..., ImportLoc=..., Path=...); at /home/jun/dev/root/interpreter/llvm/src/tools/clang/lib/Sema/SemaModule.cpp:325; #26 0x00007fffef9655fa in cling::Interpreter::loadModule (this=0x5555555ef460, M=0x555555956a90, complain=true) at /home/jun/dev/root/interpreter/cling/lib/Interpreter/Interpreter.cpp:908; #27 0x00007fffef965326 in cling::Interpreter::loadModule (this=0x5555555ef460, Python Exception <class 'gdb.error'>: There is no member named _M_p.; moduleName=, complain=true) at /home/jun/dev/root/interpreter/cling/lib/Interpreter/Interpreter.cpp:872; #28 0x00007fffef85f5f6 in TClingCallbacks::findInGlobalModuleIndex (this=0x5555563ffde0, Name=..., loadFirstMat",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10910#issuecomment-1253760320
Testability,test,testReport,"Here's simpler reproducer for https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/154832/testReport/projectroot/runtutorials/tutorial_multicore_mp101_fillNtuples/ ; ```;  cat Demo.C; void Demo() {; auto X = ROOT::TSeqI(42);; } ; ```. The error message is:; ```. Processing Demo.C...; In module 'Core':; /home/jun/dev/root/Debug/include/ROOT/TSeq.hxx:67:10: error: instantiation of 'ROOT::TSeq<int>' is different in different modules; class TSeq {; ^; In module 'std' imported from input_line_1:1:; /usr/bin/../lib/gcc/x86_64-linux-gnu/11/../../../../include/c++/11/type_traits:1910:13: error: 'std::__make_signed_selector<int, true, false>::__type' from module 'std.type_traits' is not present in definition of 'std::__make_signed_selector<int, true, false>' provided earlier; using __type; ^; /usr/bin/../lib/gcc/x86_64-linux-gnu/11/../../../../include/c++/11/type_traits:1901:11: note: definition has no member '__type'; class __make_signed_selector;; ^; /usr/bin/../lib/gcc/x86_64-linux-gnu/11/../../../../include/c++/11/type_traits:1966:12: error: 'std::make_signed<int>' has different definitions in different modules; defined here; struct make_signed; ^; /usr/bin/../lib/gcc/x86_64-linux-gnu/11/../../../../include/c++/11/type_traits:1966:12: note: definition in module 'std.type_traits' is here; In module 'Core':; /home/jun/dev/root/Debug/include/ROOT/TSeq.hxx:79:7: error: multiple overloads of 'TSeq' instantiate to the same signature 'void (int)'; TSeq(T theEnd): fBegin(), fEnd(theEnd), fStep(1) {; ^; /home/jun/dev/root/Debug/Demo.C:2:12: note: in instantiation of template class 'ROOT::TSeq<int>' requested here; auto X = ROOT::TSeqI(42);; ^; /home/jun/dev/root/Debug/include/ROOT/TSeq.hxx:79:7: note: previous declaration is here; TSeq(T theEnd): fBegin(), fEnd(theEnd), fStep(1) {; ^; /home/jun/dev/root/Debug/include/ROOT/TSeq.hxx:82:7: error: multiple overloads of 'TSeq' instantiate to the same signature 'void (int, int, int)'; TSeq(T theBegin, T theEnd, T th",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10910#issuecomment-1253760320
Usability,simpl,simpler,"Here's simpler reproducer for https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/154832/testReport/projectroot/runtutorials/tutorial_multicore_mp101_fillNtuples/ ; ```;  cat Demo.C; void Demo() {; auto X = ROOT::TSeqI(42);; } ; ```. The error message is:; ```. Processing Demo.C...; In module 'Core':; /home/jun/dev/root/Debug/include/ROOT/TSeq.hxx:67:10: error: instantiation of 'ROOT::TSeq<int>' is different in different modules; class TSeq {; ^; In module 'std' imported from input_line_1:1:; /usr/bin/../lib/gcc/x86_64-linux-gnu/11/../../../../include/c++/11/type_traits:1910:13: error: 'std::__make_signed_selector<int, true, false>::__type' from module 'std.type_traits' is not present in definition of 'std::__make_signed_selector<int, true, false>' provided earlier; using __type; ^; /usr/bin/../lib/gcc/x86_64-linux-gnu/11/../../../../include/c++/11/type_traits:1901:11: note: definition has no member '__type'; class __make_signed_selector;; ^; /usr/bin/../lib/gcc/x86_64-linux-gnu/11/../../../../include/c++/11/type_traits:1966:12: error: 'std::make_signed<int>' has different definitions in different modules; defined here; struct make_signed; ^; /usr/bin/../lib/gcc/x86_64-linux-gnu/11/../../../../include/c++/11/type_traits:1966:12: note: definition in module 'std.type_traits' is here; In module 'Core':; /home/jun/dev/root/Debug/include/ROOT/TSeq.hxx:79:7: error: multiple overloads of 'TSeq' instantiate to the same signature 'void (int)'; TSeq(T theEnd): fBegin(), fEnd(theEnd), fStep(1) {; ^; /home/jun/dev/root/Debug/Demo.C:2:12: note: in instantiation of template class 'ROOT::TSeq<int>' requested here; auto X = ROOT::TSeqI(42);; ^; /home/jun/dev/root/Debug/include/ROOT/TSeq.hxx:79:7: note: previous declaration is here; TSeq(T theEnd): fBegin(), fEnd(theEnd), fStep(1) {; ^; /home/jun/dev/root/Debug/include/ROOT/TSeq.hxx:82:7: error: multiple overloads of 'TSeq' instantiate to the same signature 'void (int, int, int)'; TSeq(T theBegin, T theEnd, T th",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10910#issuecomment-1253760320
Energy Efficiency,adapt,adapted,Nice change. I proposed a simplification. The tests seem to fail because the change does what it is supposed to do and the reference would need to be adapted.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10928#issuecomment-1947173074
Modifiability,adapt,adapted,Nice change. I proposed a simplification. The tests seem to fail because the change does what it is supposed to do and the reference would need to be adapted.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10928#issuecomment-1947173074
Testability,test,tests,Nice change. I proposed a simplification. The tests seem to fail because the change does what it is supposed to do and the reference would need to be adapted.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10928#issuecomment-1947173074
Usability,simpl,simplification,Nice change. I proposed a simplification. The tests seem to fail because the change does what it is supposed to do and the reference would need to be adapted.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10928#issuecomment-1947173074
Energy Efficiency,adapt,adapted,> Nice change. I proposed a simplification. The tests seem to fail because the change does what it is supposed to do and the reference would need to be adapted. Thanks! We're on it,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10928#issuecomment-1947918617
Modifiability,adapt,adapted,> Nice change. I proposed a simplification. The tests seem to fail because the change does what it is supposed to do and the reference would need to be adapted. Thanks! We're on it,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10928#issuecomment-1947918617
Testability,test,tests,> Nice change. I proposed a simplification. The tests seem to fail because the change does what it is supposed to do and the reference would need to be adapted. Thanks! We're on it,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10928#issuecomment-1947918617
Usability,simpl,simplification,> Nice change. I proposed a simplification. The tests seem to fail because the change does what it is supposed to do and the reference would need to be adapted. Thanks! We're on it,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10928#issuecomment-1947918617
Availability,error,error,"@vepadulano @Axel-Naumann with the last commit the situation is now the following:. explicit column list passed, a necessary size branch was omitted:; - compiled Snapshot throws an exception with a (hopefully) clear error message; - jitted Snapshot silently adds the required size branches. explicit column list passed, a necessary size branch is listed _after_ the branch that needs it:; - compiled and jitted Snapshot both work. no explicit column list passed:; - this is only possible with jitted Snapshots and this now works despite the fact that Snapshot reorders the column names in alphabetical order (which might put a size branch after the branch that needs it). In a subsequent PR I'll try to go back to Snapshot using the same ordering for the output columns as the ordering of the input columns -- it's not super straightforward.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10934#issuecomment-1190273501
Integrability,message,message,"@vepadulano @Axel-Naumann with the last commit the situation is now the following:. explicit column list passed, a necessary size branch was omitted:; - compiled Snapshot throws an exception with a (hopefully) clear error message; - jitted Snapshot silently adds the required size branches. explicit column list passed, a necessary size branch is listed _after_ the branch that needs it:; - compiled and jitted Snapshot both work. no explicit column list passed:; - this is only possible with jitted Snapshots and this now works despite the fact that Snapshot reorders the column names in alphabetical order (which might put a size branch after the branch that needs it). In a subsequent PR I'll try to go back to Snapshot using the same ordering for the output columns as the ordering of the input columns -- it's not super straightforward.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10934#issuecomment-1190273501
Usability,clear,clear,"@vepadulano @Axel-Naumann with the last commit the situation is now the following:. explicit column list passed, a necessary size branch was omitted:; - compiled Snapshot throws an exception with a (hopefully) clear error message; - jitted Snapshot silently adds the required size branches. explicit column list passed, a necessary size branch is listed _after_ the branch that needs it:; - compiled and jitted Snapshot both work. no explicit column list passed:; - this is only possible with jitted Snapshots and this now works despite the fact that Snapshot reorders the column names in alphabetical order (which might put a size branch after the branch that needs it). In a subsequent PR I'll try to go back to Snapshot using the same ordering for the output columns as the ordering of the input columns -- it's not super straightforward.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10934#issuecomment-1190273501
Usability,clear,clearer,"@saisoma123, I have squashed the commits. In future we should do these changes in a single commit to have a clearer history.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10936#issuecomment-1185376282
Usability,simpl,simply,The best solution is to simply remove the ClassImp which are deprecated and offer very little value added. Another solution is to simply add an empty line about of the two ClassImp so that there are not on the same line number.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10948#issuecomment-1195998820
Availability,error,error,"Just for completeness, here is a simple reproducer of the problem:. ```c++; // compile with g++ -fabi-version=6 -o test test.cpp using GCC 13.2; #include <memory>. std::unique_ptr<int> foo() { return nullptr; }. int main() {}; ```; Here is again the error:; ```txt; In file included from /usr/include/c++/13.2.1/memory:78,; from test.C:1:; /usr/include/c++/13.2.1/bits/unique_ptr.h: In instantiation of constexpr std::unique_ptr<_Tp, _Dp>::unique_ptr(std::nullptr_t) [with _Del = std::default_delete<int>; <template-parameter-2-2> = void; _Tp = int; _Dp = std::default_delete<int>; std::nullptr_t = std::nullptr_t]:; test.C:3:37: required from here; /usr/include/c++/13.2.1/bits/unique_ptr.h:360:11: error: no matching function for call to std::__uniq_ptr_data<int, std::default_delete<int>, true, true>::__uniq_ptr_data(); 360 | : _M_t(); | ^~~~~~; /usr/include/c++/13.2.1/bits/unique_ptr.h:241:40: note: candidate: template<class _Del> std::__uniq_ptr_data<int, std::default_delete<int>, true, true>::__uniq_ptr_data(std::__uniq_ptr_impl<int, std::default_delete<int> >::pointer, _Del&&) [inherited from std::__uniq_ptr_impl<int, std::default_delete<int> >]; 241 | using __uniq_ptr_impl<_Tp, _Dp>::__uniq_ptr_impl;; | ^~~~~~~~~~~~~~~; /usr/include/c++/13.2.1/bits/unique_ptr.h:241:40: note: template argument deduction/substitution failed:; /usr/include/c++/13.2.1/bits/unique_ptr.h:360:11: note: candidate expects 2 arguments, 0 provided; 360 | : _M_t(); | ^~~~~~; /usr/include/c++/13.2.1/bits/unique_ptr.h:241:40: note: candidate: std::__uniq_ptr_data<int, std::default_delete<int>, true, true>::__uniq_ptr_data(std::__uniq_ptr_impl<int, std::default_delete<int> >::pointer) [inherited from std::__uniq_ptr_impl<int, std::default_delete<int> >]; 241 | using __uniq_ptr_impl<_Tp, _Dp>::__uniq_ptr_impl;; | ^~~~~~~~~~~~~~~; /usr/include/c++/13.2.1/bits/unique_ptr.h:241:40: note: candidate expects 1 argument, 0 provided; /usr/include/c++/13.2.1/bits/unique_ptr.h:242:7: note: candidate: st",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984#issuecomment-1739815648
Modifiability,inherit,inherited," compile with g++ -fabi-version=6 -o test test.cpp using GCC 13.2; #include <memory>. std::unique_ptr<int> foo() { return nullptr; }. int main() {}; ```; Here is again the error:; ```txt; In file included from /usr/include/c++/13.2.1/memory:78,; from test.C:1:; /usr/include/c++/13.2.1/bits/unique_ptr.h: In instantiation of constexpr std::unique_ptr<_Tp, _Dp>::unique_ptr(std::nullptr_t) [with _Del = std::default_delete<int>; <template-parameter-2-2> = void; _Tp = int; _Dp = std::default_delete<int>; std::nullptr_t = std::nullptr_t]:; test.C:3:37: required from here; /usr/include/c++/13.2.1/bits/unique_ptr.h:360:11: error: no matching function for call to std::__uniq_ptr_data<int, std::default_delete<int>, true, true>::__uniq_ptr_data(); 360 | : _M_t(); | ^~~~~~; /usr/include/c++/13.2.1/bits/unique_ptr.h:241:40: note: candidate: template<class _Del> std::__uniq_ptr_data<int, std::default_delete<int>, true, true>::__uniq_ptr_data(std::__uniq_ptr_impl<int, std::default_delete<int> >::pointer, _Del&&) [inherited from std::__uniq_ptr_impl<int, std::default_delete<int> >]; 241 | using __uniq_ptr_impl<_Tp, _Dp>::__uniq_ptr_impl;; | ^~~~~~~~~~~~~~~; /usr/include/c++/13.2.1/bits/unique_ptr.h:241:40: note: template argument deduction/substitution failed:; /usr/include/c++/13.2.1/bits/unique_ptr.h:360:11: note: candidate expects 2 arguments, 0 provided; 360 | : _M_t(); | ^~~~~~; /usr/include/c++/13.2.1/bits/unique_ptr.h:241:40: note: candidate: std::__uniq_ptr_data<int, std::default_delete<int>, true, true>::__uniq_ptr_data(std::__uniq_ptr_impl<int, std::default_delete<int> >::pointer) [inherited from std::__uniq_ptr_impl<int, std::default_delete<int> >]; 241 | using __uniq_ptr_impl<_Tp, _Dp>::__uniq_ptr_impl;; | ^~~~~~~~~~~~~~~; /usr/include/c++/13.2.1/bits/unique_ptr.h:241:40: note: candidate expects 1 argument, 0 provided; /usr/include/c++/13.2.1/bits/unique_ptr.h:242:7: note: candidate: std::__uniq_ptr_data<_Tp, _Dp, <anonymous>, <anonymous> >::__uniq_ptr_data(std::",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984#issuecomment-1739815648
Testability,test,test,"Just for completeness, here is a simple reproducer of the problem:. ```c++; // compile with g++ -fabi-version=6 -o test test.cpp using GCC 13.2; #include <memory>. std::unique_ptr<int> foo() { return nullptr; }. int main() {}; ```; Here is again the error:; ```txt; In file included from /usr/include/c++/13.2.1/memory:78,; from test.C:1:; /usr/include/c++/13.2.1/bits/unique_ptr.h: In instantiation of constexpr std::unique_ptr<_Tp, _Dp>::unique_ptr(std::nullptr_t) [with _Del = std::default_delete<int>; <template-parameter-2-2> = void; _Tp = int; _Dp = std::default_delete<int>; std::nullptr_t = std::nullptr_t]:; test.C:3:37: required from here; /usr/include/c++/13.2.1/bits/unique_ptr.h:360:11: error: no matching function for call to std::__uniq_ptr_data<int, std::default_delete<int>, true, true>::__uniq_ptr_data(); 360 | : _M_t(); | ^~~~~~; /usr/include/c++/13.2.1/bits/unique_ptr.h:241:40: note: candidate: template<class _Del> std::__uniq_ptr_data<int, std::default_delete<int>, true, true>::__uniq_ptr_data(std::__uniq_ptr_impl<int, std::default_delete<int> >::pointer, _Del&&) [inherited from std::__uniq_ptr_impl<int, std::default_delete<int> >]; 241 | using __uniq_ptr_impl<_Tp, _Dp>::__uniq_ptr_impl;; | ^~~~~~~~~~~~~~~; /usr/include/c++/13.2.1/bits/unique_ptr.h:241:40: note: template argument deduction/substitution failed:; /usr/include/c++/13.2.1/bits/unique_ptr.h:360:11: note: candidate expects 2 arguments, 0 provided; 360 | : _M_t(); | ^~~~~~; /usr/include/c++/13.2.1/bits/unique_ptr.h:241:40: note: candidate: std::__uniq_ptr_data<int, std::default_delete<int>, true, true>::__uniq_ptr_data(std::__uniq_ptr_impl<int, std::default_delete<int> >::pointer) [inherited from std::__uniq_ptr_impl<int, std::default_delete<int> >]; 241 | using __uniq_ptr_impl<_Tp, _Dp>::__uniq_ptr_impl;; | ^~~~~~~~~~~~~~~; /usr/include/c++/13.2.1/bits/unique_ptr.h:241:40: note: candidate expects 1 argument, 0 provided; /usr/include/c++/13.2.1/bits/unique_ptr.h:242:7: note: candidate: st",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984#issuecomment-1739815648
Usability,simpl,simple,"Just for completeness, here is a simple reproducer of the problem:. ```c++; // compile with g++ -fabi-version=6 -o test test.cpp using GCC 13.2; #include <memory>. std::unique_ptr<int> foo() { return nullptr; }. int main() {}; ```; Here is again the error:; ```txt; In file included from /usr/include/c++/13.2.1/memory:78,; from test.C:1:; /usr/include/c++/13.2.1/bits/unique_ptr.h: In instantiation of constexpr std::unique_ptr<_Tp, _Dp>::unique_ptr(std::nullptr_t) [with _Del = std::default_delete<int>; <template-parameter-2-2> = void; _Tp = int; _Dp = std::default_delete<int>; std::nullptr_t = std::nullptr_t]:; test.C:3:37: required from here; /usr/include/c++/13.2.1/bits/unique_ptr.h:360:11: error: no matching function for call to std::__uniq_ptr_data<int, std::default_delete<int>, true, true>::__uniq_ptr_data(); 360 | : _M_t(); | ^~~~~~; /usr/include/c++/13.2.1/bits/unique_ptr.h:241:40: note: candidate: template<class _Del> std::__uniq_ptr_data<int, std::default_delete<int>, true, true>::__uniq_ptr_data(std::__uniq_ptr_impl<int, std::default_delete<int> >::pointer, _Del&&) [inherited from std::__uniq_ptr_impl<int, std::default_delete<int> >]; 241 | using __uniq_ptr_impl<_Tp, _Dp>::__uniq_ptr_impl;; | ^~~~~~~~~~~~~~~; /usr/include/c++/13.2.1/bits/unique_ptr.h:241:40: note: template argument deduction/substitution failed:; /usr/include/c++/13.2.1/bits/unique_ptr.h:360:11: note: candidate expects 2 arguments, 0 provided; 360 | : _M_t(); | ^~~~~~; /usr/include/c++/13.2.1/bits/unique_ptr.h:241:40: note: candidate: std::__uniq_ptr_data<int, std::default_delete<int>, true, true>::__uniq_ptr_data(std::__uniq_ptr_impl<int, std::default_delete<int> >::pointer) [inherited from std::__uniq_ptr_impl<int, std::default_delete<int> >]; 241 | using __uniq_ptr_impl<_Tp, _Dp>::__uniq_ptr_impl;; | ^~~~~~~~~~~~~~~; /usr/include/c++/13.2.1/bits/unique_ptr.h:241:40: note: candidate expects 1 argument, 0 provided; /usr/include/c++/13.2.1/bits/unique_ptr.h:242:7: note: candidate: st",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984#issuecomment-1739815648
Testability,log,logic,"Sorry Olivier, I missed your reply. The loop was just to see if the offset of 4 pixels appeared always, or only if the canvas was big enough. Or also to see if the offset was proportional to canvas size or not. I am not creating PNGs in the snippet above, but rather looking at the graphics are size without borders, which is what the PNG should become later. I took the logic out of the ROOT documentation:. ```; To define precisely the graphics area size of a canvas in the interactive mode, the following four lines of code should be used:; {; Double_t w = 600;; Double_t h = 600;; auto c = new TCanvas(""c"", ""c"", w, h);; c->SetWindowSize(w + (w - c->GetWw()), h + (h - c->GetWh()));; }. and in the batch mode simply do:; c->SetCanvasSize(w,h);; ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11004#issuecomment-1618360139
Usability,simpl,simply,"Sorry Olivier, I missed your reply. The loop was just to see if the offset of 4 pixels appeared always, or only if the canvas was big enough. Or also to see if the offset was proportional to canvas size or not. I am not creating PNGs in the snippet above, but rather looking at the graphics are size without borders, which is what the PNG should become later. I took the logic out of the ROOT documentation:. ```; To define precisely the graphics area size of a canvas in the interactive mode, the following four lines of code should be used:; {; Double_t w = 600;; Double_t h = 600;; auto c = new TCanvas(""c"", ""c"", w, h);; c->SetWindowSize(w + (w - c->GetWw()), h + (h - c->GetWh()));; }. and in the batch mode simply do:; c->SetCanvasSize(w,h);; ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11004#issuecomment-1618360139
Availability,failure,failures,"Correct - and I wanted to start small (`vector`, `string`) and see what roottest has to say about that. I did expect some test failures?! That would guide me what else we should expose. Which makes me wonder whether this works at all - nope, it doesn't. Let me fix that...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11027#issuecomment-1192710542
Security,expose,expose,"Correct - and I wanted to start small (`vector`, `string`) and see what roottest has to say about that. I did expect some test failures?! That would guide me what else we should expose. Which makes me wonder whether this works at all - nope, it doesn't. Let me fix that...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11027#issuecomment-1192710542
Testability,test,test,"Correct - and I wanted to start small (`vector`, `string`) and see what roottest has to say about that. I did expect some test failures?! That would guide me what else we should expose. Which makes me wonder whether this works at all - nope, it doesn't. Let me fix that...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11027#issuecomment-1192710542
Usability,guid,guide,"Correct - and I wanted to start small (`vector`, `string`) and see what roottest has to say about that. I did expect some test failures?! That would guide me what else we should expose. Which makes me wonder whether this works at all - nope, it doesn't. Let me fix that...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11027#issuecomment-1192710542
Availability,error,error,Build failed on mac12/noimt.; Running on macphsft18.dyndns.cern.ch:/Users/sftnight/build/jenkins/workspace/root-pullrequests-build; [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/174395/console).; ### Errors:; - [2023-05-11T12:18:54.188Z] FAILED: core/CMakeFiles/G__Core.dir/G__Core.cxx.o ; - [2023-05-11T12:18:54.761Z] /Users/sftnight/build/jenkins/workspace/root-pullrequests-build/build/core/G__Core.cxx:11318:52: error: no type named 'TVirtualRWMutex' in the global namespace; did you mean simply 'TVirtualRWMutex'? ; - [2023-05-11T12:18:54.761Z] /Users/sftnight/build/jenkins/workspace/root-pullrequests-build/build/core/G__Core.cxx:11324:52: error: no type named 'TVirtualRWMutex' in the global namespace; did you mean simply 'TVirtualRWMutex'? ; - [2023-05-11T12:18:54.761Z] /Users/sftnight/build/jenkins/workspace/root-pullrequests-build/build/core/G__Core.cxx:11330:53: error: no type named 'TVirtualRWMutex' in the global namespace; did you mean simply 'TVirtualRWMutex'? ; - [2023-05-11T12:18:54.761Z] /Users/sftnight/build/jenkins/workspace/root-pullrequests-build/build/core/G__Core.cxx:11337:107: error: no type named 'TVirtualRWMutex' in the global namespace; did you mean simply 'TVirtualRWMutex'? ; - [2023-05-11T12:18:54.761Z] /Users/sftnight/build/jenkins/workspace/root-pullrequests-build/build/core/G__Core.cxx:11355:52: error: no type named 'TReadLockGuard' in the global namespace; did you mean simply 'TReadLockGuard'? ; - [2023-05-11T12:18:54.761Z] /Users/sftnight/build/jenkins/workspace/root-pullrequests-build/build/core/G__Core.cxx:11361:52: error: no type named 'TReadLockGuard' in the global namespace; did you mean simply 'TReadLockGuard'? ; - [2023-05-11T12:18:54.761Z] /Users/sftnight/build/jenkins/workspace/root-pullrequests-build/build/core/G__Core.cxx:11367:53: error: no type named 'TReadLockGuard' in the global namespace; did you mean simply 'TReadLockGuard'? ; - [2023-05-11T12:18:54.761Z] /Users/sftnight/build/,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11027#issuecomment-1543894216
Usability,simpl,simply,Build failed on mac12/noimt.; Running on macphsft18.dyndns.cern.ch:/Users/sftnight/build/jenkins/workspace/root-pullrequests-build; [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/174395/console).; ### Errors:; - [2023-05-11T12:18:54.188Z] FAILED: core/CMakeFiles/G__Core.dir/G__Core.cxx.o ; - [2023-05-11T12:18:54.761Z] /Users/sftnight/build/jenkins/workspace/root-pullrequests-build/build/core/G__Core.cxx:11318:52: error: no type named 'TVirtualRWMutex' in the global namespace; did you mean simply 'TVirtualRWMutex'? ; - [2023-05-11T12:18:54.761Z] /Users/sftnight/build/jenkins/workspace/root-pullrequests-build/build/core/G__Core.cxx:11324:52: error: no type named 'TVirtualRWMutex' in the global namespace; did you mean simply 'TVirtualRWMutex'? ; - [2023-05-11T12:18:54.761Z] /Users/sftnight/build/jenkins/workspace/root-pullrequests-build/build/core/G__Core.cxx:11330:53: error: no type named 'TVirtualRWMutex' in the global namespace; did you mean simply 'TVirtualRWMutex'? ; - [2023-05-11T12:18:54.761Z] /Users/sftnight/build/jenkins/workspace/root-pullrequests-build/build/core/G__Core.cxx:11337:107: error: no type named 'TVirtualRWMutex' in the global namespace; did you mean simply 'TVirtualRWMutex'? ; - [2023-05-11T12:18:54.761Z] /Users/sftnight/build/jenkins/workspace/root-pullrequests-build/build/core/G__Core.cxx:11355:52: error: no type named 'TReadLockGuard' in the global namespace; did you mean simply 'TReadLockGuard'? ; - [2023-05-11T12:18:54.761Z] /Users/sftnight/build/jenkins/workspace/root-pullrequests-build/build/core/G__Core.cxx:11361:52: error: no type named 'TReadLockGuard' in the global namespace; did you mean simply 'TReadLockGuard'? ; - [2023-05-11T12:18:54.761Z] /Users/sftnight/build/jenkins/workspace/root-pullrequests-build/build/core/G__Core.cxx:11367:53: error: no type named 'TReadLockGuard' in the global namespace; did you mean simply 'TReadLockGuard'? ; - [2023-05-11T12:18:54.761Z] /Users/sftnight/build/,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11027#issuecomment-1543894216
Availability,error,error,Build failed on mac11/cxx14.; Running on macphsft23.dyndns.cern.ch:/Users/sftnight/build/workspace/root-pullrequests-build; [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/174396/console).; ### Errors:; - [2023-05-11T12:52:41.022Z] FAILED: core/CMakeFiles/G__Core.dir/G__Core.cxx.o ; - [2023-05-11T12:52:41.023Z] /Users/sftnight/build/workspace/root-pullrequests-build/build/core/G__Core.cxx:11318:52: error: no type named 'TVirtualRWMutex' in the global namespace; did you mean simply 'TVirtualRWMutex'? ; - [2023-05-11T12:52:41.023Z] /Users/sftnight/build/workspace/root-pullrequests-build/build/core/G__Core.cxx:11324:52: error: no type named 'TVirtualRWMutex' in the global namespace; did you mean simply 'TVirtualRWMutex'? ; - [2023-05-11T12:52:41.023Z] /Users/sftnight/build/workspace/root-pullrequests-build/build/core/G__Core.cxx:11330:53: error: no type named 'TVirtualRWMutex' in the global namespace; did you mean simply 'TVirtualRWMutex'? ; - [2023-05-11T12:52:41.023Z] /Users/sftnight/build/workspace/root-pullrequests-build/build/core/G__Core.cxx:11337:107: error: no type named 'TVirtualRWMutex' in the global namespace; did you mean simply 'TVirtualRWMutex'? ; - [2023-05-11T12:52:41.023Z] /Users/sftnight/build/workspace/root-pullrequests-build/build/core/G__Core.cxx:11355:52: error: no type named 'TReadLockGuard' in the global namespace; did you mean simply 'TReadLockGuard'? ; - [2023-05-11T12:52:41.023Z] /Users/sftnight/build/workspace/root-pullrequests-build/build/core/G__Core.cxx:11361:52: error: no type named 'TReadLockGuard' in the global namespace; did you mean simply 'TReadLockGuard'? ; - [2023-05-11T12:52:41.023Z] /Users/sftnight/build/workspace/root-pullrequests-build/build/core/G__Core.cxx:11367:53: error: no type named 'TReadLockGuard' in the global namespace; did you mean simply 'TReadLockGuard'? ; - [2023-05-11T12:52:41.023Z] /Users/sftnight/build/workspace/root-pullrequests-build/build/core/G__Core.cxx:11374:1,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11027#issuecomment-1543945512
Usability,simpl,simply,Build failed on mac11/cxx14.; Running on macphsft23.dyndns.cern.ch:/Users/sftnight/build/workspace/root-pullrequests-build; [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/174396/console).; ### Errors:; - [2023-05-11T12:52:41.022Z] FAILED: core/CMakeFiles/G__Core.dir/G__Core.cxx.o ; - [2023-05-11T12:52:41.023Z] /Users/sftnight/build/workspace/root-pullrequests-build/build/core/G__Core.cxx:11318:52: error: no type named 'TVirtualRWMutex' in the global namespace; did you mean simply 'TVirtualRWMutex'? ; - [2023-05-11T12:52:41.023Z] /Users/sftnight/build/workspace/root-pullrequests-build/build/core/G__Core.cxx:11324:52: error: no type named 'TVirtualRWMutex' in the global namespace; did you mean simply 'TVirtualRWMutex'? ; - [2023-05-11T12:52:41.023Z] /Users/sftnight/build/workspace/root-pullrequests-build/build/core/G__Core.cxx:11330:53: error: no type named 'TVirtualRWMutex' in the global namespace; did you mean simply 'TVirtualRWMutex'? ; - [2023-05-11T12:52:41.023Z] /Users/sftnight/build/workspace/root-pullrequests-build/build/core/G__Core.cxx:11337:107: error: no type named 'TVirtualRWMutex' in the global namespace; did you mean simply 'TVirtualRWMutex'? ; - [2023-05-11T12:52:41.023Z] /Users/sftnight/build/workspace/root-pullrequests-build/build/core/G__Core.cxx:11355:52: error: no type named 'TReadLockGuard' in the global namespace; did you mean simply 'TReadLockGuard'? ; - [2023-05-11T12:52:41.023Z] /Users/sftnight/build/workspace/root-pullrequests-build/build/core/G__Core.cxx:11361:52: error: no type named 'TReadLockGuard' in the global namespace; did you mean simply 'TReadLockGuard'? ; - [2023-05-11T12:52:41.023Z] /Users/sftnight/build/workspace/root-pullrequests-build/build/core/G__Core.cxx:11367:53: error: no type named 'TReadLockGuard' in the global namespace; did you mean simply 'TReadLockGuard'? ; - [2023-05-11T12:52:41.023Z] /Users/sftnight/build/workspace/root-pullrequests-build/build/core/G__Core.cxx:11374:1,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11027#issuecomment-1543945512
Modifiability,variab,variables,"I am realizing that making removing the global variables which are meant to hold the values from the argument parser is probably not a good idea after all. It makes the code less clear for me. Is there a way to make a global variable in python read only?. I know we merged already at least one PR of that kind but I fear we might need to revert it... @saisoma123, @jalopezg-r00t, what do you think?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11037#issuecomment-1200360373
Usability,clear,clear,"I am realizing that making removing the global variables which are meant to hold the values from the argument parser is probably not a good idea after all. It makes the code less clear for me. Is there a way to make a global variable in python read only?. I know we merged already at least one PR of that kind but I fear we might need to revert it... @saisoma123, @jalopezg-r00t, what do you think?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11037#issuecomment-1200360373
Energy Efficiency,reduce,reduce,"Hi, I had to rebase to change the code format to pass the clang-tools code analysis check (is this new? I didn't have to do this in my previous pull request which had the same formatting as this PR which it is now unhappy with. Also weirdly one of the things it required was in LinkDef.h putting a space before and after ""+"" which isn't consistent with the other lines. Also it required some very weird/bad formatting for calling the function ""plotTwoTGraphs"" in the tutorial added, I think it is trying to reduce the number of characters per line, but it does it in a quite poor way. Also the command that the script ""https://github.com/root-project/root/blob/master/.ci/format_script.sh"" which does this format check says to run to rebase is incorrect. It says to do:. ```; git rebase -i -x ""git-clang-format-7 master && git commit -a --allow-empty --fixup=HEAD"" --strategy-option=theirs origin/master; git rebase --autosquash -i master; ```; But this does not run and complains that master does not exist. It should be; ```; git rebase -i -x ""git-clang-format-8 origin/master && git commit -a --allow-empty --fixup=HEAD"" --strategy-option=theirs origin/master; git rebase --autosquash -i origin/master; ```; [i.e. master-> origin/master]; ). This rebase added some spurious commit messages. When (/if) this pull request is accepted, could you please select ""squash and merge"", it's a lot simpler than me having to rebase and squashing manually in the terminal (which last time I tried I messed up so bad I ended up just having to delete my fork and start over), the title of the PR works as a commit message for the full thing ""Add Relativistic Voigt Function to TMath"". Thanks in advance for any help,; Jack",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11049#issuecomment-1194998699
Integrability,message,messages,"Hi, I had to rebase to change the code format to pass the clang-tools code analysis check (is this new? I didn't have to do this in my previous pull request which had the same formatting as this PR which it is now unhappy with. Also weirdly one of the things it required was in LinkDef.h putting a space before and after ""+"" which isn't consistent with the other lines. Also it required some very weird/bad formatting for calling the function ""plotTwoTGraphs"" in the tutorial added, I think it is trying to reduce the number of characters per line, but it does it in a quite poor way. Also the command that the script ""https://github.com/root-project/root/blob/master/.ci/format_script.sh"" which does this format check says to run to rebase is incorrect. It says to do:. ```; git rebase -i -x ""git-clang-format-7 master && git commit -a --allow-empty --fixup=HEAD"" --strategy-option=theirs origin/master; git rebase --autosquash -i master; ```; But this does not run and complains that master does not exist. It should be; ```; git rebase -i -x ""git-clang-format-8 origin/master && git commit -a --allow-empty --fixup=HEAD"" --strategy-option=theirs origin/master; git rebase --autosquash -i origin/master; ```; [i.e. master-> origin/master]; ). This rebase added some spurious commit messages. When (/if) this pull request is accepted, could you please select ""squash and merge"", it's a lot simpler than me having to rebase and squashing manually in the terminal (which last time I tried I messed up so bad I ended up just having to delete my fork and start over), the title of the PR works as a commit message for the full thing ""Add Relativistic Voigt Function to TMath"". Thanks in advance for any help,; Jack",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11049#issuecomment-1194998699
Usability,simpl,simpler,"Hi, I had to rebase to change the code format to pass the clang-tools code analysis check (is this new? I didn't have to do this in my previous pull request which had the same formatting as this PR which it is now unhappy with. Also weirdly one of the things it required was in LinkDef.h putting a space before and after ""+"" which isn't consistent with the other lines. Also it required some very weird/bad formatting for calling the function ""plotTwoTGraphs"" in the tutorial added, I think it is trying to reduce the number of characters per line, but it does it in a quite poor way. Also the command that the script ""https://github.com/root-project/root/blob/master/.ci/format_script.sh"" which does this format check says to run to rebase is incorrect. It says to do:. ```; git rebase -i -x ""git-clang-format-7 master && git commit -a --allow-empty --fixup=HEAD"" --strategy-option=theirs origin/master; git rebase --autosquash -i master; ```; But this does not run and complains that master does not exist. It should be; ```; git rebase -i -x ""git-clang-format-8 origin/master && git commit -a --allow-empty --fixup=HEAD"" --strategy-option=theirs origin/master; git rebase --autosquash -i origin/master; ```; [i.e. master-> origin/master]; ). This rebase added some spurious commit messages. When (/if) this pull request is accepted, could you please select ""squash and merge"", it's a lot simpler than me having to rebase and squashing manually in the terminal (which last time I tried I messed up so bad I ended up just having to delete my fork and start over), the title of the PR works as a commit message for the full thing ""Add Relativistic Voigt Function to TMath"". Thanks in advance for any help,; Jack",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11049#issuecomment-1194998699
Performance,cache,cache,"Hi,; yes following the linked example of the VavilovAccuratePdf is fine. It is true you have made a class, but only with static functions. Like this is not needed to be a class, can be simple function in a namespace. The advantage of having as a class is that one can cache some information as class data members. . Then test of the Vavilov is also a good example, however it is better to use the google test framework, resulting in a much simpler test to write. You need just to use the macro defined by test to compare the function value with the reference one. ; You have many examples in ROOT for gtest, for example in `hist/hist/test` directory like `test_TH1.cxx` or `test_TFormula.cxx`, `test_TF123_Moments.cxx`. If you need any help for the test, please let me know",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11049#issuecomment-1202195997
Testability,test,test,"Hi,; yes following the linked example of the VavilovAccuratePdf is fine. It is true you have made a class, but only with static functions. Like this is not needed to be a class, can be simple function in a namespace. The advantage of having as a class is that one can cache some information as class data members. . Then test of the Vavilov is also a good example, however it is better to use the google test framework, resulting in a much simpler test to write. You need just to use the macro defined by test to compare the function value with the reference one. ; You have many examples in ROOT for gtest, for example in `hist/hist/test` directory like `test_TH1.cxx` or `test_TFormula.cxx`, `test_TF123_Moments.cxx`. If you need any help for the test, please let me know",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11049#issuecomment-1202195997
Usability,simpl,simple,"Hi,; yes following the linked example of the VavilovAccuratePdf is fine. It is true you have made a class, but only with static functions. Like this is not needed to be a class, can be simple function in a namespace. The advantage of having as a class is that one can cache some information as class data members. . Then test of the Vavilov is also a good example, however it is better to use the google test framework, resulting in a much simpler test to write. You need just to use the macro defined by test to compare the function value with the reference one. ; You have many examples in ROOT for gtest, for example in `hist/hist/test` directory like `test_TH1.cxx` or `test_TFormula.cxx`, `test_TF123_Moments.cxx`. If you need any help for the test, please let me know",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11049#issuecomment-1202195997
Availability,toler,tolerance,"Here you go!; - It checks pdg against TGeoROOT with tolerance; - It checks pdg against TGeoG4 with tolerance; - It checks TGeoROOT against TGeoG4 with numerical tolerance 1e-15 (some math simply is different); ```; $> root.exe test_material_units.C; ------------------------------------------------------------------; | Welcome to ROOT 6.27/01 https://root.cern |; | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |; | Built for linuxx8664gcc on Jul 27 2022, 14:22:00 |; | From heads/fix_radlen_g4units@v6-25-01-4723-g1344269685 |; | With |; | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |; ------------------------------------------------------------------. root [0] ; Processing ../test_material_units.C...; Using ROOT system of units. ; Element: SI Z=14 N=28.000000 A=28.085500 [g/mole]; Material Mat_Si_TGeo A=28.0855 Z=14 rho=2.329 radlen=9.35361 intlen=45.7729 index=0; Element: FE Z=26 N=56.000000 A=55.845000 [g/mole]; Material Mat_Fe_TGeo A=55.845 Z=26 rho=7.874 radlen=1.75666 intlen=16.9589 index=4; Element: U Z=92 N=238.000000 A=238.028900 [g/mole]; Material Mat_U_TGeo A=238.029 Z=92 rho=18.95 radlen=0.316948 intlen=11.4473 index=8; Info in <TGeoManager>: Changing system of units to Geant4 units (mm, ns, MeV).; Using Geant4 system of units. ; Element: SI Z=14 N=28.000000 A=28.085500 [g/mole]; Material Mat_Si_G4 A=28.0855 Z=14 rho=2.329 radlen=93.5361 intlen=457.729 index=0; Element: FE Z=26 N=56.000000 A=55.845000 [g/mole]; Material Mat_Fe_G4 A=55.845 Z=26 rho=7.874 radlen=17.5666 intlen=169.589 index=4; Element: U Z=92 N=238.000000 A=238.028900 [g/mole]; Material Mat_U_G4 A=238.029 Z=92 rho=18.95 radlen=3.16948 intlen=114.473 index=8; TEST PASSED Si vs. Mat_Si_TGeo Units: TGeo Deviation density: 0 % RadLen: 0.17 % IntLen: 1.6 % ; TEST PASSED Si vs. Mix_1_Si_TGeo Units: TGeo Deviation density: 0 % RadLen: 0.0015 % IntLen: 1.6 % ; TEST PASSED Si vs. Mix_2_Si_TGeo Units: TGeo Deviation density: 0 % RadLen: 0.17 % IntLen: 1.6 % ; TEST ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11060#issuecomment-1198355345
Safety,detect,detected,e vs. Mix_1_Fe_G4 Units: G4 Deviation density: 0 % RadLen: 0.028 % IntLen: 1.1 % ; TEST PASSED Fe vs. Mix_2_Fe_G4 Units: G4 Deviation density: 0 % RadLen: 0.019 % IntLen: 1.1 % ; TEST PASSED Fe vs. Mix_3_Fe_G4 Units: G4 Deviation density: 0 % RadLen: 0.019 % IntLen: 1.1 % ; TEST PASSED Mat_Fe_TGeo vs. Mat_Fe_G4 Units: G4 Deviation density: 0 % RadLen: 2.2e-14 % IntLen: 0 % ; TEST PASSED Mix_1_Fe_TGeo vs. Mix_1_Fe_G4 Units: G4 Deviation density: 0 % RadLen: 0 % IntLen: 0 % ; TEST PASSED Mix_2_Fe_TGeo vs. Mix_2_Fe_G4 Units: G4 Deviation density: 0 % RadLen: 2.2e-14 % IntLen: 0 % ; TEST PASSED Mix_3_Fe_TGeo vs. Mix_3_Fe_G4 Units: G4 Deviation density: 0 % RadLen: 2.2e-14 % IntLen: 0 % ; TEST PASSED U vs. Mat_U_TGeo Units: TGeo Deviation density: 0 % RadLen: 0.11 % IntLen: 3.8 % ; TEST PASSED U vs. Mix_1_U_TGeo Units: TGeo Deviation density: 0 % RadLen: 0.0093 % IntLen: 3.8 % ; TEST PASSED U vs. Mix_2_U_TGeo Units: TGeo Deviation density: 0 % RadLen: 0.11 % IntLen: 3.8 % ; TEST PASSED U vs. Mix_3_U_TGeo Units: TGeo Deviation density: 0 % RadLen: 0.11 % IntLen: 3.8 % ; TEST PASSED U vs. Mat_U_G4 Units: G4 Deviation density: 0 % RadLen: 0.11 % IntLen: 3.8 % ; TEST PASSED U vs. Mix_1_U_G4 Units: G4 Deviation density: 0 % RadLen: 0.0093 % IntLen: 3.8 % ; TEST PASSED U vs. Mix_2_U_G4 Units: G4 Deviation density: 0 % RadLen: 0.11 % IntLen: 3.8 % ; TEST PASSED U vs. Mix_3_U_G4 Units: G4 Deviation density: 0 % RadLen: 0.11 % IntLen: 3.8 % ; TEST PASSED Mat_U_TGeo vs. Mat_U_G4 Units: G4 Deviation density: 0 % RadLen: 0 % IntLen: 0 % ; TEST PASSED Mix_1_U_TGeo vs. Mix_1_U_G4 Units: G4 Deviation density: 0 % RadLen: 0 % IntLen: 0 % ; TEST PASSED Mix_2_U_TGeo vs. Mix_2_U_G4 Units: G4 Deviation density: 0 % RadLen: 0 % IntLen: 0 % ; TEST PASSED Mix_3_U_TGeo vs. Mix_3_U_G4 Units: G4 Deviation density: 0 % RadLen: 0 % IntLen: 0 % . TEST PASSED Hurray!!!! 0 failures detected.; ```; [test_material_units.C.txt](https://github.com/root-project/root/files/9212397/test_material_units.C.txt),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11060#issuecomment-1198355345
Usability,simpl,simply,"Here you go!; - It checks pdg against TGeoROOT with tolerance; - It checks pdg against TGeoG4 with tolerance; - It checks TGeoROOT against TGeoG4 with numerical tolerance 1e-15 (some math simply is different); ```; $> root.exe test_material_units.C; ------------------------------------------------------------------; | Welcome to ROOT 6.27/01 https://root.cern |; | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |; | Built for linuxx8664gcc on Jul 27 2022, 14:22:00 |; | From heads/fix_radlen_g4units@v6-25-01-4723-g1344269685 |; | With |; | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |; ------------------------------------------------------------------. root [0] ; Processing ../test_material_units.C...; Using ROOT system of units. ; Element: SI Z=14 N=28.000000 A=28.085500 [g/mole]; Material Mat_Si_TGeo A=28.0855 Z=14 rho=2.329 radlen=9.35361 intlen=45.7729 index=0; Element: FE Z=26 N=56.000000 A=55.845000 [g/mole]; Material Mat_Fe_TGeo A=55.845 Z=26 rho=7.874 radlen=1.75666 intlen=16.9589 index=4; Element: U Z=92 N=238.000000 A=238.028900 [g/mole]; Material Mat_U_TGeo A=238.029 Z=92 rho=18.95 radlen=0.316948 intlen=11.4473 index=8; Info in <TGeoManager>: Changing system of units to Geant4 units (mm, ns, MeV).; Using Geant4 system of units. ; Element: SI Z=14 N=28.000000 A=28.085500 [g/mole]; Material Mat_Si_G4 A=28.0855 Z=14 rho=2.329 radlen=93.5361 intlen=457.729 index=0; Element: FE Z=26 N=56.000000 A=55.845000 [g/mole]; Material Mat_Fe_G4 A=55.845 Z=26 rho=7.874 radlen=17.5666 intlen=169.589 index=4; Element: U Z=92 N=238.000000 A=238.028900 [g/mole]; Material Mat_U_G4 A=238.029 Z=92 rho=18.95 radlen=3.16948 intlen=114.473 index=8; TEST PASSED Si vs. Mat_Si_TGeo Units: TGeo Deviation density: 0 % RadLen: 0.17 % IntLen: 1.6 % ; TEST PASSED Si vs. Mix_1_Si_TGeo Units: TGeo Deviation density: 0 % RadLen: 0.0015 % IntLen: 1.6 % ; TEST PASSED Si vs. Mix_2_Si_TGeo Units: TGeo Deviation density: 0 % RadLen: 0.17 % IntLen: 1.6 % ; TEST ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11060#issuecomment-1198355345
Availability,error,error,"Indeed, I should have updated the PR with a comment earlier. At least we can raise the error on the python side though, the call to the pythonization happens before the C++ constructor is called. Maybe the check can be something more specific like; ```python; url = ROOT.TUrl(filename); if url.GetProtocol() != ""file"":; raise ValueError(); ```; instead of the current more simplistic check",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11063#issuecomment-1198458818
Deployability,update,updated,"Indeed, I should have updated the PR with a comment earlier. At least we can raise the error on the python side though, the call to the pythonization happens before the C++ constructor is called. Maybe the check can be something more specific like; ```python; url = ROOT.TUrl(filename); if url.GetProtocol() != ""file"":; raise ValueError(); ```; instead of the current more simplistic check",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11063#issuecomment-1198458818
Usability,simpl,simplistic,"Indeed, I should have updated the PR with a comment earlier. At least we can raise the error on the python side though, the call to the pythonization happens before the C++ constructor is called. Maybe the check can be something more specific like; ```python; url = ROOT.TUrl(filename); if url.GetProtocol() != ""file"":; raise ValueError(); ```; instead of the current more simplistic check",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11063#issuecomment-1198458818
Usability,clear,clear,"Please use https://root-forum.cern.ch to discuss issues. A GitHub bug report is most useful only once it's clear that it is indeed an issue with ROOT and that we know how to reproduce it. This here is *not* and issue with ROOT, at least it's all but obvious why it would be. The crash happens in `Fatima::ReadSensitive(G4Event const*)` or something called by it, and that's not ROOT.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11071#issuecomment-1199109958
Availability,error,error,"I don't think this is used by anyone, as it is not clear to the users that copy assignment does for RooFit objects. More complicated user codes like for example are CMS combine are still compiling with these changes. If someone was using this functionality, they will get warned with a compiler error now and can find a workaround.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11079#issuecomment-1204165478
Usability,clear,clear,"I don't think this is used by anyone, as it is not clear to the users that copy assignment does for RooFit objects. More complicated user codes like for example are CMS combine are still compiling with these changes. If someone was using this functionality, they will get warned with a compiler error now and can find a workaround.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11079#issuecomment-1204165478
Availability,redundant,redundant,"> Hi Hanna, thank you very much for the PR!; > ; > Code changes look fine, but can you please change the commit message to explain why it was possible to use `setValFast` in `setBin`? That it's redundant to do the range, check in `getVal`, because the value you pass to `setBin` is a bin center which is in the variable range by definition anyway. Thank you for the comment, I hope the new commit message is clearer!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11090#issuecomment-1202401228
Integrability,message,message,"> Hi Hanna, thank you very much for the PR!; > ; > Code changes look fine, but can you please change the commit message to explain why it was possible to use `setValFast` in `setBin`? That it's redundant to do the range, check in `getVal`, because the value you pass to `setBin` is a bin center which is in the variable range by definition anyway. Thank you for the comment, I hope the new commit message is clearer!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11090#issuecomment-1202401228
Modifiability,variab,variable,"> Hi Hanna, thank you very much for the PR!; > ; > Code changes look fine, but can you please change the commit message to explain why it was possible to use `setValFast` in `setBin`? That it's redundant to do the range, check in `getVal`, because the value you pass to `setBin` is a bin center which is in the variable range by definition anyway. Thank you for the comment, I hope the new commit message is clearer!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11090#issuecomment-1202401228
Safety,redund,redundant,"> Hi Hanna, thank you very much for the PR!; > ; > Code changes look fine, but can you please change the commit message to explain why it was possible to use `setValFast` in `setBin`? That it's redundant to do the range, check in `getVal`, because the value you pass to `setBin` is a bin center which is in the variable range by definition anyway. Thank you for the comment, I hope the new commit message is clearer!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11090#issuecomment-1202401228
Usability,clear,clearer,"> Hi Hanna, thank you very much for the PR!; > ; > Code changes look fine, but can you please change the commit message to explain why it was possible to use `setValFast` in `setBin`? That it's redundant to do the range, check in `getVal`, because the value you pass to `setBin` is a bin center which is in the variable range by definition anyway. Thank you for the comment, I hope the new commit message is clearer!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11090#issuecomment-1202401228
Energy Efficiency,power,power,"> > I am almost certain that non-critical changes wont make it back upstream.; > ; > I think all of us appreciate the time and brain power Vincenzo invests in improving the code. I bet it's useful to propose changes coming out of this upstream where relevant, @sudo-panda ?. Hi @Axel-Naumann ,. I am really grateful to @vepadulano for investing his precious time in reviewing this PR and suggesting changes to improve it. If not for his suggestions about the `namespace NumbaExt` code, I wouldn't have been able to simplify it. On the other hand, @vgvassilev is right about the global statements being a non-critical change and wouldn't be accepted upstream. And I am sure when he said that, he didn't mean that Vincenzo's efforts were wasteful. Finally, AFAIU Vincenzo thinks that global statements are unnecessary because the code acts in the same way whether you keep them or not. I have a few counterpoints to this:. 1. It gives programmers an idea about where the variable was initialized before use. Modifying the code provided by Vincenzo:. ```python; cache = {}. def foo():; .....; .... Many lines of code ...; .....; cache[""foo""] = 1. .....; .... Many lines of code ...; ..... def bar():; .....; .... Many lines of code ...; .....; cache[""bar""] = 2; ```. I hope you can see it becomes difficult to understand where did cache come from. A `global cache` statement at the top of the function or before its use clarifies the intent. 2. Removing the `global` statement doesn't affect the scope of the variable. It is purely meant to [guide Python for the code block it is used in.](https://docs.python.org/3/reference/simple_stmts.html#the-global-statement). 3. ROOT already uses `global` keyword in [JupyROOT](https://github.com/root-project/root/blame/a90d76b7798dc4332425d29794089fceaebccb60/bindings/jupyroot/python/JupyROOT/helpers/utils.py#L126 ). So unless ""we should never use `global`"" is a new convention being followed in ROOT, I believe it doesn't seem to track. 4. As seen in this [",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11096#issuecomment-1603484912
Modifiability,variab,variable,"> > I am almost certain that non-critical changes wont make it back upstream.; > ; > I think all of us appreciate the time and brain power Vincenzo invests in improving the code. I bet it's useful to propose changes coming out of this upstream where relevant, @sudo-panda ?. Hi @Axel-Naumann ,. I am really grateful to @vepadulano for investing his precious time in reviewing this PR and suggesting changes to improve it. If not for his suggestions about the `namespace NumbaExt` code, I wouldn't have been able to simplify it. On the other hand, @vgvassilev is right about the global statements being a non-critical change and wouldn't be accepted upstream. And I am sure when he said that, he didn't mean that Vincenzo's efforts were wasteful. Finally, AFAIU Vincenzo thinks that global statements are unnecessary because the code acts in the same way whether you keep them or not. I have a few counterpoints to this:. 1. It gives programmers an idea about where the variable was initialized before use. Modifying the code provided by Vincenzo:. ```python; cache = {}. def foo():; .....; .... Many lines of code ...; .....; cache[""foo""] = 1. .....; .... Many lines of code ...; ..... def bar():; .....; .... Many lines of code ...; .....; cache[""bar""] = 2; ```. I hope you can see it becomes difficult to understand where did cache come from. A `global cache` statement at the top of the function or before its use clarifies the intent. 2. Removing the `global` statement doesn't affect the scope of the variable. It is purely meant to [guide Python for the code block it is used in.](https://docs.python.org/3/reference/simple_stmts.html#the-global-statement). 3. ROOT already uses `global` keyword in [JupyROOT](https://github.com/root-project/root/blame/a90d76b7798dc4332425d29794089fceaebccb60/bindings/jupyroot/python/JupyROOT/helpers/utils.py#L126 ). So unless ""we should never use `global`"" is a new convention being followed in ROOT, I believe it doesn't seem to track. 4. As seen in this [",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11096#issuecomment-1603484912
Performance,cache,cache,"e it back upstream.; > ; > I think all of us appreciate the time and brain power Vincenzo invests in improving the code. I bet it's useful to propose changes coming out of this upstream where relevant, @sudo-panda ?. Hi @Axel-Naumann ,. I am really grateful to @vepadulano for investing his precious time in reviewing this PR and suggesting changes to improve it. If not for his suggestions about the `namespace NumbaExt` code, I wouldn't have been able to simplify it. On the other hand, @vgvassilev is right about the global statements being a non-critical change and wouldn't be accepted upstream. And I am sure when he said that, he didn't mean that Vincenzo's efforts were wasteful. Finally, AFAIU Vincenzo thinks that global statements are unnecessary because the code acts in the same way whether you keep them or not. I have a few counterpoints to this:. 1. It gives programmers an idea about where the variable was initialized before use. Modifying the code provided by Vincenzo:. ```python; cache = {}. def foo():; .....; .... Many lines of code ...; .....; cache[""foo""] = 1. .....; .... Many lines of code ...; ..... def bar():; .....; .... Many lines of code ...; .....; cache[""bar""] = 2; ```. I hope you can see it becomes difficult to understand where did cache come from. A `global cache` statement at the top of the function or before its use clarifies the intent. 2. Removing the `global` statement doesn't affect the scope of the variable. It is purely meant to [guide Python for the code block it is used in.](https://docs.python.org/3/reference/simple_stmts.html#the-global-statement). 3. ROOT already uses `global` keyword in [JupyROOT](https://github.com/root-project/root/blame/a90d76b7798dc4332425d29794089fceaebccb60/bindings/jupyroot/python/JupyROOT/helpers/utils.py#L126 ). So unless ""we should never use `global`"" is a new convention being followed in ROOT, I believe it doesn't seem to track. 4. As seen in this [SO answer](https://stackoverflow.com/a/4693392), Python use",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11096#issuecomment-1603484912
Usability,simpl,simplify,"> > I am almost certain that non-critical changes wont make it back upstream.; > ; > I think all of us appreciate the time and brain power Vincenzo invests in improving the code. I bet it's useful to propose changes coming out of this upstream where relevant, @sudo-panda ?. Hi @Axel-Naumann ,. I am really grateful to @vepadulano for investing his precious time in reviewing this PR and suggesting changes to improve it. If not for his suggestions about the `namespace NumbaExt` code, I wouldn't have been able to simplify it. On the other hand, @vgvassilev is right about the global statements being a non-critical change and wouldn't be accepted upstream. And I am sure when he said that, he didn't mean that Vincenzo's efforts were wasteful. Finally, AFAIU Vincenzo thinks that global statements are unnecessary because the code acts in the same way whether you keep them or not. I have a few counterpoints to this:. 1. It gives programmers an idea about where the variable was initialized before use. Modifying the code provided by Vincenzo:. ```python; cache = {}. def foo():; .....; .... Many lines of code ...; .....; cache[""foo""] = 1. .....; .... Many lines of code ...; ..... def bar():; .....; .... Many lines of code ...; .....; cache[""bar""] = 2; ```. I hope you can see it becomes difficult to understand where did cache come from. A `global cache` statement at the top of the function or before its use clarifies the intent. 2. Removing the `global` statement doesn't affect the scope of the variable. It is purely meant to [guide Python for the code block it is used in.](https://docs.python.org/3/reference/simple_stmts.html#the-global-statement). 3. ROOT already uses `global` keyword in [JupyROOT](https://github.com/root-project/root/blame/a90d76b7798dc4332425d29794089fceaebccb60/bindings/jupyroot/python/JupyROOT/helpers/utils.py#L126 ). So unless ""we should never use `global`"" is a new convention being followed in ROOT, I believe it doesn't seem to track. 4. As seen in this [",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11096#issuecomment-1603484912
Usability,clear,clearly,"I'll just close this, for me it's clearly off-topic.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11097#issuecomment-1404930474
Availability,error,error,"Build failed on ROOT-ubuntu18.04/nortcxxmod.; Running on sft-ubuntu-1804-2.cern.ch:/build/workspace/root-pullrequests-build; [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/151341/console).; ### Errors:; - [2022-08-05T22:57:53.738Z] FAILED: tree/dataframe/test/CMakeFiles/dataframe_vary.dir/dataframe_vary.cxx.o ; - [2022-08-05T22:57:53.995Z] /mnt/build/workspace/root-pullrequests-build/root/tree/dataframe/inc/ROOT/RDF/ActionHelpers.hxx:507:49: error: call to non-constexpr function ROOT::Internal::RDF::FillHelper&lt;HIST&gt;::Exec(unsigned int, const Xs& ...)::&lt;lambda(const auto:2&)&gt; [with auto:2 = std::array&lt;bool, 1&gt;; Xs = {ROOT::VecOps::RVec&lt;int&gt;}; typename std::enable_if&lt;ROOT::Internal::RDF::Disjunction&lt;ROOT::Internal::RDF::IsDataContainer&lt;ValTypes&gt;...&gt;::value, int&gt;::type &lt;anonymous&gt; = 0; HIST = TH1D] ; - [2022-08-05T22:57:53.995Z] /mnt/build/workspace/root-pullrequests-build/root/tree/dataframe/inc/ROOT/RDF/ActionHelpers.hxx:498:44: error: the value of i is not usable in a constant expression ; - [2022-08-05T22:57:53.995Z] /mnt/build/workspace/root-pullrequests-build/root/tree/dataframe/inc/ROOT/RDF/ActionHelpers.hxx:512:58: error: no matching function for call to GetNthElement&lt;colidx&gt;(const ROOT::VecOps::RVec&lt;int&gt;&) ; - [2022-08-05T22:57:54.253Z] /mnt/build/workspace/root-pullrequests-build/root/tree/dataframe/inc/ROOT/RDF/ActionHelpers.hxx:507:49: error: call to non-constexpr function ROOT::Internal::RDF::FillHelper&lt;HIST&gt;::Exec(unsigned int, const Xs& ...)::&lt;lambda(const auto:2&)&gt; [with auto:2 = std::array&lt;bool, 3&gt;; Xs = {ROOT::VecOps::RVec&lt;int&gt;, ROOT::VecOps::RVec&lt;int&gt;, ROOT::VecOps::RVec&lt;int&gt;}; typename std::enable_if&lt;ROOT::Internal::RDF::Disjunction&lt;ROOT::Internal::RDF::IsDataContainer&lt;ValTypes&gt;...&gt;::value, int&gt;::type &lt;anonymous&gt; = 0; HIST = TProfile2D] ; - [2022-08-05T22:57:54.253Z] /mnt/build/",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11127#issuecomment-1207076516
Testability,test,test,"Build failed on ROOT-ubuntu18.04/nortcxxmod.; Running on sft-ubuntu-1804-2.cern.ch:/build/workspace/root-pullrequests-build; [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/151341/console).; ### Errors:; - [2022-08-05T22:57:53.738Z] FAILED: tree/dataframe/test/CMakeFiles/dataframe_vary.dir/dataframe_vary.cxx.o ; - [2022-08-05T22:57:53.995Z] /mnt/build/workspace/root-pullrequests-build/root/tree/dataframe/inc/ROOT/RDF/ActionHelpers.hxx:507:49: error: call to non-constexpr function ROOT::Internal::RDF::FillHelper&lt;HIST&gt;::Exec(unsigned int, const Xs& ...)::&lt;lambda(const auto:2&)&gt; [with auto:2 = std::array&lt;bool, 1&gt;; Xs = {ROOT::VecOps::RVec&lt;int&gt;}; typename std::enable_if&lt;ROOT::Internal::RDF::Disjunction&lt;ROOT::Internal::RDF::IsDataContainer&lt;ValTypes&gt;...&gt;::value, int&gt;::type &lt;anonymous&gt; = 0; HIST = TH1D] ; - [2022-08-05T22:57:53.995Z] /mnt/build/workspace/root-pullrequests-build/root/tree/dataframe/inc/ROOT/RDF/ActionHelpers.hxx:498:44: error: the value of i is not usable in a constant expression ; - [2022-08-05T22:57:53.995Z] /mnt/build/workspace/root-pullrequests-build/root/tree/dataframe/inc/ROOT/RDF/ActionHelpers.hxx:512:58: error: no matching function for call to GetNthElement&lt;colidx&gt;(const ROOT::VecOps::RVec&lt;int&gt;&) ; - [2022-08-05T22:57:54.253Z] /mnt/build/workspace/root-pullrequests-build/root/tree/dataframe/inc/ROOT/RDF/ActionHelpers.hxx:507:49: error: call to non-constexpr function ROOT::Internal::RDF::FillHelper&lt;HIST&gt;::Exec(unsigned int, const Xs& ...)::&lt;lambda(const auto:2&)&gt; [with auto:2 = std::array&lt;bool, 3&gt;; Xs = {ROOT::VecOps::RVec&lt;int&gt;, ROOT::VecOps::RVec&lt;int&gt;, ROOT::VecOps::RVec&lt;int&gt;}; typename std::enable_if&lt;ROOT::Internal::RDF::Disjunction&lt;ROOT::Internal::RDF::IsDataContainer&lt;ValTypes&gt;...&gt;::value, int&gt;::type &lt;anonymous&gt; = 0; HIST = TProfile2D] ; - [2022-08-05T22:57:54.253Z] /mnt/build/",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11127#issuecomment-1207076516
Usability,usab,usable,"rn.ch:/build/workspace/root-pullrequests-build; [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/151341/console).; ### Errors:; - [2022-08-05T22:57:53.738Z] FAILED: tree/dataframe/test/CMakeFiles/dataframe_vary.dir/dataframe_vary.cxx.o ; - [2022-08-05T22:57:53.995Z] /mnt/build/workspace/root-pullrequests-build/root/tree/dataframe/inc/ROOT/RDF/ActionHelpers.hxx:507:49: error: call to non-constexpr function ROOT::Internal::RDF::FillHelper&lt;HIST&gt;::Exec(unsigned int, const Xs& ...)::&lt;lambda(const auto:2&)&gt; [with auto:2 = std::array&lt;bool, 1&gt;; Xs = {ROOT::VecOps::RVec&lt;int&gt;}; typename std::enable_if&lt;ROOT::Internal::RDF::Disjunction&lt;ROOT::Internal::RDF::IsDataContainer&lt;ValTypes&gt;...&gt;::value, int&gt;::type &lt;anonymous&gt; = 0; HIST = TH1D] ; - [2022-08-05T22:57:53.995Z] /mnt/build/workspace/root-pullrequests-build/root/tree/dataframe/inc/ROOT/RDF/ActionHelpers.hxx:498:44: error: the value of i is not usable in a constant expression ; - [2022-08-05T22:57:53.995Z] /mnt/build/workspace/root-pullrequests-build/root/tree/dataframe/inc/ROOT/RDF/ActionHelpers.hxx:512:58: error: no matching function for call to GetNthElement&lt;colidx&gt;(const ROOT::VecOps::RVec&lt;int&gt;&) ; - [2022-08-05T22:57:54.253Z] /mnt/build/workspace/root-pullrequests-build/root/tree/dataframe/inc/ROOT/RDF/ActionHelpers.hxx:507:49: error: call to non-constexpr function ROOT::Internal::RDF::FillHelper&lt;HIST&gt;::Exec(unsigned int, const Xs& ...)::&lt;lambda(const auto:2&)&gt; [with auto:2 = std::array&lt;bool, 3&gt;; Xs = {ROOT::VecOps::RVec&lt;int&gt;, ROOT::VecOps::RVec&lt;int&gt;, ROOT::VecOps::RVec&lt;int&gt;}; typename std::enable_if&lt;ROOT::Internal::RDF::Disjunction&lt;ROOT::Internal::RDF::IsDataContainer&lt;ValTypes&gt;...&gt;::value, int&gt;::type &lt;anonymous&gt; = 0; HIST = TProfile2D] ; - [2022-08-05T22:57:54.253Z] /mnt/build/workspace/root-pullrequests-build/root/tree/dataframe/inc/ROOT/RDF/ActionHel",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11127#issuecomment-1207076516
Usability,simpl,simple,"Wow, you were fast in spotting this :smiley: I think there's a relatively simple fix, see https://github.com/root-project/root/pull/11148",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11128#issuecomment-1208232344
Testability,test,test,"I not yet test latest `nlohmann/json.hpp`, but seems to be it is incompatible with previous versions.; The simple solution for now would be ignoring incompatible versions of `nlohmann/json.hpp` and use builtin one.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11130#issuecomment-1208998994
Usability,simpl,simple,"I not yet test latest `nlohmann/json.hpp`, but seems to be it is incompatible with previous versions.; The simple solution for now would be ignoring incompatible versions of `nlohmann/json.hpp` and use builtin one.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11130#issuecomment-1208998994
Usability,simpl,simply,"Ok, then I still don't understand the issue. Yesterday I understood that it's *not* related to LLVM, but that ROOT's forward declaration is simply ""wrong"" for newer versions of `nlohmann/json` because it changed some template parameters...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11130#issuecomment-1216411826
Availability,avail,available,"@kgizdov the problem is the two cases are non-exhaustive: For versions before 3.11.0, our own forward declaration will always work. Starting with 3.11.2, `json_fwd.hpp` is always available. But in between, for 3.11.0 and 3.11.1, we can hit an ""external"" version of the library without `json_fwd.hpp` where our own forward declaration doesn't work (because of https://github.com/nlohmann/json/pull/3590). It's not clear to me how to make this case work, but I also don't think it's really that important.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11130#issuecomment-1218222161
Usability,clear,clear,"@kgizdov the problem is the two cases are non-exhaustive: For versions before 3.11.0, our own forward declaration will always work. Starting with 3.11.2, `json_fwd.hpp` is always available. But in between, for 3.11.0 and 3.11.1, we can hit an ""external"" version of the library without `json_fwd.hpp` where our own forward declaration doesn't work (because of https://github.com/nlohmann/json/pull/3590). It's not clear to me how to make this case work, but I also don't think it's really that important.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11130#issuecomment-1218222161
Usability,simpl,simple,"Another ""simple"" approach to compile ROOT is specify `-Droot7=OFF`. This will disable eve7 compilation which has such problem with forward declarations.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11130#issuecomment-1218228421
Usability,clear,clear,"Ok, if there's no clear way here, I will close this for now.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11147#issuecomment-1774992019
Usability,clear,clear,"Okay. I used htmls in every possible SaveGraph ""bubble type"" (e.g. datasource/define/filter/actions for consistency). The actual reason to move to html is that in the action node, I want to use a smaller font to say that the action has run, e.g.:; ```; <BR/><FONT POINT-SIZE=\""10.0\"">Already Run</FONT>; ```. There are 2 possible solutions:. 1. Keep only the actions as an html, (so as in current master) this would give:; ![out](https://user-images.githubusercontent.com/46775299/185161238-f0dd3d47-9bc3-49ee-90c6-766b860d2a90.png). 2. Move all ""bubble types"" to plain text -- `Already Run` would appear slightly larger:; ![out2](https://user-images.githubusercontent.com/46775299/185161401-c014eb40-5423-4907-b3c0-4934e21f27c0.png). I am currently migrating to solution 2, as I think it is more consistent and still it is clear that the action has run (it is also in different color because it is run).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11173#issuecomment-1218093192
Usability,clear,clear,"Hi! I'm still not 100 % sure this is the right fix, and I didn't have the time to think more about this so far. I will come back to this, but right now this PR is not ready yet. I'll change it to a draft to make this clear.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11228#issuecomment-1270167122
Testability,test,tests,"Hi @j-mathe , I think you used `clang-format filename1 filename2 ...` instead of `git clang-format --diff ...`, right? because the clang-format commit introduces many formatting changes that are unrelated to the PR and that we should not apply here. It also makes it a bit harder to review the PR. Please remove that commit and only format your changes (e.g. with `git clang-format --diff master kahan | git apply`). I guess you will need to do an interactive git rebase -- you could also take this chance to clean the commit history, leaving only one commit or one for the new implementation plus one for the new tests. That would make it simpler for me to do a last review pass.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11230#issuecomment-1237232362
Usability,simpl,simpler,"Hi @j-mathe , I think you used `clang-format filename1 filename2 ...` instead of `git clang-format --diff ...`, right? because the clang-format commit introduces many formatting changes that are unrelated to the PR and that we should not apply here. It also makes it a bit harder to review the PR. Please remove that commit and only format your changes (e.g. with `git clang-format --diff master kahan | git apply`). I guess you will need to do an interactive git rebase -- you could also take this chance to clean the commit history, leaving only one commit or one for the new implementation plus one for the new tests. That would make it simpler for me to do a last review pass.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11230#issuecomment-1237232362
Usability,simpl,simple,"For bench-marking the change can you run and compare with and without the PR:; ```; #include ""TChain.h"". void callfuncbench(int repeat = 1000) ; {; TChain ch(""ntuple""); ; for(int i = 0 ; i < repeat; ++i); ch.Draw(""TMath::TanH(px)"", """", ""goff""););; }; ```; This demonstrates a simple common (indirect) usage of CallFunc. . Thanks,; Philippe. They are also usage of CallFunc in Signal/Slot mechanism and QT.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11252#issuecomment-1251578429
Availability,failure,failure,"> For bench-marking the change can you run and compare with and without the PR:; > ; > ```; > #include ""TChain.h""; > ; > void callfuncbench(int repeat = 1000) ; > {; > TChain ch(""ntuple""); ; > for(int i = 0 ; i < repeat; ++i); > ch.Draw(""TMath::TanH(px)"", """", ""goff""););; > }; > ```; > ; > This demonstrates a simple common (indirect) usage of CallFunc.; > ; > Thanks, Philippe.; > ; > They are also usage of CallFunc in Signal/Slot mechanism and QT. I used `ctest --output-on-failure -R .*treefor.*` and `ctest -j12 --output-on-failure -R .*callfunc.*` to benchmark. I noticed around 20% slowdown and I decided to go with the enum implementation which I just pushed. Now with it we seem to be consistent with what we used to have but I am still looking how to make it faster. That benchmark runs more or less for the same time (0.16 +-2):. ```; root-callfunc-master/release $ /usr/bin/time -v root.exe -l -b -q /build/vvassilev/root-release-master/callfuncbench.C\(1000000\). Processing /build/vvassilev/root-release-master/callfuncbench.C(1000000)...; 	Command being timed: ""root.exe -l -b -q /build/vvassilev/root-release-master/callfuncbench.C(1000000)""; 	User time (seconds): 0.16; 	System time (seconds): 0.06; 	Percent of CPU this job got: 100%; 	Elapsed (wall clock) time (h:mm:ss or m:ss): 0:00.22; 	Average shared text size (kbytes): 0; 	Average unshared data size (kbytes): 0; 	Average stack size (kbytes): 0; 	Average total size (kbytes): 0; 	Maximum resident set size (kbytes): 195476; 	Average resident set size (kbytes): 0; 	Major (requiring I/O) page faults: 0; 	Minor (reclaiming a frame) page faults: 25164; 	Voluntary context switches: 218; 	Involuntary context switches: 6; 	Swaps: 0; 	File system inputs: 0; 	File system outputs: 0; 	Socket messages sent: 0; 	Socket messages received: 0; 	Signals delivered: 0; 	Page size (bytes): 4096; 	Exit status: 0; ```; and this PR on my machine:; ```; /usr/bin/time -v root.exe -l -b -q /build/vvassilev/root-release-master/callfuncbench.C",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11252#issuecomment-1251821611
Deployability,release,release,"> For bench-marking the change can you run and compare with and without the PR:; > ; > ```; > #include ""TChain.h""; > ; > void callfuncbench(int repeat = 1000) ; > {; > TChain ch(""ntuple""); ; > for(int i = 0 ; i < repeat; ++i); > ch.Draw(""TMath::TanH(px)"", """", ""goff""););; > }; > ```; > ; > This demonstrates a simple common (indirect) usage of CallFunc.; > ; > Thanks, Philippe.; > ; > They are also usage of CallFunc in Signal/Slot mechanism and QT. I used `ctest --output-on-failure -R .*treefor.*` and `ctest -j12 --output-on-failure -R .*callfunc.*` to benchmark. I noticed around 20% slowdown and I decided to go with the enum implementation which I just pushed. Now with it we seem to be consistent with what we used to have but I am still looking how to make it faster. That benchmark runs more or less for the same time (0.16 +-2):. ```; root-callfunc-master/release $ /usr/bin/time -v root.exe -l -b -q /build/vvassilev/root-release-master/callfuncbench.C\(1000000\). Processing /build/vvassilev/root-release-master/callfuncbench.C(1000000)...; 	Command being timed: ""root.exe -l -b -q /build/vvassilev/root-release-master/callfuncbench.C(1000000)""; 	User time (seconds): 0.16; 	System time (seconds): 0.06; 	Percent of CPU this job got: 100%; 	Elapsed (wall clock) time (h:mm:ss or m:ss): 0:00.22; 	Average shared text size (kbytes): 0; 	Average unshared data size (kbytes): 0; 	Average stack size (kbytes): 0; 	Average total size (kbytes): 0; 	Maximum resident set size (kbytes): 195476; 	Average resident set size (kbytes): 0; 	Major (requiring I/O) page faults: 0; 	Minor (reclaiming a frame) page faults: 25164; 	Voluntary context switches: 218; 	Involuntary context switches: 6; 	Swaps: 0; 	File system inputs: 0; 	File system outputs: 0; 	Socket messages sent: 0; 	Socket messages received: 0; 	Signals delivered: 0; 	Page size (bytes): 4096; 	Exit status: 0; ```; and this PR on my machine:; ```; /usr/bin/time -v root.exe -l -b -q /build/vvassilev/root-release-master/callfuncbench.C",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11252#issuecomment-1251821611
Integrability,message,messages,"th the enum implementation which I just pushed. Now with it we seem to be consistent with what we used to have but I am still looking how to make it faster. That benchmark runs more or less for the same time (0.16 +-2):. ```; root-callfunc-master/release $ /usr/bin/time -v root.exe -l -b -q /build/vvassilev/root-release-master/callfuncbench.C\(1000000\). Processing /build/vvassilev/root-release-master/callfuncbench.C(1000000)...; 	Command being timed: ""root.exe -l -b -q /build/vvassilev/root-release-master/callfuncbench.C(1000000)""; 	User time (seconds): 0.16; 	System time (seconds): 0.06; 	Percent of CPU this job got: 100%; 	Elapsed (wall clock) time (h:mm:ss or m:ss): 0:00.22; 	Average shared text size (kbytes): 0; 	Average unshared data size (kbytes): 0; 	Average stack size (kbytes): 0; 	Average total size (kbytes): 0; 	Maximum resident set size (kbytes): 195476; 	Average resident set size (kbytes): 0; 	Major (requiring I/O) page faults: 0; 	Minor (reclaiming a frame) page faults: 25164; 	Voluntary context switches: 218; 	Involuntary context switches: 6; 	Swaps: 0; 	File system inputs: 0; 	File system outputs: 0; 	Socket messages sent: 0; 	Socket messages received: 0; 	Signals delivered: 0; 	Page size (bytes): 4096; 	Exit status: 0; ```; and this PR on my machine:; ```; /usr/bin/time -v root.exe -l -b -q /build/vvassilev/root-release-master/callfuncbench.C\(1000000\). Processing /build/vvassilev/root-release-master/callfuncbench.C(1000000)...; 	Command being timed: ""root.exe -l -b -q /build/vvassilev/root-release-master/callfuncbench.C(1000000)""; 	User time (seconds): 0.18; 	System time (seconds): 0.06; 	Percent of CPU this job got: 100%; 	Elapsed (wall clock) time (h:mm:ss or m:ss): 0:00.24; 	Average shared text size (kbytes): 0; 	Average unshared data size (kbytes): 0; 	Average stack size (kbytes): 0; 	Average total size (kbytes): 0; 	Maximum resident set size (kbytes): 220812; 	Average resident set size (kbytes): 0; 	Major (requiring I/O) page faults: 0; 	Mino",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11252#issuecomment-1251821611
Testability,benchmark,benchmark,"> For bench-marking the change can you run and compare with and without the PR:; > ; > ```; > #include ""TChain.h""; > ; > void callfuncbench(int repeat = 1000) ; > {; > TChain ch(""ntuple""); ; > for(int i = 0 ; i < repeat; ++i); > ch.Draw(""TMath::TanH(px)"", """", ""goff""););; > }; > ```; > ; > This demonstrates a simple common (indirect) usage of CallFunc.; > ; > Thanks, Philippe.; > ; > They are also usage of CallFunc in Signal/Slot mechanism and QT. I used `ctest --output-on-failure -R .*treefor.*` and `ctest -j12 --output-on-failure -R .*callfunc.*` to benchmark. I noticed around 20% slowdown and I decided to go with the enum implementation which I just pushed. Now with it we seem to be consistent with what we used to have but I am still looking how to make it faster. That benchmark runs more or less for the same time (0.16 +-2):. ```; root-callfunc-master/release $ /usr/bin/time -v root.exe -l -b -q /build/vvassilev/root-release-master/callfuncbench.C\(1000000\). Processing /build/vvassilev/root-release-master/callfuncbench.C(1000000)...; 	Command being timed: ""root.exe -l -b -q /build/vvassilev/root-release-master/callfuncbench.C(1000000)""; 	User time (seconds): 0.16; 	System time (seconds): 0.06; 	Percent of CPU this job got: 100%; 	Elapsed (wall clock) time (h:mm:ss or m:ss): 0:00.22; 	Average shared text size (kbytes): 0; 	Average unshared data size (kbytes): 0; 	Average stack size (kbytes): 0; 	Average total size (kbytes): 0; 	Maximum resident set size (kbytes): 195476; 	Average resident set size (kbytes): 0; 	Major (requiring I/O) page faults: 0; 	Minor (reclaiming a frame) page faults: 25164; 	Voluntary context switches: 218; 	Involuntary context switches: 6; 	Swaps: 0; 	File system inputs: 0; 	File system outputs: 0; 	Socket messages sent: 0; 	Socket messages received: 0; 	Signals delivered: 0; 	Page size (bytes): 4096; 	Exit status: 0; ```; and this PR on my machine:; ```; /usr/bin/time -v root.exe -l -b -q /build/vvassilev/root-release-master/callfuncbench.C",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11252#issuecomment-1251821611
Usability,simpl,simple,"> For bench-marking the change can you run and compare with and without the PR:; > ; > ```; > #include ""TChain.h""; > ; > void callfuncbench(int repeat = 1000) ; > {; > TChain ch(""ntuple""); ; > for(int i = 0 ; i < repeat; ++i); > ch.Draw(""TMath::TanH(px)"", """", ""goff""););; > }; > ```; > ; > This demonstrates a simple common (indirect) usage of CallFunc.; > ; > Thanks, Philippe.; > ; > They are also usage of CallFunc in Signal/Slot mechanism and QT. I used `ctest --output-on-failure -R .*treefor.*` and `ctest -j12 --output-on-failure -R .*callfunc.*` to benchmark. I noticed around 20% slowdown and I decided to go with the enum implementation which I just pushed. Now with it we seem to be consistent with what we used to have but I am still looking how to make it faster. That benchmark runs more or less for the same time (0.16 +-2):. ```; root-callfunc-master/release $ /usr/bin/time -v root.exe -l -b -q /build/vvassilev/root-release-master/callfuncbench.C\(1000000\). Processing /build/vvassilev/root-release-master/callfuncbench.C(1000000)...; 	Command being timed: ""root.exe -l -b -q /build/vvassilev/root-release-master/callfuncbench.C(1000000)""; 	User time (seconds): 0.16; 	System time (seconds): 0.06; 	Percent of CPU this job got: 100%; 	Elapsed (wall clock) time (h:mm:ss or m:ss): 0:00.22; 	Average shared text size (kbytes): 0; 	Average unshared data size (kbytes): 0; 	Average stack size (kbytes): 0; 	Average total size (kbytes): 0; 	Maximum resident set size (kbytes): 195476; 	Average resident set size (kbytes): 0; 	Major (requiring I/O) page faults: 0; 	Minor (reclaiming a frame) page faults: 25164; 	Voluntary context switches: 218; 	Involuntary context switches: 6; 	Swaps: 0; 	File system inputs: 0; 	File system outputs: 0; 	Socket messages sent: 0; 	Socket messages received: 0; 	Signals delivered: 0; 	Page size (bytes): 4096; 	Exit status: 0; ```; and this PR on my machine:; ```; /usr/bin/time -v root.exe -l -b -q /build/vvassilev/root-release-master/callfuncbench.C",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11252#issuecomment-1251821611
Availability,down,down,"My version of os/compiler/valgrind seems to work better and I got some useful information. For `root.exe -b -l -q callfuncbench.cxx+(1000)`. The new code is a big faster: `42,696,463,692` instead of `45,892,859,389`. Some of the calculation are shifted to `Value::Value`: `5,000,000,988` vs `3,100,001,703` (it grows by 2 billions when the overall goes down by 3 billions). The gains comes from the disappearance of `TClingCallFunc::InitRefAndExec` (minus 3.8 billions) and the simplifications of `std::function_handler (removed) and TClingCallFunc::exec` (minus 1.2 billions). So it is getting better and `Value::Value` is a potential source of further optimization (see related comment). [callgrind-callfund.tar.gz](https://github.com/root-project/root/files/9665974/callgrind-callfund.tar.gz)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11252#issuecomment-1261020879
Performance,optimiz,optimization,"My version of os/compiler/valgrind seems to work better and I got some useful information. For `root.exe -b -l -q callfuncbench.cxx+(1000)`. The new code is a big faster: `42,696,463,692` instead of `45,892,859,389`. Some of the calculation are shifted to `Value::Value`: `5,000,000,988` vs `3,100,001,703` (it grows by 2 billions when the overall goes down by 3 billions). The gains comes from the disappearance of `TClingCallFunc::InitRefAndExec` (minus 3.8 billions) and the simplifications of `std::function_handler (removed) and TClingCallFunc::exec` (minus 1.2 billions). So it is getting better and `Value::Value` is a potential source of further optimization (see related comment). [callgrind-callfund.tar.gz](https://github.com/root-project/root/files/9665974/callgrind-callfund.tar.gz)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11252#issuecomment-1261020879
Usability,simpl,simplifications,"My version of os/compiler/valgrind seems to work better and I got some useful information. For `root.exe -b -l -q callfuncbench.cxx+(1000)`. The new code is a big faster: `42,696,463,692` instead of `45,892,859,389`. Some of the calculation are shifted to `Value::Value`: `5,000,000,988` vs `3,100,001,703` (it grows by 2 billions when the overall goes down by 3 billions). The gains comes from the disappearance of `TClingCallFunc::InitRefAndExec` (minus 3.8 billions) and the simplifications of `std::function_handler (removed) and TClingCallFunc::exec` (minus 1.2 billions). So it is getting better and `Value::Value` is a potential source of further optimization (see related comment). [callgrind-callfund.tar.gz](https://github.com/root-project/root/files/9665974/callgrind-callfund.tar.gz)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11252#issuecomment-1261020879
Availability,down,down,"> My version of os/compiler/valgrind seems to work better and I got some useful information.; > ; > For `root.exe -b -l -q callfuncbench.cxx+(1000)`.; > ; > The new code is a big faster: `42,696,463,692` instead of `45,892,859,389`; > ; > Some of the calculation are shifted to `Value::Value`: `5,000,000,988` vs `3,100,001,703` (it grows by 2 billions when the overall goes down by 3 billions).; > ; > The gains comes from the disappearance of `TClingCallFunc::InitRefAndExec` (minus 3.8 billions) and the simplifications of `std::function_handler (removed) and TClingCallFunc::exec` (minus 1.2 billions).; > ; > So it is getting better and `Value::Value` is a potential source of further optimization (see related comment).; > ; > [callgrind-callfund.tar.gz](https://github.com/root-project/root/files/9665974/callgrind-callfund.tar.gz). Thanks for the details. I've pushed the further optimization of `Value::Value`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11252#issuecomment-1262680556
Performance,optimiz,optimization,"> My version of os/compiler/valgrind seems to work better and I got some useful information.; > ; > For `root.exe -b -l -q callfuncbench.cxx+(1000)`.; > ; > The new code is a big faster: `42,696,463,692` instead of `45,892,859,389`; > ; > Some of the calculation are shifted to `Value::Value`: `5,000,000,988` vs `3,100,001,703` (it grows by 2 billions when the overall goes down by 3 billions).; > ; > The gains comes from the disappearance of `TClingCallFunc::InitRefAndExec` (minus 3.8 billions) and the simplifications of `std::function_handler (removed) and TClingCallFunc::exec` (minus 1.2 billions).; > ; > So it is getting better and `Value::Value` is a potential source of further optimization (see related comment).; > ; > [callgrind-callfund.tar.gz](https://github.com/root-project/root/files/9665974/callgrind-callfund.tar.gz). Thanks for the details. I've pushed the further optimization of `Value::Value`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11252#issuecomment-1262680556
Usability,simpl,simplifications,"> My version of os/compiler/valgrind seems to work better and I got some useful information.; > ; > For `root.exe -b -l -q callfuncbench.cxx+(1000)`.; > ; > The new code is a big faster: `42,696,463,692` instead of `45,892,859,389`; > ; > Some of the calculation are shifted to `Value::Value`: `5,000,000,988` vs `3,100,001,703` (it grows by 2 billions when the overall goes down by 3 billions).; > ; > The gains comes from the disappearance of `TClingCallFunc::InitRefAndExec` (minus 3.8 billions) and the simplifications of `std::function_handler (removed) and TClingCallFunc::exec` (minus 1.2 billions).; > ; > So it is getting better and `Value::Value` is a potential source of further optimization (see related comment).; > ; > [callgrind-callfund.tar.gz](https://github.com/root-project/root/files/9665974/callgrind-callfund.tar.gz). Thanks for the details. I've pushed the further optimization of `Value::Value`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11252#issuecomment-1262680556
Availability,down,down,"> > My version of os/compiler/valgrind seems to work better and I got some useful information.; > > For `root.exe -b -l -q callfuncbench.cxx+(1000)`.; > > The new code is a big faster: `42,696,463,692` instead of `45,892,859,389`; > > Some of the calculation are shifted to `Value::Value`: `5,000,000,988` vs `3,100,001,703` (it grows by 2 billions when the overall goes down by 3 billions).; > > The gains comes from the disappearance of `TClingCallFunc::InitRefAndExec` (minus 3.8 billions) and the simplifications of `std::function_handler (removed) and TClingCallFunc::exec` (minus 1.2 billions).; > > So it is getting better and `Value::Value` is a potential source of further optimization (see related comment).; > > [callgrind-callfund.tar.gz](https://github.com/root-project/root/files/9665974/callgrind-callfund.tar.gz); > ; > Thanks for the details. I've pushed the further optimization of `Value::Value`. Can you remeasure?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11252#issuecomment-1262860929
Performance,optimiz,optimization,"> > My version of os/compiler/valgrind seems to work better and I got some useful information.; > > For `root.exe -b -l -q callfuncbench.cxx+(1000)`.; > > The new code is a big faster: `42,696,463,692` instead of `45,892,859,389`; > > Some of the calculation are shifted to `Value::Value`: `5,000,000,988` vs `3,100,001,703` (it grows by 2 billions when the overall goes down by 3 billions).; > > The gains comes from the disappearance of `TClingCallFunc::InitRefAndExec` (minus 3.8 billions) and the simplifications of `std::function_handler (removed) and TClingCallFunc::exec` (minus 1.2 billions).; > > So it is getting better and `Value::Value` is a potential source of further optimization (see related comment).; > > [callgrind-callfund.tar.gz](https://github.com/root-project/root/files/9665974/callgrind-callfund.tar.gz); > ; > Thanks for the details. I've pushed the further optimization of `Value::Value`. Can you remeasure?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11252#issuecomment-1262860929
Usability,simpl,simplifications,"> > My version of os/compiler/valgrind seems to work better and I got some useful information.; > > For `root.exe -b -l -q callfuncbench.cxx+(1000)`.; > > The new code is a big faster: `42,696,463,692` instead of `45,892,859,389`; > > Some of the calculation are shifted to `Value::Value`: `5,000,000,988` vs `3,100,001,703` (it grows by 2 billions when the overall goes down by 3 billions).; > > The gains comes from the disappearance of `TClingCallFunc::InitRefAndExec` (minus 3.8 billions) and the simplifications of `std::function_handler (removed) and TClingCallFunc::exec` (minus 1.2 billions).; > > So it is getting better and `Value::Value` is a potential source of further optimization (see related comment).; > > [callgrind-callfund.tar.gz](https://github.com/root-project/root/files/9665974/callgrind-callfund.tar.gz); > ; > Thanks for the details. I've pushed the further optimization of `Value::Value`. Can you remeasure?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11252#issuecomment-1262860929
Modifiability,config,config,"cling startup scripts are different from rootlogon.C and rootrc .; rootrc is a config file while .clingrc is a regular cling script. cling startup scripts are executed also in invocation of standalone cling binary (not from root interpreter). Question:; 1. Renaming `.cling_profile` and `.clingrc` with suffix `.C` ?; 2. Rename `.clingrc` to something else so that `.clingrc` can be reserved for cling config file in the future (if any)?; Making it a config file instead of a cling script aligns with rootrc but not with bashrc, zshrc.; 3. Drop `.clingrc` for now and keep `.cling_profile` only ? If a cling script can easily tell if it is in interactive mode then keeping only 1 script makes sense. Otherwise it is better to keep both to align with bash and other interpreter inspired by bash design. By easily telling I mean a macro like `CLING_INTERACTIVE` or something simple that does not access `gCling`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11262#issuecomment-1229254493
Security,access,access,"cling startup scripts are different from rootlogon.C and rootrc .; rootrc is a config file while .clingrc is a regular cling script. cling startup scripts are executed also in invocation of standalone cling binary (not from root interpreter). Question:; 1. Renaming `.cling_profile` and `.clingrc` with suffix `.C` ?; 2. Rename `.clingrc` to something else so that `.clingrc` can be reserved for cling config file in the future (if any)?; Making it a config file instead of a cling script aligns with rootrc but not with bashrc, zshrc.; 3. Drop `.clingrc` for now and keep `.cling_profile` only ? If a cling script can easily tell if it is in interactive mode then keeping only 1 script makes sense. Otherwise it is better to keep both to align with bash and other interpreter inspired by bash design. By easily telling I mean a macro like `CLING_INTERACTIVE` or something simple that does not access `gCling`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11262#issuecomment-1229254493
Usability,simpl,simple,"cling startup scripts are different from rootlogon.C and rootrc .; rootrc is a config file while .clingrc is a regular cling script. cling startup scripts are executed also in invocation of standalone cling binary (not from root interpreter). Question:; 1. Renaming `.cling_profile` and `.clingrc` with suffix `.C` ?; 2. Rename `.clingrc` to something else so that `.clingrc` can be reserved for cling config file in the future (if any)?; Making it a config file instead of a cling script aligns with rootrc but not with bashrc, zshrc.; 3. Drop `.clingrc` for now and keep `.cling_profile` only ? If a cling script can easily tell if it is in interactive mode then keeping only 1 script makes sense. Otherwise it is better to keep both to align with bash and other interpreter inspired by bash design. By easily telling I mean a macro like `CLING_INTERACTIVE` or something simple that does not access `gCling`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11262#issuecomment-1229254493
Usability,feedback,feedback,"@Axel-Naumann , @vgvassilev Could you provide some feedback?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11262#issuecomment-1251040944
Modifiability,config,config,"> cling startup scripts are different from rootlogon.C and rootrc . rootrc is a config file while .clingrc is a regular cling script. cling startup scripts are executed also in invocation of standalone cling binary (not from root interpreter).; > ; > Question:; > ; > 1. Renaming `.cling_profile` and `.clingrc` with suffix `.C` ?; > ; > 2. Rename `.clingrc` to something else so that `.clingrc` can be reserved for cling config file in the future (if any)?; > Making it a config file instead of a cling script aligns with rootrc but not with bashrc, zshrc.; > ; > 3. Drop `.clingrc` for now and keep `.cling_profile` only ? If a cling script can easily tell if it is in interactive mode then keeping only 1 script makes sense. Otherwise it is better to keep both to align with bash and other interpreter inspired by bash design. By easily telling I mean a macro like `CLING_INTERACTIVE` or something simple that does not access `gCling`. How about a `~/.cling.d` folder where we glob all files and execute?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11262#issuecomment-1255476176
Security,access,access,"> cling startup scripts are different from rootlogon.C and rootrc . rootrc is a config file while .clingrc is a regular cling script. cling startup scripts are executed also in invocation of standalone cling binary (not from root interpreter).; > ; > Question:; > ; > 1. Renaming `.cling_profile` and `.clingrc` with suffix `.C` ?; > ; > 2. Rename `.clingrc` to something else so that `.clingrc` can be reserved for cling config file in the future (if any)?; > Making it a config file instead of a cling script aligns with rootrc but not with bashrc, zshrc.; > ; > 3. Drop `.clingrc` for now and keep `.cling_profile` only ? If a cling script can easily tell if it is in interactive mode then keeping only 1 script makes sense. Otherwise it is better to keep both to align with bash and other interpreter inspired by bash design. By easily telling I mean a macro like `CLING_INTERACTIVE` or something simple that does not access `gCling`. How about a `~/.cling.d` folder where we glob all files and execute?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11262#issuecomment-1255476176
Usability,simpl,simple,"> cling startup scripts are different from rootlogon.C and rootrc . rootrc is a config file while .clingrc is a regular cling script. cling startup scripts are executed also in invocation of standalone cling binary (not from root interpreter).; > ; > Question:; > ; > 1. Renaming `.cling_profile` and `.clingrc` with suffix `.C` ?; > ; > 2. Rename `.clingrc` to something else so that `.clingrc` can be reserved for cling config file in the future (if any)?; > Making it a config file instead of a cling script aligns with rootrc but not with bashrc, zshrc.; > ; > 3. Drop `.clingrc` for now and keep `.cling_profile` only ? If a cling script can easily tell if it is in interactive mode then keeping only 1 script makes sense. Otherwise it is better to keep both to align with bash and other interpreter inspired by bash design. By easily telling I mean a macro like `CLING_INTERACTIVE` or something simple that does not access `gCling`. How about a `~/.cling.d` folder where we glob all files and execute?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11262#issuecomment-1255476176
Availability,failure,failure,"I am able to reproduce the failure with a simple standalone reproducer (2 threads one loading and unloading a library, the other interogating `TClassTable`). I will prepare a PR with the fine grained locking (or whatever is needed to make the crash go away :) )",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11263#issuecomment-1483286941
Performance,load,loading,"I am able to reproduce the failure with a simple standalone reproducer (2 threads one loading and unloading a library, the other interogating `TClassTable`). I will prepare a PR with the fine grained locking (or whatever is needed to make the crash go away :) )",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11263#issuecomment-1483286941
Usability,simpl,simple,"I am able to reproduce the failure with a simple standalone reproducer (2 threads one loading and unloading a library, the other interogating `TClassTable`). I will prepare a PR with the fine grained locking (or whatever is needed to make the crash go away :) )",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11263#issuecomment-1483286941
Availability,error,error,"> It removes the requirement for version 3.9. Technically code works with all 3.x versions of `nlohmann/json.hpp`. I add requirement for 3.9 recently just because we were not using and not testing for `json_fwd.hpp`. Now version restriction is not necessary. > It worsens the error message in case json_fwd.h when it is required for recent versions. They were written based on feedback from upstream, so I would like to keep the detailed messages. `json_fwd.hpp` now always required - not only for 3.11. Just as workaround for time been we allow to use [3.10 .. 3.11] versions without it. After LLVM upgrade we could completely skip usage of `json_fwd.h`. I hope it will happen before 6.28 release.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11268#issuecomment-1230200939
Deployability,upgrade,upgrade,"> It removes the requirement for version 3.9. Technically code works with all 3.x versions of `nlohmann/json.hpp`. I add requirement for 3.9 recently just because we were not using and not testing for `json_fwd.hpp`. Now version restriction is not necessary. > It worsens the error message in case json_fwd.h when it is required for recent versions. They were written based on feedback from upstream, so I would like to keep the detailed messages. `json_fwd.hpp` now always required - not only for 3.11. Just as workaround for time been we allow to use [3.10 .. 3.11] versions without it. After LLVM upgrade we could completely skip usage of `json_fwd.h`. I hope it will happen before 6.28 release.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11268#issuecomment-1230200939
Integrability,message,message,"> It removes the requirement for version 3.9. Technically code works with all 3.x versions of `nlohmann/json.hpp`. I add requirement for 3.9 recently just because we were not using and not testing for `json_fwd.hpp`. Now version restriction is not necessary. > It worsens the error message in case json_fwd.h when it is required for recent versions. They were written based on feedback from upstream, so I would like to keep the detailed messages. `json_fwd.hpp` now always required - not only for 3.11. Just as workaround for time been we allow to use [3.10 .. 3.11] versions without it. After LLVM upgrade we could completely skip usage of `json_fwd.h`. I hope it will happen before 6.28 release.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11268#issuecomment-1230200939
Testability,test,testing,"> It removes the requirement for version 3.9. Technically code works with all 3.x versions of `nlohmann/json.hpp`. I add requirement for 3.9 recently just because we were not using and not testing for `json_fwd.hpp`. Now version restriction is not necessary. > It worsens the error message in case json_fwd.h when it is required for recent versions. They were written based on feedback from upstream, so I would like to keep the detailed messages. `json_fwd.hpp` now always required - not only for 3.11. Just as workaround for time been we allow to use [3.10 .. 3.11] versions without it. After LLVM upgrade we could completely skip usage of `json_fwd.h`. I hope it will happen before 6.28 release.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11268#issuecomment-1230200939
Usability,feedback,feedback,"> It removes the requirement for version 3.9. Technically code works with all 3.x versions of `nlohmann/json.hpp`. I add requirement for 3.9 recently just because we were not using and not testing for `json_fwd.hpp`. Now version restriction is not necessary. > It worsens the error message in case json_fwd.h when it is required for recent versions. They were written based on feedback from upstream, so I would like to keep the detailed messages. `json_fwd.hpp` now always required - not only for 3.11. Just as workaround for time been we allow to use [3.10 .. 3.11] versions without it. After LLVM upgrade we could completely skip usage of `json_fwd.h`. I hope it will happen before 6.28 release.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11268#issuecomment-1230200939
Deployability,upgrade,upgrade,> I still don't understand this. All discussions we had so far ended with agreeing that the LLVM upgrade will change nothing wrt the JSON library. After LLVM upgrade we can use `json.hpp` directly in header files.; Thus one can simply avoid complication with `json_fwd.hpp`,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11268#issuecomment-1230211903
Safety,avoid,avoid,> I still don't understand this. All discussions we had so far ended with agreeing that the LLVM upgrade will change nothing wrt the JSON library. After LLVM upgrade we can use `json.hpp` directly in header files.; Thus one can simply avoid complication with `json_fwd.hpp`,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11268#issuecomment-1230211903
Usability,simpl,simply,> I still don't understand this. All discussions we had so far ended with agreeing that the LLVM upgrade will change nothing wrt the JSON library. After LLVM upgrade we can use `json.hpp` directly in header files.; Thus one can simply avoid complication with `json_fwd.hpp`,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11268#issuecomment-1230211903
Testability,test,testing,"> I don't understand why we would want to allow older versions than we did in the past. The reason why we restrict version - we were not testing for `json_fwd.hpp`. ; With 3.11.x version such simple restriction no longer working. But now we testing `json_fwd.hpp` and can use it, and restriction making no sense.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11268#issuecomment-1245012584
Usability,simpl,simple,"> I don't understand why we would want to allow older versions than we did in the past. The reason why we restrict version - we were not testing for `json_fwd.hpp`. ; With 3.11.x version such simple restriction no longer working. But now we testing `json_fwd.hpp` and can use it, and restriction making no sense.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11268#issuecomment-1245012584
Deployability,integrat,integration,"The fix works in my standalone ROOT test. To test the integration with DD4hep and the LHCb detector, the simplest is to add it to the SFT nightlies.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11272#issuecomment-1232170822
Integrability,integrat,integration,"The fix works in my standalone ROOT test. To test the integration with DD4hep and the LHCb detector, the simplest is to add it to the SFT nightlies.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11272#issuecomment-1232170822
Safety,detect,detector,"The fix works in my standalone ROOT test. To test the integration with DD4hep and the LHCb detector, the simplest is to add it to the SFT nightlies.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11272#issuecomment-1232170822
Testability,test,test,"The fix works in my standalone ROOT test. To test the integration with DD4hep and the LHCb detector, the simplest is to add it to the SFT nightlies.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11272#issuecomment-1232170822
Usability,simpl,simplest,"The fix works in my standalone ROOT test. To test the integration with DD4hep and the LHCb detector, the simplest is to add it to the SFT nightlies.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11272#issuecomment-1232170822
Deployability,pipeline,pipeline,@vgvassilev Test is added. Please help resume github pipeline.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11286#issuecomment-1268422584
Usability,resume,resume,@vgvassilev Test is added. Please help resume github pipeline.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11286#issuecomment-1268422584
Usability,feedback,feedback,"> Many thanks for the contribution, @jiangyilism! ; > ; > In principle, LGTM, but I will defer the approval to @vgvassilev. Could you apply the included suggestions in the interim?; > . Sure. Thanks for the feedback.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11286#issuecomment-1401028920
Usability,simpl,simply,"Fixed in #11553 with the caveat that in order to be able to pass temporaries one should use e.g. `""const RVecF""` in the signature passed to `Numba.Declare` rather than simply `""RVecF""`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11294#issuecomment-1597506324
Usability,simpl,simply,"As a side note, C++ already has a notion of onload so another option could be for the user to simply use:; ```; int anyfunction( .... ) { ... }; int execthefunctonload = anyfunction();; ```; (and on-unload can also be done (using a class destructor for example) but requires a bit more scaffolding)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11299#issuecomment-1235433090
Availability,error,error,"Using `.L` or `__attribute__((constructor))` or static initialization are good alternatives. However that does not improve usability of `.x` .; As mentioned in the first post, entry function still need renaming when file get renamed.; Also we get function redefinition error when `.x` or `.L` two scripts with same name. For example `dir0/test.C` and `dir1/dir2/test.C` (with completely different content) cannot both define their `test(...)` entry functions. They cannot be put into different namespaces either otherwise cling does not recognize them as entry functions. However, `__main__(...)` approach suffers from multiple definitions too. Unless cling unloads/drops symbol `__main__` after executing it (btw. In this case will static variables of `__main__` get destructed too?)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11299#issuecomment-1235581331
Modifiability,variab,variables,"Using `.L` or `__attribute__((constructor))` or static initialization are good alternatives. However that does not improve usability of `.x` .; As mentioned in the first post, entry function still need renaming when file get renamed.; Also we get function redefinition error when `.x` or `.L` two scripts with same name. For example `dir0/test.C` and `dir1/dir2/test.C` (with completely different content) cannot both define their `test(...)` entry functions. They cannot be put into different namespaces either otherwise cling does not recognize them as entry functions. However, `__main__(...)` approach suffers from multiple definitions too. Unless cling unloads/drops symbol `__main__` after executing it (btw. In this case will static variables of `__main__` get destructed too?)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11299#issuecomment-1235581331
Testability,test,test,"Using `.L` or `__attribute__((constructor))` or static initialization are good alternatives. However that does not improve usability of `.x` .; As mentioned in the first post, entry function still need renaming when file get renamed.; Also we get function redefinition error when `.x` or `.L` two scripts with same name. For example `dir0/test.C` and `dir1/dir2/test.C` (with completely different content) cannot both define their `test(...)` entry functions. They cannot be put into different namespaces either otherwise cling does not recognize them as entry functions. However, `__main__(...)` approach suffers from multiple definitions too. Unless cling unloads/drops symbol `__main__` after executing it (btw. In this case will static variables of `__main__` get destructed too?)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11299#issuecomment-1235581331
Usability,usab,usability,"Using `.L` or `__attribute__((constructor))` or static initialization are good alternatives. However that does not improve usability of `.x` .; As mentioned in the first post, entry function still need renaming when file get renamed.; Also we get function redefinition error when `.x` or `.L` two scripts with same name. For example `dir0/test.C` and `dir1/dir2/test.C` (with completely different content) cannot both define their `test(...)` entry functions. They cannot be put into different namespaces either otherwise cling does not recognize them as entry functions. However, `__main__(...)` approach suffers from multiple definitions too. Unless cling unloads/drops symbol `__main__` after executing it (btw. In this case will static variables of `__main__` get destructed too?)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11299#issuecomment-1235581331
Availability,avail,available,"> In what situation is `R__HAS_STD_SPAN` not sufficient? If `ROOT` has been configured to build in C++20 mode and properly installed, it must be set in `RConfigure.h`. If it is not set, this means that the `ROOT` code will use an alternative to `std::span` (because at configure and build time, it detected it was not available). In fact, I have a project that uses C++20, and uses ROOT compiled with C++17, and I encountered compilation errors in the ROOT header file RSpan.hxx as mentioned (redefinition of std::span). However, once the restriction of this preprocessor macro is resolved, the compilation could pass, and no related problems have been encountered for the time being. I also checked RStringView.hxx, this header file also uses a similar technique, so I submitted this patch. I believe that I may not be considerate about this in depth, but I hope that the issues of ""mixing standards"", which seems not to be issues, can be solved. If there are indeed many restrictions/issues on this issue, I admit that this is not such simple...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11311#issuecomment-1252761771
Deployability,install,installed,"> In what situation is `R__HAS_STD_SPAN` not sufficient? If `ROOT` has been configured to build in C++20 mode and properly installed, it must be set in `RConfigure.h`. If it is not set, this means that the `ROOT` code will use an alternative to `std::span` (because at configure and build time, it detected it was not available). In fact, I have a project that uses C++20, and uses ROOT compiled with C++17, and I encountered compilation errors in the ROOT header file RSpan.hxx as mentioned (redefinition of std::span). However, once the restriction of this preprocessor macro is resolved, the compilation could pass, and no related problems have been encountered for the time being. I also checked RStringView.hxx, this header file also uses a similar technique, so I submitted this patch. I believe that I may not be considerate about this in depth, but I hope that the issues of ""mixing standards"", which seems not to be issues, can be solved. If there are indeed many restrictions/issues on this issue, I admit that this is not such simple...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11311#issuecomment-1252761771
Modifiability,config,configured,"> In what situation is `R__HAS_STD_SPAN` not sufficient? If `ROOT` has been configured to build in C++20 mode and properly installed, it must be set in `RConfigure.h`. If it is not set, this means that the `ROOT` code will use an alternative to `std::span` (because at configure and build time, it detected it was not available). In fact, I have a project that uses C++20, and uses ROOT compiled with C++17, and I encountered compilation errors in the ROOT header file RSpan.hxx as mentioned (redefinition of std::span). However, once the restriction of this preprocessor macro is resolved, the compilation could pass, and no related problems have been encountered for the time being. I also checked RStringView.hxx, this header file also uses a similar technique, so I submitted this patch. I believe that I may not be considerate about this in depth, but I hope that the issues of ""mixing standards"", which seems not to be issues, can be solved. If there are indeed many restrictions/issues on this issue, I admit that this is not such simple...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11311#issuecomment-1252761771
Safety,detect,detected,"> In what situation is `R__HAS_STD_SPAN` not sufficient? If `ROOT` has been configured to build in C++20 mode and properly installed, it must be set in `RConfigure.h`. If it is not set, this means that the `ROOT` code will use an alternative to `std::span` (because at configure and build time, it detected it was not available). In fact, I have a project that uses C++20, and uses ROOT compiled with C++17, and I encountered compilation errors in the ROOT header file RSpan.hxx as mentioned (redefinition of std::span). However, once the restriction of this preprocessor macro is resolved, the compilation could pass, and no related problems have been encountered for the time being. I also checked RStringView.hxx, this header file also uses a similar technique, so I submitted this patch. I believe that I may not be considerate about this in depth, but I hope that the issues of ""mixing standards"", which seems not to be issues, can be solved. If there are indeed many restrictions/issues on this issue, I admit that this is not such simple...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11311#issuecomment-1252761771
Usability,simpl,simple,"> In what situation is `R__HAS_STD_SPAN` not sufficient? If `ROOT` has been configured to build in C++20 mode and properly installed, it must be set in `RConfigure.h`. If it is not set, this means that the `ROOT` code will use an alternative to `std::span` (because at configure and build time, it detected it was not available). In fact, I have a project that uses C++20, and uses ROOT compiled with C++17, and I encountered compilation errors in the ROOT header file RSpan.hxx as mentioned (redefinition of std::span). However, once the restriction of this preprocessor macro is resolved, the compilation could pass, and no related problems have been encountered for the time being. I also checked RStringView.hxx, this header file also uses a similar technique, so I submitted this patch. I believe that I may not be considerate about this in depth, but I hope that the issues of ""mixing standards"", which seems not to be issues, can be solved. If there are indeed many restrictions/issues on this issue, I admit that this is not such simple...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11311#issuecomment-1252761771
Safety,safe,safe-to-link-," with the same compiler ABI) to compile libA and libB (this is a common behavior), the compiler ABI condition is automatically met. On the other hand, the C++ standard library API is specified by ISO C++, and we can believe that the implementation of the standard library is compatible between different standards. So generally speaking, libA and libB are compatible even if they are compiled by different standards. However, in practice, the sequence of tokens of the same entity in the library may be different between different C++ standards, so the same symbol (such as a function) may correspond to different binaries, which indeed violates the ODR. However, as long as their behaviors are compatible, no matter which version of the linker is selected, there should be no serious problems. In other words, it can be considered that this is only a minor ODR violation, because it does not produce observable effects. The GCC document does not seem to clearly indicate whether compiling with mixed standards would work, but its [ABI policy](https://gcc.gnu.org/onlinedocs/libstdc++/manual/abi.html) seems to imply that this is feasible. In addition, this issue has also been [discussed on StackOverflow](https://stackoverflow.com/questions/46746878/is-it-safe-to-link-c17-c14-and-c11-objects), and the view is that it is feasible to do so. Back to our current issue, ideally, as long as there is no explicit ODR violation in the header file, the only thing left is to ensure ABI compatibility, which should be guaranteed by the compiler. It can be said that if the current `span` implementation of ROOT is compatible with the implementation of the standard library, the problem of mixed standards is not serious, but it is difficult to always guarantee. But as I said, if there is something like `cxx20::span` instead of crashing with the standard library, this issue can be solved from its source. The rest is just the ABI compatibility of this `cxx20::span`, which is guaranteed by the compiler.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11311#issuecomment-1254026839
Usability,clear,clearly,"st compilers with the same compiler ABI) to compile libA and libB (this is a common behavior), the compiler ABI condition is automatically met. On the other hand, the C++ standard library API is specified by ISO C++, and we can believe that the implementation of the standard library is compatible between different standards. So generally speaking, libA and libB are compatible even if they are compiled by different standards. However, in practice, the sequence of tokens of the same entity in the library may be different between different C++ standards, so the same symbol (such as a function) may correspond to different binaries, which indeed violates the ODR. However, as long as their behaviors are compatible, no matter which version of the linker is selected, there should be no serious problems. In other words, it can be considered that this is only a minor ODR violation, because it does not produce observable effects. The GCC document does not seem to clearly indicate whether compiling with mixed standards would work, but its [ABI policy](https://gcc.gnu.org/onlinedocs/libstdc++/manual/abi.html) seems to imply that this is feasible. In addition, this issue has also been [discussed on StackOverflow](https://stackoverflow.com/questions/46746878/is-it-safe-to-link-c17-c14-and-c11-objects), and the view is that it is feasible to do so. Back to our current issue, ideally, as long as there is no explicit ODR violation in the header file, the only thing left is to ensure ABI compatibility, which should be guaranteed by the compiler. It can be said that if the current `span` implementation of ROOT is compatible with the implementation of the standard library, the problem of mixed standards is not serious, but it is difficult to always guarantee. But as I said, if there is something like `cxx20::span` instead of crashing with the standard library, this issue can be solved from its source. The rest is just the ABI compatibility of this `cxx20::span`, which is guaranteed by t",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11311#issuecomment-1254026839
Usability,simpl,simply,"It turns out this is due to an integer underflow that is triggered by the machinery of `DisplayHelper`:. https://github.com/root-project/root/blob/3160daafc008d8080cb9b3c602f4134b521ca8ad/tree/dataframe/inc/ROOT/RDF/ActionHelpers.hxx#L1334-L1337. The intended workflow is:; 1. Add the next row to be displayed to the `RDisplay` object. The `AddRow` method decreases an internal counter of how many entries are left to be displayed at https://github.com/root-project/root/blob/3160daafc008d8080cb9b3c602f4134b521ca8ad/tree/dataframe/inc/ROOT/RDF/RDisplay.hxx#L227; 2. Check whether there are no more entries to be displayed (`!fDisplayerHelper->HasNext()`).; 3. If so, signal the previous node that this node has finished its job through the `StopProcessing` method. There are a bunch of flaws in this workflow. Uncoditionally calling `AddRow` may trigger the integer underflow by calling `fEntries--` when `fEntries==0`. This can be seen quite simply with the following example; ```cpp; root [0] ROOT::RDataFrame d{1};; root [1] auto dd = d.Define(""b1"", [] { return 42; }).Display<int>({""b1""}, 0);; root [2] dd->Print(); +-----+----+; | Row | b1 | ; +-----+----+; | 0 | 42 | ; +-----+----+. ```; The row is printed even though the user asked for `0` entries to be displayed. The other problem, more subtle and the actual culprit of the reproducer above, is when there is more than just the `Display` operation in the computation graph. `DisplayHelper::Exec` is called once per entry to be processed, as this is the normal working condition in `RLoopManager::Run`. When there is only the `Display` operation, the moment there are no more entries to be displayed, `DisplayHelper` will tell `RLoopManager` that it has finished, thus triggering an early stop of the execution (e.g. if a tree has 100 entries but we only want to display 5). When there is more than one operation, i.e. more than one child of the `RLoopManager`, the call to `StopProcessing` coming from `DisplayHelper::Exec` is not enough t",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11390#issuecomment-1253381156
Usability,clear,clear,"There is still no fix for this yet, but I have changed the title to make clear that this problem is more general. Also there is the same issue in JIRA, that I'll now close because it is a duplicate of this GitHub issue:; https://sft.its.cern.ch/jira/browse/ROOT-9776. The proper fix would be in my opinion to tag the relevant functions in C++ with an attribute, and then have these considered by PyROOT to set the `_creates` attribute automatically.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11397#issuecomment-1432035579
Deployability,patch,patch,"Applying the patch causes a crash when cloning a `THnD`. Here is a simple code reproducing this:; ```; int bins[] = {10}; double xmin[] = {0}; double xmax[] = {10}; ; auto h = new THnD(""h"",""h"",1,bins,xmin,xmax);; h->Sumw2();; h->Clone();; ```. @pcanal , any idea what could be the problem ?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11409#issuecomment-1255079351
Usability,simpl,simple,"Applying the patch causes a crash when cloning a `THnD`. Here is a simple code reproducing this:; ```; int bins[] = {10}; double xmin[] = {0}; double xmax[] = {10}; ; auto h = new THnD(""h"",""h"",1,bins,xmin,xmax);; h->Sumw2();; h->Clone();; ```. @pcanal , any idea what could be the problem ?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11409#issuecomment-1255079351
Availability,alive,alive,"Thanks a lot for your comment!. > * sometimes I would have found useful to be able to pass python number anywhere a RooAbsReal is required, although I suspect this may require a pythonization for each pdf. Yes, I would like this too, but it's technically not easy to implement without changing the source for all PDFs. Maybe I will have an idea at some point as I learn more about PyROOT, but for now I have none. > * `RooSimultaneous` map constructor does not accept a python dictionary yet. That's a very good idea!. > * one thing that surprised me a couple of times at the beginning is that `RooAbsArg` does not keep its servers alive from the python GC so you actually need the same workarounds as in C++ (importing frequently to a workspace).; However, I suspect that if they did keep servers alive, server redirection would likely lead to desync between the C++ and python views of the graph. That's a pretty good idea too. I guess one can simply create new Python references to each server that are set as an attribute of the server, such that they are always kept alive. But you're right, server redirection would break this, unless there are Pythonizations for that one too.... So I still need to think if this is worth it, also considering that users can also use the RooWorkspace factory interface to create PDFs, which doesn't have this problem.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11421#issuecomment-1257762156
Integrability,interface,interface,"Thanks a lot for your comment!. > * sometimes I would have found useful to be able to pass python number anywhere a RooAbsReal is required, although I suspect this may require a pythonization for each pdf. Yes, I would like this too, but it's technically not easy to implement without changing the source for all PDFs. Maybe I will have an idea at some point as I learn more about PyROOT, but for now I have none. > * `RooSimultaneous` map constructor does not accept a python dictionary yet. That's a very good idea!. > * one thing that surprised me a couple of times at the beginning is that `RooAbsArg` does not keep its servers alive from the python GC so you actually need the same workarounds as in C++ (importing frequently to a workspace).; However, I suspect that if they did keep servers alive, server redirection would likely lead to desync between the C++ and python views of the graph. That's a pretty good idea too. I guess one can simply create new Python references to each server that are set as an attribute of the server, such that they are always kept alive. But you're right, server redirection would break this, unless there are Pythonizations for that one too.... So I still need to think if this is worth it, also considering that users can also use the RooWorkspace factory interface to create PDFs, which doesn't have this problem.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11421#issuecomment-1257762156
Usability,learn,learn,"Thanks a lot for your comment!. > * sometimes I would have found useful to be able to pass python number anywhere a RooAbsReal is required, although I suspect this may require a pythonization for each pdf. Yes, I would like this too, but it's technically not easy to implement without changing the source for all PDFs. Maybe I will have an idea at some point as I learn more about PyROOT, but for now I have none. > * `RooSimultaneous` map constructor does not accept a python dictionary yet. That's a very good idea!. > * one thing that surprised me a couple of times at the beginning is that `RooAbsArg` does not keep its servers alive from the python GC so you actually need the same workarounds as in C++ (importing frequently to a workspace).; However, I suspect that if they did keep servers alive, server redirection would likely lead to desync between the C++ and python views of the graph. That's a pretty good idea too. I guess one can simply create new Python references to each server that are set as an attribute of the server, such that they are always kept alive. But you're right, server redirection would break this, unless there are Pythonizations for that one too.... So I still need to think if this is worth it, also considering that users can also use the RooWorkspace factory interface to create PDFs, which doesn't have this problem.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11421#issuecomment-1257762156
Deployability,update,updated,"This PR has been rebased and simplified to leverage the changes introduced by #11828. Accessing single pages that are remotely caged is now unsupported unless page buffering is enabled as a source option (which is by default the case). More details in the updated PR description. The change precludes storing the cage sizes in metadata or upper-bounding it in `RPageSourceDaos`, though it constrains that the entire page-group is requested and fetched - as the allocated buffer size for a cage depends on the sum of all the compressed sizes stored in the individual locators of requested pages belonging to that cage.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11466#issuecomment-1359215581
Energy Efficiency,allocate,allocated,"This PR has been rebased and simplified to leverage the changes introduced by #11828. Accessing single pages that are remotely caged is now unsupported unless page buffering is enabled as a source option (which is by default the case). More details in the updated PR description. The change precludes storing the cage sizes in metadata or upper-bounding it in `RPageSourceDaos`, though it constrains that the entire page-group is requested and fetched - as the allocated buffer size for a cage depends on the sum of all the compressed sizes stored in the individual locators of requested pages belonging to that cage.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11466#issuecomment-1359215581
Integrability,depend,depends,"This PR has been rebased and simplified to leverage the changes introduced by #11828. Accessing single pages that are remotely caged is now unsupported unless page buffering is enabled as a source option (which is by default the case). More details in the updated PR description. The change precludes storing the cage sizes in metadata or upper-bounding it in `RPageSourceDaos`, though it constrains that the entire page-group is requested and fetched - as the allocated buffer size for a cage depends on the sum of all the compressed sizes stored in the individual locators of requested pages belonging to that cage.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11466#issuecomment-1359215581
Usability,simpl,simplified,"This PR has been rebased and simplified to leverage the changes introduced by #11828. Accessing single pages that are remotely caged is now unsupported unless page buffering is enabled as a source option (which is by default the case). More details in the updated PR description. The change precludes storing the cage sizes in metadata or upper-bounding it in `RPageSourceDaos`, though it constrains that the entire page-group is requested and fetched - as the allocated buffer size for a cage depends on the sum of all the compressed sizes stored in the individual locators of requested pages belonging to that cage.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11466#issuecomment-1359215581
Availability,avail,available,"Thank you @jalopezg-r00t :partying_face: I'll rebase the commits shortly and a bit indiscriminately. > I would just suggest testing it again on `olsky-03` or similar, when available. All clear on our (thankfully operational) HPE cluster with daos / libdaos 2.2.0.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11480#issuecomment-1312341311
Testability,test,testing,"Thank you @jalopezg-r00t :partying_face: I'll rebase the commits shortly and a bit indiscriminately. > I would just suggest testing it again on `olsky-03` or similar, when available. All clear on our (thankfully operational) HPE cluster with daos / libdaos 2.2.0.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11480#issuecomment-1312341311
Usability,clear,clear,"Thank you @jalopezg-r00t :partying_face: I'll rebase the commits shortly and a bit indiscriminately. > I would just suggest testing it again on `olsky-03` or similar, when available. All clear on our (thankfully operational) HPE cluster with daos / libdaos 2.2.0.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11480#issuecomment-1312341311
Availability,error,errors,"> The errors seen in the CI such as; > ; > ```; > Error in <TFile::TFile>: file /Users/sftnight/build/jenkins/workspace/root-pullrequests-build/build/roottest/python/distrdf/dask/distrdf_check_friend_trees_alignment_dask_file_1.root/distrdf_check_friend_trees_alignment_dask_tree_1.root does not exist; > ```; > ; > Show that something is wrong with the file names. Notice the double file name above. Probably in the creation of the spec passed to the task-local RDF something is wrong. Hmm that is very strange. I grepped for `distrdf_check_friend_trees_alignment_dask_tree`. It is present only in `python/distrdf/dask/check_friend_trees_alignment.py`. I see that there the chain is created like:; ```py; def create_chain():. main = ROOT.TChain(); for i in range(3):; main.Add(f""{FILENAMES[i]}?#{TREENAMES[i]}""). friend = ROOT.TChain(); for i in range(3, 6):; friend.Add(f""{FILENAMES[i]}?#{TREENAMES[i]}""). main.AddFriend(friend, ""friend""). # import pdb; pdb.set_trace() --> a breakpoint I added. return main; ```; Then calling `df = Dask.RDataFrame(chain, daskclient=connection, npartitions=nparts)`. 1. Is it intentional not to use a spec instead?; 2. From the breakpoint I printed the contents of file and tree names and they looked all file:; ```py; (Pdb) p FILENAMES; ['distrdf_check_friend_trees_alignment_dask_file_1.root', 'distrdf_check_friend_trees_alignment_dask_file_2.root', 'distrdf_check_friend_trees_alignment_dask_file_3.root', 'distrdf_check_friend_trees_alignment_dask_file_4.root', 'distrdf_check_friend_trees_alignment_dask_file_5.root', 'distrdf_check_friend_trees_alignment_dask_file_6.root']; (Pdb) p TREENAMES; ['distrdf_check_friend_trees_alignment_dask_tree_1.root', 'distrdf_check_friend_trees_alignment_dask_tree_2.root', 'distrdf_check_friend_trees_alignment_dask_tree_3.root', 'distrdf_check_friend_trees_alignment_dask_tree_4.root', 'distrdf_check_friend_trees_alignment_dask_tree_5.root', 'distrdf_check_friend_trees_alignment_dask_tree_6.root']; ```; 3. Locally this",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11526#issuecomment-1340908063
Testability,test,test,"urn main; ```; Then calling `df = Dask.RDataFrame(chain, daskclient=connection, npartitions=nparts)`. 1. Is it intentional not to use a spec instead?; 2. From the breakpoint I printed the contents of file and tree names and they looked all file:; ```py; (Pdb) p FILENAMES; ['distrdf_check_friend_trees_alignment_dask_file_1.root', 'distrdf_check_friend_trees_alignment_dask_file_2.root', 'distrdf_check_friend_trees_alignment_dask_file_3.root', 'distrdf_check_friend_trees_alignment_dask_file_4.root', 'distrdf_check_friend_trees_alignment_dask_file_5.root', 'distrdf_check_friend_trees_alignment_dask_file_6.root']; (Pdb) p TREENAMES; ['distrdf_check_friend_trees_alignment_dask_tree_1.root', 'distrdf_check_friend_trees_alignment_dask_tree_2.root', 'distrdf_check_friend_trees_alignment_dask_tree_3.root', 'distrdf_check_friend_trees_alignment_dask_tree_4.root', 'distrdf_check_friend_trees_alignment_dask_tree_5.root', 'distrdf_check_friend_trees_alignment_dask_tree_6.root']; ```; 3. Locally this test fails for me on `s1val = s1.GetValue()`. From pdb I get this stack strace:; ```py; ... > rdf_node = rdf_operation(*in_task_op.args, **in_task_op.kwargs); E cppyy.ll.SegmentationViolation: Template method resolution failed:; E ROOT::RDF::RResultPtr<double> ROOT::RDF::RInterface<ROOT::Detail::RDF::RLoopManager,void>::Sum(basic_string_view<char,char_traits<char> > columnName = """", double& initValue = RDFDetail::SumReturnType_t<RInferredType>{}) =>; E SegmentationViolation: segfault in C++; program state was reset; E ROOT::RDF::RResultPtr<double> ROOT::RDF::RInterface<ROOT::Detail::RDF::RLoopManager,void>::Sum(basic_string_view<char,char_traits<char> > columnName = """", double& initValue = RDFDetail::SumReturnType_t<RInferredType>{}) =>; E SegmentationViolation: segfault in C++; program state was reset. ../../../../rb/lib/DistRDF/ComputationGraphGenerator.py:134: SegmentationViolation; ```; This is also what jenkins complains about. I don't clearly see what is wrong. Investigating ...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11526#issuecomment-1340908063
Usability,clear,clearly,"urn main; ```; Then calling `df = Dask.RDataFrame(chain, daskclient=connection, npartitions=nparts)`. 1. Is it intentional not to use a spec instead?; 2. From the breakpoint I printed the contents of file and tree names and they looked all file:; ```py; (Pdb) p FILENAMES; ['distrdf_check_friend_trees_alignment_dask_file_1.root', 'distrdf_check_friend_trees_alignment_dask_file_2.root', 'distrdf_check_friend_trees_alignment_dask_file_3.root', 'distrdf_check_friend_trees_alignment_dask_file_4.root', 'distrdf_check_friend_trees_alignment_dask_file_5.root', 'distrdf_check_friend_trees_alignment_dask_file_6.root']; (Pdb) p TREENAMES; ['distrdf_check_friend_trees_alignment_dask_tree_1.root', 'distrdf_check_friend_trees_alignment_dask_tree_2.root', 'distrdf_check_friend_trees_alignment_dask_tree_3.root', 'distrdf_check_friend_trees_alignment_dask_tree_4.root', 'distrdf_check_friend_trees_alignment_dask_tree_5.root', 'distrdf_check_friend_trees_alignment_dask_tree_6.root']; ```; 3. Locally this test fails for me on `s1val = s1.GetValue()`. From pdb I get this stack strace:; ```py; ... > rdf_node = rdf_operation(*in_task_op.args, **in_task_op.kwargs); E cppyy.ll.SegmentationViolation: Template method resolution failed:; E ROOT::RDF::RResultPtr<double> ROOT::RDF::RInterface<ROOT::Detail::RDF::RLoopManager,void>::Sum(basic_string_view<char,char_traits<char> > columnName = """", double& initValue = RDFDetail::SumReturnType_t<RInferredType>{}) =>; E SegmentationViolation: segfault in C++; program state was reset; E ROOT::RDF::RResultPtr<double> ROOT::RDF::RInterface<ROOT::Detail::RDF::RLoopManager,void>::Sum(basic_string_view<char,char_traits<char> > columnName = """", double& initValue = RDFDetail::SumReturnType_t<RInferredType>{}) =>; E SegmentationViolation: segfault in C++; program state was reset. ../../../../rb/lib/DistRDF/ComputationGraphGenerator.py:134: SegmentationViolation; ```; This is also what jenkins complains about. I don't clearly see what is wrong. Investigating ...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11526#issuecomment-1340908063
Usability,clear,clear,"The fix seems fine (we are indeed using `fail-on-missing` by default through the spack package). It is still not entirely clear in advance which features require connectivity, and which don't (or even what to do in advance in order to pre-populate the FetchContent locations). There is also confusion with the names of the features: `builtin_` would lead one to think it's provided with the source tree but it isn't, except for `builtin_openui5` where it is the opposite.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11603#issuecomment-2102644827
Deployability,install,install,"Cool, good to hear that the PR goes in the right direction then!. > It is still not entirely clear in advance which features require connectivity. All features of builtins that do require network note this in their description:; * https://root.cern/install/build_from_source/#all-build-options; * https://github.com/root-project/root/blob/master/cmake/modules/RootBuildOptions.cmake#L87. I agree that `builtin_openui5` should explicitly say that it requires network if `OFF`. For the confusing name with `builtin_`, do you have a suggestion to make this clearer? I don't think there are many options there, we meant of course builtin to the ROOT build, not the source tree :slightly_smiling_face: . About the pre-populating of FetchContent locations: I was facing the same problem recently for nix packages. I fixed it in the end by patching the CMake code of ROOT:; https://github.com/NixOS/nixpkgs/pull/308497",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11603#issuecomment-2102765857
Usability,clear,clear,"Cool, good to hear that the PR goes in the right direction then!. > It is still not entirely clear in advance which features require connectivity. All features of builtins that do require network note this in their description:; * https://root.cern/install/build_from_source/#all-build-options; * https://github.com/root-project/root/blob/master/cmake/modules/RootBuildOptions.cmake#L87. I agree that `builtin_openui5` should explicitly say that it requires network if `OFF`. For the confusing name with `builtin_`, do you have a suggestion to make this clearer? I don't think there are many options there, we meant of course builtin to the ROOT build, not the source tree :slightly_smiling_face: . About the pre-populating of FetchContent locations: I was facing the same problem recently for nix packages. I fixed it in the end by patching the CMake code of ROOT:; https://github.com/NixOS/nixpkgs/pull/308497",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11603#issuecomment-2102765857
Availability,error,error,"It is more tricky than I thought. Actually I see the error ""sometimes"" on fresh builds only. That's not clear yet ...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11614#issuecomment-1305640008
Usability,clear,clear,"It is more tricky than I thought. Actually I see the error ""sometimes"" on fresh builds only. That's not clear yet ...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11614#issuecomment-1305640008
Availability,error,error," modes and joins across rather heterogenous datasets. This can make things much easier in the case that, for instance, some random machine learning tool cannot output root files but can produce some other usefully structured data format. . *** - The more general term for this is a a join, and I think you should use that concept here rather than the precise concept of friends in TTree/RNtuple, which is limiting in scope for what is possible for dataset augmentation. Moreover, this allows the definition of left/right/inner/outer joins at the metadata level which is extremely useful for understanding how that additional data is intended to be used (are you just augmenting the number of columns in the dataset, are you x-referencing two datasets, etc.). It is then up to the system ingesting this data to implement the join specified by the user correctly (which can be tested for). For the second *** reference, this is also a restriction of your program, not the metadata, an error should be thrown by whatever is executing and cannot handle a case rather than restricting concepts for describing a dataset. Furthermore, going to joins as a metadata concept allows the user to specify an entire dataset for a join rather than individual files, resulting in significant reduction of doubly-bookkept data. . Entry ranges: I don't think this is very useful data to record. This is either kept track of as a good-luminosity block list, or specified at execution time by the user (since it is often the case they will want to run over a limited piece of the data to test things and then run over the full dataset). Re-writing the metadata on each run would get cumbersome quickly. To take all this and mutate your original suggestion (I haven't defined all the types but hopefully it's intelligible):; ```; {; ""datasets"":{; ""dataset"":{; ""treenames"": Union[List[String], String],; ""files"": List[String],; ""friends"":{; ""treenames"": Union[List[String], String],; ""files"": List[String],; ""joinType"": One",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624#issuecomment-1293743624
Integrability,depend,depending,"Hi - this is an excellent start but I'd like to offer a few considerations given that not everyone uses root files these days. Specifically, friend trees are not a widely accepted concept outside of TTrees and RNtuple. It is, however, easy to abstract away from this so that this metadata specification is more universal. In coffea, we didn't go all the way to formalizing it in a schema since there are many details but you can see the basic validation we do here:; https://github.com/CoffeaTeam/coffea/blob/master/coffea/processor/executor.py#L1353; We allow forms like:; ```; fileset = { ""dataset"" : [""some"", ""list"", ""of"", ""files""], ...}; # and; fileset = { ""dataset"": { ""files"": [""file1"", ""file2"", ...], ""treename"": ""Events"", ""metadata"": { ""stuff"": ""about stuff""}, ...}, { .... } }; ```; depending on user need.; I think optional and union types are very convenient here since not every user will need or want to specify all components of the full schema on each use (but uniformizing the description when needed is very important). . To repeat from above here is the suggested metadata requirements (with annotations).; """"""; This new standard schema should support a few key features of the definition of a dataset:. * Specify groups of several input files, each with associated metadata; * Decide what term to use instead of ""groups"" (dataset is probably best); * Cover TTree but plan for RNTuple support (metadata should not care about file formats, your program does); * Should support friend trees per group *** (see below); * Should support entry ranges per group (why? this makes little operational sense from the POV of an analyst); * No indexed friend trees (at least for now) *** (also); """"""; This specification of requirements mixes things that are describing the data (metadata) and and how to react to it (something in a program, not part of the schema). I believe a clean factorization along these lines is very important to creating a well-adopted schema if you intend to develop a ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624#issuecomment-1293743624
Security,validat,validation,"Hi - this is an excellent start but I'd like to offer a few considerations given that not everyone uses root files these days. Specifically, friend trees are not a widely accepted concept outside of TTrees and RNtuple. It is, however, easy to abstract away from this so that this metadata specification is more universal. In coffea, we didn't go all the way to formalizing it in a schema since there are many details but you can see the basic validation we do here:; https://github.com/CoffeaTeam/coffea/blob/master/coffea/processor/executor.py#L1353; We allow forms like:; ```; fileset = { ""dataset"" : [""some"", ""list"", ""of"", ""files""], ...}; # and; fileset = { ""dataset"": { ""files"": [""file1"", ""file2"", ...], ""treename"": ""Events"", ""metadata"": { ""stuff"": ""about stuff""}, ...}, { .... } }; ```; depending on user need.; I think optional and union types are very convenient here since not every user will need or want to specify all components of the full schema on each use (but uniformizing the description when needed is very important). . To repeat from above here is the suggested metadata requirements (with annotations).; """"""; This new standard schema should support a few key features of the definition of a dataset:. * Specify groups of several input files, each with associated metadata; * Decide what term to use instead of ""groups"" (dataset is probably best); * Cover TTree but plan for RNTuple support (metadata should not care about file formats, your program does); * Should support friend trees per group *** (see below); * Should support entry ranges per group (why? this makes little operational sense from the POV of an analyst); * No indexed friend trees (at least for now) *** (also); """"""; This specification of requirements mixes things that are describing the data (metadata) and and how to react to it (something in a program, not part of the schema). I believe a clean factorization along these lines is very important to creating a well-adopted schema if you intend to develop a ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624#issuecomment-1293743624
Testability,test,tested,"people do use parquet or hdf5 in analysis. Removing those formats as concepts to describe a dataset is rather limiting. Allowing them opens up many possibilities, including mixed modes and joins across rather heterogenous datasets. This can make things much easier in the case that, for instance, some random machine learning tool cannot output root files but can produce some other usefully structured data format. . *** - The more general term for this is a a join, and I think you should use that concept here rather than the precise concept of friends in TTree/RNtuple, which is limiting in scope for what is possible for dataset augmentation. Moreover, this allows the definition of left/right/inner/outer joins at the metadata level which is extremely useful for understanding how that additional data is intended to be used (are you just augmenting the number of columns in the dataset, are you x-referencing two datasets, etc.). It is then up to the system ingesting this data to implement the join specified by the user correctly (which can be tested for). For the second *** reference, this is also a restriction of your program, not the metadata, an error should be thrown by whatever is executing and cannot handle a case rather than restricting concepts for describing a dataset. Furthermore, going to joins as a metadata concept allows the user to specify an entire dataset for a join rather than individual files, resulting in significant reduction of doubly-bookkept data. . Entry ranges: I don't think this is very useful data to record. This is either kept track of as a good-luminosity block list, or specified at execution time by the user (since it is often the case they will want to run over a limited piece of the data to test things and then run over the full dataset). Re-writing the metadata on each run would get cumbersome quickly. To take all this and mutate your original suggestion (I haven't defined all the types but hopefully it's intelligible):; ```; {; ""datasets"":",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624#issuecomment-1293743624
Usability,learn,learning,"r TTree but plan for RNTuple support (metadata should not care about file formats, your program does); * Should support friend trees per group *** (see below); * Should support entry ranges per group (why? this makes little operational sense from the POV of an analyst); * No indexed friend trees (at least for now) *** (also); """"""; This specification of requirements mixes things that are describing the data (metadata) and and how to react to it (something in a program, not part of the schema). I believe a clean factorization along these lines is very important to creating a well-adopted schema if you intend to develop a standard. As to files - it is not very common but people do use parquet or hdf5 in analysis. Removing those formats as concepts to describe a dataset is rather limiting. Allowing them opens up many possibilities, including mixed modes and joins across rather heterogenous datasets. This can make things much easier in the case that, for instance, some random machine learning tool cannot output root files but can produce some other usefully structured data format. . *** - The more general term for this is a a join, and I think you should use that concept here rather than the precise concept of friends in TTree/RNtuple, which is limiting in scope for what is possible for dataset augmentation. Moreover, this allows the definition of left/right/inner/outer joins at the metadata level which is extremely useful for understanding how that additional data is intended to be used (are you just augmenting the number of columns in the dataset, are you x-referencing two datasets, etc.). It is then up to the system ingesting this data to implement the join specified by the user correctly (which can be tested for). For the second *** reference, this is also a restriction of your program, not the metadata, an error should be thrown by whatever is executing and cannot handle a case rather than restricting concepts for describing a dataset. Furthermore, going to joins as",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624#issuecomment-1293743624
Availability,error,error," a large consensus on this information being useful when written at the datasets/samples level. I also agree with you that an entry range is usually specified when testing before running the full thing. Nonetheless, the important part of this feature was the ability to tie a specific entry range to a specific dataset/sample and not to the global dataset, so that even when testing at least N entries from each dataset/sample would be processed. If this is not specified when definining the dataset metadata, then I suppose we should expose some API like:. ```python; entry_ranges = [(0,1000), (50000, 60000)] # taken from my initial specification example; df = RDataFrame(...); df.SetEntryRanges(entry_ranges); ```; And similarly for coffea and other frameworks. What I don't like about this is that I need to remember how many datasets/samples I have in my specification so that `len(entry_ranges)` corresponds to that number. Of course the tool can error and say ""You have specified too many entry ranges, please use only N"", maybe that's good enough but I'm not sure. One other comment could be that we don't need to have exactly one entry range per dataset/sample, maybe some datasets just need to be processed fully. But the API from above would not be able to distinguish whether the user actually didn't want to provide an entry range for a certain dataset or just forgot how many datasets were there. How would you address this part?. > To take all this and mutate your original suggestion. Thanks for taking the time to include this example. I am happy that you agree on having a single top-level key ""datasets"" in which all the various datasets can be defined. I think this opens possibilities to use the rest of the JSON file for describing more parts of the analysis while not touching the dataset specification. I just wanted to ask you a clarification regarding the type `List[Dict[As in Single Dict]]` mentioned in the ""friends"" key. This is practically saying that instead of a singl",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624#issuecomment-1297411993
Deployability,pipeline,pipeline," the other. Do you think we should poll the larger audience at some point, for this and probably other questions? One other option could be just accepting both ""datasets"" and ""samples"" as the top-level key in the JSON object. > Cover TTree but plan for RNTuple support (metadata should not care about file formats, your program does). Indeed, this point was more directed towards us developers rather than user-facing. Metadata will definitely be orthogonal to the data format. > Allowing them opens up many possibilities, including mixed modes and joins across rather heterogenous datasets. This is an interesting comment, something that I hadn't put too much thought into. I think that it is much related with the other comment regarding joins. Mixed modes sounds intriguing although I can't see a clear path for its implementation in the I/O layer, rather we may be better off doing this at the analysis tool layer directly. In general, the usecase of reading the output of some ML pipeline during the execution of the analysis is definitely something we want to address. For what concerns this specification, the easy part is just deciding for something more generic than ""treenames"" when specifying these other data formats; the trickier part is deciding how these other input data should be read. See the next comment for more discussion about this. > The more general term for this is a a join, and I think you should use that concept here rather than the precise concept of friends in TTree/RNtuple. Yes I agree we can describe adding more columns to the main dataset as a join, with the implicit but crucial clarification that it is a view on the join operation and not a concrete join operation that would involve copying the two operands. With this sense, a friend TTree is equivalent to a left join where both unique IDs correspond to the event index and are the same number. I completely agree that this is a limit, indexed friends only extend it a little bit by allowing different sets o",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624#issuecomment-1297411993
Modifiability,extend,extend,"g the output of some ML pipeline during the execution of the analysis is definitely something we want to address. For what concerns this specification, the easy part is just deciding for something more generic than ""treenames"" when specifying these other data formats; the trickier part is deciding how these other input data should be read. See the next comment for more discussion about this. > The more general term for this is a a join, and I think you should use that concept here rather than the precise concept of friends in TTree/RNtuple. Yes I agree we can describe adding more columns to the main dataset as a join, with the implicit but crucial clarification that it is a view on the join operation and not a concrete join operation that would involve copying the two operands. With this sense, a friend TTree is equivalent to a left join where both unique IDs correspond to the event index and are the same number. I completely agree that this is a limit, indexed friends only extend it a little bit by allowing different sets of event indexes in the two tables. The idea of an heterogeneous dataset layout, with some datasets/samples having to be left-joined and others having to be inner-joined (for example), involves some design work and I would like to discuss it further, although I'd like to get a better idea of the use cases that need any joins other than left join. > Entry ranges: I don't think this is very useful data to record. This is either kept track of as a good-luminosity block list, or specified at execution time by the user. During the meeting a few weeks ago there was quite a large consensus on this information being useful when written at the datasets/samples level. I also agree with you that an entry range is usually specified when testing before running the full thing. Nonetheless, the important part of this feature was the ability to tie a specific entry range to a specific dataset/sample and not to the global dataset, so that even when testing at leas",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624#issuecomment-1297411993
Security,validat,validation,"Dear @lgray,. Thanks a lot for your input! Let me try to comment on the various parts. > I think optional and union types are very convenient here. Absolutely, I agree. Thank you also for the info about the data validation in coffea. The decision on the keys that need a union type should also be part of this formalization effort. > Decide what term to use instead of ""groups"" (dataset is probably best). I see there are these two schools of thought but I cannot grasp how much of the community leans towards one vs the other. Do you think we should poll the larger audience at some point, for this and probably other questions? One other option could be just accepting both ""datasets"" and ""samples"" as the top-level key in the JSON object. > Cover TTree but plan for RNTuple support (metadata should not care about file formats, your program does). Indeed, this point was more directed towards us developers rather than user-facing. Metadata will definitely be orthogonal to the data format. > Allowing them opens up many possibilities, including mixed modes and joins across rather heterogenous datasets. This is an interesting comment, something that I hadn't put too much thought into. I think that it is much related with the other comment regarding joins. Mixed modes sounds intriguing although I can't see a clear path for its implementation in the I/O layer, rather we may be better off doing this at the analysis tool layer directly. In general, the usecase of reading the output of some ML pipeline during the execution of the analysis is definitely something we want to address. For what concerns this specification, the easy part is just deciding for something more generic than ""treenames"" when specifying these other data formats; the trickier part is deciding how these other input data should be read. See the next comment for more discussion about this. > The more general term for this is a a join, and I think you should use that concept here rather than the precise concept of fri",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624#issuecomment-1297411993
Testability,test,testing,"olve copying the two operands. With this sense, a friend TTree is equivalent to a left join where both unique IDs correspond to the event index and are the same number. I completely agree that this is a limit, indexed friends only extend it a little bit by allowing different sets of event indexes in the two tables. The idea of an heterogeneous dataset layout, with some datasets/samples having to be left-joined and others having to be inner-joined (for example), involves some design work and I would like to discuss it further, although I'd like to get a better idea of the use cases that need any joins other than left join. > Entry ranges: I don't think this is very useful data to record. This is either kept track of as a good-luminosity block list, or specified at execution time by the user. During the meeting a few weeks ago there was quite a large consensus on this information being useful when written at the datasets/samples level. I also agree with you that an entry range is usually specified when testing before running the full thing. Nonetheless, the important part of this feature was the ability to tie a specific entry range to a specific dataset/sample and not to the global dataset, so that even when testing at least N entries from each dataset/sample would be processed. If this is not specified when definining the dataset metadata, then I suppose we should expose some API like:. ```python; entry_ranges = [(0,1000), (50000, 60000)] # taken from my initial specification example; df = RDataFrame(...); df.SetEntryRanges(entry_ranges); ```; And similarly for coffea and other frameworks. What I don't like about this is that I need to remember how many datasets/samples I have in my specification so that `len(entry_ranges)` corresponds to that number. Of course the tool can error and say ""You have specified too many entry ranges, please use only N"", maybe that's good enough but I'm not sure. One other comment could be that we don't need to have exactly one entry rang",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624#issuecomment-1297411993
Usability,clear,clear,"o use instead of ""groups"" (dataset is probably best). I see there are these two schools of thought but I cannot grasp how much of the community leans towards one vs the other. Do you think we should poll the larger audience at some point, for this and probably other questions? One other option could be just accepting both ""datasets"" and ""samples"" as the top-level key in the JSON object. > Cover TTree but plan for RNTuple support (metadata should not care about file formats, your program does). Indeed, this point was more directed towards us developers rather than user-facing. Metadata will definitely be orthogonal to the data format. > Allowing them opens up many possibilities, including mixed modes and joins across rather heterogenous datasets. This is an interesting comment, something that I hadn't put too much thought into. I think that it is much related with the other comment regarding joins. Mixed modes sounds intriguing although I can't see a clear path for its implementation in the I/O layer, rather we may be better off doing this at the analysis tool layer directly. In general, the usecase of reading the output of some ML pipeline during the execution of the analysis is definitely something we want to address. For what concerns this specification, the easy part is just deciding for something more generic than ""treenames"" when specifying these other data formats; the trickier part is deciding how these other input data should be read. See the next comment for more discussion about this. > The more general term for this is a a join, and I think you should use that concept here rather than the precise concept of friends in TTree/RNtuple. Yes I agree we can describe adding more columns to the main dataset as a join, with the implicit but crucial clarification that it is a view on the join operation and not a concrete join operation that would involve copying the two operands. With this sense, a friend TTree is equivalent to a left join where both unique IDs corr",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624#issuecomment-1297411993
Deployability,update,update,"Ah, no, actually that first part can also be non-increasing, for instance if the reception of tasks on the queue for some reason pauses half way through, so e.g. you could get:; 1 [ reception pauses on queue here ]; 0 [ reception continues now, 2 comes in ]; 2 [ while executing 2, everything else is received ]; 9; 8; 7; 6; ... And that is still valid. I will just push one more update with a refactoring to not have this complicated expectation correction code duplicate.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627#issuecomment-1330826120
Modifiability,refactor,refactoring,"Ah, no, actually that first part can also be non-increasing, for instance if the reception of tasks on the queue for some reason pauses half way through, so e.g. you could get:; 1 [ reception pauses on queue here ]; 0 [ reception continues now, 2 comes in ]; 2 [ while executing 2, everything else is received ]; 9; 8; 7; 6; ... And that is still valid. I will just push one more update with a refactoring to not have this complicated expectation correction code duplicate.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627#issuecomment-1330826120
Performance,queue,queue,"Ah, no, actually that first part can also be non-increasing, for instance if the reception of tasks on the queue for some reason pauses half way through, so e.g. you could get:; 1 [ reception pauses on queue here ]; 0 [ reception continues now, 2 comes in ]; 2 [ while executing 2, everything else is received ]; 9; 8; 7; 6; ... And that is still valid. I will just push one more update with a refactoring to not have this complicated expectation correction code duplicate.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627#issuecomment-1330826120
Usability,pause,pauses,"Ah, no, actually that first part can also be non-increasing, for instance if the reception of tasks on the queue for some reason pauses half way through, so e.g. you could get:; 1 [ reception pauses on queue here ]; 0 [ reception continues now, 2 comes in ]; 2 [ while executing 2, everything else is received ]; 9; 8; 7; 6; ... And that is still valid. I will just push one more update with a refactoring to not have this complicated expectation correction code duplicate.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11627#issuecomment-1330826120
Availability,failure,failure,"And when building with gcc and only asan like:; ```; cmake -DCMAKE_BUILD_TYPE=""Release"" -Dasan=ON -Dtesting=ON -DPYTHON_EXECUTABLE=/usr/bin/python3 /home/linev/git/webgui ; ```; I getting failure by simply starting ROOT: . ```; ==11405==ERROR: AddressSanitizer: use-after-poison on address 0x621000160c68 at pc 0x7fae6dbe9aa1 bp 0x7fff179941b0 sp 0x7fff179941a8; READ of size 8 at 0x621000160c68 thread T0; #0 0x7fae6dbe9aa0 in clang::LookupResult::configure() (/home/linev/build/asan/lib/libCling.so+0x9be9aa0) (BuildId: b992d84f780d9cdfaac57feecd814f7d11e56300); #1 0x7fae66c6d0ec in clad::plugin::CladPlugin::CheckBuiltins() [clone .part.0] (/home/linev/build/asan/lib/libCling.so+0x2c6d0ec) (BuildId: b992d84f780d9cdfaac57feecd814f7d11e56300); ```. Full error output: [start_log.txt](https://github.com/root-project/root/files/10519690/start_log.txt)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629#issuecomment-1406573290
Modifiability,config,configure,"And when building with gcc and only asan like:; ```; cmake -DCMAKE_BUILD_TYPE=""Release"" -Dasan=ON -Dtesting=ON -DPYTHON_EXECUTABLE=/usr/bin/python3 /home/linev/git/webgui ; ```; I getting failure by simply starting ROOT: . ```; ==11405==ERROR: AddressSanitizer: use-after-poison on address 0x621000160c68 at pc 0x7fae6dbe9aa1 bp 0x7fff179941b0 sp 0x7fff179941a8; READ of size 8 at 0x621000160c68 thread T0; #0 0x7fae6dbe9aa0 in clang::LookupResult::configure() (/home/linev/build/asan/lib/libCling.so+0x9be9aa0) (BuildId: b992d84f780d9cdfaac57feecd814f7d11e56300); #1 0x7fae66c6d0ec in clad::plugin::CladPlugin::CheckBuiltins() [clone .part.0] (/home/linev/build/asan/lib/libCling.so+0x2c6d0ec) (BuildId: b992d84f780d9cdfaac57feecd814f7d11e56300); ```. Full error output: [start_log.txt](https://github.com/root-project/root/files/10519690/start_log.txt)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629#issuecomment-1406573290
Usability,simpl,simply,"And when building with gcc and only asan like:; ```; cmake -DCMAKE_BUILD_TYPE=""Release"" -Dasan=ON -Dtesting=ON -DPYTHON_EXECUTABLE=/usr/bin/python3 /home/linev/git/webgui ; ```; I getting failure by simply starting ROOT: . ```; ==11405==ERROR: AddressSanitizer: use-after-poison on address 0x621000160c68 at pc 0x7fae6dbe9aa1 bp 0x7fff179941b0 sp 0x7fff179941a8; READ of size 8 at 0x621000160c68 thread T0; #0 0x7fae6dbe9aa0 in clang::LookupResult::configure() (/home/linev/build/asan/lib/libCling.so+0x9be9aa0) (BuildId: b992d84f780d9cdfaac57feecd814f7d11e56300); #1 0x7fae66c6d0ec in clad::plugin::CladPlugin::CheckBuiltins() [clone .part.0] (/home/linev/build/asan/lib/libCling.so+0x2c6d0ec) (BuildId: b992d84f780d9cdfaac57feecd814f7d11e56300); ```. Full error output: [start_log.txt](https://github.com/root-project/root/files/10519690/start_log.txt)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11629#issuecomment-1406573290
Deployability,release,release,"The issue in CMSSW is fixed now by just not doing a ranged fit, but in ROOT master this performance regression still needs to be fixed. Here is a simple reproducer for the problem, with the code extracted from the CMSSW source linked in the initial post:; ```c++; void script(); {; using namespace RooFit;. RooRealVar x(""x"", """", 0, 10);. RooRealVar mean(""mu"", """", 5.0, 0, 10);; RooRealVar width(""width"", """", 1.0, 0.1, 10);; RooRealVar sigma(""sigma"", """", 2.0, 0.1, 10);; RooVoigtian voigt(""voigt"", """", x, mean, width, sigma);. RooRealVar lambda(""lambda"", """", -0.01, -100., 1.);; RooExponential expo(""expo"", """", x, lambda);. RooRealVar b(""n_bkg"", """", 100., 0, 1000);; RooRealVar s(""n_sig"", """", 1000., 0, 10000);. RooAddPdf model(""model"", """", {voigt, expo}, {s, b});. std::unique_ptr<RooDataSet> data{model.generate(x)};. model.fitTo(*data, Range(0.0, 10.0), PrintLevel(-1));; }; ```. Most likely, this issue was caused by https://github.com/root-project/root/pull/11455. I set the priority to `high` now, because this is a regression that also affects experiment workflows and it needs to be fixed before the 6.28 release for sure! Therefore, this issue is also added to the 6.28 milestone.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11637#issuecomment-1297108209
Performance,perform,performance,"The issue in CMSSW is fixed now by just not doing a ranged fit, but in ROOT master this performance regression still needs to be fixed. Here is a simple reproducer for the problem, with the code extracted from the CMSSW source linked in the initial post:; ```c++; void script(); {; using namespace RooFit;. RooRealVar x(""x"", """", 0, 10);. RooRealVar mean(""mu"", """", 5.0, 0, 10);; RooRealVar width(""width"", """", 1.0, 0.1, 10);; RooRealVar sigma(""sigma"", """", 2.0, 0.1, 10);; RooVoigtian voigt(""voigt"", """", x, mean, width, sigma);. RooRealVar lambda(""lambda"", """", -0.01, -100., 1.);; RooExponential expo(""expo"", """", x, lambda);. RooRealVar b(""n_bkg"", """", 100., 0, 1000);; RooRealVar s(""n_sig"", """", 1000., 0, 10000);. RooAddPdf model(""model"", """", {voigt, expo}, {s, b});. std::unique_ptr<RooDataSet> data{model.generate(x)};. model.fitTo(*data, Range(0.0, 10.0), PrintLevel(-1));; }; ```. Most likely, this issue was caused by https://github.com/root-project/root/pull/11455. I set the priority to `high` now, because this is a regression that also affects experiment workflows and it needs to be fixed before the 6.28 release for sure! Therefore, this issue is also added to the 6.28 milestone.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11637#issuecomment-1297108209
Usability,simpl,simple,"The issue in CMSSW is fixed now by just not doing a ranged fit, but in ROOT master this performance regression still needs to be fixed. Here is a simple reproducer for the problem, with the code extracted from the CMSSW source linked in the initial post:; ```c++; void script(); {; using namespace RooFit;. RooRealVar x(""x"", """", 0, 10);. RooRealVar mean(""mu"", """", 5.0, 0, 10);; RooRealVar width(""width"", """", 1.0, 0.1, 10);; RooRealVar sigma(""sigma"", """", 2.0, 0.1, 10);; RooVoigtian voigt(""voigt"", """", x, mean, width, sigma);. RooRealVar lambda(""lambda"", """", -0.01, -100., 1.);; RooExponential expo(""expo"", """", x, lambda);. RooRealVar b(""n_bkg"", """", 100., 0, 1000);; RooRealVar s(""n_sig"", """", 1000., 0, 10000);. RooAddPdf model(""model"", """", {voigt, expo}, {s, b});. std::unique_ptr<RooDataSet> data{model.generate(x)};. model.fitTo(*data, Range(0.0, 10.0), PrintLevel(-1));; }; ```. Most likely, this issue was caused by https://github.com/root-project/root/pull/11455. I set the priority to `high` now, because this is a regression that also affects experiment workflows and it needs to be fixed before the 6.28 release for sure! Therefore, this issue is also added to the 6.28 milestone.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11637#issuecomment-1297108209
Availability,down,down,"I narrowed the issue down to a more simple reproducer:; ```C++; void script(); {; RooRealVar x{""x"", """", -10, 10};; x.setRange(""fit"", 0, 10);. RooGenericPdf gauss{""gauss"", ""std::exp(-0.5 * (x*x))"", x};; RooRealVar s{""n_sig"", """", 1000., 0, 10000};; RooAddPdf model{""model"", """", {gauss}, {s}};. std::unique_ptr<RooDataSet> data{model.generate(x)};. // Comment this out and it is fast again; model.setNormRange(""fit"");. std::unique_ptr<RooAbsReal> nll{model.createNLL(*data)};. for(std::size_t i = 0; i < 1000; ++i) {; s.setVal(s.getVal() + (i % 2 ? +1 : -1));; nll->getVal();; }; }; ```. The problem might have something to do with the old test statistics, because if you use the new BatchMode things are going fine. Probably, the dirty flags to the integral are propagated wrongly, causing a numeric integral to be computed for each event.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11637#issuecomment-1297295506
Testability,test,test,"I narrowed the issue down to a more simple reproducer:; ```C++; void script(); {; RooRealVar x{""x"", """", -10, 10};; x.setRange(""fit"", 0, 10);. RooGenericPdf gauss{""gauss"", ""std::exp(-0.5 * (x*x))"", x};; RooRealVar s{""n_sig"", """", 1000., 0, 10000};; RooAddPdf model{""model"", """", {gauss}, {s}};. std::unique_ptr<RooDataSet> data{model.generate(x)};. // Comment this out and it is fast again; model.setNormRange(""fit"");. std::unique_ptr<RooAbsReal> nll{model.createNLL(*data)};. for(std::size_t i = 0; i < 1000; ++i) {; s.setVal(s.getVal() + (i % 2 ? +1 : -1));; nll->getVal();; }; }; ```. The problem might have something to do with the old test statistics, because if you use the new BatchMode things are going fine. Probably, the dirty flags to the integral are propagated wrongly, causing a numeric integral to be computed for each event.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11637#issuecomment-1297295506
Usability,simpl,simple,"I narrowed the issue down to a more simple reproducer:; ```C++; void script(); {; RooRealVar x{""x"", """", -10, 10};; x.setRange(""fit"", 0, 10);. RooGenericPdf gauss{""gauss"", ""std::exp(-0.5 * (x*x))"", x};; RooRealVar s{""n_sig"", """", 1000., 0, 10000};; RooAddPdf model{""model"", """", {gauss}, {s}};. std::unique_ptr<RooDataSet> data{model.generate(x)};. // Comment this out and it is fast again; model.setNormRange(""fit"");. std::unique_ptr<RooAbsReal> nll{model.createNLL(*data)};. for(std::size_t i = 0; i < 1000; ++i) {; s.setVal(s.getVal() + (i % 2 ? +1 : -1));; nll->getVal();; }; }; ```. The problem might have something to do with the old test statistics, because if you use the new BatchMode things are going fine. Probably, the dirty flags to the integral are propagated wrongly, causing a numeric integral to be computed for each event.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11637#issuecomment-1297295506
Testability,test,test,"Thanks, @pcanal. I will move the code. Hopefully after that we can merge. I also had a request to test this across the ocean, so if you could try to compare before/after by running something simple using data at CERN (or let me know of a file publicly avaiable via XRootD in Fermilab or other location in the US), I would appreciate it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644#issuecomment-1308989870
Usability,simpl,simple,"Thanks, @pcanal. I will move the code. Hopefully after that we can merge. I also had a request to test this across the ocean, so if you could try to compare before/after by running something simple using data at CERN (or let me know of a file publicly avaiable via XRootD in Fermilab or other location in the US), I would appreciate it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644#issuecomment-1308989870
Security,certificate,certificate,> so if you could try to compare before/after by running something simple using data at CERN. CMS currently does not mount CERN's eos through fuse at FNAL and does not export (without grid certificate) any data.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644#issuecomment-1309267711
Usability,simpl,simple,> so if you could try to compare before/after by running something simple using data at CERN. CMS currently does not mount CERN's eos through fuse at FNAL and does not export (without grid certificate) any data.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11644#issuecomment-1309267711
Testability,test,tests,"Right, of course the tests are correctly failing now where they still use `Offset` for the `NewStyle` likelihoods :). We should probably do two things to finish this PR:; 1. Add a test somewhere (I guess `testLikelihoodGradientJob.cxx` is as good a place as any) that fails when creating a likelihood with the two arguments together. The test can simply check whether the output of `createNLL` is `0`.; 2. Remove `Offset` from the `NewStyle` likelihood creation lines. _Side note:_ I think it would be much better if [`createNLL` just throws here](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooAbsPdf.cxx#L1032) instead of returning zero and causing segfaults along the way. But this is probably an issue for a different PR. Would probably be good to run by Wouter to make sure there are no valid usecases of returning a `nullptr`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11650#issuecomment-1330379864
Usability,simpl,simply,"Right, of course the tests are correctly failing now where they still use `Offset` for the `NewStyle` likelihoods :). We should probably do two things to finish this PR:; 1. Add a test somewhere (I guess `testLikelihoodGradientJob.cxx` is as good a place as any) that fails when creating a likelihood with the two arguments together. The test can simply check whether the output of `createNLL` is `0`.; 2. Remove `Offset` from the `NewStyle` likelihood creation lines. _Side note:_ I think it would be much better if [`createNLL` just throws here](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooAbsPdf.cxx#L1032) instead of returning zero and causing segfaults along the way. But this is probably an issue for a different PR. Would probably be good to run by Wouter to make sure there are no valid usecases of returning a `nullptr`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11650#issuecomment-1330379864
Performance,multi-thread,multi-threading,"If we enable ORCV2 asynchronous compilation, it is clear we have to enable threading support in LLVM. So the question is whether we do want to enable ORCV2 asynchronous compilation or not, some things to consider:; * cost to all or most (?) of the interpreter calls (which then would likely takes 2 locks instead of one); * risk of dead locks; now that the interpreter takes 2 locks, if there is any way that code that takes the LLVM lock calls code directly or indirectly (via user function or even dlopen) take the ROOT locks then they will be dead locks.; * risk of over-subscribing the CPU (i.e. see the many back and forth in the PPP between the way we setup resource sharing between the experiment framework and the implicit multi-threading). ; * size of the gain; given than most (but indeed not all) compilation are very small, is it worth the costs?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11699#issuecomment-1312791296
Safety,risk,risk,"If we enable ORCV2 asynchronous compilation, it is clear we have to enable threading support in LLVM. So the question is whether we do want to enable ORCV2 asynchronous compilation or not, some things to consider:; * cost to all or most (?) of the interpreter calls (which then would likely takes 2 locks instead of one); * risk of dead locks; now that the interpreter takes 2 locks, if there is any way that code that takes the LLVM lock calls code directly or indirectly (via user function or even dlopen) take the ROOT locks then they will be dead locks.; * risk of over-subscribing the CPU (i.e. see the many back and forth in the PPP between the way we setup resource sharing between the experiment framework and the implicit multi-threading). ; * size of the gain; given than most (but indeed not all) compilation are very small, is it worth the costs?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11699#issuecomment-1312791296
Usability,clear,clear,"If we enable ORCV2 asynchronous compilation, it is clear we have to enable threading support in LLVM. So the question is whether we do want to enable ORCV2 asynchronous compilation or not, some things to consider:; * cost to all or most (?) of the interpreter calls (which then would likely takes 2 locks instead of one); * risk of dead locks; now that the interpreter takes 2 locks, if there is any way that code that takes the LLVM lock calls code directly or indirectly (via user function or even dlopen) take the ROOT locks then they will be dead locks.; * risk of over-subscribing the CPU (i.e. see the many back and forth in the PPP between the way we setup resource sharing between the experiment framework and the implicit multi-threading). ; * size of the gain; given than most (but indeed not all) compilation are very small, is it worth the costs?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11699#issuecomment-1312791296
Availability,error,error,"I do not get this crash:; ```; % root -l main.cpp ; root [0] ; Processing main.cpp...; Error in <TApplication::TApplication>: only one instance of TApplication allowed; ------------------------------------------------------------------; | Welcome to ROOT 6.27/01 https://root.cern |; | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |; | Built for macosx64 on Nov 15 2022, 10:28:34 |; | From heads/master@v6-25-02-2747-g7a90392f2a |; | With Apple clang version 14.0.0 (clang-1400.0.29.202) |; | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |; ------------------------------------------------------------------. root [0] ; ```; For me, on Mac, it is protected. Seems to me the error is not cryptic at all. It makes it clear that `main()` already exists.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11707#issuecomment-1315410117
Usability,clear,clear,"I do not get this crash:; ```; % root -l main.cpp ; root [0] ; Processing main.cpp...; Error in <TApplication::TApplication>: only one instance of TApplication allowed; ------------------------------------------------------------------; | Welcome to ROOT 6.27/01 https://root.cern |; | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |; | Built for macosx64 on Nov 15 2022, 10:28:34 |; | From heads/master@v6-25-02-2747-g7a90392f2a |; | With Apple clang version 14.0.0 (clang-1400.0.29.202) |; | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |; ------------------------------------------------------------------. root [0] ; ```; For me, on Mac, it is protected. Seems to me the error is not cryptic at all. It makes it clear that `main()` already exists.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11707#issuecomment-1315410117
Availability,error,error,"> Seems to me the error is not cryptic at all. It makes it clear that `main()` already exists. Newbie users do not know what TApplication is, and how that should be related with main(). See https://stackoverflow.com/questions/74247557/warning-failed-to-call-main-to-execute-the-macro/74445395#74445395",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11707#issuecomment-1315414134
Usability,clear,clear,"> Seems to me the error is not cryptic at all. It makes it clear that `main()` already exists. Newbie users do not know what TApplication is, and how that should be related with main(). See https://stackoverflow.com/questions/74247557/warning-failed-to-call-main-to-execute-the-macro/74445395#74445395",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11707#issuecomment-1315414134
Availability,error,error,Maybe it can be made more clear but the message comes from [here](https://github.com/root-project/root/blob/bd200315c50ac1520f75f959a852c6d3333f8aa9/core/base/src/TApplication.cxx#L147). I guess this error can occur for many more reasons than a macro called `main.cpp`. So it will not be easy to make it clearer there. Maybe @Axel-Naumann or @pcanal can comment.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11707#issuecomment-1315426448
Integrability,message,message,Maybe it can be made more clear but the message comes from [here](https://github.com/root-project/root/blob/bd200315c50ac1520f75f959a852c6d3333f8aa9/core/base/src/TApplication.cxx#L147). I guess this error can occur for many more reasons than a macro called `main.cpp`. So it will not be easy to make it clearer there. Maybe @Axel-Naumann or @pcanal can comment.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11707#issuecomment-1315426448
Usability,clear,clear,Maybe it can be made more clear but the message comes from [here](https://github.com/root-project/root/blob/bd200315c50ac1520f75f959a852c6d3333f8aa9/core/base/src/TApplication.cxx#L147). I guess this error can occur for many more reasons than a macro called `main.cpp`. So it will not be easy to make it clearer there. Maybe @Axel-Naumann or @pcanal can comment.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11707#issuecomment-1315426448
Availability,avail,available,"> I think we need to think about mapping and the view interface, which uses `RField<T>::Map()` where available. I'd be in favor of ignoring read callbacks for mapping. Mapping should be the interface to get the fastest possible performance. Of course, that would break views on simple types with read callback. One way to deal with it is to simply not allow creating a view on a field with a mappable type and a read callback. Good point; I agree on that :+1:. However, given that any `RField<T>` instance that has an on-disk field ID set (such as the one internally kept by `RNTupleView`) can be connected to a page source, additional bookkeeping is required somewhere else. (**EDIT:** see the pull request description - everything discussed there)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11731#issuecomment-1334547546
Integrability,interface,interface,"> I think we need to think about mapping and the view interface, which uses `RField<T>::Map()` where available. I'd be in favor of ignoring read callbacks for mapping. Mapping should be the interface to get the fastest possible performance. Of course, that would break views on simple types with read callback. One way to deal with it is to simply not allow creating a view on a field with a mappable type and a read callback. Good point; I agree on that :+1:. However, given that any `RField<T>` instance that has an on-disk field ID set (such as the one internally kept by `RNTupleView`) can be connected to a page source, additional bookkeeping is required somewhere else. (**EDIT:** see the pull request description - everything discussed there)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11731#issuecomment-1334547546
Performance,perform,performance,"> I think we need to think about mapping and the view interface, which uses `RField<T>::Map()` where available. I'd be in favor of ignoring read callbacks for mapping. Mapping should be the interface to get the fastest possible performance. Of course, that would break views on simple types with read callback. One way to deal with it is to simply not allow creating a view on a field with a mappable type and a read callback. Good point; I agree on that :+1:. However, given that any `RField<T>` instance that has an on-disk field ID set (such as the one internally kept by `RNTupleView`) can be connected to a page source, additional bookkeeping is required somewhere else. (**EDIT:** see the pull request description - everything discussed there)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11731#issuecomment-1334547546
Usability,simpl,simple,"> I think we need to think about mapping and the view interface, which uses `RField<T>::Map()` where available. I'd be in favor of ignoring read callbacks for mapping. Mapping should be the interface to get the fastest possible performance. Of course, that would break views on simple types with read callback. One way to deal with it is to simply not allow creating a view on a field with a mappable type and a read callback. Good point; I agree on that :+1:. However, given that any `RField<T>` instance that has an on-disk field ID set (such as the one internally kept by `RNTupleView`) can be connected to a page source, additional bookkeeping is required somewhere else. (**EDIT:** see the pull request description - everything discussed there)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11731#issuecomment-1334547546
Usability,simpl,simply,Can't you simply use the `-Dbuiltin_xrootd=ON` option?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11750#issuecomment-1339375009
Security,expose,expose,"I think we gain by having in 6.28 to expose this to the users. This will fix issues happening with fits using the `G` option (external gradient) and in addition, will give us more feedback on using an external Hessian computation. This will be certainly useful. ; In addition, the PR, improves significantly the Minuit2/Fumili algorithm, especially for the case of binned likelihood fit. I think also this is worth having in 6.28.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11755#issuecomment-1357810874
Usability,feedback,feedback,"I think we gain by having in 6.28 to expose this to the users. This will fix issues happening with fits using the `G` option (external gradient) and in addition, will give us more feedback on using an external Hessian computation. This will be certainly useful. ; In addition, the PR, improves significantly the Minuit2/Fumili algorithm, especially for the case of binned likelihood fit. I think also this is worth having in 6.28.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11755#issuecomment-1357810874
Usability,simpl,simpler,"> Thanks for noticing, @bellenot! I think that the suggestion should also fix it (and is simpler) . You're right, thanks!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11782#issuecomment-1327938951
Usability,simpl,simpler,"> > Thanks for noticing, @bellenot! I think that the suggestion should also fix it (and is simpler) slightly_smiling_face.; > ; > You're right, thanks!. Can we squash the changes in a single commit on merge? Many thanks!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11782#issuecomment-1327939751
Usability,simpl,simpler,"> > > Thanks for noticing, @bellenot! I think that the suggestion should also fix it (and is simpler) slightly_smiling_face.; > > ; > > ; > > You're right, thanks!; > ; > Can we squash the changes in a single commit on merge? Many thanks!. Indeed!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11782#issuecomment-1327943698
Usability,simpl,simple,"> Another question is if gGeometryLocked should be a member of the TGeoManager and the; > TGeoElement checks via the gGeoManager->SetDefaultUnits(...), but this sure is a change of; > behavior and also not so simple to implement rigorously. It would however bind units to an instance of the TGeoManager. I'm not sure we want to support the complications coming from handling 2 geometries in memory with different systems of units. If we bump into a real use case that cannot live without this, we may change this later.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11789#issuecomment-1329220374
Testability,test,test,"Hi @guitargeek, I've addressed your changes and rebased to master. I've also changed `LogTimings` to `TimingAnalysis` to it is clear that it is different to the existing profiling and allows for a bit more of an in-depth analysis. I did not add the test that you requested yet since I noticed it required some more changes to the `RooFit::MultiProcessing` then simply implementing the test. I am happy to look into this later though, but I think out of the scope of this MR. But for now we have the unit tests of the HeatmapAnalyzer and the ProcessTimer themselves.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11791#issuecomment-1354447607
Usability,clear,clear,"Hi @guitargeek, I've addressed your changes and rebased to master. I've also changed `LogTimings` to `TimingAnalysis` to it is clear that it is different to the existing profiling and allows for a bit more of an in-depth analysis. I did not add the test that you requested yet since I noticed it required some more changes to the `RooFit::MultiProcessing` then simply implementing the test. I am happy to look into this later though, but I think out of the scope of this MR. But for now we have the unit tests of the HeatmapAnalyzer and the ProcessTimer themselves.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11791#issuecomment-1354447607
Availability,robust,robust,"; + find_dependency(Vdt); +endif(); ; #----------------------------------------------------------------------------; # Now set them to ROOT_LIBRARIES; ```. Though on this latter part I wasn't sure how you prefer to pass configuration options from the build to the generated `ROOTConfig.cmake` file. :thinking:. 2. Just use `VDT_INCLUDE_DIRS` and `VDT_LIBRARIES` correctly. Like:. ```diff; diff --git a/math/vecops/CMakeLists.txt b/math/vecops/CMakeLists.txt; index 09fde3eb40..dd998c1a9b 100644; --- a/math/vecops/CMakeLists.txt; +++ b/math/vecops/CMakeLists.txt; @@ -8,10 +8,6 @@; # CMakeLists.txt file for building ROOT math/vecops package; ############################################################################; ; -if(builtin_vdt); - link_directories(${CMAKE_LIBRARY_OUTPUT_DIRECTORY}); -endif(); -; ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps; HEADERS; ROOT/RVec.hxx; @@ -23,13 +19,13 @@ ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps; Core; ); ; -if(builtin_vdt OR vdt); - target_include_directories(ROOTVecOps PRIVATE ${VDT_INCLUDE_DIRS} INTERFACE $<BUILD_INTERFACE:${VDT_INCLUDE_DIRS}>); -endif(); -; if(builtin_vdt); - target_link_libraries(ROOTVecOps PRIVATE ${VDT_LIBRARIES}); + target_include_directories(ROOTVecOps PUBLIC $<BUILD_INTERFACE:${VDT_INCLUDE_DIRS}>; + $<INSTALL_INTERFACE:${CMAKE_INSTALL_INCLUDEDIR}>); + target_link_libraries(ROOTVecOps PUBLIC $<BUILD_INTERFACE:${VDT_LIBRARIES}>; + $<INSTALL_INTERFACE:${CMAKE_INSTALL_LIBDIR}/${CMAKE_STATIC_LIBRARY_PREFIX}vdt${CMAKE_SHARED_LIBRARY_SUFFIX}>); elseif(vdt); + target_include_directories(ROOTVecOps PUBLIC ${VDT_INCLUDE_DIRS}); target_link_libraries(ROOTVecOps PUBLIC ${VDT_LIBRARIES}); endif(); ```. I personally favour option 1, as it should be a bit more robust in the long run in my mind. But option 2 could work as well. Though it makes relocatabiity harder. (If VDT is in a different place after relocation, the `ROOTConfig-targets.cmake` file now needs to be manually updated as part of the relocation. Which is not great.)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797#issuecomment-1339057027
Deployability,configurat,configuration,"utorial time... You basically have 2 ways in my mind to solve this nicely.; 1. Switch to using the `VDT::VDT` library during the build.; - For this you need to introduce a global imported library for `builtin_vdt`. Something like:. ```diff; diff --git a/cmake/modules/SearchInstalledSoftware.cmake b/cmake/modules/SearchInstalledSoftware.cmake; index 7947fddfc0..7ad5fd91af 100644; --- a/cmake/modules/SearchInstalledSoftware.cmake; +++ b/cmake/modules/SearchInstalledSoftware.cmake; @@ -1678,6 +1678,12 @@ if(vdt OR builtin_vdt); DESTINATION ${CMAKE_INSTALL_INCLUDEDIR} COMPONENT extra-headers); set(vdt ON CACHE BOOL ""Enabled because builtin_vdt enabled (${vdt_description})"" FORCE); set_property(GLOBAL APPEND PROPERTY ROOT_BUILTIN_TARGETS VDT); + add_library(VDT::VDT UNKNOWN IMPORTED GLOBAL); + set_target_properties(VDT::VDT; + PROPERTIES; + IMPORTED_LOCATION ""${VDT_LIBRARIES}""; + INTERFACE_INCLUDE_DIRECTORIES ""${VDT_INCLUDE_DIRS}""; + ); endif(); endif(); ```. - At this point you could simplify the build configuration to:. ```diff; diff --git a/math/vecops/CMakeLists.txt b/math/vecops/CMakeLists.txt; index 09fde3eb40..e15b5ea186 100644; --- a/math/vecops/CMakeLists.txt; +++ b/math/vecops/CMakeLists.txt; @@ -8,10 +8,6 @@; # CMakeLists.txt file for building ROOT math/vecops package; ############################################################################; ; -if(builtin_vdt); - link_directories(${CMAKE_LIBRARY_OUTPUT_DIRECTORY}); -endif(); -; ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps; HEADERS; ROOT/RVec.hxx; @@ -24,13 +20,7 @@ ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps; ); ; if(builtin_vdt OR vdt); - target_include_directories(ROOTVecOps PRIVATE ${VDT_INCLUDE_DIRS} INTERFACE $<BUILD_INTERFACE:${VDT_INCLUDE_DIRS}>); -endif(); -; -if(builtin_vdt); - target_link_libraries(ROOTVecOps PRIVATE ${VDT_LIBRARIES}); -elseif(vdt); - target_link_libraries(ROOTVecOps PUBLIC ${VDT_LIBRARIES}); + target_link_libraries(ROOTVecOps PUBLIC VDT::VDT); endif(); ; if(MSVC); ```. - Finally, you w",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797#issuecomment-1339057027
Modifiability,config,configuration,"utorial time... You basically have 2 ways in my mind to solve this nicely.; 1. Switch to using the `VDT::VDT` library during the build.; - For this you need to introduce a global imported library for `builtin_vdt`. Something like:. ```diff; diff --git a/cmake/modules/SearchInstalledSoftware.cmake b/cmake/modules/SearchInstalledSoftware.cmake; index 7947fddfc0..7ad5fd91af 100644; --- a/cmake/modules/SearchInstalledSoftware.cmake; +++ b/cmake/modules/SearchInstalledSoftware.cmake; @@ -1678,6 +1678,12 @@ if(vdt OR builtin_vdt); DESTINATION ${CMAKE_INSTALL_INCLUDEDIR} COMPONENT extra-headers); set(vdt ON CACHE BOOL ""Enabled because builtin_vdt enabled (${vdt_description})"" FORCE); set_property(GLOBAL APPEND PROPERTY ROOT_BUILTIN_TARGETS VDT); + add_library(VDT::VDT UNKNOWN IMPORTED GLOBAL); + set_target_properties(VDT::VDT; + PROPERTIES; + IMPORTED_LOCATION ""${VDT_LIBRARIES}""; + INTERFACE_INCLUDE_DIRECTORIES ""${VDT_INCLUDE_DIRS}""; + ); endif(); endif(); ```. - At this point you could simplify the build configuration to:. ```diff; diff --git a/math/vecops/CMakeLists.txt b/math/vecops/CMakeLists.txt; index 09fde3eb40..e15b5ea186 100644; --- a/math/vecops/CMakeLists.txt; +++ b/math/vecops/CMakeLists.txt; @@ -8,10 +8,6 @@; # CMakeLists.txt file for building ROOT math/vecops package; ############################################################################; ; -if(builtin_vdt); - link_directories(${CMAKE_LIBRARY_OUTPUT_DIRECTORY}); -endif(); -; ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps; HEADERS; ROOT/RVec.hxx; @@ -24,13 +20,7 @@ ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps; ); ; if(builtin_vdt OR vdt); - target_include_directories(ROOTVecOps PRIVATE ${VDT_INCLUDE_DIRS} INTERFACE $<BUILD_INTERFACE:${VDT_INCLUDE_DIRS}>); -endif(); -; -if(builtin_vdt); - target_link_libraries(ROOTVecOps PRIVATE ${VDT_LIBRARIES}); -elseif(vdt); - target_link_libraries(ROOTVecOps PUBLIC ${VDT_LIBRARIES}); + target_link_libraries(ROOTVecOps PUBLIC VDT::VDT); endif(); ; if(MSVC); ```. - Finally, you w",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797#issuecomment-1339057027
Usability,simpl,simplify,"utorial time... You basically have 2 ways in my mind to solve this nicely.; 1. Switch to using the `VDT::VDT` library during the build.; - For this you need to introduce a global imported library for `builtin_vdt`. Something like:. ```diff; diff --git a/cmake/modules/SearchInstalledSoftware.cmake b/cmake/modules/SearchInstalledSoftware.cmake; index 7947fddfc0..7ad5fd91af 100644; --- a/cmake/modules/SearchInstalledSoftware.cmake; +++ b/cmake/modules/SearchInstalledSoftware.cmake; @@ -1678,6 +1678,12 @@ if(vdt OR builtin_vdt); DESTINATION ${CMAKE_INSTALL_INCLUDEDIR} COMPONENT extra-headers); set(vdt ON CACHE BOOL ""Enabled because builtin_vdt enabled (${vdt_description})"" FORCE); set_property(GLOBAL APPEND PROPERTY ROOT_BUILTIN_TARGETS VDT); + add_library(VDT::VDT UNKNOWN IMPORTED GLOBAL); + set_target_properties(VDT::VDT; + PROPERTIES; + IMPORTED_LOCATION ""${VDT_LIBRARIES}""; + INTERFACE_INCLUDE_DIRECTORIES ""${VDT_INCLUDE_DIRS}""; + ); endif(); endif(); ```. - At this point you could simplify the build configuration to:. ```diff; diff --git a/math/vecops/CMakeLists.txt b/math/vecops/CMakeLists.txt; index 09fde3eb40..e15b5ea186 100644; --- a/math/vecops/CMakeLists.txt; +++ b/math/vecops/CMakeLists.txt; @@ -8,10 +8,6 @@; # CMakeLists.txt file for building ROOT math/vecops package; ############################################################################; ; -if(builtin_vdt); - link_directories(${CMAKE_LIBRARY_OUTPUT_DIRECTORY}); -endif(); -; ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps; HEADERS; ROOT/RVec.hxx; @@ -24,13 +20,7 @@ ROOT_STANDARD_LIBRARY_PACKAGE(ROOTVecOps; ); ; if(builtin_vdt OR vdt); - target_include_directories(ROOTVecOps PRIVATE ${VDT_INCLUDE_DIRS} INTERFACE $<BUILD_INTERFACE:${VDT_INCLUDE_DIRS}>); -endif(); -; -if(builtin_vdt); - target_link_libraries(ROOTVecOps PRIVATE ${VDT_LIBRARIES}); -elseif(vdt); - target_link_libraries(ROOTVecOps PUBLIC ${VDT_LIBRARIES}); + target_link_libraries(ROOTVecOps PUBLIC VDT::VDT); endif(); ; if(MSVC); ```. - Finally, you w",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797#issuecomment-1339057027
Availability,error,errors,"I'm totally +1 for using target-based CMake, and I believe I have fixed the issue of ROOT picking up its own headers here:; https://github.com/root-project/root/pull/8709 (needs rebasing). This fixed it at least for many builtins. There still might be more builtins that have the same problem, but let's go one step at a time. I solved the VDT-related part a bit differently. If I rebased, the diff would approximately read (done manually, sorry for possible indentation errors):; ```diff; DESTINATION ${CMAKE_INSTALL_INCLUDEDIR} COMPONENT extra-headers); set(vdt ON CACHE BOOL ""Enabled because builtin_vdt enabled (${vdt_description})"" FORCE); set_property(GLOBAL APPEND PROPERTY ROOT_BUILTIN_TARGETS VDT); - add_library(VDT::VDT STATIC IMPORTED GLOBAL); - set_target_properties(VDT::VDT; - PROPERTIES; - IMPORTED_LOCATION ""${VDT_LIBRARIES}""; - INTERFACE_INCLUDE_DIRECTORIES ""${VDT_INCLUDE_DIRS}""; + add_library(VDT IMPORTED SHARED); + add_dependencies(VDT BUILTIN_VDT); + set_target_properties(VDT PROPERTIES IMPORTED_LOCATION ""${VDT_LIBRARIES}""); + target_include_directories(VDT INTERFACE $<BUILD_INTERFACE:${VDT_INCLUDE_DIR}> $<INSTALL_INTERFACE:include/>); ); endif(); endif(); ```; Whether the target is declared global, static or shared, I'm not sure if it makes a big difference. I'm happy to call it `VDT::VDT`, though. I think the important part was to switch the include directories via generator expressions, and to use **SYSTEM** includes instead of includes in `FindVDT`. #11844 is missing the usage of the `VDT::VDT` target in RooFit and in tmva, but that would come into effect after a rebase of #8709. I guess therefore that we could proceed with merging #11844 if it's green, and then I rebase #8709, so I have to do the rebase work only once. Does that sound reasonable for @amadio, @krasznaa, @bellenot ?. ### Edit ; And to be clear, for `SearchInstalledSoftware` I would leave everything as proposed in Attila's commit but the change to `target_include_directories` with the two ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797#issuecomment-1339660363
Energy Efficiency,green,green,"g target-based CMake, and I believe I have fixed the issue of ROOT picking up its own headers here:; https://github.com/root-project/root/pull/8709 (needs rebasing). This fixed it at least for many builtins. There still might be more builtins that have the same problem, but let's go one step at a time. I solved the VDT-related part a bit differently. If I rebased, the diff would approximately read (done manually, sorry for possible indentation errors):; ```diff; DESTINATION ${CMAKE_INSTALL_INCLUDEDIR} COMPONENT extra-headers); set(vdt ON CACHE BOOL ""Enabled because builtin_vdt enabled (${vdt_description})"" FORCE); set_property(GLOBAL APPEND PROPERTY ROOT_BUILTIN_TARGETS VDT); - add_library(VDT::VDT STATIC IMPORTED GLOBAL); - set_target_properties(VDT::VDT; - PROPERTIES; - IMPORTED_LOCATION ""${VDT_LIBRARIES}""; - INTERFACE_INCLUDE_DIRECTORIES ""${VDT_INCLUDE_DIRS}""; + add_library(VDT IMPORTED SHARED); + add_dependencies(VDT BUILTIN_VDT); + set_target_properties(VDT PROPERTIES IMPORTED_LOCATION ""${VDT_LIBRARIES}""); + target_include_directories(VDT INTERFACE $<BUILD_INTERFACE:${VDT_INCLUDE_DIR}> $<INSTALL_INTERFACE:include/>); ); endif(); endif(); ```; Whether the target is declared global, static or shared, I'm not sure if it makes a big difference. I'm happy to call it `VDT::VDT`, though. I think the important part was to switch the include directories via generator expressions, and to use **SYSTEM** includes instead of includes in `FindVDT`. #11844 is missing the usage of the `VDT::VDT` target in RooFit and in tmva, but that would come into effect after a rebase of #8709. I guess therefore that we could proceed with merging #11844 if it's green, and then I rebase #8709, so I have to do the rebase work only once. Does that sound reasonable for @amadio, @krasznaa, @bellenot ?. ### Edit ; And to be clear, for `SearchInstalledSoftware` I would leave everything as proposed in Attila's commit but the change to `target_include_directories` with the two generator expressions.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797#issuecomment-1339660363
Usability,clear,clear,"g target-based CMake, and I believe I have fixed the issue of ROOT picking up its own headers here:; https://github.com/root-project/root/pull/8709 (needs rebasing). This fixed it at least for many builtins. There still might be more builtins that have the same problem, but let's go one step at a time. I solved the VDT-related part a bit differently. If I rebased, the diff would approximately read (done manually, sorry for possible indentation errors):; ```diff; DESTINATION ${CMAKE_INSTALL_INCLUDEDIR} COMPONENT extra-headers); set(vdt ON CACHE BOOL ""Enabled because builtin_vdt enabled (${vdt_description})"" FORCE); set_property(GLOBAL APPEND PROPERTY ROOT_BUILTIN_TARGETS VDT); - add_library(VDT::VDT STATIC IMPORTED GLOBAL); - set_target_properties(VDT::VDT; - PROPERTIES; - IMPORTED_LOCATION ""${VDT_LIBRARIES}""; - INTERFACE_INCLUDE_DIRECTORIES ""${VDT_INCLUDE_DIRS}""; + add_library(VDT IMPORTED SHARED); + add_dependencies(VDT BUILTIN_VDT); + set_target_properties(VDT PROPERTIES IMPORTED_LOCATION ""${VDT_LIBRARIES}""); + target_include_directories(VDT INTERFACE $<BUILD_INTERFACE:${VDT_INCLUDE_DIR}> $<INSTALL_INTERFACE:include/>); ); endif(); endif(); ```; Whether the target is declared global, static or shared, I'm not sure if it makes a big difference. I'm happy to call it `VDT::VDT`, though. I think the important part was to switch the include directories via generator expressions, and to use **SYSTEM** includes instead of includes in `FindVDT`. #11844 is missing the usage of the `VDT::VDT` target in RooFit and in tmva, but that would come into effect after a rebase of #8709. I guess therefore that we could proceed with merging #11844 if it's green, and then I rebase #8709, so I have to do the rebase work only once. Does that sound reasonable for @amadio, @krasznaa, @bellenot ?. ### Edit ; And to be clear, for `SearchInstalledSoftware` I would leave everything as proposed in Attila's commit but the change to `target_include_directories` with the two generator expressions.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11797#issuecomment-1339660363
Deployability,update,update,"Just a small update,; I did a fresh build of ROOT, current master, with Python 3.11, on Fedora Linux 37. I tried your reproducer 100 times and could never trigger the segfault. Also this simpler reproducer never causes a segfault:; ```python; import ROOT; f = ROOT.TFile(""file1.root"", ""recreate""); f.Close(); f.Close(); ```; So apparently it is not Python 3.11 giving issues, maybe something else in your case, unclear.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11823#issuecomment-1337020095
Usability,simpl,simpler,"Just a small update,; I did a fresh build of ROOT, current master, with Python 3.11, on Fedora Linux 37. I tried your reproducer 100 times and could never trigger the segfault. Also this simpler reproducer never causes a segfault:; ```python; import ROOT; f = ROOT.TFile(""file1.root"", ""recreate""); f.Close(); f.Close(); ```; So apparently it is not Python 3.11 giving issues, maybe something else in your case, unclear.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11823#issuecomment-1337020095
Availability,error,errors,"@vepadulano thanks for the reply! (got caught up with some other work in the meantime). the simpler reproducer does not throw any errors, and removing the extra outfile.Close() no longer does as well. I had rebooted my computer and re-sourced thisroot.sh, so maybe there was something bad being referenced? Not sure. Hopefully issues doesn't arise again. Thanks for the help!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11823#issuecomment-1347823222
Usability,simpl,simpler,"@vepadulano thanks for the reply! (got caught up with some other work in the meantime). the simpler reproducer does not throw any errors, and removing the extra outfile.Close() no longer does as well. I had rebooted my computer and re-sourced thisroot.sh, so maybe there was something bad being referenced? Not sure. Hopefully issues doesn't arise again. Thanks for the help!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11823#issuecomment-1347823222
Availability,error,error,"It always works when you try on your own machine, and then fails when a different version of CMake or a different configuration is used. That's a lesson usually learned the hard way with CMake :-). > Also, how the heck is a generated ROOTConfig.cmake file being used during the configuration of ROOT itself?. That's likely used by `roottest`, as it's actually a separate CMake project which builds against ROOT (and can also be built separately if needed). The error you see happens because `find_dependency(Vdt)` tries to read a header for Vdt (to figure out its version) which should be in the build directory (builtin_vdt==True), but is not there yet, because the build/install of Vdt as a builtin happens only at build time, not configuration time.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11844#issuecomment-1339205080
Deployability,configurat,configuration,"It always works when you try on your own machine, and then fails when a different version of CMake or a different configuration is used. That's a lesson usually learned the hard way with CMake :-). > Also, how the heck is a generated ROOTConfig.cmake file being used during the configuration of ROOT itself?. That's likely used by `roottest`, as it's actually a separate CMake project which builds against ROOT (and can also be built separately if needed). The error you see happens because `find_dependency(Vdt)` tries to read a header for Vdt (to figure out its version) which should be in the build directory (builtin_vdt==True), but is not there yet, because the build/install of Vdt as a builtin happens only at build time, not configuration time.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11844#issuecomment-1339205080
Modifiability,config,configuration,"It always works when you try on your own machine, and then fails when a different version of CMake or a different configuration is used. That's a lesson usually learned the hard way with CMake :-). > Also, how the heck is a generated ROOTConfig.cmake file being used during the configuration of ROOT itself?. That's likely used by `roottest`, as it's actually a separate CMake project which builds against ROOT (and can also be built separately if needed). The error you see happens because `find_dependency(Vdt)` tries to read a header for Vdt (to figure out its version) which should be in the build directory (builtin_vdt==True), but is not there yet, because the build/install of Vdt as a builtin happens only at build time, not configuration time.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11844#issuecomment-1339205080
Usability,learn,learned,"It always works when you try on your own machine, and then fails when a different version of CMake or a different configuration is used. That's a lesson usually learned the hard way with CMake :-). > Also, how the heck is a generated ROOTConfig.cmake file being used during the configuration of ROOT itself?. That's likely used by `roottest`, as it's actually a separate CMake project which builds against ROOT (and can also be built separately if needed). The error you see happens because `find_dependency(Vdt)` tries to read a header for Vdt (to figure out its version) which should be in the build directory (builtin_vdt==True), but is not there yet, because the build/install of Vdt as a builtin happens only at build time, not configuration time.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11844#issuecomment-1339205080
Availability,error,error,"I'm quite baffled every time I come in contact with it, how you guys manage to survive with such a testing infrastructure. :confused: I did have a fork of [roottest](https://github.com/root-project/roottest) from a long time ago. https://github.com/krasznaa/roottest. What I didn't have was it being up to date with the main repository. Plus, did I see correctly in your copy-pasted error message that the CI complained about not finding a branch in my roottest fork with the same name as the branch that I opened this PR from? :confused: What the heck? Is it really expected that one would create a branch in both repositories to make a modification to ROOT?. After some deliberation I updated the PR as you can see. The setup that you guys have with `ROOTConfig.cmake` being generated twice, and one of them possibly being used already during the main configuration is... unique... (Just so that I stay PC...) I've seen similar configurations being used for header-only libraries in the past, but never for anything that needed an actual build before becoming usable. In any case, making `ROOTConfig.cmake` skip `find_dependency(Vdt)` if `VDT::VDT` is already available as a target, was the most robust thing that I could come up with...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11844#issuecomment-1339364132
Deployability,update,updated,"I'm quite baffled every time I come in contact with it, how you guys manage to survive with such a testing infrastructure. :confused: I did have a fork of [roottest](https://github.com/root-project/roottest) from a long time ago. https://github.com/krasznaa/roottest. What I didn't have was it being up to date with the main repository. Plus, did I see correctly in your copy-pasted error message that the CI complained about not finding a branch in my roottest fork with the same name as the branch that I opened this PR from? :confused: What the heck? Is it really expected that one would create a branch in both repositories to make a modification to ROOT?. After some deliberation I updated the PR as you can see. The setup that you guys have with `ROOTConfig.cmake` being generated twice, and one of them possibly being used already during the main configuration is... unique... (Just so that I stay PC...) I've seen similar configurations being used for header-only libraries in the past, but never for anything that needed an actual build before becoming usable. In any case, making `ROOTConfig.cmake` skip `find_dependency(Vdt)` if `VDT::VDT` is already available as a target, was the most robust thing that I could come up with...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11844#issuecomment-1339364132
Integrability,message,message,"I'm quite baffled every time I come in contact with it, how you guys manage to survive with such a testing infrastructure. :confused: I did have a fork of [roottest](https://github.com/root-project/roottest) from a long time ago. https://github.com/krasznaa/roottest. What I didn't have was it being up to date with the main repository. Plus, did I see correctly in your copy-pasted error message that the CI complained about not finding a branch in my roottest fork with the same name as the branch that I opened this PR from? :confused: What the heck? Is it really expected that one would create a branch in both repositories to make a modification to ROOT?. After some deliberation I updated the PR as you can see. The setup that you guys have with `ROOTConfig.cmake` being generated twice, and one of them possibly being used already during the main configuration is... unique... (Just so that I stay PC...) I've seen similar configurations being used for header-only libraries in the past, but never for anything that needed an actual build before becoming usable. In any case, making `ROOTConfig.cmake` skip `find_dependency(Vdt)` if `VDT::VDT` is already available as a target, was the most robust thing that I could come up with...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11844#issuecomment-1339364132
Modifiability,config,configuration,"I'm quite baffled every time I come in contact with it, how you guys manage to survive with such a testing infrastructure. :confused: I did have a fork of [roottest](https://github.com/root-project/roottest) from a long time ago. https://github.com/krasznaa/roottest. What I didn't have was it being up to date with the main repository. Plus, did I see correctly in your copy-pasted error message that the CI complained about not finding a branch in my roottest fork with the same name as the branch that I opened this PR from? :confused: What the heck? Is it really expected that one would create a branch in both repositories to make a modification to ROOT?. After some deliberation I updated the PR as you can see. The setup that you guys have with `ROOTConfig.cmake` being generated twice, and one of them possibly being used already during the main configuration is... unique... (Just so that I stay PC...) I've seen similar configurations being used for header-only libraries in the past, but never for anything that needed an actual build before becoming usable. In any case, making `ROOTConfig.cmake` skip `find_dependency(Vdt)` if `VDT::VDT` is already available as a target, was the most robust thing that I could come up with...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11844#issuecomment-1339364132
Testability,test,testing,"I'm quite baffled every time I come in contact with it, how you guys manage to survive with such a testing infrastructure. :confused: I did have a fork of [roottest](https://github.com/root-project/roottest) from a long time ago. https://github.com/krasznaa/roottest. What I didn't have was it being up to date with the main repository. Plus, did I see correctly in your copy-pasted error message that the CI complained about not finding a branch in my roottest fork with the same name as the branch that I opened this PR from? :confused: What the heck? Is it really expected that one would create a branch in both repositories to make a modification to ROOT?. After some deliberation I updated the PR as you can see. The setup that you guys have with `ROOTConfig.cmake` being generated twice, and one of them possibly being used already during the main configuration is... unique... (Just so that I stay PC...) I've seen similar configurations being used for header-only libraries in the past, but never for anything that needed an actual build before becoming usable. In any case, making `ROOTConfig.cmake` skip `find_dependency(Vdt)` if `VDT::VDT` is already available as a target, was the most robust thing that I could come up with...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11844#issuecomment-1339364132
Usability,usab,usable,"I'm quite baffled every time I come in contact with it, how you guys manage to survive with such a testing infrastructure. :confused: I did have a fork of [roottest](https://github.com/root-project/roottest) from a long time ago. https://github.com/krasznaa/roottest. What I didn't have was it being up to date with the main repository. Plus, did I see correctly in your copy-pasted error message that the CI complained about not finding a branch in my roottest fork with the same name as the branch that I opened this PR from? :confused: What the heck? Is it really expected that one would create a branch in both repositories to make a modification to ROOT?. After some deliberation I updated the PR as you can see. The setup that you guys have with `ROOTConfig.cmake` being generated twice, and one of them possibly being used already during the main configuration is... unique... (Just so that I stay PC...) I've seen similar configurations being used for header-only libraries in the past, but never for anything that needed an actual build before becoming usable. In any case, making `ROOTConfig.cmake` skip `find_dependency(Vdt)` if `VDT::VDT` is already available as a target, was the most robust thing that I could come up with...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11844#issuecomment-1339364132
Usability,simpl,simply,Do you see the same memory usage?. Also notice that the issue with the first reproducer might simply be some issue with my attempt to swap the arrow buffers for the std::vector.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11853#issuecomment-1343199135
Integrability,depend,depend,"An even simpler example which doesn't depend on RDF:. ```python; import ROOT. ret = ROOT.gInterpreter.Declare('#include ""test.h""'). print(""declare ret"", ret). print(""creating helper""); helper = ROOT.Helper[ROOT.std.vector[""double""]](). res = ROOT.call_helper(helper); print(res); ```. test.h:; ```cpp; template <typename T>; class Helper {. public:. Helper() {}. std::size_t operator() () const {; const std::size_t res = 0;; res = T{0, 0}.size();; return res;; }. };. template <typename H>; std::size_t call_helper(const H &helper) {; return helper();; }; ```. Output (again with centos stream 8, root 6.26/10):; ```; declare ret True; creating helper; IncrementalExecutor::executeFunction: symbol '_ZNK6HelperISt6vectorIdSaIdEEEclEv' unresolved while linking symbol '__cf_11'!; You are probably missing the definition of Helper<std::vector<double, std::allocator<double> > >::operator()() const; Maybe you need to load the corresponding shared library?; 18446744073709551615; ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11854#issuecomment-1341802449
Performance,load,load,"An even simpler example which doesn't depend on RDF:. ```python; import ROOT. ret = ROOT.gInterpreter.Declare('#include ""test.h""'). print(""declare ret"", ret). print(""creating helper""); helper = ROOT.Helper[ROOT.std.vector[""double""]](). res = ROOT.call_helper(helper); print(res); ```. test.h:; ```cpp; template <typename T>; class Helper {. public:. Helper() {}. std::size_t operator() () const {; const std::size_t res = 0;; res = T{0, 0}.size();; return res;; }. };. template <typename H>; std::size_t call_helper(const H &helper) {; return helper();; }; ```. Output (again with centos stream 8, root 6.26/10):; ```; declare ret True; creating helper; IncrementalExecutor::executeFunction: symbol '_ZNK6HelperISt6vectorIdSaIdEEEclEv' unresolved while linking symbol '__cf_11'!; You are probably missing the definition of Helper<std::vector<double, std::allocator<double> > >::operator()() const; Maybe you need to load the corresponding shared library?; 18446744073709551615; ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11854#issuecomment-1341802449
Testability,test,test,"An even simpler example which doesn't depend on RDF:. ```python; import ROOT. ret = ROOT.gInterpreter.Declare('#include ""test.h""'). print(""declare ret"", ret). print(""creating helper""); helper = ROOT.Helper[ROOT.std.vector[""double""]](). res = ROOT.call_helper(helper); print(res); ```. test.h:; ```cpp; template <typename T>; class Helper {. public:. Helper() {}. std::size_t operator() () const {; const std::size_t res = 0;; res = T{0, 0}.size();; return res;; }. };. template <typename H>; std::size_t call_helper(const H &helper) {; return helper();; }; ```. Output (again with centos stream 8, root 6.26/10):; ```; declare ret True; creating helper; IncrementalExecutor::executeFunction: symbol '_ZNK6HelperISt6vectorIdSaIdEEEclEv' unresolved while linking symbol '__cf_11'!; You are probably missing the definition of Helper<std::vector<double, std::allocator<double> > >::operator()() const; Maybe you need to load the corresponding shared library?; 18446744073709551615; ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11854#issuecomment-1341802449
Usability,simpl,simpler,"An even simpler example which doesn't depend on RDF:. ```python; import ROOT. ret = ROOT.gInterpreter.Declare('#include ""test.h""'). print(""declare ret"", ret). print(""creating helper""); helper = ROOT.Helper[ROOT.std.vector[""double""]](). res = ROOT.call_helper(helper); print(res); ```. test.h:; ```cpp; template <typename T>; class Helper {. public:. Helper() {}. std::size_t operator() () const {; const std::size_t res = 0;; res = T{0, 0}.size();; return res;; }. };. template <typename H>; std::size_t call_helper(const H &helper) {; return helper();; }; ```. Output (again with centos stream 8, root 6.26/10):; ```; declare ret True; creating helper; IncrementalExecutor::executeFunction: symbol '_ZNK6HelperISt6vectorIdSaIdEEEclEv' unresolved while linking symbol '__cf_11'!; You are probably missing the definition of Helper<std::vector<double, std::allocator<double> > >::operator()() const; Maybe you need to load the corresponding shared library?; 18446744073709551615; ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11854#issuecomment-1341802449
Availability,error,error,"Another very simple example, less serious because at least it fails, but still problematic because it makes debugging very difficult. test.h:; ```cpp; template <typename T>; int some_template_function(const T &x) {; return x.size();; }; ```. test.py:; ```python; import ROOT. ret = ROOT.gInterpreter.Declare('#include ""test.h""'). print(""declare ret"", ret). res0 = ROOT.some_template_function(ROOT.std.vector[""double""]()); print(""res0"", res0). res1 = ROOT.some_template_function(0.0); print(""res1"", res1); ```. output:; ```; declare ret True; res0 0; Traceback (most recent call last):; File ""/home/b/bendavid/pyrootdebug2/test.py"", line 10, in <module>; res1 = ROOT.some_template_function(0.0); TypeError: Template method resolution failed:; int ::some_template_function(const vector<double>& x) =>; TypeError: could not convert argument 1; Failed to instantiate ""some_template_function(double)""; ```; ; Compare to the same in c++ ; ```; #include ""test.h"". const int res = some_template_function(0.0);; ```; ; Then the output of clang++ with nice error message is:; ```; In file included from test.cpp:1:; ./test.h:3:11: error: member reference base type 'const double' is not a structure or union; return x.size();; ~^~~~~; test.cpp:3:17: note: in instantiation of function template specialization 'some_template_function<double>' requested here; const int res = some_template_function(0.0);; ^; 1 error generated.; ```. So in the pyroot case all of the useful compiler errors are suppressed.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11854#issuecomment-1410720055
Integrability,message,message,"Another very simple example, less serious because at least it fails, but still problematic because it makes debugging very difficult. test.h:; ```cpp; template <typename T>; int some_template_function(const T &x) {; return x.size();; }; ```. test.py:; ```python; import ROOT. ret = ROOT.gInterpreter.Declare('#include ""test.h""'). print(""declare ret"", ret). res0 = ROOT.some_template_function(ROOT.std.vector[""double""]()); print(""res0"", res0). res1 = ROOT.some_template_function(0.0); print(""res1"", res1); ```. output:; ```; declare ret True; res0 0; Traceback (most recent call last):; File ""/home/b/bendavid/pyrootdebug2/test.py"", line 10, in <module>; res1 = ROOT.some_template_function(0.0); TypeError: Template method resolution failed:; int ::some_template_function(const vector<double>& x) =>; TypeError: could not convert argument 1; Failed to instantiate ""some_template_function(double)""; ```; ; Compare to the same in c++ ; ```; #include ""test.h"". const int res = some_template_function(0.0);; ```; ; Then the output of clang++ with nice error message is:; ```; In file included from test.cpp:1:; ./test.h:3:11: error: member reference base type 'const double' is not a structure or union; return x.size();; ~^~~~~; test.cpp:3:17: note: in instantiation of function template specialization 'some_template_function<double>' requested here; const int res = some_template_function(0.0);; ^; 1 error generated.; ```. So in the pyroot case all of the useful compiler errors are suppressed.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11854#issuecomment-1410720055
Testability,test,test,"Another very simple example, less serious because at least it fails, but still problematic because it makes debugging very difficult. test.h:; ```cpp; template <typename T>; int some_template_function(const T &x) {; return x.size();; }; ```. test.py:; ```python; import ROOT. ret = ROOT.gInterpreter.Declare('#include ""test.h""'). print(""declare ret"", ret). res0 = ROOT.some_template_function(ROOT.std.vector[""double""]()); print(""res0"", res0). res1 = ROOT.some_template_function(0.0); print(""res1"", res1); ```. output:; ```; declare ret True; res0 0; Traceback (most recent call last):; File ""/home/b/bendavid/pyrootdebug2/test.py"", line 10, in <module>; res1 = ROOT.some_template_function(0.0); TypeError: Template method resolution failed:; int ::some_template_function(const vector<double>& x) =>; TypeError: could not convert argument 1; Failed to instantiate ""some_template_function(double)""; ```; ; Compare to the same in c++ ; ```; #include ""test.h"". const int res = some_template_function(0.0);; ```; ; Then the output of clang++ with nice error message is:; ```; In file included from test.cpp:1:; ./test.h:3:11: error: member reference base type 'const double' is not a structure or union; return x.size();; ~^~~~~; test.cpp:3:17: note: in instantiation of function template specialization 'some_template_function<double>' requested here; const int res = some_template_function(0.0);; ^; 1 error generated.; ```. So in the pyroot case all of the useful compiler errors are suppressed.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11854#issuecomment-1410720055
Usability,simpl,simple,"Another very simple example, less serious because at least it fails, but still problematic because it makes debugging very difficult. test.h:; ```cpp; template <typename T>; int some_template_function(const T &x) {; return x.size();; }; ```. test.py:; ```python; import ROOT. ret = ROOT.gInterpreter.Declare('#include ""test.h""'). print(""declare ret"", ret). res0 = ROOT.some_template_function(ROOT.std.vector[""double""]()); print(""res0"", res0). res1 = ROOT.some_template_function(0.0); print(""res1"", res1); ```. output:; ```; declare ret True; res0 0; Traceback (most recent call last):; File ""/home/b/bendavid/pyrootdebug2/test.py"", line 10, in <module>; res1 = ROOT.some_template_function(0.0); TypeError: Template method resolution failed:; int ::some_template_function(const vector<double>& x) =>; TypeError: could not convert argument 1; Failed to instantiate ""some_template_function(double)""; ```; ; Compare to the same in c++ ; ```; #include ""test.h"". const int res = some_template_function(0.0);; ```; ; Then the output of clang++ with nice error message is:; ```; In file included from test.cpp:1:; ./test.h:3:11: error: member reference base type 'const double' is not a structure or union; return x.size();; ~^~~~~; test.cpp:3:17: note: in instantiation of function template specialization 'some_template_function<double>' requested here; const int res = some_template_function(0.0);; ^; 1 error generated.; ```. So in the pyroot case all of the useful compiler errors are suppressed.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11854#issuecomment-1410720055
Availability,failure,failure,"Excellent work, @bendavid and apologies for not doing this myself, in time. Would it be an option to simply repeat the lookup without the RAII in case of failure to find an overload? It's only in the error case, where performance isn't as crucial anyway, and simplifies the interplay between PyROOT/cppyy and cling.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11854#issuecomment-1455544084
Performance,perform,performance,"Excellent work, @bendavid and apologies for not doing this myself, in time. Would it be an option to simply repeat the lookup without the RAII in case of failure to find an overload? It's only in the error case, where performance isn't as crucial anyway, and simplifies the interplay between PyROOT/cppyy and cling.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11854#issuecomment-1455544084
Usability,simpl,simply,"Excellent work, @bendavid and apologies for not doing this myself, in time. Would it be an option to simply repeat the lookup without the RAII in case of failure to find an overload? It's only in the error case, where performance isn't as crucial anyway, and simplifies the interplay between PyROOT/cppyy and cling.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11854#issuecomment-1455544084
Availability,error,error,"Build failed on ROOT-ubuntu2204/cxx20.; Running on root-ubuntu-2204-1.cern.ch:/home/sftnight/build/workspace/root-pullrequests-build; [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/162985/console).; ### Errors:; - [2022-12-21T14:38:19.707Z] /home/sftnight/build/workspace/root-pullrequests-build/build/etc/cling/std20.modulemap:438:12: error: header 'bits/chrono.h' not found ; - [2022-12-21T14:38:19.707Z] /home/sftnight/build/workspace/root-pullrequests-build/build/etc/cling/std20.modulemap:438:12: error: header 'bits/chrono.h' not found ; - [2022-12-21T14:38:19.707Z] /home/sftnight/build/workspace/root-pullrequests-build/build/etc/cling/Interpreter/DynamicExprInfo.h:40:7: error: use of undeclared identifier 'std' ; - [2022-12-21T14:38:19.707Z] /home/sftnight/build/workspace/root-pullrequests-build/build/etc/cling/std20.modulemap:438:12: error: header 'bits/chrono.h' not found ; - [2022-12-21T14:38:19.707Z] /home/sftnight/build/workspace/root-pullrequests-build/build/etc/cling/Interpreter/DynamicLookupLifetimeHandler.h:56:7: error: use of undeclared identifier 'std' ; - [2022-12-21T14:38:19.708Z] /home/sftnight/build/workspace/root-pullrequests-build/build/etc/cling/std20.modulemap:438:12: error: header 'bits/chrono.h' not found ; - [2022-12-21T14:38:19.708Z] /home/sftnight/build/workspace/root-pullrequests-build/build/etc/cling/Interpreter/Value.h:93:41: error: use of undeclared identifier 'std' ; - [2022-12-21T14:38:19.708Z] /home/sftnight/build/workspace/root-pullrequests-build/build/etc/cling/Interpreter/Value.h:93:55: error: expected ',' or '&gt;' in template-parameter-list ; - [2022-12-21T14:38:19.708Z] /home/sftnight/build/workspace/root-pullrequests-build/build/etc/cling/Interpreter/Value.h:93:75: error: no type named 'value' in the global namespace; did you mean 'Value'? ; - [2022-12-21T14:38:19.708Z] /home/sftnight/build/workspace/root-pullrequests-build/build/etc/cling/Interpreter/Value.h:93:82: error: expected ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11874#issuecomment-1361406497
Usability,simpl,simple,"no.h' not found ; - [2022-12-21T14:38:19.707Z] /home/sftnight/build/workspace/root-pullrequests-build/build/etc/cling/Interpreter/DynamicLookupLifetimeHandler.h:56:7: error: use of undeclared identifier 'std' ; - [2022-12-21T14:38:19.708Z] /home/sftnight/build/workspace/root-pullrequests-build/build/etc/cling/std20.modulemap:438:12: error: header 'bits/chrono.h' not found ; - [2022-12-21T14:38:19.708Z] /home/sftnight/build/workspace/root-pullrequests-build/build/etc/cling/Interpreter/Value.h:93:41: error: use of undeclared identifier 'std' ; - [2022-12-21T14:38:19.708Z] /home/sftnight/build/workspace/root-pullrequests-build/build/etc/cling/Interpreter/Value.h:93:55: error: expected ',' or '&gt;' in template-parameter-list ; - [2022-12-21T14:38:19.708Z] /home/sftnight/build/workspace/root-pullrequests-build/build/etc/cling/Interpreter/Value.h:93:75: error: no type named 'value' in the global namespace; did you mean 'Value'? ; - [2022-12-21T14:38:19.708Z] /home/sftnight/build/workspace/root-pullrequests-build/build/etc/cling/Interpreter/Value.h:93:82: error: expected member name or ';' after declaration specifiers . And 30 more. ### Warnings:; - [2022-12-21T14:26:00.154Z] /home/sftnight/build/workspace/root-pullrequests-build/root/net/rpdutils/src/rpdutils.cxx:422:54: warning: using value of simple assignment with volatile-qualified left operand is deprecated [-Wvolatile] ; - [2022-12-21T14:26:23.830Z] /home/sftnight/build/workspace/root-pullrequests-build/root/core/base/src/TSystem.cxx:4040:42: warning: bitwise operation between different enumeration types TSystem::EAclicProperties and TObject::&lt;unnamed enum&gt; is deprecated [-Wdeprecated-enum-enum-conversion] ; - [2022-12-21T14:26:23.830Z] /home/sftnight/build/workspace/root-pullrequests-build/root/core/base/src/TSystem.cxx:4042:43: warning: bitwise operation between different enumeration types TSystem::EAclicProperties and TObject::&lt;unnamed enum&gt; is deprecated [-Wdeprecated-enum-enum-conversion]",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11874#issuecomment-1361406497
Availability,error,error,"Build failed on ROOT-ubuntu2204/cxx20.; Running on root-ubuntu-2204-1.cern.ch:/home/sftnight/build/workspace/root-pullrequests-build; [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/163232/console).; ### Errors:; - [2022-12-28T08:32:45.548Z] /home/sftnight/build/workspace/root-pullrequests-build/build/etc/cling/std20.modulemap:438:12: error: header 'bits/chrono.h' not found ; - [2022-12-28T08:32:45.548Z] /home/sftnight/build/workspace/root-pullrequests-build/build/etc/cling/std20.modulemap:438:12: error: header 'bits/chrono.h' not found ; - [2022-12-28T08:32:45.548Z] /home/sftnight/build/workspace/root-pullrequests-build/build/etc/cling/Interpreter/DynamicExprInfo.h:40:7: error: use of undeclared identifier 'std' ; - [2022-12-28T08:32:45.548Z] /home/sftnight/build/workspace/root-pullrequests-build/build/etc/cling/std20.modulemap:438:12: error: header 'bits/chrono.h' not found ; - [2022-12-28T08:32:45.548Z] /home/sftnight/build/workspace/root-pullrequests-build/build/etc/cling/Interpreter/DynamicLookupLifetimeHandler.h:56:7: error: use of undeclared identifier 'std' ; - [2022-12-28T08:32:45.548Z] /home/sftnight/build/workspace/root-pullrequests-build/build/etc/cling/std20.modulemap:438:12: error: header 'bits/chrono.h' not found ; - [2022-12-28T08:32:45.548Z] /home/sftnight/build/workspace/root-pullrequests-build/build/etc/cling/Interpreter/Value.h:93:41: error: use of undeclared identifier 'std' ; - [2022-12-28T08:32:45.548Z] /home/sftnight/build/workspace/root-pullrequests-build/build/etc/cling/Interpreter/Value.h:93:55: error: expected ',' or '&gt;' in template-parameter-list ; - [2022-12-28T08:32:45.548Z] /home/sftnight/build/workspace/root-pullrequests-build/build/etc/cling/Interpreter/Value.h:93:75: error: no type named 'value' in the global namespace; did you mean 'Value'? ; - [2022-12-28T08:32:45.548Z] /home/sftnight/build/workspace/root-pullrequests-build/build/etc/cling/Interpreter/Value.h:93:82: error: expected ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11874#issuecomment-1366467620
Usability,simpl,simple,"no.h' not found ; - [2022-12-28T08:32:45.548Z] /home/sftnight/build/workspace/root-pullrequests-build/build/etc/cling/Interpreter/DynamicLookupLifetimeHandler.h:56:7: error: use of undeclared identifier 'std' ; - [2022-12-28T08:32:45.548Z] /home/sftnight/build/workspace/root-pullrequests-build/build/etc/cling/std20.modulemap:438:12: error: header 'bits/chrono.h' not found ; - [2022-12-28T08:32:45.548Z] /home/sftnight/build/workspace/root-pullrequests-build/build/etc/cling/Interpreter/Value.h:93:41: error: use of undeclared identifier 'std' ; - [2022-12-28T08:32:45.548Z] /home/sftnight/build/workspace/root-pullrequests-build/build/etc/cling/Interpreter/Value.h:93:55: error: expected ',' or '&gt;' in template-parameter-list ; - [2022-12-28T08:32:45.548Z] /home/sftnight/build/workspace/root-pullrequests-build/build/etc/cling/Interpreter/Value.h:93:75: error: no type named 'value' in the global namespace; did you mean 'Value'? ; - [2022-12-28T08:32:45.548Z] /home/sftnight/build/workspace/root-pullrequests-build/build/etc/cling/Interpreter/Value.h:93:82: error: expected member name or ';' after declaration specifiers . And 30 more. ### Warnings:; - [2022-12-28T08:32:20.829Z] /home/sftnight/build/workspace/root-pullrequests-build/root/net/rpdutils/src/rpdutils.cxx:422:54: warning: using value of simple assignment with volatile-qualified left operand is deprecated [-Wvolatile] ; - [2022-12-28T08:32:21.099Z] /home/sftnight/build/workspace/root-pullrequests-build/root/core/base/src/TSystem.cxx:4040:42: warning: bitwise operation between different enumeration types TSystem::EAclicProperties and TObject::&lt;unnamed enum&gt; is deprecated [-Wdeprecated-enum-enum-conversion] ; - [2022-12-28T08:32:21.099Z] /home/sftnight/build/workspace/root-pullrequests-build/root/core/base/src/TSystem.cxx:4042:43: warning: bitwise operation between different enumeration types TSystem::EAclicProperties and TObject::&lt;unnamed enum&gt; is deprecated [-Wdeprecated-enum-enum-conversion]",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11874#issuecomment-1366467620
Availability,error,error,Build failed on ROOT-ubuntu2204/cxx20.; Running on root-ubuntu-2204-1.cern.ch:/home/sftnight/build/workspace/root-pullrequests-build; [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/163311/console).; ### Errors:; - [2023-01-02T13:46:22.128Z] /home/sftnight/build/workspace/root-pullrequests-build/root/tree/ntuple/v7/src/RPageStorageDaos.cxx:307:80: error: no matching function for call to ROOT::Experimental::Detail::RDaosContainer::ROidDkeyPair::ROidDkeyPair(&lt;brace-enclosed initializer list&gt;) ; - [2023-01-02T13:46:22.128Z] /home/sftnight/build/workspace/root-pullrequests-build/root/tree/ntuple/v7/src/RPageStorageDaos.cxx:701:80: error: no matching function for call to ROOT::Experimental::Detail::RDaosContainer::ROidDkeyPair::ROidDkeyPair(&lt;brace-enclosed initializer list&gt;) . ### Warnings:; - [2023-01-02T13:41:26.055Z] /home/sftnight/build/workspace/root-pullrequests-build/root/net/rpdutils/src/rpdutils.cxx:422:54: warning: using value of simple assignment with volatile-qualified left operand is deprecated [-Wvolatile] ; - [2023-01-02T13:41:26.575Z] /home/sftnight/build/workspace/root-pullrequests-build/root/core/base/src/TSystem.cxx:4040:42: warning: bitwise operation between different enumeration types TSystem::EAclicProperties and TObject::&lt;unnamed enum&gt; is deprecated [-Wdeprecated-enum-enum-conversion] ; - [2023-01-02T13:41:26.575Z] /home/sftnight/build/workspace/root-pullrequests-build/root/core/base/src/TSystem.cxx:4042:43: warning: bitwise operation between different enumeration types TSystem::EAclicProperties and TObject::&lt;unnamed enum&gt; is deprecated [-Wdeprecated-enum-enum-conversion] ; - [2023-01-02T13:42:45.530Z] /home/sftnight/build/workspace/root-pullrequests-build/root/io/io/src/TEmulatedMapProxy.cxx:144:25: warning: bitwise operation between different enumeration types EProperty and TGenCollectionProxy::&lt;unnamed enum&gt; is deprecated [-Wdeprecated-enum-enum-conversi,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11874#issuecomment-1368960482
Usability,simpl,simple, on root-ubuntu-2204-1.cern.ch:/home/sftnight/build/workspace/root-pullrequests-build; [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/163311/console).; ### Errors:; - [2023-01-02T13:46:22.128Z] /home/sftnight/build/workspace/root-pullrequests-build/root/tree/ntuple/v7/src/RPageStorageDaos.cxx:307:80: error: no matching function for call to ROOT::Experimental::Detail::RDaosContainer::ROidDkeyPair::ROidDkeyPair(&lt;brace-enclosed initializer list&gt;) ; - [2023-01-02T13:46:22.128Z] /home/sftnight/build/workspace/root-pullrequests-build/root/tree/ntuple/v7/src/RPageStorageDaos.cxx:701:80: error: no matching function for call to ROOT::Experimental::Detail::RDaosContainer::ROidDkeyPair::ROidDkeyPair(&lt;brace-enclosed initializer list&gt;) . ### Warnings:; - [2023-01-02T13:41:26.055Z] /home/sftnight/build/workspace/root-pullrequests-build/root/net/rpdutils/src/rpdutils.cxx:422:54: warning: using value of simple assignment with volatile-qualified left operand is deprecated [-Wvolatile] ; - [2023-01-02T13:41:26.575Z] /home/sftnight/build/workspace/root-pullrequests-build/root/core/base/src/TSystem.cxx:4040:42: warning: bitwise operation between different enumeration types TSystem::EAclicProperties and TObject::&lt;unnamed enum&gt; is deprecated [-Wdeprecated-enum-enum-conversion] ; - [2023-01-02T13:41:26.575Z] /home/sftnight/build/workspace/root-pullrequests-build/root/core/base/src/TSystem.cxx:4042:43: warning: bitwise operation between different enumeration types TSystem::EAclicProperties and TObject::&lt;unnamed enum&gt; is deprecated [-Wdeprecated-enum-enum-conversion] ; - [2023-01-02T13:42:45.530Z] /home/sftnight/build/workspace/root-pullrequests-build/root/io/io/src/TEmulatedMapProxy.cxx:144:25: warning: bitwise operation between different enumeration types EProperty and TGenCollectionProxy::&lt;unnamed enum&gt; is deprecated [-Wdeprecated-enum-enum-conversion] ; - [2023-01-02T13:42:45.530Z] /home/sftnig,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11874#issuecomment-1368960482
Availability,error,error,Build failed on ROOT-ubuntu2204/cxx20.; Running on root-ubuntu-2204-1.cern.ch:/home/sftnight/build/workspace/root-pullrequests-build; [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/163670/console).; ### Errors:; - [2023-01-10T07:30:15.222Z] /home/sftnight/build/workspace/root-pullrequests-build/root/tree/ntuple/v7/src/RPageStorageDaos.cxx:307:80: error: no matching function for call to ROOT::Experimental::Detail::RDaosContainer::ROidDkeyPair::ROidDkeyPair(&lt;brace-enclosed initializer list&gt;) ; - [2023-01-10T07:30:15.222Z] /home/sftnight/build/workspace/root-pullrequests-build/root/tree/ntuple/v7/src/RPageStorageDaos.cxx:701:80: error: no matching function for call to ROOT::Experimental::Detail::RDaosContainer::ROidDkeyPair::ROidDkeyPair(&lt;brace-enclosed initializer list&gt;) . ### Warnings:; - [2023-01-10T07:26:17.045Z] /home/sftnight/build/workspace/root-pullrequests-build/root/net/rpdutils/src/rpdutils.cxx:422:54: warning: using value of simple assignment with volatile-qualified left operand is deprecated [-Wvolatile] ; - [2023-01-10T07:26:17.322Z] /home/sftnight/build/workspace/root-pullrequests-build/root/core/base/src/TSystem.cxx:4040:42: warning: bitwise operation between different enumeration types TSystem::EAclicProperties and TObject::&lt;unnamed enum&gt; is deprecated [-Wdeprecated-enum-enum-conversion] ; - [2023-01-10T07:26:17.322Z] /home/sftnight/build/workspace/root-pullrequests-build/root/core/base/src/TSystem.cxx:4042:43: warning: bitwise operation between different enumeration types TSystem::EAclicProperties and TObject::&lt;unnamed enum&gt; is deprecated [-Wdeprecated-enum-enum-conversion] ; - [2023-01-10T07:26:46.426Z] /home/sftnight/build/workspace/root-pullrequests-build/root/io/io/src/TEmulatedMapProxy.cxx:144:25: warning: bitwise operation between different enumeration types EProperty and TGenCollectionProxy::&lt;unnamed enum&gt; is deprecated [-Wdeprecated-enum-enum-conversi,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11874#issuecomment-1376839076
Usability,simpl,simple, on root-ubuntu-2204-1.cern.ch:/home/sftnight/build/workspace/root-pullrequests-build; [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/163670/console).; ### Errors:; - [2023-01-10T07:30:15.222Z] /home/sftnight/build/workspace/root-pullrequests-build/root/tree/ntuple/v7/src/RPageStorageDaos.cxx:307:80: error: no matching function for call to ROOT::Experimental::Detail::RDaosContainer::ROidDkeyPair::ROidDkeyPair(&lt;brace-enclosed initializer list&gt;) ; - [2023-01-10T07:30:15.222Z] /home/sftnight/build/workspace/root-pullrequests-build/root/tree/ntuple/v7/src/RPageStorageDaos.cxx:701:80: error: no matching function for call to ROOT::Experimental::Detail::RDaosContainer::ROidDkeyPair::ROidDkeyPair(&lt;brace-enclosed initializer list&gt;) . ### Warnings:; - [2023-01-10T07:26:17.045Z] /home/sftnight/build/workspace/root-pullrequests-build/root/net/rpdutils/src/rpdutils.cxx:422:54: warning: using value of simple assignment with volatile-qualified left operand is deprecated [-Wvolatile] ; - [2023-01-10T07:26:17.322Z] /home/sftnight/build/workspace/root-pullrequests-build/root/core/base/src/TSystem.cxx:4040:42: warning: bitwise operation between different enumeration types TSystem::EAclicProperties and TObject::&lt;unnamed enum&gt; is deprecated [-Wdeprecated-enum-enum-conversion] ; - [2023-01-10T07:26:17.322Z] /home/sftnight/build/workspace/root-pullrequests-build/root/core/base/src/TSystem.cxx:4042:43: warning: bitwise operation between different enumeration types TSystem::EAclicProperties and TObject::&lt;unnamed enum&gt; is deprecated [-Wdeprecated-enum-enum-conversion] ; - [2023-01-10T07:26:46.426Z] /home/sftnight/build/workspace/root-pullrequests-build/root/io/io/src/TEmulatedMapProxy.cxx:144:25: warning: bitwise operation between different enumeration types EProperty and TGenCollectionProxy::&lt;unnamed enum&gt; is deprecated [-Wdeprecated-enum-enum-conversion] ; - [2023-01-10T07:26:46.426Z] /home/sftnig,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11874#issuecomment-1376839076
Usability,simpl,simply,"> You should probably just delete that commit from the branch history, e.g. with an interactive rebase (`git rebase -i master` + `git push --force`). Isn't ""squash and merge"" good enough? Otherwise I will simply make another PR, so I'm sure not to screw up ;-)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11892#issuecomment-1351098247
Availability,error,errors,"developers. Use -Wno-dev to suppress it. CMake Warning (dev) at /usr/share/cmake/Modules/CMakeDependentOption.cmake:75 (option):; Policy CMP0077 is not set: option() honors normal variables. Run ""cmake; --help-policy CMP0077"" for policy details. Use the cmake_policy command to; set the policy and suppress this warning. For compatibility with older versions of CMake, option is clearing the; normal variable 'LLVM_EXPORT_SYMBOLS_FOR_PLUGINS'.; Call Stack (most recent call first):; /usr/lib/llvm/15/lib/cmake/llvm/HandleLLVMOptions.cmake:1157 (CMAKE_DEPENDENT_OPTION); CMakeLists.txt:95 (include); This warning is for project developers. Use -Wno-dev to suppress it. -- Looking for os_signpost_interval_begin; -- Looking for os_signpost_interval_begin - not found; -- Found PythonInterp: /usr/bin/python (found version ""3.10.9""); -- Performing Test CXX_HAS_Wno_nested_anon_types; -- Performing Test CXX_HAS_Wno_nested_anon_types - Success; -- Performing Test CXX_HAS_Wno_covered_switch_default; -- Performing Test CXX_HAS_Wno_covered_switch_default - Success; -- Performing Test CXX_HAS_Wno_unused_local_typedef; -- Performing Test CXX_HAS_Wno_unused_local_typedef - Success; -- Cling version (from VERSION file): 1.0~dev; -- Cling will look for C++ headers in '/usr/lib/gcc/x86_64-pc-linux-gnu/11/include/g++-v11:/usr/lib/gcc/x86_64-pc-linux-gnu/11/include/g++-v11/x86_64-pc-linux-gnu:/usr/lib/gcc/x86_64-pc-linux-gnu/11/include/g++-v11/backward' at runtime.; -- And if not found, will invoke: '/usr/bin/c++ ' for them.; CMake Error: Could not open file for write in copy operation /usr/lib/llvm/15/lib/cmake/cling/ClingConfig.cmake.tmp; CMake Error: : System Error: No such file or directory; CMake Error at cmake/modules/CMakeLists.txt:22 (configure_file):; configure_file Problem configuring file. -- Configuring incomplete, errors occurred!; See also ""/home/jonesmz/build-cling/CMakeFiles/CMakeOutput.log"".; See also ""/home/jonesmz/build-cling/CMakeFiles/CMakeError.log"".; jonesmz@ymir ~ $; ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11920#issuecomment-1370394653
Modifiability,config,config,"Also reproducible on gentoo. ```; jonesmz@ymir ~ $ git clone git@github.com:root-project/cling.git; Cloning into 'cling'...; remote: Enumerating objects: 31202, done.; remote: Counting objects: 100% (651/651), done.; remote: Compressing objects: 100% (193/193), done.; remote: Total 31202 (delta 448), reused 561 (delta 442), pack-reused 30551; Receiving objects: 100% (31202/31202), 19.11 MiB | 22.64 MiB/s, done.; Resolving deltas: 100% (23380/23380), done.; jonesmz@ymir ~ $ cmake -S cling -B build-cling -Dbuiltin_llvm=OFF; -- The C compiler identification is GNU 11.3.1; -- The CXX compiler identification is GNU 11.3.1; -- Detecting C compiler ABI info; -- Detecting C compiler ABI info - done; -- Check for working C compiler: /usr/bin/cc - skipped; -- Detecting C compile features; -- Detecting C compile features - done; -- Detecting CXX compiler ABI info; -- Detecting CXX compiler ABI info - done; -- Check for working CXX compiler: /usr/bin/c++ - skipped; -- Detecting CXX compile features; -- Detecting CXX compile features - done; -- Found LLVM_CONFIG as /usr/lib/llvm/15/bin/llvm-config; -- Performing Test HAVE_FFI_CALL; -- Performing Test HAVE_FFI_CALL - Success; -- Found FFI: /usr/lib64/libffi.so; -- Performing Test Terminfo_LINKABLE; -- Performing Test Terminfo_LINKABLE - Success; -- Found Terminfo: /usr/lib64/libtinfo.so; -- Found ZLIB: /usr/lib64/libz.so (found version ""1.2.13""); -- Found LibXml2: /usr/lib64/libxml2.so (found version ""2.10.3""); -- Linker detection: GNU ld; -- Performing Test C_SUPPORTS_FPIC; -- Performing Test C_SUPPORTS_FPIC - Success; -- Performing Test CXX_SUPPORTS_FPIC; -- Performing Test CXX_SUPPORTS_FPIC - Success; -- Building with -fPIC; -- Performing Test C_SUPPORTS_FNO_SEMANTIC_INTERPOSITION; -- Performing Test C_SUPPORTS_FNO_SEMANTIC_INTERPOSITION - Success; -- Performing Test CXX_SUPPORTS_FNO_SEMANTIC_INTERPOSITION; -- Performing Test CXX_SUPPORTS_FNO_SEMANTIC_INTERPOSITION - Success; -- Performing Test SUPPORTS_FVISIBILITY_INLINES_HIDD",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11920#issuecomment-1370394653
Safety,detect,detection,"le features - done; -- Detecting CXX compiler ABI info; -- Detecting CXX compiler ABI info - done; -- Check for working CXX compiler: /usr/bin/c++ - skipped; -- Detecting CXX compile features; -- Detecting CXX compile features - done; -- Found LLVM_CONFIG as /usr/lib/llvm/15/bin/llvm-config; -- Performing Test HAVE_FFI_CALL; -- Performing Test HAVE_FFI_CALL - Success; -- Found FFI: /usr/lib64/libffi.so; -- Performing Test Terminfo_LINKABLE; -- Performing Test Terminfo_LINKABLE - Success; -- Found Terminfo: /usr/lib64/libtinfo.so; -- Found ZLIB: /usr/lib64/libz.so (found version ""1.2.13""); -- Found LibXml2: /usr/lib64/libxml2.so (found version ""2.10.3""); -- Linker detection: GNU ld; -- Performing Test C_SUPPORTS_FPIC; -- Performing Test C_SUPPORTS_FPIC - Success; -- Performing Test CXX_SUPPORTS_FPIC; -- Performing Test CXX_SUPPORTS_FPIC - Success; -- Building with -fPIC; -- Performing Test C_SUPPORTS_FNO_SEMANTIC_INTERPOSITION; -- Performing Test C_SUPPORTS_FNO_SEMANTIC_INTERPOSITION - Success; -- Performing Test CXX_SUPPORTS_FNO_SEMANTIC_INTERPOSITION; -- Performing Test CXX_SUPPORTS_FNO_SEMANTIC_INTERPOSITION - Success; -- Performing Test SUPPORTS_FVISIBILITY_INLINES_HIDDEN_FLAG; -- Performing Test SUPPORTS_FVISIBILITY_INLINES_HIDDEN_FLAG - Success; CMake Warning (dev) at /usr/lib/llvm/15/lib/cmake/llvm/HandleLLVMOptions.cmake:449 (option):; Policy CMP0077 is not set: option() honors normal variables. Run ""cmake; --help-policy CMP0077"" for policy details. Use the cmake_policy command to; set the policy and suppress this warning. For compatibility with older versions of CMake, option is clearing the; normal variable 'LLVM_ENABLE_WARNINGS'.; Call Stack (most recent call first):; CMakeLists.txt:95 (include); This warning is for project developers. Use -Wno-dev to suppress it. -- Performing Test C_SUPPORTS_WERROR_DATE_TIME; -- Performing Test C_SUPPORTS_WERROR_DATE_TIME - Success; -- Performing Test CXX_SUPPORTS_WERROR_DATE_TIME; -- Performing Test CXX_SUPPORTS_WERROR_D",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11920#issuecomment-1370394653
Testability,log,log,"developers. Use -Wno-dev to suppress it. CMake Warning (dev) at /usr/share/cmake/Modules/CMakeDependentOption.cmake:75 (option):; Policy CMP0077 is not set: option() honors normal variables. Run ""cmake; --help-policy CMP0077"" for policy details. Use the cmake_policy command to; set the policy and suppress this warning. For compatibility with older versions of CMake, option is clearing the; normal variable 'LLVM_EXPORT_SYMBOLS_FOR_PLUGINS'.; Call Stack (most recent call first):; /usr/lib/llvm/15/lib/cmake/llvm/HandleLLVMOptions.cmake:1157 (CMAKE_DEPENDENT_OPTION); CMakeLists.txt:95 (include); This warning is for project developers. Use -Wno-dev to suppress it. -- Looking for os_signpost_interval_begin; -- Looking for os_signpost_interval_begin - not found; -- Found PythonInterp: /usr/bin/python (found version ""3.10.9""); -- Performing Test CXX_HAS_Wno_nested_anon_types; -- Performing Test CXX_HAS_Wno_nested_anon_types - Success; -- Performing Test CXX_HAS_Wno_covered_switch_default; -- Performing Test CXX_HAS_Wno_covered_switch_default - Success; -- Performing Test CXX_HAS_Wno_unused_local_typedef; -- Performing Test CXX_HAS_Wno_unused_local_typedef - Success; -- Cling version (from VERSION file): 1.0~dev; -- Cling will look for C++ headers in '/usr/lib/gcc/x86_64-pc-linux-gnu/11/include/g++-v11:/usr/lib/gcc/x86_64-pc-linux-gnu/11/include/g++-v11/x86_64-pc-linux-gnu:/usr/lib/gcc/x86_64-pc-linux-gnu/11/include/g++-v11/backward' at runtime.; -- And if not found, will invoke: '/usr/bin/c++ ' for them.; CMake Error: Could not open file for write in copy operation /usr/lib/llvm/15/lib/cmake/cling/ClingConfig.cmake.tmp; CMake Error: : System Error: No such file or directory; CMake Error at cmake/modules/CMakeLists.txt:22 (configure_file):; configure_file Problem configuring file. -- Configuring incomplete, errors occurred!; See also ""/home/jonesmz/build-cling/CMakeFiles/CMakeOutput.log"".; See also ""/home/jonesmz/build-cling/CMakeFiles/CMakeError.log"".; jonesmz@ymir ~ $; ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11920#issuecomment-1370394653
Usability,clear,clearing,"2: /usr/lib64/libxml2.so (found version ""2.10.3""); -- Linker detection: GNU ld; -- Performing Test C_SUPPORTS_FPIC; -- Performing Test C_SUPPORTS_FPIC - Success; -- Performing Test CXX_SUPPORTS_FPIC; -- Performing Test CXX_SUPPORTS_FPIC - Success; -- Building with -fPIC; -- Performing Test C_SUPPORTS_FNO_SEMANTIC_INTERPOSITION; -- Performing Test C_SUPPORTS_FNO_SEMANTIC_INTERPOSITION - Success; -- Performing Test CXX_SUPPORTS_FNO_SEMANTIC_INTERPOSITION; -- Performing Test CXX_SUPPORTS_FNO_SEMANTIC_INTERPOSITION - Success; -- Performing Test SUPPORTS_FVISIBILITY_INLINES_HIDDEN_FLAG; -- Performing Test SUPPORTS_FVISIBILITY_INLINES_HIDDEN_FLAG - Success; CMake Warning (dev) at /usr/lib/llvm/15/lib/cmake/llvm/HandleLLVMOptions.cmake:449 (option):; Policy CMP0077 is not set: option() honors normal variables. Run ""cmake; --help-policy CMP0077"" for policy details. Use the cmake_policy command to; set the policy and suppress this warning. For compatibility with older versions of CMake, option is clearing the; normal variable 'LLVM_ENABLE_WARNINGS'.; Call Stack (most recent call first):; CMakeLists.txt:95 (include); This warning is for project developers. Use -Wno-dev to suppress it. -- Performing Test C_SUPPORTS_WERROR_DATE_TIME; -- Performing Test C_SUPPORTS_WERROR_DATE_TIME - Success; -- Performing Test CXX_SUPPORTS_WERROR_DATE_TIME; -- Performing Test CXX_SUPPORTS_WERROR_DATE_TIME - Success; -- Performing Test C_SUPPORTS_WERROR_UNGUARDED_AVAILABILITY_NEW; -- Performing Test C_SUPPORTS_WERROR_UNGUARDED_AVAILABILITY_NEW - Failed; -- Performing Test CXX_SUPPORTS_WERROR_UNGUARDED_AVAILABILITY_NEW; -- Performing Test CXX_SUPPORTS_WERROR_UNGUARDED_AVAILABILITY_NEW - Failed; -- Performing Test CXX_SUPPORTS_MISSING_FIELD_INITIALIZERS_FLAG; -- Performing Test CXX_SUPPORTS_MISSING_FIELD_INITIALIZERS_FLAG - Success; -- Performing Test C_SUPPORTS_IMPLICIT_FALLTHROUGH_FLAG; -- Performing Test C_SUPPORTS_IMPLICIT_FALLTHROUGH_FLAG - Success; -- Performing Test CXX_SUPPORTS_IMPLICIT_FAL",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11920#issuecomment-1370394653
Availability,echo,echo,@Axel-Naumann ; In case simple `-m profile` can be helpful:. ```; ( lb-set-platform x86_64-centos7-gcc11-opt ; source /cvmfs/sft.cern.ch/lcg/views/LCG_102/${CMTCONFIG}/setup.sh ; echo $ROOTSYS ; time python -m profile ./tst100.py | tee root626.txt) ; ... ; real	0m14.144s; user	0m10.412s; sys	0m2.730s. ( lb-set-platform x86_64-centos7-gcc12-opt ; source /cvmfs/sft.cern.ch/lcg/views/dev3/latest/${CMTCONFIG}/setup.sh ; echo $ROOTSYS ; time python -m profile ./tst100.py | tee root627.txt ); ... real	0m45.779s; user	0m36.429s; sys	0m4.734s. ```; output files: ; [root626.txt](https://gist.github.com/VanyaBelyaev/17884a2fb55deea182d27fe1b3076c70); [root627.txt](https://gist.github.com/VanyaBelyaev/c8bc792ead4f2a76c08edb0392046211),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11927#issuecomment-1361002552
Usability,simpl,simple,@Axel-Naumann ; In case simple `-m profile` can be helpful:. ```; ( lb-set-platform x86_64-centos7-gcc11-opt ; source /cvmfs/sft.cern.ch/lcg/views/LCG_102/${CMTCONFIG}/setup.sh ; echo $ROOTSYS ; time python -m profile ./tst100.py | tee root626.txt) ; ... ; real	0m14.144s; user	0m10.412s; sys	0m2.730s. ( lb-set-platform x86_64-centos7-gcc12-opt ; source /cvmfs/sft.cern.ch/lcg/views/dev3/latest/${CMTCONFIG}/setup.sh ; echo $ROOTSYS ; time python -m profile ./tst100.py | tee root627.txt ); ... real	0m45.779s; user	0m36.429s; sys	0m4.734s. ```; output files: ; [root626.txt](https://gist.github.com/VanyaBelyaev/17884a2fb55deea182d27fe1b3076c70); [root627.txt](https://gist.github.com/VanyaBelyaev/c8bc792ead4f2a76c08edb0392046211),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11927#issuecomment-1361002552
Availability,echo,echo,"For completeness dev3/Fri vs dev3/Thu. ```; ( lb-set-platform x86_64-centos7-gcc12-opt ; source /cvmfs/sft.cern.ch/lcg/views/dev3/Fri/${CMTCONFIG}/setup.sh ; echo $ROOTSYS ; time python -m profile ./tst100.py | tee root627_friday.txt ; ...; real	0m45.976s; user	0m36.305s; sys	0m5.073s. ( lb-set-platform x86_64-centos7-gcc12-opt ; source /cvmfs/sft.cern.ch/lcg/views/dev3/Thu/${CMTCONFIG}/setup.sh ; echo $ROOTSYS ; time python -m profile ./tst100.py | tee root627_thursday.txt ); ... real	0m31.001s; user	0m12.790s; sys	0m4.830s. ```. this time no factor of 2, but 1.5 . [log-files](https://gist.github.com/VanyaBelyaev/0e55d321d554af63b56b8f881804e7eb). but much more important for me - that [GitHub Action](https://github.com/OstapHEP/ostap/actions) tests for my real project clearly show a jump in bad direction for CPU performance - from something a bit smaller than 2 hours to something exceeding 6 hours with fails due to timeover",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11927#issuecomment-1361014198
Performance,perform,performance,"For completeness dev3/Fri vs dev3/Thu. ```; ( lb-set-platform x86_64-centos7-gcc12-opt ; source /cvmfs/sft.cern.ch/lcg/views/dev3/Fri/${CMTCONFIG}/setup.sh ; echo $ROOTSYS ; time python -m profile ./tst100.py | tee root627_friday.txt ; ...; real	0m45.976s; user	0m36.305s; sys	0m5.073s. ( lb-set-platform x86_64-centos7-gcc12-opt ; source /cvmfs/sft.cern.ch/lcg/views/dev3/Thu/${CMTCONFIG}/setup.sh ; echo $ROOTSYS ; time python -m profile ./tst100.py | tee root627_thursday.txt ); ... real	0m31.001s; user	0m12.790s; sys	0m4.830s. ```. this time no factor of 2, but 1.5 . [log-files](https://gist.github.com/VanyaBelyaev/0e55d321d554af63b56b8f881804e7eb). but much more important for me - that [GitHub Action](https://github.com/OstapHEP/ostap/actions) tests for my real project clearly show a jump in bad direction for CPU performance - from something a bit smaller than 2 hours to something exceeding 6 hours with fails due to timeover",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11927#issuecomment-1361014198
Testability,log,log-files,"For completeness dev3/Fri vs dev3/Thu. ```; ( lb-set-platform x86_64-centos7-gcc12-opt ; source /cvmfs/sft.cern.ch/lcg/views/dev3/Fri/${CMTCONFIG}/setup.sh ; echo $ROOTSYS ; time python -m profile ./tst100.py | tee root627_friday.txt ; ...; real	0m45.976s; user	0m36.305s; sys	0m5.073s. ( lb-set-platform x86_64-centos7-gcc12-opt ; source /cvmfs/sft.cern.ch/lcg/views/dev3/Thu/${CMTCONFIG}/setup.sh ; echo $ROOTSYS ; time python -m profile ./tst100.py | tee root627_thursday.txt ); ... real	0m31.001s; user	0m12.790s; sys	0m4.830s. ```. this time no factor of 2, but 1.5 . [log-files](https://gist.github.com/VanyaBelyaev/0e55d321d554af63b56b8f881804e7eb). but much more important for me - that [GitHub Action](https://github.com/OstapHEP/ostap/actions) tests for my real project clearly show a jump in bad direction for CPU performance - from something a bit smaller than 2 hours to something exceeding 6 hours with fails due to timeover",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11927#issuecomment-1361014198
Usability,clear,clearly,"For completeness dev3/Fri vs dev3/Thu. ```; ( lb-set-platform x86_64-centos7-gcc12-opt ; source /cvmfs/sft.cern.ch/lcg/views/dev3/Fri/${CMTCONFIG}/setup.sh ; echo $ROOTSYS ; time python -m profile ./tst100.py | tee root627_friday.txt ; ...; real	0m45.976s; user	0m36.305s; sys	0m5.073s. ( lb-set-platform x86_64-centos7-gcc12-opt ; source /cvmfs/sft.cern.ch/lcg/views/dev3/Thu/${CMTCONFIG}/setup.sh ; echo $ROOTSYS ; time python -m profile ./tst100.py | tee root627_thursday.txt ); ... real	0m31.001s; user	0m12.790s; sys	0m4.830s. ```. this time no factor of 2, but 1.5 . [log-files](https://gist.github.com/VanyaBelyaev/0e55d321d554af63b56b8f881804e7eb). but much more important for me - that [GitHub Action](https://github.com/OstapHEP/ostap/actions) tests for my real project clearly show a jump in bad direction for CPU performance - from something a bit smaller than 2 hours to something exceeding 6 hours with fails due to timeover",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11927#issuecomment-1361014198
Performance,perform,performance,"after very long pause (sorry), I've rerun my tests with dev3 LCG nightly slot and I see that performance is close to values from the start of December. Likely the the problem is solved and the issue can be closed.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11927#issuecomment-1399911161
Testability,test,tests,"after very long pause (sorry), I've rerun my tests with dev3 LCG nightly slot and I see that performance is close to values from the start of December. Likely the the problem is solved and the issue can be closed.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11927#issuecomment-1399911161
Usability,pause,pause,"after very long pause (sorry), I've rerun my tests with dev3 LCG nightly slot and I see that performance is close to values from the start of December. Likely the the problem is solved and the issue can be closed.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11927#issuecomment-1399911161
Usability,simpl,simpler,"a simpler reproducer:; ```; void HV_comp_red(){; Double_t biasVoltage[28] = {80., 70., 60., 50., 40., 30., 20., 10., 9., 8., 7., 6., 5., 4., 3., 2., 1., 0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1, 0.08, 0.06};; Double_t mean0[28] = {0., -4.45, -3.81, -14.65, -11.81, -12.56, -12.25, -6.26, -9.40, -7.98, -7.14, -17.87, -12.26, -11.41, -13.35, -14.51, -7.51, -16.15, -12.67, -18.58, -8.76, -8.94, -13.75, -14.31, -12.76, -14.16, -8.24, -135.4};. auto graph0 = new TGraph(28, biasVoltage, mean0);. graph0->SetMarkerColor(2);; graph0->SetMarkerStyle(20);. TCanvas *canvas = new TCanvas(""c"", ""c"", 200,10,900,600);; canvas->SetLogx();; graph0->Draw(""a p rx"");; }; ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11938#issuecomment-1372092925
Availability,error,error,high_resolution_clock::now(); TH1 *hpxCumu = hpx->GetCumulativeIncExc(); std::chrono::time_point<std::chrono::high_resolution_clock> stop = std::chrono::high_resolution_clock::now();; root [2] static_cast<std::chrono::duration<double>>(stop - start).count(); (double) 0.00024412700; root [3] .q; [yuehshun@lxplus8s13 root-build.incexc]$ cd ../root-build; [yuehshun@lxplus8s13 root-build]$ ./bin/root -l tutorials/hsimple.root; root [0]; Attaching file tutorials/hsimple.root as _file0...; (TFile *) 0x23be190; root [1] std::chrono::time_point<std::chrono::high_resolution_clock> start = std::chrono::high_resolution_clock::now(); TH1 *hpxCumu = hpx->GetCumulativeIncExc(); std::chrono::time_point<std::chrono::high_resolution_clock> stop = std::chrono::high_resolution_clock::now();; ROOT_prompt_1:1:132: error: no member named 'GetCumulativeIncExc' in 'TH1F'; std::chrono::time_point<std::chrono::high_resolution_clock> start = std::chrono::high_resolution_clock::now(); TH1 *hpxCumu = hpx->GetCumulativeIncExc(); std::chrono::time_point<std::chrono::high_resolution_clock> stop = std::chrono::high_resolution_clock::now();; ~~~ ^; root [2] std::chrono::time_point<std::chrono::high_resolution_clock> start = std::chrono::high_resolution_clock::now(); TH1 *hpxCumu = hpx->GetCumulative(); std::chrono::time_point<std::chrono::high_resolution_clock> stop = std::chrono::high_resolution_clock::now();; [IncrementalJIT] addModule() failed: Duplicate definition of symbol '_ZN21__ROOT_SpecialObjects3hpxE'; root [3] .q; [yuehshun@lxplus8s13 root-build]$ ./bin/root -l tutorials/hsimple.root; root [0]; Attaching file tutorials/hsimple.root as _file0...; (TFile *) 0x1d86820; root [1] std::chrono::time_point<std::chrono::high_resolution_clock> start = std::chrono::high_resolution_clock::now(); TH1 *hpxCumu = hpx->GetCumulative(); std::chrono::time_point<std::chrono::high_resolution_clock> stop = std::chrono::high_resolution_clock::now();; root [2] static_cast<std::chrono::duration<double>>(stop - st,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11949#issuecomment-1361867780
Testability,benchmark,benchmark,"Regarding the efficiency, I don't know what's the proper way to benchmark the cumulative histogram generation. In the following simple benchmark targeting the `hpx` 1D histogram in `tutorials/hsimple.root`, the difference is not much, though `TH1::GetCumulativeIncExc` seems slightly faster. ```; [yuehshun@lxplus8s13 root-build]$ ./bin/root -l tutorials/hsimple.root; root [0]; Attaching file tutorials/hsimple.root as _file0...; (TFile *) 0x372cc00; root [1] std::chrono::time_point<std::chrono::high_resolution_clock> start = std::chrono::high_resolution_clock::now(); TH1 *hpxCumu = hpx->GetCumulative(); std::chrono::time_point<std::chrono::high_resolution_clock> stop = std::chrono::high_resolution_clock::now();; root [2] static_cast<std::chrono::duration<double>>(stop - start).count(); (double) 0.00026606600; root [3] .q; [yuehshun@lxplus8s13 root-build]$ cd ../root-build.incexc/; [yuehshun@lxplus8s13 root-build.incexc]$ ./bin/root -l tutorials/hsimple.root; root [0]; Attaching file tutorials/hsimple.root as _file0...; (TFile *) 0x3c458b0; root [1] std::chrono::time_point<std::chrono::high_resolution_clock> start = std::chrono::high_resolution_clock::now(); TH. 1 *hpxCumu = hpx->GetCumulativeIncExc(); std::chrono::time_poroot [2] static_cast<std::chrono::duration<double>>(stop - start).count(); (double) 0.00024825600; root [3] .q; [yuehshun@lxplus8s13 root-build.incexc]$ cd ../root-build; [yuehshun@lxplus8s13 root-build]$ ./bin/root -l tutorials/hsimple.root; root [0]; Attaching file tutorials/hsimple.root as _file0...; (TFile *) 0x2b9a7d0; root [1] std::chrono::time_point<std::chrono::high_resolution_clock> start = std::chrono::high_resolution_clock::now(); TH1 *hpxCumu = hpx->GetCumulative(); std::chrono::time_point<std::chrono::high_resolution_clock> stop = std::chrono::high_re; solution_clock::now();; root [2] static_cast<std::chrono::duration<double>>(stop - start).count(); (double) 0.00027867100; root [3] .q; [yuehshun@lxplus8s13 root-build]$ cd ../root-build.inc",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11949#issuecomment-1361867780
Usability,simpl,simple,"Regarding the efficiency, I don't know what's the proper way to benchmark the cumulative histogram generation. In the following simple benchmark targeting the `hpx` 1D histogram in `tutorials/hsimple.root`, the difference is not much, though `TH1::GetCumulativeIncExc` seems slightly faster. ```; [yuehshun@lxplus8s13 root-build]$ ./bin/root -l tutorials/hsimple.root; root [0]; Attaching file tutorials/hsimple.root as _file0...; (TFile *) 0x372cc00; root [1] std::chrono::time_point<std::chrono::high_resolution_clock> start = std::chrono::high_resolution_clock::now(); TH1 *hpxCumu = hpx->GetCumulative(); std::chrono::time_point<std::chrono::high_resolution_clock> stop = std::chrono::high_resolution_clock::now();; root [2] static_cast<std::chrono::duration<double>>(stop - start).count(); (double) 0.00026606600; root [3] .q; [yuehshun@lxplus8s13 root-build]$ cd ../root-build.incexc/; [yuehshun@lxplus8s13 root-build.incexc]$ ./bin/root -l tutorials/hsimple.root; root [0]; Attaching file tutorials/hsimple.root as _file0...; (TFile *) 0x3c458b0; root [1] std::chrono::time_point<std::chrono::high_resolution_clock> start = std::chrono::high_resolution_clock::now(); TH. 1 *hpxCumu = hpx->GetCumulativeIncExc(); std::chrono::time_poroot [2] static_cast<std::chrono::duration<double>>(stop - start).count(); (double) 0.00024825600; root [3] .q; [yuehshun@lxplus8s13 root-build.incexc]$ cd ../root-build; [yuehshun@lxplus8s13 root-build]$ ./bin/root -l tutorials/hsimple.root; root [0]; Attaching file tutorials/hsimple.root as _file0...; (TFile *) 0x2b9a7d0; root [1] std::chrono::time_point<std::chrono::high_resolution_clock> start = std::chrono::high_resolution_clock::now(); TH1 *hpxCumu = hpx->GetCumulative(); std::chrono::time_point<std::chrono::high_resolution_clock> stop = std::chrono::high_re; solution_clock::now();; root [2] static_cast<std::chrono::duration<double>>(stop - start).count(); (double) 0.00027867100; root [3] .q; [yuehshun@lxplus8s13 root-build]$ cd ../root-build.inc",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11949#issuecomment-1361867780
Usability,simpl,simpler,"Hi @HenryDayHall ,. yes that line is a leftover and #11972 will remove it (thanks to @ferdymercury ). I suggest looking at RCsvDS, RNTupleDS or RArrowDS (ordered from simpler to more complex) for existing implementations of data sources. RRootDS is unused and we might remove it in the future.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11971#issuecomment-1371082629
Testability,test,tests,Build failed on ROOT-debian10-i386/soversion.; Running on pcepsft10.dyndns.cern.ch:/build/workspace/root-pullrequests-build; [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/164000/console).; ### Failing tests:; - [projectroot.test.test_stressmathcore_interpreted](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/164000/testReport/projectroot/test/test_stressmathcore_interpreted/); - [projectroot.bindings.pyroot.pythonizations.test.pyunittests_pyroot_import_load_libs](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/164000/testReport/projectroot.bindings.pyroot.pythonizations/test/pyunittests_pyroot_import_load_libs/); - [projectroot.roottest.cling.offset.roottest_cling_offset_interpreted](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/164000/testReport/projectroot.roottest.cling/offset/roottest_cling_offset_interpreted/); - [projectroot.roottest.cling.other.roottest_cling_other_execValuePrint](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/164000/testReport/projectroot.roottest.cling/other/roottest_cling_other_execValuePrint/); - [projectroot.roottest.root.meta.dictSelection.roottest_root_meta_dictSelection_execAtlasTest2](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/164000/testReport/projectroot.roottest.root.meta/dictSelection/roottest_root_meta_dictSelection_execAtlasTest2/); - [projectroot.roottest.root.selector.simple.roottest_root_selector_simple_runtestLoadingSelector](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/164000/testReport/projectroot.roottest.root.selector/simple/roottest_root_selector_simple_runtestLoadingSelector/); - [projectroot.roottest.root.tree.reader.roottest_root_tree_reader_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/164000/testReport/projectroot.roottest.root.tree/reader/roottest_root_tree_reader_make/); - [p,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12018#issuecomment-1380358995
Usability,simpl,simple,zations.test.pyunittests_pyroot_import_load_libs](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/164000/testReport/projectroot.bindings.pyroot.pythonizations/test/pyunittests_pyroot_import_load_libs/); - [projectroot.roottest.cling.offset.roottest_cling_offset_interpreted](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/164000/testReport/projectroot.roottest.cling/offset/roottest_cling_offset_interpreted/); - [projectroot.roottest.cling.other.roottest_cling_other_execValuePrint](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/164000/testReport/projectroot.roottest.cling/other/roottest_cling_other_execValuePrint/); - [projectroot.roottest.root.meta.dictSelection.roottest_root_meta_dictSelection_execAtlasTest2](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/164000/testReport/projectroot.roottest.root.meta/dictSelection/roottest_root_meta_dictSelection_execAtlasTest2/); - [projectroot.roottest.root.selector.simple.roottest_root_selector_simple_runtestLoadingSelector](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/164000/testReport/projectroot.roottest.root.selector/simple/roottest_root_selector_simple_runtestLoadingSelector/); - [projectroot.roottest.root.tree.reader.roottest_root_tree_reader_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/164000/testReport/projectroot.roottest.root.tree/reader/roottest_root_tree_reader_make/); - [projectroot.roottest.root.tree.selector.roottest_root_tree_selector_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/164000/testReport/projectroot.roottest.root.tree/selector/roottest_root_tree_selector_make/); - [projectroot.roottest.root.treeformula.stl.roottest_root_treeformula_stl_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/164000/testReport/projectroot.roottest.root.treeformula/stl/roottest_root_treeformula_stl_make/),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12018#issuecomment-1380358995
Testability,test,tests,Build failed on ROOT-ubuntu18.04/nortcxxmod.; Running on sft-ubuntu-1804-3.cern.ch:/build/workspace/root-pullrequests-build; [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/164079/console).; ### Failing tests:; - [projectroot.roottest.root.dataframe.roottest_root_dataframe_test_stringfiltercolumn](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/164079/testReport/projectroot.roottest.root/dataframe/roottest_root_dataframe_test_stringfiltercolumn/); - [projectroot.roottest.root.dataframe.roottest_root_dataframe_test_snapshot](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/164079/testReport/projectroot.roottest.root/dataframe/roottest_root_dataframe_test_snapshot/); - [projectroot.roottest.root.dataframe.roottest_root_dataframe_test_nested_rvec_snapshot](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/164079/testReport/projectroot.roottest.root/dataframe/roottest_root_dataframe_test_nested_rvec_snapshot/); - [projectroot.roottest.root.dataframe.roottest_root_dataframe_misc](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/164079/testReport/projectroot.roottest.root/dataframe/roottest_root_dataframe_misc/); - [projectroot.roottest.root.dataframe.roottest_root_dataframe_regression_multipletriggerrun](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/164079/testReport/projectroot.roottest.root/dataframe/roottest_root_dataframe_regression_multipletriggerrun/); - [projectroot.roottest.root.io.stdarray.roottest_root_io_stdarray_modelCheckValues](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/164079/testReport/projectroot.roottest.root.io/stdarray/roottest_root_io_stdarray_modelCheckValues/); - [projectroot.roottest.root.meta.dictSelection.roottest_root_meta_dictSelection_execAtlasTest2](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/164079/testReport/projectr,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12018#issuecomment-1380875995
Usability,simpl,simple,ts-build/164079/testReport/projectroot.roottest.root/dataframe/roottest_root_dataframe_test_snapshot/); - [projectroot.roottest.root.dataframe.roottest_root_dataframe_test_nested_rvec_snapshot](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/164079/testReport/projectroot.roottest.root/dataframe/roottest_root_dataframe_test_nested_rvec_snapshot/); - [projectroot.roottest.root.dataframe.roottest_root_dataframe_misc](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/164079/testReport/projectroot.roottest.root/dataframe/roottest_root_dataframe_misc/); - [projectroot.roottest.root.dataframe.roottest_root_dataframe_regression_multipletriggerrun](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/164079/testReport/projectroot.roottest.root/dataframe/roottest_root_dataframe_regression_multipletriggerrun/); - [projectroot.roottest.root.io.stdarray.roottest_root_io_stdarray_modelCheckValues](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/164079/testReport/projectroot.roottest.root.io/stdarray/roottest_root_io_stdarray_modelCheckValues/); - [projectroot.roottest.root.meta.dictSelection.roottest_root_meta_dictSelection_execAtlasTest2](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/164079/testReport/projectroot.roottest.root.meta/dictSelection/roottest_root_meta_dictSelection_execAtlasTest2/); - [projectroot.roottest.root.selector.simple.roottest_root_selector_simple_runtestLoadingSelector](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/164079/testReport/projectroot.roottest.root.selector/simple/roottest_root_selector_simple_runtestLoadingSelector/); - [projectroot.roottest.root.tree.fastcloning.roottest_root_tree_fastcloning_execCheckClusterRange](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/164079/testReport/projectroot.roottest.root.tree/fastcloning/roottest_root_tree_fastcloning_execCheckClusterRange/),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12018#issuecomment-1380875995
Testability,test,tests,Build failed on ROOT-debian10-i386/soversion.; Running on pcepsft11.dyndns.cern.ch:/home/sftnight/build/workspace/root-pullrequests-build; [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/164077/console).; ### Failing tests:; - [projectroot.test.test_stressmathcore_interpreted](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/164077/testReport/projectroot/test/test_stressmathcore_interpreted/); - [projectroot.roottest.root.io.stdarray.roottest_root_io_stdarray_modelCheckValues](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/164077/testReport/projectroot.roottest.root.io/stdarray/roottest_root_io_stdarray_modelCheckValues/); - [projectroot.roottest.root.selector.simple.roottest_root_selector_simple_runtestLoadingSelector](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/164077/testReport/projectroot.roottest.root.selector/simple/roottest_root_selector_simple_runtestLoadingSelector/); - [projectroot.roottest.root.tree.reader.roottest_root_tree_reader_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/164077/testReport/projectroot.roottest.root.tree/reader/roottest_root_tree_reader_make/),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12018#issuecomment-1380914798
Usability,simpl,simple,Build failed on ROOT-debian10-i386/soversion.; Running on pcepsft11.dyndns.cern.ch:/home/sftnight/build/workspace/root-pullrequests-build; [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/164077/console).; ### Failing tests:; - [projectroot.test.test_stressmathcore_interpreted](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/164077/testReport/projectroot/test/test_stressmathcore_interpreted/); - [projectroot.roottest.root.io.stdarray.roottest_root_io_stdarray_modelCheckValues](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/164077/testReport/projectroot.roottest.root.io/stdarray/roottest_root_io_stdarray_modelCheckValues/); - [projectroot.roottest.root.selector.simple.roottest_root_selector_simple_runtestLoadingSelector](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/164077/testReport/projectroot.roottest.root.selector/simple/roottest_root_selector_simple_runtestLoadingSelector/); - [projectroot.roottest.root.tree.reader.roottest_root_tree_reader_make](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/164077/testReport/projectroot.roottest.root.tree/reader/roottest_root_tree_reader_make/),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12018#issuecomment-1380914798
Usability,undo,undocumented,"Additional mention of the original issue (chained lookups): https://developer.apple.com/forums/thread/719961, https://github.com/python/cpython/issues/97524 ; and https://openradar.appspot.com/radar?id=5536824084660224. Instead of `-Wl,-w` (which suppress all warnings), an undocumented options seems to be `-Xlinker -no_fixup_chains` (humm I guess actually maybe `-Wl,-no_fixup_chains`)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12045#issuecomment-1385813529
Usability,undo,undocumented,"> Instead of -Wl,-w (which suppress all warnings), an undocumented options seems to be -Xlinker -no_fixup_chains (humm I guess actually maybe -Wl,-no_fixup_chains). I am afraid that older linkers will not know `-no_fixup_chains` as that seems to be a new concern. So `-w` it is.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12045#issuecomment-1386778190
Integrability,message,message,"Good question, but unfortunately I have to admit I don't really know why. I didn't have that much time to investigate but needed a fix for 6.28 for which I'm already late. The TFoam class is quite fundamental to RooFit, and the memory increase has affected many users. All I had was this hint by valgrind when checked the reproducer in the commit message:; ```; Conditional jump or move depends on uninitialised value(s); at 0x402E09: TStorage::UpdateIsOnHeap(unsigned int const volatile&, unsigned int volatile&) (TStorage.h:132); by 0x501B33D: TDirectory::TDirectory() (in /usr/lib64/root/libCore.so.6.26.10); by 0x5816D81: TDirectoryFile::TDirectoryFile() (in /usr/lib64/root/libRIO.so.6.26.10); by 0x5833AF8: TFile::TFile(char const*, char const*, char const*, int) (in /usr/lib64/root/libRIO.so.6.26.10); by 0xE2D86A6: TCling::LoadPCM(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) (in /usr/lib64/root/libCling.so.6.26.10); by 0xE2D9A17: TCling::RegisterModule(char const*, char const**, char const**, char const*, char const*, void (*)(), std::vector<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >,; allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, int> > > const&, char const**, bool, bool) (in /usr/lib64/root/libCling.so.6.26.10); by 0x4FF098E: TROOT::InitInterpreter() (in /usr/lib64/root/libCore.so.6.26.10); by 0x4FF0C9E: ROOT::Internal::GetROOT2() (in /usr/lib64/root/libCore.so.6.26.10); by 0x510209C: ROOT::TGenericClassInfo::GetClass() (in /usr/lib64/root/libCore.so.6.26.10); by 0x90B67CA: TFoamCell::Class() (in /usr/lib64/root/libFoam.so.6.26.10); by 0x504BE7A: TRef::operator=(TObject*) (in /usr/lib64/root/libCore.so.6.26.10); by 0x90B126F: TFoamCell::Fill(int, TFoamCell*, TFoamCell*, TFoamCell*) (in /usr/lib64/root/libFoam.so.6.26.10); Uninitialised value was created by a stack allocation; at 0xE2D8106: TCling::LoadPCM(std::__cxx11::basic_string<",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12061#issuecomment-1397463096
Usability,simpl,simple,"nt by valgrind when checked the reproducer in the commit message:; ```; Conditional jump or move depends on uninitialised value(s); at 0x402E09: TStorage::UpdateIsOnHeap(unsigned int const volatile&, unsigned int volatile&) (TStorage.h:132); by 0x501B33D: TDirectory::TDirectory() (in /usr/lib64/root/libCore.so.6.26.10); by 0x5816D81: TDirectoryFile::TDirectoryFile() (in /usr/lib64/root/libRIO.so.6.26.10); by 0x5833AF8: TFile::TFile(char const*, char const*, char const*, int) (in /usr/lib64/root/libRIO.so.6.26.10); by 0xE2D86A6: TCling::LoadPCM(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) (in /usr/lib64/root/libCling.so.6.26.10); by 0xE2D9A17: TCling::RegisterModule(char const*, char const**, char const**, char const*, char const*, void (*)(), std::vector<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >,; allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, int> > > const&, char const**, bool, bool) (in /usr/lib64/root/libCling.so.6.26.10); by 0x4FF098E: TROOT::InitInterpreter() (in /usr/lib64/root/libCore.so.6.26.10); by 0x4FF0C9E: ROOT::Internal::GetROOT2() (in /usr/lib64/root/libCore.so.6.26.10); by 0x510209C: ROOT::TGenericClassInfo::GetClass() (in /usr/lib64/root/libCore.so.6.26.10); by 0x90B67CA: TFoamCell::Class() (in /usr/lib64/root/libFoam.so.6.26.10); by 0x504BE7A: TRef::operator=(TObject*) (in /usr/lib64/root/libCore.so.6.26.10); by 0x90B126F: TFoamCell::Fill(int, TFoamCell*, TFoamCell*, TFoamCell*) (in /usr/lib64/root/libFoam.so.6.26.10); Uninitialised value was created by a stack allocation; at 0xE2D8106: TCling::LoadPCM(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) (in /usr/lib64/root/libCling.so.6.26.10); ```. This made me think that maybe TRef is the problem, and indeed replacind the TRef with simple indices solved the problem. Is there something that you can make of that valgrind output maybe?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12061#issuecomment-1397463096
Usability,simpl,simplified,"Some further debugging (but really just dumping notes from some experiments):; * The problem of `histhistdrawv7testUnit` can be simplified, in some approximation, to:; ```; root [0] TClass::GetClass(""ROOT::Experimental::RHist<1, double, ROOT::Experimental::RHistStatContent, ROOT::Experimental::RHistStatUncertainty>""); root.exe: /home/jhahnfel/ROOT/src/interpreter/llvm/src/tools/clang/lib/AST/Decl.cpp:4120: unsigned int clang::FunctionDecl::getODRHash() const: Assertion `hasODRHash()' failed.; ```; * Even simpler, just trying to create an object of that template instantiation fails:; ```; root [0] ROOT::Experimental::RHist<1, double, ROOT::Experimental::RHistStatContent, ROOT::Experimental::RHistStatUncertainty> h;; root.exe: /home/jhahnfel/ROOT/src/interpreter/llvm/src/tools/clang/lib/AST/Decl.cpp:4120: unsigned int clang::FunctionDecl::getODRHash() const: Assertion `hasODRHash()' failed.; ```; * Funnily enough, the `using RH1D = RHist<1, double, RHistStatContent, RHistStatUncertainty>` works just fine; same if I remove the second `STAT` template and only leave `RHistStatContent`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12062#issuecomment-1419006181
Modifiability,inherit,inheritance,"> Some further debugging (but really just dumping notes from some experiments):; > ; > * The problem of `histhistdrawv7testUnit` can be simplified, in some approximation, to:; > ; > ; > ```; > root [0] TClass::GetClass(""ROOT::Experimental::RHist<1, double, ROOT::Experimental::RHistStatContent, ROOT::Experimental::RHistStatUncertainty>""); > root.exe: /home/jhahnfel/ROOT/src/interpreter/llvm/src/tools/clang/lib/AST/Decl.cpp:4120: unsigned int clang::FunctionDecl::getODRHash() const: Assertion `hasODRHash()' failed.; > ```; > ; > * Even simpler, just trying to create an object of that template instantiation fails:; > ; > ; > ```; > root [0] ROOT::Experimental::RHist<1, double, ROOT::Experimental::RHistStatContent, ROOT::Experimental::RHistStatUncertainty> h;; > root.exe: /home/jhahnfel/ROOT/src/interpreter/llvm/src/tools/clang/lib/AST/Decl.cpp:4120: unsigned int clang::FunctionDecl::getODRHash() const: Assertion `hasODRHash()' failed.; > ```; > ; > * Funnily enough, the `using RH1D = RHist<1, double, RHistStatContent, RHistStatUncertainty>` works just fine; same if I remove the second `STAT` template and only leave `RHistStatContent`. I've been stumbling upon these before: this is not simple as it has some template parameter pack expansion as part of the class inheritance chain...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12062#issuecomment-1419265262
Usability,simpl,simplified,"> Some further debugging (but really just dumping notes from some experiments):; > ; > * The problem of `histhistdrawv7testUnit` can be simplified, in some approximation, to:; > ; > ; > ```; > root [0] TClass::GetClass(""ROOT::Experimental::RHist<1, double, ROOT::Experimental::RHistStatContent, ROOT::Experimental::RHistStatUncertainty>""); > root.exe: /home/jhahnfel/ROOT/src/interpreter/llvm/src/tools/clang/lib/AST/Decl.cpp:4120: unsigned int clang::FunctionDecl::getODRHash() const: Assertion `hasODRHash()' failed.; > ```; > ; > * Even simpler, just trying to create an object of that template instantiation fails:; > ; > ; > ```; > root [0] ROOT::Experimental::RHist<1, double, ROOT::Experimental::RHistStatContent, ROOT::Experimental::RHistStatUncertainty> h;; > root.exe: /home/jhahnfel/ROOT/src/interpreter/llvm/src/tools/clang/lib/AST/Decl.cpp:4120: unsigned int clang::FunctionDecl::getODRHash() const: Assertion `hasODRHash()' failed.; > ```; > ; > * Funnily enough, the `using RH1D = RHist<1, double, RHistStatContent, RHistStatUncertainty>` works just fine; same if I remove the second `STAT` template and only leave `RHistStatContent`. I've been stumbling upon these before: this is not simple as it has some template parameter pack expansion as part of the class inheritance chain...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12062#issuecomment-1419265262
Deployability,release,released,"> Hi, I don't understand what temporary gcc's message refers to?; > ; > * `GetColumnType` returns a `string` by value that is taken in as a `const string &` by `TypeName2TypeID`, so everything should be fine there; > ; > * `TypeName2TypeID` returns a `const type_info &` that is conditionally assigned to a `const auto &` and that should also be ok: the `const type_info &` is produced by expressions such as `typeid(bool)` and that value should have static lifetime; > ; > ; > Help?. GCC13 has not been officially released yet. It comes with the [new `-Wdangling-reference` diagnostic](https://gcc.gnu.org/bugzilla/show_bug.cgi?id=106393), which I think still provides many false positives, e.g. [see this](https://gcc.gnu.org/bugzilla/show_bug.cgi?id=107532). In particular, this warning seems absolutely bogus. It can be reproduced with this simple excerpt (compile with `g++ -Werror=dangling-reference`).; ```c++; #include <string>; #include <typeinfo>. const std::type_info &f(const std::string &);; void g() {; // A `std::string` temporary is implicitly constructed passing the string literal ""foo"" to the ctor.; // Apparently, this triggers one of the patterns in GCC's new `[-Wdangling-reference]`. ; const auto &ti = f(""foo"");; }; ```. IMO, this warning is totally bogus (and might be seen in other parts of ROOT). Thus, I would suggest not changing the code but conditionally ignoring it,; _(a)_ Either in this translation unit only; ```c++; #pragma GCC diagnostic ignored ...; ```; , or _(b)_ most likely for all ROOT (appending `-Wno-dangling-reference` from CMake). I would go for `_(b)_`, at least until the feature becomes mature enough and does not yield false positives. What do you think, @linev, @eguiraud?. Also CC: @Axel-Naumann and @hahnjo.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12085#issuecomment-1403615900
Integrability,message,message,"> Hi, I don't understand what temporary gcc's message refers to?; > ; > * `GetColumnType` returns a `string` by value that is taken in as a `const string &` by `TypeName2TypeID`, so everything should be fine there; > ; > * `TypeName2TypeID` returns a `const type_info &` that is conditionally assigned to a `const auto &` and that should also be ok: the `const type_info &` is produced by expressions such as `typeid(bool)` and that value should have static lifetime; > ; > ; > Help?. GCC13 has not been officially released yet. It comes with the [new `-Wdangling-reference` diagnostic](https://gcc.gnu.org/bugzilla/show_bug.cgi?id=106393), which I think still provides many false positives, e.g. [see this](https://gcc.gnu.org/bugzilla/show_bug.cgi?id=107532). In particular, this warning seems absolutely bogus. It can be reproduced with this simple excerpt (compile with `g++ -Werror=dangling-reference`).; ```c++; #include <string>; #include <typeinfo>. const std::type_info &f(const std::string &);; void g() {; // A `std::string` temporary is implicitly constructed passing the string literal ""foo"" to the ctor.; // Apparently, this triggers one of the patterns in GCC's new `[-Wdangling-reference]`. ; const auto &ti = f(""foo"");; }; ```. IMO, this warning is totally bogus (and might be seen in other parts of ROOT). Thus, I would suggest not changing the code but conditionally ignoring it,; _(a)_ Either in this translation unit only; ```c++; #pragma GCC diagnostic ignored ...; ```; , or _(b)_ most likely for all ROOT (appending `-Wno-dangling-reference` from CMake). I would go for `_(b)_`, at least until the feature becomes mature enough and does not yield false positives. What do you think, @linev, @eguiraud?. Also CC: @Axel-Naumann and @hahnjo.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12085#issuecomment-1403615900
Usability,simpl,simple,"> Hi, I don't understand what temporary gcc's message refers to?; > ; > * `GetColumnType` returns a `string` by value that is taken in as a `const string &` by `TypeName2TypeID`, so everything should be fine there; > ; > * `TypeName2TypeID` returns a `const type_info &` that is conditionally assigned to a `const auto &` and that should also be ok: the `const type_info &` is produced by expressions such as `typeid(bool)` and that value should have static lifetime; > ; > ; > Help?. GCC13 has not been officially released yet. It comes with the [new `-Wdangling-reference` diagnostic](https://gcc.gnu.org/bugzilla/show_bug.cgi?id=106393), which I think still provides many false positives, e.g. [see this](https://gcc.gnu.org/bugzilla/show_bug.cgi?id=107532). In particular, this warning seems absolutely bogus. It can be reproduced with this simple excerpt (compile with `g++ -Werror=dangling-reference`).; ```c++; #include <string>; #include <typeinfo>. const std::type_info &f(const std::string &);; void g() {; // A `std::string` temporary is implicitly constructed passing the string literal ""foo"" to the ctor.; // Apparently, this triggers one of the patterns in GCC's new `[-Wdangling-reference]`. ; const auto &ti = f(""foo"");; }; ```. IMO, this warning is totally bogus (and might be seen in other parts of ROOT). Thus, I would suggest not changing the code but conditionally ignoring it,; _(a)_ Either in this translation unit only; ```c++; #pragma GCC diagnostic ignored ...; ```; , or _(b)_ most likely for all ROOT (appending `-Wno-dangling-reference` from CMake). I would go for `_(b)_`, at least until the feature becomes mature enough and does not yield false positives. What do you think, @linev, @eguiraud?. Also CC: @Axel-Naumann and @hahnjo.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12085#issuecomment-1403615900
Availability,down,downside,"+1 as it make `diffs` clearer in case of change to the member initialization. (downside, is the number of extra lines).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12102#issuecomment-1419337842
Usability,clear,clearer,"+1 as it make `diffs` clearer in case of change to the member initialization. (downside, is the number of extra lines).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12102#issuecomment-1419337842
Usability,learn,learned,"Just because I learned to not trust the lifetime of GitHub comments: this refers to the comment; ```c++; // FIXME: Uncomment and debug the various type mismatches.; ```; in a future version of `interpreter/cling/include/cling/Interpreter/Value.h`, around line 266.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12116#issuecomment-1405620021
Deployability,update,updated,"Thanks @eguiraud for all your comments! I've updated the text, I believe it is now clearer and more to the point.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12121#issuecomment-1405524377
Usability,clear,clearer,"Thanks @eguiraud for all your comments! I've updated the text, I believe it is now clearer and more to the point.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12121#issuecomment-1405524377
Modifiability,refactor,refactored,"> Can you elaborate a bit: what is the purpose of this change or the benefits/changes to the code using views?. Sure, `RNTupleGlobalRange` and `RNTupleClusterRange` before this PR are defined as forward ranges. So they can basically be used in a range-for loop and for STL algorithms, but they will use slower versions in some cases, because of the less capable iterator category. A good example is that `std::distance(globalRange.begin(), globalRange.end())` unnecessarily has linear complexity, although it could easility be constant. This effects us a lot as well for the parallel STL. E.g. spanning a parallel index space:; ```c++; std::for_each(std::execution::par, globalRange.begin(), globalRange.end(), [](NTupleSize_t i) { ... });; ```; This has unnecessary complex setup time, because partitioning the index space has linear complexity due to the iterator category. The support for C++20 ranges is orthogonal to these usuability improvements, but should fall out for free. Allowing the refactored types to be used with ranges is just a cherry-on-top to allow the client using the RNTuple API to combine it with a larger set of the C++ standard library. So this changeset is mainly about broadening the usability of these types.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12140#issuecomment-1410407239
Usability,usab,usability,"> Can you elaborate a bit: what is the purpose of this change or the benefits/changes to the code using views?. Sure, `RNTupleGlobalRange` and `RNTupleClusterRange` before this PR are defined as forward ranges. So they can basically be used in a range-for loop and for STL algorithms, but they will use slower versions in some cases, because of the less capable iterator category. A good example is that `std::distance(globalRange.begin(), globalRange.end())` unnecessarily has linear complexity, although it could easility be constant. This effects us a lot as well for the parallel STL. E.g. spanning a parallel index space:; ```c++; std::for_each(std::execution::par, globalRange.begin(), globalRange.end(), [](NTupleSize_t i) { ... });; ```; This has unnecessary complex setup time, because partitioning the index space has linear complexity due to the iterator category. The support for C++20 ranges is orthogonal to these usuability improvements, but should fall out for free. Allowing the refactored types to be used with ranges is just a cherry-on-top to allow the client using the RNTuple API to combine it with a larger set of the C++ standard library. So this changeset is mainly about broadening the usability of these types.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12140#issuecomment-1410407239
Usability,clear,clear,"Well not quite, it broke clean builds on the `master` branch on basically all platforms... Not clear why, investigating.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12149#issuecomment-1661811809
Usability,clear,clear,"> Well not quite, it broke clean builds on the `master` branch on basically all platforms... Not clear why, investigating. Where did you see that?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12149#issuecomment-1661819517
Security,access,access,It is really simple to check what gets linked in with a debugger if you have the setup done already. If I can get ssh access to a node somewhere I can do that.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12156#issuecomment-1665604004
Usability,simpl,simple,It is really simple to check what gets linked in with a debugger if you have the setup done already. If I can get ssh access to a node somewhere I can do that.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12156#issuecomment-1665604004
Modifiability,config,config,"> It is really simple to check what gets linked in with a debugger if you have the setup done already. If I can get ssh access to a node somewhere I can do that. Unfortunately I don't have a public instance where you get ssh into. I created a simple example that links against ROOT and a different LLVM version, that worked without issue. While doing that I noticed that by default everything is linked using the static libraries from LLVM. This is probably what we want?. In `llvm-config`, one needs to pass `--link-static`, and that's about it. Will try it...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12156#issuecomment-1666915077
Security,access,access,"> It is really simple to check what gets linked in with a debugger if you have the setup done already. If I can get ssh access to a node somewhere I can do that. Unfortunately I don't have a public instance where you get ssh into. I created a simple example that links against ROOT and a different LLVM version, that worked without issue. While doing that I noticed that by default everything is linked using the static libraries from LLVM. This is probably what we want?. In `llvm-config`, one needs to pass `--link-static`, and that's about it. Will try it...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12156#issuecomment-1666915077
Usability,simpl,simple,"> It is really simple to check what gets linked in with a debugger if you have the setup done already. If I can get ssh access to a node somewhere I can do that. Unfortunately I don't have a public instance where you get ssh into. I created a simple example that links against ROOT and a different LLVM version, that worked without issue. While doing that I noticed that by default everything is linked using the static libraries from LLVM. This is probably what we want?. In `llvm-config`, one needs to pass `--link-static`, and that's about it. Will try it...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12156#issuecomment-1666915077
Modifiability,config,config,"> I noticed that by default everything is linked using the static libraries from LLVM. As I [said](https://github.com/root-project/root/issues/12156#issuecomment-1662255320):; > if we link the static libraries we don't want to *also* link the shared library. And we prefer static libs. And what you suggest:; > In `llvm-config`, one needs to pass `--link-static`, and that's about it. Will try it... sounds both plausible and simple :-) Let us know, please!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12156#issuecomment-1666916384
Usability,simpl,simple,"> I noticed that by default everything is linked using the static libraries from LLVM. As I [said](https://github.com/root-project/root/issues/12156#issuecomment-1662255320):; > if we link the static libraries we don't want to *also* link the shared library. And we prefer static libs. And what you suggest:; > In `llvm-config`, one needs to pass `--link-static`, and that's about it. Will try it... sounds both plausible and simple :-) Let us know, please!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12156#issuecomment-1666916384
Modifiability,config,config,"> sounds both plausible and simple :-) Let us know, please!. I struggle a bit to find out exactly where CMake gets the LLVM library, unfortunately it doesn't look like it uses `llvm-config --libs`...; Will look around though",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12156#issuecomment-1666920625
Usability,simpl,simple,"> sounds both plausible and simple :-) Let us know, please!. I struggle a bit to find out exactly where CMake gets the LLVM library, unfortunately it doesn't look like it uses `llvm-config --libs`...; Will look around though",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12156#issuecomment-1666920625
Deployability,install,installed,"Found it! As it turns out, it is a ""simple"" 2 line fix:; https://github.com/stephanlachnit/root/commit/65ae229c6ba458c610f0a41d32b798a132f385e4. We need to set `LLVM_LINK_LLVM_DYLIB=OFF` for clang, this will prefer static libs. The only disadvantage is that links against *all* LLVM libraries, which means additionally dependencies might need to be installed. In particular LLVM 16 is broken due to https://github.com/llvm/llvm-project/issues/62300.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12156#issuecomment-1666954709
Integrability,depend,dependencies,"Found it! As it turns out, it is a ""simple"" 2 line fix:; https://github.com/stephanlachnit/root/commit/65ae229c6ba458c610f0a41d32b798a132f385e4. We need to set `LLVM_LINK_LLVM_DYLIB=OFF` for clang, this will prefer static libs. The only disadvantage is that links against *all* LLVM libraries, which means additionally dependencies might need to be installed. In particular LLVM 16 is broken due to https://github.com/llvm/llvm-project/issues/62300.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12156#issuecomment-1666954709
Usability,simpl,simple,"Found it! As it turns out, it is a ""simple"" 2 line fix:; https://github.com/stephanlachnit/root/commit/65ae229c6ba458c610f0a41d32b798a132f385e4. We need to set `LLVM_LINK_LLVM_DYLIB=OFF` for clang, this will prefer static libs. The only disadvantage is that links against *all* LLVM libraries, which means additionally dependencies might need to be installed. In particular LLVM 16 is broken due to https://github.com/llvm/llvm-project/issues/62300.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12156#issuecomment-1666954709
Usability,simpl,simple,"> Found it! As it turns out, it is a ""simple"" 2 line fix: [stephanlachnit@65ae229](https://github.com/stephanlachnit/root/commit/65ae229c6ba458c610f0a41d32b798a132f385e4); > ; > We need to set `LLVM_LINK_LLVM_DYLIB=OFF` for clang, this will prefer static libs. I'm surprised that this helps. I remember trying using a static-only build of LLVM to fix this with no success.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12156#issuecomment-1668344363
Modifiability,variab,variable,"It's understood; Lorenzo will find a workaround for 6.28/00. We will still need to solve the underlying issue, but with lower urgency. The issue is with llvm-IR using non-unique symbol names for the function-local constants, and re-using the already emitted symbols in subsequent modules (due to cling's ""private"" => ""weak"" symbol rewriting). A simple workaround is to use different variable names for the function-local constants.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12164#issuecomment-1410380142
Usability,simpl,simple,"It's understood; Lorenzo will find a workaround for 6.28/00. We will still need to solve the underlying issue, but with lower urgency. The issue is with llvm-IR using non-unique symbol names for the function-local constants, and re-using the already emitted symbols in subsequent modules (due to cling's ""private"" => ""weak"" symbol rewriting). A simple workaround is to use different variable names for the function-local constants.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12164#issuecomment-1410380142
Usability,simpl,simple,"This is another simple reproducible example: ; ```; #include <iostream>; #include <vector>. void Dummy(const std::vector<size_t> & targetShape) {; std::cout << ""target shape "";; for (size_t i = 0; i < targetShape.size(); i++) std::cout << targetShape[i] << "" "";; std::cout << std::endl;; }. struct Test1 {; Test1() {; Dummy({ 1 , 2 , 3, 4 });; }; };. struct Test2 {; Test2() {; Dummy({ 5 , 6 , 7});; }. };",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12164#issuecomment-1410442720
Usability,clear,clear,"Hello, I can do that. Just to be clear, that applies only to RooEffGenContex.h and cxx, right? Not RooRealIntegral.cxx, which would change a lot with the ROOT format",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12178#issuecomment-1410285135
Modifiability,variab,variable,"I can't identify the problem either. But there is a simple workaround: you can just use `TPython::Exec()` and bring the string to the C++ world with an output variable. In the interest of a more stable ROOT, I would suggest to promote this way of doing things and to to deprecate `TPython::Eval()`:. * https://github.com/root-project/root/pull/16175. Would this be a good way forward also for ATLAS?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12182#issuecomment-2270986830
Usability,simpl,simple,"I can't identify the problem either. But there is a simple workaround: you can just use `TPython::Exec()` and bring the string to the C++ world with an output variable. In the interest of a more stable ROOT, I would suggest to promote this way of doing things and to to deprecate `TPython::Eval()`:. * https://github.com/root-project/root/pull/16175. Would this be a good way forward also for ATLAS?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12182#issuecomment-2270986830
Usability,clear,clearing,"Build failed on ROOT-ubuntu2204/cxx17.; Running on root-ubuntu-2204-2.cern.ch:/home/sftnight/build/workspace/root-pullrequests-build; [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/166598/console).; ### Warnings:; - [2023-02-01T13:46:58.435Z] /home/sftnight/build/workspace/root-pullrequests-build/build/include/tbb/concurrent_hash_map.h:131:24: warning: void* memset(void*, int, size_t) clearing an object of type struct tbb::interface5::internal::hash_map_base::bucket with no trivial copy-assignment; use value-initialization instead [-Wclass-memaccess]",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12187#issuecomment-1412117260
Usability,simpl,simple,"Do we need to keep the credential file around during the time that the build happens? Or can we delay the creation of this file until after the build? Or remove it before the build starts? I understand that the CI workflow can be maliciously changed - but a change to the CI workflow is a very visible change, more than a simple addition of `print some credential file` as part of the build system...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12201#issuecomment-1412357738
Availability,avail,available,"> Do we need to keep the credential file around during the time that the build happens? Or can we delay the creation of this file until after the build? Or remove it before the build starts? I understand that the CI workflow can be maliciously changed - but a change to the CI workflow is a very visible change, more than a simple addition of `print some credential file` as part of the build system... You're saying that having the file available at certain steps such as in the workflow definition and right before uploading is managable but that that it should be unavailable while e.g. cmake is running?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12201#issuecomment-1412402025
Usability,simpl,simple,"> Do we need to keep the credential file around during the time that the build happens? Or can we delay the creation of this file until after the build? Or remove it before the build starts? I understand that the CI workflow can be maliciously changed - but a change to the CI workflow is a very visible change, more than a simple addition of `print some credential file` as part of the build system... You're saying that having the file available at certain steps such as in the workflow definition and right before uploading is managable but that that it should be unavailable while e.g. cmake is running?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12201#issuecomment-1412402025
Integrability,wrap,wrapper,"@guitargeek While addressing your comments, I started thinking that there's perhaps a better design. 1. I don't think we should have a default parameter at all, but only one ctor with the offset parameters. In real life current cases, these classes are always used from MinuitFcnGrad and they always share offsets with one or two other Likelihood* objects. The only cases where no shared offsets are necessary is in unit tests, but in those cases it's easy to just create a dummy offset vector.; 2. All the offset management is distracting a bit from the core Likelihood logic. I think it may be nicer to make a simple wrapper class `LikelihoodOffset` that holds the shared_ptrs to the vectors, does the swapping, and a few other things. This also makes it easier to create, because the unwieldy types that you also rightly point out would then only be contained within `LikelihoodOffset`. I will start working on point 1 at least, and in the meantime will consider (and allow you to comment on ;) ) point 2.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12202#issuecomment-2091419386
Testability,test,tests,"@guitargeek While addressing your comments, I started thinking that there's perhaps a better design. 1. I don't think we should have a default parameter at all, but only one ctor with the offset parameters. In real life current cases, these classes are always used from MinuitFcnGrad and they always share offsets with one or two other Likelihood* objects. The only cases where no shared offsets are necessary is in unit tests, but in those cases it's easy to just create a dummy offset vector.; 2. All the offset management is distracting a bit from the core Likelihood logic. I think it may be nicer to make a simple wrapper class `LikelihoodOffset` that holds the shared_ptrs to the vectors, does the swapping, and a few other things. This also makes it easier to create, because the unwieldy types that you also rightly point out would then only be contained within `LikelihoodOffset`. I will start working on point 1 at least, and in the meantime will consider (and allow you to comment on ;) ) point 2.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12202#issuecomment-2091419386
Usability,simpl,simple,"@guitargeek While addressing your comments, I started thinking that there's perhaps a better design. 1. I don't think we should have a default parameter at all, but only one ctor with the offset parameters. In real life current cases, these classes are always used from MinuitFcnGrad and they always share offsets with one or two other Likelihood* objects. The only cases where no shared offsets are necessary is in unit tests, but in those cases it's easy to just create a dummy offset vector.; 2. All the offset management is distracting a bit from the core Likelihood logic. I think it may be nicer to make a simple wrapper class `LikelihoodOffset` that holds the shared_ptrs to the vectors, does the swapping, and a few other things. This also makes it easier to create, because the unwieldy types that you also rightly point out would then only be contained within `LikelihoodOffset`. I will start working on point 1 at least, and in the meantime will consider (and allow you to comment on ;) ) point 2.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12202#issuecomment-2091419386
Deployability,rolling,rolling,"Thanks for your report! I think much of this would cause churn without much benefit on the users' side: they would simply hate us for littering them with deprecation warnings that they just don't care about. Instead, we moved away from these types in new code (RDataFrame, RNTuple, etc); new tutorials are also just using standard types. I don't know whether anything but this will be constructive / productive enough. What are your thoughts?. I'd certainly like to use std features for the underlying types / values for what's in Rtypes as much as possible, instead of rolling out own. But that seems orthogonal.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12208#issuecomment-1413764933
Usability,simpl,simply,"Thanks for your report! I think much of this would cause churn without much benefit on the users' side: they would simply hate us for littering them with deprecation warnings that they just don't care about. Instead, we moved away from these types in new code (RDataFrame, RNTuple, etc); new tutorials are also just using standard types. I don't know whether anything but this will be constructive / productive enough. What are your thoughts?. I'd certainly like to use std features for the underlying types / values for what's in Rtypes as much as possible, instead of rolling out own. But that seems orthogonal.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12208#issuecomment-1413764933
Usability,clear,clearing,"Build failed on ROOT-ubuntu2204/cxx17.; Running on root-ubuntu-2204-2.cern.ch:/home/sftnight/build/workspace/root-pullrequests-build; [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/166784/console).; ### Warnings:; - [2023-02-02T16:04:19.482Z] /home/sftnight/build/workspace/root-pullrequests-build/build/include/tbb/concurrent_hash_map.h:131:24: warning: void* memset(void*, int, size_t) clearing an object of type struct tbb::interface5::internal::hash_map_base::bucket with no trivial copy-assignment; use value-initialization instead [-Wclass-memaccess]",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12211#issuecomment-1414055652
Integrability,message,message,The commit message seems pretty clear to me. Can you suggest something?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276#issuecomment-1427114379
Usability,clear,clear,The commit message seems pretty clear to me. Can you suggest something?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276#issuecomment-1427114379
Availability,failure,failure,"Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it!. Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:; ```; That should fix a recent nightly failure with gcc11 avoiding to require; module ""bits/ranges_base.h"" in C++20 context.; ```. does not call out; - that it's during dictionary generation; - that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17); - that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers); - the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276#issuecomment-1429251757
Deployability,update,update,"Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it!. Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:; ```; That should fix a recent nightly failure with gcc11 avoiding to require; module ""bits/ranges_base.h"" in C++20 context.; ```. does not call out; - that it's during dictionary generation; - that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17); - that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers); - the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276#issuecomment-1429251757
Integrability,message,message,"Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it!. Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:; ```; That should fix a recent nightly failure with gcc11 avoiding to require; module ""bits/ranges_base.h"" in C++20 context.; ```. does not call out; - that it's during dictionary generation; - that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17); - that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers); - the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276#issuecomment-1429251757
Safety,avoid,avoiding,"Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it!. Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:; ```; That should fix a recent nightly failure with gcc11 avoiding to require; module ""bits/ranges_base.h"" in C++20 context.; ```. does not call out; - that it's during dictionary generation; - that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17); - that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers); - the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276#issuecomment-1429251757
Testability,log,log,"Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it!. Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:; ```; That should fix a recent nightly failure with gcc11 avoiding to require; module ""bits/ranges_base.h"" in C++20 context.; ```. does not call out; - that it's during dictionary generation; - that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17); - that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers); - the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276#issuecomment-1429251757
Usability,simpl,simply,"Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it!. Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:; ```; That should fix a recent nightly failure with gcc11 avoiding to require; module ""bits/ranges_base.h"" in C++20 context.; ```. does not call out; - that it's during dictionary generation; - that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17); - that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers); - the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276#issuecomment-1429251757
Availability,failure,failure,"> Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it!; > ; > Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:; > ; > ```; > That should fix a recent nightly failure with gcc11 avoiding to require; > module ""bits/ranges_base.h"" in C++20 context.; > ```; > ; > does not call out; > ; > * that it's during dictionary generation; > ; > * that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17); > ; > * that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers); > ; > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`; > ; > ; > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?); > ; > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the exp",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276#issuecomment-1430019305
Deployability,update,update,"emap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17); > ; > * that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers); > ; > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`; > ; > ; > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?); > ; > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). I am not sure if pasting a diagnostic from a random system makes this clearer in any form. I agree with you this should have be 1 min review fixing an important failure that we introduced with the c++20 support and some of the new releases of maybe libstdc++. @pcanal I find pasting errors in the logs a bad practice, especially when it obfuscates the real fix. Can you suggest a commit message which adds enough information which makes me happy as well?. In general it is a bit unfortunate how the whole review went fo",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276#issuecomment-1430019305
Integrability,message,message,"> Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it!; > ; > Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:; > ; > ```; > That should fix a recent nightly failure with gcc11 avoiding to require; > module ""bits/ranges_base.h"" in C++20 context.; > ```; > ; > does not call out; > ; > * that it's during dictionary generation; > ; > * that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17); > ; > * that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers); > ; > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`; > ; > ; > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?); > ; > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the exp",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276#issuecomment-1430019305
Safety,avoid,avoiding,"> Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it!; > ; > Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:; > ; > ```; > That should fix a recent nightly failure with gcc11 avoiding to require; > module ""bits/ranges_base.h"" in C++20 context.; > ```; > ; > does not call out; > ; > * that it's during dictionary generation; > ; > * that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17); > ; > * that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers); > ; > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`; > ; > ; > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?); > ; > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the exp",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276#issuecomment-1430019305
Testability,log,log,"> Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it!; > ; > Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:; > ; > ```; > That should fix a recent nightly failure with gcc11 avoiding to require; > module ""bits/ranges_base.h"" in C++20 context.; > ```; > ; > does not call out; > ; > * that it's during dictionary generation; > ; > * that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17); > ; > * that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers); > ; > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`; > ; > ; > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?); > ; > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the exp",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276#issuecomment-1430019305
Usability,simpl,simply,"our message seems to suggest that it's only with GCC11 headers); > ; > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`; > ; > ; > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?); > ; > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). I am not sure if pasting a diagnostic from a random system makes this clearer in any form. I agree with you this should have be 1 min review fixing an important failure that we introduced with the c++20 support and some of the new releases of maybe libstdc++. @pcanal I find pasting errors in the logs a bad practice, especially when it obfuscates the real fix. Can you suggest a commit message which adds enough information which makes me happy as well?. In general it is a bit unfortunate how the whole review went for this PR. This should been just a simple ""approve"" as I thought we needed a quick fix which I developed in between travels and a business trip... I suspect this would help me define urgent/important in similar circumstances in future...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276#issuecomment-1430019305
Availability,failure,failure,"@vgvassilev Let me clarify the disconnect. The title says ""Add **a** module for experimental/string_view""; The commit says:. That should fix a recent nightly failure with gcc11 avoiding to require; module ""bits/ranges_base.h"" in C++20 context. The code says:; ```; module ""experimental/string_view"" {; export *; header ""experimental/algorithm""; }; ```; ; The commit content as-is seems completely unrelated to the commit log as far as I could tell (without doing research on the relationship between `range_base`, `string_view` and `algorithm`.; ; So I pondered whether the fix was the right fix for a problem I did not know anything about ... ; ; The right thing to do would have probably be have been to request a complete explanation of what the original problem was, what was the mechanism leading to the error and why this solution was the best solution. This was obviously much more than this seemingly simple fix required. So instead I thought to ask for a very low cost, straight forward solution: simply copy/pasting the error with no additional effort to explain in detail. > Can you suggest a commit message which adds enough information which makes me happy as well?. That requires to paraphrase the error and add a few more details. ```; That should fix a recent nightly failure with gcc11. The failure presented during dictionary generation in a C++14 and C++17 build and incorrectly complained about needing the 'cplusplus20' feature for the 'std.bits/ranges_base.h' module. The issue was triggered by an inclusion of `<bits/ranges_base.h>` from `string_view`. This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). . It seems the issue is solved by exporting `algorithm` as part of the `string_view` module.; ```. Actually, I still don't know why adding `algorithm` fixes a problem with `range_base.h`, so I can't add that to the commit ... maybe it is something like ""... by avoiding to use the module m",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276#issuecomment-1430326540
Integrability,message,message,"says ""Add **a** module for experimental/string_view""; The commit says:. That should fix a recent nightly failure with gcc11 avoiding to require; module ""bits/ranges_base.h"" in C++20 context. The code says:; ```; module ""experimental/string_view"" {; export *; header ""experimental/algorithm""; }; ```; ; The commit content as-is seems completely unrelated to the commit log as far as I could tell (without doing research on the relationship between `range_base`, `string_view` and `algorithm`.; ; So I pondered whether the fix was the right fix for a problem I did not know anything about ... ; ; The right thing to do would have probably be have been to request a complete explanation of what the original problem was, what was the mechanism leading to the error and why this solution was the best solution. This was obviously much more than this seemingly simple fix required. So instead I thought to ask for a very low cost, straight forward solution: simply copy/pasting the error with no additional effort to explain in detail. > Can you suggest a commit message which adds enough information which makes me happy as well?. That requires to paraphrase the error and add a few more details. ```; That should fix a recent nightly failure with gcc11. The failure presented during dictionary generation in a C++14 and C++17 build and incorrectly complained about needing the 'cplusplus20' feature for the 'std.bits/ranges_base.h' module. The issue was triggered by an inclusion of `<bits/ranges_base.h>` from `string_view`. This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). . It seems the issue is solved by exporting `algorithm` as part of the `string_view` module.; ```. Actually, I still don't know why adding `algorithm` fixes a problem with `range_base.h`, so I can't add that to the commit ... maybe it is something like ""... by avoiding to use the module maps provided by the standard library in those case""?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276#issuecomment-1430326540
Safety,avoid,avoiding,"@vgvassilev Let me clarify the disconnect. The title says ""Add **a** module for experimental/string_view""; The commit says:. That should fix a recent nightly failure with gcc11 avoiding to require; module ""bits/ranges_base.h"" in C++20 context. The code says:; ```; module ""experimental/string_view"" {; export *; header ""experimental/algorithm""; }; ```; ; The commit content as-is seems completely unrelated to the commit log as far as I could tell (without doing research on the relationship between `range_base`, `string_view` and `algorithm`.; ; So I pondered whether the fix was the right fix for a problem I did not know anything about ... ; ; The right thing to do would have probably be have been to request a complete explanation of what the original problem was, what was the mechanism leading to the error and why this solution was the best solution. This was obviously much more than this seemingly simple fix required. So instead I thought to ask for a very low cost, straight forward solution: simply copy/pasting the error with no additional effort to explain in detail. > Can you suggest a commit message which adds enough information which makes me happy as well?. That requires to paraphrase the error and add a few more details. ```; That should fix a recent nightly failure with gcc11. The failure presented during dictionary generation in a C++14 and C++17 build and incorrectly complained about needing the 'cplusplus20' feature for the 'std.bits/ranges_base.h' module. The issue was triggered by an inclusion of `<bits/ranges_base.h>` from `string_view`. This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). . It seems the issue is solved by exporting `algorithm` as part of the `string_view` module.; ```. Actually, I still don't know why adding `algorithm` fixes a problem with `range_base.h`, so I can't add that to the commit ... maybe it is something like ""... by avoiding to use the module m",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276#issuecomment-1430326540
Testability,log,log,"@vgvassilev Let me clarify the disconnect. The title says ""Add **a** module for experimental/string_view""; The commit says:. That should fix a recent nightly failure with gcc11 avoiding to require; module ""bits/ranges_base.h"" in C++20 context. The code says:; ```; module ""experimental/string_view"" {; export *; header ""experimental/algorithm""; }; ```; ; The commit content as-is seems completely unrelated to the commit log as far as I could tell (without doing research on the relationship between `range_base`, `string_view` and `algorithm`.; ; So I pondered whether the fix was the right fix for a problem I did not know anything about ... ; ; The right thing to do would have probably be have been to request a complete explanation of what the original problem was, what was the mechanism leading to the error and why this solution was the best solution. This was obviously much more than this seemingly simple fix required. So instead I thought to ask for a very low cost, straight forward solution: simply copy/pasting the error with no additional effort to explain in detail. > Can you suggest a commit message which adds enough information which makes me happy as well?. That requires to paraphrase the error and add a few more details. ```; That should fix a recent nightly failure with gcc11. The failure presented during dictionary generation in a C++14 and C++17 build and incorrectly complained about needing the 'cplusplus20' feature for the 'std.bits/ranges_base.h' module. The issue was triggered by an inclusion of `<bits/ranges_base.h>` from `string_view`. This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). . It seems the issue is solved by exporting `algorithm` as part of the `string_view` module.; ```. Actually, I still don't know why adding `algorithm` fixes a problem with `range_base.h`, so I can't add that to the commit ... maybe it is something like ""... by avoiding to use the module m",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276#issuecomment-1430326540
Usability,simpl,simple,"@vgvassilev Let me clarify the disconnect. The title says ""Add **a** module for experimental/string_view""; The commit says:. That should fix a recent nightly failure with gcc11 avoiding to require; module ""bits/ranges_base.h"" in C++20 context. The code says:; ```; module ""experimental/string_view"" {; export *; header ""experimental/algorithm""; }; ```; ; The commit content as-is seems completely unrelated to the commit log as far as I could tell (without doing research on the relationship between `range_base`, `string_view` and `algorithm`.; ; So I pondered whether the fix was the right fix for a problem I did not know anything about ... ; ; The right thing to do would have probably be have been to request a complete explanation of what the original problem was, what was the mechanism leading to the error and why this solution was the best solution. This was obviously much more than this seemingly simple fix required. So instead I thought to ask for a very low cost, straight forward solution: simply copy/pasting the error with no additional effort to explain in detail. > Can you suggest a commit message which adds enough information which makes me happy as well?. That requires to paraphrase the error and add a few more details. ```; That should fix a recent nightly failure with gcc11. The failure presented during dictionary generation in a C++14 and C++17 build and incorrectly complained about needing the 'cplusplus20' feature for the 'std.bits/ranges_base.h' module. The issue was triggered by an inclusion of `<bits/ranges_base.h>` from `string_view`. This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). . It seems the issue is solved by exporting `algorithm` as part of the `string_view` module.; ```. Actually, I still don't know why adding `algorithm` fixes a problem with `range_base.h`, so I can't add that to the commit ... maybe it is something like ""... by avoiding to use the module m",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276#issuecomment-1430326540
Usability,simpl,simply,Thank you for the fix! ; It appears that while forcing the use of `RooFoamGenerator` I simply skipped that code path...,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12286#issuecomment-1425901083
Integrability,message,messages,"I tried to reproduce this issue with the following C++ script:; ```; void nan(){; auto g = new TGraph ();; g->AddPoint(0,TMath::QuietNaN());; g->AddPoint(1,TMath::QuietNaN());; g->AddPoint(2,TMath::QuietNaN());; g->AddPoint(3,TMath::QuietNaN());; g->AddPoint(4,TMath::QuietNaN());; g->Draw(""APL"");; }; ```; Like you it gives me a blank canvas but in parallel, I get the following messages in the terminal output:; ```; root [0] ; Processing nan.C...; Info in <TCanvas::MakeDefCanvas>: created default TCanvas with name c1; Warning in <TCanvas::ResizePad>: Inf/NaN propagated to the pad. Check drawn objects.; Warning in <TCanvas::ResizePad>: c1 height changed from 0 to 10; ``` ; So it is pretty clear that there NaNs in the data. ; The message even invites the user to check the ""drawn objects"". I do not think we can do more than that.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12296#issuecomment-1431275163
Usability,clear,clear,"I tried to reproduce this issue with the following C++ script:; ```; void nan(){; auto g = new TGraph ();; g->AddPoint(0,TMath::QuietNaN());; g->AddPoint(1,TMath::QuietNaN());; g->AddPoint(2,TMath::QuietNaN());; g->AddPoint(3,TMath::QuietNaN());; g->AddPoint(4,TMath::QuietNaN());; g->Draw(""APL"");; }; ```; Like you it gives me a blank canvas but in parallel, I get the following messages in the terminal output:; ```; root [0] ; Processing nan.C...; Info in <TCanvas::MakeDefCanvas>: created default TCanvas with name c1; Warning in <TCanvas::ResizePad>: Inf/NaN propagated to the pad. Check drawn objects.; Warning in <TCanvas::ResizePad>: c1 height changed from 0 to 10; ``` ; So it is pretty clear that there NaNs in the data. ; The message even invites the user to check the ""drawn objects"". I do not think we can do more than that.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12296#issuecomment-1431275163
Availability,failure,failures,"Right - @smuzaffar was quite clear that we should separate build failures from test failures. But we now fail for build failures, too, so maybe including test failures in the failed state makes sense? Anyway, just pinging @smuzaffar for his recommendation + arguments before we decide what to do here!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307#issuecomment-1542423864
Testability,test,test,"Right - @smuzaffar was quite clear that we should separate build failures from test failures. But we now fail for build failures, too, so maybe including test failures in the failed state makes sense? Anyway, just pinging @smuzaffar for his recommendation + arguments before we decide what to do here!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307#issuecomment-1542423864
Usability,clear,clear,"Right - @smuzaffar was quite clear that we should separate build failures from test failures. But we now fail for build failures, too, so maybe including test failures in the failed state makes sense? Anyway, just pinging @smuzaffar for his recommendation + arguments before we decide what to do here!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307#issuecomment-1542423864
Integrability,message,messages,"Well, that argument would apply to 95 % percent of the classes in ROOT then :D Users that are adventurous to use this probably also know about C++ ownership. I personally don't think the added complexity and less clear ownership when using `shared_ptr` + `weak_ptr` is justified in this case. I think `shared_ptr` should only be used when there are really shared resources in the implementation details, not as a general solution to prevent the user from making memory management mistakes. As you say, it gives also mixed messages on how to manage the resources. Would you be okay with leaving it like this for now? We can always revisit this if need be...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12348#issuecomment-1439898961
Usability,clear,clear,"Well, that argument would apply to 95 % percent of the classes in ROOT then :D Users that are adventurous to use this probably also know about C++ ownership. I personally don't think the added complexity and less clear ownership when using `shared_ptr` + `weak_ptr` is justified in this case. I think `shared_ptr` should only be used when there are really shared resources in the implementation details, not as a general solution to prevent the user from making memory management mistakes. As you say, it gives also mixed messages on how to manage the resources. Would you be okay with leaving it like this for now? We can always revisit this if need be...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12348#issuecomment-1439898961
Usability,simpl,simplify,"I add commit to fix compiler warning and simplify a bit code.; @couet, can I merge it?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12349#issuecomment-1479066603
Usability,simpl,simply,"> I don't think `#if __arm64__` will work. Should be `#ifdef __aarch64__`. Oh yes, my bad, I simply copied from the line above which is for Apple / macOS. Thanks for catching, fixing, and confirming that the approach works. Then we can merge this and backport for 6.28/02 :smiley:",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12353#issuecomment-1437462950
Deployability,update,updated,"Thank you so much @eguiraud for the comments! I have addressed all of them and updated the commits accordingly, also splitting them in smaller commits to make intentions clearer. New tests are still missing, but I would appreciate if you could take another look. In particular, these changes hopefully streamline the code a bit:; * `rdf_uuid`: this was previously not well named, since we need something that contains both an identifier for the current RDataFrame instance and also one for the current (distributed) execution of that RDataFrame (e.g. to separate to consecutive triggers of the computation graph). I have added the type `ExecutionIdentifier` that holds both. This class is now used everywhere (in Ranges.py, HeadNode.py) and should improve readability.; * I merged `CloneResultPtr` and `CloneResultMap` into `CloneResultAndAction`. This helps making the logic in DistRDF more simple (i.e. is what allows the usage of `singledispatch` to distinguish different ways of cloning actions of the distributed computation graph).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363#issuecomment-1581162133
Testability,test,tests,"Thank you so much @eguiraud for the comments! I have addressed all of them and updated the commits accordingly, also splitting them in smaller commits to make intentions clearer. New tests are still missing, but I would appreciate if you could take another look. In particular, these changes hopefully streamline the code a bit:; * `rdf_uuid`: this was previously not well named, since we need something that contains both an identifier for the current RDataFrame instance and also one for the current (distributed) execution of that RDataFrame (e.g. to separate to consecutive triggers of the computation graph). I have added the type `ExecutionIdentifier` that holds both. This class is now used everywhere (in Ranges.py, HeadNode.py) and should improve readability.; * I merged `CloneResultPtr` and `CloneResultMap` into `CloneResultAndAction`. This helps making the logic in DistRDF more simple (i.e. is what allows the usage of `singledispatch` to distinguish different ways of cloning actions of the distributed computation graph).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363#issuecomment-1581162133
Usability,clear,clearer,"Thank you so much @eguiraud for the comments! I have addressed all of them and updated the commits accordingly, also splitting them in smaller commits to make intentions clearer. New tests are still missing, but I would appreciate if you could take another look. In particular, these changes hopefully streamline the code a bit:; * `rdf_uuid`: this was previously not well named, since we need something that contains both an identifier for the current RDataFrame instance and also one for the current (distributed) execution of that RDataFrame (e.g. to separate to consecutive triggers of the computation graph). I have added the type `ExecutionIdentifier` that holds both. This class is now used everywhere (in Ranges.py, HeadNode.py) and should improve readability.; * I merged `CloneResultPtr` and `CloneResultMap` into `CloneResultAndAction`. This helps making the logic in DistRDF more simple (i.e. is what allows the usage of `singledispatch` to distinguish different ways of cloning actions of the distributed computation graph).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363#issuecomment-1581162133
Availability,failure,failure,"Added tests for the C++ mechanisms, and attempt at fixing the ubuntu18 failure (see last commit) with a much more simplified approach w.r.t. https://github.com/root-project/root/pull/12981, which should not be needed anymore (let's see what the CI thinks).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363#issuecomment-1585596942
Testability,test,tests,"Added tests for the C++ mechanisms, and attempt at fixing the ubuntu18 failure (see last commit) with a much more simplified approach w.r.t. https://github.com/root-project/root/pull/12981, which should not be needed anymore (let's see what the CI thinks).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363#issuecomment-1585596942
Usability,simpl,simplified,"Added tests for the C++ mechanisms, and attempt at fixing the ubuntu18 failure (see last commit) with a much more simplified approach w.r.t. https://github.com/root-project/root/pull/12981, which should not be needed anymore (let's see what the CI thinks).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363#issuecomment-1585596942
Deployability,install,installed,"Hi @bsunanda ,; Can you provide a simple reproducer of your case? Together with some information about your system (how you installed ROOT etc., compiler version etc.)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370#issuecomment-1443741367
Usability,simpl,simple,"Hi @bsunanda ,; Can you provide a simple reproducer of your case? Together with some information about your system (how you installed ROOT etc., compiler version etc.)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370#issuecomment-1443741367
Testability,test,test,"Hi Marcin,. That worked and did some progress in understanding the problem. A potential work-around would be requested the dictionary for the 2 level of namespace/struct that contains the typedef (in the same dictionary). In order to test any solution to the problem I still need a standalone reproducer and I am still having some difficulties. In particular in my attempts to reproduce the dictionary generation the typedef does not appear in the dictionary nor in the rootmap file. Weirder even, when I follow the [instructions](https://atlassoftwaredocs.web.cern.ch/guides/build_release/) to build Athena from scratch (on zeus.lbl.gov; done a couple of weeks ago), I get a different rootmap file (however because the build is currently (for other reason) partially broken I did not try with it):; ```; grep jetlink_t ../atlas_working/build/build/Athena/_CPack_Packages/Linux/RPM/Athena_23.0.17_x86_64-centos7-gcc11-opt/usr/Athena/23.0.17/InstallArea/x86_64-centos7-gcc11-opt/lib/Athena.rootmap; ```; vs; ```; grep jetlink_t /cvmfs/atlas-nightlies.cern.ch/repo/sw/master_Athena_x86_64-centos7-gcc11-opt/2023-03-05T2101/Athena/23.0.20/InstallArea/x86_64-centos7-gcc11-opt/lib/Athena.rootmap; typedef MissingETBase::Types::jetlink_t; ```. So I am not sure what I am doing different in my reproducer and in my local Athena.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12378#issuecomment-1462615809
Usability,guid,guides,"Hi Marcin,. That worked and did some progress in understanding the problem. A potential work-around would be requested the dictionary for the 2 level of namespace/struct that contains the typedef (in the same dictionary). In order to test any solution to the problem I still need a standalone reproducer and I am still having some difficulties. In particular in my attempts to reproduce the dictionary generation the typedef does not appear in the dictionary nor in the rootmap file. Weirder even, when I follow the [instructions](https://atlassoftwaredocs.web.cern.ch/guides/build_release/) to build Athena from scratch (on zeus.lbl.gov; done a couple of weeks ago), I get a different rootmap file (however because the build is currently (for other reason) partially broken I did not try with it):; ```; grep jetlink_t ../atlas_working/build/build/Athena/_CPack_Packages/Linux/RPM/Athena_23.0.17_x86_64-centos7-gcc11-opt/usr/Athena/23.0.17/InstallArea/x86_64-centos7-gcc11-opt/lib/Athena.rootmap; ```; vs; ```; grep jetlink_t /cvmfs/atlas-nightlies.cern.ch/repo/sw/master_Athena_x86_64-centos7-gcc11-opt/2023-03-05T2101/Athena/23.0.20/InstallArea/x86_64-centos7-gcc11-opt/lib/Athena.rootmap; typedef MissingETBase::Types::jetlink_t; ```. So I am not sure what I am doing different in my reproducer and in my local Athena.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12378#issuecomment-1462615809
Availability,down,down,"I agree that it is an unfortunate circumstance to have the test not passing. However, I still urge you to consider the effect on debugability removing strict tests will have. I have wasted a lot of time trying to track down a subtle bug due to loose tests which left me unable to determine where the bug came from. Conversely, setting tests strictly and tracing discrepancies, I found a different bug in the Kahan sum: #11940. Unit tests especially should be as strict as possible. In absence of unit tests (which unfortunately is the case for the parts of RooFit I worked on), strict ""integration"" tests like these are the closest I could get. Note also that it was simply part of my original assignment: to ensure users can trust the new parallelized methods, I built them to be bit-wise exactly equal to the old methods. So, I know from experience how tedious it is to trace down these bit-wise differences to their actual concrete source, but also think that because we are dealing with scientific software, precision, robustness, reliability and interpretability (of components and hence the whole) are important. Of course, performance is an important factor too, but it's just one of the aspects. We want the end-results of experiments to be accurate and explainable, right? I personally at least don't like when I have to sell a ""because of floating point errors"", because I've been bitten by them a few times now. Now, I'm also well aware that the project only has a given amount of resources and I myself am currently more or less out of resources (I can spend only my free time), so my vote probably doesn't count strongly :) If I could be of more practical help in this, I would definitely be happy to, but I also don't have a non-x86 machine, so it's not feasible for me to do much right now. So, feel free to make a call on this as you all best see fit!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389#issuecomment-1538758017
Deployability,integrat,integration,"I agree that it is an unfortunate circumstance to have the test not passing. However, I still urge you to consider the effect on debugability removing strict tests will have. I have wasted a lot of time trying to track down a subtle bug due to loose tests which left me unable to determine where the bug came from. Conversely, setting tests strictly and tracing discrepancies, I found a different bug in the Kahan sum: #11940. Unit tests especially should be as strict as possible. In absence of unit tests (which unfortunately is the case for the parts of RooFit I worked on), strict ""integration"" tests like these are the closest I could get. Note also that it was simply part of my original assignment: to ensure users can trust the new parallelized methods, I built them to be bit-wise exactly equal to the old methods. So, I know from experience how tedious it is to trace down these bit-wise differences to their actual concrete source, but also think that because we are dealing with scientific software, precision, robustness, reliability and interpretability (of components and hence the whole) are important. Of course, performance is an important factor too, but it's just one of the aspects. We want the end-results of experiments to be accurate and explainable, right? I personally at least don't like when I have to sell a ""because of floating point errors"", because I've been bitten by them a few times now. Now, I'm also well aware that the project only has a given amount of resources and I myself am currently more or less out of resources (I can spend only my free time), so my vote probably doesn't count strongly :) If I could be of more practical help in this, I would definitely be happy to, but I also don't have a non-x86 machine, so it's not feasible for me to do much right now. So, feel free to make a call on this as you all best see fit!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389#issuecomment-1538758017
Integrability,integrat,integration,"I agree that it is an unfortunate circumstance to have the test not passing. However, I still urge you to consider the effect on debugability removing strict tests will have. I have wasted a lot of time trying to track down a subtle bug due to loose tests which left me unable to determine where the bug came from. Conversely, setting tests strictly and tracing discrepancies, I found a different bug in the Kahan sum: #11940. Unit tests especially should be as strict as possible. In absence of unit tests (which unfortunately is the case for the parts of RooFit I worked on), strict ""integration"" tests like these are the closest I could get. Note also that it was simply part of my original assignment: to ensure users can trust the new parallelized methods, I built them to be bit-wise exactly equal to the old methods. So, I know from experience how tedious it is to trace down these bit-wise differences to their actual concrete source, but also think that because we are dealing with scientific software, precision, robustness, reliability and interpretability (of components and hence the whole) are important. Of course, performance is an important factor too, but it's just one of the aspects. We want the end-results of experiments to be accurate and explainable, right? I personally at least don't like when I have to sell a ""because of floating point errors"", because I've been bitten by them a few times now. Now, I'm also well aware that the project only has a given amount of resources and I myself am currently more or less out of resources (I can spend only my free time), so my vote probably doesn't count strongly :) If I could be of more practical help in this, I would definitely be happy to, but I also don't have a non-x86 machine, so it's not feasible for me to do much right now. So, feel free to make a call on this as you all best see fit!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389#issuecomment-1538758017
Performance,perform,performance,"I agree that it is an unfortunate circumstance to have the test not passing. However, I still urge you to consider the effect on debugability removing strict tests will have. I have wasted a lot of time trying to track down a subtle bug due to loose tests which left me unable to determine where the bug came from. Conversely, setting tests strictly and tracing discrepancies, I found a different bug in the Kahan sum: #11940. Unit tests especially should be as strict as possible. In absence of unit tests (which unfortunately is the case for the parts of RooFit I worked on), strict ""integration"" tests like these are the closest I could get. Note also that it was simply part of my original assignment: to ensure users can trust the new parallelized methods, I built them to be bit-wise exactly equal to the old methods. So, I know from experience how tedious it is to trace down these bit-wise differences to their actual concrete source, but also think that because we are dealing with scientific software, precision, robustness, reliability and interpretability (of components and hence the whole) are important. Of course, performance is an important factor too, but it's just one of the aspects. We want the end-results of experiments to be accurate and explainable, right? I personally at least don't like when I have to sell a ""because of floating point errors"", because I've been bitten by them a few times now. Now, I'm also well aware that the project only has a given amount of resources and I myself am currently more or less out of resources (I can spend only my free time), so my vote probably doesn't count strongly :) If I could be of more practical help in this, I would definitely be happy to, but I also don't have a non-x86 machine, so it's not feasible for me to do much right now. So, feel free to make a call on this as you all best see fit!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389#issuecomment-1538758017
Testability,test,test,"I agree that it is an unfortunate circumstance to have the test not passing. However, I still urge you to consider the effect on debugability removing strict tests will have. I have wasted a lot of time trying to track down a subtle bug due to loose tests which left me unable to determine where the bug came from. Conversely, setting tests strictly and tracing discrepancies, I found a different bug in the Kahan sum: #11940. Unit tests especially should be as strict as possible. In absence of unit tests (which unfortunately is the case for the parts of RooFit I worked on), strict ""integration"" tests like these are the closest I could get. Note also that it was simply part of my original assignment: to ensure users can trust the new parallelized methods, I built them to be bit-wise exactly equal to the old methods. So, I know from experience how tedious it is to trace down these bit-wise differences to their actual concrete source, but also think that because we are dealing with scientific software, precision, robustness, reliability and interpretability (of components and hence the whole) are important. Of course, performance is an important factor too, but it's just one of the aspects. We want the end-results of experiments to be accurate and explainable, right? I personally at least don't like when I have to sell a ""because of floating point errors"", because I've been bitten by them a few times now. Now, I'm also well aware that the project only has a given amount of resources and I myself am currently more or less out of resources (I can spend only my free time), so my vote probably doesn't count strongly :) If I could be of more practical help in this, I would definitely be happy to, but I also don't have a non-x86 machine, so it's not feasible for me to do much right now. So, feel free to make a call on this as you all best see fit!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389#issuecomment-1538758017
Usability,simpl,simply,"I agree that it is an unfortunate circumstance to have the test not passing. However, I still urge you to consider the effect on debugability removing strict tests will have. I have wasted a lot of time trying to track down a subtle bug due to loose tests which left me unable to determine where the bug came from. Conversely, setting tests strictly and tracing discrepancies, I found a different bug in the Kahan sum: #11940. Unit tests especially should be as strict as possible. In absence of unit tests (which unfortunately is the case for the parts of RooFit I worked on), strict ""integration"" tests like these are the closest I could get. Note also that it was simply part of my original assignment: to ensure users can trust the new parallelized methods, I built them to be bit-wise exactly equal to the old methods. So, I know from experience how tedious it is to trace down these bit-wise differences to their actual concrete source, but also think that because we are dealing with scientific software, precision, robustness, reliability and interpretability (of components and hence the whole) are important. Of course, performance is an important factor too, but it's just one of the aspects. We want the end-results of experiments to be accurate and explainable, right? I personally at least don't like when I have to sell a ""because of floating point errors"", because I've been bitten by them a few times now. Now, I'm also well aware that the project only has a given amount of resources and I myself am currently more or less out of resources (I can spend only my free time), so my vote probably doesn't count strongly :) If I could be of more practical help in this, I would definitely be happy to, but I also don't have a non-x86 machine, so it's not feasible for me to do much right now. So, feel free to make a call on this as you all best see fit!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389#issuecomment-1538758017
Availability,failure,failure,"I cannot decide, that's up to you @egpbos and @lmoneta given the input by @hahnjo and me here. Please consider this:. IIUC you are interpreting this lack of bitwise equality as a bug. In that case our approach is to fix the failure asap. If ""asap"" isn't happening because reasons then we disable the test, and create a bug report about the test failure, reminding ourselves (you, @egpbos in this case) that the test needs to be fixed and re-enabled. ""Disabling the test"" can as well be a switch from equality to equality-with-range, as long as the GitHub issue is clear which commit needs to be reverted to reprouce the original test failure. How does that sound?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389#issuecomment-1540010898
Testability,test,test,"I cannot decide, that's up to you @egpbos and @lmoneta given the input by @hahnjo and me here. Please consider this:. IIUC you are interpreting this lack of bitwise equality as a bug. In that case our approach is to fix the failure asap. If ""asap"" isn't happening because reasons then we disable the test, and create a bug report about the test failure, reminding ourselves (you, @egpbos in this case) that the test needs to be fixed and re-enabled. ""Disabling the test"" can as well be a switch from equality to equality-with-range, as long as the GitHub issue is clear which commit needs to be reverted to reprouce the original test failure. How does that sound?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389#issuecomment-1540010898
Usability,clear,clear,"I cannot decide, that's up to you @egpbos and @lmoneta given the input by @hahnjo and me here. Please consider this:. IIUC you are interpreting this lack of bitwise equality as a bug. In that case our approach is to fix the failure asap. If ""asap"" isn't happening because reasons then we disable the test, and create a bug report about the test failure, reminding ourselves (you, @egpbos in this case) that the test needs to be fixed and re-enabled. ""Disabling the test"" can as well be a switch from equality to equality-with-range, as long as the GitHub issue is clear which commit needs to be reverted to reprouce the original test failure. How does that sound?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389#issuecomment-1540010898
Modifiability,inherit,inherited,"Hi! I'm not sure if this is a good idea. The ROOT Fitter is not meant to be inherited from in C++, right? It has no virtual functions, and nowhere do we inherit from it. I'm worried that encouraging users to inherit from the Fitter like this will cause further complications, so maybe it's good that it doesn't work? What is the benefit of this?. If you think this is really necessary, maybe better add a comment to the destructor explaining why it needs to be `virtual` for PyROOT, because when reading the C++ code it's not clear why it should be there and there is the risk that future developers interpret it as an accidentally added keyword and remove it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12397#issuecomment-1448506389
Safety,risk,risk,"Hi! I'm not sure if this is a good idea. The ROOT Fitter is not meant to be inherited from in C++, right? It has no virtual functions, and nowhere do we inherit from it. I'm worried that encouraging users to inherit from the Fitter like this will cause further complications, so maybe it's good that it doesn't work? What is the benefit of this?. If you think this is really necessary, maybe better add a comment to the destructor explaining why it needs to be `virtual` for PyROOT, because when reading the C++ code it's not clear why it should be there and there is the risk that future developers interpret it as an accidentally added keyword and remove it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12397#issuecomment-1448506389
Usability,clear,clear,"Hi! I'm not sure if this is a good idea. The ROOT Fitter is not meant to be inherited from in C++, right? It has no virtual functions, and nowhere do we inherit from it. I'm worried that encouraging users to inherit from the Fitter like this will cause further complications, so maybe it's good that it doesn't work? What is the benefit of this?. If you think this is really necessary, maybe better add a comment to the destructor explaining why it needs to be `virtual` for PyROOT, because when reading the C++ code it's not clear why it should be there and there is the risk that future developers interpret it as an accidentally added keyword and remove it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12397#issuecomment-1448506389
Testability,test,tests,Build failed on windows10/cxx14.; Running on null:C:\build\workspace\root-pullrequests-build; [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/169780/console).; ### Failing tests:; - [projectroot.roottest.root.io.stdpair.roottest_root_io_stdpair_collection_build](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/169780/testReport/projectroot.roottest.root.io/stdpair/roottest_root_io_stdpair_collection_build/); - [projectroot.roottest.root.io.stdpair.roottest_root_io_stdpair_pair_build](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/169780/testReport/projectroot.roottest.root.io/stdpair/roottest_root_io_stdpair_pair_build/); - [projectroot.roottest.root.multicore.roottest_root_multicore_tp_process_imt_build](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/169780/testReport/projectroot.roottest.root/multicore/roottest_root_multicore_tp_process_imt_build/); - [projectroot.roottest.root.multicore.roottest_root_multicore_tprofile_build](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/169780/testReport/projectroot.roottest.root/multicore/roottest_root_multicore_tprofile_build/); - [projectroot.roottest.root.multicore.roottest_root_multicore_ttree_read_imt_build](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/169780/testReport/projectroot.roottest.root/multicore/roottest_root_multicore_ttree_read_imt_build/); - [projectroot.roottest.root.multicore.roottest_root_multicore_th1f_fill_build](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/169780/testReport/projectroot.roottest.root/multicore/roottest_root_multicore_th1f_fill_build/); - [projectroot.roottest.root.meta.tclass.roottest_root_meta_tclass_libInitOrderDups_build](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/169780/testReport/projectroot.roottest.root.meta/tclass/roottest_root_meta_tclass_libInitOrde,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12415#issuecomment-1456017123
Usability,simpl,simple,ild/169780/testReport/projectroot.roottest.root/multicore/roottest_root_multicore_tp_process_imt_build/); - [projectroot.roottest.root.multicore.roottest_root_multicore_tprofile_build](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/169780/testReport/projectroot.roottest.root/multicore/roottest_root_multicore_tprofile_build/); - [projectroot.roottest.root.multicore.roottest_root_multicore_ttree_read_imt_build](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/169780/testReport/projectroot.roottest.root/multicore/roottest_root_multicore_ttree_read_imt_build/); - [projectroot.roottest.root.multicore.roottest_root_multicore_th1f_fill_build](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/169780/testReport/projectroot.roottest.root/multicore/roottest_root_multicore_th1f_fill_build/); - [projectroot.roottest.root.meta.tclass.roottest_root_meta_tclass_libInitOrderDups_build](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/169780/testReport/projectroot.roottest.root.meta/tclass/roottest_root_meta_tclass_libInitOrderDups_build/); - [projectroot.roottest.root.meta.genreflex.ROOT-5709.roottest_root_meta_genreflex_ROOT_5709_Tau_libgen_build](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/169780/testReport/projectroot.roottest.root.meta.genreflex/ROOT-5709/roottest_root_meta_genreflex_ROOT_5709_Tau_libgen_build/); - [projectroot.roottest.root.multicore.roottest_root_multicore_testSetAddress_build](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/169780/testReport/projectroot.roottest.root/multicore/roottest_root_multicore_testSetAddress_build/); - [projectroot.roottest.root.selector.simple.roottest_root_selector_simple_testSelector_build](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/169780/testReport/projectroot.roottest.root.selector/simple/roottest_root_selector_simple_testSelector_build/). And 155 more,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12415#issuecomment-1456017123
Usability,simpl,simplify,"Ok, so, despite being a native speaker, I'll admit writing is not my forte. I tried to simplify what you wrote a bit, but please lmk what to change.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12421#issuecomment-1458668358
Usability,simpl,simpler,"Thank you for the additional information! We are setting up a big endian node here, which will make working on this issue simpler.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12426#issuecomment-1470788474
Usability,simpl,simpler,"Thank you for the bug report! Our 32bit CI is currently not running on the experimental namespace (including RNTuple). Let us fix that first, which will make it simpler to fix this issue.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12427#issuecomment-1458084140
Testability,log,logs,"Dear Denys,. Thanks for the logs and for the information. So if you cannot use c++17, why not simply use c++14 and disable root7?. Cheers, Bertrand.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12492#issuecomment-1473275035
Usability,simpl,simply,"Dear Denys,. Thanks for the logs and for the information. So if you cannot use c++17, why not simply use c++14 and disable root7?. Cheers, Bertrand.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12492#issuecomment-1473275035
Usability,feedback,feedback,"@eguiraud , thanks for the feedback!. Ineed I have tried my reproducer with `/cvmfs/sft.cern.ch/lcg/views/LCG_103/x86_64-centos7-gcc11-opt/setup.sh`; and everything seems to work properly!. So I assume something magical happened between; `root 6.26.06` and `root 6.28.00`; or between; `Python 3.9.10` and `Python 3.9.12`. I will close the issue then. Thanks for your time investigating this :pray:.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12496#issuecomment-1564653938
Usability,simpl,simple,"You mean `gStyle->GetAxisMaxDigits()`?. I guess, one should understand why it happens.; How I can reproduce it?. As a workaround, I can add simple check in this function that it returns meaningful positive value from the range [0..100]",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12513#issuecomment-1490325536
Usability,guid,guide,"In principle, the user's guide is frozen. We now rely on the [Manual](https://root.cern/manual/) and the [reference guide](https://root.cern/doc/master/).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12551#issuecomment-1485254013
Usability,guid,guide,"@olantwin how did you find this? (Tells us what we need to remove.). > In principle, the user's guide is frozen. @couet should we remove this file then?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12551#issuecomment-1485286794
Usability,guid,guide,"@axel, It is just a few lines to be removed in [documentation/users-guide/Trees.md](https://github.com/root-project/root/pull/12551#diff-117cc7b0ab6e57e24e841291453a0649b39771247133629bd536ebd0212a3510) (not a complete file).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12551#issuecomment-1485324939
Usability,guid,guide,"There was no followup here on the discussion on what should be in the manual and in the reference guide, but I think this discussion is not directly connected to removing this outdated statement about STL splitting from the users guide. So I would suggest to merge this PR as is, thanks @olantwin! If you want to follow up on adding this information to the reference guide (doxygen) or have other suggestions to improve the documentation, feel free to open more PRs :slightly_smiling_face:",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12551#issuecomment-1882573439
Usability,simpl,simple,"The problem is in automatic reading the objects, probably for some missing library (as in this case the `TMath::Abs` definition). I think we had similar issues with TFormula/TF1 before. ; There is the simple workaround:; ```; auto legends = file->Get(""legends""); legends->Draw();; ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12559#issuecomment-1494518922
Availability,failure,failures,"> > > @hahnjo, is there a way to move forward without losing progress we made for windows?; > > ; > > I don't see one, please see my very lengthy and detailed commit message of why I think it's not going to work like that.; > ; > Would it not help if we annotate all dependencies by hand all of the dependencies that cannot work with modules?. Yes, this is the direction I've also been thinking about. But it's certainly not an easy change of a couple of lines, and I really would like to fix the currently broken state first. To be clear, this is currently *blocking* me from making changes in ROOT / Cling, or at least making it unnecessarily hard because I always have to either deal with 20-ish unrelated test failures or base my branches on these fixes. It's really painful.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12561#issuecomment-1491725885
Integrability,message,message,"> > > @hahnjo, is there a way to move forward without losing progress we made for windows?; > > ; > > I don't see one, please see my very lengthy and detailed commit message of why I think it's not going to work like that.; > ; > Would it not help if we annotate all dependencies by hand all of the dependencies that cannot work with modules?. Yes, this is the direction I've also been thinking about. But it's certainly not an easy change of a couple of lines, and I really would like to fix the currently broken state first. To be clear, this is currently *blocking* me from making changes in ROOT / Cling, or at least making it unnecessarily hard because I always have to either deal with 20-ish unrelated test failures or base my branches on these fixes. It's really painful.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12561#issuecomment-1491725885
Testability,test,test,"> > > @hahnjo, is there a way to move forward without losing progress we made for windows?; > > ; > > I don't see one, please see my very lengthy and detailed commit message of why I think it's not going to work like that.; > ; > Would it not help if we annotate all dependencies by hand all of the dependencies that cannot work with modules?. Yes, this is the direction I've also been thinking about. But it's certainly not an easy change of a couple of lines, and I really would like to fix the currently broken state first. To be clear, this is currently *blocking* me from making changes in ROOT / Cling, or at least making it unnecessarily hard because I always have to either deal with 20-ish unrelated test failures or base my branches on these fixes. It's really painful.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12561#issuecomment-1491725885
Usability,clear,clear,"> > > @hahnjo, is there a way to move forward without losing progress we made for windows?; > > ; > > I don't see one, please see my very lengthy and detailed commit message of why I think it's not going to work like that.; > ; > Would it not help if we annotate all dependencies by hand all of the dependencies that cannot work with modules?. Yes, this is the direction I've also been thinking about. But it's certainly not an easy change of a couple of lines, and I really would like to fix the currently broken state first. To be clear, this is currently *blocking* me from making changes in ROOT / Cling, or at least making it unnecessarily hard because I always have to either deal with 20-ish unrelated test failures or base my branches on these fixes. It's really painful.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12561#issuecomment-1491725885
Availability,error,errors,"Yes, of course! I will also copy it here:. The rationale behind this change is that the public methods will (in most cases) be directly used by end users, so there is no need to further propagate potential errors. It removes the need to `Unwrap` the importer object returned by `Create`, making it more intuitive to use. As a potential downside, this means that in case the importer is used in more elaborate call; chains this propagation is of course not possible anymore. A possible solution could be to have methods for both, although this will obviously add some bloat.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12565#issuecomment-1488072046
Usability,intuit,intuitive,"Yes, of course! I will also copy it here:. The rationale behind this change is that the public methods will (in most cases) be directly used by end users, so there is no need to further propagate potential errors. It removes the need to `Unwrap` the importer object returned by `Create`, making it more intuitive to use. As a potential downside, this means that in case the importer is used in more elaborate call; chains this propagation is of course not possible anymore. A possible solution could be to have methods for both, although this will obviously add some bloat.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12565#issuecomment-1488072046
Usability,simpl,simple,A simple workaround that does not involve modifying the TTimeStamp code is provided o the ROOT forum.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12569#issuecomment-1561019614
Availability,error,errors,"ls using AD. This commits adds support for including analytical integrals into the mock code-squashing test by introducing a private header that stores the stateless implementation details.; [RF][HS3] Consistent range for nominal alpha params with HistFactory; [RF][HS3] Remember simultaneous channel names when writing JSON; [RF][HS3] Avoid turning RooConstVar into RooRealVar in JSON roundtrip; [RF][HS3] Use `RooConstVar` for sigma parameters in HF constraints; [RF][HS3] Don't mix up free functions and class impl in JSON tool; [RF][HS3] Consistently have implicit fallback for HistFactory variables; [RF][HS3] Don't import datasets that are parts of a combined dataset; [RF][HS3] Some code simplification in `RooJSONFactoryWSTool`; [RF][HS3] Generate input file for testHS3HistFactory on the fly; [RF][HS3] Improvements to the HS3 HistFactory implementation; [RF] Use `std::vector` diretly in RooVectorDataStore::RealFullVector; [RF][HS3] Some refactoring for less lines of code; [RF][HS3] Ordering fixes; [RF][HS3] Achieved closure for ATLAS ttW workspace; [RF][HS3] Sorting distributions; [RF][HS3] Bugfixes for histfactory workspaces; [RF][HS3] Small renamings; [RF][HS3] Improved attribute handling, caught some typecast-errors; [RF][HS3] Bugfix for FlexibleInterpVar; [RF] Avoid unnecessary warnings in `FlexibleInterpVar::setInterpCode`; [RF] Enable analytic integration of RooHistPdfs with RooLinearVars; [RF] Replace `RooAbsReal::_lastNSet` pointer with ID of last normSet; [RF] Remove `evaluateSpan()` from RooGenericPdf and RooFormulaVar; [RF][HS3] Re-retrieve element after exporting dependants; [RF][HS3] Don't write `histfactory_dist` axes redundantly; [RF] Exclude RooHistError from IO; [RF] Remove `add(row, weight, weightError)` from RooAbsData interface; [RF] Code-format `testRooDataHist.cxx`; [RF][HS3] Change analysis and likelihoods fields to match HS3 standard; [RF] Remove native buffers from `RooVectorDataStore::RealFullVector`; [RF] Modernize `RooVectorDataStore::RealF",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12590#issuecomment-1491813664
Deployability,patch,patches,"After merging this PR, the following commits in ROOT `master` (as of `6dcc352289`) are the ones that are not in `v6-28-00-patches` (as of `c512572f9973`). ```txt; 41370dd378 [RF] Make it possible to use parameter titles in `RooAbsPdf::paramOn()`; 912c32c5e2 [RF] Remove deprecated `Format(const char*, int)` command argument; 3f925503b4 [RF] Fix memory leaks from `RooAbsL::getParameters()`; fb891723bc [RF][HS3] Avoid code duplication in `JSONFactories_RooFitCore`; 9a605d7f35 [RF][HS3] Make `combined_data_name` optional; b87c368b6a [RF][HS3] Keep all info necessary to reconstruct simultaneous pdfs; f9348f857c [RF][HS3] Don't convert RooHistPdf first to TH1 when exporting; 195d5b8111 [RF][HS3] Additions to JSONInterface to reduce code duplication; a75dec1868 [RF][HS3] Keep all information necessary to reconstruct combined datas; 6b80645765 Revert ""[RF] Make RooBatchCompute dependency public.""; [RF] Move loop management for code generation into CodeSquashContext; [RF] Avoid need for buildLoopBegin() by recursive calls to translate(); [RF] Add 'translate' to RooNllVarNew.; [RF] Remove function declarations in RooStats LinkDef.h; [RF] Apply clang-format to ModelConfig.h and ModelConfig.cxx; [RF] Move `ModelConfig` from RooStats to RooFit; [RF] Don't add `weightVar` to observables in HistFactory; [RF] Minor improvements to RooFit evaluation code generation; [RF][NFC] Fix typo.; [RF] Disable RooFuncWrapper test if clad is off.; [RF] Remove wrong header declaration from roofit/roofit.; [RF] Fix visibility of the res/ directories.; [RF] Make RooBatchCompute dependency public.; [RF] Add initial interface and implementation for code-squashing.; [RF][HS3] Put exported `histosys` in the correct vector; [RF][HS3] Avoid creating temporary objects to import into workspace; [RF][HS3][HF] General cleanup of HS3 HistFactory implementation; [RF][HS3] Cover also `HistoSys` in HS3 HistFactory test; [RF] Enable passing of gradient function directly to RooMinimizer; [RF] Add support for diffe",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12590#issuecomment-1491813664
Energy Efficiency,reduce,reduce,"After merging this PR, the following commits in ROOT `master` (as of `6dcc352289`) are the ones that are not in `v6-28-00-patches` (as of `c512572f9973`). ```txt; 41370dd378 [RF] Make it possible to use parameter titles in `RooAbsPdf::paramOn()`; 912c32c5e2 [RF] Remove deprecated `Format(const char*, int)` command argument; 3f925503b4 [RF] Fix memory leaks from `RooAbsL::getParameters()`; fb891723bc [RF][HS3] Avoid code duplication in `JSONFactories_RooFitCore`; 9a605d7f35 [RF][HS3] Make `combined_data_name` optional; b87c368b6a [RF][HS3] Keep all info necessary to reconstruct simultaneous pdfs; f9348f857c [RF][HS3] Don't convert RooHistPdf first to TH1 when exporting; 195d5b8111 [RF][HS3] Additions to JSONInterface to reduce code duplication; a75dec1868 [RF][HS3] Keep all information necessary to reconstruct combined datas; 6b80645765 Revert ""[RF] Make RooBatchCompute dependency public.""; [RF] Move loop management for code generation into CodeSquashContext; [RF] Avoid need for buildLoopBegin() by recursive calls to translate(); [RF] Add 'translate' to RooNllVarNew.; [RF] Remove function declarations in RooStats LinkDef.h; [RF] Apply clang-format to ModelConfig.h and ModelConfig.cxx; [RF] Move `ModelConfig` from RooStats to RooFit; [RF] Don't add `weightVar` to observables in HistFactory; [RF] Minor improvements to RooFit evaluation code generation; [RF][NFC] Fix typo.; [RF] Disable RooFuncWrapper test if clad is off.; [RF] Remove wrong header declaration from roofit/roofit.; [RF] Fix visibility of the res/ directories.; [RF] Make RooBatchCompute dependency public.; [RF] Add initial interface and implementation for code-squashing.; [RF][HS3] Put exported `histosys` in the correct vector; [RF][HS3] Avoid creating temporary objects to import into workspace; [RF][HS3][HF] General cleanup of HS3 HistFactory implementation; [RF][HS3] Cover also `HistoSys` in HS3 HistFactory test; [RF] Enable passing of gradient function directly to RooMinimizer; [RF] Add support for diffe",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12590#issuecomment-1491813664
Integrability,depend,dependency,"After merging this PR, the following commits in ROOT `master` (as of `6dcc352289`) are the ones that are not in `v6-28-00-patches` (as of `c512572f9973`). ```txt; 41370dd378 [RF] Make it possible to use parameter titles in `RooAbsPdf::paramOn()`; 912c32c5e2 [RF] Remove deprecated `Format(const char*, int)` command argument; 3f925503b4 [RF] Fix memory leaks from `RooAbsL::getParameters()`; fb891723bc [RF][HS3] Avoid code duplication in `JSONFactories_RooFitCore`; 9a605d7f35 [RF][HS3] Make `combined_data_name` optional; b87c368b6a [RF][HS3] Keep all info necessary to reconstruct simultaneous pdfs; f9348f857c [RF][HS3] Don't convert RooHistPdf first to TH1 when exporting; 195d5b8111 [RF][HS3] Additions to JSONInterface to reduce code duplication; a75dec1868 [RF][HS3] Keep all information necessary to reconstruct combined datas; 6b80645765 Revert ""[RF] Make RooBatchCompute dependency public.""; [RF] Move loop management for code generation into CodeSquashContext; [RF] Avoid need for buildLoopBegin() by recursive calls to translate(); [RF] Add 'translate' to RooNllVarNew.; [RF] Remove function declarations in RooStats LinkDef.h; [RF] Apply clang-format to ModelConfig.h and ModelConfig.cxx; [RF] Move `ModelConfig` from RooStats to RooFit; [RF] Don't add `weightVar` to observables in HistFactory; [RF] Minor improvements to RooFit evaluation code generation; [RF][NFC] Fix typo.; [RF] Disable RooFuncWrapper test if clad is off.; [RF] Remove wrong header declaration from roofit/roofit.; [RF] Fix visibility of the res/ directories.; [RF] Make RooBatchCompute dependency public.; [RF] Add initial interface and implementation for code-squashing.; [RF][HS3] Put exported `histosys` in the correct vector; [RF][HS3] Avoid creating temporary objects to import into workspace; [RF][HS3][HF] General cleanup of HS3 HistFactory implementation; [RF][HS3] Cover also `HistoSys` in HS3 HistFactory test; [RF] Enable passing of gradient function directly to RooMinimizer; [RF] Add support for diffe",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12590#issuecomment-1491813664
Modifiability,variab,variables,"ls using AD. This commits adds support for including analytical integrals into the mock code-squashing test by introducing a private header that stores the stateless implementation details.; [RF][HS3] Consistent range for nominal alpha params with HistFactory; [RF][HS3] Remember simultaneous channel names when writing JSON; [RF][HS3] Avoid turning RooConstVar into RooRealVar in JSON roundtrip; [RF][HS3] Use `RooConstVar` for sigma parameters in HF constraints; [RF][HS3] Don't mix up free functions and class impl in JSON tool; [RF][HS3] Consistently have implicit fallback for HistFactory variables; [RF][HS3] Don't import datasets that are parts of a combined dataset; [RF][HS3] Some code simplification in `RooJSONFactoryWSTool`; [RF][HS3] Generate input file for testHS3HistFactory on the fly; [RF][HS3] Improvements to the HS3 HistFactory implementation; [RF] Use `std::vector` diretly in RooVectorDataStore::RealFullVector; [RF][HS3] Some refactoring for less lines of code; [RF][HS3] Ordering fixes; [RF][HS3] Achieved closure for ATLAS ttW workspace; [RF][HS3] Sorting distributions; [RF][HS3] Bugfixes for histfactory workspaces; [RF][HS3] Small renamings; [RF][HS3] Improved attribute handling, caught some typecast-errors; [RF][HS3] Bugfix for FlexibleInterpVar; [RF] Avoid unnecessary warnings in `FlexibleInterpVar::setInterpCode`; [RF] Enable analytic integration of RooHistPdfs with RooLinearVars; [RF] Replace `RooAbsReal::_lastNSet` pointer with ID of last normSet; [RF] Remove `evaluateSpan()` from RooGenericPdf and RooFormulaVar; [RF][HS3] Re-retrieve element after exporting dependants; [RF][HS3] Don't write `histfactory_dist` axes redundantly; [RF] Exclude RooHistError from IO; [RF] Remove `add(row, weight, weightError)` from RooAbsData interface; [RF] Code-format `testRooDataHist.cxx`; [RF][HS3] Change analysis and likelihoods fields to match HS3 standard; [RF] Remove native buffers from `RooVectorDataStore::RealFullVector`; [RF] Modernize `RooVectorDataStore::RealF",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12590#issuecomment-1491813664
Safety,redund,redundantly,"ls using AD. This commits adds support for including analytical integrals into the mock code-squashing test by introducing a private header that stores the stateless implementation details.; [RF][HS3] Consistent range for nominal alpha params with HistFactory; [RF][HS3] Remember simultaneous channel names when writing JSON; [RF][HS3] Avoid turning RooConstVar into RooRealVar in JSON roundtrip; [RF][HS3] Use `RooConstVar` for sigma parameters in HF constraints; [RF][HS3] Don't mix up free functions and class impl in JSON tool; [RF][HS3] Consistently have implicit fallback for HistFactory variables; [RF][HS3] Don't import datasets that are parts of a combined dataset; [RF][HS3] Some code simplification in `RooJSONFactoryWSTool`; [RF][HS3] Generate input file for testHS3HistFactory on the fly; [RF][HS3] Improvements to the HS3 HistFactory implementation; [RF] Use `std::vector` diretly in RooVectorDataStore::RealFullVector; [RF][HS3] Some refactoring for less lines of code; [RF][HS3] Ordering fixes; [RF][HS3] Achieved closure for ATLAS ttW workspace; [RF][HS3] Sorting distributions; [RF][HS3] Bugfixes for histfactory workspaces; [RF][HS3] Small renamings; [RF][HS3] Improved attribute handling, caught some typecast-errors; [RF][HS3] Bugfix for FlexibleInterpVar; [RF] Avoid unnecessary warnings in `FlexibleInterpVar::setInterpCode`; [RF] Enable analytic integration of RooHistPdfs with RooLinearVars; [RF] Replace `RooAbsReal::_lastNSet` pointer with ID of last normSet; [RF] Remove `evaluateSpan()` from RooGenericPdf and RooFormulaVar; [RF][HS3] Re-retrieve element after exporting dependants; [RF][HS3] Don't write `histfactory_dist` axes redundantly; [RF] Exclude RooHistError from IO; [RF] Remove `add(row, weight, weightError)` from RooAbsData interface; [RF] Code-format `testRooDataHist.cxx`; [RF][HS3] Change analysis and likelihoods fields to match HS3 standard; [RF] Remove native buffers from `RooVectorDataStore::RealFullVector`; [RF] Modernize `RooVectorDataStore::RealF",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12590#issuecomment-1491813664
Security,access,access,"ctionaries; [RF] Suggest alternative to RooDataSet c'tor that takes weight name; [RF] Add unit test for splitting RooDataSets with weight errors; [RF] Add weight errors and not weight squared when filling split data; [RF] Correctly propagate error storage in `RooDataSet::emptyClone()`; [RF][HS3] Don't assume that combined dataset name is always `""obsData""`; [RF][HS3] Use less `c_str()` conversions in RooFitHS3; [RF][HS3] New `wsEmplace()` method for creating objects in workspace; [RF][HS3] New `wsImport()` function to avoid repeating command args; [RF] Less manual memory management in RooAbsArg and RooProdGenContext; [RF] Code modernization of RooAbsReal; [RF][HS3] Renaming some distributions to conform with HS3 standard; [RF][HS3] Use HistFunc variables instead of underlying hist variables; [RF] Added protection against invalid variable names in createHistogram; [RF][HS3] Correct error messages when IO keys are missing; [RF][HS3] Code improvements in HS3 HistFactory; [RF][HS3] Small HS3 closure fixes; [RF][HS3] Import HistFactory constraints directly upon creation; [RF][HS3] Cleanup of generic functions to avoid using arguments; [RF][HS3] Don't import embedded data directly to RooWorkspace; [RF] Avoid false warnings in RooAbsReal::createHistogram(); [RF][HS3] Reduce verbosity of unit tests; [RF][HS3] Less usage of TString; [RF][HS3] Avoid code duplication when requesting RooArgLists and Sets; [RF][HS3] Remove unused functions from JSONFactories_HistFactory; [RF][HS3] Export `staterror` correctly for HistFactory; [RF][HS3] Major restructuring of HistFactory in HS3 - part 2; [RF][HS3] Major refactoring of `JSONFactories_HistFactory`; [RF][HS3] Correctly consider weight errors in `readBinnedData()`; [RF][HS3] Small code style improvement (renaming); [RF][HS3] Make `testHS3HistFactory` less verbose; [RF][HS3] Changed some JSON keywords to comply with new HS3 standard; [RF][HS3] Moved `DependencyMissingError` to public to make it catchable; [RF][HS3] Support MultiVarGauss",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12590#issuecomment-1491813664
Testability,test,test,"id code duplication in `JSONFactories_RooFitCore`; 9a605d7f35 [RF][HS3] Make `combined_data_name` optional; b87c368b6a [RF][HS3] Keep all info necessary to reconstruct simultaneous pdfs; f9348f857c [RF][HS3] Don't convert RooHistPdf first to TH1 when exporting; 195d5b8111 [RF][HS3] Additions to JSONInterface to reduce code duplication; a75dec1868 [RF][HS3] Keep all information necessary to reconstruct combined datas; 6b80645765 Revert ""[RF] Make RooBatchCompute dependency public.""; [RF] Move loop management for code generation into CodeSquashContext; [RF] Avoid need for buildLoopBegin() by recursive calls to translate(); [RF] Add 'translate' to RooNllVarNew.; [RF] Remove function declarations in RooStats LinkDef.h; [RF] Apply clang-format to ModelConfig.h and ModelConfig.cxx; [RF] Move `ModelConfig` from RooStats to RooFit; [RF] Don't add `weightVar` to observables in HistFactory; [RF] Minor improvements to RooFit evaluation code generation; [RF][NFC] Fix typo.; [RF] Disable RooFuncWrapper test if clad is off.; [RF] Remove wrong header declaration from roofit/roofit.; [RF] Fix visibility of the res/ directories.; [RF] Make RooBatchCompute dependency public.; [RF] Add initial interface and implementation for code-squashing.; [RF][HS3] Put exported `histosys` in the correct vector; [RF][HS3] Avoid creating temporary objects to import into workspace; [RF][HS3][HF] General cleanup of HS3 HistFactory implementation; [RF][HS3] Cover also `HistoSys` in HS3 HistFactory test; [RF] Enable passing of gradient function directly to RooMinimizer; [RF] Add support for differentiating Gaussian integrals using AD. This commits adds support for including analytical integrals into the mock code-squashing test by introducing a private header that stores the stateless implementation details.; [RF][HS3] Consistent range for nominal alpha params with HistFactory; [RF][HS3] Remember simultaneous channel names when writing JSON; [RF][HS3] Avoid turning RooConstVar into RooRealVar in JSON ro",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12590#issuecomment-1491813664
Usability,simpl,simplification,"ls using AD. This commits adds support for including analytical integrals into the mock code-squashing test by introducing a private header that stores the stateless implementation details.; [RF][HS3] Consistent range for nominal alpha params with HistFactory; [RF][HS3] Remember simultaneous channel names when writing JSON; [RF][HS3] Avoid turning RooConstVar into RooRealVar in JSON roundtrip; [RF][HS3] Use `RooConstVar` for sigma parameters in HF constraints; [RF][HS3] Don't mix up free functions and class impl in JSON tool; [RF][HS3] Consistently have implicit fallback for HistFactory variables; [RF][HS3] Don't import datasets that are parts of a combined dataset; [RF][HS3] Some code simplification in `RooJSONFactoryWSTool`; [RF][HS3] Generate input file for testHS3HistFactory on the fly; [RF][HS3] Improvements to the HS3 HistFactory implementation; [RF] Use `std::vector` diretly in RooVectorDataStore::RealFullVector; [RF][HS3] Some refactoring for less lines of code; [RF][HS3] Ordering fixes; [RF][HS3] Achieved closure for ATLAS ttW workspace; [RF][HS3] Sorting distributions; [RF][HS3] Bugfixes for histfactory workspaces; [RF][HS3] Small renamings; [RF][HS3] Improved attribute handling, caught some typecast-errors; [RF][HS3] Bugfix for FlexibleInterpVar; [RF] Avoid unnecessary warnings in `FlexibleInterpVar::setInterpCode`; [RF] Enable analytic integration of RooHistPdfs with RooLinearVars; [RF] Replace `RooAbsReal::_lastNSet` pointer with ID of last normSet; [RF] Remove `evaluateSpan()` from RooGenericPdf and RooFormulaVar; [RF][HS3] Re-retrieve element after exporting dependants; [RF][HS3] Don't write `histfactory_dist` axes redundantly; [RF] Exclude RooHistError from IO; [RF] Remove `add(row, weight, weightError)` from RooAbsData interface; [RF] Code-format `testRooDataHist.cxx`; [RF][HS3] Change analysis and likelihoods fields to match HS3 standard; [RF] Remove native buffers from `RooVectorDataStore::RealFullVector`; [RF] Modernize `RooVectorDataStore::RealF",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12590#issuecomment-1491813664
Usability,clear,clear,"To be clear, this would just be a first step towards (partially enabled) modules on Windows",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12602#issuecomment-1787077863
Availability,checkpoint,checkpointing,"By any means I am not against this change. However, since such overhead is a significant problem for your O(N) microservices and saving a few calls makes a difference, have you considered using checkpointing to cache ROOT startup operations altogether? A very simplistic way to achieve the checkpointing is to implement a core dump. That would probably yield better results AFAICT.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12613#issuecomment-1496294487
Performance,cache,cache,"By any means I am not against this change. However, since such overhead is a significant problem for your O(N) microservices and saving a few calls makes a difference, have you considered using checkpointing to cache ROOT startup operations altogether? A very simplistic way to achieve the checkpointing is to implement a core dump. That would probably yield better results AFAICT.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12613#issuecomment-1496294487
Usability,simpl,simplistic,"By any means I am not against this change. However, since such overhead is a significant problem for your O(N) microservices and saving a few calls makes a difference, have you considered using checkpointing to cache ROOT startup operations altogether? A very simplistic way to achieve the checkpointing is to implement a core dump. That would probably yield better results AFAICT.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12613#issuecomment-1496294487
Usability,simpl,simple,"@vgvassilev : Your idea sounds nice. Implementation of such a system is, however, not realistic for us at the moment and it would also go far far beyond the simple step here. Of course, we'd be happy to address smaller comments (naming of things, etc.) if there are any.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12613#issuecomment-1514749749
Modifiability,variab,variable,This is indeed a good improvement. A few comments/opinions:; * The variable are used within `Cling` and thus should probably be prefixed by `CLING_` rather than `ROOT_`; * The setting used/necessary is complex and maybe we ought to provide a simpler mechanism (some thing similar to ; ```; export CLING_LDSYSPATH=`cling print_ld_syspath();`; ```; * The (pre-existing) duplication of the code/feature dealing with `ldsyspath` is less than optimal.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12613#issuecomment-1514918749
Usability,simpl,simpler,This is indeed a good improvement. A few comments/opinions:; * The variable are used within `Cling` and thus should probably be prefixed by `CLING_` rather than `ROOT_`; * The setting used/necessary is complex and maybe we ought to provide a simpler mechanism (some thing similar to ; ```; export CLING_LDSYSPATH=`cling print_ld_syspath();`; ```; * The (pre-existing) duplication of the code/feature dealing with `ldsyspath` is less than optimal.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12613#issuecomment-1514918749
Availability,error,errors,"ls using AD. This commits adds support for including analytical integrals into the mock code-squashing test by introducing a private header that stores the stateless implementation details.; [RF][HS3] Consistent range for nominal alpha params with HistFactory; [RF][HS3] Remember simultaneous channel names when writing JSON; [RF][HS3] Avoid turning RooConstVar into RooRealVar in JSON roundtrip; [RF][HS3] Use `RooConstVar` for sigma parameters in HF constraints; [RF][HS3] Don't mix up free functions and class impl in JSON tool; [RF][HS3] Consistently have implicit fallback for HistFactory variables; [RF][HS3] Don't import datasets that are parts of a combined dataset; [RF][HS3] Some code simplification in `RooJSONFactoryWSTool`; [RF][HS3] Generate input file for testHS3HistFactory on the fly; [RF][HS3] Improvements to the HS3 HistFactory implementation; [RF] Use `std::vector` diretly in RooVectorDataStore::RealFullVector; [RF][HS3] Some refactoring for less lines of code; [RF][HS3] Ordering fixes; [RF][HS3] Achieved closure for ATLAS ttW workspace; [RF][HS3] Sorting distributions; [RF][HS3] Bugfixes for histfactory workspaces; [RF][HS3] Small renamings; [RF][HS3] Improved attribute handling, caught some typecast-errors; [RF][HS3] Bugfix for FlexibleInterpVar; [RF] Avoid unnecessary warnings in `FlexibleInterpVar::setInterpCode`; [RF] Enable analytic integration of RooHistPdfs with RooLinearVars; [RF] Replace `RooAbsReal::_lastNSet` pointer with ID of last normSet; [RF] Remove `evaluateSpan()` from RooGenericPdf and RooFormulaVar; [RF][HS3] Re-retrieve element after exporting dependants; [RF][HS3] Don't write `histfactory_dist` axes redundantly; [RF] Exclude RooHistError from IO; [RF] Remove `add(row, weight, weightError)` from RooAbsData interface; [RF] Code-format `testRooDataHist.cxx`; [RF][HS3] Change analysis and likelihoods fields to match HS3 standard; [RF] Remove native buffers from `RooVectorDataStore::RealFullVector`; [RF] Modernize `RooVectorDataStore::RealF",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12618#issuecomment-1497317057
Deployability,patch,patches,"After merging this PR, the following commits in ROOT `master` (as of `2bb0f40e74`) are the ones that are not in `v6-28-00-patches` (`b700f596dbd8`). ```txt; 41370dd378 [RF] Make it possible to use parameter titles in `RooAbsPdf::paramOn()`; 912c32c5e2 [RF] Remove deprecated `Format(const char*, int)` command argument; 3f925503b4 [RF] Fix memory leaks from `RooAbsL::getParameters()`; fb891723bc [RF][HS3] Avoid code duplication in `JSONFactories_RooFitCore`; 9a605d7f35 [RF][HS3] Make `combined_data_name` optional; b87c368b6a [RF][HS3] Keep all info necessary to reconstruct simultaneous pdfs; f9348f857c [RF][HS3] Don't convert RooHistPdf first to TH1 when exporting; 195d5b8111 [RF][HS3] Additions to JSONInterface to reduce code duplication; a75dec1868 [RF][HS3] Keep all information necessary to reconstruct combined datas; [RF] Move loop management for code generation into CodeSquashContext; [RF] Avoid need for buildLoopBegin() by recursive calls to translate(); [RF] Add 'translate' to RooNllVarNew.; [RF] Remove function declarations in RooStats LinkDef.h; [RF] Apply clang-format to ModelConfig.h and ModelConfig.cxx; [RF] Move `ModelConfig` from RooStats to RooFit; [RF] Don't add `weightVar` to observables in HistFactory; [RF] Minor improvements to RooFit evaluation code generation; [RF][NFC] Fix typo.; [RF] Disable RooFuncWrapper test if clad is off.; [RF] Remove wrong header declaration from roofit/roofit.; [RF] Fix visibility of the res/ directories.; [RF] Make RooBatchCompute dependency public.; [RF] Add initial interface and implementation for code-squashing.; [RF][HS3] Put exported `histosys` in the correct vector; [RF][HS3] Avoid creating temporary objects to import into workspace; [RF][HS3][HF] General cleanup of HS3 HistFactory implementation; [RF][HS3] Cover also `HistoSys` in HS3 HistFactory test; [RF] Enable passing of gradient function directly to RooMinimizer; [RF] Add support for differentiating Gaussian integrals using AD. This commits adds support for in",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12618#issuecomment-1497317057
Energy Efficiency,reduce,reduce,"After merging this PR, the following commits in ROOT `master` (as of `2bb0f40e74`) are the ones that are not in `v6-28-00-patches` (`b700f596dbd8`). ```txt; 41370dd378 [RF] Make it possible to use parameter titles in `RooAbsPdf::paramOn()`; 912c32c5e2 [RF] Remove deprecated `Format(const char*, int)` command argument; 3f925503b4 [RF] Fix memory leaks from `RooAbsL::getParameters()`; fb891723bc [RF][HS3] Avoid code duplication in `JSONFactories_RooFitCore`; 9a605d7f35 [RF][HS3] Make `combined_data_name` optional; b87c368b6a [RF][HS3] Keep all info necessary to reconstruct simultaneous pdfs; f9348f857c [RF][HS3] Don't convert RooHistPdf first to TH1 when exporting; 195d5b8111 [RF][HS3] Additions to JSONInterface to reduce code duplication; a75dec1868 [RF][HS3] Keep all information necessary to reconstruct combined datas; [RF] Move loop management for code generation into CodeSquashContext; [RF] Avoid need for buildLoopBegin() by recursive calls to translate(); [RF] Add 'translate' to RooNllVarNew.; [RF] Remove function declarations in RooStats LinkDef.h; [RF] Apply clang-format to ModelConfig.h and ModelConfig.cxx; [RF] Move `ModelConfig` from RooStats to RooFit; [RF] Don't add `weightVar` to observables in HistFactory; [RF] Minor improvements to RooFit evaluation code generation; [RF][NFC] Fix typo.; [RF] Disable RooFuncWrapper test if clad is off.; [RF] Remove wrong header declaration from roofit/roofit.; [RF] Fix visibility of the res/ directories.; [RF] Make RooBatchCompute dependency public.; [RF] Add initial interface and implementation for code-squashing.; [RF][HS3] Put exported `histosys` in the correct vector; [RF][HS3] Avoid creating temporary objects to import into workspace; [RF][HS3][HF] General cleanup of HS3 HistFactory implementation; [RF][HS3] Cover also `HistoSys` in HS3 HistFactory test; [RF] Enable passing of gradient function directly to RooMinimizer; [RF] Add support for differentiating Gaussian integrals using AD. This commits adds support for in",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12618#issuecomment-1497317057
Integrability,depend,dependency,_data_name` optional; b87c368b6a [RF][HS3] Keep all info necessary to reconstruct simultaneous pdfs; f9348f857c [RF][HS3] Don't convert RooHistPdf first to TH1 when exporting; 195d5b8111 [RF][HS3] Additions to JSONInterface to reduce code duplication; a75dec1868 [RF][HS3] Keep all information necessary to reconstruct combined datas; [RF] Move loop management for code generation into CodeSquashContext; [RF] Avoid need for buildLoopBegin() by recursive calls to translate(); [RF] Add 'translate' to RooNllVarNew.; [RF] Remove function declarations in RooStats LinkDef.h; [RF] Apply clang-format to ModelConfig.h and ModelConfig.cxx; [RF] Move `ModelConfig` from RooStats to RooFit; [RF] Don't add `weightVar` to observables in HistFactory; [RF] Minor improvements to RooFit evaluation code generation; [RF][NFC] Fix typo.; [RF] Disable RooFuncWrapper test if clad is off.; [RF] Remove wrong header declaration from roofit/roofit.; [RF] Fix visibility of the res/ directories.; [RF] Make RooBatchCompute dependency public.; [RF] Add initial interface and implementation for code-squashing.; [RF][HS3] Put exported `histosys` in the correct vector; [RF][HS3] Avoid creating temporary objects to import into workspace; [RF][HS3][HF] General cleanup of HS3 HistFactory implementation; [RF][HS3] Cover also `HistoSys` in HS3 HistFactory test; [RF] Enable passing of gradient function directly to RooMinimizer; [RF] Add support for differentiating Gaussian integrals using AD. This commits adds support for including analytical integrals into the mock code-squashing test by introducing a private header that stores the stateless implementation details.; [RF][HS3] Consistent range for nominal alpha params with HistFactory; [RF][HS3] Remember simultaneous channel names when writing JSON; [RF][HS3] Avoid turning RooConstVar into RooRealVar in JSON roundtrip; [RF][HS3] Use `RooConstVar` for sigma parameters in HF constraints; [RF][HS3] Don't mix up free functions and class impl in JSON tool; [RF][HS3,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12618#issuecomment-1497317057
Modifiability,variab,variables,"ls using AD. This commits adds support for including analytical integrals into the mock code-squashing test by introducing a private header that stores the stateless implementation details.; [RF][HS3] Consistent range for nominal alpha params with HistFactory; [RF][HS3] Remember simultaneous channel names when writing JSON; [RF][HS3] Avoid turning RooConstVar into RooRealVar in JSON roundtrip; [RF][HS3] Use `RooConstVar` for sigma parameters in HF constraints; [RF][HS3] Don't mix up free functions and class impl in JSON tool; [RF][HS3] Consistently have implicit fallback for HistFactory variables; [RF][HS3] Don't import datasets that are parts of a combined dataset; [RF][HS3] Some code simplification in `RooJSONFactoryWSTool`; [RF][HS3] Generate input file for testHS3HistFactory on the fly; [RF][HS3] Improvements to the HS3 HistFactory implementation; [RF] Use `std::vector` diretly in RooVectorDataStore::RealFullVector; [RF][HS3] Some refactoring for less lines of code; [RF][HS3] Ordering fixes; [RF][HS3] Achieved closure for ATLAS ttW workspace; [RF][HS3] Sorting distributions; [RF][HS3] Bugfixes for histfactory workspaces; [RF][HS3] Small renamings; [RF][HS3] Improved attribute handling, caught some typecast-errors; [RF][HS3] Bugfix for FlexibleInterpVar; [RF] Avoid unnecessary warnings in `FlexibleInterpVar::setInterpCode`; [RF] Enable analytic integration of RooHistPdfs with RooLinearVars; [RF] Replace `RooAbsReal::_lastNSet` pointer with ID of last normSet; [RF] Remove `evaluateSpan()` from RooGenericPdf and RooFormulaVar; [RF][HS3] Re-retrieve element after exporting dependants; [RF][HS3] Don't write `histfactory_dist` axes redundantly; [RF] Exclude RooHistError from IO; [RF] Remove `add(row, weight, weightError)` from RooAbsData interface; [RF] Code-format `testRooDataHist.cxx`; [RF][HS3] Change analysis and likelihoods fields to match HS3 standard; [RF] Remove native buffers from `RooVectorDataStore::RealFullVector`; [RF] Modernize `RooVectorDataStore::RealF",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12618#issuecomment-1497317057
Safety,redund,redundantly,"ls using AD. This commits adds support for including analytical integrals into the mock code-squashing test by introducing a private header that stores the stateless implementation details.; [RF][HS3] Consistent range for nominal alpha params with HistFactory; [RF][HS3] Remember simultaneous channel names when writing JSON; [RF][HS3] Avoid turning RooConstVar into RooRealVar in JSON roundtrip; [RF][HS3] Use `RooConstVar` for sigma parameters in HF constraints; [RF][HS3] Don't mix up free functions and class impl in JSON tool; [RF][HS3] Consistently have implicit fallback for HistFactory variables; [RF][HS3] Don't import datasets that are parts of a combined dataset; [RF][HS3] Some code simplification in `RooJSONFactoryWSTool`; [RF][HS3] Generate input file for testHS3HistFactory on the fly; [RF][HS3] Improvements to the HS3 HistFactory implementation; [RF] Use `std::vector` diretly in RooVectorDataStore::RealFullVector; [RF][HS3] Some refactoring for less lines of code; [RF][HS3] Ordering fixes; [RF][HS3] Achieved closure for ATLAS ttW workspace; [RF][HS3] Sorting distributions; [RF][HS3] Bugfixes for histfactory workspaces; [RF][HS3] Small renamings; [RF][HS3] Improved attribute handling, caught some typecast-errors; [RF][HS3] Bugfix for FlexibleInterpVar; [RF] Avoid unnecessary warnings in `FlexibleInterpVar::setInterpCode`; [RF] Enable analytic integration of RooHistPdfs with RooLinearVars; [RF] Replace `RooAbsReal::_lastNSet` pointer with ID of last normSet; [RF] Remove `evaluateSpan()` from RooGenericPdf and RooFormulaVar; [RF][HS3] Re-retrieve element after exporting dependants; [RF][HS3] Don't write `histfactory_dist` axes redundantly; [RF] Exclude RooHistError from IO; [RF] Remove `add(row, weight, weightError)` from RooAbsData interface; [RF] Code-format `testRooDataHist.cxx`; [RF][HS3] Change analysis and likelihoods fields to match HS3 standard; [RF] Remove native buffers from `RooVectorDataStore::RealFullVector`; [RF] Modernize `RooVectorDataStore::RealF",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12618#issuecomment-1497317057
Security,access,access,"ctionaries; [RF] Suggest alternative to RooDataSet c'tor that takes weight name; [RF] Add unit test for splitting RooDataSets with weight errors; [RF] Add weight errors and not weight squared when filling split data; [RF] Correctly propagate error storage in `RooDataSet::emptyClone()`; [RF][HS3] Don't assume that combined dataset name is always `""obsData""`; [RF][HS3] Use less `c_str()` conversions in RooFitHS3; [RF][HS3] New `wsEmplace()` method for creating objects in workspace; [RF][HS3] New `wsImport()` function to avoid repeating command args; [RF] Less manual memory management in RooAbsArg and RooProdGenContext; [RF] Code modernization of RooAbsReal; [RF][HS3] Renaming some distributions to conform with HS3 standard; [RF][HS3] Use HistFunc variables instead of underlying hist variables; [RF] Added protection against invalid variable names in createHistogram; [RF][HS3] Correct error messages when IO keys are missing; [RF][HS3] Code improvements in HS3 HistFactory; [RF][HS3] Small HS3 closure fixes; [RF][HS3] Import HistFactory constraints directly upon creation; [RF][HS3] Cleanup of generic functions to avoid using arguments; [RF][HS3] Don't import embedded data directly to RooWorkspace; [RF] Avoid false warnings in RooAbsReal::createHistogram(); [RF][HS3] Reduce verbosity of unit tests; [RF][HS3] Less usage of TString; [RF][HS3] Avoid code duplication when requesting RooArgLists and Sets; [RF][HS3] Remove unused functions from JSONFactories_HistFactory; [RF][HS3] Export `staterror` correctly for HistFactory; [RF][HS3] Major restructuring of HistFactory in HS3 - part 2; [RF][HS3] Major refactoring of `JSONFactories_HistFactory`; [RF][HS3] Correctly consider weight errors in `readBinnedData()`; [RF][HS3] Small code style improvement (renaming); [RF][HS3] Make `testHS3HistFactory` less verbose; [RF][HS3] Changed some JSON keywords to comply with new HS3 standard; [RF][HS3] Moved `DependencyMissingError` to public to make it catchable; [RF][HS3] Support MultiVarGauss",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12618#issuecomment-1497317057
Testability,test,test,ry leaks from `RooAbsL::getParameters()`; fb891723bc [RF][HS3] Avoid code duplication in `JSONFactories_RooFitCore`; 9a605d7f35 [RF][HS3] Make `combined_data_name` optional; b87c368b6a [RF][HS3] Keep all info necessary to reconstruct simultaneous pdfs; f9348f857c [RF][HS3] Don't convert RooHistPdf first to TH1 when exporting; 195d5b8111 [RF][HS3] Additions to JSONInterface to reduce code duplication; a75dec1868 [RF][HS3] Keep all information necessary to reconstruct combined datas; [RF] Move loop management for code generation into CodeSquashContext; [RF] Avoid need for buildLoopBegin() by recursive calls to translate(); [RF] Add 'translate' to RooNllVarNew.; [RF] Remove function declarations in RooStats LinkDef.h; [RF] Apply clang-format to ModelConfig.h and ModelConfig.cxx; [RF] Move `ModelConfig` from RooStats to RooFit; [RF] Don't add `weightVar` to observables in HistFactory; [RF] Minor improvements to RooFit evaluation code generation; [RF][NFC] Fix typo.; [RF] Disable RooFuncWrapper test if clad is off.; [RF] Remove wrong header declaration from roofit/roofit.; [RF] Fix visibility of the res/ directories.; [RF] Make RooBatchCompute dependency public.; [RF] Add initial interface and implementation for code-squashing.; [RF][HS3] Put exported `histosys` in the correct vector; [RF][HS3] Avoid creating temporary objects to import into workspace; [RF][HS3][HF] General cleanup of HS3 HistFactory implementation; [RF][HS3] Cover also `HistoSys` in HS3 HistFactory test; [RF] Enable passing of gradient function directly to RooMinimizer; [RF] Add support for differentiating Gaussian integrals using AD. This commits adds support for including analytical integrals into the mock code-squashing test by introducing a private header that stores the stateless implementation details.; [RF][HS3] Consistent range for nominal alpha params with HistFactory; [RF][HS3] Remember simultaneous channel names when writing JSON; [RF][HS3] Avoid turning RooConstVar into RooRealVar in JSON ro,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12618#issuecomment-1497317057
Usability,simpl,simplification,"ls using AD. This commits adds support for including analytical integrals into the mock code-squashing test by introducing a private header that stores the stateless implementation details.; [RF][HS3] Consistent range for nominal alpha params with HistFactory; [RF][HS3] Remember simultaneous channel names when writing JSON; [RF][HS3] Avoid turning RooConstVar into RooRealVar in JSON roundtrip; [RF][HS3] Use `RooConstVar` for sigma parameters in HF constraints; [RF][HS3] Don't mix up free functions and class impl in JSON tool; [RF][HS3] Consistently have implicit fallback for HistFactory variables; [RF][HS3] Don't import datasets that are parts of a combined dataset; [RF][HS3] Some code simplification in `RooJSONFactoryWSTool`; [RF][HS3] Generate input file for testHS3HistFactory on the fly; [RF][HS3] Improvements to the HS3 HistFactory implementation; [RF] Use `std::vector` diretly in RooVectorDataStore::RealFullVector; [RF][HS3] Some refactoring for less lines of code; [RF][HS3] Ordering fixes; [RF][HS3] Achieved closure for ATLAS ttW workspace; [RF][HS3] Sorting distributions; [RF][HS3] Bugfixes for histfactory workspaces; [RF][HS3] Small renamings; [RF][HS3] Improved attribute handling, caught some typecast-errors; [RF][HS3] Bugfix for FlexibleInterpVar; [RF] Avoid unnecessary warnings in `FlexibleInterpVar::setInterpCode`; [RF] Enable analytic integration of RooHistPdfs with RooLinearVars; [RF] Replace `RooAbsReal::_lastNSet` pointer with ID of last normSet; [RF] Remove `evaluateSpan()` from RooGenericPdf and RooFormulaVar; [RF][HS3] Re-retrieve element after exporting dependants; [RF][HS3] Don't write `histfactory_dist` axes redundantly; [RF] Exclude RooHistError from IO; [RF] Remove `add(row, weight, weightError)` from RooAbsData interface; [RF] Code-format `testRooDataHist.cxx`; [RF][HS3] Change analysis and likelihoods fields to match HS3 standard; [RF] Remove native buffers from `RooVectorDataStore::RealFullVector`; [RF] Modernize `RooVectorDataStore::RealF",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12618#issuecomment-1497317057
Availability,error,error-on-ubuntu-externally-managed-environment,"Hi @dpiparo and thanks a lot @adriansev for this useful report!. Yes, there is probably even more breakage than before now that the `cppyy` in ROOT is synced more with `cppyy` upstream. More files are expected to collide. The cppyy module is part of ROOT, and if you install it in two different ways in the same environment (standalone and via ROOT), clashes are bound to happen. So the question to @adriansev is really: what's your usecase for installing cppyy in two different ways in the same environment? What does cppyy standalone give you that you won't get with ROOT? And why is the recommended way of dealing with this (virtual environments) not an option for you?. Many Linux distributions even *force* you to use virtual environments and don't allow `pip install --user` outside of virtual environments anymore. E.g. Arch, NixOS, or Ubuntu:; * https://askubuntu.com/questions/1465218/pip-error-on-ubuntu-externally-managed-environment-%C3%97-this-environment-is-extern. So given that your usecase is against good practices and that it's expected that if you install the same library from two different sources you get breakage, I'm in favor of closing this as ""not planned"" unless @adriansev can follow up with a clear motivation :slightly_smiling_face:",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12635#issuecomment-2314956198
Deployability,install,install,"Hi @dpiparo and thanks a lot @adriansev for this useful report!. Yes, there is probably even more breakage than before now that the `cppyy` in ROOT is synced more with `cppyy` upstream. More files are expected to collide. The cppyy module is part of ROOT, and if you install it in two different ways in the same environment (standalone and via ROOT), clashes are bound to happen. So the question to @adriansev is really: what's your usecase for installing cppyy in two different ways in the same environment? What does cppyy standalone give you that you won't get with ROOT? And why is the recommended way of dealing with this (virtual environments) not an option for you?. Many Linux distributions even *force* you to use virtual environments and don't allow `pip install --user` outside of virtual environments anymore. E.g. Arch, NixOS, or Ubuntu:; * https://askubuntu.com/questions/1465218/pip-error-on-ubuntu-externally-managed-environment-%C3%97-this-environment-is-extern. So given that your usecase is against good practices and that it's expected that if you install the same library from two different sources you get breakage, I'm in favor of closing this as ""not planned"" unless @adriansev can follow up with a clear motivation :slightly_smiling_face:",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12635#issuecomment-2314956198
Usability,clear,clear,"Hi @dpiparo and thanks a lot @adriansev for this useful report!. Yes, there is probably even more breakage than before now that the `cppyy` in ROOT is synced more with `cppyy` upstream. More files are expected to collide. The cppyy module is part of ROOT, and if you install it in two different ways in the same environment (standalone and via ROOT), clashes are bound to happen. So the question to @adriansev is really: what's your usecase for installing cppyy in two different ways in the same environment? What does cppyy standalone give you that you won't get with ROOT? And why is the recommended way of dealing with this (virtual environments) not an option for you?. Many Linux distributions even *force* you to use virtual environments and don't allow `pip install --user` outside of virtual environments anymore. E.g. Arch, NixOS, or Ubuntu:; * https://askubuntu.com/questions/1465218/pip-error-on-ubuntu-externally-managed-environment-%C3%97-this-environment-is-extern. So given that your usecase is against good practices and that it's expected that if you install the same library from two different sources you get breakage, I'm in favor of closing this as ""not planned"" unless @adriansev can follow up with a clear motivation :slightly_smiling_face:",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12635#issuecomment-2314956198
Usability,simpl,simpler,"When using the non-homebrew cmake, make sure you removed the previous CMakeCache.txt. As a brutal measure you can temporarily rename/ops/homebrew; that should also move it out of the way... Can you explain why you don't want to use homebrew's build of ROOT? This seems much simpler than building ROOT yourself - unless you want to help develop ROOT, of course! ;-)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12648#issuecomment-1523186097
Availability,error,error,"> @cxwx please do not try to find workarounds when I try to find the source of the issues; we really don't want our users to pile up workarounds. sorry for that. > Can you explain why you don't want to use homebrew's build of ROOT? This seems much simpler than building ROOT yourself - unless you want to help develop ROOT, of course! ;-). I thought Josiah1 may meet the same problem, The home-brew root is still ver6.26.06(not upgrade), ; brew install --build-from-source also failed with the old version.; when using rootcling to generate DICTIONARY, it cause . ```; In file included from input_line_1:1:; In file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX13.sdk/usr/include/c++/v1/new:93:; /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX13.sdk/usr/include/c++/v1/cstdlib:135:9: error: no member named 'at_quick_exit' in the global namespace; using ::at_quick_exit _LIBCPP_USING_IF_EXISTS;; ~~^; /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX13.sdk/usr/include/c++/v1/cstdlib:136:9: error: no member named 'quick_exit' in the global namespace; using ::quick_exit _LIBCPP_USING_IF_EXISTS;; ~~^; In file included from input_line_1:1:; In file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX13.sdk/usr/include/c++/v1/new:94:; In file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX13.sdk/usr/include/c++/v1/exception:85:; In file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX13.sdk/usr/include/c++/v1/type_traits:485:; /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX13.sdk/usr/include/c++/v1/__type_traits/is_pod.h:29:38: error: no template named 'is_trivially_default_constructible'; did you mean; 'is_nothrow_default_constructible'?; :",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12648#issuecomment-1523361441
Deployability,upgrade,upgrade,"> @cxwx please do not try to find workarounds when I try to find the source of the issues; we really don't want our users to pile up workarounds. sorry for that. > Can you explain why you don't want to use homebrew's build of ROOT? This seems much simpler than building ROOT yourself - unless you want to help develop ROOT, of course! ;-). I thought Josiah1 may meet the same problem, The home-brew root is still ver6.26.06(not upgrade), ; brew install --build-from-source also failed with the old version.; when using rootcling to generate DICTIONARY, it cause . ```; In file included from input_line_1:1:; In file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX13.sdk/usr/include/c++/v1/new:93:; /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX13.sdk/usr/include/c++/v1/cstdlib:135:9: error: no member named 'at_quick_exit' in the global namespace; using ::at_quick_exit _LIBCPP_USING_IF_EXISTS;; ~~^; /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX13.sdk/usr/include/c++/v1/cstdlib:136:9: error: no member named 'quick_exit' in the global namespace; using ::quick_exit _LIBCPP_USING_IF_EXISTS;; ~~^; In file included from input_line_1:1:; In file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX13.sdk/usr/include/c++/v1/new:94:; In file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX13.sdk/usr/include/c++/v1/exception:85:; In file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX13.sdk/usr/include/c++/v1/type_traits:485:; /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX13.sdk/usr/include/c++/v1/__type_traits/is_pod.h:29:38: error: no template named 'is_trivially_default_constructible'; did you mean; 'is_nothrow_default_constructible'?; :",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12648#issuecomment-1523361441
Usability,simpl,simpler,"> @cxwx please do not try to find workarounds when I try to find the source of the issues; we really don't want our users to pile up workarounds. sorry for that. > Can you explain why you don't want to use homebrew's build of ROOT? This seems much simpler than building ROOT yourself - unless you want to help develop ROOT, of course! ;-). I thought Josiah1 may meet the same problem, The home-brew root is still ver6.26.06(not upgrade), ; brew install --build-from-source also failed with the old version.; when using rootcling to generate DICTIONARY, it cause . ```; In file included from input_line_1:1:; In file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX13.sdk/usr/include/c++/v1/new:93:; /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX13.sdk/usr/include/c++/v1/cstdlib:135:9: error: no member named 'at_quick_exit' in the global namespace; using ::at_quick_exit _LIBCPP_USING_IF_EXISTS;; ~~^; /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX13.sdk/usr/include/c++/v1/cstdlib:136:9: error: no member named 'quick_exit' in the global namespace; using ::quick_exit _LIBCPP_USING_IF_EXISTS;; ~~^; In file included from input_line_1:1:; In file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX13.sdk/usr/include/c++/v1/new:94:; In file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX13.sdk/usr/include/c++/v1/exception:85:; In file included from /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX13.sdk/usr/include/c++/v1/type_traits:485:; /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX13.sdk/usr/include/c++/v1/__type_traits/is_pod.h:29:38: error: no template named 'is_trivially_default_constructible'; did you mean; 'is_nothrow_default_constructible'?; :",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12648#issuecomment-1523361441
Availability,error,errors,"> the APPLE system SDK has changed. @cxwx I agree. But I can't figure out why you can build successfully by turning off some options, but I can't. I also updated the command line tool to 14.3, did you?. > When using the non-homebrew cmake, make sure you removed the previous CMakeCache.txt. As a brutal measure you can temporarily rename/ops/homebrew; that should also move it out of the way... @Axel-Naumann Sure. I cleared all files when I built. It may work but I need to install the dependencies manually, which is also an annoying thing. ; And I do think there is something new happening for these building errors other than homebrew things. rootfit and glew errors are always there no matter if I use external dependencies or builtins. I have never encountered these errors before. >Can you explain why you don't want to use homebrew's build of ROOT? This seems much simpler than building ROOT yourself - unless you want to help develop ROOT, of course! ;-). It really isn't necessary, it's just a habit. In addition to macos, I also use root on various versions of linux servers. For the latter, in most cases, I can only compile it myself. And we have many codes that depend on root, so we hope that root's compilation options can be mastered by ourselves. As for contributing to the development of root, I hope that I can do it in the future, but at present more is to use root to complete physical analysis. Thank you for your invaluable contributions!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12648#issuecomment-1523586633
Deployability,update,updated,"> the APPLE system SDK has changed. @cxwx I agree. But I can't figure out why you can build successfully by turning off some options, but I can't. I also updated the command line tool to 14.3, did you?. > When using the non-homebrew cmake, make sure you removed the previous CMakeCache.txt. As a brutal measure you can temporarily rename/ops/homebrew; that should also move it out of the way... @Axel-Naumann Sure. I cleared all files when I built. It may work but I need to install the dependencies manually, which is also an annoying thing. ; And I do think there is something new happening for these building errors other than homebrew things. rootfit and glew errors are always there no matter if I use external dependencies or builtins. I have never encountered these errors before. >Can you explain why you don't want to use homebrew's build of ROOT? This seems much simpler than building ROOT yourself - unless you want to help develop ROOT, of course! ;-). It really isn't necessary, it's just a habit. In addition to macos, I also use root on various versions of linux servers. For the latter, in most cases, I can only compile it myself. And we have many codes that depend on root, so we hope that root's compilation options can be mastered by ourselves. As for contributing to the development of root, I hope that I can do it in the future, but at present more is to use root to complete physical analysis. Thank you for your invaluable contributions!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12648#issuecomment-1523586633
Integrability,depend,dependencies,"> the APPLE system SDK has changed. @cxwx I agree. But I can't figure out why you can build successfully by turning off some options, but I can't. I also updated the command line tool to 14.3, did you?. > When using the non-homebrew cmake, make sure you removed the previous CMakeCache.txt. As a brutal measure you can temporarily rename/ops/homebrew; that should also move it out of the way... @Axel-Naumann Sure. I cleared all files when I built. It may work but I need to install the dependencies manually, which is also an annoying thing. ; And I do think there is something new happening for these building errors other than homebrew things. rootfit and glew errors are always there no matter if I use external dependencies or builtins. I have never encountered these errors before. >Can you explain why you don't want to use homebrew's build of ROOT? This seems much simpler than building ROOT yourself - unless you want to help develop ROOT, of course! ;-). It really isn't necessary, it's just a habit. In addition to macos, I also use root on various versions of linux servers. For the latter, in most cases, I can only compile it myself. And we have many codes that depend on root, so we hope that root's compilation options can be mastered by ourselves. As for contributing to the development of root, I hope that I can do it in the future, but at present more is to use root to complete physical analysis. Thank you for your invaluable contributions!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12648#issuecomment-1523586633
Usability,clear,cleared,"> the APPLE system SDK has changed. @cxwx I agree. But I can't figure out why you can build successfully by turning off some options, but I can't. I also updated the command line tool to 14.3, did you?. > When using the non-homebrew cmake, make sure you removed the previous CMakeCache.txt. As a brutal measure you can temporarily rename/ops/homebrew; that should also move it out of the way... @Axel-Naumann Sure. I cleared all files when I built. It may work but I need to install the dependencies manually, which is also an annoying thing. ; And I do think there is something new happening for these building errors other than homebrew things. rootfit and glew errors are always there no matter if I use external dependencies or builtins. I have never encountered these errors before. >Can you explain why you don't want to use homebrew's build of ROOT? This seems much simpler than building ROOT yourself - unless you want to help develop ROOT, of course! ;-). It really isn't necessary, it's just a habit. In addition to macos, I also use root on various versions of linux servers. For the latter, in most cases, I can only compile it myself. And we have many codes that depend on root, so we hope that root's compilation options can be mastered by ourselves. As for contributing to the development of root, I hope that I can do it in the future, but at present more is to use root to complete physical analysis. Thank you for your invaluable contributions!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12648#issuecomment-1523586633
Usability,feedback,feedback,"Alright, thanks again for the feedback!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12653#issuecomment-1507275282
Availability,error,error,"dy represent the yields that can be; // used by the RooNLLVar to sum the Poisson terms. However, this optimization; // doesn't work for this demo, maybe because it's not compatible with the; // RooBarlowBeestonLL. See also https://root.cern/doc/v628/release-notes.html.; HistoToWorkspaceFactoryFast::Configuration cfg;; cfg.binnedFitOptimization = false;; auto ws = RooStats::HistFactory::MakeModelAndMeasurementFast(meas, cfg);; #endif; ```. With this, the results I get with 6.28 are already more comparable to 6.24. Here the results of `fit-noshapes`:; ## ROOT 6.28. ```txt; FVAL = -1581.9159109118475; Edm = 0.000441898404860980383; Nfcn = 187; Lumi	 = 0.937281	 +/- 0.041571	(limited); Nmu	 = 68079	 +/- 3149.09	(limited); RawRDst	 = 0.0394995	 +/- 0.00466377	(limited); alpha_BFD1	 = -1.56966	 +/- 0.268056	(limited); Info in <Minuit2>: Minuit2Minimizer::Hesse Using max-calls 2000; Info in <Minuit2>: Minuit2Minimizer::Hesse Hesse is valid - matrix is accurate; 0.000441626; Fit ran with status 0; Stat error on R(D*) is 0.004650; EDM at end was 0.000442; RooArgList:: = (Lumi,Nmu,RawRDst,alpha_BFD1); CURRENT NUISANCE PARAMETERS:; 0: Lumi			 = 0.937281 +/- 0.0414063; 1: Nmu			 = 68079 +/- 3136.33; 3: alpha_BFD1			 = -1.56966 +/- 0.267557; ```. ## ROOT 6.24; ```txt; FVAL = -1581.92046482683691; Edm = 1.80973200685341769e-07; Nfcn = 258; Lumi	 = 0.936911	 +/- 0.041654	(limited); Nmu	 = 63811.4	 +/- 402.673	(limited); RawRDst	 = 0.0394923	 +/- 0.00466481	(limited); alpha_BFD1	 = -1.56652	 +/- 0.266527	(limited); Info in <Minuit2>: Minuit2Minimizer::Hesse Using max-calls 2000; Info in <Minuit2>: Minuit2Minimizer::Hesse Hesse is valid - matrix is accurate; 1.8221e-07; Fit ran with status 0; Stat error on R(D*) is 0.004658; EDM at end was 0.000000; RooArgList:: = (Lumi,Nmu,RawRDst,alpha_BFD1); CURRENT NUISANCE PARAMETERS:; 0: Lumi			 = 0.936911 +/- 0.0416284; 1: Nmu			 = 63811.4 +/- 401.335; 3: alpha_BFD1			 = -1.56652 +/- 0.264945; ```. There are still some problems. The produced p",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12729#issuecomment-1527829256
Deployability,release,release-notes,"Hi, thanks for the reports! Okay, the problem with the `RooRealSumPdf` hinted me that this new optimization was part of the problem (look for ""binned likelihood fit optimization"").; https://root.cern/doc/v628/release-notes.html. This optimization was used inside ATLAS for a long time to great success (speedups), so I was enabling it by default. However, it seems to be problematic here, maybe it doesn't work with the RooBarlowBeestonLL. You should for now disable it when the demo is compiled with ROOT 6.28. So the line with `MakeModelAndMeasurementFast` in `histfact_demo.cpp` would become:; ```C++; #if ROOT_VERSION_CODE < ROOT_VERSION(6,28,00); auto ws = RooStats::HistFactory::MakeModelAndMeasurementFast(meas);; #else; // Disable the binned fit optimization that was enabled by default in ROOT 6.28.; // This optimization skips the normalization of the RooRealSumPdf, because; // the unnormalized bin contents already represent the yields that can be; // used by the RooNLLVar to sum the Poisson terms. However, this optimization; // doesn't work for this demo, maybe because it's not compatible with the; // RooBarlowBeestonLL. See also https://root.cern/doc/v628/release-notes.html.; HistoToWorkspaceFactoryFast::Configuration cfg;; cfg.binnedFitOptimization = false;; auto ws = RooStats::HistFactory::MakeModelAndMeasurementFast(meas, cfg);; #endif; ```. With this, the results I get with 6.28 are already more comparable to 6.24. Here the results of `fit-noshapes`:; ## ROOT 6.28. ```txt; FVAL = -1581.9159109118475; Edm = 0.000441898404860980383; Nfcn = 187; Lumi	 = 0.937281	 +/- 0.041571	(limited); Nmu	 = 68079	 +/- 3149.09	(limited); RawRDst	 = 0.0394995	 +/- 0.00466377	(limited); alpha_BFD1	 = -1.56966	 +/- 0.268056	(limited); Info in <Minuit2>: Minuit2Minimizer::Hesse Using max-calls 2000; Info in <Minuit2>: Minuit2Minimizer::Hesse Hesse is valid - matrix is accurate; 0.000441626; Fit ran with status 0; Stat error on R(D*) is 0.004650; EDM at end was 0.000442; RooArgList:: =",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12729#issuecomment-1527829256
Performance,optimiz,optimization,"Hi, thanks for the reports! Okay, the problem with the `RooRealSumPdf` hinted me that this new optimization was part of the problem (look for ""binned likelihood fit optimization"").; https://root.cern/doc/v628/release-notes.html. This optimization was used inside ATLAS for a long time to great success (speedups), so I was enabling it by default. However, it seems to be problematic here, maybe it doesn't work with the RooBarlowBeestonLL. You should for now disable it when the demo is compiled with ROOT 6.28. So the line with `MakeModelAndMeasurementFast` in `histfact_demo.cpp` would become:; ```C++; #if ROOT_VERSION_CODE < ROOT_VERSION(6,28,00); auto ws = RooStats::HistFactory::MakeModelAndMeasurementFast(meas);; #else; // Disable the binned fit optimization that was enabled by default in ROOT 6.28.; // This optimization skips the normalization of the RooRealSumPdf, because; // the unnormalized bin contents already represent the yields that can be; // used by the RooNLLVar to sum the Poisson terms. However, this optimization; // doesn't work for this demo, maybe because it's not compatible with the; // RooBarlowBeestonLL. See also https://root.cern/doc/v628/release-notes.html.; HistoToWorkspaceFactoryFast::Configuration cfg;; cfg.binnedFitOptimization = false;; auto ws = RooStats::HistFactory::MakeModelAndMeasurementFast(meas, cfg);; #endif; ```. With this, the results I get with 6.28 are already more comparable to 6.24. Here the results of `fit-noshapes`:; ## ROOT 6.28. ```txt; FVAL = -1581.9159109118475; Edm = 0.000441898404860980383; Nfcn = 187; Lumi	 = 0.937281	 +/- 0.041571	(limited); Nmu	 = 68079	 +/- 3149.09	(limited); RawRDst	 = 0.0394995	 +/- 0.00466377	(limited); alpha_BFD1	 = -1.56966	 +/- 0.268056	(limited); Info in <Minuit2>: Minuit2Minimizer::Hesse Using max-calls 2000; Info in <Minuit2>: Minuit2Minimizer::Hesse Hesse is valid - matrix is accurate; 0.000441626; Fit ran with status 0; Stat error on R(D*) is 0.004650; EDM at end was 0.000442; RooArgList:: =",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12729#issuecomment-1527829256
Usability,learn,learn,"eady more comparable to 6.24. Here the results of `fit-noshapes`:; ## ROOT 6.28. ```txt; FVAL = -1581.9159109118475; Edm = 0.000441898404860980383; Nfcn = 187; Lumi	 = 0.937281	 +/- 0.041571	(limited); Nmu	 = 68079	 +/- 3149.09	(limited); RawRDst	 = 0.0394995	 +/- 0.00466377	(limited); alpha_BFD1	 = -1.56966	 +/- 0.268056	(limited); Info in <Minuit2>: Minuit2Minimizer::Hesse Using max-calls 2000; Info in <Minuit2>: Minuit2Minimizer::Hesse Hesse is valid - matrix is accurate; 0.000441626; Fit ran with status 0; Stat error on R(D*) is 0.004650; EDM at end was 0.000442; RooArgList:: = (Lumi,Nmu,RawRDst,alpha_BFD1); CURRENT NUISANCE PARAMETERS:; 0: Lumi			 = 0.937281 +/- 0.0414063; 1: Nmu			 = 68079 +/- 3136.33; 3: alpha_BFD1			 = -1.56966 +/- 0.267557; ```. ## ROOT 6.24; ```txt; FVAL = -1581.92046482683691; Edm = 1.80973200685341769e-07; Nfcn = 258; Lumi	 = 0.936911	 +/- 0.041654	(limited); Nmu	 = 63811.4	 +/- 402.673	(limited); RawRDst	 = 0.0394923	 +/- 0.00466481	(limited); alpha_BFD1	 = -1.56652	 +/- 0.266527	(limited); Info in <Minuit2>: Minuit2Minimizer::Hesse Using max-calls 2000; Info in <Minuit2>: Minuit2Minimizer::Hesse Hesse is valid - matrix is accurate; 1.8221e-07; Fit ran with status 0; Stat error on R(D*) is 0.004658; EDM at end was 0.000000; RooArgList:: = (Lumi,Nmu,RawRDst,alpha_BFD1); CURRENT NUISANCE PARAMETERS:; 0: Lumi			 = 0.936911 +/- 0.0416284; 1: Nmu			 = 63811.4 +/- 401.335; 3: alpha_BFD1			 = -1.56652 +/- 0.264945; ```. There are still some problems. The produced plots don't look correct, and the `Nmu` parameter has an error that is way off. This is a problem I already see with 6.26, and it is probably related to the reorganization of the HistFactory model RooFit representation:; https://github.com/root-project/root/pull/8167. Indeed, it could be related to the new `RooBinWidthFunction`. I can only continue the investigation next week on Wednesday, if you learn something new in the meantime @yipengsun and @CoffeeIntoScience please let me know!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12729#issuecomment-1527829256
Usability,simpl,simple,"Apparently, this is due to a flaw in the implementation of `RColumn::AppendV()` (whose only current user seems to be `RField<std::string>`). The following simple excerpt reproduces the problem:; ```c++; auto model = RNTupleModel::Create();; auto str = model->MakeField<std::string>(""str"");. RNTupleWriteOptions options;; options.SetApproxUnzippedPageSize(16);; {; auto ntuple = RNTupleWriter::Recreate(std::move(model), ""ntuple"", ""/tmp/out.ntuple"", options);; *str = ""01234567890123456789012"";; ntuple->Fill();; *str = ""012"";; ntuple->Fill();; }; ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12742#issuecomment-1529137927
Usability,guid,guide,"Thank you very much! I'm sure there must be a way to do that. However, I think this must be a rather rare demand, so this should be some second-order feature...; But it may also be that it is already possible through command line/environment arguments - maybe someone who knows CMake could guide how to do that.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12744#issuecomment-1549824735
Usability,intuit,intuitive,"Okay, putting the ""right"" `gcc` into `$PATH` works, though I have to say this is *very* counter-intuitive...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12747#issuecomment-1532508987
Availability,error,error,"ble> m_vIntDataSD[NUMBER_OF_COLORS];; 	std::vector<double> m_vPkRatio;; 	std::vector<int> m_vEvtErr;; 	std::vector<double> m_vEvRate;; 	std::vector<double> m_vGEV;; 	std::vector<int> m_vChEnbMask;. 	bool m_bAllChannelsEnabled;; ```. Here, NUMBER_OF_COLORS = 5. The generated _dict file in root 5 show, at one point (note the vector declaration), . ```; {; for (Int_t R__l = 0; R__l < 5; R__l++) {; vector<double> &R__stl = m_vIntData[R__l];; R__stl.clear();; int R__i, R__n;; R__b >> R__n;; R__stl.reserve(R__n);; for (R__i = 0; R__i < R__n; R__i++) {; double R__t;; R__b >> R__t;; R__stl.push_back(R__t);; }; }; }; ```. This seems to work well. But in root 6 it produces (note the [5] after vector<double>). ```; for (Int_t R__l = 0; R__l < 5; R__l++) {; vector<double>[5] &R__stl = m_vIntData[R__l];; R__stl.clear();; int R__i, R__n;; R__b >> R__n;; R__stl.reserve(R__n);; for (R__i = 0; R__i < R__n; R__i++) {; double R__t;; R__b >> R__t;; R__stl.push_back(R__t);; }; }; }. ```. this produces the compilation error:. ```; g++ -O -Wall -fPIC -pthread -std=c++14 -m64 -I/usr/include/root -I/home/vmecomp/Projects/Cytogate/CytCommon -I../../Include -I. -I/usr/include -I/home/vmecomp/Projects/Cytogate/Bus -I/home/vmecomp/Projects/Cytogate/Include -I/home/vmecomp/Projects/Cytogate/CytCommon -I/usr/include/root -c -o CytStatInfo_dict.o CytStatInfo_dict.C; CytStatInfo_dict.C: In member function virtual void CytStatInfo::Streamer(TBuffer&):; CytStatInfo_dict.C:202:25: error: expected identifier before numeric constant; vector<double>[5] &R__stl = m_vIntData[R__l];; ^; CytStatInfo_dict.C:202:25: error: expected ] before numeric constant; vector<double>[5] &R__stl = m_vIntData[R__l];; ^; ]; CytStatInfo_dict.C:202:24: warning: structured bindings only available with -std=c++17 or -std=gnu++17; vector<double>[5] &R__stl = m_vIntData[R__l];; ```. It is possible that root is expecting better coding than my app shows, so if I'm doing something wrong please let me know. I include below the ta",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12755#issuecomment-1534658132
Usability,clear,clear,"he app is not able to go forward. . As a summary of the problem, it shows up on the lines of m_vIntData and m_vIntDatSD, below:; ```; class CytStatInfo : public TObject {; private:; 	int m_iMachineSize;; 	int m_bMachineSizeSet;; 	double m_dMotorPos;; 	int m_iFIndex;; 	std::vector<int> m_vChNum;; 	std::vector<int> m_vNoEv;; 	std::vector<long long> m_vTsFirst;; 	std::vector<double> m_vVel;; 	std::vector<double> m_vOpPow;; 	std::vector<double> m_vPulseMag;; 	std::vector<double> m_vIntData[NUMBER_OF_COLORS];; 	std::vector<double> m_vIntDataSD[NUMBER_OF_COLORS];; 	std::vector<double> m_vPkRatio;; 	std::vector<int> m_vEvtErr;; 	std::vector<double> m_vEvRate;; 	std::vector<double> m_vGEV;; 	std::vector<int> m_vChEnbMask;. 	bool m_bAllChannelsEnabled;; ```. Here, NUMBER_OF_COLORS = 5. The generated _dict file in root 5 show, at one point (note the vector declaration), . ```; {; for (Int_t R__l = 0; R__l < 5; R__l++) {; vector<double> &R__stl = m_vIntData[R__l];; R__stl.clear();; int R__i, R__n;; R__b >> R__n;; R__stl.reserve(R__n);; for (R__i = 0; R__i < R__n; R__i++) {; double R__t;; R__b >> R__t;; R__stl.push_back(R__t);; }; }; }; ```. This seems to work well. But in root 6 it produces (note the [5] after vector<double>). ```; for (Int_t R__l = 0; R__l < 5; R__l++) {; vector<double>[5] &R__stl = m_vIntData[R__l];; R__stl.clear();; int R__i, R__n;; R__b >> R__n;; R__stl.reserve(R__n);; for (R__i = 0; R__i < R__n; R__i++) {; double R__t;; R__b >> R__t;; R__stl.push_back(R__t);; }; }; }. ```. this produces the compilation error:. ```; g++ -O -Wall -fPIC -pthread -std=c++14 -m64 -I/usr/include/root -I/home/vmecomp/Projects/Cytogate/CytCommon -I../../Include -I. -I/usr/include -I/home/vmecomp/Projects/Cytogate/Bus -I/home/vmecomp/Projects/Cytogate/Include -I/home/vmecomp/Projects/Cytogate/CytCommon -I/usr/include/root -c -o CytStatInfo_dict.o CytStatInfo_dict.C; CytStatInfo_dict.C: In member function virtual void CytStatInfo::Streamer(TBuffer&):; CytStatInfo_dict.C:202:25: er",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12755#issuecomment-1534658132
Usability,clear,clear,The failing part is:; ```; /Users/ktf/src/sw/osx_arm64/AliEn-Runtime/v2-19-le-local1/include/ApMon.h:59:9: note: expanding this definition of '_POSIX_VERSION'; #define _POSIX_VERSION 200101L; ^; /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX.sdk/usr/include/sys/unistd.h:79:9: note: other definition of '_POSIX_VERSION'; #define _POSIX_VERSION 200112L; ^; ```; One of the two might be coming (indirectly) through a precompiled module (associated with a dictionary). It is not clear why `ApMon.h` does not include `unistd.h` in the first place.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12762#issuecomment-1535382726
Usability,clear,clear,"> It is not clear why `ApMon.h` does not include `unistd.h` in the first place. It actually does, but only later in the the compilation unit. I think this is some weird SunOS heritage (sigh). I am trying to see if I can simply get rid of that part.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12762#issuecomment-1535844840
Usability,clear,clear,"Dear @jan-busa , @lmoneta : it is not clear to me from the conversation if this is still an issue. If not, can this be closed?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12770#issuecomment-1926372761
Deployability,release,release,"Thank you very much! Great that is works now!. The fix also needs to be backported to the 6.26 branch, since the problem is also in that release cycle since 6.26.02. I would appreciate if at some point there would be another 6.26 patch release. In RooFit, the small bug fixes were already piling up:; https://github.com/root-project/root/issues/11534. And especially with this issue fixed, a new release could be worthwhile. We know that this bug broke some ATLAS RooFit workspaces already, so this fix has a clear benefit. I'll ask ATLAS whether it helps to have a patch release for 6.26 or if they moved on to 6.28 anyway.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12783#issuecomment-1556797954
Usability,clear,clear,"Thank you very much! Great that is works now!. The fix also needs to be backported to the 6.26 branch, since the problem is also in that release cycle since 6.26.02. I would appreciate if at some point there would be another 6.26 patch release. In RooFit, the small bug fixes were already piling up:; https://github.com/root-project/root/issues/11534. And especially with this issue fixed, a new release could be worthwhile. We know that this bug broke some ATLAS RooFit workspaces already, so this fix has a clear benefit. I'll ask ATLAS whether it helps to have a patch release for 6.26 or if they moved on to 6.28 anyway.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12783#issuecomment-1556797954
Testability,test,tested,"@hahnjo Hi, I finally found some time to get this building, the branch now seems to somewhat work. Few things:; - it seems not to break the linux build; - seems to work for now, in whatever simple scenarios I have tested it till now; - the TThread tests crap out saying the _REENTRANT macro is not defined (I think it should be by -pthread which is enabled), probably needs some attention by an expert.; - there is an issue with library unload order vs the thread local dtor calling. Not a dealbreaker but the FreeBSD __cxa_thread_call_dtors is a bit verbose and prints warnings to stderr about that. Also here there is quite some room for experts to look at since there already are mitigations to similar issues in the code. (__cxa_thread_call_dtors: dtr 0x82b2c78f0 from unloaded dso, skipping); - actually a lot more tests fail - what is the general state of the test results on the master branch?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12787#issuecomment-1585584886
Usability,simpl,simple,"@hahnjo Hi, I finally found some time to get this building, the branch now seems to somewhat work. Few things:; - it seems not to break the linux build; - seems to work for now, in whatever simple scenarios I have tested it till now; - the TThread tests crap out saying the _REENTRANT macro is not defined (I think it should be by -pthread which is enabled), probably needs some attention by an expert.; - there is an issue with library unload order vs the thread local dtor calling. Not a dealbreaker but the FreeBSD __cxa_thread_call_dtors is a bit verbose and prints warnings to stderr about that. Also here there is quite some room for experts to look at since there already are mitigations to similar issues in the code. (__cxa_thread_call_dtors: dtr 0x82b2c78f0 from unloaded dso, skipping); - actually a lot more tests fail - what is the general state of the test results on the master branch?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12787#issuecomment-1585584886
Availability,error,error,"> However, ROOT accepts the code without complaint.; > That actually is the issue. In your original post, you mention that the behaviour you expect to see is that both parameters should be usable. Implementing this would mean openly violating C++ standard (even further than CINT already did at the time of ROOT 5.34). On the other hand, a proper fix would be raising a compiler error. I am unsure whether providing such a fix for CINT is what we want, cling already works properly and it's just a matter of updating the ROOT version. I will leave to @Axel-Naumann the final say on this. In any case, isn't it possible for you to declare functions on your application side that do not have a trailing comma?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12840#issuecomment-1570855626
Usability,usab,usable,"> However, ROOT accepts the code without complaint.; > That actually is the issue. In your original post, you mention that the behaviour you expect to see is that both parameters should be usable. Implementing this would mean openly violating C++ standard (even further than CINT already did at the time of ROOT 5.34). On the other hand, a proper fix would be raising a compiler error. I am unsure whether providing such a fix for CINT is what we want, cling already works properly and it's just a matter of updating the ROOT version. I will leave to @Axel-Naumann the final say on this. In any case, isn't it possible for you to declare functions on your application side that do not have a trailing comma?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12840#issuecomment-1570855626
Availability,avail,available,"The code inlining mechanism uses the doxygen command [`\include`](https://www.doxygen.nl/manual/commands.html#cmdinclude). This command does not allow to specify the type of code to be inlined (C++ or python) the only two options available are `doc` and `lineno`. I guess the ""code"" is considered as C/C++ that's why the highlighting is not correct for that python example. I'll try to find a solution. The simplest would have been an option `.py` like for the `\code` doxygen command (see help). I tried but it does not work.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12851#issuecomment-1558888571
Usability,simpl,simplest,"The code inlining mechanism uses the doxygen command [`\include`](https://www.doxygen.nl/manual/commands.html#cmdinclude). This command does not allow to specify the type of code to be inlined (C++ or python) the only two options available are `doc` and `lineno`. I guess the ""code"" is considered as C/C++ that's why the highlighting is not correct for that python example. I'll try to find a solution. The simplest would have been an option `.py` like for the `\code` doxygen command (see help). I tried but it does not work.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12851#issuecomment-1558888571
Usability,clear,clear,"Hi @bendavid, with this PR we are officially not supporting to build ROOT with these minuit omp or mpi build options anymore:; * https://github.com/root-project/root/pull/12970. I'll close this issue here, because not it's clear that RooFit can't be used with Minuit2 multithreading. You are right that it's not unreasonable to expect that Minuit2 multithreading can be enabled/disabled at runtime, but this is another issue. Given the limited developer time we have, I think we need a better motivation than ""we realized it would be nice to have"" to implement this. If you have any usecase for Minuit 2 multithreading in ROOT that is covered by these flags, then please go ahead and open a new issue whenever :slightly_smiling_face:",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12940#issuecomment-1796837979
Deployability,install,install,"rc/TBufferFile.cxx:3580; #29 0x00007ffff76f1b94 in TBufferFile::ReadClassBuffer (this=0x7fffffffd9d0, cl=0x555558490b70, pointer=<optimized out>, onFileClass=<optimized out>); at /home/rembserj/spaces/master/root/src/root/io/io/src/TBufferFile.cxx:3499; #30 0x00007ffff778a22e in TClass::Streamer (onfile_class=0x0, b=..., obj=0x55555855a0c0, this=0x555558490b70); at /home/rembserj/spaces/master/root/src/root/core/meta/inc/TClass.h:610; #31 TKey::ReadObjectAny (this=0x5555569f77a0, expectedClass=<optimized out>) at /home/rembserj/spaces/master/root/src/root/io/io/src/TKey.cxx:1108; #32 0x00007ffff774aa1b in TDirectoryFile::GetObjectChecked (this=0x555556a15ce0, namecycle=<optimized out>, expectedClass=0x555558490b70); at /home/rembserj/spaces/master/root/src/root/io/io/src/TDirectoryFile.cxx:1111; #33 0x00005555555551f6 in TDirectory::Get<RooStats::HistFactory::Measurement> (this=0x555556a15ce0, namecycle=<optimized out>); at /home/rembserj/spaces/master/root/src/build/../install/include/root/TDirectory.h:207; #34 TDirectoryFile::Get<RooStats::HistFactory::Measurement> (this=0x555556a15ce0, namecycle=<optimized out>); at /home/rembserj/spaces/master/root/src/build/../install/include/root/TDirectoryFile.h:84; #35 repro () at repro.C:10; ```. So the crash is here (https://github.com/root-project/root/blob/master/io/io/src/TBufferFile.cxx#L245):; ```c++; if (nwh == 255) {; *this >> nbig;; obj->resize(nbig,'\0');; ReadFastArray((char*)obj->data(),nbig);; }; ```; I have put some debug printouts. When it crashes, `nbig` is `-1`, and resize() expects and unsigned int. The -1 becomes a very large unsigned number that exceeds the maximum allowed length of a `std::string`. To me that looks more like a problem with IO than with HistFactory (the memory layout of the `HistFactory::Measurement` classes hasn't changed from 6.26 to 6.28. Is that something that makes sense to you, @pcanal? What does this `nbig` stand for, and in which circumstances can this be `-1`?. Maybe in the best ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12967#issuecomment-1581261520
Modifiability,config,config," 0x00007ffff787d2bd in TStreamerInfo::ReadBufferSTL (v7=<optimized out>, eoffset=<optimized out>, nc=<optimized out>, cont=<optimized out>, b=...,; this=<optimized out>) at /home/rembserj/spaces/master/root/src/root/io/io/src/TStreamerInfoReadBuffer.cxx:1741; #20 TStreamerInfo::ReadBufferSTL (this=<optimized out>, b=..., cont=<optimized out>, nc=<optimized out>, eoffset=<optimized out>, v7=<optimized out>); at /home/rembserj/spaces/master/root/src/root/io/io/src/TStreamerInfoReadBuffer.cxx:1737; #21 0x00007ffff793f598 in TStreamerInfo::ReadBuffer<char**> (this=0x555558602630, b=..., arr=@0x7fffffffd740: 0x55555862ab20,; compinfo=compinfo@entry=0x55555862ab08, first=first@entry=0, last=last@entry=1, narr=2, eoffset=0, arrayMode=3); at /home/rembserj/spaces/master/root/src/root/io/io/src/TStreamerInfoReadBuffer.cxx:1274; #22 0x00007ffff77f92ac in TStreamerInfoActions::VectorLooper::GenericRead (buf=..., start=<optimized out>, end=0x555556a3aaa0, loopconfig=<optimized out>,; config=0x55555862aaf0) at /home/rembserj/spaces/master/root/src/root/io/io/src/TStreamerInfoActions.cxx:1883; #23 0x00007ffff76e978c in TStreamerInfoActions::TConfiguredAction::operator() (loopconf=0x55555862a9e0, end_collection=0x555556a3aaa0,; start_collection=0x555556a3a850, buffer=..., this=0x55555862a9b0) at /home/rembserj/spaces/master/root/src/root/io/io/inc/TStreamerInfoActions.h:131; #24 TBufferFile::ApplySequence (this=0x7fffffffd9d0, sequence=..., start_collection=0x555556a3a850, end_collection=0x555556a3aaa0); at /home/rembserj/spaces/master/root/src/root/io/io/src/TBufferFile.cxx:3646; #25 0x00007ffff781f65e in TStreamerInfoActions::ReadSTLMemberWiseSameClass (buf=..., addr=<optimized out>, conf=conf@entry=0x555558626dd0,; vers=<optimized out>) at /home/rembserj/spaces/master/root/src/root/io/io/src/TStreamerInfoActions.cxx:1155; #26 0x00007ffff781f896 in TStreamerInfoActions::ReadSTL<&TStreamerInfoActions::ReadSTLMemberWiseSameClass, &TStreamerInfoActions::ReadSTLObjectWiseFastArray>;",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12967#issuecomment-1581261520
Performance,optimiz,optimized,"Hi, thanks for reporting this!. It is indeed a bug that you can't read the 6.26 workspace in 6.28. The other way around is expected, with RooFit you can't read back a RooWorkspace with any ROOT version that is older that the version it was created with. When I run the reproducer in the debugger, I get this stack trace:; ```; Program received signal SIGABRT, Aborted.; 0x00007ffff4a9f26c in ?? () from /usr/lib/libc.so.6; (gdb) bt; #0 0x00007ffff4a9f26c in ?? () from /usr/lib/libc.so.6; #1 0x00007ffff4a4fa08 in raise () from /usr/lib/libc.so.6; #2 0x00007ffff4a38538 in abort () from /usr/lib/libc.so.6; #3 0x00007ffff4c9ca6f in __gnu_cxx::__verbose_terminate_handler () at /usr/src/debug/gcc/gcc/libstdc++-v3/libsupc++/vterminate.cc:95; #4 0x00007ffff4cb011c in __cxxabiv1::__terminate (handler=<optimized out>) at /usr/src/debug/gcc/gcc/libstdc++-v3/libsupc++/eh_terminate.cc:48; #5 0x00007ffff4cb0189 in std::terminate () at /usr/src/debug/gcc/gcc/libstdc++-v3/libsupc++/eh_terminate.cc:58; #6 0x00007ffff4cb03ed in __cxxabiv1::__cxa_throw (obj=<optimized out>, tinfo=0x7ffff4e6c0d0 <typeinfo for std::length_error>,; dest=0x7ffff4cc8580 <std::length_error::~length_error()>) at /usr/src/debug/gcc/gcc/libstdc++-v3/libsupc++/eh_throw.cc:98; #7 0x00007ffff4ca01ca in std::__throw_length_error (__s=__s@entry=0x7ffff79711aa ""basic_string::_M_replace_aux""); at /usr/src/debug/gcc/gcc/libstdc++-v3/src/c++11/functexcept.cc:82; #8 0x00007ffff76f2ae8 in std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::_M_check_length (__s=<optimized out>,; __n2=<optimized out>, __n1=<optimized out>, this=<optimized out>) at /usr/include/c++/13.1.1/bits/basic_string.h:403; #9 std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::_M_replace_aux (__c=<optimized out>, __n2=<optimized out>,; __n1=<optimized out>, __pos1=<optimized out>, this=<optimized out>) at /usr/include/c++/13.1.1/bits/basic_string.tcc:450; #10 std::__cxx11::basic_string<char, std::c",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12967#issuecomment-1581261520
Safety,abort,abort,"Hi, thanks for reporting this!. It is indeed a bug that you can't read the 6.26 workspace in 6.28. The other way around is expected, with RooFit you can't read back a RooWorkspace with any ROOT version that is older that the version it was created with. When I run the reproducer in the debugger, I get this stack trace:; ```; Program received signal SIGABRT, Aborted.; 0x00007ffff4a9f26c in ?? () from /usr/lib/libc.so.6; (gdb) bt; #0 0x00007ffff4a9f26c in ?? () from /usr/lib/libc.so.6; #1 0x00007ffff4a4fa08 in raise () from /usr/lib/libc.so.6; #2 0x00007ffff4a38538 in abort () from /usr/lib/libc.so.6; #3 0x00007ffff4c9ca6f in __gnu_cxx::__verbose_terminate_handler () at /usr/src/debug/gcc/gcc/libstdc++-v3/libsupc++/vterminate.cc:95; #4 0x00007ffff4cb011c in __cxxabiv1::__terminate (handler=<optimized out>) at /usr/src/debug/gcc/gcc/libstdc++-v3/libsupc++/eh_terminate.cc:48; #5 0x00007ffff4cb0189 in std::terminate () at /usr/src/debug/gcc/gcc/libstdc++-v3/libsupc++/eh_terminate.cc:58; #6 0x00007ffff4cb03ed in __cxxabiv1::__cxa_throw (obj=<optimized out>, tinfo=0x7ffff4e6c0d0 <typeinfo for std::length_error>,; dest=0x7ffff4cc8580 <std::length_error::~length_error()>) at /usr/src/debug/gcc/gcc/libstdc++-v3/libsupc++/eh_throw.cc:98; #7 0x00007ffff4ca01ca in std::__throw_length_error (__s=__s@entry=0x7ffff79711aa ""basic_string::_M_replace_aux""); at /usr/src/debug/gcc/gcc/libstdc++-v3/src/c++11/functexcept.cc:82; #8 0x00007ffff76f2ae8 in std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::_M_check_length (__s=<optimized out>,; __n2=<optimized out>, __n1=<optimized out>, this=<optimized out>) at /usr/include/c++/13.1.1/bits/basic_string.h:403; #9 std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::_M_replace_aux (__c=<optimized out>, __n2=<optimized out>,; __n1=<optimized out>, __pos1=<optimized out>, this=<optimized out>) at /usr/include/c++/13.1.1/bits/basic_string.tcc:450; #10 std::__cxx11::basic_string<char, std::c",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12967#issuecomment-1581261520
Usability,simpl,simple,"fffffd9d0, cl=0x555558490b70, pointer=<optimized out>, onFileClass=<optimized out>); at /home/rembserj/spaces/master/root/src/root/io/io/src/TBufferFile.cxx:3499; #30 0x00007ffff778a22e in TClass::Streamer (onfile_class=0x0, b=..., obj=0x55555855a0c0, this=0x555558490b70); at /home/rembserj/spaces/master/root/src/root/core/meta/inc/TClass.h:610; #31 TKey::ReadObjectAny (this=0x5555569f77a0, expectedClass=<optimized out>) at /home/rembserj/spaces/master/root/src/root/io/io/src/TKey.cxx:1108; #32 0x00007ffff774aa1b in TDirectoryFile::GetObjectChecked (this=0x555556a15ce0, namecycle=<optimized out>, expectedClass=0x555558490b70); at /home/rembserj/spaces/master/root/src/root/io/io/src/TDirectoryFile.cxx:1111; #33 0x00005555555551f6 in TDirectory::Get<RooStats::HistFactory::Measurement> (this=0x555556a15ce0, namecycle=<optimized out>); at /home/rembserj/spaces/master/root/src/build/../install/include/root/TDirectory.h:207; #34 TDirectoryFile::Get<RooStats::HistFactory::Measurement> (this=0x555556a15ce0, namecycle=<optimized out>); at /home/rembserj/spaces/master/root/src/build/../install/include/root/TDirectoryFile.h:84; #35 repro () at repro.C:10; ```. So the crash is here (https://github.com/root-project/root/blob/master/io/io/src/TBufferFile.cxx#L245):; ```c++; if (nwh == 255) {; *this >> nbig;; obj->resize(nbig,'\0');; ReadFastArray((char*)obj->data(),nbig);; }; ```; I have put some debug printouts. When it crashes, `nbig` is `-1`, and resize() expects and unsigned int. The -1 becomes a very large unsigned number that exceeds the maximum allowed length of a `std::string`. To me that looks more like a problem with IO than with HistFactory (the memory layout of the `HistFactory::Measurement` classes hasn't changed from 6.26 to 6.28. Is that something that makes sense to you, @pcanal? What does this `nbig` stand for, and in which circumstances can this be `-1`?. Maybe in the best case, the fix would just be adding a simple `if(nbig >= 0)` before the call to `resize()`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12967#issuecomment-1581261520
Availability,robust,robust,Closing the PR after some discussion. The added benefit of having a more robust usage of namespaces and clearer definition of the classes being used in the headers is not worth w.r.t. having to rebase larger PRs on top of these changes.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12981#issuecomment-1585597579
Usability,clear,clearer,Closing the PR after some discussion. The added benefit of having a more robust usage of namespaces and clearer definition of the classes being used in the headers is not worth w.r.t. having to rebase larger PRs on top of these changes.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12981#issuecomment-1585597579
Performance,load,load,"> > Could it be that the issue is TBranch now has Experimental::Internal::TBulkBranchRead as a member?; > ; > Yes! Very likely. That's actually it. If I remove the Experimental namespace and simply use Internal::TBulkBranchRead, it does not load the other Experimental bits either.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13000#issuecomment-1615245128
Usability,simpl,simply,"> > Could it be that the issue is TBranch now has Experimental::Internal::TBulkBranchRead as a member?; > ; > Yes! Very likely. That's actually it. If I remove the Experimental namespace and simply use Internal::TBulkBranchRead, it does not load the other Experimental bits either.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13000#issuecomment-1615245128
Availability,reliab,reliable,"> > > Could it be that the issue is TBranch now has Experimental::Internal::TBulkBranchRead as a member?; > > ; > > ; > > Yes! Very likely.; > ; > That's actually it. If I remove the Experimental namespace and simply use Internal::TBulkBranchRead, it does not load the other Experimental bits either. However, that in practice shows a more generic design problem in the clang modules system. That is, then we make a lookup of a namespace identifier clang (rightfully) tries to collect all namespace partitions from all reachable modules. This has to do with things like overload resolution. Due to the autoloading system, ROOT essentially considers all modules reachable and thus loads them. The only reliable way to fix this is to make the clang module loads a no-op which is a bit of a challenge",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13000#issuecomment-1615514852
Performance,load,load,"> > > Could it be that the issue is TBranch now has Experimental::Internal::TBulkBranchRead as a member?; > > ; > > ; > > Yes! Very likely.; > ; > That's actually it. If I remove the Experimental namespace and simply use Internal::TBulkBranchRead, it does not load the other Experimental bits either. However, that in practice shows a more generic design problem in the clang modules system. That is, then we make a lookup of a namespace identifier clang (rightfully) tries to collect all namespace partitions from all reachable modules. This has to do with things like overload resolution. Due to the autoloading system, ROOT essentially considers all modules reachable and thus loads them. The only reliable way to fix this is to make the clang module loads a no-op which is a bit of a challenge",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13000#issuecomment-1615514852
Usability,simpl,simply,"> > > Could it be that the issue is TBranch now has Experimental::Internal::TBulkBranchRead as a member?; > > ; > > ; > > Yes! Very likely.; > ; > That's actually it. If I remove the Experimental namespace and simply use Internal::TBulkBranchRead, it does not load the other Experimental bits either. However, that in practice shows a more generic design problem in the clang modules system. That is, then we make a lookup of a namespace identifier clang (rightfully) tries to collect all namespace partitions from all reachable modules. This has to do with things like overload resolution. Due to the autoloading system, ROOT essentially considers all modules reachable and thus loads them. The only reliable way to fix this is to make the clang module loads a no-op which is a bit of a challenge",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13000#issuecomment-1615514852
Testability,test,tests,"Ok, let me know if you have other tests which you would like me to do. One more question for my understanding. Are those big vectors actually needed at all when reading a file? If not why aren't they swapped out to disk either implicitly via some madvise or by simply caching to disk the results? The latter might even give some startup advantage, assuming they are offsets to the pcms and they do not change (not the basic root ones, at least).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13000#issuecomment-1628343236
Usability,simpl,simply,"Ok, let me know if you have other tests which you would like me to do. One more question for my understanding. Are those big vectors actually needed at all when reading a file? If not why aren't they swapped out to disk either implicitly via some madvise or by simply caching to disk the results? The latter might even give some startup advantage, assuming they are offsets to the pcms and they do not change (not the basic root ones, at least).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13000#issuecomment-1628343236
Availability,ping,ping,"> Ok, let me know if you have other tests which you would like me to do. I was a bit surprised to learn that:. > > Thank you for the nice investigations. What are the next steps? I tried #13139 but that does not help us. I see a different memory profile, but the extra memory due to ROOT is stil around 70MB (even a bit more with that PR, AFAICT).; > ; > Is that with or without opening the file? My expectation is that `root.exe -l -b -q` will take a lot less rss. ping. > One more question for my understanding. Are those big vectors actually needed at all when reading a file? If not why aren't they swapped out to disk either implicitly via some madvise or by simply caching to disk the results? The latter might even give some startup advantage, assuming they are offsets to the pcms and they do not change (not the basic root ones, at least). They are not needed upon module loads. We tried to implement some sparse vectors to mitigate this issue. However, I feel like we did not have the persistence to make it work. That is, we can implement a lazy vector structure that behaves just like vector but the reserve operation does not allocate. Instead, we allocate slabs around the access pattern (we override the subscript operator, etc). This would help us avoid eager allocations and hopefully, depending on whether there is a clear access pattern to optimize things. Our implementation seems to be still [here](https://github.com/Teemperor/llvm/commit/a06b21cbc55c6d2f1d2bf6f39771411ccc17342b). Another easier thing to try is reviving https://reviews.llvm.org/D89749",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13000#issuecomment-1629035353
Energy Efficiency,allocate,allocate,"> Ok, let me know if you have other tests which you would like me to do. I was a bit surprised to learn that:. > > Thank you for the nice investigations. What are the next steps? I tried #13139 but that does not help us. I see a different memory profile, but the extra memory due to ROOT is stil around 70MB (even a bit more with that PR, AFAICT).; > ; > Is that with or without opening the file? My expectation is that `root.exe -l -b -q` will take a lot less rss. ping. > One more question for my understanding. Are those big vectors actually needed at all when reading a file? If not why aren't they swapped out to disk either implicitly via some madvise or by simply caching to disk the results? The latter might even give some startup advantage, assuming they are offsets to the pcms and they do not change (not the basic root ones, at least). They are not needed upon module loads. We tried to implement some sparse vectors to mitigate this issue. However, I feel like we did not have the persistence to make it work. That is, we can implement a lazy vector structure that behaves just like vector but the reserve operation does not allocate. Instead, we allocate slabs around the access pattern (we override the subscript operator, etc). This would help us avoid eager allocations and hopefully, depending on whether there is a clear access pattern to optimize things. Our implementation seems to be still [here](https://github.com/Teemperor/llvm/commit/a06b21cbc55c6d2f1d2bf6f39771411ccc17342b). Another easier thing to try is reviving https://reviews.llvm.org/D89749",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13000#issuecomment-1629035353
Integrability,depend,depending,"> Ok, let me know if you have other tests which you would like me to do. I was a bit surprised to learn that:. > > Thank you for the nice investigations. What are the next steps? I tried #13139 but that does not help us. I see a different memory profile, but the extra memory due to ROOT is stil around 70MB (even a bit more with that PR, AFAICT).; > ; > Is that with or without opening the file? My expectation is that `root.exe -l -b -q` will take a lot less rss. ping. > One more question for my understanding. Are those big vectors actually needed at all when reading a file? If not why aren't they swapped out to disk either implicitly via some madvise or by simply caching to disk the results? The latter might even give some startup advantage, assuming they are offsets to the pcms and they do not change (not the basic root ones, at least). They are not needed upon module loads. We tried to implement some sparse vectors to mitigate this issue. However, I feel like we did not have the persistence to make it work. That is, we can implement a lazy vector structure that behaves just like vector but the reserve operation does not allocate. Instead, we allocate slabs around the access pattern (we override the subscript operator, etc). This would help us avoid eager allocations and hopefully, depending on whether there is a clear access pattern to optimize things. Our implementation seems to be still [here](https://github.com/Teemperor/llvm/commit/a06b21cbc55c6d2f1d2bf6f39771411ccc17342b). Another easier thing to try is reviving https://reviews.llvm.org/D89749",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13000#issuecomment-1629035353
Performance,load,loads,"> Ok, let me know if you have other tests which you would like me to do. I was a bit surprised to learn that:. > > Thank you for the nice investigations. What are the next steps? I tried #13139 but that does not help us. I see a different memory profile, but the extra memory due to ROOT is stil around 70MB (even a bit more with that PR, AFAICT).; > ; > Is that with or without opening the file? My expectation is that `root.exe -l -b -q` will take a lot less rss. ping. > One more question for my understanding. Are those big vectors actually needed at all when reading a file? If not why aren't they swapped out to disk either implicitly via some madvise or by simply caching to disk the results? The latter might even give some startup advantage, assuming they are offsets to the pcms and they do not change (not the basic root ones, at least). They are not needed upon module loads. We tried to implement some sparse vectors to mitigate this issue. However, I feel like we did not have the persistence to make it work. That is, we can implement a lazy vector structure that behaves just like vector but the reserve operation does not allocate. Instead, we allocate slabs around the access pattern (we override the subscript operator, etc). This would help us avoid eager allocations and hopefully, depending on whether there is a clear access pattern to optimize things. Our implementation seems to be still [here](https://github.com/Teemperor/llvm/commit/a06b21cbc55c6d2f1d2bf6f39771411ccc17342b). Another easier thing to try is reviving https://reviews.llvm.org/D89749",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13000#issuecomment-1629035353
Safety,avoid,avoid,"> Ok, let me know if you have other tests which you would like me to do. I was a bit surprised to learn that:. > > Thank you for the nice investigations. What are the next steps? I tried #13139 but that does not help us. I see a different memory profile, but the extra memory due to ROOT is stil around 70MB (even a bit more with that PR, AFAICT).; > ; > Is that with or without opening the file? My expectation is that `root.exe -l -b -q` will take a lot less rss. ping. > One more question for my understanding. Are those big vectors actually needed at all when reading a file? If not why aren't they swapped out to disk either implicitly via some madvise or by simply caching to disk the results? The latter might even give some startup advantage, assuming they are offsets to the pcms and they do not change (not the basic root ones, at least). They are not needed upon module loads. We tried to implement some sparse vectors to mitigate this issue. However, I feel like we did not have the persistence to make it work. That is, we can implement a lazy vector structure that behaves just like vector but the reserve operation does not allocate. Instead, we allocate slabs around the access pattern (we override the subscript operator, etc). This would help us avoid eager allocations and hopefully, depending on whether there is a clear access pattern to optimize things. Our implementation seems to be still [here](https://github.com/Teemperor/llvm/commit/a06b21cbc55c6d2f1d2bf6f39771411ccc17342b). Another easier thing to try is reviving https://reviews.llvm.org/D89749",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13000#issuecomment-1629035353
Security,access,access,"> Ok, let me know if you have other tests which you would like me to do. I was a bit surprised to learn that:. > > Thank you for the nice investigations. What are the next steps? I tried #13139 but that does not help us. I see a different memory profile, but the extra memory due to ROOT is stil around 70MB (even a bit more with that PR, AFAICT).; > ; > Is that with or without opening the file? My expectation is that `root.exe -l -b -q` will take a lot less rss. ping. > One more question for my understanding. Are those big vectors actually needed at all when reading a file? If not why aren't they swapped out to disk either implicitly via some madvise or by simply caching to disk the results? The latter might even give some startup advantage, assuming they are offsets to the pcms and they do not change (not the basic root ones, at least). They are not needed upon module loads. We tried to implement some sparse vectors to mitigate this issue. However, I feel like we did not have the persistence to make it work. That is, we can implement a lazy vector structure that behaves just like vector but the reserve operation does not allocate. Instead, we allocate slabs around the access pattern (we override the subscript operator, etc). This would help us avoid eager allocations and hopefully, depending on whether there is a clear access pattern to optimize things. Our implementation seems to be still [here](https://github.com/Teemperor/llvm/commit/a06b21cbc55c6d2f1d2bf6f39771411ccc17342b). Another easier thing to try is reviving https://reviews.llvm.org/D89749",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13000#issuecomment-1629035353
Testability,test,tests,"> Ok, let me know if you have other tests which you would like me to do. I was a bit surprised to learn that:. > > Thank you for the nice investigations. What are the next steps? I tried #13139 but that does not help us. I see a different memory profile, but the extra memory due to ROOT is stil around 70MB (even a bit more with that PR, AFAICT).; > ; > Is that with or without opening the file? My expectation is that `root.exe -l -b -q` will take a lot less rss. ping. > One more question for my understanding. Are those big vectors actually needed at all when reading a file? If not why aren't they swapped out to disk either implicitly via some madvise or by simply caching to disk the results? The latter might even give some startup advantage, assuming they are offsets to the pcms and they do not change (not the basic root ones, at least). They are not needed upon module loads. We tried to implement some sparse vectors to mitigate this issue. However, I feel like we did not have the persistence to make it work. That is, we can implement a lazy vector structure that behaves just like vector but the reserve operation does not allocate. Instead, we allocate slabs around the access pattern (we override the subscript operator, etc). This would help us avoid eager allocations and hopefully, depending on whether there is a clear access pattern to optimize things. Our implementation seems to be still [here](https://github.com/Teemperor/llvm/commit/a06b21cbc55c6d2f1d2bf6f39771411ccc17342b). Another easier thing to try is reviving https://reviews.llvm.org/D89749",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13000#issuecomment-1629035353
Usability,learn,learn,"> Ok, let me know if you have other tests which you would like me to do. I was a bit surprised to learn that:. > > Thank you for the nice investigations. What are the next steps? I tried #13139 but that does not help us. I see a different memory profile, but the extra memory due to ROOT is stil around 70MB (even a bit more with that PR, AFAICT).; > ; > Is that with or without opening the file? My expectation is that `root.exe -l -b -q` will take a lot less rss. ping. > One more question for my understanding. Are those big vectors actually needed at all when reading a file? If not why aren't they swapped out to disk either implicitly via some madvise or by simply caching to disk the results? The latter might even give some startup advantage, assuming they are offsets to the pcms and they do not change (not the basic root ones, at least). They are not needed upon module loads. We tried to implement some sparse vectors to mitigate this issue. However, I feel like we did not have the persistence to make it work. That is, we can implement a lazy vector structure that behaves just like vector but the reserve operation does not allocate. Instead, we allocate slabs around the access pattern (we override the subscript operator, etc). This would help us avoid eager allocations and hopefully, depending on whether there is a clear access pattern to optimize things. Our implementation seems to be still [here](https://github.com/Teemperor/llvm/commit/a06b21cbc55c6d2f1d2bf6f39771411ccc17342b). Another easier thing to try is reviving https://reviews.llvm.org/D89749",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13000#issuecomment-1629035353
Usability,clear,clear,"to be clear, as I said above, the profile changed, however the total sum for cling initialisation is still at 70MB.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13000#issuecomment-1630736477
Availability,ping,ping,"> > > Is that with or without opening the file? My expectation is that root.exe -l -b -q will take a lot less rss.; > > > ping.; > ; > With the file. I meant to ping on the stats without a file. > to be clear, as I said above, the profile changed, however the total sum for cling initialisation is still at 70MB. Can you share the new profile?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13000#issuecomment-1630908477
Usability,clear,clear,"> > > Is that with or without opening the file? My expectation is that root.exe -l -b -q will take a lot less rss.; > > > ping.; > ; > With the file. I meant to ping on the stats without a file. > to be clear, as I said above, the profile changed, however the total sum for cling initialisation is still at 70MB. Can you share the new profile?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13000#issuecomment-1630908477
Energy Efficiency,allocate,allocated,"So I finally managed to get back to this and try a few things and as a result in my tests I managed to go from 82 MB of overhead to 62 MB. See https://github.com/root-project/root/pull/13641 for the actual code. While there is still a few things to cleanup, I think what I have is fairly general and quite self contained change, so I would appreciate feedback and if people like it, instructions on how to proceed to make sure this ends up upstream. The solution is based on a newly introduced `PagedVector<T>` which allows registering callbacks which get invoked whenever the associated range is accessed the first time. At such point, the range is actually allocated and each element of the range is passed to the callback. Initially I developed a mechanism to be general enough to do complex initialisations of the elements, however I later realised this is not actually needed. In order to optimise the issue with the large vectors `TypesLoaded` and `DeclsLoaded` one only needs to have something which does the default construction of their elements for ranges which are small enough to avoid to large upfront allocations. The code which is currently there in root / clang is already smart enough to lazily initialise only the elements which are actually needed, so the whole issue is to find a good tradeoff between number of ranges and sparse enough ones. A few caveats:. - `PagedVector` is a bad name, I agree. Suggestions are welcome.; - At the moment the implementation allows generic callbacks for ranges, however as I said we only need default initialisation. Removing such flexibility should buy another 1 MB from my test.; - In case `DeclID*` and `QualType` can default to all 0, one could probably achieve the same result in a more elegant way using calloc / realloc.; - There are probably other vectors which can be optimised in the same way, in particular IdentifiersLoaded as already mentioned by @vgvassilev. Comments?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13000#issuecomment-1715921216
Safety,avoid,avoid,"So I finally managed to get back to this and try a few things and as a result in my tests I managed to go from 82 MB of overhead to 62 MB. See https://github.com/root-project/root/pull/13641 for the actual code. While there is still a few things to cleanup, I think what I have is fairly general and quite self contained change, so I would appreciate feedback and if people like it, instructions on how to proceed to make sure this ends up upstream. The solution is based on a newly introduced `PagedVector<T>` which allows registering callbacks which get invoked whenever the associated range is accessed the first time. At such point, the range is actually allocated and each element of the range is passed to the callback. Initially I developed a mechanism to be general enough to do complex initialisations of the elements, however I later realised this is not actually needed. In order to optimise the issue with the large vectors `TypesLoaded` and `DeclsLoaded` one only needs to have something which does the default construction of their elements for ranges which are small enough to avoid to large upfront allocations. The code which is currently there in root / clang is already smart enough to lazily initialise only the elements which are actually needed, so the whole issue is to find a good tradeoff between number of ranges and sparse enough ones. A few caveats:. - `PagedVector` is a bad name, I agree. Suggestions are welcome.; - At the moment the implementation allows generic callbacks for ranges, however as I said we only need default initialisation. Removing such flexibility should buy another 1 MB from my test.; - In case `DeclID*` and `QualType` can default to all 0, one could probably achieve the same result in a more elegant way using calloc / realloc.; - There are probably other vectors which can be optimised in the same way, in particular IdentifiersLoaded as already mentioned by @vgvassilev. Comments?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13000#issuecomment-1715921216
Security,access,accessed,"So I finally managed to get back to this and try a few things and as a result in my tests I managed to go from 82 MB of overhead to 62 MB. See https://github.com/root-project/root/pull/13641 for the actual code. While there is still a few things to cleanup, I think what I have is fairly general and quite self contained change, so I would appreciate feedback and if people like it, instructions on how to proceed to make sure this ends up upstream. The solution is based on a newly introduced `PagedVector<T>` which allows registering callbacks which get invoked whenever the associated range is accessed the first time. At such point, the range is actually allocated and each element of the range is passed to the callback. Initially I developed a mechanism to be general enough to do complex initialisations of the elements, however I later realised this is not actually needed. In order to optimise the issue with the large vectors `TypesLoaded` and `DeclsLoaded` one only needs to have something which does the default construction of their elements for ranges which are small enough to avoid to large upfront allocations. The code which is currently there in root / clang is already smart enough to lazily initialise only the elements which are actually needed, so the whole issue is to find a good tradeoff between number of ranges and sparse enough ones. A few caveats:. - `PagedVector` is a bad name, I agree. Suggestions are welcome.; - At the moment the implementation allows generic callbacks for ranges, however as I said we only need default initialisation. Removing such flexibility should buy another 1 MB from my test.; - In case `DeclID*` and `QualType` can default to all 0, one could probably achieve the same result in a more elegant way using calloc / realloc.; - There are probably other vectors which can be optimised in the same way, in particular IdentifiersLoaded as already mentioned by @vgvassilev. Comments?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13000#issuecomment-1715921216
Testability,test,tests,"So I finally managed to get back to this and try a few things and as a result in my tests I managed to go from 82 MB of overhead to 62 MB. See https://github.com/root-project/root/pull/13641 for the actual code. While there is still a few things to cleanup, I think what I have is fairly general and quite self contained change, so I would appreciate feedback and if people like it, instructions on how to proceed to make sure this ends up upstream. The solution is based on a newly introduced `PagedVector<T>` which allows registering callbacks which get invoked whenever the associated range is accessed the first time. At such point, the range is actually allocated and each element of the range is passed to the callback. Initially I developed a mechanism to be general enough to do complex initialisations of the elements, however I later realised this is not actually needed. In order to optimise the issue with the large vectors `TypesLoaded` and `DeclsLoaded` one only needs to have something which does the default construction of their elements for ranges which are small enough to avoid to large upfront allocations. The code which is currently there in root / clang is already smart enough to lazily initialise only the elements which are actually needed, so the whole issue is to find a good tradeoff between number of ranges and sparse enough ones. A few caveats:. - `PagedVector` is a bad name, I agree. Suggestions are welcome.; - At the moment the implementation allows generic callbacks for ranges, however as I said we only need default initialisation. Removing such flexibility should buy another 1 MB from my test.; - In case `DeclID*` and `QualType` can default to all 0, one could probably achieve the same result in a more elegant way using calloc / realloc.; - There are probably other vectors which can be optimised in the same way, in particular IdentifiersLoaded as already mentioned by @vgvassilev. Comments?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13000#issuecomment-1715921216
Usability,feedback,feedback,"So I finally managed to get back to this and try a few things and as a result in my tests I managed to go from 82 MB of overhead to 62 MB. See https://github.com/root-project/root/pull/13641 for the actual code. While there is still a few things to cleanup, I think what I have is fairly general and quite self contained change, so I would appreciate feedback and if people like it, instructions on how to proceed to make sure this ends up upstream. The solution is based on a newly introduced `PagedVector<T>` which allows registering callbacks which get invoked whenever the associated range is accessed the first time. At such point, the range is actually allocated and each element of the range is passed to the callback. Initially I developed a mechanism to be general enough to do complex initialisations of the elements, however I later realised this is not actually needed. In order to optimise the issue with the large vectors `TypesLoaded` and `DeclsLoaded` one only needs to have something which does the default construction of their elements for ranges which are small enough to avoid to large upfront allocations. The code which is currently there in root / clang is already smart enough to lazily initialise only the elements which are actually needed, so the whole issue is to find a good tradeoff between number of ranges and sparse enough ones. A few caveats:. - `PagedVector` is a bad name, I agree. Suggestions are welcome.; - At the moment the implementation allows generic callbacks for ranges, however as I said we only need default initialisation. Removing such flexibility should buy another 1 MB from my test.; - In case `DeclID*` and `QualType` can default to all 0, one could probably achieve the same result in a more elegant way using calloc / realloc.; - There are probably other vectors which can be optimised in the same way, in particular IdentifiersLoaded as already mentioned by @vgvassilev. Comments?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13000#issuecomment-1715921216
Energy Efficiency,allocate,allocate,"> ; > Comments?. This looks awesome!. > A few caveats:; > ; > * `PagedVector` is a bad name, I agree. Suggestions are welcome. We did not come up with a better name. Ours was `SparseVector`. Just to confirm, we do not pre-allocate the entire vector but we deterministically allocate the slabs. That is, if I hardcoded an offset `101` in my code and the pre-allocation allocated just a slab [0-100), then when I do PagedVector[101] it would put what I need where I need it, right?. > ; > * At the moment the implementation allows generic callbacks for ranges, however as I said we only need default initialisation. Removing such flexibility should buy another 1 MB from my test. If it is not needed, let's keep it simple. It would be easier to go through the upstream llvm reviews. > ; > * In case `DeclID*` and `QualType` can default to all 0, one could probably achieve the same result in a more elegant way using calloc / realloc. Can we make the API of the `PagedVector` such that it becomes a drop-in replacement? I have not looked deeply in the PR but I see some work being done on the users side. > ; > * There are probably other vectors which can be optimised in the same way, in particular IdentifiersLoaded as already mentioned by @vgvassilev. The source locations offset would be a major source of improvement if this technique flies there. PP: It seems llvm has some facility along these lines: https://llvm.org/doxygen/classllvm_1_1SparseBitVector.html",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13000#issuecomment-1716088321
Testability,test,test,"> ; > Comments?. This looks awesome!. > A few caveats:; > ; > * `PagedVector` is a bad name, I agree. Suggestions are welcome. We did not come up with a better name. Ours was `SparseVector`. Just to confirm, we do not pre-allocate the entire vector but we deterministically allocate the slabs. That is, if I hardcoded an offset `101` in my code and the pre-allocation allocated just a slab [0-100), then when I do PagedVector[101] it would put what I need where I need it, right?. > ; > * At the moment the implementation allows generic callbacks for ranges, however as I said we only need default initialisation. Removing such flexibility should buy another 1 MB from my test. If it is not needed, let's keep it simple. It would be easier to go through the upstream llvm reviews. > ; > * In case `DeclID*` and `QualType` can default to all 0, one could probably achieve the same result in a more elegant way using calloc / realloc. Can we make the API of the `PagedVector` such that it becomes a drop-in replacement? I have not looked deeply in the PR but I see some work being done on the users side. > ; > * There are probably other vectors which can be optimised in the same way, in particular IdentifiersLoaded as already mentioned by @vgvassilev. The source locations offset would be a major source of improvement if this technique flies there. PP: It seems llvm has some facility along these lines: https://llvm.org/doxygen/classllvm_1_1SparseBitVector.html",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13000#issuecomment-1716088321
Usability,simpl,simple,"> ; > Comments?. This looks awesome!. > A few caveats:; > ; > * `PagedVector` is a bad name, I agree. Suggestions are welcome. We did not come up with a better name. Ours was `SparseVector`. Just to confirm, we do not pre-allocate the entire vector but we deterministically allocate the slabs. That is, if I hardcoded an offset `101` in my code and the pre-allocation allocated just a slab [0-100), then when I do PagedVector[101] it would put what I need where I need it, right?. > ; > * At the moment the implementation allows generic callbacks for ranges, however as I said we only need default initialisation. Removing such flexibility should buy another 1 MB from my test. If it is not needed, let's keep it simple. It would be easier to go through the upstream llvm reviews. > ; > * In case `DeclID*` and `QualType` can default to all 0, one could probably achieve the same result in a more elegant way using calloc / realloc. Can we make the API of the `PagedVector` such that it becomes a drop-in replacement? I have not looked deeply in the PR but I see some work being done on the users side. > ; > * There are probably other vectors which can be optimised in the same way, in particular IdentifiersLoaded as already mentioned by @vgvassilev. The source locations offset would be a major source of improvement if this technique flies there. PP: It seems llvm has some facility along these lines: https://llvm.org/doxygen/classllvm_1_1SparseBitVector.html",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13000#issuecomment-1716088321
Energy Efficiency,allocate,allocate,"> We did not come up with a better name. Ours was SparseVector. Just to confirm, we do not pre-allocate the entire vector but we deterministically allocate the slabs. That is, if I hardcoded an offset 101 in my code and the pre-allocation allocated just a slab [0-100), then when I do PagedVector[101] it would put what I need where I need it, right?. No, you would need first to register the range [100, 200) via addEmptyRange(). I could try to modify it for that behaviour, if you prefer. Maybe it would allow me to get rid of the logarithmic lookup, actually (basically, one less vector to worry about). > If it is not needed, let's keep it simple. It would be easier to go through the upstream llvm reviews. Ok, I will clean it up a bit more. > Can we make the API of the PagedVector such that it becomes a drop-in replacement? I have not looked deeply in the PR but I see some work being done on the users side. Yes, users would need to addEmptyRange where they now do resize(). I guess I could actually hide addEmptyRange inside the resize. Is it allowed to use std::pmr::vector in the llvm codebase?. > The source locations offset would be a major source of improvement if this technique flies there. I couldn't find the source locations vector anymore. Could you point it to me?. > PP: It seems llvm has some facility along these lines: https://llvm.org/doxygen/classllvm_1_1SparseBitVector.html. I will have a look.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13000#issuecomment-1717037288
Testability,log,logarithmic,"> We did not come up with a better name. Ours was SparseVector. Just to confirm, we do not pre-allocate the entire vector but we deterministically allocate the slabs. That is, if I hardcoded an offset 101 in my code and the pre-allocation allocated just a slab [0-100), then when I do PagedVector[101] it would put what I need where I need it, right?. No, you would need first to register the range [100, 200) via addEmptyRange(). I could try to modify it for that behaviour, if you prefer. Maybe it would allow me to get rid of the logarithmic lookup, actually (basically, one less vector to worry about). > If it is not needed, let's keep it simple. It would be easier to go through the upstream llvm reviews. Ok, I will clean it up a bit more. > Can we make the API of the PagedVector such that it becomes a drop-in replacement? I have not looked deeply in the PR but I see some work being done on the users side. Yes, users would need to addEmptyRange where they now do resize(). I guess I could actually hide addEmptyRange inside the resize. Is it allowed to use std::pmr::vector in the llvm codebase?. > The source locations offset would be a major source of improvement if this technique flies there. I couldn't find the source locations vector anymore. Could you point it to me?. > PP: It seems llvm has some facility along these lines: https://llvm.org/doxygen/classllvm_1_1SparseBitVector.html. I will have a look.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13000#issuecomment-1717037288
Usability,simpl,simple,"> We did not come up with a better name. Ours was SparseVector. Just to confirm, we do not pre-allocate the entire vector but we deterministically allocate the slabs. That is, if I hardcoded an offset 101 in my code and the pre-allocation allocated just a slab [0-100), then when I do PagedVector[101] it would put what I need where I need it, right?. No, you would need first to register the range [100, 200) via addEmptyRange(). I could try to modify it for that behaviour, if you prefer. Maybe it would allow me to get rid of the logarithmic lookup, actually (basically, one less vector to worry about). > If it is not needed, let's keep it simple. It would be easier to go through the upstream llvm reviews. Ok, I will clean it up a bit more. > Can we make the API of the PagedVector such that it becomes a drop-in replacement? I have not looked deeply in the PR but I see some work being done on the users side. Yes, users would need to addEmptyRange where they now do resize(). I guess I could actually hide addEmptyRange inside the resize. Is it allowed to use std::pmr::vector in the llvm codebase?. > The source locations offset would be a major source of improvement if this technique flies there. I couldn't find the source locations vector anymore. Could you point it to me?. > PP: It seems llvm has some facility along these lines: https://llvm.org/doxygen/classllvm_1_1SparseBitVector.html. I will have a look.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13000#issuecomment-1717037288
Performance,load,loads,"It's not an issue for adoption. The underlying issue is still there, though. ROOT still loads a bunch of unneeded PCM when simply opening a file, it's just the cost is half what it was before and the reproducer is the same as above.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13000#issuecomment-2304636324
Usability,simpl,simply,"It's not an issue for adoption. The underlying issue is still there, though. ROOT still loads a bunch of unneeded PCM when simply opening a file, it's just the cost is half what it was before and the reproducer is the same as above.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13000#issuecomment-2304636324
Availability,error,error,"Yes, of course, I can reproduce the error in regular C++ with something as simple as <https://godbolt.org/z/rnqWer3bj>:; ```cpp; #include <ranges>; using namespace std;; #include <range/v3/views.hpp>; ```; but I see 2 errors in this example:; - using std::ranges and ranges at the same time (not really an error, but a bit silly); - `using namespace std` before including `range/v3/views.hpp` (actually `using namespace std` should be considered an error by itself). The following code works:; ```cpp; #include <ranges>; #include <range/v3/views.hpp>; using namespace std;; ```; still a bit silly, but it works. So, I'm sorry, but I do not buy the comment that developers of libraries should always put `::` in front of every top level namespace. I believe it is fairy reasonable to assume that nobody does `using namespace std;` before including any header.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13001#issuecomment-1591318680
Usability,simpl,simple,"Yes, of course, I can reproduce the error in regular C++ with something as simple as <https://godbolt.org/z/rnqWer3bj>:; ```cpp; #include <ranges>; using namespace std;; #include <range/v3/views.hpp>; ```; but I see 2 errors in this example:; - using std::ranges and ranges at the same time (not really an error, but a bit silly); - `using namespace std` before including `range/v3/views.hpp` (actually `using namespace std` should be considered an error by itself). The following code works:; ```cpp; #include <ranges>; #include <range/v3/views.hpp>; using namespace std;; ```; still a bit silly, but it works. So, I'm sorry, but I do not buy the comment that developers of libraries should always put `::` in front of every top level namespace. I believe it is fairy reasonable to assume that nobody does `using namespace std;` before including any header.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13001#issuecomment-1591318680
Usability,simpl,simply,"if you need 1e-9 simply change it when you call Integral, that is what ""defined by eps"" means. You defined it, either by using the default value 1e-6 or by specifying this parameter.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13005#issuecomment-1591002768
Performance,latency,latency,"One potential reason - huge latency for simple request of 4 bytes. Just submitting simple request:; ```; time curl -ik https://cernbox.cern.ch/remote.php/dav/public-files/1Cy1HIf03Ca76Dm/test_ntuples_200123.root -H ""Range: bytes=0-4,100-104"" --output -; ```. Gives me: `1.423 sec` total time.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13018#issuecomment-1592003325
Usability,simpl,simple,"One potential reason - huge latency for simple request of 4 bytes. Just submitting simple request:; ```; time curl -ik https://cernbox.cern.ch/remote.php/dav/public-files/1Cy1HIf03Ca76Dm/test_ntuples_200123.root -H ""Range: bytes=0-4,100-104"" --output -; ```. Gives me: `1.423 sec` total time.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13018#issuecomment-1592003325
Availability,error,errors,"I have more strange effect. I do not compile davix and therefore after opening the file with:; `TFile::Open(""https://cernbox.cern.ch/remote.php/dav/public-files/1Cy1HIf03Ca76Dm/test_ntuples_200123.root"");` ; I getting instance of `TWebFile`. And if enable `gDebug=1`, one clearly sees ~1.5s per each http request. Moreover, when I try to perform `TTree::Draw()` from the `TBrowser` (web and normal one), `TWebFile` submits multirange request, but not able to parse result of it. Producing several errors - it fully crashes, including my console. Seems to be, it is another issue.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13018#issuecomment-1592493876
Performance,perform,perform,"I have more strange effect. I do not compile davix and therefore after opening the file with:; `TFile::Open(""https://cernbox.cern.ch/remote.php/dav/public-files/1Cy1HIf03Ca76Dm/test_ntuples_200123.root"");` ; I getting instance of `TWebFile`. And if enable `gDebug=1`, one clearly sees ~1.5s per each http request. Moreover, when I try to perform `TTree::Draw()` from the `TBrowser` (web and normal one), `TWebFile` submits multirange request, but not able to parse result of it. Producing several errors - it fully crashes, including my console. Seems to be, it is another issue.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13018#issuecomment-1592493876
Usability,clear,clearly,"I have more strange effect. I do not compile davix and therefore after opening the file with:; `TFile::Open(""https://cernbox.cern.ch/remote.php/dav/public-files/1Cy1HIf03Ca76Dm/test_ntuples_200123.root"");` ; I getting instance of `TWebFile`. And if enable `gDebug=1`, one clearly sees ~1.5s per each http request. Moreover, when I try to perform `TTree::Draw()` from the `TBrowser` (web and normal one), `TWebFile` submits multirange request, but not able to parse result of it. Producing several errors - it fully crashes, including my console. Seems to be, it is another issue.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13018#issuecomment-1592493876
Performance,latency,latency,"Now I start understanding problem with cernbox http server.; It returns wrong http response header on multi-range request.; Therefore ROOT not able to recognize it and either fail or fall-back to single http requests - ; which is VERY slow method due to 1.5s latency per single request. Here is example of ""normal"" response on multipart http request:; ```; curl -ik https://root.cern/js/files/hsimple.root -H ""Range: bytes=0-15,1000-1015"" --output - (15.06. 11:15:48) !11391 ; HTTP/1.1 206 Partial Content; Date: Thu, 15 Jun 2023 09:16:57 GMT; Server: Apache/2.4.41 (Ubuntu); X-Frame-Options: SAMEORIGIN; Last-Modified: Thu, 04 Jul 2013 08:21:05 GMT; ETag: ""6521f-4e0ab42683e40""; Accept-Ranges: bytes; Content-Length: 177; Cache-Control: max-age=1800; Expires: Thu, 15 Jun 2023 09:46:57 GMT; Content-Security-Policy: frame-ancestors 'self';; Strict-Transport-Security: max-age=15768000; Access-Control-Allow-Origin: *; Access-Control-Allow-Headers: range; Access-Control-Expose-Headers: content-range,content-length,content-type,accept-ranges; Access-Control-Allow-Methods: HEAD,GET; Content-Type: multipart/byteranges; boundary=61c842e35204a0c7. --61c842e35204a0c7; Content-range: bytes 0-15/414239. rootmdR; --61c842e35204a0c7; Content-range: bytes 1000-1015/414239. 1ZGqP; --61c842e35204a0c7--; ```. And here is result from cernbox:; ```; curl -ik https://cernbox.cern.ch/remote.php/dav/public-files/1Cy1HIf03Ca76Dm/test_ntuples_200123.root -H ""Range: bytes=0-15,1000-1015"" --output - (15.06. 11:15:25) !11380 ; HTTP/1.1 206 Partial Content; Access-Control-Allow-Origin: *; Content-Disposition: attachment; filename=""test_ntuples_200123.root""; Content-Length: 389; Content-Range: ; Content-Security-Policy: default-src 'none';; Content-Type: application/octet-stream; Date: Thu, 15 Jun 2023 09:15:48 GMT; Etag: ""329762575417868288:9d274a18""; Last-Modified: Wed, 24 May 2023 12:22:19 +0000; Oc-Etag: ""329762575417868288:9d274a18""; Oc-Fileid: eoshome-t!103034857; Server: nginx/1.20.1; Strict-Tran",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13018#issuecomment-1592696000
Usability,clear,clearly,"gth,content-type,accept-ranges; Access-Control-Allow-Methods: HEAD,GET; Content-Type: multipart/byteranges; boundary=61c842e35204a0c7. --61c842e35204a0c7; Content-range: bytes 0-15/414239. rootmdR; --61c842e35204a0c7; Content-range: bytes 1000-1015/414239. 1ZGqP; --61c842e35204a0c7--; ```. And here is result from cernbox:; ```; curl -ik https://cernbox.cern.ch/remote.php/dav/public-files/1Cy1HIf03Ca76Dm/test_ntuples_200123.root -H ""Range: bytes=0-15,1000-1015"" --output - (15.06. 11:15:25) !11380 ; HTTP/1.1 206 Partial Content; Access-Control-Allow-Origin: *; Content-Disposition: attachment; filename=""test_ntuples_200123.root""; Content-Length: 389; Content-Range: ; Content-Security-Policy: default-src 'none';; Content-Type: application/octet-stream; Date: Thu, 15 Jun 2023 09:15:48 GMT; Etag: ""329762575417868288:9d274a18""; Last-Modified: Wed, 24 May 2023 12:22:19 +0000; Oc-Etag: ""329762575417868288:9d274a18""; Oc-Fileid: eoshome-t!103034857; Server: nginx/1.20.1; Strict-Transport-Security: max-age=63072000; Vary: Origin; X-Content-Type-Options: nosniff; X-Download-Options: noopen; X-Frame-Options: SAMEORIGIN; X-Permitted-Cross-Domain-Policies: none; X-Robots-Tag: none; X-Xss-Protection: 1; mode=block. --1941f188e1f15cbc8af2c2ce8ba24411209981093834f193e96822568cbb; Content-Range: bytes 0-15/4667337; Content-Type: application/octet-stream. rootdG7; --1941f188e1f15cbc8af2c2ce8ba24411209981093834f193e96822568cbb; Content-Range: bytes 1000-1015/4667337; Content-Type: application/octet-stream. .J.f6Mm; --1941f188e1f15cbc8af2c2ce8ba24411209981093834f193e96822568cbb--; ```. That is wrong?; First of all content type must be: ""Content-Type: multipart/something""; In the same line one should have boundary like ""boundary=61c842e35204a0c7""; Such line is not present in cernbox response.; Without clearly specified ""boundary"" it is not possible to decode data afterwards. My conclusion - malformed http response and large latency make impossible to use cernbox http server.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13018#issuecomment-1592696000
Availability,error,error,"I see https://github.com/root-project/root/pull/11311. Is missing the R__HAS_STD_SPAN, I would say to avoid more improper reporting, it should be made more clear when those header are imported that this is the intended behaviour. I would say you should add a ; ```; #if __cplusplus >= 202002L; ```. inside those code block if they are enabled due to this mismatched compilation version and report the error",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13042#issuecomment-1595270233
Safety,avoid,avoid,"I see https://github.com/root-project/root/pull/11311. Is missing the R__HAS_STD_SPAN, I would say to avoid more improper reporting, it should be made more clear when those header are imported that this is the intended behaviour. I would say you should add a ; ```; #if __cplusplus >= 202002L; ```. inside those code block if they are enabled due to this mismatched compilation version and report the error",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13042#issuecomment-1595270233
Usability,clear,clear,"I see https://github.com/root-project/root/pull/11311. Is missing the R__HAS_STD_SPAN, I would say to avoid more improper reporting, it should be made more clear when those header are imported that this is the intended behaviour. I would say you should add a ; ```; #if __cplusplus >= 202002L; ```. inside those code block if they are enabled due to this mismatched compilation version and report the error",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13042#issuecomment-1595270233
Testability,test,tested,"> I see https://github.com/root-project/root/pull/11311. This was not merged and does not reflect that actual content of the file. Somehow in your environment the code snippet I copy/pasted is failing. We need to understand if:; * If the code snippet works in (your) C++20 (expected behavior); * Why is the code snippet failing in (your) C++23 (never tested by us). This should be testable with a simple source file containing just:; ```; #include <span>; #include ""ROOT/RRangeCast.hxx""; ```; (and another test with just the second one).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13042#issuecomment-1595284979
Usability,simpl,simple,"> I see https://github.com/root-project/root/pull/11311. This was not merged and does not reflect that actual content of the file. Somehow in your environment the code snippet I copy/pasted is failing. We need to understand if:; * If the code snippet works in (your) C++20 (expected behavior); * Why is the code snippet failing in (your) C++23 (never tested by us). This should be testable with a simple source file containing just:; ```; #include <span>; #include ""ROOT/RRangeCast.hxx""; ```; (and another test with just the second one).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13042#issuecomment-1595284979
Integrability,wrap,wrapper,"Dear @couet thank you very much. Is this something that could be implemented soon in ROOT. If it's a simple change to add the copy CTOR to the API it would avoid us in CMSSW to have to create a custom-made wrapper for TH2Poly.; Many thanks in advance, Pedro",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13075#issuecomment-1891586098
Safety,avoid,avoid,"Dear @couet thank you very much. Is this something that could be implemented soon in ROOT. If it's a simple change to add the copy CTOR to the API it would avoid us in CMSSW to have to create a custom-made wrapper for TH2Poly.; Many thanks in advance, Pedro",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13075#issuecomment-1891586098
Usability,simpl,simple,"Dear @couet thank you very much. Is this something that could be implemented soon in ROOT. If it's a simple change to add the copy CTOR to the API it would avoid us in CMSSW to have to create a custom-made wrapper for TH2Poly.; Many thanks in advance, Pedro",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13075#issuecomment-1891586098
Usability,clear,clear,"Thanks @pfs . @couet it is not clear to me whether this copy constructor has been implemented or not from the conversation, but it should be pretty straightforward. Can you take care, or, if already done, close the issue directly? Thanks!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13075#issuecomment-1926390637
Usability,simpl,simple,"Hi @bernhardmgruber , thank you for reporting this!. I understand the problem, we need to make sure we give a meaningful name to the RNTuple. Regarding your specific example above, I have a doubt about the design. Since the input is a `TChain` with no name, there is no evident unique name to give to the imported RNTuple. If the `TChain` had a name then that would be the correct name to assign. But in this case, we could:. 1. Get the name of the first tree in the first file of the chain, and assign that irrespective of the names of the other trees in the chain.; 2. Check that all trees of the chain have the same name (the first one), and assign that. If this is not the case, fallback to assigning the first name anyway ?; 3. Invent a new name for the imported RNTuple which will always be applied in case the user is importing from an un-named `TChain`. This could be anything from something simple like `MyRNTuple` to something more unique and complicated like `R__IMPORTED_RNTUPLE`. Thoughts? Also inviting @pcanal and @jblomer to comment",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13088#issuecomment-1605303317
Usability,simpl,simple,"> If the `TChain` had a name then that would be the correct name to assign. Yes.; (I didn't know `TChain`'s could have a name. I thought they were conceptually just concatenations of trees). > 1. Get the name of the first tree in the first file of the chain, and assign that irrespective of the names of the other trees in the chain. That sounds too deliberate to me. > 2. Check that all trees of the chain have the same name (the first one), and assign that. I think this would be the only sensible solution. But I don't kow how big `TChain`s can get and whether such a check would become expensive at some point. > If this is not the case, fallback to assigning the first name anyway ?. Again, I think this is too deliberate. > 3. Invent a new name for the imported RNTuple which will always be applied in case the user is importing from an un-named `TChain`. This could be anything from something simple like `MyRNTuple` to something more unique and complicated like `R__IMPORTED_RNTUPLE`. That is the the status quo, as observed by me. The name picked is `ROOT::Experimental::RNTuple`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13088#issuecomment-1606956482
Usability,user experience,user experience,"For completeness, `RNTupleImporter` already allows to supply a tree name:; ```c++; auto imp = ROOT::Experimental::RNTupleImporter::Create(&chain, ""B2HHH~zstd~10x.ntuple"");; imp->SetNTupleName(DecayTree);; imp->Import();; ```; My issue is just about an improvement of user experience.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13088#issuecomment-1612018808
Availability,error,errors,"Indeed, but for that we would need to change the public interfaces of (at least) `TLatex` and `TMathText`.; So now my question is the following: do we simply fix the compilation warnings/errors on Windows, or do we want to make it working with all possible characters, requiring new interfaces with `char32_t`?. I'll let @couet comment on that (BTW, it doesn't work on Linux or Mac either).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13091#issuecomment-1614327543
Integrability,interface,interfaces,"Indeed, but for that we would need to change the public interfaces of (at least) `TLatex` and `TMathText`.; So now my question is the following: do we simply fix the compilation warnings/errors on Windows, or do we want to make it working with all possible characters, requiring new interfaces with `char32_t`?. I'll let @couet comment on that (BTW, it doesn't work on Linux or Mac either).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13091#issuecomment-1614327543
Usability,simpl,simply,"Indeed, but for that we would need to change the public interfaces of (at least) `TLatex` and `TMathText`.; So now my question is the following: do we simply fix the compilation warnings/errors on Windows, or do we want to make it working with all possible characters, requiring new interfaces with `char32_t`?. I'll let @couet comment on that (BTW, it doesn't work on Linux or Mac either).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13091#issuecomment-1614327543
Energy Efficiency,allocate,allocates,"@vepadulano , not clear from the conversation to me, but is the comment above about the suppression file and how cling allocates addressing your original issue? If yes,could you close this item?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13130#issuecomment-1926398466
Usability,clear,clear,"@vepadulano , not clear from the conversation to me, but is the comment above about the suppression file and how cling allocates addressing your original issue? If yes,could you close this item?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13130#issuecomment-1926398466
Availability,error,error,"My 2 cents:. 1. It is extremly weird/ a bug that the webgui needs to depend on `TObject`.; 2. `RBrowserDataCleanup` derives from `TObject`, so it *must* have a `ClassDef` as per https://root.cern/manual/io_custom_classes/#the-classdef-macro . I am not sure about what using `ClassDefInline` as suggested by @pcanal would change; 2a. Can `RBrowserDataCleanup` just avoid inheriting from `TObject` completely? ; 3. `RBrowserData` has a dictionary and allows I/O, as it is defined in `LinkDef.h`, so it is only natural that its data members need a dictionary as well. As @hahnjo commented, the particular error coming from a `std::tuple` is due to the fact that the class uses ` std::unique_ptr<RBrowserDataCleanup>`. Bottom line, to me everything looks very clear and I don't understand the comments regarding looking for a deeper reason behind the error. The only thing I don't understand is the dependency from `TObject` itself, but that's beyond the scope of this PR",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13134#issuecomment-1637626198
Integrability,depend,depend,"My 2 cents:. 1. It is extremly weird/ a bug that the webgui needs to depend on `TObject`.; 2. `RBrowserDataCleanup` derives from `TObject`, so it *must* have a `ClassDef` as per https://root.cern/manual/io_custom_classes/#the-classdef-macro . I am not sure about what using `ClassDefInline` as suggested by @pcanal would change; 2a. Can `RBrowserDataCleanup` just avoid inheriting from `TObject` completely? ; 3. `RBrowserData` has a dictionary and allows I/O, as it is defined in `LinkDef.h`, so it is only natural that its data members need a dictionary as well. As @hahnjo commented, the particular error coming from a `std::tuple` is due to the fact that the class uses ` std::unique_ptr<RBrowserDataCleanup>`. Bottom line, to me everything looks very clear and I don't understand the comments regarding looking for a deeper reason behind the error. The only thing I don't understand is the dependency from `TObject` itself, but that's beyond the scope of this PR",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13134#issuecomment-1637626198
Modifiability,inherit,inheriting,"My 2 cents:. 1. It is extremly weird/ a bug that the webgui needs to depend on `TObject`.; 2. `RBrowserDataCleanup` derives from `TObject`, so it *must* have a `ClassDef` as per https://root.cern/manual/io_custom_classes/#the-classdef-macro . I am not sure about what using `ClassDefInline` as suggested by @pcanal would change; 2a. Can `RBrowserDataCleanup` just avoid inheriting from `TObject` completely? ; 3. `RBrowserData` has a dictionary and allows I/O, as it is defined in `LinkDef.h`, so it is only natural that its data members need a dictionary as well. As @hahnjo commented, the particular error coming from a `std::tuple` is due to the fact that the class uses ` std::unique_ptr<RBrowserDataCleanup>`. Bottom line, to me everything looks very clear and I don't understand the comments regarding looking for a deeper reason behind the error. The only thing I don't understand is the dependency from `TObject` itself, but that's beyond the scope of this PR",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13134#issuecomment-1637626198
Safety,avoid,avoid,"My 2 cents:. 1. It is extremly weird/ a bug that the webgui needs to depend on `TObject`.; 2. `RBrowserDataCleanup` derives from `TObject`, so it *must* have a `ClassDef` as per https://root.cern/manual/io_custom_classes/#the-classdef-macro . I am not sure about what using `ClassDefInline` as suggested by @pcanal would change; 2a. Can `RBrowserDataCleanup` just avoid inheriting from `TObject` completely? ; 3. `RBrowserData` has a dictionary and allows I/O, as it is defined in `LinkDef.h`, so it is only natural that its data members need a dictionary as well. As @hahnjo commented, the particular error coming from a `std::tuple` is due to the fact that the class uses ` std::unique_ptr<RBrowserDataCleanup>`. Bottom line, to me everything looks very clear and I don't understand the comments regarding looking for a deeper reason behind the error. The only thing I don't understand is the dependency from `TObject` itself, but that's beyond the scope of this PR",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13134#issuecomment-1637626198
Usability,clear,clear,"My 2 cents:. 1. It is extremly weird/ a bug that the webgui needs to depend on `TObject`.; 2. `RBrowserDataCleanup` derives from `TObject`, so it *must* have a `ClassDef` as per https://root.cern/manual/io_custom_classes/#the-classdef-macro . I am not sure about what using `ClassDefInline` as suggested by @pcanal would change; 2a. Can `RBrowserDataCleanup` just avoid inheriting from `TObject` completely? ; 3. `RBrowserData` has a dictionary and allows I/O, as it is defined in `LinkDef.h`, so it is only natural that its data members need a dictionary as well. As @hahnjo commented, the particular error coming from a `std::tuple` is due to the fact that the class uses ` std::unique_ptr<RBrowserDataCleanup>`. Bottom line, to me everything looks very clear and I don't understand the comments regarding looking for a deeper reason behind the error. The only thing I don't understand is the dependency from `TObject` itself, but that's beyond the scope of this PR",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13134#issuecomment-1637626198
Usability,simpl,simpler,">> Is it so?. > Yes, as written in the manual. . I still do not see reason why dictionary is necessary here. ; It is really question for @pcanal. ; Is there special handling of `std::unique_ptr<T>` for the types derived from `TObject`? ; In dictionary for transient members? ; And how one gets such information for the class which does not appears in header files?. As I mention - there is much simpler workaround with plain pointer.; But once I implement it - one immediately forgets about the problem.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13134#issuecomment-1638477128
Testability,test,test,It's not clear to me what the actually issue with Jenkins is. It looks like a fluke in one of the jenkins components. Could you restart the test?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13146#issuecomment-1620049875
Usability,clear,clear,It's not clear to me what the actually issue with Jenkins is. It looks like a fluke in one of the jenkins components. Could you restart the test?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13146#issuecomment-1620049875
Availability,error,error,"> I think it should live in InternalTreeUtils?. I was thinking this is generic enough that we may want to use it in places that do not strictly depend from `libTree`, but maybe I'm just overthinking. > How can we be sure that this function returns the same files in the same order as the previous one in all cases?. I hope we already get a (very good?) degree of certainty by not breaking existing test cases. I can come up with a few more just to add extra safety. Irrespective of this, the function is taken verbatim from the logic in `TChain::Add`. Do you see any part of the function that intuitively might lead to different results? I was thinking about this and the only place that remotely gives me a slight doubt is using `std::sort` instead of `TList::Sort`, but I really hope that doesn't introduce a different behaviour. > the new one throws if a directory cannot be opened. Yes indeed that's a different behaviour. The existing logic never throws. In case `dir == nullptr`, which I guess happens if the expanded directory cannot be found/opened (?), then it will just fall to the end of the `TChain::Add` method and `return nf`, where `nf` will be zero since no files have been added. In this regard I see two options:. 1. The new function throws (because subjectively is the correct behaviour). Then in `TChain::Add` we can keep the old behaviour, by catching the error and not re-raising it.; 2. The new function can return an empty vector, in case `dir == nullptr`. This is more similar in spirit with the old behaviour.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13160#issuecomment-1619057225
Integrability,depend,depend,"> I think it should live in InternalTreeUtils?. I was thinking this is generic enough that we may want to use it in places that do not strictly depend from `libTree`, but maybe I'm just overthinking. > How can we be sure that this function returns the same files in the same order as the previous one in all cases?. I hope we already get a (very good?) degree of certainty by not breaking existing test cases. I can come up with a few more just to add extra safety. Irrespective of this, the function is taken verbatim from the logic in `TChain::Add`. Do you see any part of the function that intuitively might lead to different results? I was thinking about this and the only place that remotely gives me a slight doubt is using `std::sort` instead of `TList::Sort`, but I really hope that doesn't introduce a different behaviour. > the new one throws if a directory cannot be opened. Yes indeed that's a different behaviour. The existing logic never throws. In case `dir == nullptr`, which I guess happens if the expanded directory cannot be found/opened (?), then it will just fall to the end of the `TChain::Add` method and `return nf`, where `nf` will be zero since no files have been added. In this regard I see two options:. 1. The new function throws (because subjectively is the correct behaviour). Then in `TChain::Add` we can keep the old behaviour, by catching the error and not re-raising it.; 2. The new function can return an empty vector, in case `dir == nullptr`. This is more similar in spirit with the old behaviour.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13160#issuecomment-1619057225
Safety,safe,safety,"> I think it should live in InternalTreeUtils?. I was thinking this is generic enough that we may want to use it in places that do not strictly depend from `libTree`, but maybe I'm just overthinking. > How can we be sure that this function returns the same files in the same order as the previous one in all cases?. I hope we already get a (very good?) degree of certainty by not breaking existing test cases. I can come up with a few more just to add extra safety. Irrespective of this, the function is taken verbatim from the logic in `TChain::Add`. Do you see any part of the function that intuitively might lead to different results? I was thinking about this and the only place that remotely gives me a slight doubt is using `std::sort` instead of `TList::Sort`, but I really hope that doesn't introduce a different behaviour. > the new one throws if a directory cannot be opened. Yes indeed that's a different behaviour. The existing logic never throws. In case `dir == nullptr`, which I guess happens if the expanded directory cannot be found/opened (?), then it will just fall to the end of the `TChain::Add` method and `return nf`, where `nf` will be zero since no files have been added. In this regard I see two options:. 1. The new function throws (because subjectively is the correct behaviour). Then in `TChain::Add` we can keep the old behaviour, by catching the error and not re-raising it.; 2. The new function can return an empty vector, in case `dir == nullptr`. This is more similar in spirit with the old behaviour.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13160#issuecomment-1619057225
Testability,test,test,"> I think it should live in InternalTreeUtils?. I was thinking this is generic enough that we may want to use it in places that do not strictly depend from `libTree`, but maybe I'm just overthinking. > How can we be sure that this function returns the same files in the same order as the previous one in all cases?. I hope we already get a (very good?) degree of certainty by not breaking existing test cases. I can come up with a few more just to add extra safety. Irrespective of this, the function is taken verbatim from the logic in `TChain::Add`. Do you see any part of the function that intuitively might lead to different results? I was thinking about this and the only place that remotely gives me a slight doubt is using `std::sort` instead of `TList::Sort`, but I really hope that doesn't introduce a different behaviour. > the new one throws if a directory cannot be opened. Yes indeed that's a different behaviour. The existing logic never throws. In case `dir == nullptr`, which I guess happens if the expanded directory cannot be found/opened (?), then it will just fall to the end of the `TChain::Add` method and `return nf`, where `nf` will be zero since no files have been added. In this regard I see two options:. 1. The new function throws (because subjectively is the correct behaviour). Then in `TChain::Add` we can keep the old behaviour, by catching the error and not re-raising it.; 2. The new function can return an empty vector, in case `dir == nullptr`. This is more similar in spirit with the old behaviour.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13160#issuecomment-1619057225
Usability,intuit,intuitively,"> I think it should live in InternalTreeUtils?. I was thinking this is generic enough that we may want to use it in places that do not strictly depend from `libTree`, but maybe I'm just overthinking. > How can we be sure that this function returns the same files in the same order as the previous one in all cases?. I hope we already get a (very good?) degree of certainty by not breaking existing test cases. I can come up with a few more just to add extra safety. Irrespective of this, the function is taken verbatim from the logic in `TChain::Add`. Do you see any part of the function that intuitively might lead to different results? I was thinking about this and the only place that remotely gives me a slight doubt is using `std::sort` instead of `TList::Sort`, but I really hope that doesn't introduce a different behaviour. > the new one throws if a directory cannot be opened. Yes indeed that's a different behaviour. The existing logic never throws. In case `dir == nullptr`, which I guess happens if the expanded directory cannot be found/opened (?), then it will just fall to the end of the `TChain::Add` method and `return nf`, where `nf` will be zero since no files have been added. In this regard I see two options:. 1. The new function throws (because subjectively is the correct behaviour). Then in `TChain::Add` we can keep the old behaviour, by catching the error and not re-raising it.; 2. The new function can return an empty vector, in case `dir == nullptr`. This is more similar in spirit with the old behaviour.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13160#issuecomment-1619057225
Deployability,patch,patch,"I think this is a clear sign we want this patch. ![image](https://github.com/root-project/root/assets/15638895/dc7f1386-c921-4796-8a92-172026517ba8). One could say that returning a string that ends with ""\n"" would be slightly more annoying for post-processing, but I really don't think that counterargument has enough weight",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13165#issuecomment-1621661045
Usability,clear,clear,"I think this is a clear sign we want this patch. ![image](https://github.com/root-project/root/assets/15638895/dc7f1386-c921-4796-8a92-172026517ba8). One could say that returning a string that ends with ""\n"" would be slightly more annoying for post-processing, but I really don't think that counterargument has enough weight",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13165#issuecomment-1621661045
Availability,error,error,"> * Revert changes to `emitLLVMUsed`: clearing the vectors `LLVMUsed` and `LLVMCompilerUsed` does not seem; > needed because `CodeGenerator::StartModule` will swap the entire `CodeGenModule`.; > . Makes sense to me. > * Revert changes to `SourceManager::isBeforeInTranslationUnit`: if assertions are enabled `llvm_unreachable` has the same effects as `assert(0)`. As we don't see this assertion in recent times, this change is probably not relevant anymore. The problem is generated (synthesized) code which have no source location information. Then when you have an error resulting in multiple overloads we will need to compare their source locations to order the diagnostics. This patch makes this codes to work while the llvm_unreachable makes it crash in production. > ; > * Revert change in `SourceLocation::isBeforeInTranslationUnitThan`: I believe that all locations have a `SourceManager` nowadays, even from the command line. That was probably relevant for the PCH and rootmaps?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13181#issuecomment-1621492471
Deployability,patch,patch,"> * Revert changes to `emitLLVMUsed`: clearing the vectors `LLVMUsed` and `LLVMCompilerUsed` does not seem; > needed because `CodeGenerator::StartModule` will swap the entire `CodeGenModule`.; > . Makes sense to me. > * Revert changes to `SourceManager::isBeforeInTranslationUnit`: if assertions are enabled `llvm_unreachable` has the same effects as `assert(0)`. As we don't see this assertion in recent times, this change is probably not relevant anymore. The problem is generated (synthesized) code which have no source location information. Then when you have an error resulting in multiple overloads we will need to compare their source locations to order the diagnostics. This patch makes this codes to work while the llvm_unreachable makes it crash in production. > ; > * Revert change in `SourceLocation::isBeforeInTranslationUnitThan`: I believe that all locations have a `SourceManager` nowadays, even from the command line. That was probably relevant for the PCH and rootmaps?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13181#issuecomment-1621492471
Testability,assert,assertions,"> * Revert changes to `emitLLVMUsed`: clearing the vectors `LLVMUsed` and `LLVMCompilerUsed` does not seem; > needed because `CodeGenerator::StartModule` will swap the entire `CodeGenModule`.; > . Makes sense to me. > * Revert changes to `SourceManager::isBeforeInTranslationUnit`: if assertions are enabled `llvm_unreachable` has the same effects as `assert(0)`. As we don't see this assertion in recent times, this change is probably not relevant anymore. The problem is generated (synthesized) code which have no source location information. Then when you have an error resulting in multiple overloads we will need to compare their source locations to order the diagnostics. This patch makes this codes to work while the llvm_unreachable makes it crash in production. > ; > * Revert change in `SourceLocation::isBeforeInTranslationUnitThan`: I believe that all locations have a `SourceManager` nowadays, even from the command line. That was probably relevant for the PCH and rootmaps?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13181#issuecomment-1621492471
Usability,clear,clearing,"> * Revert changes to `emitLLVMUsed`: clearing the vectors `LLVMUsed` and `LLVMCompilerUsed` does not seem; > needed because `CodeGenerator::StartModule` will swap the entire `CodeGenModule`.; > . Makes sense to me. > * Revert changes to `SourceManager::isBeforeInTranslationUnit`: if assertions are enabled `llvm_unreachable` has the same effects as `assert(0)`. As we don't see this assertion in recent times, this change is probably not relevant anymore. The problem is generated (synthesized) code which have no source location information. Then when you have an error resulting in multiple overloads we will need to compare their source locations to order the diagnostics. This patch makes this codes to work while the llvm_unreachable makes it crash in production. > ; > * Revert change in `SourceLocation::isBeforeInTranslationUnitThan`: I believe that all locations have a `SourceManager` nowadays, even from the command line. That was probably relevant for the PCH and rootmaps?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13181#issuecomment-1621492471
Usability,guid,guidelines,"> > @jalopezg-git Yes, can you open a PR?; > ; > @ferdymercury as you are the original author of #13217, do you want to take care of the backport?. I could do it, but I have never done it before, so I need some guidelines. Should I use rebase on some XY branch and then cherry-picking only my commit or sth like that?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13182#issuecomment-1643431150
Deployability,patch,patches,"> > > @jalopezg-git Yes, can you open a PR?; > > ; > > ; > > @ferdymercury as you are the original author of #13217, do you want to take care of the backport?; > ; > I could do it, but I have never done it before, so I need some guidelines. Should I use rebase on some XY branch and then cherry-picking only my commit or sth like that?. Assuming that the remote `origin` refers to upstream and `ferdymercury` to `https://github.com/ferdymercury/root/`, the simplest way is to; ```bash; $ git fetch origin v6-28-00-patches:v6-28-00-patches; $ git checkout -b TDirectoryFile-ls-v6.28 v6-28-00-patches; $ git cherry-pick ... # your commit(s) here - I think it was 2 commits; mention them in order here; $ git push ferdymercury TDirectoryFile-ls-v6.28; ```; , and then open a PR to be merged against the `v6-28-00-patches` branch. I'll let you try; if you don't manage, I'll do it instead :slightly_smiling_face:.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13182#issuecomment-1643640639
Usability,guid,guidelines,"> > > @jalopezg-git Yes, can you open a PR?; > > ; > > ; > > @ferdymercury as you are the original author of #13217, do you want to take care of the backport?; > ; > I could do it, but I have never done it before, so I need some guidelines. Should I use rebase on some XY branch and then cherry-picking only my commit or sth like that?. Assuming that the remote `origin` refers to upstream and `ferdymercury` to `https://github.com/ferdymercury/root/`, the simplest way is to; ```bash; $ git fetch origin v6-28-00-patches:v6-28-00-patches; $ git checkout -b TDirectoryFile-ls-v6.28 v6-28-00-patches; $ git cherry-pick ... # your commit(s) here - I think it was 2 commits; mention them in order here; $ git push ferdymercury TDirectoryFile-ls-v6.28; ```; , and then open a PR to be merged against the `v6-28-00-patches` branch. I'll let you try; if you don't manage, I'll do it instead :slightly_smiling_face:.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13182#issuecomment-1643640639
Availability,error,errors,"bjects or JSON string literals. One good target for this is the creation of HistFactory models, which can be done by importing a full HS3 JSON as described here in this tutorial:; https://root.cern/doc/master/rf515__hfJSON_8py.html. With the PRs that were already merged, creating the HistFactory pdfs from dictionaries already works. But the dataset specification still must go over string literals, as shown in this simplified version of the tutorial:. ```python; # Simplified version of the HistFactory JSON IO tutorial:; # https://root.cern/doc/master/rf515__hfJSON_8py.html; # You can also find it in the tutorials/roofit folder of the ROOT repo. import ROOT. # Python dictionary specifying the model pdf; model_channel1 = {; ""axes"": [{""name"": ""obs_x_channel1"", ""max"": 2.0, ""min"": 1.0, ""nbins"": 2}],; ""samples"": [; {; ""data"": {""contents"": [20, 10]},; ""modifiers"": [; {""data"": {""hi"": 1.05, ""lo"": 0.95}, ""name"": ""syst1"", ""type"": ""normsys""},; {""name"": ""mu"", ""type"": ""normfactor""},; ],; ""name"": ""signal"",; },; {; ""data"": {""contents"": [100, 0], ""errors"": [5, 0]},; ""modifiers"": [; {""data"": {""hi"": 1.05, ""lo"": 0.95}, ""name"": ""syst2"", ""type"": ""normsys""},; {""name"": ""mcstat"", ""type"": ""staterror""},; ],; ""name"": ""background1"",; },; {; ""data"": {""contents"": [0, 100], ""errors"": [0, 10]},; ""modifiers"": [; {""data"": {""hi"": 1.05, ""lo"": 0.95}, ""name"": ""syst3"", ""type"": ""normsys""},; {""name"": ""mcstat"", ""type"": ""staterror""},; ],; ""name"": ""background2"",; },; ],; ""type"": ""histfactory_dist"",; }. # Python dictionary specifying the binned dataset; observed_channel1 = {; ""axes"": [{""name"": ""obs_x_channel1"", ""nbins"": 2, ""min"": 1, ""max"": 2}],; ""contents"": [122, 112],; ""type"": ""binned"",; }. # Creating an empty workspace; ws = ROOT.RooWorkspace(""workspace""). # Importing the HistFactory pdf from a dictionary specification already works!; ws[""model_channel1""] = model_channel1. # It would be nice if the user can also specify the datasets like this, such; # that no string literals are necessary to specify everything ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13185#issuecomment-1621628860
Usability,simpl,simplified,"One of the project goals is to support setting up the workspace for likelihood fits purely from Python dictionaries, without using RooFit objects or JSON string literals. One good target for this is the creation of HistFactory models, which can be done by importing a full HS3 JSON as described here in this tutorial:; https://root.cern/doc/master/rf515__hfJSON_8py.html. With the PRs that were already merged, creating the HistFactory pdfs from dictionaries already works. But the dataset specification still must go over string literals, as shown in this simplified version of the tutorial:. ```python; # Simplified version of the HistFactory JSON IO tutorial:; # https://root.cern/doc/master/rf515__hfJSON_8py.html; # You can also find it in the tutorials/roofit folder of the ROOT repo. import ROOT. # Python dictionary specifying the model pdf; model_channel1 = {; ""axes"": [{""name"": ""obs_x_channel1"", ""max"": 2.0, ""min"": 1.0, ""nbins"": 2}],; ""samples"": [; {; ""data"": {""contents"": [20, 10]},; ""modifiers"": [; {""data"": {""hi"": 1.05, ""lo"": 0.95}, ""name"": ""syst1"", ""type"": ""normsys""},; {""name"": ""mu"", ""type"": ""normfactor""},; ],; ""name"": ""signal"",; },; {; ""data"": {""contents"": [100, 0], ""errors"": [5, 0]},; ""modifiers"": [; {""data"": {""hi"": 1.05, ""lo"": 0.95}, ""name"": ""syst2"", ""type"": ""normsys""},; {""name"": ""mcstat"", ""type"": ""staterror""},; ],; ""name"": ""background1"",; },; {; ""data"": {""contents"": [0, 100], ""errors"": [0, 10]},; ""modifiers"": [; {""data"": {""hi"": 1.05, ""lo"": 0.95}, ""name"": ""syst3"", ""type"": ""normsys""},; {""name"": ""mcstat"", ""type"": ""staterror""},; ],; ""name"": ""background2"",; },; ],; ""type"": ""histfactory_dist"",; }. # Python dictionary specifying the binned dataset; observed_channel1 = {; ""axes"": [{""name"": ""obs_x_channel1"", ""nbins"": 2, ""min"": 1, ""max"": 2}],; ""contents"": [122, 112],; ""type"": ""binned"",; }. # Creating an empty workspace; ws = ROOT.RooWorkspace(""workspace""). # Importing the HistFactory pdf from a dictionary specification already works!; ws[""model_channel1""] = model_channel1. #",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13185#issuecomment-1621628860
Usability,learn,learnt,"Hi @jalopezg-git et al :). Thank you for your comments and suggestions, I have learnt new things in this PR. In the last commits I implemented the changes suggested by @vepadulano. Note that I have added a new file with the two lines that print the contents of the TTree using a RDF. The topics that would remain open are:; * Extension of README, as stated [here](https://github.com/root-project/root/pull/13205#discussion_r1259443075). I am sorry but that is beyond my knowledge. Please feel free to complement the README of this tutorial or the ROOT documentation.; * The dot at the end of the branch name is not documented, but it is discussed in some forum threads. I would suggest to add the comment from P. Canal [here](https://github.com/root-project/root/pull/13205#discussion_r1265655686) for sake of clarity. Thank you for your time. Best,; Alvaro",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13205#issuecomment-1673054332
Usability,clear,clear,"> > > @Nowakus: if this change is merged, you will most likely need to slightly adjust your code. Just to make it clear that there is absolutely no problem with adjusting my code to your changes for the time being. ; (as long as I am able to make it still work that is )",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13219#issuecomment-1630954373
Availability,error,error,"Hi @VanyaBelyaev, thanks for posting about this!. As explained in [this PR](https://github.com/root-project/root/pull/11909/files) and later also dicussed in [this forum post](https://root-forum.cern.ch/t/retreiving-the-calculation-strategy-of-a-roonll/55715/2), saving test statistics objects to ROOT files like `RooNLLVar` is now prohibited since ROOT 6.28. It only technically seemed to work without error, but in fact the read-back RooNLLVars are corrupted and give wrong results when you read them back even for simple Gaussian cases, as I showed in the description of the linked PR. This and other reasons lead us to the decision to disallow the IO of `RooNLLVar` and other test statistics classes. From your warnings and error messages, it seems like you're trying to do IO of the RooNLLVar. Is there a way you can avoid this in your workflow? As I said it's not allowed anymore and in older ROOT versions it was not reliable. What people usually do is to save the pdf and the datasets in a RooWorkspace, and maybe a `ModelConfig` to simplify the NLL creation when reading back the data and pdf. Is that not an option for your?. Certainly I was not expecting that the removal of this accidental and buggy IO feature would cause some friction with some users, so I'm happy to help you finding an alternative and better solution!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13280#issuecomment-1644053557
Integrability,message,messages,"Hi @VanyaBelyaev, thanks for posting about this!. As explained in [this PR](https://github.com/root-project/root/pull/11909/files) and later also dicussed in [this forum post](https://root-forum.cern.ch/t/retreiving-the-calculation-strategy-of-a-roonll/55715/2), saving test statistics objects to ROOT files like `RooNLLVar` is now prohibited since ROOT 6.28. It only technically seemed to work without error, but in fact the read-back RooNLLVars are corrupted and give wrong results when you read them back even for simple Gaussian cases, as I showed in the description of the linked PR. This and other reasons lead us to the decision to disallow the IO of `RooNLLVar` and other test statistics classes. From your warnings and error messages, it seems like you're trying to do IO of the RooNLLVar. Is there a way you can avoid this in your workflow? As I said it's not allowed anymore and in older ROOT versions it was not reliable. What people usually do is to save the pdf and the datasets in a RooWorkspace, and maybe a `ModelConfig` to simplify the NLL creation when reading back the data and pdf. Is that not an option for your?. Certainly I was not expecting that the removal of this accidental and buggy IO feature would cause some friction with some users, so I'm happy to help you finding an alternative and better solution!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13280#issuecomment-1644053557
Safety,avoid,avoid,"Hi @VanyaBelyaev, thanks for posting about this!. As explained in [this PR](https://github.com/root-project/root/pull/11909/files) and later also dicussed in [this forum post](https://root-forum.cern.ch/t/retreiving-the-calculation-strategy-of-a-roonll/55715/2), saving test statistics objects to ROOT files like `RooNLLVar` is now prohibited since ROOT 6.28. It only technically seemed to work without error, but in fact the read-back RooNLLVars are corrupted and give wrong results when you read them back even for simple Gaussian cases, as I showed in the description of the linked PR. This and other reasons lead us to the decision to disallow the IO of `RooNLLVar` and other test statistics classes. From your warnings and error messages, it seems like you're trying to do IO of the RooNLLVar. Is there a way you can avoid this in your workflow? As I said it's not allowed anymore and in older ROOT versions it was not reliable. What people usually do is to save the pdf and the datasets in a RooWorkspace, and maybe a `ModelConfig` to simplify the NLL creation when reading back the data and pdf. Is that not an option for your?. Certainly I was not expecting that the removal of this accidental and buggy IO feature would cause some friction with some users, so I'm happy to help you finding an alternative and better solution!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13280#issuecomment-1644053557
Testability,test,test,"Hi @VanyaBelyaev, thanks for posting about this!. As explained in [this PR](https://github.com/root-project/root/pull/11909/files) and later also dicussed in [this forum post](https://root-forum.cern.ch/t/retreiving-the-calculation-strategy-of-a-roonll/55715/2), saving test statistics objects to ROOT files like `RooNLLVar` is now prohibited since ROOT 6.28. It only technically seemed to work without error, but in fact the read-back RooNLLVars are corrupted and give wrong results when you read them back even for simple Gaussian cases, as I showed in the description of the linked PR. This and other reasons lead us to the decision to disallow the IO of `RooNLLVar` and other test statistics classes. From your warnings and error messages, it seems like you're trying to do IO of the RooNLLVar. Is there a way you can avoid this in your workflow? As I said it's not allowed anymore and in older ROOT versions it was not reliable. What people usually do is to save the pdf and the datasets in a RooWorkspace, and maybe a `ModelConfig` to simplify the NLL creation when reading back the data and pdf. Is that not an option for your?. Certainly I was not expecting that the removal of this accidental and buggy IO feature would cause some friction with some users, so I'm happy to help you finding an alternative and better solution!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13280#issuecomment-1644053557
Usability,simpl,simple,"Hi @VanyaBelyaev, thanks for posting about this!. As explained in [this PR](https://github.com/root-project/root/pull/11909/files) and later also dicussed in [this forum post](https://root-forum.cern.ch/t/retreiving-the-calculation-strategy-of-a-roonll/55715/2), saving test statistics objects to ROOT files like `RooNLLVar` is now prohibited since ROOT 6.28. It only technically seemed to work without error, but in fact the read-back RooNLLVars are corrupted and give wrong results when you read them back even for simple Gaussian cases, as I showed in the description of the linked PR. This and other reasons lead us to the decision to disallow the IO of `RooNLLVar` and other test statistics classes. From your warnings and error messages, it seems like you're trying to do IO of the RooNLLVar. Is there a way you can avoid this in your workflow? As I said it's not allowed anymore and in older ROOT versions it was not reliable. What people usually do is to save the pdf and the datasets in a RooWorkspace, and maybe a `ModelConfig` to simplify the NLL creation when reading back the data and pdf. Is that not an option for your?. Certainly I was not expecting that the removal of this accidental and buggy IO feature would cause some friction with some users, so I'm happy to help you finding an alternative and better solution!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13280#issuecomment-1644053557
Usability,simpl,simple,"> Well, what I'm doing here i prevent the following example: The class `TVector3` has a method `Orthogonal()` returning a `TVector3`, which as a method `Orthogonal()`, and so on. It's maybe not optimal, but it's a good compromise between not browsing any `TMethodBrowsable` and having infinite recursion. That being said, feel free to propose a better solution (it's @pcanal code anyway wink). At the end of the day, IIUC, what we need is to be able to (even partially) browse methods to be able to draw something... Yes, I see. However, while the case `Orthogonal()->Orthogonal()` is seldomly useful, other simple cases like `Orthogonal()->Px()` might be useful. . So I do actually wonder why the infinite recursion is an issue  I'm with @pcanal 's comment from #13233 here, i.e. since the recursion is real, and given that the populating is already done lazily (i.e. triggered by the user clicking), it does not break anything technically (unless I missed something). . In other words: Is JIRA issue [#9260](https://sft.its.cern.ch/jira/browse/ROOT-9260) actually a bug? In my opinion, this would be intended behaviour (if I click on a method which returns something not really useful from the mathematical / physics point of view, ROOT has no way to know and gives me exactly what I asked for :wink: ).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13284#issuecomment-1642563861
Testability,test,tests,"> Thank you for the addition @ferdymercury ! I believe this is better than `std::tuple_cat` as it doesn't need the input arguments to be `tuples` and it already returns the formatted string. Can I ask you to provide a couple of tests for the new feature?. Thanks! I just wrote a couple of tests, but I am not very familiar with the GTest infrastructure, I usually use CTest. So I will need some guidance from you ;)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13299#issuecomment-1723612261
Usability,guid,guidance,"> Thank you for the addition @ferdymercury ! I believe this is better than `std::tuple_cat` as it doesn't need the input arguments to be `tuples` and it already returns the formatted string. Can I ask you to provide a couple of tests for the new feature?. Thanks! I just wrote a couple of tests, but I am not very familiar with the GTest infrastructure, I usually use CTest. So I will need some guidance from you ;)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13299#issuecomment-1723612261
Usability,clear,clear,"That's a nice demo, @dpiparo, and how it's commonly done. Or you can just copy the collection, if it's not too expensive. As for the actual issue: it should be clear that reader views should not be sortable. We can't make this explicitly clear with `const` because ROOT and it's users are not very consistent with that keyword, as @Axel-Naumann said. So there is no solution here - ROOT and C++ just allow you to shoot yourself in the foot :slightly_smiling_face:",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13314#issuecomment-2046122952
Performance,perform,performing,"My two cents about the naming; * `GenerateValueFor` doesn't work since the value is not being generated for the other instance, but for this one (AFAIU).; * `GenerateValueBy` sounds fine in principle since the `GenerateValue` call is called *by* the other instance. I have to admit that I personally do not get this immediately and I have to stop half a second to think about the meaning of the function name.; * `GenerateValueOn` also doesn't work because the value is being generated by the other instance, not on.; * `GenerateValueFrom` personally has a similar meaning to `GenerateValueBy` and is easier to get intuitively.; * The `GenerateValueFrom` naming works for `Generate` but not for `Append`. I.e. I don't like `AppendFrom` since that sounds like we are appending some value *from* the other instance *into* this one; * To me it looks like all these functions are performing a call of the same function name on another instance. Thus, personally I would go with a naming like `CallGenerateValueOn`, `CallAppendOn`, `CallReadOn` etc.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13317#issuecomment-1651710380
Usability,intuit,intuitively,"My two cents about the naming; * `GenerateValueFor` doesn't work since the value is not being generated for the other instance, but for this one (AFAIU).; * `GenerateValueBy` sounds fine in principle since the `GenerateValue` call is called *by* the other instance. I have to admit that I personally do not get this immediately and I have to stop half a second to think about the meaning of the function name.; * `GenerateValueOn` also doesn't work because the value is being generated by the other instance, not on.; * `GenerateValueFrom` personally has a similar meaning to `GenerateValueBy` and is easier to get intuitively.; * The `GenerateValueFrom` naming works for `Generate` but not for `Append`. I.e. I don't like `AppendFrom` since that sounds like we are appending some value *from* the other instance *into* this one; * To me it looks like all these functions are performing a call of the same function name on another instance. Thus, personally I would go with a naming like `CallGenerateValueOn`, `CallAppendOn`, `CallReadOn` etc.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13317#issuecomment-1651710380
Usability,simpl,simply,"@moneta maybe simply `shape.push_back(1);` instead of `shape.insert(shape.end() + 1 + idx, 1);` would do it?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13325#issuecomment-1651741707
Usability,clear,clear,"> Very nice! Initially, I thought that `includeSubFields` means that a matching fields counts with the size of its subtree. Perhaps the true meaning can be made more clear with `searchInSubfields`. Ah, good point! Yes, that sounds like a better name.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13331#issuecomment-1655666693
Safety,avoid,avoid,Thanks for all the feedback. A more comprehensive solution to avoid spurious lookups triggered by TClass::GetClass will be proposed.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13341#issuecomment-1862225290
Usability,feedback,feedback,Thanks for all the feedback. A more comprehensive solution to avoid spurious lookups triggered by TClass::GetClass will be proposed.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13341#issuecomment-1862225290
Usability,simpl,simply,"Well, I don't think it's a GUI issue at all, but more a design issue. Why not simply organize your histograms in directories (`TDirectory`)?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13352#issuecomment-1657939361
Usability,simpl,simple,"I should have been more specific mentioning TH1D maybe. ; - The x axis usually has time information. ; - Bin content are be filled with these Re/Im/Ph/Mag. I would like to get an outgoing object without such directory structure because this would spread many histograms inside my root file structure and I want to keep my object simple. Using such structure would make the retrieval from TFile a way more complex than just reading a TKey. Combining Re/Im would not help quickly visualizing. From TBrowser, I can usually open my class structure and find fName or string entries inside but this time I would like to find TH1. I think TTree is providing such feature as vector are usually represented as TH1.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13352#issuecomment-1661250419
Deployability,patch,patch,"> Awesome, @AniqJaved - thanks a lot for all your work!; > ; > * Could you please reduce the number of commits to something like 5 max? I'm happy to. show you how to rewrite the commit history.; > ; > * `.github/workflows/root-ci-config/__pycache__/build_utils.cpython-39.pyc`, `patch.txt`, and `.github/workflows/root-ci-config/test_file.py` won't be needed in the repo, please don't add them.; > ; > * `.github/workflows/test-coverage.yml` needs only one platform iiuc? Why does it have e.g. `build-macos`?; > ; > ; > I will have a closer look at the code after we chat tomorrow :-). Thank you for your help along the way @Axel-Naumann  ,; I have made the proposed changes relating to the files, but I am not sure how to decrease the number of commits, would love to have your guidance on that.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13394#issuecomment-1665533318
Energy Efficiency,reduce,reduce,"> Awesome, @AniqJaved - thanks a lot for all your work!; > ; > * Could you please reduce the number of commits to something like 5 max? I'm happy to. show you how to rewrite the commit history.; > ; > * `.github/workflows/root-ci-config/__pycache__/build_utils.cpython-39.pyc`, `patch.txt`, and `.github/workflows/root-ci-config/test_file.py` won't be needed in the repo, please don't add them.; > ; > * `.github/workflows/test-coverage.yml` needs only one platform iiuc? Why does it have e.g. `build-macos`?; > ; > ; > I will have a closer look at the code after we chat tomorrow :-). Thank you for your help along the way @Axel-Naumann  ,; I have made the proposed changes relating to the files, but I am not sure how to decrease the number of commits, would love to have your guidance on that.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13394#issuecomment-1665533318
Modifiability,rewrite,rewrite,"> Awesome, @AniqJaved - thanks a lot for all your work!; > ; > * Could you please reduce the number of commits to something like 5 max? I'm happy to. show you how to rewrite the commit history.; > ; > * `.github/workflows/root-ci-config/__pycache__/build_utils.cpython-39.pyc`, `patch.txt`, and `.github/workflows/root-ci-config/test_file.py` won't be needed in the repo, please don't add them.; > ; > * `.github/workflows/test-coverage.yml` needs only one platform iiuc? Why does it have e.g. `build-macos`?; > ; > ; > I will have a closer look at the code after we chat tomorrow :-). Thank you for your help along the way @Axel-Naumann  ,; I have made the proposed changes relating to the files, but I am not sure how to decrease the number of commits, would love to have your guidance on that.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13394#issuecomment-1665533318
Testability,test,test-coverage,"> Awesome, @AniqJaved - thanks a lot for all your work!; > ; > * Could you please reduce the number of commits to something like 5 max? I'm happy to. show you how to rewrite the commit history.; > ; > * `.github/workflows/root-ci-config/__pycache__/build_utils.cpython-39.pyc`, `patch.txt`, and `.github/workflows/root-ci-config/test_file.py` won't be needed in the repo, please don't add them.; > ; > * `.github/workflows/test-coverage.yml` needs only one platform iiuc? Why does it have e.g. `build-macos`?; > ; > ; > I will have a closer look at the code after we chat tomorrow :-). Thank you for your help along the way @Axel-Naumann  ,; I have made the proposed changes relating to the files, but I am not sure how to decrease the number of commits, would love to have your guidance on that.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13394#issuecomment-1665533318
Usability,guid,guidance,"> Awesome, @AniqJaved - thanks a lot for all your work!; > ; > * Could you please reduce the number of commits to something like 5 max? I'm happy to. show you how to rewrite the commit history.; > ; > * `.github/workflows/root-ci-config/__pycache__/build_utils.cpython-39.pyc`, `patch.txt`, and `.github/workflows/root-ci-config/test_file.py` won't be needed in the repo, please don't add them.; > ; > * `.github/workflows/test-coverage.yml` needs only one platform iiuc? Why does it have e.g. `build-macos`?; > ; > ; > I will have a closer look at the code after we chat tomorrow :-). Thank you for your help along the way @Axel-Naumann  ,; I have made the proposed changes relating to the files, but I am not sure how to decrease the number of commits, would love to have your guidance on that.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13394#issuecomment-1665533318
Availability,error,error-reference,## [Codecov](https://app.codecov.io/gh/root-project/root/pull/13414?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=root-project) Report; > :exclamation: No coverage uploaded for pull request base (`master@0d1f204`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=root-project#section-missing-base-commit).; > The diff coverage is `n/a`. > :exclamation: Current head 15e8116 differs from pull request most recent head e2c1183. Consider uploading reports for the commit e2c1183 to get more accurate results. ```diff; @@ Coverage Diff @@; ## master #13414 +/- ##; ==========================================; Coverage ? 23.83% ; ==========================================; Files ? 8507 ; Lines ? 1719518 ; Branches ? 717767 ; ==========================================; Hits ? 409914 ; Misses ? 1083067 ; Partials ? 226537 ; ```. | Flag | Coverage  | |; |---|---|---|; | unittests | `23.83% <0.00%> (?)` | |. Flags with carried forward coverage won't be shown. [Click here](https://docs.codecov.io/docs/carryforward-flags?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=root-project#carryforward-flags-in-the-pull-request-comment) to find out more.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13414#issuecomment-1672056213
Usability,learn,learn,## [Codecov](https://app.codecov.io/gh/root-project/root/pull/13414?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=root-project) Report; > :exclamation: No coverage uploaded for pull request base (`master@0d1f204`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=root-project#section-missing-base-commit).; > The diff coverage is `n/a`. > :exclamation: Current head 15e8116 differs from pull request most recent head e2c1183. Consider uploading reports for the commit e2c1183 to get more accurate results. ```diff; @@ Coverage Diff @@; ## master #13414 +/- ##; ==========================================; Coverage ? 23.83% ; ==========================================; Files ? 8507 ; Lines ? 1719518 ; Branches ? 717767 ; ==========================================; Hits ? 409914 ; Misses ? 1083067 ; Partials ? 226537 ; ```. | Flag | Coverage  | |; |---|---|---|; | unittests | `23.83% <0.00%> (?)` | |. Flags with carried forward coverage won't be shown. [Click here](https://docs.codecov.io/docs/carryforward-flags?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=root-project#carryforward-flags-in-the-pull-request-comment) to find out more.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13414#issuecomment-1672056213
Availability,error,error,"Hi Olivier,. I had a similar situation with a Fermilab server and requested computing support to install missing libraries. I do not have a CERN account so can't open a ticket for lxplus9, but it makes sense to install the libraries there to make the machine usable with ROOT. Andrei. ________________________________________; From: Olivier Couet ***@***.***>; Sent: Tuesday, August 15, 2023 9:27 AM; To: root-project/root; Cc: Andrei Gaponenko; Author; Subject: Re: [root-project/root] clip edit in GL viewer is still broken (Issue #13418). Gl does not seem properly installed there:. $ glxgears; libGL error: No matching fbConfigs or visuals found; libGL error: failed to load driver: swrast; Error: glXCreateContext failed. ; Reply to this email directly, view it on GitHub<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_root-2Dproject_root_issues_13418-23issuecomment-2D1679025586&d=DwMCaQ&c=gRgGjJ3BkIsb5y6s49QqsA&r=O47fc5vzDTR2V_gla4Ub0Q&m=pYI_UukDspkvToM08be43rqW1Ini373CaTW7YzYzXvzaAbgFN1hfOxDILOY5LkIt&s=ejeOXHRM6NnnTa4TA470cGD4wj63fFxBITffmOQ02lc&e=>, or unsubscribe<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_notifications_unsubscribe-2Dauth_AAXVCGSO4HWIKORE7ZRV24LXVOBONANCNFSM6AAAAAA3I665NU&d=DwMCaQ&c=gRgGjJ3BkIsb5y6s49QqsA&r=O47fc5vzDTR2V_gla4Ub0Q&m=pYI_UukDspkvToM08be43rqW1Ini373CaTW7YzYzXvzaAbgFN1hfOxDILOY5LkIt&s=Qa0IvEvjeyrinJUtkFkmyfcNPybfsSDQQI7cpx17nBw&e=>.; You are receiving this because you authored the thread.Message ID: ***@***.***>",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13418#issuecomment-1679169141
Deployability,install,install,"Hi Olivier,. I had a similar situation with a Fermilab server and requested computing support to install missing libraries. I do not have a CERN account so can't open a ticket for lxplus9, but it makes sense to install the libraries there to make the machine usable with ROOT. Andrei. ________________________________________; From: Olivier Couet ***@***.***>; Sent: Tuesday, August 15, 2023 9:27 AM; To: root-project/root; Cc: Andrei Gaponenko; Author; Subject: Re: [root-project/root] clip edit in GL viewer is still broken (Issue #13418). Gl does not seem properly installed there:. $ glxgears; libGL error: No matching fbConfigs or visuals found; libGL error: failed to load driver: swrast; Error: glXCreateContext failed. ; Reply to this email directly, view it on GitHub<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_root-2Dproject_root_issues_13418-23issuecomment-2D1679025586&d=DwMCaQ&c=gRgGjJ3BkIsb5y6s49QqsA&r=O47fc5vzDTR2V_gla4Ub0Q&m=pYI_UukDspkvToM08be43rqW1Ini373CaTW7YzYzXvzaAbgFN1hfOxDILOY5LkIt&s=ejeOXHRM6NnnTa4TA470cGD4wj63fFxBITffmOQ02lc&e=>, or unsubscribe<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_notifications_unsubscribe-2Dauth_AAXVCGSO4HWIKORE7ZRV24LXVOBONANCNFSM6AAAAAA3I665NU&d=DwMCaQ&c=gRgGjJ3BkIsb5y6s49QqsA&r=O47fc5vzDTR2V_gla4Ub0Q&m=pYI_UukDspkvToM08be43rqW1Ini373CaTW7YzYzXvzaAbgFN1hfOxDILOY5LkIt&s=Qa0IvEvjeyrinJUtkFkmyfcNPybfsSDQQI7cpx17nBw&e=>.; You are receiving this because you authored the thread.Message ID: ***@***.***>",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13418#issuecomment-1679169141
Performance,load,load,"Hi Olivier,. I had a similar situation with a Fermilab server and requested computing support to install missing libraries. I do not have a CERN account so can't open a ticket for lxplus9, but it makes sense to install the libraries there to make the machine usable with ROOT. Andrei. ________________________________________; From: Olivier Couet ***@***.***>; Sent: Tuesday, August 15, 2023 9:27 AM; To: root-project/root; Cc: Andrei Gaponenko; Author; Subject: Re: [root-project/root] clip edit in GL viewer is still broken (Issue #13418). Gl does not seem properly installed there:. $ glxgears; libGL error: No matching fbConfigs or visuals found; libGL error: failed to load driver: swrast; Error: glXCreateContext failed. ; Reply to this email directly, view it on GitHub<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_root-2Dproject_root_issues_13418-23issuecomment-2D1679025586&d=DwMCaQ&c=gRgGjJ3BkIsb5y6s49QqsA&r=O47fc5vzDTR2V_gla4Ub0Q&m=pYI_UukDspkvToM08be43rqW1Ini373CaTW7YzYzXvzaAbgFN1hfOxDILOY5LkIt&s=ejeOXHRM6NnnTa4TA470cGD4wj63fFxBITffmOQ02lc&e=>, or unsubscribe<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_notifications_unsubscribe-2Dauth_AAXVCGSO4HWIKORE7ZRV24LXVOBONANCNFSM6AAAAAA3I665NU&d=DwMCaQ&c=gRgGjJ3BkIsb5y6s49QqsA&r=O47fc5vzDTR2V_gla4Ub0Q&m=pYI_UukDspkvToM08be43rqW1Ini373CaTW7YzYzXvzaAbgFN1hfOxDILOY5LkIt&s=Qa0IvEvjeyrinJUtkFkmyfcNPybfsSDQQI7cpx17nBw&e=>.; You are receiving this because you authored the thread.Message ID: ***@***.***>",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13418#issuecomment-1679169141
Usability,usab,usable,"Hi Olivier,. I had a similar situation with a Fermilab server and requested computing support to install missing libraries. I do not have a CERN account so can't open a ticket for lxplus9, but it makes sense to install the libraries there to make the machine usable with ROOT. Andrei. ________________________________________; From: Olivier Couet ***@***.***>; Sent: Tuesday, August 15, 2023 9:27 AM; To: root-project/root; Cc: Andrei Gaponenko; Author; Subject: Re: [root-project/root] clip edit in GL viewer is still broken (Issue #13418). Gl does not seem properly installed there:. $ glxgears; libGL error: No matching fbConfigs or visuals found; libGL error: failed to load driver: swrast; Error: glXCreateContext failed. ; Reply to this email directly, view it on GitHub<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_root-2Dproject_root_issues_13418-23issuecomment-2D1679025586&d=DwMCaQ&c=gRgGjJ3BkIsb5y6s49QqsA&r=O47fc5vzDTR2V_gla4Ub0Q&m=pYI_UukDspkvToM08be43rqW1Ini373CaTW7YzYzXvzaAbgFN1hfOxDILOY5LkIt&s=ejeOXHRM6NnnTa4TA470cGD4wj63fFxBITffmOQ02lc&e=>, or unsubscribe<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_notifications_unsubscribe-2Dauth_AAXVCGSO4HWIKORE7ZRV24LXVOBONANCNFSM6AAAAAA3I665NU&d=DwMCaQ&c=gRgGjJ3BkIsb5y6s49QqsA&r=O47fc5vzDTR2V_gla4Ub0Q&m=pYI_UukDspkvToM08be43rqW1Ini373CaTW7YzYzXvzaAbgFN1hfOxDILOY5LkIt&s=Qa0IvEvjeyrinJUtkFkmyfcNPybfsSDQQI7cpx17nBw&e=>.; You are receiving this because you authored the thread.Message ID: ***@***.***>",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13418#issuecomment-1679169141
Availability,error,error-reference,## [Codecov](https://app.codecov.io/gh/root-project/root/pull/13430?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=root-project) Report; > :exclamation: No coverage uploaded for pull request base (`master@6276954`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=root-project#section-missing-base-commit).; > The diff coverage is `n/a`. > :exclamation: Current head 85ba098 differs from pull request most recent head 6c6f6da. Consider uploading reports for the commit 6c6f6da to get more accurate results. ```diff; @@ Coverage Diff @@; ## master #13430 +/- ##; ==========================================; Coverage ? 23.80% ; ==========================================; Files ? 8507 ; Lines ? 1719515 ; Branches ? 717824 ; ==========================================; Hits ? 409380 ; Misses ? 1083984 ; Partials ? 226151 ; ```. | Flag | Coverage  | |; |---|---|---|; | unittests | `23.80% <0.00%> (?)` | |. Flags with carried forward coverage won't be shown. [Click here](https://docs.codecov.io/docs/carryforward-flags?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=root-project#carryforward-flags-in-the-pull-request-comment) to find out more.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13430#issuecomment-1678240847
Usability,learn,learn,## [Codecov](https://app.codecov.io/gh/root-project/root/pull/13430?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=root-project) Report; > :exclamation: No coverage uploaded for pull request base (`master@6276954`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=root-project#section-missing-base-commit).; > The diff coverage is `n/a`. > :exclamation: Current head 85ba098 differs from pull request most recent head 6c6f6da. Consider uploading reports for the commit 6c6f6da to get more accurate results. ```diff; @@ Coverage Diff @@; ## master #13430 +/- ##; ==========================================; Coverage ? 23.80% ; ==========================================; Files ? 8507 ; Lines ? 1719515 ; Branches ? 717824 ; ==========================================; Hits ? 409380 ; Misses ? 1083984 ; Partials ? 226151 ; ```. | Flag | Coverage  | |; |---|---|---|; | unittests | `23.80% <0.00%> (?)` | |. Flags with carried forward coverage won't be shown. [Click here](https://docs.codecov.io/docs/carryforward-flags?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=root-project#carryforward-flags-in-the-pull-request-comment) to find out more.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13430#issuecomment-1678240847
Availability,error,error-reference,## [Codecov](https://app.codecov.io/gh/root-project/root/pull/13466?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=root-project) Report; > :exclamation: No coverage uploaded for pull request base (`master@4f0450b`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=root-project#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #13466 +/- ##; ==========================================; Coverage ? 23.84% ; ==========================================; Files ? 8508 ; Lines ? 1719789 ; Branches ? 717998 ; ==========================================; Hits ? 410002 ; Misses ? 1083133 ; Partials ? 226654 ; ```. | [Flag](https://app.codecov.io/gh/root-project/root/pull/13466/flags?src=pr&el=flags&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=root-project) | Coverage  | |; |---|---|---|; | [unittests](https://app.codecov.io/gh/root-project/root/pull/13466/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=root-project) | `23.84% <0.00%> (?)` | |. Flags with carried forward coverage won't be shown. [Click here](https://docs.codecov.io/docs/carryforward-flags?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=root-project#carryforward-flags-in-the-pull-request-comment) to find out more.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13466#issuecomment-1681134447
Usability,learn,learn,## [Codecov](https://app.codecov.io/gh/root-project/root/pull/13466?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=root-project) Report; > :exclamation: No coverage uploaded for pull request base (`master@4f0450b`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=root-project#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #13466 +/- ##; ==========================================; Coverage ? 23.84% ; ==========================================; Files ? 8508 ; Lines ? 1719789 ; Branches ? 717998 ; ==========================================; Hits ? 410002 ; Misses ? 1083133 ; Partials ? 226654 ; ```. | [Flag](https://app.codecov.io/gh/root-project/root/pull/13466/flags?src=pr&el=flags&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=root-project) | Coverage  | |; |---|---|---|; | [unittests](https://app.codecov.io/gh/root-project/root/pull/13466/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=root-project) | `23.84% <0.00%> (?)` | |. Flags with carried forward coverage won't be shown. [Click here](https://docs.codecov.io/docs/carryforward-flags?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=root-project#carryforward-flags-in-the-pull-request-comment) to find out more.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13466#issuecomment-1681134447
Availability,error,error-reference,## [Codecov](https://app.codecov.io/gh/root-project/root/pull/13478?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=root-project) Report; > :exclamation: No coverage uploaded for pull request base (`master@ebe4f59`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=root-project#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #13478 +/- ##; ==========================================; Coverage ? 23.80% ; ==========================================; Files ? 8508 ; Lines ? 1719800 ; Branches ? 718008 ; ==========================================; Hits ? 409426 ; Misses ? 1083951 ; Partials ? 226423 ; ```. | [Flag](https://app.codecov.io/gh/root-project/root/pull/13478/flags?src=pr&el=flags&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=root-project) | Coverage  | |; |---|---|---|; | [unittests](https://app.codecov.io/gh/root-project/root/pull/13478/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=root-project) | `23.80% <0.00%> (?)` | |. Flags with carried forward coverage won't be shown. [Click here](https://docs.codecov.io/docs/carryforward-flags?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=root-project#carryforward-flags-in-the-pull-request-comment) to find out more.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13478#issuecomment-1685023865
Usability,learn,learn,## [Codecov](https://app.codecov.io/gh/root-project/root/pull/13478?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=root-project) Report; > :exclamation: No coverage uploaded for pull request base (`master@ebe4f59`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=root-project#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #13478 +/- ##; ==========================================; Coverage ? 23.80% ; ==========================================; Files ? 8508 ; Lines ? 1719800 ; Branches ? 718008 ; ==========================================; Hits ? 409426 ; Misses ? 1083951 ; Partials ? 226423 ; ```. | [Flag](https://app.codecov.io/gh/root-project/root/pull/13478/flags?src=pr&el=flags&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=root-project) | Coverage  | |; |---|---|---|; | [unittests](https://app.codecov.io/gh/root-project/root/pull/13478/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=root-project) | `23.80% <0.00%> (?)` | |. Flags with carried forward coverage won't be shown. [Click here](https://docs.codecov.io/docs/carryforward-flags?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=root-project#carryforward-flags-in-the-pull-request-comment) to find out more.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13478#issuecomment-1685023865
Usability,simpl,simple,There is very simple fix to make `TNetXNGFile::Close()` reentrant.; See PR: https://github.com/root-project/root/pull/13559,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13503#issuecomment-1697016701
Usability,simpl,simple,Here is macro which reproduces the problem with simple histogram/latex drawing. [dupl.cxx.txt](https://github.com/root-project/root/files/12418698/dupl.cxx.txt). Important that canvas should be stored/restored from I/O.; Only in such case `ROOT::Detail::HasBeenDeleted` fails,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13506#issuecomment-1689807535
Usability,undo,undo,I noticed that the code you upload contains:; ```; gROOT->Reset();; ```; This call is only valid when used in an unnamed macro. In all other scenario it has the potential of being harmful (undo/reset too many things). Please try again after removing those lines.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13511#issuecomment-1696533640
Availability,reliab,reliably,"s as described by the C++ standard. At the moment you start using C++ 20 you could use the `import`/`export` constructs and you will be able to use that feature for encapsulation purposes. There is not enough project transitions which are bigger than toy examples. One of the challenges is how we discover module dependencies. That is, we need extra tooling to decide how to split the source files into modules. In practice we need to pre-lex all of the content before the build system can start processing project files. The community is discussing scanners (such as clang scan-deps), daemons (the gcc implementation), protocols, etc. There is increasing amount of papers trying to address how we put C++ modules at scale (https://wg21.link/p2656, https://wg21.link/P2409, https://youtu.be/_LGR0U5Opdg?si=AbLazREvyl5PXVFG). Some papers/talks are more radical claiming that we cannot even roll out modules (as written in the standard) at such scale. . For modules to be useful and work reliably we know that we need to apply modularization bottom up. That means that before modularizing cmssw/art we need everything below starting from libc and libxml to become modular. That's something we observed during our modularization efforts in cmssw (see https://github.com/cms-sw/cmssw/issues/15248). The reasons we cannot make it yet default is discussed here: https://github.com/cms-sw/cmssw/issues/41810#issuecomment-1578982627 and here https://github.com/root-project/root/pull/13000 Not surprisingly we have observed similar comments coming from modularization efforts in gcc and msvc. . Let's assume we live in an platonic world where all of the above is resolved. It still seems we will be able to use our dictionary system as it is because we will in the end have a build system that processes textual files to build them. There we could use any custom flavor of modules (or something better) that makes our I/O work. We can go one step further and claim that, even if we introduce strict interface ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13536#issuecomment-1693395998
Energy Efficiency,green,greenc-FNAL,"Hi @greenc-FNAL,. Thanks for this request. I will try to reply inline directly to some of the concerns and try to give some public-friendly outline the bigger picture as I see it. > Generated module files are compiler-specific, which would seem likely to lead to issues with interactions between Cling-generated PCM dictionaries and any C++20 modules used by the code upon which those dictionaries depend. I am not sure if that is the case at least for the next 10 years. I see this can be an issue if we start shipping module files (`bmi`s or equivalent) instead of header files. However, in practice that won't be the case in near future because the compiler vendors cannot agree on a common file format and make it standard. Until then, there will be always some sort of a textual header file which can be processed with our clang-based rootcling and build a pcm file as basis for our dictionaries. . > My request is for the upcoming ROOT with Clang 16 to be able to accommodate the generation and use of PCM dictionaries where dependencies thereof are or use C++20 modules. Clang has at least 5 different ""flavors"" of modules. One of them is the C++20 modules as described by the C++ standard. At the moment you start using C++ 20 you could use the `import`/`export` constructs and you will be able to use that feature for encapsulation purposes. There is not enough project transitions which are bigger than toy examples. One of the challenges is how we discover module dependencies. That is, we need extra tooling to decide how to split the source files into modules. In practice we need to pre-lex all of the content before the build system can start processing project files. The community is discussing scanners (such as clang scan-deps), daemons (the gcc implementation), protocols, etc. There is increasing amount of papers trying to address how we put C++ modules at scale (https://wg21.link/p2656, https://wg21.link/P2409, https://youtu.be/_LGR0U5Opdg?si=AbLazREvyl5PXVFG). Some papers/ta",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13536#issuecomment-1693395998
Integrability,depend,depend,"Hi @greenc-FNAL,. Thanks for this request. I will try to reply inline directly to some of the concerns and try to give some public-friendly outline the bigger picture as I see it. > Generated module files are compiler-specific, which would seem likely to lead to issues with interactions between Cling-generated PCM dictionaries and any C++20 modules used by the code upon which those dictionaries depend. I am not sure if that is the case at least for the next 10 years. I see this can be an issue if we start shipping module files (`bmi`s or equivalent) instead of header files. However, in practice that won't be the case in near future because the compiler vendors cannot agree on a common file format and make it standard. Until then, there will be always some sort of a textual header file which can be processed with our clang-based rootcling and build a pcm file as basis for our dictionaries. . > My request is for the upcoming ROOT with Clang 16 to be able to accommodate the generation and use of PCM dictionaries where dependencies thereof are or use C++20 modules. Clang has at least 5 different ""flavors"" of modules. One of them is the C++20 modules as described by the C++ standard. At the moment you start using C++ 20 you could use the `import`/`export` constructs and you will be able to use that feature for encapsulation purposes. There is not enough project transitions which are bigger than toy examples. One of the challenges is how we discover module dependencies. That is, we need extra tooling to decide how to split the source files into modules. In practice we need to pre-lex all of the content before the build system can start processing project files. The community is discussing scanners (such as clang scan-deps), daemons (the gcc implementation), protocols, etc. There is increasing amount of papers trying to address how we put C++ modules at scale (https://wg21.link/p2656, https://wg21.link/P2409, https://youtu.be/_LGR0U5Opdg?si=AbLazREvyl5PXVFG). Some papers/ta",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13536#issuecomment-1693395998
Modifiability,adapt,adapt,"rotocols, etc. There is increasing amount of papers trying to address how we put C++ modules at scale (https://wg21.link/p2656, https://wg21.link/P2409, https://youtu.be/_LGR0U5Opdg?si=AbLazREvyl5PXVFG). Some papers/talks are more radical claiming that we cannot even roll out modules (as written in the standard) at such scale. . For modules to be useful and work reliably we know that we need to apply modularization bottom up. That means that before modularizing cmssw/art we need everything below starting from libc and libxml to become modular. That's something we observed during our modularization efforts in cmssw (see https://github.com/cms-sw/cmssw/issues/15248). The reasons we cannot make it yet default is discussed here: https://github.com/cms-sw/cmssw/issues/41810#issuecomment-1578982627 and here https://github.com/root-project/root/pull/13000 Not surprisingly we have observed similar comments coming from modularization efforts in gcc and msvc. . Let's assume we live in an platonic world where all of the above is resolved. It still seems we will be able to use our dictionary system as it is because we will in the end have a build system that processes textual files to build them. There we could use any custom flavor of modules (or something better) that makes our I/O work. We can go one step further and claim that, even if we introduce strict interface encapsulation via C++ 20 modules, our I/O system would require to know more about the non-exported entities so that we can serialize and deserialize the private dependencies of the exported entities. That is, we will probably end up with a very similar system that we have today. I would personally like to tackle the engineering challenge as you have described. However I believe we are not there yet and any efforts into trying to adapt to a still volatile area would probably cause disturbances in our user base for not yet clear final goal. Does that address/answer the concerns you had when you opened that request?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13536#issuecomment-1693395998
Usability,clear,clear,"rotocols, etc. There is increasing amount of papers trying to address how we put C++ modules at scale (https://wg21.link/p2656, https://wg21.link/P2409, https://youtu.be/_LGR0U5Opdg?si=AbLazREvyl5PXVFG). Some papers/talks are more radical claiming that we cannot even roll out modules (as written in the standard) at such scale. . For modules to be useful and work reliably we know that we need to apply modularization bottom up. That means that before modularizing cmssw/art we need everything below starting from libc and libxml to become modular. That's something we observed during our modularization efforts in cmssw (see https://github.com/cms-sw/cmssw/issues/15248). The reasons we cannot make it yet default is discussed here: https://github.com/cms-sw/cmssw/issues/41810#issuecomment-1578982627 and here https://github.com/root-project/root/pull/13000 Not surprisingly we have observed similar comments coming from modularization efforts in gcc and msvc. . Let's assume we live in an platonic world where all of the above is resolved. It still seems we will be able to use our dictionary system as it is because we will in the end have a build system that processes textual files to build them. There we could use any custom flavor of modules (or something better) that makes our I/O work. We can go one step further and claim that, even if we introduce strict interface encapsulation via C++ 20 modules, our I/O system would require to know more about the non-exported entities so that we can serialize and deserialize the private dependencies of the exported entities. That is, we will probably end up with a very similar system that we have today. I would personally like to tackle the engineering challenge as you have described. However I believe we are not there yet and any efforts into trying to adapt to a still volatile area would probably cause disturbances in our user base for not yet clear final goal. Does that address/answer the concerns you had when you opened that request?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13536#issuecomment-1693395998
Integrability,message,message,"> I am not sure that we should increment the number of fNRuns and log as if everything went fine if an exception was thrown during the event loop. a different message might be warranted. Indeed this could be a good idea, to further clarify that the RDF is not usable anymore and should just be thrown away",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13546#issuecomment-1707966075
Testability,log,log,"> I am not sure that we should increment the number of fNRuns and log as if everything went fine if an exception was thrown during the event loop. a different message might be warranted. Indeed this could be a good idea, to further clarify that the RDF is not usable anymore and should just be thrown away",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13546#issuecomment-1707966075
Usability,usab,usable,"> I am not sure that we should increment the number of fNRuns and log as if everything went fine if an exception was thrown during the event loop. a different message might be warranted. Indeed this could be a good idea, to further clarify that the RDF is not usable anymore and should just be thrown away",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13546#issuecomment-1707966075
Usability,usab,usable,"> Not exactly the same. Sorry, I meant it's the same in the context that I mentioned: the computation graph is left in a state that at least I do not completely understand and I cannot guarantee is fully usable.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13546#issuecomment-1707994347
Deployability,update,updated,I have updated the root-spi repo for the old (Jenkins) CI to learn about this new module and know that it should be built everywhere.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13571#issuecomment-1705212121
Usability,learn,learn,I have updated the root-spi repo for the old (Jenkins) CI to learn about this new module and know that it should be built everywhere.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13571#issuecomment-1705212121
Testability,test,tests,"Build failed on ROOT-ubuntu2004/python3.; Running on root-ubuntu-2004-1.cern.ch:/home/sftnight/build/workspace/root-pullrequests-build; [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/183764/console).; ### Warnings:; - [2023-08-31T18:23:40.513Z] include/tbb/concurrent_hash_map.h:124:51: warning: void* memset(void*, int, size_t) clearing an object of type class tbb::interface5::internal::hash_map_base with no trivial copy-assignment; use value-initialization instead [-Wclass-memaccess] ; - [2023-08-31T18:29:46.289Z] include/tbb/concurrent_hash_map.h:124:51: warning: void* memset(void*, int, size_t) clearing an object of type class tbb::interface5::internal::hash_map_base with no trivial copy-assignment; use value-initialization instead [-Wclass-memaccess] . ### Failing tests:; - [projectroot.roottest.python.basic.roottest_python_basic_datatype](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/183764/testReport/projectroot.roottest.python/basic/roottest_python_basic_datatype/); - [projectroot.roottest.python.basic.roottest_python_basic_basic](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/183764/testReport/projectroot.roottest.python/basic/roottest_python_basic_basic/); - [projectroot.roottest.python.basic.roottest_python_basic_overload](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/183764/testReport/projectroot.roottest.python/basic/roottest_python_basic_overload/); - [projectroot.roottest.python.pythonizations.roottest_python_pythonizations_pythonizations](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/183764/testReport/projectroot.roottest.python/pythonizations/roottest_python_pythonizations_pythonizations/); - [projectroot.roottest.python.pythonizations.roottest_python_pythonizations_smartptr](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/183764/testReport/projectroot.roottest.python/",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13577#issuecomment-1701582600
Usability,clear,clearing,"Build failed on ROOT-ubuntu2004/python3.; Running on root-ubuntu-2004-1.cern.ch:/home/sftnight/build/workspace/root-pullrequests-build; [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/183764/console).; ### Warnings:; - [2023-08-31T18:23:40.513Z] include/tbb/concurrent_hash_map.h:124:51: warning: void* memset(void*, int, size_t) clearing an object of type class tbb::interface5::internal::hash_map_base with no trivial copy-assignment; use value-initialization instead [-Wclass-memaccess] ; - [2023-08-31T18:29:46.289Z] include/tbb/concurrent_hash_map.h:124:51: warning: void* memset(void*, int, size_t) clearing an object of type class tbb::interface5::internal::hash_map_base with no trivial copy-assignment; use value-initialization instead [-Wclass-memaccess] . ### Failing tests:; - [projectroot.roottest.python.basic.roottest_python_basic_datatype](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/183764/testReport/projectroot.roottest.python/basic/roottest_python_basic_datatype/); - [projectroot.roottest.python.basic.roottest_python_basic_basic](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/183764/testReport/projectroot.roottest.python/basic/roottest_python_basic_basic/); - [projectroot.roottest.python.basic.roottest_python_basic_overload](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/183764/testReport/projectroot.roottest.python/basic/roottest_python_basic_overload/); - [projectroot.roottest.python.pythonizations.roottest_python_pythonizations_pythonizations](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/183764/testReport/projectroot.roottest.python/pythonizations/roottest_python_pythonizations_pythonizations/); - [projectroot.roottest.python.pythonizations.roottest_python_pythonizations_smartptr](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/183764/testReport/projectroot.roottest.python/",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13577#issuecomment-1701582600
Usability,simpl,simply,This PR needs to have its history rewritten - possible simply squashing all commits.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13596#issuecomment-1705308623
Deployability,release,release,"Glad if this helped someone.; However, I don't understand how users are supposed to learn about this feature (without googling).; There is nothing in the release notes on that. ; https://root.cern/doc/v630/release-notes.html",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13606#issuecomment-2104829522
Usability,learn,learn,"Glad if this helped someone.; However, I don't understand how users are supposed to learn about this feature (without googling).; There is nothing in the release notes on that. ; https://root.cern/doc/v630/release-notes.html",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13606#issuecomment-2104829522
Deployability,update,update,"> > and- in its current implementation - a working ROOT build as part of the version update. > Why is/was that?. Ouch that's wrong, that was true in the past, before I had replaced the ROOT script writing out the version number with a Python script. But the motivation for this PR is still there: instead of running a magic build step to update the version files we can now simply edit the header file.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13620#issuecomment-1713698917
Usability,simpl,simply,"> > and- in its current implementation - a working ROOT build as part of the version update. > Why is/was that?. Ouch that's wrong, that was true in the past, before I had replaced the ROOT script writing out the version number with a Python script. But the motivation for this PR is still there: instead of running a magic build step to update the version files we can now simply edit the header file.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13620#issuecomment-1713698917
Deployability,patch,patches,"Thank you for your reminders, I will for sure follow the procedure once I am convinced this works fine for all ALICE usecases. Having a PR on the v6-28-00-patches branch merely simplifies sharing something which can be immediately used in the ALICE software stack. Could you please advise regarding the data structure to use? I could not find one that fits the needed sparseness.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13641#issuecomment-1719035285
Usability,simpl,simplifies,"Thank you for your reminders, I will for sure follow the procedure once I am convinced this works fine for all ALICE usecases. Having a PR on the v6-28-00-patches branch merely simplifies sharing something which can be immediately used in the ALICE software stack. Could you please advise regarding the data structure to use? I could not find one that fits the needed sparseness.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13641#issuecomment-1719035285
Deployability,patch,patches,"> Thank you for your reminders, I will for sure follow the procedure once I am convinced this works fine for all ALICE usecases. Having a PR on the v6-28-00-patches branch merely simplifies sharing something which can be immediately used in the ALICE software stack. Yes understood :). > Could you please advise regarding the data structure to use? I could not find one that fits the needed sparseness. I'm not sure there is one already, but it has some comments to make about `std::vector` (because I saw you mentioning `std::pmr::vector`. If there is none yet (but I think Vassil mentioned one? maybe it's not listed in that document), it should likely be added to LLVM's ADT library first and then used in Clang. > On a separate note, are the tests supposed to be green?. Yes, and from a quick look it seems ~all builds are failing with; ```; Assertion `Index < TypesLoaded.size() && ""Type index out-of-range""' failed.; ```; which very much sounds like it is caused by the changes...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13641#issuecomment-1719042201
Energy Efficiency,green,green,"> Thank you for your reminders, I will for sure follow the procedure once I am convinced this works fine for all ALICE usecases. Having a PR on the v6-28-00-patches branch merely simplifies sharing something which can be immediately used in the ALICE software stack. Yes understood :). > Could you please advise regarding the data structure to use? I could not find one that fits the needed sparseness. I'm not sure there is one already, but it has some comments to make about `std::vector` (because I saw you mentioning `std::pmr::vector`. If there is none yet (but I think Vassil mentioned one? maybe it's not listed in that document), it should likely be added to LLVM's ADT library first and then used in Clang. > On a separate note, are the tests supposed to be green?. Yes, and from a quick look it seems ~all builds are failing with; ```; Assertion `Index < TypesLoaded.size() && ""Type index out-of-range""' failed.; ```; which very much sounds like it is caused by the changes...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13641#issuecomment-1719042201
Testability,test,tests,"> Thank you for your reminders, I will for sure follow the procedure once I am convinced this works fine for all ALICE usecases. Having a PR on the v6-28-00-patches branch merely simplifies sharing something which can be immediately used in the ALICE software stack. Yes understood :). > Could you please advise regarding the data structure to use? I could not find one that fits the needed sparseness. I'm not sure there is one already, but it has some comments to make about `std::vector` (because I saw you mentioning `std::pmr::vector`. If there is none yet (but I think Vassil mentioned one? maybe it's not listed in that document), it should likely be added to LLVM's ADT library first and then used in Clang. > On a separate note, are the tests supposed to be green?. Yes, and from a quick look it seems ~all builds are failing with; ```; Assertion `Index < TypesLoaded.size() && ""Type index out-of-range""' failed.; ```; which very much sounds like it is caused by the changes...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13641#issuecomment-1719042201
Usability,simpl,simplifies,"> Thank you for your reminders, I will for sure follow the procedure once I am convinced this works fine for all ALICE usecases. Having a PR on the v6-28-00-patches branch merely simplifies sharing something which can be immediately used in the ALICE software stack. Yes understood :). > Could you please advise regarding the data structure to use? I could not find one that fits the needed sparseness. I'm not sure there is one already, but it has some comments to make about `std::vector` (because I saw you mentioning `std::pmr::vector`. If there is none yet (but I think Vassil mentioned one? maybe it's not listed in that document), it should likely be added to LLVM's ADT library first and then used in Clang. > On a separate note, are the tests supposed to be green?. Yes, and from a quick look it seems ~all builds are failing with; ```; Assertion `Index < TypesLoaded.size() && ""Type index out-of-range""' failed.; ```; which very much sounds like it is caused by the changes...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13641#issuecomment-1719042201
Energy Efficiency,allocate,allocate,"Ok, I found out what was wrong and fixed it, taking advantage of some suggestion I got in the upstream LLVM review. The issue was missing pointer stability due to the fact the resizing of the backend store could have incurred in copies later than previously expected. The new code uses a BumpPtrAllocator to allocate the pages of items, rather than resizing an std::vector, so it's guaranteed that the elements don't move once they have been allocated (at the cost of the allocated memory not being necessarity contiguous anymore). With such fix, I cannot reproduce the issue anymore when running standalone, with similar memory improvements when running my simple ""open ALICE AOD file"" test.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13641#issuecomment-1723409634
Testability,test,test,"Ok, I found out what was wrong and fixed it, taking advantage of some suggestion I got in the upstream LLVM review. The issue was missing pointer stability due to the fact the resizing of the backend store could have incurred in copies later than previously expected. The new code uses a BumpPtrAllocator to allocate the pages of items, rather than resizing an std::vector, so it's guaranteed that the elements don't move once they have been allocated (at the cost of the allocated memory not being necessarity contiguous anymore). With such fix, I cannot reproduce the issue anymore when running standalone, with similar memory improvements when running my simple ""open ALICE AOD file"" test.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13641#issuecomment-1723409634
Usability,simpl,simple,"Ok, I found out what was wrong and fixed it, taking advantage of some suggestion I got in the upstream LLVM review. The issue was missing pointer stability due to the fact the resizing of the backend store could have incurred in copies later than previously expected. The new code uses a BumpPtrAllocator to allocate the pages of items, rather than resizing an std::vector, so it's guaranteed that the elements don't move once they have been allocated (at the cost of the allocated memory not being necessarity contiguous anymore). With such fix, I cannot reproduce the issue anymore when running standalone, with similar memory improvements when running my simple ""open ALICE AOD file"" test.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13641#issuecomment-1723409634
Availability,error,error,"Dear @xkzl ,. Thank you for your report. From the stack trace you provided (formatted on two lines):; ```; error: static_assert failed due to requirement 'std::is_convertible<void, bool>::value' ; ""filter expression returns a type that is not convertible to bool""; ```. The error seems quite clear to me. You have some function or expression passed to a call to `df.Filter` somewhere that does not respect the filter signature, i.e. it does not return `bool`. Let me know if you find out where this is happening. Otherwise, you can post here the full program you are trying to compile and I can try to help you. Cheers,; Vincenzo",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13656#issuecomment-1722875388
Usability,clear,clear,"Dear @xkzl ,. Thank you for your report. From the stack trace you provided (formatted on two lines):; ```; error: static_assert failed due to requirement 'std::is_convertible<void, bool>::value' ; ""filter expression returns a type that is not convertible to bool""; ```. The error seems quite clear to me. You have some function or expression passed to a call to `df.Filter` somewhere that does not respect the filter signature, i.e. it does not return `bool`. Let me know if you find out where this is happening. Otherwise, you can post here the full program you are trying to compile and I can try to help you. Cheers,; Vincenzo",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13656#issuecomment-1722875388
Usability,simpl,simply,It is already in mathmore. The license is simply not FOSS (read it carefully if you care).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13688#issuecomment-1728406175
Usability,simpl,simply,"> It is already in mathmore. The license is simply not FOSS (read it carefully if you care). Where? The header and source ""seems"" to be saying GPL.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13688#issuecomment-1728435744
Usability,simpl,simplify,"About drawing with two axes. . Web graphics supports drawing of axes on both sides.; Therefore one can simplify drawing just doing:; ```; graph->Draw(""APL"");; graphPerCore->Draw(""PLX+Y+"");; ```. No need for extra transparent pads, no need for axis drawing emulation.; I attach macro and produced output. Also see `graph->GetXaxis()->SetNdivisions(nodes.size());` - as many divisions are required. [scaling_new.C.txt](https://github.com/root-project/root/files/12724374/scaling_new.C.txt); [scaling_new.pdf](https://github.com/root-project/root/files/12724375/scaling_new.pdf)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13707#issuecomment-1734979113
Usability,simpl,simple,"I get the crash also with a simple C macro (extracted from your code) executed at the ROOT prompt. Reading the doc it looks like this functionality is meant to be used interactively from the context menu. Which means you need the graphics to be ready on the canvas. Therefore, to make it work in a ROOT script, you will need a few ""Update()"" to make sure the graphics id ready. Here is the working script:. ```; {; auto *c = new TCanvas(""c4"", """", 720, 1024);; c->Divide(1, 2);. auto f = new TF1(""lin"", ""x"", -10, 10);; c->cd(1);; f->Draw();; gPad->Update();. c->cd(2);; gPad->Update();; f->DrawIntegral();; }; ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13708#issuecomment-1733934184
Usability,simpl,simple,It would be good to have some warning here or extension of the initial use case.; I am mainly running compiled root in these days.. Is there any specific reasons why it is only meant to be used in interactive in the first place while the fix looks so simple ?. @couet,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13708#issuecomment-1734508407
Usability,simpl,simpler,[The way it is implemented](https://root.cern.ch/doc/master/TF1_8cxx_source.html#l01408) makes it mandatory to have an active pad with the TF1 drawn in it. That's why you need to add these `gPad->Update()` if you really want to use this function (see my first example). My second reply does exactly the same thing as DrawIntegral without the `GetSelectedPad()`. That's the simpler/better way when you run compiled ROOT like you.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13708#issuecomment-1734857976
Testability,test,tests,"This is an interesting situation. The build on mac12arm/cxx20 did not fail, it's ""unstable"". All tests pass but there are warnings triggered by TBB. The version is simply too old (2019). On Mac13, cxx17 or cxx20, TBB does not even build. A PR is coming to propose a fix.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13720#issuecomment-1735428320
Usability,simpl,simply,"This is an interesting situation. The build on mac12arm/cxx20 did not fail, it's ""unstable"". All tests pass but there are warnings triggered by TBB. The version is simply too old (2019). On Mac13, cxx17 or cxx20, TBB does not even build. A PR is coming to propose a fix.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13720#issuecomment-1735428320
Deployability,configurat,configuration,"> Sorry - I'm missing why updating builtin tbb unconditionally is off the table? Is it?. Not really, for continuity this was a first proposal, also linked to some discussions in the LIM. The overall cost of maintaining just one TBB version would be much lower and I personally would be in favour of simplifying the configuration, if possible.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13724#issuecomment-1736762182
Modifiability,config,configuration,"> Sorry - I'm missing why updating builtin tbb unconditionally is off the table? Is it?. Not really, for continuity this was a first proposal, also linked to some discussions in the LIM. The overall cost of maintaining just one TBB version would be much lower and I personally would be in favour of simplifying the configuration, if possible.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13724#issuecomment-1736762182
Usability,simpl,simplifying,"> Sorry - I'm missing why updating builtin tbb unconditionally is off the table? Is it?. Not really, for continuity this was a first proposal, also linked to some discussions in the LIM. The overall cost of maintaining just one TBB version would be much lower and I personally would be in favour of simplifying the configuration, if possible.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13724#issuecomment-1736762182
Integrability,interface,interface,"Hi! Since I didn't get feedback yet, I decided to just merge the refactor to check the consistency without the try-catch hack. If you need the public interface after all, fee free to open a new PR about that once this one is merged :+1:",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13748#issuecomment-1816424024
Modifiability,refactor,refactor,"Hi! Since I didn't get feedback yet, I decided to just merge the refactor to check the consistency without the try-catch hack. If you need the public interface after all, fee free to open a new PR about that once this one is merged :+1:",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13748#issuecomment-1816424024
Usability,feedback,feedback,"Hi! Since I didn't get feedback yet, I decided to just merge the refactor to check the consistency without the try-catch hack. If you need the public interface after all, fee free to open a new PR about that once this one is merged :+1:",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13748#issuecomment-1816424024
Availability,error,error,"This broke the build on all EPEL-based distributions where the headers are in `/usr/include/xrootd`, but `XRootDConfig.cmake` reports `/usr/include`. I believe this is an error in how the `rpm` is packaged, but we cannot fix it immediately. Our CI was also very clear about this problem by failing on 5 platforms (!), 3x Fedora and 2x Alma Linux, which I would again like to point out must be always checked before merging! I'm reverting the second commit in https://github.com/root-project/root/pull/14170 to restore our builds and also help the LCG people.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13752#issuecomment-1838159186
Usability,clear,clear,"This broke the build on all EPEL-based distributions where the headers are in `/usr/include/xrootd`, but `XRootDConfig.cmake` reports `/usr/include`. I believe this is an error in how the `rpm` is packaged, but we cannot fix it immediately. Our CI was also very clear about this problem by failing on 5 platforms (!), 3x Fedora and 2x Alma Linux, which I would again like to point out must be always checked before merging! I'm reverting the second commit in https://github.com/root-project/root/pull/14170 to restore our builds and also help the LCG people.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13752#issuecomment-1838159186
Availability,failure,failure,"Thanks for the review @dpiparo!. So far, the only failure is the one on ubuntu 2204 that was also seen before this PR:; https://github.com/root-project/root/pull/13775#issuecomment-1743080607. If there are no regressions in the CI output with respect to the other PR I linked, I will merge this PR and then follow up with more backports tomorrow based on the feedback from the nightlies.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13777#issuecomment-1743507531
Usability,feedback,feedback,"Thanks for the review @dpiparo!. So far, the only failure is the one on ubuntu 2204 that was also seen before this PR:; https://github.com/root-project/root/pull/13775#issuecomment-1743080607. If there are no regressions in the CI output with respect to the other PR I linked, I will merge this PR and then follow up with more backports tomorrow based on the feedback from the nightlies.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13777#issuecomment-1743507531
Safety,safe,safely,"I also have a general comment, . https://github.com/root-project/root/blob/5d2c835d1c707dbbb9d7f1a82425c0567d5527dd/tree/ntuple/v7/doc/specifications.md?plain=1#L341-L342. it's not yet clear what are the expectation around these strings, my hunch is at write-time they come from reflection, and at read-time ROOT's internal compiler will be used to restore the field to a known (maybe user-defined) C++ type. However, in principle all the logical layout of data and types are encoded without these strings, so my questions are:. 1. for non-ROOT reader, can these be safely ignored (e.g. instead of getting back a named data struct, you get an anonymous struct by ignoring the type name); 2. for non-ROOT writer, if these are left empty, can ROOT figure out based on primitive types and compositions?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13779#issuecomment-1806758875
Testability,log,logical,"I also have a general comment, . https://github.com/root-project/root/blob/5d2c835d1c707dbbb9d7f1a82425c0567d5527dd/tree/ntuple/v7/doc/specifications.md?plain=1#L341-L342. it's not yet clear what are the expectation around these strings, my hunch is at write-time they come from reflection, and at read-time ROOT's internal compiler will be used to restore the field to a known (maybe user-defined) C++ type. However, in principle all the logical layout of data and types are encoded without these strings, so my questions are:. 1. for non-ROOT reader, can these be safely ignored (e.g. instead of getting back a named data struct, you get an anonymous struct by ignoring the type name); 2. for non-ROOT writer, if these are left empty, can ROOT figure out based on primitive types and compositions?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13779#issuecomment-1806758875
Usability,clear,clear,"I also have a general comment, . https://github.com/root-project/root/blob/5d2c835d1c707dbbb9d7f1a82425c0567d5527dd/tree/ntuple/v7/doc/specifications.md?plain=1#L341-L342. it's not yet clear what are the expectation around these strings, my hunch is at write-time they come from reflection, and at read-time ROOT's internal compiler will be used to restore the field to a known (maybe user-defined) C++ type. However, in principle all the logical layout of data and types are encoded without these strings, so my questions are:. 1. for non-ROOT reader, can these be safely ignored (e.g. instead of getting back a named data struct, you get an anonymous struct by ignoring the type name); 2. for non-ROOT writer, if these are left empty, can ROOT figure out based on primitive types and compositions?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13779#issuecomment-1806758875
Deployability,update,update,"> I also have a general comment,; > ; > https://github.com/root-project/root/blob/5d2c835d1c707dbbb9d7f1a82425c0567d5527dd/tree/ntuple/v7/doc/specifications.md?plain=1#L341-L342; > ; > it's not yet clear what are the expectation around these strings, my hunch is at write-time they come from reflection, and at read-time ROOT's internal compiler will be used to restore the field to a known (maybe user-defined) C++ type. However, in principle all the logical layout of data and types are encoded without these strings, so my questions are:; > ; > 1. for non-ROOT reader, can these be safely ignored (e.g. instead of getting back a named data struct, you get an anonymous struct by ignoring the type name); > ; > 2. for non-ROOT writer, if these are left empty, can ROOT figure out based on primitive types and compositions?. This is a good question. If you omit the type name for structs or collections, they become untyped structs or untyped collections. RDF can deal with this fully, the `RNTupleReader` currently only with untyped collections (transparently cast to an `std::vector`). In general, C++/framework code is likely to have problems with untyped structs because there is no class to read data into... Still, untyped structs and untyped collections are valid RNTuple data. For basic types, we cannot omit the type because the column only specify the on-disk type while the field type information gives the in-memory type. The two don't have to be identical (e.g. `double` in memory and `Real32` on disk). I thought we already documented the allowed combinations of POD type and column types but I now realized we didn't. We'll update the docs in a follow-up PR.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13779#issuecomment-1820886920
Safety,safe,safely,"> I also have a general comment,; > ; > https://github.com/root-project/root/blob/5d2c835d1c707dbbb9d7f1a82425c0567d5527dd/tree/ntuple/v7/doc/specifications.md?plain=1#L341-L342; > ; > it's not yet clear what are the expectation around these strings, my hunch is at write-time they come from reflection, and at read-time ROOT's internal compiler will be used to restore the field to a known (maybe user-defined) C++ type. However, in principle all the logical layout of data and types are encoded without these strings, so my questions are:; > ; > 1. for non-ROOT reader, can these be safely ignored (e.g. instead of getting back a named data struct, you get an anonymous struct by ignoring the type name); > ; > 2. for non-ROOT writer, if these are left empty, can ROOT figure out based on primitive types and compositions?. This is a good question. If you omit the type name for structs or collections, they become untyped structs or untyped collections. RDF can deal with this fully, the `RNTupleReader` currently only with untyped collections (transparently cast to an `std::vector`). In general, C++/framework code is likely to have problems with untyped structs because there is no class to read data into... Still, untyped structs and untyped collections are valid RNTuple data. For basic types, we cannot omit the type because the column only specify the on-disk type while the field type information gives the in-memory type. The two don't have to be identical (e.g. `double` in memory and `Real32` on disk). I thought we already documented the allowed combinations of POD type and column types but I now realized we didn't. We'll update the docs in a follow-up PR.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13779#issuecomment-1820886920
Testability,log,logical,"> I also have a general comment,; > ; > https://github.com/root-project/root/blob/5d2c835d1c707dbbb9d7f1a82425c0567d5527dd/tree/ntuple/v7/doc/specifications.md?plain=1#L341-L342; > ; > it's not yet clear what are the expectation around these strings, my hunch is at write-time they come from reflection, and at read-time ROOT's internal compiler will be used to restore the field to a known (maybe user-defined) C++ type. However, in principle all the logical layout of data and types are encoded without these strings, so my questions are:; > ; > 1. for non-ROOT reader, can these be safely ignored (e.g. instead of getting back a named data struct, you get an anonymous struct by ignoring the type name); > ; > 2. for non-ROOT writer, if these are left empty, can ROOT figure out based on primitive types and compositions?. This is a good question. If you omit the type name for structs or collections, they become untyped structs or untyped collections. RDF can deal with this fully, the `RNTupleReader` currently only with untyped collections (transparently cast to an `std::vector`). In general, C++/framework code is likely to have problems with untyped structs because there is no class to read data into... Still, untyped structs and untyped collections are valid RNTuple data. For basic types, we cannot omit the type because the column only specify the on-disk type while the field type information gives the in-memory type. The two don't have to be identical (e.g. `double` in memory and `Real32` on disk). I thought we already documented the allowed combinations of POD type and column types but I now realized we didn't. We'll update the docs in a follow-up PR.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13779#issuecomment-1820886920
Usability,clear,clear,"> I also have a general comment,; > ; > https://github.com/root-project/root/blob/5d2c835d1c707dbbb9d7f1a82425c0567d5527dd/tree/ntuple/v7/doc/specifications.md?plain=1#L341-L342; > ; > it's not yet clear what are the expectation around these strings, my hunch is at write-time they come from reflection, and at read-time ROOT's internal compiler will be used to restore the field to a known (maybe user-defined) C++ type. However, in principle all the logical layout of data and types are encoded without these strings, so my questions are:; > ; > 1. for non-ROOT reader, can these be safely ignored (e.g. instead of getting back a named data struct, you get an anonymous struct by ignoring the type name); > ; > 2. for non-ROOT writer, if these are left empty, can ROOT figure out based on primitive types and compositions?. This is a good question. If you omit the type name for structs or collections, they become untyped structs or untyped collections. RDF can deal with this fully, the `RNTupleReader` currently only with untyped collections (transparently cast to an `std::vector`). In general, C++/framework code is likely to have problems with untyped structs because there is no class to read data into... Still, untyped structs and untyped collections are valid RNTuple data. For basic types, we cannot omit the type because the column only specify the on-disk type while the field type information gives the in-memory type. The two don't have to be identical (e.g. `double` in memory and `Real32` on disk). I thought we already documented the allowed combinations of POD type and column types but I now realized we didn't. We'll update the docs in a follow-up PR.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13779#issuecomment-1820886920
Availability,down,down,">simplify frame layout. seems like one step in the right direction in terms of trimming down number of ""speed bumps"" in reading things!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13779#issuecomment-1822922214
Usability,simpl,simplify,">simplify frame layout. seems like one step in the right direction in terms of trimming down number of ""speed bumps"" in reading things!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13779#issuecomment-1822922214
Availability,failure,failures,"As a completely anecdotical evidence, I have been running on the `root-ubuntu-2004-1` machine the distributed RDF test which used to fail, which included calls to DefinePerSample. After applying this patch, currently ~1800 iterations of the test passed without failures. ```; test_all.py::TestPropagateExceptions::test_runtime_error_is_propagated <- check_backend.py PASSED; test_all.py::TestDefinePerSample::test_definepersample_simple <- check_definepersample.py PASSED; test_all.py::TestDefinePerSample::test_definepersample_withinitialization <- check_definepersample.py PASSED; =============================== warnings summary ===============================; test_all.py::TestPropagateExceptions::test_runtime_error_is_propagated; /home/sftnight/vpadulan/rootproject/rootbuild/master-like-jenkins/lib/ROOT/_facade.py:154: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.; Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations; return _orig_ihook(name, *args, **kwds). test_all.py::TestPropagateExceptions::test_runtime_error_is_propagated; /usr/local/lib/python3.8/dist-packages/dask_jobqueue/core.py:20: FutureWarning: tmpfile is deprecated and will be removed in a future release. Please use dask.utils.tmpfile instead.; from distributed.utils import tmpfile. -- Docs: https://docs.pytest.org/en/latest/warnings.html; ==================== 3 passed, 2 warnings in 32.72 seconds =====================. Running test 1864; ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13787#issuecomment-1744852013
Deployability,patch,patch,"As a completely anecdotical evidence, I have been running on the `root-ubuntu-2004-1` machine the distributed RDF test which used to fail, which included calls to DefinePerSample. After applying this patch, currently ~1800 iterations of the test passed without failures. ```; test_all.py::TestPropagateExceptions::test_runtime_error_is_propagated <- check_backend.py PASSED; test_all.py::TestDefinePerSample::test_definepersample_simple <- check_definepersample.py PASSED; test_all.py::TestDefinePerSample::test_definepersample_withinitialization <- check_definepersample.py PASSED; =============================== warnings summary ===============================; test_all.py::TestPropagateExceptions::test_runtime_error_is_propagated; /home/sftnight/vpadulan/rootproject/rootbuild/master-like-jenkins/lib/ROOT/_facade.py:154: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.; Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations; return _orig_ihook(name, *args, **kwds). test_all.py::TestPropagateExceptions::test_runtime_error_is_propagated; /usr/local/lib/python3.8/dist-packages/dask_jobqueue/core.py:20: FutureWarning: tmpfile is deprecated and will be removed in a future release. Please use dask.utils.tmpfile instead.; from distributed.utils import tmpfile. -- Docs: https://docs.pytest.org/en/latest/warnings.html; ==================== 3 passed, 2 warnings in 32.72 seconds =====================. Running test 1864; ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13787#issuecomment-1744852013
Safety,safe,safe,"As a completely anecdotical evidence, I have been running on the `root-ubuntu-2004-1` machine the distributed RDF test which used to fail, which included calls to DefinePerSample. After applying this patch, currently ~1800 iterations of the test passed without failures. ```; test_all.py::TestPropagateExceptions::test_runtime_error_is_propagated <- check_backend.py PASSED; test_all.py::TestDefinePerSample::test_definepersample_simple <- check_definepersample.py PASSED; test_all.py::TestDefinePerSample::test_definepersample_withinitialization <- check_definepersample.py PASSED; =============================== warnings summary ===============================; test_all.py::TestPropagateExceptions::test_runtime_error_is_propagated; /home/sftnight/vpadulan/rootproject/rootbuild/master-like-jenkins/lib/ROOT/_facade.py:154: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.; Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations; return _orig_ihook(name, *args, **kwds). test_all.py::TestPropagateExceptions::test_runtime_error_is_propagated; /usr/local/lib/python3.8/dist-packages/dask_jobqueue/core.py:20: FutureWarning: tmpfile is deprecated and will be removed in a future release. Please use dask.utils.tmpfile instead.; from distributed.utils import tmpfile. -- Docs: https://docs.pytest.org/en/latest/warnings.html; ==================== 3 passed, 2 warnings in 32.72 seconds =====================. Running test 1864; ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13787#issuecomment-1744852013
Testability,test,test,"As a completely anecdotical evidence, I have been running on the `root-ubuntu-2004-1` machine the distributed RDF test which used to fail, which included calls to DefinePerSample. After applying this patch, currently ~1800 iterations of the test passed without failures. ```; test_all.py::TestPropagateExceptions::test_runtime_error_is_propagated <- check_backend.py PASSED; test_all.py::TestDefinePerSample::test_definepersample_simple <- check_definepersample.py PASSED; test_all.py::TestDefinePerSample::test_definepersample_withinitialization <- check_definepersample.py PASSED; =============================== warnings summary ===============================; test_all.py::TestPropagateExceptions::test_runtime_error_is_propagated; /home/sftnight/vpadulan/rootproject/rootbuild/master-like-jenkins/lib/ROOT/_facade.py:154: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.; Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations; return _orig_ihook(name, *args, **kwds). test_all.py::TestPropagateExceptions::test_runtime_error_is_propagated; /usr/local/lib/python3.8/dist-packages/dask_jobqueue/core.py:20: FutureWarning: tmpfile is deprecated and will be removed in a future release. Please use dask.utils.tmpfile instead.; from distributed.utils import tmpfile. -- Docs: https://docs.pytest.org/en/latest/warnings.html; ==================== 3 passed, 2 warnings in 32.72 seconds =====================. Running test 1864; ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13787#issuecomment-1744852013
Usability,guid,guidance,"As a completely anecdotical evidence, I have been running on the `root-ubuntu-2004-1` machine the distributed RDF test which used to fail, which included calls to DefinePerSample. After applying this patch, currently ~1800 iterations of the test passed without failures. ```; test_all.py::TestPropagateExceptions::test_runtime_error_is_propagated <- check_backend.py PASSED; test_all.py::TestDefinePerSample::test_definepersample_simple <- check_definepersample.py PASSED; test_all.py::TestDefinePerSample::test_definepersample_withinitialization <- check_definepersample.py PASSED; =============================== warnings summary ===============================; test_all.py::TestPropagateExceptions::test_runtime_error_is_propagated; /home/sftnight/vpadulan/rootproject/rootbuild/master-like-jenkins/lib/ROOT/_facade.py:154: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.; Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations; return _orig_ihook(name, *args, **kwds). test_all.py::TestPropagateExceptions::test_runtime_error_is_propagated; /usr/local/lib/python3.8/dist-packages/dask_jobqueue/core.py:20: FutureWarning: tmpfile is deprecated and will be removed in a future release. Please use dask.utils.tmpfile instead.; from distributed.utils import tmpfile. -- Docs: https://docs.pytest.org/en/latest/warnings.html; ==================== 3 passed, 2 warnings in 32.72 seconds =====================. Running test 1864; ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13787#issuecomment-1744852013
Availability,failure,failure,"The direct reason of the failure seems to be that, at least when using SWAN, the ROOT installation is somehow ill-formed. This is a simpler reproducer that just uses Spark primitives to try to run the `root-config` command on the worker. ![image](https://github.com/root-project/root/assets/15638895/f53c6803-7e0d-44cc-80be-160f4065af9c). In all fairness, I don't understand the reason to call into that command in the first place, which happens [here](https://github.com/root-project/root/blob/07872d92719e3682213d732956a32f16be5eacf3/bindings/pyroot/pythonizations/python/ROOT/_pythonization/_tmva/__init__.py#L47), so I will investigate if that is needed at all.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13798#issuecomment-1745696812
Deployability,install,installation,"The direct reason of the failure seems to be that, at least when using SWAN, the ROOT installation is somehow ill-formed. This is a simpler reproducer that just uses Spark primitives to try to run the `root-config` command on the worker. ![image](https://github.com/root-project/root/assets/15638895/f53c6803-7e0d-44cc-80be-160f4065af9c). In all fairness, I don't understand the reason to call into that command in the first place, which happens [here](https://github.com/root-project/root/blob/07872d92719e3682213d732956a32f16be5eacf3/bindings/pyroot/pythonizations/python/ROOT/_pythonization/_tmva/__init__.py#L47), so I will investigate if that is needed at all.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13798#issuecomment-1745696812
Modifiability,config,config,"The direct reason of the failure seems to be that, at least when using SWAN, the ROOT installation is somehow ill-formed. This is a simpler reproducer that just uses Spark primitives to try to run the `root-config` command on the worker. ![image](https://github.com/root-project/root/assets/15638895/f53c6803-7e0d-44cc-80be-160f4065af9c). In all fairness, I don't understand the reason to call into that command in the first place, which happens [here](https://github.com/root-project/root/blob/07872d92719e3682213d732956a32f16be5eacf3/bindings/pyroot/pythonizations/python/ROOT/_pythonization/_tmva/__init__.py#L47), so I will investigate if that is needed at all.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13798#issuecomment-1745696812
Usability,simpl,simpler,"The direct reason of the failure seems to be that, at least when using SWAN, the ROOT installation is somehow ill-formed. This is a simpler reproducer that just uses Spark primitives to try to run the `root-config` command on the worker. ![image](https://github.com/root-project/root/assets/15638895/f53c6803-7e0d-44cc-80be-160f4065af9c). In all fairness, I don't understand the reason to call into that command in the first place, which happens [here](https://github.com/root-project/root/blob/07872d92719e3682213d732956a32f16be5eacf3/bindings/pyroot/pythonizations/python/ROOT/_pythonization/_tmva/__init__.py#L47), so I will investigate if that is needed at all.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13798#issuecomment-1745696812
Usability,usab,usability,"Hello. I think this issue is quite relevant, not only for distributed execution, but also for PyROOT usability in general. This is why I proposed these changes, in case they turn out to seem useful https://github.com/root-project/root/pull/13803",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13798#issuecomment-1746991396
Usability,simpl,simply,I am checking what's going on. I might have simply screwed up the backport.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13808#issuecomment-1750234087
Availability,failure,failures,"Hi @ktf, as discussed yesterday the test failures are related to an issue in our incremental builds where Clad is not rebuilt after changes to the Clang headers. This leads to very weird symptoms because some ""stale"" functions access memory where they shouldn't and so on. I was hit by this problem already twice and it's tracked in https://github.com/root-project/root/issues/7977, so one would suppose that I remember by now but evidently I didn't... Apologies for the confusion and the delay it caused in integrating this. I've now synchronized the changes to https://github.com/root-project/llvm-project/releases/tag/ROOT-llvm16-20240116-01, moving the header to `clang/include/clang/Basic` as mentioned yesterday to keep the ability to build against a vanilla version of LLVM). @vgvassilev I put the commit only into `ROOT-llvm16`, not `cling-llvm16` because I think it's not that relevant for Cling standalone. Let me know if you disagree and I can of course move it. Some measurements of this change on my machine: for a simple `./bin/root.exe -q`, it reduces the maximum RSS from 217MB to 192MB and for `./bin/root.exe -q -e ""std::vector<int> v"" -e ""return 0;""` from 255MB to 230MB :clap:",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13808#issuecomment-1893308958
Deployability,integrat,integrating,"Hi @ktf, as discussed yesterday the test failures are related to an issue in our incremental builds where Clad is not rebuilt after changes to the Clang headers. This leads to very weird symptoms because some ""stale"" functions access memory where they shouldn't and so on. I was hit by this problem already twice and it's tracked in https://github.com/root-project/root/issues/7977, so one would suppose that I remember by now but evidently I didn't... Apologies for the confusion and the delay it caused in integrating this. I've now synchronized the changes to https://github.com/root-project/llvm-project/releases/tag/ROOT-llvm16-20240116-01, moving the header to `clang/include/clang/Basic` as mentioned yesterday to keep the ability to build against a vanilla version of LLVM). @vgvassilev I put the commit only into `ROOT-llvm16`, not `cling-llvm16` because I think it's not that relevant for Cling standalone. Let me know if you disagree and I can of course move it. Some measurements of this change on my machine: for a simple `./bin/root.exe -q`, it reduces the maximum RSS from 217MB to 192MB and for `./bin/root.exe -q -e ""std::vector<int> v"" -e ""return 0;""` from 255MB to 230MB :clap:",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13808#issuecomment-1893308958
Energy Efficiency,reduce,reduces,"Hi @ktf, as discussed yesterday the test failures are related to an issue in our incremental builds where Clad is not rebuilt after changes to the Clang headers. This leads to very weird symptoms because some ""stale"" functions access memory where they shouldn't and so on. I was hit by this problem already twice and it's tracked in https://github.com/root-project/root/issues/7977, so one would suppose that I remember by now but evidently I didn't... Apologies for the confusion and the delay it caused in integrating this. I've now synchronized the changes to https://github.com/root-project/llvm-project/releases/tag/ROOT-llvm16-20240116-01, moving the header to `clang/include/clang/Basic` as mentioned yesterday to keep the ability to build against a vanilla version of LLVM). @vgvassilev I put the commit only into `ROOT-llvm16`, not `cling-llvm16` because I think it's not that relevant for Cling standalone. Let me know if you disagree and I can of course move it. Some measurements of this change on my machine: for a simple `./bin/root.exe -q`, it reduces the maximum RSS from 217MB to 192MB and for `./bin/root.exe -q -e ""std::vector<int> v"" -e ""return 0;""` from 255MB to 230MB :clap:",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13808#issuecomment-1893308958
Integrability,integrat,integrating,"Hi @ktf, as discussed yesterday the test failures are related to an issue in our incremental builds where Clad is not rebuilt after changes to the Clang headers. This leads to very weird symptoms because some ""stale"" functions access memory where they shouldn't and so on. I was hit by this problem already twice and it's tracked in https://github.com/root-project/root/issues/7977, so one would suppose that I remember by now but evidently I didn't... Apologies for the confusion and the delay it caused in integrating this. I've now synchronized the changes to https://github.com/root-project/llvm-project/releases/tag/ROOT-llvm16-20240116-01, moving the header to `clang/include/clang/Basic` as mentioned yesterday to keep the ability to build against a vanilla version of LLVM). @vgvassilev I put the commit only into `ROOT-llvm16`, not `cling-llvm16` because I think it's not that relevant for Cling standalone. Let me know if you disagree and I can of course move it. Some measurements of this change on my machine: for a simple `./bin/root.exe -q`, it reduces the maximum RSS from 217MB to 192MB and for `./bin/root.exe -q -e ""std::vector<int> v"" -e ""return 0;""` from 255MB to 230MB :clap:",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13808#issuecomment-1893308958
Security,access,access,"Hi @ktf, as discussed yesterday the test failures are related to an issue in our incremental builds where Clad is not rebuilt after changes to the Clang headers. This leads to very weird symptoms because some ""stale"" functions access memory where they shouldn't and so on. I was hit by this problem already twice and it's tracked in https://github.com/root-project/root/issues/7977, so one would suppose that I remember by now but evidently I didn't... Apologies for the confusion and the delay it caused in integrating this. I've now synchronized the changes to https://github.com/root-project/llvm-project/releases/tag/ROOT-llvm16-20240116-01, moving the header to `clang/include/clang/Basic` as mentioned yesterday to keep the ability to build against a vanilla version of LLVM). @vgvassilev I put the commit only into `ROOT-llvm16`, not `cling-llvm16` because I think it's not that relevant for Cling standalone. Let me know if you disagree and I can of course move it. Some measurements of this change on my machine: for a simple `./bin/root.exe -q`, it reduces the maximum RSS from 217MB to 192MB and for `./bin/root.exe -q -e ""std::vector<int> v"" -e ""return 0;""` from 255MB to 230MB :clap:",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13808#issuecomment-1893308958
Testability,test,test,"Hi @ktf, as discussed yesterday the test failures are related to an issue in our incremental builds where Clad is not rebuilt after changes to the Clang headers. This leads to very weird symptoms because some ""stale"" functions access memory where they shouldn't and so on. I was hit by this problem already twice and it's tracked in https://github.com/root-project/root/issues/7977, so one would suppose that I remember by now but evidently I didn't... Apologies for the confusion and the delay it caused in integrating this. I've now synchronized the changes to https://github.com/root-project/llvm-project/releases/tag/ROOT-llvm16-20240116-01, moving the header to `clang/include/clang/Basic` as mentioned yesterday to keep the ability to build against a vanilla version of LLVM). @vgvassilev I put the commit only into `ROOT-llvm16`, not `cling-llvm16` because I think it's not that relevant for Cling standalone. Let me know if you disagree and I can of course move it. Some measurements of this change on my machine: for a simple `./bin/root.exe -q`, it reduces the maximum RSS from 217MB to 192MB and for `./bin/root.exe -q -e ""std::vector<int> v"" -e ""return 0;""` from 255MB to 230MB :clap:",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13808#issuecomment-1893308958
Usability,simpl,simple,"Hi @ktf, as discussed yesterday the test failures are related to an issue in our incremental builds where Clad is not rebuilt after changes to the Clang headers. This leads to very weird symptoms because some ""stale"" functions access memory where they shouldn't and so on. I was hit by this problem already twice and it's tracked in https://github.com/root-project/root/issues/7977, so one would suppose that I remember by now but evidently I didn't... Apologies for the confusion and the delay it caused in integrating this. I've now synchronized the changes to https://github.com/root-project/llvm-project/releases/tag/ROOT-llvm16-20240116-01, moving the header to `clang/include/clang/Basic` as mentioned yesterday to keep the ability to build against a vanilla version of LLVM). @vgvassilev I put the commit only into `ROOT-llvm16`, not `cling-llvm16` because I think it's not that relevant for Cling standalone. Let me know if you disagree and I can of course move it. Some measurements of this change on my machine: for a simple `./bin/root.exe -q`, it reduces the maximum RSS from 217MB to 192MB and for `./bin/root.exe -q -e ""std::vector<int> v"" -e ""return 0;""` from 255MB to 230MB :clap:",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13808#issuecomment-1893308958
Availability,recover,recovery,"Fair enough. The LLVM 16 is revealing a part of the problem we had not solved yet :) [Note the simplified example is different from the real use case in that there is no expectation of recovery in that case while inside Core/Meta there is; i.e. once the problem is fixed, the command line reproducer will (and should) still fail ]",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13815#issuecomment-1757758714
Safety,recover,recovery,"Fair enough. The LLVM 16 is revealing a part of the problem we had not solved yet :) [Note the simplified example is different from the real use case in that there is no expectation of recovery in that case while inside Core/Meta there is; i.e. once the problem is fixed, the command line reproducer will (and should) still fail ]",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13815#issuecomment-1757758714
Usability,simpl,simplified,"Fair enough. The LLVM 16 is revealing a part of the problem we had not solved yet :) [Note the simplified example is different from the real use case in that there is no expectation of recovery in that case while inside Core/Meta there is; i.e. once the problem is fixed, the command line reproducer will (and should) still fail ]",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13815#issuecomment-1757758714
Availability,error,errors,"I agree that there is a problem here. That might involve the `DeclCollector` or the `DeclUnloader` or some other parts of ROOT. However, IMHO https://github.com/root-project/root/issues/13815#issuecomment-1759250811 clearly shows that the underlying problem is much bigger and older than just the failing test with LLVM 16. So I'd be very much interested in a pragmatic solution to resolve this last blocker for the upgrade. P.S.: One idea I had was to split the test into two parts, ie one ""bad"" part that tests the behavior with an incomplete class and one ""good"" part that loads `inst2lib`. However I quickly got stuck because just removing `o->Print();` on the first loaded object leads to many errors of the form `Error parsing payload code for class Inner` that I can't make sense of...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13815#issuecomment-1768325139
Deployability,upgrade,upgrade,"I agree that there is a problem here. That might involve the `DeclCollector` or the `DeclUnloader` or some other parts of ROOT. However, IMHO https://github.com/root-project/root/issues/13815#issuecomment-1759250811 clearly shows that the underlying problem is much bigger and older than just the failing test with LLVM 16. So I'd be very much interested in a pragmatic solution to resolve this last blocker for the upgrade. P.S.: One idea I had was to split the test into two parts, ie one ""bad"" part that tests the behavior with an incomplete class and one ""good"" part that loads `inst2lib`. However I quickly got stuck because just removing `o->Print();` on the first loaded object leads to many errors of the form `Error parsing payload code for class Inner` that I can't make sense of...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13815#issuecomment-1768325139
Performance,load,loads,"I agree that there is a problem here. That might involve the `DeclCollector` or the `DeclUnloader` or some other parts of ROOT. However, IMHO https://github.com/root-project/root/issues/13815#issuecomment-1759250811 clearly shows that the underlying problem is much bigger and older than just the failing test with LLVM 16. So I'd be very much interested in a pragmatic solution to resolve this last blocker for the upgrade. P.S.: One idea I had was to split the test into two parts, ie one ""bad"" part that tests the behavior with an incomplete class and one ""good"" part that loads `inst2lib`. However I quickly got stuck because just removing `o->Print();` on the first loaded object leads to many errors of the form `Error parsing payload code for class Inner` that I can't make sense of...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13815#issuecomment-1768325139
Testability,test,test,"I agree that there is a problem here. That might involve the `DeclCollector` or the `DeclUnloader` or some other parts of ROOT. However, IMHO https://github.com/root-project/root/issues/13815#issuecomment-1759250811 clearly shows that the underlying problem is much bigger and older than just the failing test with LLVM 16. So I'd be very much interested in a pragmatic solution to resolve this last blocker for the upgrade. P.S.: One idea I had was to split the test into two parts, ie one ""bad"" part that tests the behavior with an incomplete class and one ""good"" part that loads `inst2lib`. However I quickly got stuck because just removing `o->Print();` on the first loaded object leads to many errors of the form `Error parsing payload code for class Inner` that I can't make sense of...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13815#issuecomment-1768325139
Usability,clear,clearly,"I agree that there is a problem here. That might involve the `DeclCollector` or the `DeclUnloader` or some other parts of ROOT. However, IMHO https://github.com/root-project/root/issues/13815#issuecomment-1759250811 clearly shows that the underlying problem is much bigger and older than just the failing test with LLVM 16. So I'd be very much interested in a pragmatic solution to resolve this last blocker for the upgrade. P.S.: One idea I had was to split the test into two parts, ie one ""bad"" part that tests the behavior with an incomplete class and one ""good"" part that loads `inst2lib`. However I quickly got stuck because just removing `o->Print();` on the first loaded object leads to many errors of the form `Error parsing payload code for class Inner` that I can't make sense of...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13815#issuecomment-1768325139
Usability,clear,clearly,"> IMHO https://github.com/root-project/root/issues/13815#issuecomment-1759250811 clearly shows that the underlying problem. I would agree if it was not the fact that this is being triggered by a benign and wildely used class ... i.e. `std::pair` ... . Consequently, it my opinion we are almost guaranteed to have this problem appear almost immediately in the wild (i.e. code and code flow that worked before will now fail)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13815#issuecomment-1768955888
Usability,clear,clear,"> Yes, but on that web page, there is no module for MacOS14 yet. That might be the cause of the problem because when I build it from sources on my MacOS 14 machine I have no problem with TBrowser. The version for macOS14 should come soon. Meanwhile, you can try to build from the sources if you want. I'm sorry if I didn't make myself clear. I also build it from sources on my MacOS 14 machine.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13834#issuecomment-1756960653
Modifiability,variab,variable,"> I wonder, whether all the new TList should be moved to an in-class member variable initializer (See [C++ Core Guidelines C.48](https://isocpp.github.io/CppCoreGuidelines/CppCoreGuidelines#Rc-in-class-initializer))?. Yes, this is a fair point. Feel free to open another PR with that further simplification.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13840#issuecomment-1760218445
Usability,simpl,simplification,"> I wonder, whether all the new TList should be moved to an in-class member variable initializer (See [C++ Core Guidelines C.48](https://isocpp.github.io/CppCoreGuidelines/CppCoreGuidelines#Rc-in-class-initializer))?. Yes, this is a fair point. Feel free to open another PR with that further simplification.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13840#issuecomment-1760218445
Modifiability,variab,variable,"> > I wonder, whether all the `new TList` should be moved to an in-class member variable initializer (See [C++ Core Guidelines C.48](https://isocpp.github.io/CppCoreGuidelines/CppCoreGuidelines#Rc-in-class-initializer))?; > ; > Yes, this is a fair point. Feel free to open another PR with that further simplification. Hi @pcanal,. I started to look into this. And; ```cpp; #ifdef R__LESS_INCLUDES; class TList;; #else; #include ""TList.h""; #endif; ```; in `TTask.h` would need to be changed to a plain `#include ""TList.h""`. That sounds like it contradicts the `R__LESS_INCLUDES` movement?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13840#issuecomment-1760285333
Usability,simpl,simplification,"> > I wonder, whether all the `new TList` should be moved to an in-class member variable initializer (See [C++ Core Guidelines C.48](https://isocpp.github.io/CppCoreGuidelines/CppCoreGuidelines#Rc-in-class-initializer))?; > ; > Yes, this is a fair point. Feel free to open another PR with that further simplification. Hi @pcanal,. I started to look into this. And; ```cpp; #ifdef R__LESS_INCLUDES; class TList;; #else; #include ""TList.h""; #endif; ```; in `TTask.h` would need to be changed to a plain `#include ""TList.h""`. That sounds like it contradicts the `R__LESS_INCLUDES` movement?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13840#issuecomment-1760285333
Usability,simpl,simpler,"Dear @mmaneyro ,. Thank you for your report. I take it that `Event.NParticles` is a sub-branch of the `Event` branch. What you describe is not really surprising, as `Redefine` is meant to substitute the values of the full column of the RDataFrame (column==branch). The difference in behaviour between non-jitted and jitted code is more surprising though. As a fast workaround, you could be more explicit about the columns you want to save in your output TTree by adding the list of column names to the `Snapshot` call. ```cpp; auto snap = df2.Snapshot(""LHEF"", ""out_snapshot.root"", {""Event.NParticles""});; ```. In order for me to better reproduce your problem though, I believe I would also need some instructions on how to generate the dictionaries for the classes in your file. Meanwhile, I can try to come up with a simpler reproducer, but having also your scenario would help. Cheers,; Vincenzo",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13846#issuecomment-1760263815
Availability,error,error,"Dear Vincenzo,. I have already managed to work with the redefined trees I need, just with a number of workarounds. The tree files in this case are generated from Les Houches event files using the ExRootLHEFConverter from ExRootAnalysis. As such the branches are custom classes, which can be found in the ExRootAnalysis source files. I can't actually snapshot individual columns without gettting an error as there are TClonesArray column headers which specify the structure of the branches. The obvious fix would be to snapshot the column plus the header, but then that also gives me an error. I understand that Redefine is ideally used for columns, however I need to be able to apply different redefinitions to different leaves within a branch. Do RDataFrames just not support rewriting leaves/nested columns? The columns seem to actually be doing what I'd like before snapshotting. It seems like there's not a simple solution where I get to benefit from using RDataFrame and keep the tree structure untouched. I need to be able to add rows of data to each entry within a leaf (I'm actually concatenating multiple trees), and TTrees don't allow this as far as I can see. I guess I could define a new TTree by hand, setup the branches and fill new arrays from my original trees with the redefinitions I need,(just by iterating over every entry and data value). But then I'm still changing my TTree stucture, as with snapshot. Maybe next time I'll just start by rewriting ExRootLHEFConverter to take the data from two .lhe files, or just stick to TTrees, but to be fair this project has been my first attempt at using ROOT/C++. You code you learn!. What I am trying to do may be a bit of a niche use case, but I hope some of what I wrote is useful to you. Regards, ; Marina",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13846#issuecomment-1760467268
Usability,simpl,simple,"Dear Vincenzo,. I have already managed to work with the redefined trees I need, just with a number of workarounds. The tree files in this case are generated from Les Houches event files using the ExRootLHEFConverter from ExRootAnalysis. As such the branches are custom classes, which can be found in the ExRootAnalysis source files. I can't actually snapshot individual columns without gettting an error as there are TClonesArray column headers which specify the structure of the branches. The obvious fix would be to snapshot the column plus the header, but then that also gives me an error. I understand that Redefine is ideally used for columns, however I need to be able to apply different redefinitions to different leaves within a branch. Do RDataFrames just not support rewriting leaves/nested columns? The columns seem to actually be doing what I'd like before snapshotting. It seems like there's not a simple solution where I get to benefit from using RDataFrame and keep the tree structure untouched. I need to be able to add rows of data to each entry within a leaf (I'm actually concatenating multiple trees), and TTrees don't allow this as far as I can see. I guess I could define a new TTree by hand, setup the branches and fill new arrays from my original trees with the redefinitions I need,(just by iterating over every entry and data value). But then I'm still changing my TTree stucture, as with snapshot. Maybe next time I'll just start by rewriting ExRootLHEFConverter to take the data from two .lhe files, or just stick to TTrees, but to be fair this project has been my first attempt at using ROOT/C++. You code you learn!. What I am trying to do may be a bit of a niche use case, but I hope some of what I wrote is useful to you. Regards, ; Marina",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13846#issuecomment-1760467268
Safety,avoid,avoid,"If you try fitting the obtained slice (slice 21), you will see that in both Minuit and Minuit2 the fit did not work. ; Just run this simple code: ; ```; auto f = TFile::Open(""histo.root"", ""READ"");; auto hist = f->Get<TH2>(""dxyres_vs_eta"");. auto h20 = hist->ProjectionY(""h20"",20,20);; auto h21 = hist->ProjectionY(""h21"",21,21);; auto c1 = new TCanvas();; c1->Divide(1,2);; c1->cd(1);; h20->Fit(""gaus"");; c1->cd(2);; // second fit fails ; h21->Fit(""gaus"");; ```. If you run only the second fit, it works because some default steps sizes are used at the beginning. ; You will get better slice fits if using option `L` when fitting the slices:; ```; hist->FitSlicesY(nullptr, 10, 21, 0, ""LR"");; ```; and defining a restricted range for the fitted functions to avoid fitting the outlier events. Close the issue since it is not a bug.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13852#issuecomment-1777016344
Usability,simpl,simple,"If you try fitting the obtained slice (slice 21), you will see that in both Minuit and Minuit2 the fit did not work. ; Just run this simple code: ; ```; auto f = TFile::Open(""histo.root"", ""READ"");; auto hist = f->Get<TH2>(""dxyres_vs_eta"");. auto h20 = hist->ProjectionY(""h20"",20,20);; auto h21 = hist->ProjectionY(""h21"",21,21);; auto c1 = new TCanvas();; c1->Divide(1,2);; c1->cd(1);; h20->Fit(""gaus"");; c1->cd(2);; // second fit fails ; h21->Fit(""gaus"");; ```. If you run only the second fit, it works because some default steps sizes are used at the beginning. ; You will get better slice fits if using option `L` when fitting the slices:; ```; hist->FitSlicesY(nullptr, 10, 21, 0, ""LR"");; ```; and defining a restricted range for the fitted functions to avoid fitting the outlier events. Close the issue since it is not a bug.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13852#issuecomment-1777016344
Usability,clear,clear,"Closing because the usecase is gone, and the features is probably impossible to implement in cppyy. Without a clear usecase, we should not go into this rabbit hole.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13875#issuecomment-1991844247
Usability,clear,clear,Fair enough. We need to make that the distinction is clear.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13917#issuecomment-1778121890
Usability,simpl,simple,Looks like the problem is present since the beginning. ; Already initial commit https://github.com/root-project/root/commit/852600061bcacd9b255d44f6312c96b6b1e00a2d has it. I can provide simple fix which makes it properly.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/13927#issuecomment-1780888955
Performance,multi-thread,multi-threaded,"We are still discussing the names. The current proposal is:; ```; using TFilePtr = std::unique_ptr<TFile>;. /// Open a file with `name` for reading.; ///; /// \note: Synchronizes multi-threaded accesses through locks.; static TFilePtr OpenForRead(std::string_view name, const Options_t &opts = Options_t());. /// Open an existing file with `name` for reading and writing. If a file with; /// that name does not exist, an invalid RFilePtr will be returned.; ///; /// \note: Synchronizes multi-threaded accesses through locks.; static TFilePtr OpenForUpdate(std::string_view name, const Options_t &opts = Options_t());. /// Open a file with `name` for reading and writing. Fail (return an invalid; /// `RFilePtr`) if a file with this name already exists.; ///; /// \note: Synchronizes multi-threaded accesses through locks.; static TFilePtr Create(std::string_view name, const Options_t &opts = Options_t());. /// Open a file with `name` for reading and writing. If a file with this name; /// already exists, delete it and create a new one. Else simply create a new file.; ///; /// \note: Synchronizes multi-threaded accesses through locks.; static TFilePtr Recreate(std::string_view name, const Options_t &opts = Options_t());; ```. In the meantime, you should indeed start getting familiar with the testing infrastructure. See io/io/test for some examples.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14017#issuecomment-1821818413
Security,access,accesses,"We are still discussing the names. The current proposal is:; ```; using TFilePtr = std::unique_ptr<TFile>;. /// Open a file with `name` for reading.; ///; /// \note: Synchronizes multi-threaded accesses through locks.; static TFilePtr OpenForRead(std::string_view name, const Options_t &opts = Options_t());. /// Open an existing file with `name` for reading and writing. If a file with; /// that name does not exist, an invalid RFilePtr will be returned.; ///; /// \note: Synchronizes multi-threaded accesses through locks.; static TFilePtr OpenForUpdate(std::string_view name, const Options_t &opts = Options_t());. /// Open a file with `name` for reading and writing. Fail (return an invalid; /// `RFilePtr`) if a file with this name already exists.; ///; /// \note: Synchronizes multi-threaded accesses through locks.; static TFilePtr Create(std::string_view name, const Options_t &opts = Options_t());. /// Open a file with `name` for reading and writing. If a file with this name; /// already exists, delete it and create a new one. Else simply create a new file.; ///; /// \note: Synchronizes multi-threaded accesses through locks.; static TFilePtr Recreate(std::string_view name, const Options_t &opts = Options_t());; ```. In the meantime, you should indeed start getting familiar with the testing infrastructure. See io/io/test for some examples.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14017#issuecomment-1821818413
Testability,test,testing,"We are still discussing the names. The current proposal is:; ```; using TFilePtr = std::unique_ptr<TFile>;. /// Open a file with `name` for reading.; ///; /// \note: Synchronizes multi-threaded accesses through locks.; static TFilePtr OpenForRead(std::string_view name, const Options_t &opts = Options_t());. /// Open an existing file with `name` for reading and writing. If a file with; /// that name does not exist, an invalid RFilePtr will be returned.; ///; /// \note: Synchronizes multi-threaded accesses through locks.; static TFilePtr OpenForUpdate(std::string_view name, const Options_t &opts = Options_t());. /// Open a file with `name` for reading and writing. Fail (return an invalid; /// `RFilePtr`) if a file with this name already exists.; ///; /// \note: Synchronizes multi-threaded accesses through locks.; static TFilePtr Create(std::string_view name, const Options_t &opts = Options_t());. /// Open a file with `name` for reading and writing. If a file with this name; /// already exists, delete it and create a new one. Else simply create a new file.; ///; /// \note: Synchronizes multi-threaded accesses through locks.; static TFilePtr Recreate(std::string_view name, const Options_t &opts = Options_t());; ```. In the meantime, you should indeed start getting familiar with the testing infrastructure. See io/io/test for some examples.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14017#issuecomment-1821818413
Usability,simpl,simply,"We are still discussing the names. The current proposal is:; ```; using TFilePtr = std::unique_ptr<TFile>;. /// Open a file with `name` for reading.; ///; /// \note: Synchronizes multi-threaded accesses through locks.; static TFilePtr OpenForRead(std::string_view name, const Options_t &opts = Options_t());. /// Open an existing file with `name` for reading and writing. If a file with; /// that name does not exist, an invalid RFilePtr will be returned.; ///; /// \note: Synchronizes multi-threaded accesses through locks.; static TFilePtr OpenForUpdate(std::string_view name, const Options_t &opts = Options_t());. /// Open a file with `name` for reading and writing. Fail (return an invalid; /// `RFilePtr`) if a file with this name already exists.; ///; /// \note: Synchronizes multi-threaded accesses through locks.; static TFilePtr Create(std::string_view name, const Options_t &opts = Options_t());. /// Open a file with `name` for reading and writing. If a file with this name; /// already exists, delete it and create a new one. Else simply create a new file.; ///; /// \note: Synchronizes multi-threaded accesses through locks.; static TFilePtr Recreate(std::string_view name, const Options_t &opts = Options_t());; ```. In the meantime, you should indeed start getting familiar with the testing infrastructure. See io/io/test for some examples.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14017#issuecomment-1821818413
Testability,test,tested,"@pcanal I tested with RDataFrame `Snapshot` and a hand-written usage of `TBufferMerger`, writing a quite simple tree. Any ideas what else to test, do we have a more complex benchmark / a production use case?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14034#issuecomment-1803962285
Usability,simpl,simple,"@pcanal I tested with RDataFrame `Snapshot` and a hand-written usage of `TBufferMerger`, writing a quite simple tree. Any ideas what else to test, do we have a more complex benchmark / a production use case?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14034#issuecomment-1803962285
Availability,down,down,"392068. ttreeTBufferMerger 20000000 16; User time (seconds): 404.52; Elapsed (wall clock) time (h:mm:ss or m:ss): 0:30.24; Maximum resident set size (kbytes): 3631212. ttreeTBufferMerger 20000000 16; User time (seconds): 407.27; Elapsed (wall clock) time (h:mm:ss or m:ss): 0:29.89; Maximum resident set size (kbytes): 2579396. ttreeTBufferMerger 20000000 128; User time (seconds): 6726.12; Elapsed (wall clock) time (h:mm:ss or m:ss): 2:11.26; Maximum resident set size (kbytes): 90232780. ttreeTBufferMerger 20000000 128; User time (seconds): 4558.00; Elapsed (wall clock) time (h:mm:ss or m:ss): 1:50.53; Maximum resident set size (kbytes): 34501092. ttreeTBufferMerger 20000000 128; User time (seconds): 4089.10; Elapsed (wall clock) time (h:mm:ss or m:ss): 1:40.39; Maximum resident set size (kbytes): 19870924. ntpl-perf01:/data/hddext4/jonas/20231113; ttreeTBufferMerger 20000000 16; User time (seconds): 406.02; Elapsed (wall clock) time (h:mm:ss or m:ss): 0:59.20; Maximum resident set size (kbytes): 3479780. ttreeTBufferMerger 20000000 16; User time (seconds): 405.00; Elapsed (wall clock) time (h:mm:ss or m:ss): 1:00.22; Maximum resident set size (kbytes): 4285016. ttreeTBufferMerger 20000000 16; User time (seconds): 406.67; Elapsed (wall clock) time (h:mm:ss or m:ss): 1:00.26; Maximum resident set size (kbytes): 2565488. ttreeTBufferMerger 20000000 128; User time (seconds): 6967.42; Elapsed (wall clock) time (h:mm:ss or m:ss): 4:35.79; Maximum resident set size (kbytes): 89252804. ttreeTBufferMerger 20000000 128; User time (seconds): 4209.07; Elapsed (wall clock) time (h:mm:ss or m:ss): 4:37.90; Maximum resident set size (kbytes): 39543736. ttreeTBufferMerger 20000000 128; User time (seconds): 3700.49; Elapsed (wall clock) time (h:mm:ss or m:ss): 4:34.74; Maximum resident set size (kbytes): 20422848; ```; </details>. My conclusion would be that memory goes down everywhere (as expected) and, especially for higher thread counts and faster storage, we even gain performance",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14034#issuecomment-1808248792
Performance,queue,queue,"Some measurements from `ntpl-perf01`; `ttreeTBufferMerger` is a simple program that writes 20000000 entries (2 branches) with each thread. The first timing is with `master`, then the first commit from this PR, and finally the second commit (removing the queue):; <details>; <summary>full data</summary>. ```; ntpl-perf01:/data/ssdext4/jonas/20231113; ttreeTBufferMerger 20000000 16; User time (seconds): 406.16; Elapsed (wall clock) time (h:mm:ss or m:ss): 0:30.30; Maximum resident set size (kbytes): 3392068. ttreeTBufferMerger 20000000 16; User time (seconds): 404.52; Elapsed (wall clock) time (h:mm:ss or m:ss): 0:30.24; Maximum resident set size (kbytes): 3631212. ttreeTBufferMerger 20000000 16; User time (seconds): 407.27; Elapsed (wall clock) time (h:mm:ss or m:ss): 0:29.89; Maximum resident set size (kbytes): 2579396. ttreeTBufferMerger 20000000 128; User time (seconds): 6726.12; Elapsed (wall clock) time (h:mm:ss or m:ss): 2:11.26; Maximum resident set size (kbytes): 90232780. ttreeTBufferMerger 20000000 128; User time (seconds): 4558.00; Elapsed (wall clock) time (h:mm:ss or m:ss): 1:50.53; Maximum resident set size (kbytes): 34501092. ttreeTBufferMerger 20000000 128; User time (seconds): 4089.10; Elapsed (wall clock) time (h:mm:ss or m:ss): 1:40.39; Maximum resident set size (kbytes): 19870924. ntpl-perf01:/data/hddext4/jonas/20231113; ttreeTBufferMerger 20000000 16; User time (seconds): 406.02; Elapsed (wall clock) time (h:mm:ss or m:ss): 0:59.20; Maximum resident set size (kbytes): 3479780. ttreeTBufferMerger 20000000 16; User time (seconds): 405.00; Elapsed (wall clock) time (h:mm:ss or m:ss): 1:00.22; Maximum resident set size (kbytes): 4285016. ttreeTBufferMerger 20000000 16; User time (seconds): 406.67; Elapsed (wall clock) time (h:mm:ss or m:ss): 1:00.26; Maximum resident set size (kbytes): 2565488. ttreeTBufferMerger 20000000 128; User time (seconds): 6967.42; Elapsed (wall clock) time (h:mm:ss or m:ss): 4:35.79; Maximum resident set size (kbytes): 892528",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14034#issuecomment-1808248792
Usability,simpl,simple,"Some measurements from `ntpl-perf01`; `ttreeTBufferMerger` is a simple program that writes 20000000 entries (2 branches) with each thread. The first timing is with `master`, then the first commit from this PR, and finally the second commit (removing the queue):; <details>; <summary>full data</summary>. ```; ntpl-perf01:/data/ssdext4/jonas/20231113; ttreeTBufferMerger 20000000 16; User time (seconds): 406.16; Elapsed (wall clock) time (h:mm:ss or m:ss): 0:30.30; Maximum resident set size (kbytes): 3392068. ttreeTBufferMerger 20000000 16; User time (seconds): 404.52; Elapsed (wall clock) time (h:mm:ss or m:ss): 0:30.24; Maximum resident set size (kbytes): 3631212. ttreeTBufferMerger 20000000 16; User time (seconds): 407.27; Elapsed (wall clock) time (h:mm:ss or m:ss): 0:29.89; Maximum resident set size (kbytes): 2579396. ttreeTBufferMerger 20000000 128; User time (seconds): 6726.12; Elapsed (wall clock) time (h:mm:ss or m:ss): 2:11.26; Maximum resident set size (kbytes): 90232780. ttreeTBufferMerger 20000000 128; User time (seconds): 4558.00; Elapsed (wall clock) time (h:mm:ss or m:ss): 1:50.53; Maximum resident set size (kbytes): 34501092. ttreeTBufferMerger 20000000 128; User time (seconds): 4089.10; Elapsed (wall clock) time (h:mm:ss or m:ss): 1:40.39; Maximum resident set size (kbytes): 19870924. ntpl-perf01:/data/hddext4/jonas/20231113; ttreeTBufferMerger 20000000 16; User time (seconds): 406.02; Elapsed (wall clock) time (h:mm:ss or m:ss): 0:59.20; Maximum resident set size (kbytes): 3479780. ttreeTBufferMerger 20000000 16; User time (seconds): 405.00; Elapsed (wall clock) time (h:mm:ss or m:ss): 1:00.22; Maximum resident set size (kbytes): 4285016. ttreeTBufferMerger 20000000 16; User time (seconds): 406.67; Elapsed (wall clock) time (h:mm:ss or m:ss): 1:00.26; Maximum resident set size (kbytes): 2565488. ttreeTBufferMerger 20000000 128; User time (seconds): 6967.42; Elapsed (wall clock) time (h:mm:ss or m:ss): 4:35.79; Maximum resident set size (kbytes): 892528",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14034#issuecomment-1808248792
Energy Efficiency,efficient,efficient,"I think that is sufficient efficient evidence albeit there is one more simple test to do, is to introduce a synchronization point every once in a while to insure that the queue is actually filled/used and then later emptied.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14034#issuecomment-1821703597
Integrability,synchroniz,synchronization,"I think that is sufficient efficient evidence albeit there is one more simple test to do, is to introduce a synchronization point every once in a while to insure that the queue is actually filled/used and then later emptied.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14034#issuecomment-1821703597
Performance,queue,queue,"I think that is sufficient efficient evidence albeit there is one more simple test to do, is to introduce a synchronization point every once in a while to insure that the queue is actually filled/used and then later emptied.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14034#issuecomment-1821703597
Testability,test,test,"I think that is sufficient efficient evidence albeit there is one more simple test to do, is to introduce a synchronization point every once in a while to insure that the queue is actually filled/used and then later emptied.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14034#issuecomment-1821703597
Usability,simpl,simple,"I think that is sufficient efficient evidence albeit there is one more simple test to do, is to introduce a synchronization point every once in a while to insure that the queue is actually filled/used and then later emptied.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14034#issuecomment-1821703597
Energy Efficiency,efficient,efficient,"> I think that is sufficient efficient evidence albeit there is one more simple test to do, is to introduce a synchronization point every once in a while to insure that the queue is actually filled/used and then later emptied. Right; for this I went back to the variant of the benchmark that has perfectly balanced time per event and fills identical data into 10 branches. Then I added barriers around the call to `TBufferMergerFile::Write()` to make sure there is as much synchronization and contention as possible. With that, only the run with 64 threads on `/data/ssdext4` is measurably slower (4m16s instead of 3m57s, 9%), lower numbers of threads show very similar performance within noise. However, I then realized that the second barrier after the call to `Write()` is actually not necessary since we want contention when going into the merging / queuing, but the second barrier prevents threads that exit merging early from making further progress. With *only one barrier* before the call to `TBufferMergerFile::Write()` the version without any queuing is consistently faster at higher thread counts. I think this supports my hypothesis that things will balance out automagically. Finally, on `/data/hddext4/` I cannot measure any difference at all outside of noise.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14034#issuecomment-1823482567
Integrability,synchroniz,synchronization,"> I think that is sufficient efficient evidence albeit there is one more simple test to do, is to introduce a synchronization point every once in a while to insure that the queue is actually filled/used and then later emptied. Right; for this I went back to the variant of the benchmark that has perfectly balanced time per event and fills identical data into 10 branches. Then I added barriers around the call to `TBufferMergerFile::Write()` to make sure there is as much synchronization and contention as possible. With that, only the run with 64 threads on `/data/ssdext4` is measurably slower (4m16s instead of 3m57s, 9%), lower numbers of threads show very similar performance within noise. However, I then realized that the second barrier after the call to `Write()` is actually not necessary since we want contention when going into the merging / queuing, but the second barrier prevents threads that exit merging early from making further progress. With *only one barrier* before the call to `TBufferMergerFile::Write()` the version without any queuing is consistently faster at higher thread counts. I think this supports my hypothesis that things will balance out automagically. Finally, on `/data/hddext4/` I cannot measure any difference at all outside of noise.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14034#issuecomment-1823482567
Performance,queue,queue,"> I think that is sufficient efficient evidence albeit there is one more simple test to do, is to introduce a synchronization point every once in a while to insure that the queue is actually filled/used and then later emptied. Right; for this I went back to the variant of the benchmark that has perfectly balanced time per event and fills identical data into 10 branches. Then I added barriers around the call to `TBufferMergerFile::Write()` to make sure there is as much synchronization and contention as possible. With that, only the run with 64 threads on `/data/ssdext4` is measurably slower (4m16s instead of 3m57s, 9%), lower numbers of threads show very similar performance within noise. However, I then realized that the second barrier after the call to `Write()` is actually not necessary since we want contention when going into the merging / queuing, but the second barrier prevents threads that exit merging early from making further progress. With *only one barrier* before the call to `TBufferMergerFile::Write()` the version without any queuing is consistently faster at higher thread counts. I think this supports my hypothesis that things will balance out automagically. Finally, on `/data/hddext4/` I cannot measure any difference at all outside of noise.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14034#issuecomment-1823482567
Testability,test,test,"> I think that is sufficient efficient evidence albeit there is one more simple test to do, is to introduce a synchronization point every once in a while to insure that the queue is actually filled/used and then later emptied. Right; for this I went back to the variant of the benchmark that has perfectly balanced time per event and fills identical data into 10 branches. Then I added barriers around the call to `TBufferMergerFile::Write()` to make sure there is as much synchronization and contention as possible. With that, only the run with 64 threads on `/data/ssdext4` is measurably slower (4m16s instead of 3m57s, 9%), lower numbers of threads show very similar performance within noise. However, I then realized that the second barrier after the call to `Write()` is actually not necessary since we want contention when going into the merging / queuing, but the second barrier prevents threads that exit merging early from making further progress. With *only one barrier* before the call to `TBufferMergerFile::Write()` the version without any queuing is consistently faster at higher thread counts. I think this supports my hypothesis that things will balance out automagically. Finally, on `/data/hddext4/` I cannot measure any difference at all outside of noise.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14034#issuecomment-1823482567
Usability,simpl,simple,"> I think that is sufficient efficient evidence albeit there is one more simple test to do, is to introduce a synchronization point every once in a while to insure that the queue is actually filled/used and then later emptied. Right; for this I went back to the variant of the benchmark that has perfectly balanced time per event and fills identical data into 10 branches. Then I added barriers around the call to `TBufferMergerFile::Write()` to make sure there is as much synchronization and contention as possible. With that, only the run with 64 threads on `/data/ssdext4` is measurably slower (4m16s instead of 3m57s, 9%), lower numbers of threads show very similar performance within noise. However, I then realized that the second barrier after the call to `Write()` is actually not necessary since we want contention when going into the merging / queuing, but the second barrier prevents threads that exit merging early from making further progress. With *only one barrier* before the call to `TBufferMergerFile::Write()` the version without any queuing is consistently faster at higher thread counts. I think this supports my hypothesis that things will balance out automagically. Finally, on `/data/hddext4/` I cannot measure any difference at all outside of noise.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14034#issuecomment-1823482567
Deployability,install,installed,"I believe the real issue here is about user experience. Suppose I'm a mac user, I only use safari and don't even have chrome installed. I have been using ROOT for 10+ years, I want to see my plot in a canvas. Now the default canvas is the web canvas, so it will go through the only browser it can find on my machine, safari. That breaks functionality w.r.t. how I was using the canvas before. So, that's something we want to fix, right?. In general, I would imagine that at the very least for the three most commonly used browsers i.e. Chrome, Safari, Firefox (Edge even?) we should be able to provide exactly the same functionality to users. Writing in the documentation that they need to install google chrome on their machine in order to have a properly working canvas is not an option in my opinion. Practically, that would imply that ROOT has a dependency on Chrome and I don't think that's what we want",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14051#issuecomment-1813149328
Integrability,depend,dependency,"I believe the real issue here is about user experience. Suppose I'm a mac user, I only use safari and don't even have chrome installed. I have been using ROOT for 10+ years, I want to see my plot in a canvas. Now the default canvas is the web canvas, so it will go through the only browser it can find on my machine, safari. That breaks functionality w.r.t. how I was using the canvas before. So, that's something we want to fix, right?. In general, I would imagine that at the very least for the three most commonly used browsers i.e. Chrome, Safari, Firefox (Edge even?) we should be able to provide exactly the same functionality to users. Writing in the documentation that they need to install google chrome on their machine in order to have a properly working canvas is not an option in my opinion. Practically, that would imply that ROOT has a dependency on Chrome and I don't think that's what we want",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14051#issuecomment-1813149328
Usability,user experience,user experience,"I believe the real issue here is about user experience. Suppose I'm a mac user, I only use safari and don't even have chrome installed. I have been using ROOT for 10+ years, I want to see my plot in a canvas. Now the default canvas is the web canvas, so it will go through the only browser it can find on my machine, safari. That breaks functionality w.r.t. how I was using the canvas before. So, that's something we want to fix, right?. In general, I would imagine that at the very least for the three most commonly used browsers i.e. Chrome, Safari, Firefox (Edge even?) we should be able to provide exactly the same functionality to users. Writing in the documentation that they need to install google chrome on their machine in order to have a properly working canvas is not an option in my opinion. Practically, that would imply that ROOT has a dependency on Chrome and I don't think that's what we want",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14051#issuecomment-1813149328
Modifiability,variab,variables,"> In particular, I tried to add a trivial unit test file [...] and compiling as the other ones, i.e. linking it to [...] makes the sanitiser running the test still complain as above. Depending on how you compile it, you might get `-fsanitize=address` from the ROOT C++ flags. But in general yes, the libraries are sanitized and will operate no matter if your application itself is built with sanitizers or not. > I guess I could create a standalone hello-world C++ code and compile it with the sanitiser linking to ROOT as our unit test does and I should get the same report. Let me know if you need so. That would be as expected, so I don't think it's worth the effort. > Now, this behaviour (leaking just linking) should make it not too difficult to locate the issue. Do you do something [with globals or static variables](https://stackoverflow.com/a/8353892/14967071)? Or do you have [a `_init` and/or `_fini` function](https://stackoverflow.com/a/6412445/14967071)?. As explained before, what the AddressSanitizer is complaining about is well understood and it also doesn't explain growing memory usage when not interacting with ROOT. This latter is what needs a clear reproducer to dig out the problem.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14055#issuecomment-1818478493
Security,sanitiz,sanitized,"> In particular, I tried to add a trivial unit test file [...] and compiling as the other ones, i.e. linking it to [...] makes the sanitiser running the test still complain as above. Depending on how you compile it, you might get `-fsanitize=address` from the ROOT C++ flags. But in general yes, the libraries are sanitized and will operate no matter if your application itself is built with sanitizers or not. > I guess I could create a standalone hello-world C++ code and compile it with the sanitiser linking to ROOT as our unit test does and I should get the same report. Let me know if you need so. That would be as expected, so I don't think it's worth the effort. > Now, this behaviour (leaking just linking) should make it not too difficult to locate the issue. Do you do something [with globals or static variables](https://stackoverflow.com/a/8353892/14967071)? Or do you have [a `_init` and/or `_fini` function](https://stackoverflow.com/a/6412445/14967071)?. As explained before, what the AddressSanitizer is complaining about is well understood and it also doesn't explain growing memory usage when not interacting with ROOT. This latter is what needs a clear reproducer to dig out the problem.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14055#issuecomment-1818478493
Testability,test,test,"> In particular, I tried to add a trivial unit test file [...] and compiling as the other ones, i.e. linking it to [...] makes the sanitiser running the test still complain as above. Depending on how you compile it, you might get `-fsanitize=address` from the ROOT C++ flags. But in general yes, the libraries are sanitized and will operate no matter if your application itself is built with sanitizers or not. > I guess I could create a standalone hello-world C++ code and compile it with the sanitiser linking to ROOT as our unit test does and I should get the same report. Let me know if you need so. That would be as expected, so I don't think it's worth the effort. > Now, this behaviour (leaking just linking) should make it not too difficult to locate the issue. Do you do something [with globals or static variables](https://stackoverflow.com/a/8353892/14967071)? Or do you have [a `_init` and/or `_fini` function](https://stackoverflow.com/a/6412445/14967071)?. As explained before, what the AddressSanitizer is complaining about is well understood and it also doesn't explain growing memory usage when not interacting with ROOT. This latter is what needs a clear reproducer to dig out the problem.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14055#issuecomment-1818478493
Usability,clear,clear,"> In particular, I tried to add a trivial unit test file [...] and compiling as the other ones, i.e. linking it to [...] makes the sanitiser running the test still complain as above. Depending on how you compile it, you might get `-fsanitize=address` from the ROOT C++ flags. But in general yes, the libraries are sanitized and will operate no matter if your application itself is built with sanitizers or not. > I guess I could create a standalone hello-world C++ code and compile it with the sanitiser linking to ROOT as our unit test does and I should get the same report. Let me know if you need so. That would be as expected, so I don't think it's worth the effort. > Now, this behaviour (leaking just linking) should make it not too difficult to locate the issue. Do you do something [with globals or static variables](https://stackoverflow.com/a/8353892/14967071)? Or do you have [a `_init` and/or `_fini` function](https://stackoverflow.com/a/6412445/14967071)?. As explained before, what the AddressSanitizer is complaining about is well understood and it also doesn't explain growing memory usage when not interacting with ROOT. This latter is what needs a clear reproducer to dig out the problem.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14055#issuecomment-1818478493
Usability,clear,clear,"> This latter is what needs a clear reproducer to dig out the problem. I agree. This is actually what I was meaning by making an hello-world program **that does not use ROOT**, compile it linking to ROOT and with sanitiser on, and see if the same leak report is given. I would expect so and, if not, then there is something I definitely do not get in our application. ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14055#issuecomment-1818495744
Deployability,update,updates,"@AxelKrypton any updates on this? Looking over the past discussion, we are aware of the (intentional) memory leaks in `libCling` (even though we fixed one case in https://github.com/root-project/root/pull/16150 that was a mistake; the fix will appear in 6.34). I still have trouble understanding how just linking to ROOT and not using it should introduce a memory leak in the application... Lacking more feedback, I would propose to close this issue for the moment...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14055#issuecomment-2370819124
Usability,feedback,feedback,"@AxelKrypton any updates on this? Looking over the past discussion, we are aware of the (intentional) memory leaks in `libCling` (even though we fixed one case in https://github.com/root-project/root/pull/16150 that was a mistake; the fix will appear in 6.34). I still have trouble understanding how just linking to ROOT and not using it should introduce a memory leak in the application... Lacking more feedback, I would propose to close this issue for the moment...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14055#issuecomment-2370819124
Testability,test,test,"> Do you mean that the sanitiser report when running the following unit test; > ; > ```c++; > #include ""vir/test.h"" // This include has to be first -> https://github.com/mattkretz/virtest; > ; > TEST(){ std::cout << ""Hello world\n""; }; > ```; > ; > compiled linking to ROOT is about the leakage you usually suppress? . I just tried and with this simple example I don't see anything, which is totally expected because it doesn't even initialize ROOT. The other reports that you provided before were the leakage we know about, or in the case of `TemplateIdAnnotation` are fixed by https://github.com/root-project/root/pull/16150. > Still [the reported leakage above](https://github.com/root-project/root/issues/14055#issuecomment-1814642915) is a real one which appeared in `v6.28` and was not there in `v6.26`. Yes, that's why I didn't close the issue back then and came across this when re-evaluating open issues. I totally understand that creating a reproducer takes time, but I fear without it there isn't much we can do without it...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14055#issuecomment-2371254649
Usability,simpl,simple,"> Do you mean that the sanitiser report when running the following unit test; > ; > ```c++; > #include ""vir/test.h"" // This include has to be first -> https://github.com/mattkretz/virtest; > ; > TEST(){ std::cout << ""Hello world\n""; }; > ```; > ; > compiled linking to ROOT is about the leakage you usually suppress? . I just tried and with this simple example I don't see anything, which is totally expected because it doesn't even initialize ROOT. The other reports that you provided before were the leakage we know about, or in the case of `TemplateIdAnnotation` are fixed by https://github.com/root-project/root/pull/16150. > Still [the reported leakage above](https://github.com/root-project/root/issues/14055#issuecomment-1814642915) is a real one which appeared in `v6.28` and was not there in `v6.26`. Yes, that's why I didn't close the issue back then and came across this when re-evaluating open issues. I totally understand that creating a reproducer takes time, but I fear without it there isn't much we can do without it...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14055#issuecomment-2371254649
Usability,simpl,simple,"> I just tried and with this simple example I don't see anything, which is totally expected because it doesn't even initialize ROOT. The other reports that you provided before were the leakage we know about, or in the case of TemplateIdAnnotation are fixed by https://github.com/root-project/root/pull/16150. Thanks. I guess what I get from the sanitiser is what you suppress. This clarifies further the situation. > I totally understand that creating a reproducer takes time, but I fear without it there isn't much we can do without it... Fair enough. I will try to find some spare hours for this. In the best case scenario ROOT `6.34` does not show the problem and I can leave here a comment and close the issue... ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14055#issuecomment-2371268142
Availability,failure,failure,"@hahnjo I did not want to let this sit for too long and as days ahead are even busier for me I invested now some more time on this. The good news is that I can pretty confidently say that the memory leak reported [above in the left plot](https://github.com/root-project/root/issues/14055#issuecomment-1814642915) has nothing to do with ROOT  and it was an unlucky coincidence which made me think it is due to ROOT.  I still have to understand this memory behaviour in detail, but it is off-topic here.  . I was about simply closing the issue, when I remembered checking old issues in our project that our tests were just passing with ROOT `v6.26` and started to fail reporting the above mentioned sanitiser complaint from `v6.28`. I now checked and these failure occur as well with `v6.30` and `v6.32`. As far as I understand from our exchange above, we can safely suppress these adding `leak:libCling'` to `lsan-root.supp` file (I would not exclude more than the bare minimum in order to avoid suppress potential real problems/errors in the future). However, I would like to ask you a feedback about the fact this suppression was not necessary in `v6.26`. Is this expected for you? ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14055#issuecomment-2379654469
Safety,safe,safely,"@hahnjo I did not want to let this sit for too long and as days ahead are even busier for me I invested now some more time on this. The good news is that I can pretty confidently say that the memory leak reported [above in the left plot](https://github.com/root-project/root/issues/14055#issuecomment-1814642915) has nothing to do with ROOT  and it was an unlucky coincidence which made me think it is due to ROOT.  I still have to understand this memory behaviour in detail, but it is off-topic here.  . I was about simply closing the issue, when I remembered checking old issues in our project that our tests were just passing with ROOT `v6.26` and started to fail reporting the above mentioned sanitiser complaint from `v6.28`. I now checked and these failure occur as well with `v6.30` and `v6.32`. As far as I understand from our exchange above, we can safely suppress these adding `leak:libCling'` to `lsan-root.supp` file (I would not exclude more than the bare minimum in order to avoid suppress potential real problems/errors in the future). However, I would like to ask you a feedback about the fact this suppression was not necessary in `v6.26`. Is this expected for you? ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14055#issuecomment-2379654469
Testability,test,tests,"@hahnjo I did not want to let this sit for too long and as days ahead are even busier for me I invested now some more time on this. The good news is that I can pretty confidently say that the memory leak reported [above in the left plot](https://github.com/root-project/root/issues/14055#issuecomment-1814642915) has nothing to do with ROOT  and it was an unlucky coincidence which made me think it is due to ROOT.  I still have to understand this memory behaviour in detail, but it is off-topic here.  . I was about simply closing the issue, when I remembered checking old issues in our project that our tests were just passing with ROOT `v6.26` and started to fail reporting the above mentioned sanitiser complaint from `v6.28`. I now checked and these failure occur as well with `v6.30` and `v6.32`. As far as I understand from our exchange above, we can safely suppress these adding `leak:libCling'` to `lsan-root.supp` file (I would not exclude more than the bare minimum in order to avoid suppress potential real problems/errors in the future). However, I would like to ask you a feedback about the fact this suppression was not necessary in `v6.26`. Is this expected for you? ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14055#issuecomment-2379654469
Usability,simpl,simply,"@hahnjo I did not want to let this sit for too long and as days ahead are even busier for me I invested now some more time on this. The good news is that I can pretty confidently say that the memory leak reported [above in the left plot](https://github.com/root-project/root/issues/14055#issuecomment-1814642915) has nothing to do with ROOT  and it was an unlucky coincidence which made me think it is due to ROOT.  I still have to understand this memory behaviour in detail, but it is off-topic here.  . I was about simply closing the issue, when I remembered checking old issues in our project that our tests were just passing with ROOT `v6.26` and started to fail reporting the above mentioned sanitiser complaint from `v6.28`. I now checked and these failure occur as well with `v6.30` and `v6.32`. As far as I understand from our exchange above, we can safely suppress these adding `leak:libCling'` to `lsan-root.supp` file (I would not exclude more than the bare minimum in order to avoid suppress potential real problems/errors in the future). However, I would like to ask you a feedback about the fact this suppression was not necessary in `v6.26`. Is this expected for you? ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14055#issuecomment-2379654469
Availability,failure,failure,"> @hahnjo I did not want to let this sit for too long and as days ahead are even busier for me I invested now some more time on this. The good news is that I can pretty confidently say that the memory leak reported [above in the left plot](https://github.com/root-project/root/issues/14055#issuecomment-1814642915) has nothing to do with ROOT  and it was an unlucky coincidence which made me think it is due to ROOT.  I still have to understand this memory behaviour in detail, but it is off-topic here. . Ok, thanks for cross-checking!. > I was about simply closing the issue, when I remembered checking old issues in our project that our tests were just passing with ROOT `v6.26` and started to fail reporting the above mentioned sanitiser complaint from `v6.28`. I now checked and these failure occur as well with `v6.30` and `v6.32`. As far as I understand from our exchange above, we can safely suppress these adding `leak:libCling'` to `lsan-root.supp` file (I would not exclude more than the bare minimum in order to avoid suppress potential real problems/errors in the future). Yes, I believe from an application point of view, you can treat `libCling` as a black box. > However, I would like to ask you a feedback about the fact this suppression was not necessary in `v6.26`. Is this expected for you? . If the leaks are about `TemplateId` (as they were in the log file(s) you shared), then yes this is a problem we introduced in v6.28. It was eventually fixed in https://github.com/root-project/root/pull/16150 which will appear in v6.34 (later this year). Sorry for not recognizing this as a real problem earlier (the fix was also made difficult because it was ""caused"" by an upstream change in LLVM/Clang when we upgraded).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14055#issuecomment-2382239702
Deployability,upgrade,upgraded,"> @hahnjo I did not want to let this sit for too long and as days ahead are even busier for me I invested now some more time on this. The good news is that I can pretty confidently say that the memory leak reported [above in the left plot](https://github.com/root-project/root/issues/14055#issuecomment-1814642915) has nothing to do with ROOT  and it was an unlucky coincidence which made me think it is due to ROOT.  I still have to understand this memory behaviour in detail, but it is off-topic here. . Ok, thanks for cross-checking!. > I was about simply closing the issue, when I remembered checking old issues in our project that our tests were just passing with ROOT `v6.26` and started to fail reporting the above mentioned sanitiser complaint from `v6.28`. I now checked and these failure occur as well with `v6.30` and `v6.32`. As far as I understand from our exchange above, we can safely suppress these adding `leak:libCling'` to `lsan-root.supp` file (I would not exclude more than the bare minimum in order to avoid suppress potential real problems/errors in the future). Yes, I believe from an application point of view, you can treat `libCling` as a black box. > However, I would like to ask you a feedback about the fact this suppression was not necessary in `v6.26`. Is this expected for you? . If the leaks are about `TemplateId` (as they were in the log file(s) you shared), then yes this is a problem we introduced in v6.28. It was eventually fixed in https://github.com/root-project/root/pull/16150 which will appear in v6.34 (later this year). Sorry for not recognizing this as a real problem earlier (the fix was also made difficult because it was ""caused"" by an upstream change in LLVM/Clang when we upgraded).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14055#issuecomment-2382239702
Safety,safe,safely,"> @hahnjo I did not want to let this sit for too long and as days ahead are even busier for me I invested now some more time on this. The good news is that I can pretty confidently say that the memory leak reported [above in the left plot](https://github.com/root-project/root/issues/14055#issuecomment-1814642915) has nothing to do with ROOT  and it was an unlucky coincidence which made me think it is due to ROOT.  I still have to understand this memory behaviour in detail, but it is off-topic here. . Ok, thanks for cross-checking!. > I was about simply closing the issue, when I remembered checking old issues in our project that our tests were just passing with ROOT `v6.26` and started to fail reporting the above mentioned sanitiser complaint from `v6.28`. I now checked and these failure occur as well with `v6.30` and `v6.32`. As far as I understand from our exchange above, we can safely suppress these adding `leak:libCling'` to `lsan-root.supp` file (I would not exclude more than the bare minimum in order to avoid suppress potential real problems/errors in the future). Yes, I believe from an application point of view, you can treat `libCling` as a black box. > However, I would like to ask you a feedback about the fact this suppression was not necessary in `v6.26`. Is this expected for you? . If the leaks are about `TemplateId` (as they were in the log file(s) you shared), then yes this is a problem we introduced in v6.28. It was eventually fixed in https://github.com/root-project/root/pull/16150 which will appear in v6.34 (later this year). Sorry for not recognizing this as a real problem earlier (the fix was also made difficult because it was ""caused"" by an upstream change in LLVM/Clang when we upgraded).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14055#issuecomment-2382239702
Testability,test,tests,"> @hahnjo I did not want to let this sit for too long and as days ahead are even busier for me I invested now some more time on this. The good news is that I can pretty confidently say that the memory leak reported [above in the left plot](https://github.com/root-project/root/issues/14055#issuecomment-1814642915) has nothing to do with ROOT  and it was an unlucky coincidence which made me think it is due to ROOT.  I still have to understand this memory behaviour in detail, but it is off-topic here. . Ok, thanks for cross-checking!. > I was about simply closing the issue, when I remembered checking old issues in our project that our tests were just passing with ROOT `v6.26` and started to fail reporting the above mentioned sanitiser complaint from `v6.28`. I now checked and these failure occur as well with `v6.30` and `v6.32`. As far as I understand from our exchange above, we can safely suppress these adding `leak:libCling'` to `lsan-root.supp` file (I would not exclude more than the bare minimum in order to avoid suppress potential real problems/errors in the future). Yes, I believe from an application point of view, you can treat `libCling` as a black box. > However, I would like to ask you a feedback about the fact this suppression was not necessary in `v6.26`. Is this expected for you? . If the leaks are about `TemplateId` (as they were in the log file(s) you shared), then yes this is a problem we introduced in v6.28. It was eventually fixed in https://github.com/root-project/root/pull/16150 which will appear in v6.34 (later this year). Sorry for not recognizing this as a real problem earlier (the fix was also made difficult because it was ""caused"" by an upstream change in LLVM/Clang when we upgraded).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14055#issuecomment-2382239702
Usability,simpl,simply,"> @hahnjo I did not want to let this sit for too long and as days ahead are even busier for me I invested now some more time on this. The good news is that I can pretty confidently say that the memory leak reported [above in the left plot](https://github.com/root-project/root/issues/14055#issuecomment-1814642915) has nothing to do with ROOT  and it was an unlucky coincidence which made me think it is due to ROOT.  I still have to understand this memory behaviour in detail, but it is off-topic here. . Ok, thanks for cross-checking!. > I was about simply closing the issue, when I remembered checking old issues in our project that our tests were just passing with ROOT `v6.26` and started to fail reporting the above mentioned sanitiser complaint from `v6.28`. I now checked and these failure occur as well with `v6.30` and `v6.32`. As far as I understand from our exchange above, we can safely suppress these adding `leak:libCling'` to `lsan-root.supp` file (I would not exclude more than the bare minimum in order to avoid suppress potential real problems/errors in the future). Yes, I believe from an application point of view, you can treat `libCling` as a black box. > However, I would like to ask you a feedback about the fact this suppression was not necessary in `v6.26`. Is this expected for you? . If the leaks are about `TemplateId` (as they were in the log file(s) you shared), then yes this is a problem we introduced in v6.28. It was eventually fixed in https://github.com/root-project/root/pull/16150 which will appear in v6.34 (later this year). Sorry for not recognizing this as a real problem earlier (the fix was also made difficult because it was ""caused"" by an upstream change in LLVM/Clang when we upgraded).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14055#issuecomment-2382239702
Deployability,release,release,"At some point we want people to migrate to the new iterators, becuase as Stephan showed in the past, they are also faster. As far as feedback goes, there is quite a long time to receive it. Now, we have about 1 year until the release of ROOT 6.32 where pro users will see the warnings in `master`, and then another year the warning would be in the released ROOT 6.32. The warning explicitly states that the legacy iterators will be removed in 6.34. So if this deprecation is really a problem, people will complain and we can ""un-deprecate"" if needed.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14071#issuecomment-1816447278
Usability,feedback,feedback,"At some point we want people to migrate to the new iterators, becuase as Stephan showed in the past, they are also faster. As far as feedback goes, there is quite a long time to receive it. Now, we have about 1 year until the release of ROOT 6.32 where pro users will see the warnings in `master`, and then another year the warning would be in the released ROOT 6.32. The warning explicitly states that the legacy iterators will be removed in 6.34. So if this deprecation is really a problem, people will complain and we can ""un-deprecate"" if needed.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14071#issuecomment-1816447278
Deployability,configurat,configuration,"Thanks for the review!. > Are all RooStats tutorials dependent on XML ? I think some of them, not using the HIstFactory to create the input workspace, could work without XML. Anyway for simplicity is probably better excluding all if XML is not present. No, not all of them. In the past, I think Windows was built without XML, so it was more important to be pedantic with the vetos there to have at least some test coverage of RooStats on Windows. Nowadays, no test configuration has `xml=OFF` anyway. > Thanks for simplifying the rs401d to use the RooGenericPdf. In the past it was too slow to use with CINT the generic PDF, now with Cling should not be a problem. Yes, I measured the timing, and there was no slowdown from using `RooGenericPdf` in this particular case!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14074#issuecomment-1818475645
Integrability,depend,dependent,"Thanks for the review!. > Are all RooStats tutorials dependent on XML ? I think some of them, not using the HIstFactory to create the input workspace, could work without XML. Anyway for simplicity is probably better excluding all if XML is not present. No, not all of them. In the past, I think Windows was built without XML, so it was more important to be pedantic with the vetos there to have at least some test coverage of RooStats on Windows. Nowadays, no test configuration has `xml=OFF` anyway. > Thanks for simplifying the rs401d to use the RooGenericPdf. In the past it was too slow to use with CINT the generic PDF, now with Cling should not be a problem. Yes, I measured the timing, and there was no slowdown from using `RooGenericPdf` in this particular case!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14074#issuecomment-1818475645
Modifiability,config,configuration,"Thanks for the review!. > Are all RooStats tutorials dependent on XML ? I think some of them, not using the HIstFactory to create the input workspace, could work without XML. Anyway for simplicity is probably better excluding all if XML is not present. No, not all of them. In the past, I think Windows was built without XML, so it was more important to be pedantic with the vetos there to have at least some test coverage of RooStats on Windows. Nowadays, no test configuration has `xml=OFF` anyway. > Thanks for simplifying the rs401d to use the RooGenericPdf. In the past it was too slow to use with CINT the generic PDF, now with Cling should not be a problem. Yes, I measured the timing, and there was no slowdown from using `RooGenericPdf` in this particular case!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14074#issuecomment-1818475645
Testability,test,test,"Thanks for the review!. > Are all RooStats tutorials dependent on XML ? I think some of them, not using the HIstFactory to create the input workspace, could work without XML. Anyway for simplicity is probably better excluding all if XML is not present. No, not all of them. In the past, I think Windows was built without XML, so it was more important to be pedantic with the vetos there to have at least some test coverage of RooStats on Windows. Nowadays, no test configuration has `xml=OFF` anyway. > Thanks for simplifying the rs401d to use the RooGenericPdf. In the past it was too slow to use with CINT the generic PDF, now with Cling should not be a problem. Yes, I measured the timing, and there was no slowdown from using `RooGenericPdf` in this particular case!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14074#issuecomment-1818475645
Usability,simpl,simplicity,"Thanks for the review!. > Are all RooStats tutorials dependent on XML ? I think some of them, not using the HIstFactory to create the input workspace, could work without XML. Anyway for simplicity is probably better excluding all if XML is not present. No, not all of them. In the past, I think Windows was built without XML, so it was more important to be pedantic with the vetos there to have at least some test coverage of RooStats on Windows. Nowadays, no test configuration has `xml=OFF` anyway. > Thanks for simplifying the rs401d to use the RooGenericPdf. In the past it was too slow to use with CINT the generic PDF, now with Cling should not be a problem. Yes, I measured the timing, and there was no slowdown from using `RooGenericPdf` in this particular case!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14074#issuecomment-1818475645
Usability,feedback,feedback,"Hi @vepadulano, thanks for your comments! I hope my recent commit, that will be squashed before merging, is addressing your concerns. Unfortunately, the new CI is red because I merged a PR that broke incremental builds :( But we should get feedback from Jenkins if this PR still works with my newest change.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14098#issuecomment-1887156068
Usability,feedback,feedback,"OK, thanks for the feedback",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14113#issuecomment-1891757919
Integrability,interface,interface,"I agree that the interface is somewhat dangerous but the docs clearly mention its limitations. However, dangerous or not, this is currently broken and should be fixed.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14135#issuecomment-1830160591
Usability,clear,clearly,"I agree that the interface is somewhat dangerous but the docs clearly mention its limitations. However, dangerous or not, this is currently broken and should be fixed.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14135#issuecomment-1830160591
Performance,load,load,"@MrCarroll do not worry. These things happen, especially when one is under heavy load at work. Never hesitate to report issues as you encounter them, feedback is very important for us!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14138#issuecomment-1832630669
Usability,feedback,feedback,"@MrCarroll do not worry. These things happen, especially when one is under heavy load at work. Never hesitate to report issues as you encounter them, feedback is very important for us!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14138#issuecomment-1832630669
Usability,simpl,simply,"Well, I do not think it is a graphics issue. Nothing is drawn simply because the number of entries is 0:; ```; root [0] auto h2 = new TH2I(""h2"", ""h2"", 10, 0, 1, 2, 0, 2);; root [1] h2->AddBinContent(16,5); root [2] h2->GetEntries(); (double) 0.0000000; ```; May be @lmoneta may know.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14153#issuecomment-1833962747
Integrability,depend,dependencies,"I can reproduce this in our software stack (SHiP/snd@snd) as well, where ROOTSYS etc. are all set for dependencies that need ROOT at build and/or run-time (using ALICE's alibuild). ROOT and its `ROOTConfig.cmake` are found without issues, but the new way to deal with VDT breaks anyone trying to user `ROOTConfig.cmake`. In our case, we use the `builtin_vdt` build option when building ROOT from source. This is a clear regression from 6.28.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14163#issuecomment-1837223379
Usability,clear,clear,"I can reproduce this in our software stack (SHiP/snd@snd) as well, where ROOTSYS etc. are all set for dependencies that need ROOT at build and/or run-time (using ALICE's alibuild). ROOT and its `ROOTConfig.cmake` are found without issues, but the new way to deal with VDT breaks anyone trying to user `ROOTConfig.cmake`. In our case, we use the `builtin_vdt` build option when building ROOT from source. This is a clear regression from 6.28.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14163#issuecomment-1837223379
Availability,down,down,I boiled down the failures to a simple extension of the issue that I already reported:; https://github.com/vgvassilev/clad/issues/681#issuecomment-1904660655,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14165#issuecomment-1904662806
Usability,simpl,simple,I boiled down the failures to a simple extension of the issue that I already reported:; https://github.com/vgvassilev/clad/issues/681#issuecomment-1904660655,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14165#issuecomment-1904662806
Usability,feedback,feedback,"Unfortunately I am not being paid by CERN, and I am quite overloaded. I have to dedicate my effort to work on the projects I am being paid for. Of course, I can just live with the classes as they are written. I just thought it would be good to dedicate a bit of my time to give you just some feedback/ideas so that you understand how to improve my own user experience. Of course, I understand that my user experience might be different to that of the average user experience, and the ROOT priorities are others. But it is not me who must push for CERN reputation.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14173#issuecomment-1852074907
Deployability,install,installed,"I don't really understand your question. . [tutorials/eve7/boxset.C](https://github.com/root-project/root/blob/master/tutorials/eve7/boxset.C) doesn't seem to need `nlohmann/json.hpp`, does it?. The nlohmann_json ""library"" is a pure header ""library"". It does not need to be distributed with the ROOT binaries for those binaries to be functional. All the symbols from `nlohmann/json.hpp` are compiled into the ROOT binaries themselves. . You ""only"" need `nlohmann/json.hpp` when using a ROOT header in your own build that itself publicly uses `nlohmann/json.hpp`. For that you do need that actual header. So I'm still pretty convinced that this is a relatively simple mistake. The machine on which 6.30 was built, probably had nlohmann_json installed on it recently. And people doing the ROOT binary builds didn't notice that their build now picked up nlohmann_json from the system. This does shine light on a deeper issue though.  The ROOT CMake configuration is a bit too autonomous for my liking.  It will too easily turn features on/off based on what it finds. Instead of asking the user explicitly to specify what they want to have on or off. If it was up to me, I'd remove most of the automation in how the build figures out what it should do, and rather introduce a bunch of [CMake presets](https://cmake.org/cmake/help/latest/manual/cmake-presets.7.html) to ease the life of the users a little. For the latter, we're using those pretty happily in this project for instance:; - https://github.com/acts-project/algebra-plugins/; - https://github.com/acts-project/algebra-plugins/blob/main/CMakePresets.json. Yes, ROOT has a lot more externals than we have in that particular project, but the spaghetti code used for figuring out what would come from where, and what would be turned on or off is also not a great solution. ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14188#issuecomment-1844965943
Modifiability,config,configuration,"I don't really understand your question. . [tutorials/eve7/boxset.C](https://github.com/root-project/root/blob/master/tutorials/eve7/boxset.C) doesn't seem to need `nlohmann/json.hpp`, does it?. The nlohmann_json ""library"" is a pure header ""library"". It does not need to be distributed with the ROOT binaries for those binaries to be functional. All the symbols from `nlohmann/json.hpp` are compiled into the ROOT binaries themselves. . You ""only"" need `nlohmann/json.hpp` when using a ROOT header in your own build that itself publicly uses `nlohmann/json.hpp`. For that you do need that actual header. So I'm still pretty convinced that this is a relatively simple mistake. The machine on which 6.30 was built, probably had nlohmann_json installed on it recently. And people doing the ROOT binary builds didn't notice that their build now picked up nlohmann_json from the system. This does shine light on a deeper issue though.  The ROOT CMake configuration is a bit too autonomous for my liking.  It will too easily turn features on/off based on what it finds. Instead of asking the user explicitly to specify what they want to have on or off. If it was up to me, I'd remove most of the automation in how the build figures out what it should do, and rather introduce a bunch of [CMake presets](https://cmake.org/cmake/help/latest/manual/cmake-presets.7.html) to ease the life of the users a little. For the latter, we're using those pretty happily in this project for instance:; - https://github.com/acts-project/algebra-plugins/; - https://github.com/acts-project/algebra-plugins/blob/main/CMakePresets.json. Yes, ROOT has a lot more externals than we have in that particular project, but the spaghetti code used for figuring out what would come from where, and what would be turned on or off is also not a great solution. ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14188#issuecomment-1844965943
Usability,simpl,simple,"I don't really understand your question. . [tutorials/eve7/boxset.C](https://github.com/root-project/root/blob/master/tutorials/eve7/boxset.C) doesn't seem to need `nlohmann/json.hpp`, does it?. The nlohmann_json ""library"" is a pure header ""library"". It does not need to be distributed with the ROOT binaries for those binaries to be functional. All the symbols from `nlohmann/json.hpp` are compiled into the ROOT binaries themselves. . You ""only"" need `nlohmann/json.hpp` when using a ROOT header in your own build that itself publicly uses `nlohmann/json.hpp`. For that you do need that actual header. So I'm still pretty convinced that this is a relatively simple mistake. The machine on which 6.30 was built, probably had nlohmann_json installed on it recently. And people doing the ROOT binary builds didn't notice that their build now picked up nlohmann_json from the system. This does shine light on a deeper issue though.  The ROOT CMake configuration is a bit too autonomous for my liking.  It will too easily turn features on/off based on what it finds. Instead of asking the user explicitly to specify what they want to have on or off. If it was up to me, I'd remove most of the automation in how the build figures out what it should do, and rather introduce a bunch of [CMake presets](https://cmake.org/cmake/help/latest/manual/cmake-presets.7.html) to ease the life of the users a little. For the latter, we're using those pretty happily in this project for instance:; - https://github.com/acts-project/algebra-plugins/; - https://github.com/acts-project/algebra-plugins/blob/main/CMakePresets.json. Yes, ROOT has a lot more externals than we have in that particular project, but the spaghetti code used for figuring out what would come from where, and what would be turned on or off is also not a great solution. ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14188#issuecomment-1844965943
Deployability,configurat,configuration,"> My question was: is it possible to modify the ROOT-cmake-find script, so that it only forces the nlohmann-json-dependency if you are going to use ROOT7 classes? So to say, that depending on the `REQUIRED COMPONENTS` that you use in the `find_package` statement in your user code, it is more or less 'requiring'. That's an interesting question.  CMake project's can't easily do this. I mean, nothing is impossible, but it's not simple to do. As long as externals are handled through imported library targets (which I'm not sure the nlohmann_json dependency is used with ), one would need to tweak the behaviour of CMake in a pretty fundamental way for this.  You see, when you tell in (in this case) ROOT's build that library `Foo` needs to publicly link against library `Bar::bar`, CMake exports this information in the `ROOTConfig-targets.cmake` file. (That is a file generated fully by CMake itself.) It will say that `Foo` depends on `Bar::bar`. So at that point `ROOTConfig.cmake` has to produce `Bar::bar` in some way. Even if the user's code itself never wants to use the `Foo` library. Because CMake will not like it that it has the `Foo` library defined (even if unused by others), without all of its requirements met. So even if `ROOTConfig.cmake` itself doesn't look for nlohmann_json, if any of the CMake code depends on the `nlhmann::json` target (yes, there is such a target in CMake ), the CMake configuration would still fail. With a complaint about `nlohmann::json` not being known. . So generally, projects that publicly depend on something else, always look for all of those dependencies with [find_dependency(...)](https://cmake.org/cmake/help/latest/module/CMakeFindDependencyMacro.html). Regardless of which parts of the project the user wants to use. ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14188#issuecomment-1845002083
Integrability,depend,dependency,"> My question was: is it possible to modify the ROOT-cmake-find script, so that it only forces the nlohmann-json-dependency if you are going to use ROOT7 classes? So to say, that depending on the `REQUIRED COMPONENTS` that you use in the `find_package` statement in your user code, it is more or less 'requiring'. That's an interesting question.  CMake project's can't easily do this. I mean, nothing is impossible, but it's not simple to do. As long as externals are handled through imported library targets (which I'm not sure the nlohmann_json dependency is used with ), one would need to tweak the behaviour of CMake in a pretty fundamental way for this.  You see, when you tell in (in this case) ROOT's build that library `Foo` needs to publicly link against library `Bar::bar`, CMake exports this information in the `ROOTConfig-targets.cmake` file. (That is a file generated fully by CMake itself.) It will say that `Foo` depends on `Bar::bar`. So at that point `ROOTConfig.cmake` has to produce `Bar::bar` in some way. Even if the user's code itself never wants to use the `Foo` library. Because CMake will not like it that it has the `Foo` library defined (even if unused by others), without all of its requirements met. So even if `ROOTConfig.cmake` itself doesn't look for nlohmann_json, if any of the CMake code depends on the `nlhmann::json` target (yes, there is such a target in CMake ), the CMake configuration would still fail. With a complaint about `nlohmann::json` not being known. . So generally, projects that publicly depend on something else, always look for all of those dependencies with [find_dependency(...)](https://cmake.org/cmake/help/latest/module/CMakeFindDependencyMacro.html). Regardless of which parts of the project the user wants to use. ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14188#issuecomment-1845002083
Modifiability,config,configuration,"> My question was: is it possible to modify the ROOT-cmake-find script, so that it only forces the nlohmann-json-dependency if you are going to use ROOT7 classes? So to say, that depending on the `REQUIRED COMPONENTS` that you use in the `find_package` statement in your user code, it is more or less 'requiring'. That's an interesting question.  CMake project's can't easily do this. I mean, nothing is impossible, but it's not simple to do. As long as externals are handled through imported library targets (which I'm not sure the nlohmann_json dependency is used with ), one would need to tweak the behaviour of CMake in a pretty fundamental way for this.  You see, when you tell in (in this case) ROOT's build that library `Foo` needs to publicly link against library `Bar::bar`, CMake exports this information in the `ROOTConfig-targets.cmake` file. (That is a file generated fully by CMake itself.) It will say that `Foo` depends on `Bar::bar`. So at that point `ROOTConfig.cmake` has to produce `Bar::bar` in some way. Even if the user's code itself never wants to use the `Foo` library. Because CMake will not like it that it has the `Foo` library defined (even if unused by others), without all of its requirements met. So even if `ROOTConfig.cmake` itself doesn't look for nlohmann_json, if any of the CMake code depends on the `nlhmann::json` target (yes, there is such a target in CMake ), the CMake configuration would still fail. With a complaint about `nlohmann::json` not being known. . So generally, projects that publicly depend on something else, always look for all of those dependencies with [find_dependency(...)](https://cmake.org/cmake/help/latest/module/CMakeFindDependencyMacro.html). Regardless of which parts of the project the user wants to use. ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14188#issuecomment-1845002083
Usability,simpl,simple,"> My question was: is it possible to modify the ROOT-cmake-find script, so that it only forces the nlohmann-json-dependency if you are going to use ROOT7 classes? So to say, that depending on the `REQUIRED COMPONENTS` that you use in the `find_package` statement in your user code, it is more or less 'requiring'. That's an interesting question.  CMake project's can't easily do this. I mean, nothing is impossible, but it's not simple to do. As long as externals are handled through imported library targets (which I'm not sure the nlohmann_json dependency is used with ), one would need to tweak the behaviour of CMake in a pretty fundamental way for this.  You see, when you tell in (in this case) ROOT's build that library `Foo` needs to publicly link against library `Bar::bar`, CMake exports this information in the `ROOTConfig-targets.cmake` file. (That is a file generated fully by CMake itself.) It will say that `Foo` depends on `Bar::bar`. So at that point `ROOTConfig.cmake` has to produce `Bar::bar` in some way. Even if the user's code itself never wants to use the `Foo` library. Because CMake will not like it that it has the `Foo` library defined (even if unused by others), without all of its requirements met. So even if `ROOTConfig.cmake` itself doesn't look for nlohmann_json, if any of the CMake code depends on the `nlhmann::json` target (yes, there is such a target in CMake ), the CMake configuration would still fail. With a complaint about `nlohmann::json` not being known. . So generally, projects that publicly depend on something else, always look for all of those dependencies with [find_dependency(...)](https://cmake.org/cmake/help/latest/module/CMakeFindDependencyMacro.html). Regardless of which parts of the project the user wants to use. ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14188#issuecomment-1845002083
Deployability,patch,patch,"No, that will not work. As i said protoc is actually configured correctly already. The issue is that /opt/homebrew/include is prepended to the search path for headers. I managed to fix it by doing https://github.com/alisw/root/commit/526782cfe8b7a7fffa90ae0395521b01ae902cf7 which will make sure that my own protobuf comes earlier than the one from homebrew. I see in master protobuf will use a config file, so maybe I can simply patch it in my own build.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14207#issuecomment-1851824221
Modifiability,config,configured,"No, that will not work. As i said protoc is actually configured correctly already. The issue is that /opt/homebrew/include is prepended to the search path for headers. I managed to fix it by doing https://github.com/alisw/root/commit/526782cfe8b7a7fffa90ae0395521b01ae902cf7 which will make sure that my own protobuf comes earlier than the one from homebrew. I see in master protobuf will use a config file, so maybe I can simply patch it in my own build.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14207#issuecomment-1851824221
Usability,simpl,simply,"No, that will not work. As i said protoc is actually configured correctly already. The issue is that /opt/homebrew/include is prepended to the search path for headers. I managed to fix it by doing https://github.com/alisw/root/commit/526782cfe8b7a7fffa90ae0395521b01ae902cf7 which will make sure that my own protobuf comes earlier than the one from homebrew. I see in master protobuf will use a config file, so maybe I can simply patch it in my own build.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14207#issuecomment-1851824221
Deployability,patch,patch,"> No, that will not work. As i said protoc is actually configured correctly already. The issue is that /opt/homebrew/include is prepended to the search path for headers. I managed to fix it by doing [alisw@526782c](https://github.com/alisw/root/commit/526782cfe8b7a7fffa90ae0395521b01ae902cf7) which will make sure that my own protobuf comes earlier than the one from homebrew. I see in master protobuf will use a config file, so maybe I can simply patch it in my own build. So if it works we can implement it in ROOT. @lmoneta what do you think? Can you give it a try?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14207#issuecomment-1851925257
Modifiability,config,configured,"> No, that will not work. As i said protoc is actually configured correctly already. The issue is that /opt/homebrew/include is prepended to the search path for headers. I managed to fix it by doing [alisw@526782c](https://github.com/alisw/root/commit/526782cfe8b7a7fffa90ae0395521b01ae902cf7) which will make sure that my own protobuf comes earlier than the one from homebrew. I see in master protobuf will use a config file, so maybe I can simply patch it in my own build. So if it works we can implement it in ROOT. @lmoneta what do you think? Can you give it a try?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14207#issuecomment-1851925257
Usability,simpl,simply,"> No, that will not work. As i said protoc is actually configured correctly already. The issue is that /opt/homebrew/include is prepended to the search path for headers. I managed to fix it by doing [alisw@526782c](https://github.com/alisw/root/commit/526782cfe8b7a7fffa90ae0395521b01ae902cf7) which will make sure that my own protobuf comes earlier than the one from homebrew. I see in master protobuf will use a config file, so maybe I can simply patch it in my own build. So if it works we can implement it in ROOT. @lmoneta what do you think? Can you give it a try?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14207#issuecomment-1851925257
Deployability,upgrade,upgrade,"During the upgrade to LLVM 18, we enabled JITLink for AArch64 on Linux, because we had to (there were problems with RuntimeDyld that we could not solve). In order to switch x86 as well, we need a solution for `CLING_DEBUG` and `CLING_PROFILE`. It's not clear to me how this works with JITLink, does it have an equivalent interface to `registerJITEventListener`? Maybe @lhames can comment...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14209#issuecomment-2342696358
Integrability,interface,interface,"During the upgrade to LLVM 18, we enabled JITLink for AArch64 on Linux, because we had to (there were problems with RuntimeDyld that we could not solve). In order to switch x86 as well, we need a solution for `CLING_DEBUG` and `CLING_PROFILE`. It's not clear to me how this works with JITLink, does it have an equivalent interface to `registerJITEventListener`? Maybe @lhames can comment...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14209#issuecomment-2342696358
Usability,clear,clear,"During the upgrade to LLVM 18, we enabled JITLink for AArch64 on Linux, because we had to (there were problems with RuntimeDyld that we could not solve). In order to switch x86 as well, we need a solution for `CLING_DEBUG` and `CLING_PROFILE`. It's not clear to me how this works with JITLink, does it have an equivalent interface to `registerJITEventListener`? Maybe @lhames can comment...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14209#issuecomment-2342696358
Usability,clear,clear,"> t is clear that that inner track isn't iterating anywhere nearly as much as it should be. What is the actual difference? How much is expected vs how much is gotten? Is it for the exact same file? What code is your colleague using? Did you consider using RDataFrame?. In the code shown above, the only relevant number are `AutreeData.GetEntries()` and the set of `AutreeData.tracknumber`",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14215#issuecomment-1851592415
Usability,simpl,simple,"Hi, I managed to prepare a relatively simple code that reproduces the issue:. ```c++; void crash() {; RooStats::HistFactory::Measurement meas(""mwe"",""mwe"");; meas.SetOutputFilePrefix(""./"");; meas.SetPOI(""signalStrength"");; meas.SetLumi(1);; meas.AddConstantParam(""Lumi"");. RooStats::HistFactory::Channel chan1(""channel1"");; chan1.SetData("""","""");; RooStats::HistFactory::Sample sample1(""sample1"");; sample1.SetHistoName(""emu_OS_1b_Ma"");; sample1.SetHistoPath("""");; sample1.SetInputFile(""BLIND_separate_tt_Z_29IFB_Apr_29_histos.root"");; sample1.SetNormalizeByTheory(false);; sample1.AddNormFactor(""signalStrength"", 1, 0.8, 1.2);; sample1.AddNormFactor(""b"", 0.543, 0.5, 0.6);; sample1.AddOverallSys(""Dummy"",1,1);. RooStats::HistFactory::Sample sample2(""sample2"");; sample2.SetHistoName(""emu_OS_1b_Mb"");; sample2.SetHistoPath("""");; sample2.SetInputFile(""BLIND_separate_tt_Z_29IFB_Apr_29_histos.root"");; sample2.SetNormalizeByTheory(false);; sample2.AddNormFactor(""signalStrength"", 1, 0.8, 1.2);; sample2.AddNormFactor(""minusONE"", -1, -1.1, -0.9);; sample2.AddNormFactor(""b2"", 0.2950, 0.0, 1.0);; sample2.AddOverallSys(""Dummy"",1,1);. chan1.AddSample(sample1);; chan1.AddSample(sample2);. RooStats::HistFactory::Channel chan2(""channel2"");; chan2.SetData("""","""");; RooStats::HistFactory::Sample sample3(""sample3"");; sample3.SetHistoName(""emu_OS_2b_Mc"");; sample3.SetHistoPath("""");; sample3.SetInputFile(""BLIND_separate_tt_Z_29IFB_Apr_29_histos.root"");; sample3.SetNormalizeByTheory(false);; sample2.AddNormFactor(""signalStrength"", 1, 0.8, 1.2);; sample3.AddNormFactor(""b2"", 0.2950, 0.0, 1.0);; sample3.AddOverallSys(""Dummy"",1,1);; chan2.AddSample(sample3);. meas.AddPreprocessFunction(""b2"",""b*b"",""b[0.543,0.0,1.0]"");; meas.AddConstantParam(""minusONE"");; meas.AddChannel(chan1);; meas.AddChannel(chan2);; meas.CollectHistograms();; RooStats::HistFactory::MakeModelAndMeasurementFast(meas);; }; ```. The code and the input can be found here: `/afs/cern.ch/user/t/tdado/public/ROOT_issue_14225`. It is probably no",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14225#issuecomment-1857543387
Availability,error,error,"Am skeptical this could ever have worked even in older releases, because looking at the code I see the method ""MakeSingleChannelWorkspace"" where the measurement object is passed, and therefore it is assuming any parameter in the constant list *must* be present in the channel???. Tomas do you get the same error message about ""cannot find the variable"" in 6.28, but it succeeds? It might be blind luck that it did. . If so the fix is a simple one to just skip over said variable if its not found in the channel.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14225#issuecomment-1858155447
Deployability,release,releases,"Am skeptical this could ever have worked even in older releases, because looking at the code I see the method ""MakeSingleChannelWorkspace"" where the measurement object is passed, and therefore it is assuming any parameter in the constant list *must* be present in the channel???. Tomas do you get the same error message about ""cannot find the variable"" in 6.28, but it succeeds? It might be blind luck that it did. . If so the fix is a simple one to just skip over said variable if its not found in the channel.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14225#issuecomment-1858155447
Integrability,message,message,"Am skeptical this could ever have worked even in older releases, because looking at the code I see the method ""MakeSingleChannelWorkspace"" where the measurement object is passed, and therefore it is assuming any parameter in the constant list *must* be present in the channel???. Tomas do you get the same error message about ""cannot find the variable"" in 6.28, but it succeeds? It might be blind luck that it did. . If so the fix is a simple one to just skip over said variable if its not found in the channel.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14225#issuecomment-1858155447
Modifiability,variab,variable,"Am skeptical this could ever have worked even in older releases, because looking at the code I see the method ""MakeSingleChannelWorkspace"" where the measurement object is passed, and therefore it is assuming any parameter in the constant list *must* be present in the channel???. Tomas do you get the same error message about ""cannot find the variable"" in 6.28, but it succeeds? It might be blind luck that it did. . If so the fix is a simple one to just skip over said variable if its not found in the channel.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14225#issuecomment-1858155447
Usability,simpl,simple,"Am skeptical this could ever have worked even in older releases, because looking at the code I see the method ""MakeSingleChannelWorkspace"" where the measurement object is passed, and therefore it is assuming any parameter in the constant list *must* be present in the channel???. Tomas do you get the same error message about ""cannot find the variable"" in 6.28, but it succeeds? It might be blind luck that it did. . If so the fix is a simple one to just skip over said variable if its not found in the channel.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14225#issuecomment-1858155447
Usability,clear,clear,"Even if I remove all icons from build directory - it does not crash for me.; Seems to be warning about missing icon is not direct cause of the segfault,. From the backtrace it is not clear at which moment ROOT crashes.; Can you try to run in the debugger?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14247#issuecomment-1898343006
Deployability,patch,patch,"> I'd leave the backport decision up to you. We can patch this into our user environments without a backport too. Ok, I prefer backports over people patching ROOT :slightly_smiling_face: There is a very low risk of breaking something here, since the PF only affects the case where `exe` contains qemu, which simply didn't work before.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14251#issuecomment-1860177688
Safety,risk,risk,"> I'd leave the backport decision up to you. We can patch this into our user environments without a backport too. Ok, I prefer backports over people patching ROOT :slightly_smiling_face: There is a very low risk of breaking something here, since the PF only affects the case where `exe` contains qemu, which simply didn't work before.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14251#issuecomment-1860177688
Usability,simpl,simply,"> I'd leave the backport decision up to you. We can patch this into our user environments without a backport too. Ok, I prefer backports over people patching ROOT :slightly_smiling_face: There is a very low risk of breaking something here, since the PF only affects the case where `exe` contains qemu, which simply didn't work before.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14251#issuecomment-1860177688
Availability,fault,faults-running-the-new-llvm-modulepassmanager-with-default-pipeline,"> As a side remark, it sounds expensive to recreate all managers and passes for every module. Is this also what upstream does if it runs on multiple input files?. I agree that it might not be very efficient to recreate all managers/passes for every module. I've been looking upstream and couldn't find any instance where populating pass/analysis managers and running passes are separated (unlike the legacy pass manager). . I used this as a reference for this PR: https://reviews.llvm.org/D123425. [This issue](https://discourse.llvm.org/t/segmentation-faults-running-the-new-llvm-modulepassmanager-with-default-pipeline/59105) is what I think happened with the failing tests for us. From the thread, they recommend using a new instance every time we perform codegen as the analyses might not be cleared. I could also try using the clear() method instead,",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14267#issuecomment-1864281326
Deployability,pipeline,pipeline,"> As a side remark, it sounds expensive to recreate all managers and passes for every module. Is this also what upstream does if it runs on multiple input files?. I agree that it might not be very efficient to recreate all managers/passes for every module. I've been looking upstream and couldn't find any instance where populating pass/analysis managers and running passes are separated (unlike the legacy pass manager). . I used this as a reference for this PR: https://reviews.llvm.org/D123425. [This issue](https://discourse.llvm.org/t/segmentation-faults-running-the-new-llvm-modulepassmanager-with-default-pipeline/59105) is what I think happened with the failing tests for us. From the thread, they recommend using a new instance every time we perform codegen as the analyses might not be cleared. I could also try using the clear() method instead,",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14267#issuecomment-1864281326
Energy Efficiency,efficient,efficient,"> As a side remark, it sounds expensive to recreate all managers and passes for every module. Is this also what upstream does if it runs on multiple input files?. I agree that it might not be very efficient to recreate all managers/passes for every module. I've been looking upstream and couldn't find any instance where populating pass/analysis managers and running passes are separated (unlike the legacy pass manager). . I used this as a reference for this PR: https://reviews.llvm.org/D123425. [This issue](https://discourse.llvm.org/t/segmentation-faults-running-the-new-llvm-modulepassmanager-with-default-pipeline/59105) is what I think happened with the failing tests for us. From the thread, they recommend using a new instance every time we perform codegen as the analyses might not be cleared. I could also try using the clear() method instead,",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14267#issuecomment-1864281326
Performance,perform,perform,"> As a side remark, it sounds expensive to recreate all managers and passes for every module. Is this also what upstream does if it runs on multiple input files?. I agree that it might not be very efficient to recreate all managers/passes for every module. I've been looking upstream and couldn't find any instance where populating pass/analysis managers and running passes are separated (unlike the legacy pass manager). . I used this as a reference for this PR: https://reviews.llvm.org/D123425. [This issue](https://discourse.llvm.org/t/segmentation-faults-running-the-new-llvm-modulepassmanager-with-default-pipeline/59105) is what I think happened with the failing tests for us. From the thread, they recommend using a new instance every time we perform codegen as the analyses might not be cleared. I could also try using the clear() method instead,",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14267#issuecomment-1864281326
Testability,test,tests,"> As a side remark, it sounds expensive to recreate all managers and passes for every module. Is this also what upstream does if it runs on multiple input files?. I agree that it might not be very efficient to recreate all managers/passes for every module. I've been looking upstream and couldn't find any instance where populating pass/analysis managers and running passes are separated (unlike the legacy pass manager). . I used this as a reference for this PR: https://reviews.llvm.org/D123425. [This issue](https://discourse.llvm.org/t/segmentation-faults-running-the-new-llvm-modulepassmanager-with-default-pipeline/59105) is what I think happened with the failing tests for us. From the thread, they recommend using a new instance every time we perform codegen as the analyses might not be cleared. I could also try using the clear() method instead,",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14267#issuecomment-1864281326
Usability,clear,cleared,"> As a side remark, it sounds expensive to recreate all managers and passes for every module. Is this also what upstream does if it runs on multiple input files?. I agree that it might not be very efficient to recreate all managers/passes for every module. I've been looking upstream and couldn't find any instance where populating pass/analysis managers and running passes are separated (unlike the legacy pass manager). . I used this as a reference for this PR: https://reviews.llvm.org/D123425. [This issue](https://discourse.llvm.org/t/segmentation-faults-running-the-new-llvm-modulepassmanager-with-default-pipeline/59105) is what I think happened with the failing tests for us. From the thread, they recommend using a new instance every time we perform codegen as the analyses might not be cleared. I could also try using the clear() method instead,",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14267#issuecomment-1864281326
Availability,failure,failures,"@pcanal, do you have any intuition about what could have gone wrong that causes these failures in the `execCheckClusterRange` test because of different file sizes?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14268#issuecomment-1863121010
Testability,test,test,"@pcanal, do you have any intuition about what could have gone wrong that causes these failures in the `execCheckClusterRange` test because of different file sizes?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14268#issuecomment-1863121010
Usability,intuit,intuition,"@pcanal, do you have any intuition about what could have gone wrong that causes these failures in the `execCheckClusterRange` test because of different file sizes?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14268#issuecomment-1863121010
Availability,failure,failures,> do you have any intuition about what could have gone wrong that causes these failures in the execCheckClusterRange test because of different file sizes?. Not yet. It could be that some leaf type changed or a `StreamerInfo` changed (for that reverting just the `LinkDef` should be sufficient).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14268#issuecomment-1863174237
Testability,test,test,> do you have any intuition about what could have gone wrong that causes these failures in the execCheckClusterRange test because of different file sizes?. Not yet. It could be that some leaf type changed or a `StreamerInfo` changed (for that reverting just the `LinkDef` should be sufficient).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14268#issuecomment-1863174237
Usability,intuit,intuition,> do you have any intuition about what could have gone wrong that causes these failures in the execCheckClusterRange test because of different file sizes?. Not yet. It could be that some leaf type changed or a `StreamerInfo` changed (for that reverting just the `LinkDef` should be sufficient).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14268#issuecomment-1863174237
Availability,failure,failures,> > do you have any intuition about what could have gone wrong that causes these failures in the execCheckClusterRange test because of different file sizes?; > ; > Not yet. It could be that some leaf type changed or a `StreamerInfo` changed (for that reverting just the `LinkDef` should be sufficient). That could be it! I have removed the changes from the LinkDef files from this PR.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14268#issuecomment-1863638811
Testability,test,test,> > do you have any intuition about what could have gone wrong that causes these failures in the execCheckClusterRange test because of different file sizes?; > ; > Not yet. It could be that some leaf type changed or a `StreamerInfo` changed (for that reverting just the `LinkDef` should be sufficient). That could be it! I have removed the changes from the LinkDef files from this PR.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14268#issuecomment-1863638811
Usability,intuit,intuition,> > do you have any intuition about what could have gone wrong that causes these failures in the execCheckClusterRange test because of different file sizes?; > ; > Not yet. It could be that some leaf type changed or a `StreamerInfo` changed (for that reverting just the `LinkDef` should be sufficient). That could be it! I have removed the changes from the LinkDef files from this PR.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14268#issuecomment-1863638811
Usability,simpl,simply,"Notice that to trigger the issue is enough to have an header `bar.h`:. ```; #ifndef _STRUCT_TIMESPEC; #define _STRUCT_TIMESPEC 1. /* POSIX.1b structure for a time value. This is like a `struct timeval' but; * has nanoseconds instead of microseconds. */; struct timespec; {; int tv_sec; /* Seconds. */; int tv_nsec; /* Nanoseconds. */; };. #endif; ```. and simply include it with `#include ""bar.h""`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14272#issuecomment-1862392926
Deployability,upgrade,upgrade,"> Can you propose these changes upstream in https://github.com/wlav/cppyy and backport the commit here. That would enable us to upgrade to the upstream version easier. Okay, so I created a pull request https://github.com/wlav/cppyy/pull/207 as you suggested. But I am not sure how to backport the commit here. Would you be able to guide me how to do it?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14293#issuecomment-1866699281
Usability,guid,guide,"> Can you propose these changes upstream in https://github.com/wlav/cppyy and backport the commit here. That would enable us to upgrade to the upstream version easier. Okay, so I created a pull request https://github.com/wlav/cppyy/pull/207 as you suggested. But I am not sure how to backport the commit here. Would you be able to guide me how to do it?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14293#issuecomment-1866699281
Deployability,upgrade,upgrade,"> > Can you propose these changes upstream in https://github.com/wlav/cppyy and backport the commit here. That would enable us to upgrade to the upstream version easier.; > ; > Okay, so I created a pull request [wlav/cppyy#207](https://github.com/wlav/cppyy/pull/207) as you suggested. But I am not sure how to backport the commit here. Would you be able to guide me how to do it?. Once you get a review upstream then we can merge the same commit here.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14293#issuecomment-1866800936
Usability,guid,guide,"> > Can you propose these changes upstream in https://github.com/wlav/cppyy and backport the commit here. That would enable us to upgrade to the upstream version easier.; > ; > Okay, so I created a pull request [wlav/cppyy#207](https://github.com/wlav/cppyy/pull/207) as you suggested. But I am not sure how to backport the commit here. Would you be able to guide me how to do it?. Once you get a review upstream then we can merge the same commit here.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14293#issuecomment-1866800936
Usability,clear,clear,"Hi @jpherdi, thanks for the report! I suggest the following changes to the tutorials:; https://github.com/root-project/root/pull/14332. Would this address this issue?. Also, note that the RooFit RDF helpers are not feature complete yet:; https://github.com/root-project/root/issues/7223. I didn't continue working on this, because it was not clear to me which features would actually get used by the users. If it's missing something that you need, for example the treatment of weight columns, please comment on the other issue I linked so we can give it higher priority.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14329#issuecomment-1886862091
Availability,error,error,"You are night, we need to make sure that ROOT compiles if there is already ROOT on the system, or at least that you get a clear error. There is already an open issue about this, so I'll close this issue as duplicate:; https://github.com/root-project/root/issues/13101",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14337#issuecomment-2046073774
Usability,clear,clear,"You are night, we need to make sure that ROOT compiles if there is already ROOT on the system, or at least that you get a clear error. There is already an open issue about this, so I'll close this issue as duplicate:; https://github.com/root-project/root/issues/13101",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14337#issuecomment-2046073774
Usability,simpl,simply,"I agree with @couet , the better alternative would be to simply remove the option from cmake and always bundle libafterimage",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14395#issuecomment-1902123987
Deployability,release,released,"> I thought deprecation in 6.30 and removal 6.32, but whatever you think is best. I see more clearly what you were trying to do now. In that case I will have to say I don't agree. We cannot deprecate a feature and backport the deprecation of the feature to an already released branch. What we can do is to deprecate the build option for 6.32 and then remove it in 6.34 :+1: Sorry for my confusion :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14395#issuecomment-1924170430
Usability,clear,clearly,"> I thought deprecation in 6.30 and removal 6.32, but whatever you think is best. I see more clearly what you were trying to do now. In that case I will have to say I don't agree. We cannot deprecate a feature and backport the deprecation of the feature to an already released branch. What we can do is to deprecate the build option for 6.32 and then remove it in 6.34 :+1: Sorry for my confusion :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14395#issuecomment-1924170430
Deployability,release,released,"> > I thought deprecation in 6.30 and removal 6.32, but whatever you think is best; > ; > I see more clearly what you were trying to do now. In that case I will have to say I don't agree. We cannot deprecate a feature and backport the deprecation of the feature to an already released branch. What we can do is to deprecate the build option for 6.32 and then remove it in 6.34  Sorry for my confusion :). Your plan sounds good to me, too. I was just thinking of backporting the deprecation because this option is broken from the very beginning. So just for speeding up.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14395#issuecomment-1924196571
Usability,clear,clearly,"> > I thought deprecation in 6.30 and removal 6.32, but whatever you think is best; > ; > I see more clearly what you were trying to do now. In that case I will have to say I don't agree. We cannot deprecate a feature and backport the deprecation of the feature to an already released branch. What we can do is to deprecate the build option for 6.32 and then remove it in 6.34  Sorry for my confusion :). Your plan sounds good to me, too. I was just thinking of backporting the deprecation because this option is broken from the very beginning. So just for speeding up.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14395#issuecomment-1924196571
Integrability,interface,interface,"> Maybe we can just make RPageSource::UnsealPage a public method?. In principle yes, I guess for now it's ok to keep it private as it's not clear (to me at least) which use cases in the open this method would cater to. So we can avoid exposing an interface that we might want to take back/change at a later stage.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14403#issuecomment-1912119472
Safety,avoid,avoid,"> Maybe we can just make RPageSource::UnsealPage a public method?. In principle yes, I guess for now it's ok to keep it private as it's not clear (to me at least) which use cases in the open this method would cater to. So we can avoid exposing an interface that we might want to take back/change at a later stage.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14403#issuecomment-1912119472
Usability,clear,clear,"> Maybe we can just make RPageSource::UnsealPage a public method?. In principle yes, I guess for now it's ok to keep it private as it's not clear (to me at least) which use cases in the open this method would cater to. So we can avoid exposing an interface that we might want to take back/change at a later stage.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14403#issuecomment-1912119472
Integrability,message,messages,"> Now that I see this issue (https://its.cern.ch/jira/projects/ROOT/issues/ROOT-8915) can we perhaps also provide a template for the commit messages, and close the issue?. Yes, this seems like a nice addition. The points raised by Philippe in the comments are still valid, we can either only provide it as an opt-in template that people themselves have to add locally as a commit template, or we have to enforce it somehow in the CI. I'm not sure the latter is desirable as it would turn the guidelines into rules. I don't know if this would be possible, but what could be nice is a 'commit format checker' in the CI that doesn't immediately turn red if it doesn't succeed but rather points the contributor to the guidelines.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14410#issuecomment-1916621891
Usability,guid,guidelines,"> Now that I see this issue (https://its.cern.ch/jira/projects/ROOT/issues/ROOT-8915) can we perhaps also provide a template for the commit messages, and close the issue?. Yes, this seems like a nice addition. The points raised by Philippe in the comments are still valid, we can either only provide it as an opt-in template that people themselves have to add locally as a commit template, or we have to enforce it somehow in the CI. I'm not sure the latter is desirable as it would turn the guidelines into rules. I don't know if this would be possible, but what could be nice is a 'commit format checker' in the CI that doesn't immediately turn red if it doesn't succeed but rather points the contributor to the guidelines.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14410#issuecomment-1916621891
Energy Efficiency,allocate,allocated,"Hi @dpiparo and @lmoneta, I included an additional gtest suite. I also modified to documentation so that it's clear that whenever b is rectangular, additional memory is allocated to compute a^(-1).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14420#issuecomment-1910617703
Usability,clear,clear,"Hi @dpiparo and @lmoneta, I included an additional gtest suite. I also modified to documentation so that it's clear that whenever b is rectangular, additional memory is allocated to compute a^(-1).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14420#issuecomment-1910617703
Deployability,patch,patch,"This is dealt with in cppyy with a patch to TCling at https://github.com/wlav/cppyy-backend/blob/25caf988cef1f2f76705c07b7262f076e8ed0e01/cling/src/core/metacling/src/TClingCallFunc.cxx#L468-L485 . Applying this patch as-is is not possible as it does not work on all platforms and is not generic enough (doesn't take into account the case of a templated move constructor). More in general, it is not yet clear to me that we want to force the implicit move in these cases. Python does not have the equivalent concepts of smart pointers, move semantics etc., so the line is quite blurry here.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14425#issuecomment-1935515180
Usability,clear,clear,"This is dealt with in cppyy with a patch to TCling at https://github.com/wlav/cppyy-backend/blob/25caf988cef1f2f76705c07b7262f076e8ed0e01/cling/src/core/metacling/src/TClingCallFunc.cxx#L468-L485 . Applying this patch as-is is not possible as it does not work on all platforms and is not generic enough (doesn't take into account the case of a templated move constructor). More in general, it is not yet clear to me that we want to force the implicit move in these cases. Python does not have the equivalent concepts of smart pointers, move semantics etc., so the line is quite blurry here.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14425#issuecomment-1935515180
Availability,error,error,"So indeed this other test does not work; ```python; import ROOT. ROOT.gInterpreter.Declare(r'''; struct A{; int mA{42};; A() {}; A(const A&) = delete;; template<typename T = int>; A(A &&) {}; };; int foo(A a = A{}) { return a.mA; }; '''). print(ROOT.foo()); ```; ```; input_line_36:18:45: error: call to deleted constructor of 'A'; new (ret) (int) (((int (&)(A))foo)(*(A*)args[0]));; ^~~~~~~~~~~~; input_line_35:5:5: note: 'A' has been explicitly marked deleted here; A(const A&) = delete;; ^; ```. Also, it seems to me that indeed in the case of a templated move constructor, the AST generated by clang simply does not report it in the class definition data, see [this example](https://godbolt.org/#z:OYLghAFBqd5QCxAYwPYBMCmBRdBLAF1QCcAaPECAMzwBtMA7AQwFtMQByARg9KtQYEAysib0QXACx8BBAKoBnTAAUAHpwAMvAFYTStJg1DIApACYAQuYukl9ZATwDKjdAGFUtAK4sGIAMykrgAyeAyYAHI%2BAEaYxCAA7KQADqgKhE4MHt6%2BASlpGQKh4VEssfFJdpgOmUIETMQE2T5%2BgVU1AnUNBMWRMXGJtvWNzbltwz1hfWUDCQCUtqhexMjsHAoExF4OANQAgiYJVhp7O2c7YQQ7LAdHkmaHACIm/sen53sQczuHVgnPJ3O%2BwgaAYG325gAbN8Xo8dlh6ARMC83kCkSxkgYkS83AQAJ7JRisTA7AAqP38cMuL2wJkBHwgpyhUJhRyedNuz1eHMuO34qEZOyYFLhtz%2Bj1ZFh2xEwBGWDCFADobiifv8ORwFrROABWXh%2BDhaUioThuazWHYKJYrEnmfw8UgETSahYAaxAZh1%2Bk4kn1zuNnF4ChAGkdzoWcFgSDQGLocXIlBjyTj8WQBiMXEhGiYCiUjT4dCRxGDEGi/uiYQaeM4DorzGIeIA8tFtNUndxeDG2IJGwxaNXDbwsNEvMA3GJaMGO6QsCxDMBxIOZ3gZTUAG6YKdGzCqapeJE13iXTDape0PDRYhVjxYf2bPAsQ8LKgGYAKABqeEwAHdG4SDQ6/CCCIYjsFIMiCIoKjqEuuhcPo84oOalj6BewaQAsqDJI4AhTrwqAbsQxB4Fg6FfLYJ5tpkLgMO4ngtBIZhBLRvSlOUICQvk6Q4Vk9G5FwTGpNxmSsf08Sce0PFdCMfF%2BAJFH2FJEyiTM4lDN0oxyUxGzdCp7HQosyyrBIWq6n6S4mhwOyqAAHJCAC0kKSDsabzjsmaKhonk7BAOZ5jxCjfBAuCECQPxmPacy8O2WhzG6HpeqevqkAaRqWUGIZhoOEYwIgIBLAQyT7gmIKoLG9DEBExKcLZDlOTswDIMg7n%2BIqZi8Jg%2BBEMR6B6EBwiiOI4H9VBaj%2BnBpDfleyRPt6HB6il/qWY2%2B5FVcqBUNZdmOc5rlGO5kKed5vm5nEAVBR45VxOFkXReG8VcIqCTPTqZhmAAnP4OrPe9NmZpxSXmWlga2JlMWaqQkZ5TmBAlUmKZVWwNXbfVe3AAdR0aD5flnZkgUdV1JAkX1sggUN0gjUoY2wXoknURAriaSAkihiEUxsQMX1cYUvE5H4LPczxemc16dOdBMTMC2LDDSZMJRiQEosS7JzOhjpjTC/EX0LJsm",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14426#issuecomment-1917903939
Testability,test,test,"So indeed this other test does not work; ```python; import ROOT. ROOT.gInterpreter.Declare(r'''; struct A{; int mA{42};; A() {}; A(const A&) = delete;; template<typename T = int>; A(A &&) {}; };; int foo(A a = A{}) { return a.mA; }; '''). print(ROOT.foo()); ```; ```; input_line_36:18:45: error: call to deleted constructor of 'A'; new (ret) (int) (((int (&)(A))foo)(*(A*)args[0]));; ^~~~~~~~~~~~; input_line_35:5:5: note: 'A' has been explicitly marked deleted here; A(const A&) = delete;; ^; ```. Also, it seems to me that indeed in the case of a templated move constructor, the AST generated by clang simply does not report it in the class definition data, see [this example](https://godbolt.org/#z:OYLghAFBqd5QCxAYwPYBMCmBRdBLAF1QCcAaPECAMzwBtMA7AQwFtMQByARg9KtQYEAysib0QXACx8BBAKoBnTAAUAHpwAMvAFYTStJg1DIApACYAQuYukl9ZATwDKjdAGFUtAK4sGIAMykrgAyeAyYAHI%2BAEaYxCAA7KQADqgKhE4MHt6%2BASlpGQKh4VEssfFJdpgOmUIETMQE2T5%2BgVU1AnUNBMWRMXGJtvWNzbltwz1hfWUDCQCUtqhexMjsHAoExF4OANQAgiYJVhp7O2c7YQQ7LAdHkmaHACIm/sen53sQczuHVgnPJ3O%2BwgaAYG325gAbN8Xo8dlh6ARMC83kCkSxkgYkS83AQAJ7JRisTA7AAqP38cMuL2wJkBHwgpyhUJhRyedNuz1eHMuO34qEZOyYFLhtz%2Bj1ZFh2xEwBGWDCFADobiifv8ORwFrROABWXh%2BDhaUioThuazWHYKJYrEnmfw8UgETSahYAaxAZh1%2Bk4kn1zuNnF4ChAGkdzoWcFgSDQGLocXIlBjyTj8WQBiMXEhGiYCiUjT4dCRxGDEGi/uiYQaeM4DorzGIeIA8tFtNUndxeDG2IJGwxaNXDbwsNEvMA3GJaMGO6QsCxDMBxIOZ3gZTUAG6YKdGzCqapeJE13iXTDape0PDRYhVjxYf2bPAsQ8LKgGYAKABqeEwAHdG4SDQ6/CCCIYjsFIMiCIoKjqEuuhcPo84oOalj6BewaQAsqDJI4AhTrwqAbsQxB4Fg6FfLYJ5tpkLgMO4ngtBIZhBLRvSlOUICQvk6Q4Vk9G5FwTGpNxmSsf08Sce0PFdCMfF%2BAJFH2FJEyiTM4lDN0oxyUxGzdCp7HQosyyrBIWq6n6S4mhwOyqAAHJCAC0kKSDsabzjsmaKhonk7BAOZ5jxCjfBAuCECQPxmPacy8O2WhzG6HpeqevqkAaRqWUGIZhoOEYwIgIBLAQyT7gmIKoLG9DEBExKcLZDlOTswDIMg7n%2BIqZi8Jg%2BBEMR6B6EBwiiOI4H9VBaj%2BnBpDfleyRPt6HB6il/qWY2%2B5FVcqBUNZdmOc5rlGO5kKed5vm5nEAVBR45VxOFkXReG8VcIqCTPTqZhmAAnP4OrPe9NmZpxSXmWlga2JlMWaqQkZ5TmBAlUmKZVWwNXbfVe3AAdR0aD5flnZkgUdV1JAkX1sggUN0gjUoY2wXoknURAriaSAkihiEUxsQMX1cYUvE5H4LPczxemc16dOdBMTMC2LDDSZMJRiQEosS7JzOhjpjTC/EX0LJsm",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14426#issuecomment-1917903939
Usability,simpl,simply,"So indeed this other test does not work; ```python; import ROOT. ROOT.gInterpreter.Declare(r'''; struct A{; int mA{42};; A() {}; A(const A&) = delete;; template<typename T = int>; A(A &&) {}; };; int foo(A a = A{}) { return a.mA; }; '''). print(ROOT.foo()); ```; ```; input_line_36:18:45: error: call to deleted constructor of 'A'; new (ret) (int) (((int (&)(A))foo)(*(A*)args[0]));; ^~~~~~~~~~~~; input_line_35:5:5: note: 'A' has been explicitly marked deleted here; A(const A&) = delete;; ^; ```. Also, it seems to me that indeed in the case of a templated move constructor, the AST generated by clang simply does not report it in the class definition data, see [this example](https://godbolt.org/#z:OYLghAFBqd5QCxAYwPYBMCmBRdBLAF1QCcAaPECAMzwBtMA7AQwFtMQByARg9KtQYEAysib0QXACx8BBAKoBnTAAUAHpwAMvAFYTStJg1DIApACYAQuYukl9ZATwDKjdAGFUtAK4sGIAMykrgAyeAyYAHI%2BAEaYxCAA7KQADqgKhE4MHt6%2BASlpGQKh4VEssfFJdpgOmUIETMQE2T5%2BgVU1AnUNBMWRMXGJtvWNzbltwz1hfWUDCQCUtqhexMjsHAoExF4OANQAgiYJVhp7O2c7YQQ7LAdHkmaHACIm/sen53sQczuHVgnPJ3O%2BwgaAYG325gAbN8Xo8dlh6ARMC83kCkSxkgYkS83AQAJ7JRisTA7AAqP38cMuL2wJkBHwgpyhUJhRyedNuz1eHMuO34qEZOyYFLhtz%2Bj1ZFh2xEwBGWDCFADobiifv8ORwFrROABWXh%2BDhaUioThuazWHYKJYrEnmfw8UgETSahYAaxAZh1%2Bk4kn1zuNnF4ChAGkdzoWcFgSDQGLocXIlBjyTj8WQBiMXEhGiYCiUjT4dCRxGDEGi/uiYQaeM4DorzGIeIA8tFtNUndxeDG2IJGwxaNXDbwsNEvMA3GJaMGO6QsCxDMBxIOZ3gZTUAG6YKdGzCqapeJE13iXTDape0PDRYhVjxYf2bPAsQ8LKgGYAKABqeEwAHdG4SDQ6/CCCIYjsFIMiCIoKjqEuuhcPo84oOalj6BewaQAsqDJI4AhTrwqAbsQxB4Fg6FfLYJ5tpkLgMO4ngtBIZhBLRvSlOUICQvk6Q4Vk9G5FwTGpNxmSsf08Sce0PFdCMfF%2BAJFH2FJEyiTM4lDN0oxyUxGzdCp7HQosyyrBIWq6n6S4mhwOyqAAHJCAC0kKSDsabzjsmaKhonk7BAOZ5jxCjfBAuCECQPxmPacy8O2WhzG6HpeqevqkAaRqWUGIZhoOEYwIgIBLAQyT7gmIKoLG9DEBExKcLZDlOTswDIMg7n%2BIqZi8Jg%2BBEMR6B6EBwiiOI4H9VBaj%2BnBpDfleyRPt6HB6il/qWY2%2B5FVcqBUNZdmOc5rlGO5kKed5vm5nEAVBR45VxOFkXReG8VcIqCTPTqZhmAAnP4OrPe9NmZpxSXmWlga2JlMWaqQkZ5TmBAlUmKZVWwNXbfVe3AAdR0aD5flnZkgUdV1JAkX1sggUN0gjUoY2wXoknURAriaSAkihiEUxsQMX1cYUvE5H4LPczxemc16dOdBMTMC2LDDSZMJRiQEosS7JzOhjpjTC/EX0LJsm",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14426#issuecomment-1917903939
Availability,avail,available,"nZkgUdV1JAkX1sggUN0gjUoY2wXoknURAriaSAkihiEUxsQMX1cYUvE5H4LPczxemc16dOdBMTMC2LDDSZMJRiQEosS7JzOhjpjTC/EX0LJsmCYMTGimfNQP4Zwezgp%2BP7XbVO0uem6MeV5WMnf5eNBSF3U3fBOyXcmFVe1FWWxfFkg2W1b2SM9GhOW9GhcDZc3JalpscBlobg3Fc3tYtFkgxnCyEekziSEAA%3D). There, by commenting the template declaration of the move constructor, one can see the corresponding AST definition data being filled, i.e. from; > ; > ```; > | | |-MoveConstructor; > ```; > ; > to; > ; > ```; > | | |-MoveConstructor exists non_trivial user_declared; > ```; > ; > I am surely not expert enough in this area, but I noticed that when the constructor is templated the corresponding `CXXConstructorDecl` is nested inside a `FunctionTemplateDecl`, so that may be ""hiding"" it somehow?. I suppose that with a template move constructor is not the ""canonical form"" of a move constructor (or whatever the right standardese is). I was hoping that it's reported once the template is instantiated, but that doesn't seem the case either. In any case, what you really want to ask Clang is ""can you copy-construct this thing"" and ""can you move-construct this thing"". That logic is implemented in `EvaluateBooleanTypeTrait` of `SemaExprCXX.cpp` and is indeed a bit hairy because it actually has to run through all the machinery of template instantiation and overload resolution. You can invoke that machinery via `Sema::BuildTypeTrait` with `Kind = clang::TT_IsConstructible`. Alternatively, you can try using the `__is_constructible` builtin in the generated wrapper code, but I'm not sure how that would work because it's not available in the preprocessor... Final remark: A better heuristic could be to check for [`defaultedCopyConstructorIsDeleted()`](https://clang.llvm.org/doxygen/classclang_1_1CXXRecordDecl.html#a6cd5ebd1006eab239a19413c2886dab3) and then just try the `std::move`. I think that heuristic still has false-negatives and false-positives, but I think it gets the one case right where the explicit intent is to `delete` the copy constructor...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14426#issuecomment-1918556597
Integrability,wrap,wrapper,"nZkgUdV1JAkX1sggUN0gjUoY2wXoknURAriaSAkihiEUxsQMX1cYUvE5H4LPczxemc16dOdBMTMC2LDDSZMJRiQEosS7JzOhjpjTC/EX0LJsmCYMTGimfNQP4Zwezgp%2BP7XbVO0uem6MeV5WMnf5eNBSF3U3fBOyXcmFVe1FWWxfFkg2W1b2SM9GhOW9GhcDZc3JalpscBlobg3Fc3tYtFkgxnCyEekziSEAA%3D). There, by commenting the template declaration of the move constructor, one can see the corresponding AST definition data being filled, i.e. from; > ; > ```; > | | |-MoveConstructor; > ```; > ; > to; > ; > ```; > | | |-MoveConstructor exists non_trivial user_declared; > ```; > ; > I am surely not expert enough in this area, but I noticed that when the constructor is templated the corresponding `CXXConstructorDecl` is nested inside a `FunctionTemplateDecl`, so that may be ""hiding"" it somehow?. I suppose that with a template move constructor is not the ""canonical form"" of a move constructor (or whatever the right standardese is). I was hoping that it's reported once the template is instantiated, but that doesn't seem the case either. In any case, what you really want to ask Clang is ""can you copy-construct this thing"" and ""can you move-construct this thing"". That logic is implemented in `EvaluateBooleanTypeTrait` of `SemaExprCXX.cpp` and is indeed a bit hairy because it actually has to run through all the machinery of template instantiation and overload resolution. You can invoke that machinery via `Sema::BuildTypeTrait` with `Kind = clang::TT_IsConstructible`. Alternatively, you can try using the `__is_constructible` builtin in the generated wrapper code, but I'm not sure how that would work because it's not available in the preprocessor... Final remark: A better heuristic could be to check for [`defaultedCopyConstructorIsDeleted()`](https://clang.llvm.org/doxygen/classclang_1_1CXXRecordDecl.html#a6cd5ebd1006eab239a19413c2886dab3) and then just try the `std::move`. I think that heuristic still has false-negatives and false-positives, but I think it gets the one case right where the explicit intent is to `delete` the copy constructor...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14426#issuecomment-1918556597
Testability,log,logic,"nZkgUdV1JAkX1sggUN0gjUoY2wXoknURAriaSAkihiEUxsQMX1cYUvE5H4LPczxemc16dOdBMTMC2LDDSZMJRiQEosS7JzOhjpjTC/EX0LJsmCYMTGimfNQP4Zwezgp%2BP7XbVO0uem6MeV5WMnf5eNBSF3U3fBOyXcmFVe1FWWxfFkg2W1b2SM9GhOW9GhcDZc3JalpscBlobg3Fc3tYtFkgxnCyEekziSEAA%3D). There, by commenting the template declaration of the move constructor, one can see the corresponding AST definition data being filled, i.e. from; > ; > ```; > | | |-MoveConstructor; > ```; > ; > to; > ; > ```; > | | |-MoveConstructor exists non_trivial user_declared; > ```; > ; > I am surely not expert enough in this area, but I noticed that when the constructor is templated the corresponding `CXXConstructorDecl` is nested inside a `FunctionTemplateDecl`, so that may be ""hiding"" it somehow?. I suppose that with a template move constructor is not the ""canonical form"" of a move constructor (or whatever the right standardese is). I was hoping that it's reported once the template is instantiated, but that doesn't seem the case either. In any case, what you really want to ask Clang is ""can you copy-construct this thing"" and ""can you move-construct this thing"". That logic is implemented in `EvaluateBooleanTypeTrait` of `SemaExprCXX.cpp` and is indeed a bit hairy because it actually has to run through all the machinery of template instantiation and overload resolution. You can invoke that machinery via `Sema::BuildTypeTrait` with `Kind = clang::TT_IsConstructible`. Alternatively, you can try using the `__is_constructible` builtin in the generated wrapper code, but I'm not sure how that would work because it's not available in the preprocessor... Final remark: A better heuristic could be to check for [`defaultedCopyConstructorIsDeleted()`](https://clang.llvm.org/doxygen/classclang_1_1CXXRecordDecl.html#a6cd5ebd1006eab239a19413c2886dab3) and then just try the `std::move`. I think that heuristic still has false-negatives and false-positives, but I think it gets the one case right where the explicit intent is to `delete` the copy constructor...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14426#issuecomment-1918556597
Usability,simpl,simply,"> Also, it seems to me that indeed in the case of a templated move constructor, the AST generated by clang simply does not report it in the class definition data, see [this example](https://godbolt.org/#z:OYLghAFBqd5QCxAYwPYBMCmBRdBLAF1QCcAaPECAMzwBtMA7AQwFtMQByARg9KtQYEAysib0QXACx8BBAKoBnTAAUAHpwAMvAFYTStJg1DIApACYAQuYukl9ZATwDKjdAGFUtAK4sGIAMykrgAyeAyYAHI%2BAEaYxCAA7KQADqgKhE4MHt6%2BASlpGQKh4VEssfFJdpgOmUIETMQE2T5%2BgVU1AnUNBMWRMXGJtvWNzbltwz1hfWUDCQCUtqhexMjsHAoExF4OANQAgiYJVhp7O2c7YQQ7LAdHkmaHACIm/sen53sQczuHVgnPJ3O%2BwgaAYG325gAbN8Xo8dlh6ARMC83kCkSxkgYkS83AQAJ7JRisTA7AAqP38cMuL2wJkBHwgpyhUJhRyedNuz1eHMuO34qEZOyYFLhtz%2Bj1ZFh2xEwBGWDCFADobiifv8ORwFrROABWXh%2BDhaUioThuazWHYKJYrEnmfw8UgETSahYAaxAZh1%2Bk4kn1zuNnF4ChAGkdzoWcFgSDQGLocXIlBjyTj8WQBiMXEhGiYCiUjT4dCRxGDEGi/uiYQaeM4DorzGIeIA8tFtNUndxeDG2IJGwxaNXDbwsNEvMA3GJaMGO6QsCxDMBxIOZ3gZTUAG6YKdGzCqapeJE13iXTDape0PDRYhVjxYf2bPAsQ8LKgGYAKABqeEwAHdG4SDQ6/CCCIYjsFIMiCIoKjqEuuhcPo84oOalj6BewaQAsqDJI4AhTrwqAbsQxB4Fg6FfLYJ5tpkLgMO4ngtBIZhBLRvSlOUICQvk6Q4Vk9G5FwTGpNxmSsf08Sce0PFdCMfF%2BAJFH2FJEyiTM4lDN0oxyUxGzdCp7HQosyyrBIWq6n6S4mhwOyqAAHJCAC0kKSDsabzjsmaKhonk7BAOZ5jxCjfBAuCECQPxmPacy8O2WhzG6HpeqevqkAaRqWUGIZhoOEYwIgIBLAQyT7gmIKoLG9DEBExKcLZDlOTswDIMg7n%2BIqZi8Jg%2BBEMR6B6EBwiiOI4H9VBaj%2BnBpDfleyRPt6HB6il/qWY2%2B5FVcqBUNZdmOc5rlGO5kKed5vm5nEAVBR45VxOFkXReG8VcIqCTPTqZhmAAnP4OrPe9NmZpxSXmWlga2JlMWaqQkZ5TmBAlUmKZVWwNXbfVe3AAdR0aD5flnZkgUdV1JAkX1sggUN0gjUoY2wXoknURAriaSAkihiEUxsQMX1cYUvE5H4LPczxemc16dOdBMTMC2LDDSZMJRiQEosS7JzOhjpjTC/EX0LJsmCYMTGimfNQP4Zwezgp%2BP7XbVO0uem6MeV5WMnf5eNBSF3U3fBOyXcmFVe1FWWxfFkg2W1b2SM9GhOW9GhcDZc3JalpscBlobg3Fc3tYtFkgxnCyEekziSEAA%3D). There, by commenting the template declaration of the move constructor, one can see the corresponding AST definition data being filled, i.e. from; > ; > ```; > | | |-MoveConstructor; > ```; > ; > to; > ; > ```; > | | |-MoveConstructor exists non_trivial user_declared; > ```; > ; > I am surely not expert enough in this area, but I noticed that when the constructor is t",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14426#issuecomment-1918556597
Availability,fault,faulty,"After more investigation, it is less clear to me how the valgrind report and the `AddDataset` function are related. Still, the logic of the function seems faulty any way.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14433#issuecomment-1910477019
Testability,log,logic,"After more investigation, it is less clear to me how the valgrind report and the `AddDataset` function are related. Still, the logic of the function seems faulty any way.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14433#issuecomment-1910477019
Usability,clear,clear,"After more investigation, it is less clear to me how the valgrind report and the `AddDataset` function are related. Still, the logic of the function seems faulty any way.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14433#issuecomment-1910477019
Usability,guid,guidelines,"> Are there some common guidelines for the future on this? Like 'only do changes in 6.30 branch', or 'only do changes in master and then backport'?. I don't think we have a guideline yet for this very specific case. I think in practice, for the majority of cases we try to merge changes in master and then backport.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14439#issuecomment-1924166327
Deployability,release,released,"> > Are there some common guidelines for the future on this? Like 'only do changes in 6.30 branch', or 'only do changes in master and then backport'?; > ; > I don't think we have a guideline yet for this very specific case. I think in practice, for the majority of cases we try to merge changes in master and then backport. Let's imagine an example. I fix an issue for 6.32, and it is automatically collected and added to the 6.32 Release Notes. Furthermore i add a custom message to 6.32relnotes in the e.g. roofit section. I then backport the fix to 6.30. However, this time, the custom message in relnotes will not be automatically added to the 6.30 Release Notes because it was already released. So, after backporting the fix from master to 630, should one:. a) Create a new PR for the 630_ReleaseNotes file, but on the master branch and then after merging, backport it to 6.30 branch; or; b) Create a new PR for the 630_ReleaseNotes file and forget about the master branch, which will stay with an outdated version of 630-relnotes, which is however not very critical since the RelnotesWebpage for 6.30 is built from the 630 branch and not from master?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14439#issuecomment-1944051025
Integrability,message,message,"> > Are there some common guidelines for the future on this? Like 'only do changes in 6.30 branch', or 'only do changes in master and then backport'?; > ; > I don't think we have a guideline yet for this very specific case. I think in practice, for the majority of cases we try to merge changes in master and then backport. Let's imagine an example. I fix an issue for 6.32, and it is automatically collected and added to the 6.32 Release Notes. Furthermore i add a custom message to 6.32relnotes in the e.g. roofit section. I then backport the fix to 6.30. However, this time, the custom message in relnotes will not be automatically added to the 6.30 Release Notes because it was already released. So, after backporting the fix from master to 630, should one:. a) Create a new PR for the 630_ReleaseNotes file, but on the master branch and then after merging, backport it to 6.30 branch; or; b) Create a new PR for the 630_ReleaseNotes file and forget about the master branch, which will stay with an outdated version of 630-relnotes, which is however not very critical since the RelnotesWebpage for 6.30 is built from the 630 branch and not from master?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14439#issuecomment-1944051025
Usability,guid,guidelines,"> > Are there some common guidelines for the future on this? Like 'only do changes in 6.30 branch', or 'only do changes in master and then backport'?; > ; > I don't think we have a guideline yet for this very specific case. I think in practice, for the majority of cases we try to merge changes in master and then backport. Let's imagine an example. I fix an issue for 6.32, and it is automatically collected and added to the 6.32 Release Notes. Furthermore i add a custom message to 6.32relnotes in the e.g. roofit section. I then backport the fix to 6.30. However, this time, the custom message in relnotes will not be automatically added to the 6.30 Release Notes because it was already released. So, after backporting the fix from master to 630, should one:. a) Create a new PR for the 630_ReleaseNotes file, but on the master branch and then after merging, backport it to 6.30 branch; or; b) Create a new PR for the 630_ReleaseNotes file and forget about the master branch, which will stay with an outdated version of 630-relnotes, which is however not very critical since the RelnotesWebpage for 6.30 is built from the 630 branch and not from master?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14439#issuecomment-1944051025
Deployability,release,released,"> > it will not be automatically added to the 6.30 Release Notes because it was already released; > ; > This might not be specific enough. The release notes for the already released version of v6.30 (let's say v6.30.04) are frozen by definition. However the fix should be properly pickup by the release procedure for the next version, i.e. v6.30.06. (of course this require adding the proper tag to the issue). What am I missing?. Thanks for the message.; True, but I did not express myself well (edited now above message). I am not speaking only about the automatic fixed issues collection protocol. I am speaking about manual additions to the release notes where a more in-depth message is written. In that case, there is the ambiguity of where this should be added, in the 63006relnotes of master and then backport to 630patches, or rather directly in 630patches. Right now, we have a bit of everything. If you use 'meld' to compare them, you will see the issue more clearly.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14439#issuecomment-1947883057
Integrability,message,message,"> > it will not be automatically added to the 6.30 Release Notes because it was already released; > ; > This might not be specific enough. The release notes for the already released version of v6.30 (let's say v6.30.04) are frozen by definition. However the fix should be properly pickup by the release procedure for the next version, i.e. v6.30.06. (of course this require adding the proper tag to the issue). What am I missing?. Thanks for the message.; True, but I did not express myself well (edited now above message). I am not speaking only about the automatic fixed issues collection protocol. I am speaking about manual additions to the release notes where a more in-depth message is written. In that case, there is the ambiguity of where this should be added, in the 63006relnotes of master and then backport to 630patches, or rather directly in 630patches. Right now, we have a bit of everything. If you use 'meld' to compare them, you will see the issue more clearly.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14439#issuecomment-1947883057
Usability,clear,clearly,"> > it will not be automatically added to the 6.30 Release Notes because it was already released; > ; > This might not be specific enough. The release notes for the already released version of v6.30 (let's say v6.30.04) are frozen by definition. However the fix should be properly pickup by the release procedure for the next version, i.e. v6.30.06. (of course this require adding the proper tag to the issue). What am I missing?. Thanks for the message.; True, but I did not express myself well (edited now above message). I am not speaking only about the automatic fixed issues collection protocol. I am speaking about manual additions to the release notes where a more in-depth message is written. In that case, there is the ambiguity of where this should be added, in the 63006relnotes of master and then backport to 630patches, or rather directly in 630patches. Right now, we have a bit of everything. If you use 'meld' to compare them, you will see the issue more clearly.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14439#issuecomment-1947883057
Availability,error,error,"Alright, I think I understand what's going on (even though it's not fully clear to me why the story changes to an error in C++20): `REntry::GetPtr<T>` instantiates `RField<T>::TypeName()` to check the type name and despite the `if constexpr (std::is_void_v<T>)` check, it seems the compiler does ""something"" with `RField<void>`. In this PR, as mentioned above, the base class destructor changes to `virtual ~RFieldBase() = default;` in the header so the compiler sees it and apparently tries to instantiate also `GenerateValue`. There are a couple of solutions: First we can move `~RFieldBase()` back into the source file:; ```diff; diff --git a/tree/ntuple/v7/inc/ROOT/RField.hxx b/tree/ntuple/v7/inc/ROOT/RField.hxx; index deb9d5f4a3..cd0b5dd89e 100644; --- a/tree/ntuple/v7/inc/ROOT/RField.hxx; +++ b/tree/ntuple/v7/inc/ROOT/RField.hxx; @@ -570,7 +570,7 @@ public:; RFieldBase(RFieldBase&&) = default;; RFieldBase& operator =(const RFieldBase&) = delete;; RFieldBase& operator =(RFieldBase&&) = default;; - virtual ~RFieldBase() = default;; + virtual ~RFieldBase();; ; /// Copies the field and its sub fields using a possibly new name and a new, unconnected set of columns; std::unique_ptr<RFieldBase> Clone(std::string_view newName) const;; diff --git a/tree/ntuple/v7/src/RField.cxx b/tree/ntuple/v7/src/RField.cxx; index ef04fec76c..41d4962ac5 100644; --- a/tree/ntuple/v7/src/RField.cxx; +++ b/tree/ntuple/v7/src/RField.cxx; @@ -410,6 +410,10 @@ ROOT::Experimental::RFieldBase::RFieldBase(std::string_view name, std::string_vi; {; }; ; +ROOT::Experimental::RFieldBase::~RFieldBase(); +{; +}; +; std::string ROOT::Experimental::RFieldBase::GetQualifiedFieldName() const; {; std::string result = GetFieldName();; ```. Alternatively it helps to switch the `if constexpr` around to avoid the compiler instantiate the `RField<void>`:; ```diff; diff --git a/tree/ntuple/v7/inc/ROOT/REntry.hxx b/tree/ntuple/v7/inc/ROOT/REntry.hxx; index 1f3ec47095..b7b70b24cb 100644; --- a/tree/ntuple/v7/inc/ROOT/RE",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14468#issuecomment-1916371964
Safety,avoid,avoid,"ee/ntuple/v7/inc/ROOT/RField.hxx; @@ -570,7 +570,7 @@ public:; RFieldBase(RFieldBase&&) = default;; RFieldBase& operator =(const RFieldBase&) = delete;; RFieldBase& operator =(RFieldBase&&) = default;; - virtual ~RFieldBase() = default;; + virtual ~RFieldBase();; ; /// Copies the field and its sub fields using a possibly new name and a new, unconnected set of columns; std::unique_ptr<RFieldBase> Clone(std::string_view newName) const;; diff --git a/tree/ntuple/v7/src/RField.cxx b/tree/ntuple/v7/src/RField.cxx; index ef04fec76c..41d4962ac5 100644; --- a/tree/ntuple/v7/src/RField.cxx; +++ b/tree/ntuple/v7/src/RField.cxx; @@ -410,6 +410,10 @@ ROOT::Experimental::RFieldBase::RFieldBase(std::string_view name, std::string_vi; {; }; ; +ROOT::Experimental::RFieldBase::~RFieldBase(); +{; +}; +; std::string ROOT::Experimental::RFieldBase::GetQualifiedFieldName() const; {; std::string result = GetFieldName();; ```. Alternatively it helps to switch the `if constexpr` around to avoid the compiler instantiate the `RField<void>`:; ```diff; diff --git a/tree/ntuple/v7/inc/ROOT/REntry.hxx b/tree/ntuple/v7/inc/ROOT/REntry.hxx; index 1f3ec47095..b7b70b24cb 100644; --- a/tree/ntuple/v7/inc/ROOT/REntry.hxx; +++ b/tree/ntuple/v7/inc/ROOT/REntry.hxx; @@ -124,12 +124,11 @@ public:; if (v.GetField().GetFieldName() != fieldName); continue;; ; - if constexpr (std::is_void_v<T>); - return v.GetPtr<void>();; -; - if (v.GetField().GetTypeName() != RField<T>::TypeName()) {; - throw RException(R__FAIL(""type mismatch for field "" + std::string(fieldName) + "": "" +; - v.GetField().GetTypeName() + "" vs. "" + RField<T>::TypeName()));; + if constexpr (!std::is_void_v<T>) {; + if (v.GetField().GetTypeName() != RField<T>::TypeName()) {; + throw RException(R__FAIL(""type mismatch for field "" + std::string(fieldName) + "": "" +; + v.GetField().GetTypeName() + "" vs. "" + RField<T>::TypeName()));; + }; }; return std::static_pointer_cast<T>(v.GetPtr<void>());; }; ```. Finally we can either disable `CreateValue` in th",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14468#issuecomment-1916371964
Usability,clear,clear,"Alright, I think I understand what's going on (even though it's not fully clear to me why the story changes to an error in C++20): `REntry::GetPtr<T>` instantiates `RField<T>::TypeName()` to check the type name and despite the `if constexpr (std::is_void_v<T>)` check, it seems the compiler does ""something"" with `RField<void>`. In this PR, as mentioned above, the base class destructor changes to `virtual ~RFieldBase() = default;` in the header so the compiler sees it and apparently tries to instantiate also `GenerateValue`. There are a couple of solutions: First we can move `~RFieldBase()` back into the source file:; ```diff; diff --git a/tree/ntuple/v7/inc/ROOT/RField.hxx b/tree/ntuple/v7/inc/ROOT/RField.hxx; index deb9d5f4a3..cd0b5dd89e 100644; --- a/tree/ntuple/v7/inc/ROOT/RField.hxx; +++ b/tree/ntuple/v7/inc/ROOT/RField.hxx; @@ -570,7 +570,7 @@ public:; RFieldBase(RFieldBase&&) = default;; RFieldBase& operator =(const RFieldBase&) = delete;; RFieldBase& operator =(RFieldBase&&) = default;; - virtual ~RFieldBase() = default;; + virtual ~RFieldBase();; ; /// Copies the field and its sub fields using a possibly new name and a new, unconnected set of columns; std::unique_ptr<RFieldBase> Clone(std::string_view newName) const;; diff --git a/tree/ntuple/v7/src/RField.cxx b/tree/ntuple/v7/src/RField.cxx; index ef04fec76c..41d4962ac5 100644; --- a/tree/ntuple/v7/src/RField.cxx; +++ b/tree/ntuple/v7/src/RField.cxx; @@ -410,6 +410,10 @@ ROOT::Experimental::RFieldBase::RFieldBase(std::string_view name, std::string_vi; {; }; ; +ROOT::Experimental::RFieldBase::~RFieldBase(); +{; +}; +; std::string ROOT::Experimental::RFieldBase::GetQualifiedFieldName() const; {; std::string result = GetFieldName();; ```. Alternatively it helps to switch the `if constexpr` around to avoid the compiler instantiate the `RField<void>`:; ```diff; diff --git a/tree/ntuple/v7/inc/ROOT/REntry.hxx b/tree/ntuple/v7/inc/ROOT/REntry.hxx; index 1f3ec47095..b7b70b24cb 100644; --- a/tree/ntuple/v7/inc/ROOT/RE",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14468#issuecomment-1916371964
Availability,failure,failures,"Thank you all for your input! It is clear that the changes in this PR do not improve the situation by any means. Interestingly, this PR has triggered three new failures for exactly these two tutorials. I don't see how the failures on Windows can be related to the changes of this PR, but they are slightly more informative than usual and they were never seen before in the CI. For the failure on Mac ARM, we are hitting https://github.com/root-project/cling/issues/370 which I wasn't even aware of  . Yet another reason not to merge these changes  . ### Windows 64 bit. https://github.com/root-project/root/actions/runs/7693740131/job/20963073314?pr=14472. ```; Test #951: tutorial-v7-ntuple-ntpl007_mtFill .........................................................***Failed 2.06 sec; ; Processing C:/ROOT-CI/src/tutorials/v7/ntuple/ntpl007_mtFill.C...; Warning in <[ROOT.NTuple] Warning C:\ROOT-CI\src\tree\ntuple\v7\src\RPageStorageFile.cxx:52 in __cdecl ROOT::Experimental::Detail::RPageSinkFile::RPageSinkFile(class std::basic_string_view<char,struct std::char_traits<char> >,const class ROOT::Experimental::RNTupleWriteOptions &)>: The RNTuple file format will change. Do not store real data with this version of RNTuple!; Fatal: (typedValue->size() % fItemSize) == 0 violated at line 1986 of `C:\ROOT-CI\src\tree\ntuple\v7\src\RField.cxx'; aborting; CMake Error at C:/ROOT-CI/build/RootTestDriver.cmake:232 (message):; error code: Exit code 0xc0000374; ```. ```; 1258/2174 Test #960: tutorial-v7-concurrentfill.cxx ............................................................***Failed 6.42 sec; ; Processing C:/ROOT-CI/src/tutorials/v7/concurrentfill.cxx...; CMake Error at C:/ROOT-CI/build/RootTestDriver.cmake:232 (message):; error code: Access violation; ```. ### Windows 32bit . https://github.com/root-project/root/actions/runs/7693740131/job/20963073797?pr=14472. ```; 1242/2175 Test #950: tutorial-v7-ntuple-ntpl007_mtFill .........................................................***Fail",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14472#issuecomment-1915527940
Integrability,message,message,".com/root-project/cling/issues/370 which I wasn't even aware of  . Yet another reason not to merge these changes  . ### Windows 64 bit. https://github.com/root-project/root/actions/runs/7693740131/job/20963073314?pr=14472. ```; Test #951: tutorial-v7-ntuple-ntpl007_mtFill .........................................................***Failed 2.06 sec; ; Processing C:/ROOT-CI/src/tutorials/v7/ntuple/ntpl007_mtFill.C...; Warning in <[ROOT.NTuple] Warning C:\ROOT-CI\src\tree\ntuple\v7\src\RPageStorageFile.cxx:52 in __cdecl ROOT::Experimental::Detail::RPageSinkFile::RPageSinkFile(class std::basic_string_view<char,struct std::char_traits<char> >,const class ROOT::Experimental::RNTupleWriteOptions &)>: The RNTuple file format will change. Do not store real data with this version of RNTuple!; Fatal: (typedValue->size() % fItemSize) == 0 violated at line 1986 of `C:\ROOT-CI\src\tree\ntuple\v7\src\RField.cxx'; aborting; CMake Error at C:/ROOT-CI/build/RootTestDriver.cmake:232 (message):; error code: Exit code 0xc0000374; ```. ```; 1258/2174 Test #960: tutorial-v7-concurrentfill.cxx ............................................................***Failed 6.42 sec; ; Processing C:/ROOT-CI/src/tutorials/v7/concurrentfill.cxx...; CMake Error at C:/ROOT-CI/build/RootTestDriver.cmake:232 (message):; error code: Access violation; ```. ### Windows 32bit . https://github.com/root-project/root/actions/runs/7693740131/job/20963073797?pr=14472. ```; 1242/2175 Test #950: tutorial-v7-ntuple-ntpl007_mtFill .........................................................***Failed 2.52 sec; ; Processing C:/ROOT-CI/src/tutorials/v7/ntuple/ntpl007_mtFill.C...; Warning in <[ROOT.NTuple] Warning C:\ROOT-CI\src\tree\ntuple\v7\src\RPageStorageFile.cxx:52 in __thiscall ROOT::Experimental::Detail::RPageSinkFile::RPageSinkFile(class std::basic_string_view<char,struct std::char_traits<char> >,const class ROOT::Experimental::RNTupleWriteOptions &)>: The RNTuple file format will change. Do not store real data with ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14472#issuecomment-1915527940
Performance,concurren,concurrentfill,"are of  . Yet another reason not to merge these changes  . ### Windows 64 bit. https://github.com/root-project/root/actions/runs/7693740131/job/20963073314?pr=14472. ```; Test #951: tutorial-v7-ntuple-ntpl007_mtFill .........................................................***Failed 2.06 sec; ; Processing C:/ROOT-CI/src/tutorials/v7/ntuple/ntpl007_mtFill.C...; Warning in <[ROOT.NTuple] Warning C:\ROOT-CI\src\tree\ntuple\v7\src\RPageStorageFile.cxx:52 in __cdecl ROOT::Experimental::Detail::RPageSinkFile::RPageSinkFile(class std::basic_string_view<char,struct std::char_traits<char> >,const class ROOT::Experimental::RNTupleWriteOptions &)>: The RNTuple file format will change. Do not store real data with this version of RNTuple!; Fatal: (typedValue->size() % fItemSize) == 0 violated at line 1986 of `C:\ROOT-CI\src\tree\ntuple\v7\src\RField.cxx'; aborting; CMake Error at C:/ROOT-CI/build/RootTestDriver.cmake:232 (message):; error code: Exit code 0xc0000374; ```. ```; 1258/2174 Test #960: tutorial-v7-concurrentfill.cxx ............................................................***Failed 6.42 sec; ; Processing C:/ROOT-CI/src/tutorials/v7/concurrentfill.cxx...; CMake Error at C:/ROOT-CI/build/RootTestDriver.cmake:232 (message):; error code: Access violation; ```. ### Windows 32bit . https://github.com/root-project/root/actions/runs/7693740131/job/20963073797?pr=14472. ```; 1242/2175 Test #950: tutorial-v7-ntuple-ntpl007_mtFill .........................................................***Failed 2.52 sec; ; Processing C:/ROOT-CI/src/tutorials/v7/ntuple/ntpl007_mtFill.C...; Warning in <[ROOT.NTuple] Warning C:\ROOT-CI\src\tree\ntuple\v7\src\RPageStorageFile.cxx:52 in __thiscall ROOT::Experimental::Detail::RPageSinkFile::RPageSinkFile(class std::basic_string_view<char,struct std::char_traits<char> >,const class ROOT::Experimental::RNTupleWriteOptions &)>: The RNTuple file format will change. Do not store real data with this version of RNTuple!; CMake Error at C:/ROOT-CI/build",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14472#issuecomment-1915527940
Safety,abort,aborting," CI. For the failure on Mac ARM, we are hitting https://github.com/root-project/cling/issues/370 which I wasn't even aware of  . Yet another reason not to merge these changes  . ### Windows 64 bit. https://github.com/root-project/root/actions/runs/7693740131/job/20963073314?pr=14472. ```; Test #951: tutorial-v7-ntuple-ntpl007_mtFill .........................................................***Failed 2.06 sec; ; Processing C:/ROOT-CI/src/tutorials/v7/ntuple/ntpl007_mtFill.C...; Warning in <[ROOT.NTuple] Warning C:\ROOT-CI\src\tree\ntuple\v7\src\RPageStorageFile.cxx:52 in __cdecl ROOT::Experimental::Detail::RPageSinkFile::RPageSinkFile(class std::basic_string_view<char,struct std::char_traits<char> >,const class ROOT::Experimental::RNTupleWriteOptions &)>: The RNTuple file format will change. Do not store real data with this version of RNTuple!; Fatal: (typedValue->size() % fItemSize) == 0 violated at line 1986 of `C:\ROOT-CI\src\tree\ntuple\v7\src\RField.cxx'; aborting; CMake Error at C:/ROOT-CI/build/RootTestDriver.cmake:232 (message):; error code: Exit code 0xc0000374; ```. ```; 1258/2174 Test #960: tutorial-v7-concurrentfill.cxx ............................................................***Failed 6.42 sec; ; Processing C:/ROOT-CI/src/tutorials/v7/concurrentfill.cxx...; CMake Error at C:/ROOT-CI/build/RootTestDriver.cmake:232 (message):; error code: Access violation; ```. ### Windows 32bit . https://github.com/root-project/root/actions/runs/7693740131/job/20963073797?pr=14472. ```; 1242/2175 Test #950: tutorial-v7-ntuple-ntpl007_mtFill .........................................................***Failed 2.52 sec; ; Processing C:/ROOT-CI/src/tutorials/v7/ntuple/ntpl007_mtFill.C...; Warning in <[ROOT.NTuple] Warning C:\ROOT-CI\src\tree\ntuple\v7\src\RPageStorageFile.cxx:52 in __thiscall ROOT::Experimental::Detail::RPageSinkFile::RPageSinkFile(class std::basic_string_view<char,struct std::char_traits<char> >,const class ROOT::Experimental::RNTupleWriteOptions &)>: The ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14472#issuecomment-1915527940
Usability,clear,clear,"Thank you all for your input! It is clear that the changes in this PR do not improve the situation by any means. Interestingly, this PR has triggered three new failures for exactly these two tutorials. I don't see how the failures on Windows can be related to the changes of this PR, but they are slightly more informative than usual and they were never seen before in the CI. For the failure on Mac ARM, we are hitting https://github.com/root-project/cling/issues/370 which I wasn't even aware of  . Yet another reason not to merge these changes  . ### Windows 64 bit. https://github.com/root-project/root/actions/runs/7693740131/job/20963073314?pr=14472. ```; Test #951: tutorial-v7-ntuple-ntpl007_mtFill .........................................................***Failed 2.06 sec; ; Processing C:/ROOT-CI/src/tutorials/v7/ntuple/ntpl007_mtFill.C...; Warning in <[ROOT.NTuple] Warning C:\ROOT-CI\src\tree\ntuple\v7\src\RPageStorageFile.cxx:52 in __cdecl ROOT::Experimental::Detail::RPageSinkFile::RPageSinkFile(class std::basic_string_view<char,struct std::char_traits<char> >,const class ROOT::Experimental::RNTupleWriteOptions &)>: The RNTuple file format will change. Do not store real data with this version of RNTuple!; Fatal: (typedValue->size() % fItemSize) == 0 violated at line 1986 of `C:\ROOT-CI\src\tree\ntuple\v7\src\RField.cxx'; aborting; CMake Error at C:/ROOT-CI/build/RootTestDriver.cmake:232 (message):; error code: Exit code 0xc0000374; ```. ```; 1258/2174 Test #960: tutorial-v7-concurrentfill.cxx ............................................................***Failed 6.42 sec; ; Processing C:/ROOT-CI/src/tutorials/v7/concurrentfill.cxx...; CMake Error at C:/ROOT-CI/build/RootTestDriver.cmake:232 (message):; error code: Access violation; ```. ### Windows 32bit . https://github.com/root-project/root/actions/runs/7693740131/job/20963073797?pr=14472. ```; 1242/2175 Test #950: tutorial-v7-ntuple-ntpl007_mtFill .........................................................***Fail",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14472#issuecomment-1915527940
Testability,test,test,"> No test was broken in the incrementals: perhaps we can give it a try in the nightlies?. I was hoping getting some feedback from @krasznaa before merging, but I guess we can merge and we'll see afterwards",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14474#issuecomment-1923285964
Usability,feedback,feedback,"> No test was broken in the incrementals: perhaps we can give it a try in the nightlies?. I was hoping getting some feedback from @krasznaa before merging, but I guess we can merge and we'll see afterwards",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14474#issuecomment-1923285964
Availability,error,errors,"Hello both of you!; Thank you so much for the quick reply!; I went through my text again and didn't notice it repeated itself...! Sorry for that!. Considering the suggestion from @dpiparo , I have checked all the dependencies. Some I had to install, but now they are all in the system. I have tried to go through the cmake again and got the same problems. You suggest me to try from scratch again. I can do this simply by deleting the folders I have created for the installation and redo the process in the page ""build from source""?. I have tried the workaround suggested by @ferdymercury ! Firstly I have tried the snap version and nothing happened. Same errors. Now I have downloaded the pre-compiled version and I can use it, open canvases and browsers with no problem. I will run some macros to compare with the outputs I had previously and check if everything is according to what I had. Eventhough it is already working, I am willing to try and build it from source if that can help you somehow figuring out some kind of challanges you would like to improve in further versions! Please let me know if I can be of any use!. Thank you very much once again! It is always amazing to receive this kind of comprehensible support :))))",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14479#issuecomment-1916915766
Deployability,install,install,"Hello both of you!; Thank you so much for the quick reply!; I went through my text again and didn't notice it repeated itself...! Sorry for that!. Considering the suggestion from @dpiparo , I have checked all the dependencies. Some I had to install, but now they are all in the system. I have tried to go through the cmake again and got the same problems. You suggest me to try from scratch again. I can do this simply by deleting the folders I have created for the installation and redo the process in the page ""build from source""?. I have tried the workaround suggested by @ferdymercury ! Firstly I have tried the snap version and nothing happened. Same errors. Now I have downloaded the pre-compiled version and I can use it, open canvases and browsers with no problem. I will run some macros to compare with the outputs I had previously and check if everything is according to what I had. Eventhough it is already working, I am willing to try and build it from source if that can help you somehow figuring out some kind of challanges you would like to improve in further versions! Please let me know if I can be of any use!. Thank you very much once again! It is always amazing to receive this kind of comprehensible support :))))",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14479#issuecomment-1916915766
Integrability,depend,dependencies,"Hello both of you!; Thank you so much for the quick reply!; I went through my text again and didn't notice it repeated itself...! Sorry for that!. Considering the suggestion from @dpiparo , I have checked all the dependencies. Some I had to install, but now they are all in the system. I have tried to go through the cmake again and got the same problems. You suggest me to try from scratch again. I can do this simply by deleting the folders I have created for the installation and redo the process in the page ""build from source""?. I have tried the workaround suggested by @ferdymercury ! Firstly I have tried the snap version and nothing happened. Same errors. Now I have downloaded the pre-compiled version and I can use it, open canvases and browsers with no problem. I will run some macros to compare with the outputs I had previously and check if everything is according to what I had. Eventhough it is already working, I am willing to try and build it from source if that can help you somehow figuring out some kind of challanges you would like to improve in further versions! Please let me know if I can be of any use!. Thank you very much once again! It is always amazing to receive this kind of comprehensible support :))))",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14479#issuecomment-1916915766
Usability,simpl,simply,"Hello both of you!; Thank you so much for the quick reply!; I went through my text again and didn't notice it repeated itself...! Sorry for that!. Considering the suggestion from @dpiparo , I have checked all the dependencies. Some I had to install, but now they are all in the system. I have tried to go through the cmake again and got the same problems. You suggest me to try from scratch again. I can do this simply by deleting the folders I have created for the installation and redo the process in the page ""build from source""?. I have tried the workaround suggested by @ferdymercury ! Firstly I have tried the snap version and nothing happened. Same errors. Now I have downloaded the pre-compiled version and I can use it, open canvases and browsers with no problem. I will run some macros to compare with the outputs I had previously and check if everything is according to what I had. Eventhough it is already working, I am willing to try and build it from source if that can help you somehow figuring out some kind of challanges you would like to improve in further versions! Please let me know if I can be of any use!. Thank you very much once again! It is always amazing to receive this kind of comprehensible support :))))",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14479#issuecomment-1916915766
Usability,simpl,simpleread,[conversionWithChecksum.tgz](https://github.com/root-project/root/files/14102267/conversionWithChecksum.tgz). contains the full example:. ```; root.exe -b -l -q writedata.C+; root.exe -b -l -q simpleread.C+ ; ```; ```; ***********************************; * Row * Instance * seg_split *; ***********************************; Error in <TBufferFile::CheckByteCount>: object of class vector<CSCSegment> read too few bytes: 4 instead of 24; * 0 * 0 * 0 *; ***********************************; Error in <TBufferFile::CheckByteCount>: object of class vector<MatchedCSCSegment> read too few bytes: 12 instead of 24; ***********************************; * Row * Instance * seg_unspl *; ***********************************; Error in <TBufferFile::CheckByteCount>: object of class vector<MatchedCSCSegment> read too few bytes: 12 instead of 24; Error in <TBufferFile::CheckByteCount>: object of class vector<MatchedCSCSegment> read too few bytes: 12 instead of 24; * 0 * 0 * 1 *; ***********************************. ```,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14491#issuecomment-1917587621
Availability,error,error,Build failed on mac12arm/cxx20.; Running on 194.12.161.128:/Users/sftnight/build/workspace/root-pullrequests-build; [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/197157/console).; ### Errors:; - [2024-03-01T02:45:13.661Z] FAILED: interpreter/llvm-project/llvm/tools/clang/lib/Serialization/CMakeFiles/obj.clangSerialization.dir/ASTWriterDecl.cpp.o ; - [2024-03-01T02:45:13.661Z] /Users/sftnight/build/workspace/root-pullrequests-build/root/interpreter/llvm-project/clang/lib/Serialization/ASTWriterDecl.cpp:2440:3: error: use of undeclared identifier 'DeclSpecializationsAbbrev' ; - [2024-03-01T02:45:14.375Z] FAILED: interpreter/llvm-project/llvm/tools/clang/lib/Serialization/CMakeFiles/obj.clangSerialization.dir/ASTWriter.cpp.o ; - [2024-03-01T02:45:14.375Z] /Users/sftnight/build/workspace/root-pullrequests-build/root/interpreter/llvm-project/clang/lib/Serialization/ASTWriter.cpp:3898:29: error: no member named 'endianness' in namespace 'llvm'; did you mean simply 'endianness'? ; - [2024-03-01T02:45:14.375Z] /Users/sftnight/build/workspace/root-pullrequests-build/root/interpreter/llvm-project/clang/lib/Serialization/ASTWriter.cpp:3914:28: error: no member named 'endianness' in namespace 'llvm'; did you mean simply 'endianness'? ; - [2024-03-01T02:45:14.375Z] /Users/sftnight/build/workspace/root-pullrequests-build/root/interpreter/llvm-project/clang/lib/Serialization/ASTWriter.cpp:3922:28: error: no member named 'endianness' in namespace 'llvm'; did you mean simply 'endianness'? ; - [2024-03-01T02:45:14.375Z] /Users/sftnight/build/workspace/root-pullrequests-build/root/interpreter/llvm-project/clang/lib/Serialization/ASTWriter.cpp:3993:29: error: use of undeclared identifier 'DeclSpecializationsAbbrev',MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14495#issuecomment-1972366916
Usability,simpl,simply,Build failed on mac12arm/cxx20.; Running on 194.12.161.128:/Users/sftnight/build/workspace/root-pullrequests-build; [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/197157/console).; ### Errors:; - [2024-03-01T02:45:13.661Z] FAILED: interpreter/llvm-project/llvm/tools/clang/lib/Serialization/CMakeFiles/obj.clangSerialization.dir/ASTWriterDecl.cpp.o ; - [2024-03-01T02:45:13.661Z] /Users/sftnight/build/workspace/root-pullrequests-build/root/interpreter/llvm-project/clang/lib/Serialization/ASTWriterDecl.cpp:2440:3: error: use of undeclared identifier 'DeclSpecializationsAbbrev' ; - [2024-03-01T02:45:14.375Z] FAILED: interpreter/llvm-project/llvm/tools/clang/lib/Serialization/CMakeFiles/obj.clangSerialization.dir/ASTWriter.cpp.o ; - [2024-03-01T02:45:14.375Z] /Users/sftnight/build/workspace/root-pullrequests-build/root/interpreter/llvm-project/clang/lib/Serialization/ASTWriter.cpp:3898:29: error: no member named 'endianness' in namespace 'llvm'; did you mean simply 'endianness'? ; - [2024-03-01T02:45:14.375Z] /Users/sftnight/build/workspace/root-pullrequests-build/root/interpreter/llvm-project/clang/lib/Serialization/ASTWriter.cpp:3914:28: error: no member named 'endianness' in namespace 'llvm'; did you mean simply 'endianness'? ; - [2024-03-01T02:45:14.375Z] /Users/sftnight/build/workspace/root-pullrequests-build/root/interpreter/llvm-project/clang/lib/Serialization/ASTWriter.cpp:3922:28: error: no member named 'endianness' in namespace 'llvm'; did you mean simply 'endianness'? ; - [2024-03-01T02:45:14.375Z] /Users/sftnight/build/workspace/root-pullrequests-build/root/interpreter/llvm-project/clang/lib/Serialization/ASTWriter.cpp:3993:29: error: use of undeclared identifier 'DeclSpecializationsAbbrev',MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14495#issuecomment-1972366916
Deployability,patch,patches,"> I strongly believe we should have a similar approach as with our LLVM fork. We need to have some ""source of truth"" that is a certain cppyy/CPyCPPyy tag from upstream and then a clear way to reach the status of our fork from there, i.e. a series of patches that can be applied without conflicts. This PR goes in that direction but doesn't implement it fully as the sync script refers to a repository outside of our organisation. Ideally we would have separate repositories (one for cppyy and one for CPyCppyy) that we can refer to. Thanks for raising this point. The situation will be improved in the next weeks, I'll try to get as many patches merged to upstream as possible. Then, based on how many differences are left, we can decide if we want to go with one (or multiple) separate repositories, or we stay with the patch files.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14507#issuecomment-2007655575
Usability,clear,clear,"> I strongly believe we should have a similar approach as with our LLVM fork. We need to have some ""source of truth"" that is a certain cppyy/CPyCPPyy tag from upstream and then a clear way to reach the status of our fork from there, i.e. a series of patches that can be applied without conflicts. This PR goes in that direction but doesn't implement it fully as the sync script refers to a repository outside of our organisation. Ideally we would have separate repositories (one for cppyy and one for CPyCppyy) that we can refer to. Thanks for raising this point. The situation will be improved in the next weeks, I'll try to get as many patches merged to upstream as possible. Then, based on how many differences are left, we can decide if we want to go with one (or multiple) separate repositories, or we stay with the patch files.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14507#issuecomment-2007655575
Availability,error,errors,"So @jblomer naively asked ""what about ZLIB"", and it turns out to be equally wrong... I also added a test that at least catches the compression side of things. For the decompression, it's a bit harder because it's not clear how to check if the library read more bytes than it should have (without it running into errors because of decompression errors).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14523#issuecomment-1923740442
Testability,test,test,"So @jblomer naively asked ""what about ZLIB"", and it turns out to be equally wrong... I also added a test that at least catches the compression side of things. For the decompression, it's a bit harder because it's not clear how to check if the library read more bytes than it should have (without it running into errors because of decompression errors).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14523#issuecomment-1923740442
Usability,clear,clear,"So @jblomer naively asked ""what about ZLIB"", and it turns out to be equally wrong... I also added a test that at least catches the compression side of things. For the decompression, it's a bit harder because it's not clear how to check if the library read more bytes than it should have (without it running into errors because of decompression errors).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14523#issuecomment-1923740442
Deployability,configurat,configuration,"> To reiterate on why we ""only"" need to fix gzip and lzma: The other compression algorithms already do this,. Indeed. The diffs was made less obvious because:; ZLIB decompression is already doing the right thing.; ZLIB and LZMA use a struct to pass the configuration rather than function argument so the code pattern is slight different.; ; > it seems that all existing code paths in TKey.cxx, TBufferXML.cxx, TMessage.cxx, and TBasket.cxx allocate a buffer that is slightly larger, so it's probably not an as critical problem . Right, the allocations is done:; ```; Int_t buflen = TMath::Max(512,fKeylen + fObjlen + 9*nbuffers + 28); //add 28 bytes in case object is placed in a deleted gap; ```; and used via; ```; char *bufcur = &fBuffer[fKeylen];; ```; so the only extra is `9*nbuffers + 28` which reduces the risk of writing the end since the size is larger than `fObjlen + kHeaderSize` but that leaves 2 additional question:; * why are those added?; * why doesn't RNTuple need it?. 01bb6965557fcc63d5d2e535b89f57e025922731 hints that the compression engine were seen as writing past the end ... it is plausible since the prior delta was ``9*nbuffers + 8` with `nbuffers==0` is common case. (in hindsight, this commit was not investigated long enough and needed a test). The `9*nbuffers` is meant to be for the keys and is now inaccurate (most algorithms have a 9 bytes header but for lz4 we have seemingly 73. This part is missing from the `RNTuple` usage. The consequences is that on data set that is not compressible `TTree` might use a bit more space (header + barely compressed size) vs `RNTuple` (uncompressed size which might be less than header + barely compressed size). This of course assume that the compression algorithm strictly respect the limit given (it would be a serious security risk if not). The `8` is commented as ""8 bytes in case object is placed in a deleted gap"" (the 20 was seemingly added to work-around the bug fixed here) ~and is not clear to me (the 'delete gap' is ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14523#issuecomment-1932803605
Energy Efficiency,allocate,allocate,"> To reiterate on why we ""only"" need to fix gzip and lzma: The other compression algorithms already do this,. Indeed. The diffs was made less obvious because:; ZLIB decompression is already doing the right thing.; ZLIB and LZMA use a struct to pass the configuration rather than function argument so the code pattern is slight different.; ; > it seems that all existing code paths in TKey.cxx, TBufferXML.cxx, TMessage.cxx, and TBasket.cxx allocate a buffer that is slightly larger, so it's probably not an as critical problem . Right, the allocations is done:; ```; Int_t buflen = TMath::Max(512,fKeylen + fObjlen + 9*nbuffers + 28); //add 28 bytes in case object is placed in a deleted gap; ```; and used via; ```; char *bufcur = &fBuffer[fKeylen];; ```; so the only extra is `9*nbuffers + 28` which reduces the risk of writing the end since the size is larger than `fObjlen + kHeaderSize` but that leaves 2 additional question:; * why are those added?; * why doesn't RNTuple need it?. 01bb6965557fcc63d5d2e535b89f57e025922731 hints that the compression engine were seen as writing past the end ... it is plausible since the prior delta was ``9*nbuffers + 8` with `nbuffers==0` is common case. (in hindsight, this commit was not investigated long enough and needed a test). The `9*nbuffers` is meant to be for the keys and is now inaccurate (most algorithms have a 9 bytes header but for lz4 we have seemingly 73. This part is missing from the `RNTuple` usage. The consequences is that on data set that is not compressible `TTree` might use a bit more space (header + barely compressed size) vs `RNTuple` (uncompressed size which might be less than header + barely compressed size). This of course assume that the compression algorithm strictly respect the limit given (it would be a serious security risk if not). The `8` is commented as ""8 bytes in case object is placed in a deleted gap"" (the 20 was seemingly added to work-around the bug fixed here) ~and is not clear to me (the 'delete gap' is ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14523#issuecomment-1932803605
Modifiability,config,configuration,"> To reiterate on why we ""only"" need to fix gzip and lzma: The other compression algorithms already do this,. Indeed. The diffs was made less obvious because:; ZLIB decompression is already doing the right thing.; ZLIB and LZMA use a struct to pass the configuration rather than function argument so the code pattern is slight different.; ; > it seems that all existing code paths in TKey.cxx, TBufferXML.cxx, TMessage.cxx, and TBasket.cxx allocate a buffer that is slightly larger, so it's probably not an as critical problem . Right, the allocations is done:; ```; Int_t buflen = TMath::Max(512,fKeylen + fObjlen + 9*nbuffers + 28); //add 28 bytes in case object is placed in a deleted gap; ```; and used via; ```; char *bufcur = &fBuffer[fKeylen];; ```; so the only extra is `9*nbuffers + 28` which reduces the risk of writing the end since the size is larger than `fObjlen + kHeaderSize` but that leaves 2 additional question:; * why are those added?; * why doesn't RNTuple need it?. 01bb6965557fcc63d5d2e535b89f57e025922731 hints that the compression engine were seen as writing past the end ... it is plausible since the prior delta was ``9*nbuffers + 8` with `nbuffers==0` is common case. (in hindsight, this commit was not investigated long enough and needed a test). The `9*nbuffers` is meant to be for the keys and is now inaccurate (most algorithms have a 9 bytes header but for lz4 we have seemingly 73. This part is missing from the `RNTuple` usage. The consequences is that on data set that is not compressible `TTree` might use a bit more space (header + barely compressed size) vs `RNTuple` (uncompressed size which might be less than header + barely compressed size). This of course assume that the compression algorithm strictly respect the limit given (it would be a serious security risk if not). The `8` is commented as ""8 bytes in case object is placed in a deleted gap"" (the 20 was seemingly added to work-around the bug fixed here) ~and is not clear to me (the 'delete gap' is ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14523#issuecomment-1932803605
Safety,risk,risk,"> To reiterate on why we ""only"" need to fix gzip and lzma: The other compression algorithms already do this,. Indeed. The diffs was made less obvious because:; ZLIB decompression is already doing the right thing.; ZLIB and LZMA use a struct to pass the configuration rather than function argument so the code pattern is slight different.; ; > it seems that all existing code paths in TKey.cxx, TBufferXML.cxx, TMessage.cxx, and TBasket.cxx allocate a buffer that is slightly larger, so it's probably not an as critical problem . Right, the allocations is done:; ```; Int_t buflen = TMath::Max(512,fKeylen + fObjlen + 9*nbuffers + 28); //add 28 bytes in case object is placed in a deleted gap; ```; and used via; ```; char *bufcur = &fBuffer[fKeylen];; ```; so the only extra is `9*nbuffers + 28` which reduces the risk of writing the end since the size is larger than `fObjlen + kHeaderSize` but that leaves 2 additional question:; * why are those added?; * why doesn't RNTuple need it?. 01bb6965557fcc63d5d2e535b89f57e025922731 hints that the compression engine were seen as writing past the end ... it is plausible since the prior delta was ``9*nbuffers + 8` with `nbuffers==0` is common case. (in hindsight, this commit was not investigated long enough and needed a test). The `9*nbuffers` is meant to be for the keys and is now inaccurate (most algorithms have a 9 bytes header but for lz4 we have seemingly 73. This part is missing from the `RNTuple` usage. The consequences is that on data set that is not compressible `TTree` might use a bit more space (header + barely compressed size) vs `RNTuple` (uncompressed size which might be less than header + barely compressed size). This of course assume that the compression algorithm strictly respect the limit given (it would be a serious security risk if not). The `8` is commented as ""8 bytes in case object is placed in a deleted gap"" (the 20 was seemingly added to work-around the bug fixed here) ~and is not clear to me (the 'delete gap' is ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14523#issuecomment-1932803605
Security,secur,security,"other compression algorithms already do this,. Indeed. The diffs was made less obvious because:; ZLIB decompression is already doing the right thing.; ZLIB and LZMA use a struct to pass the configuration rather than function argument so the code pattern is slight different.; ; > it seems that all existing code paths in TKey.cxx, TBufferXML.cxx, TMessage.cxx, and TBasket.cxx allocate a buffer that is slightly larger, so it's probably not an as critical problem . Right, the allocations is done:; ```; Int_t buflen = TMath::Max(512,fKeylen + fObjlen + 9*nbuffers + 28); //add 28 bytes in case object is placed in a deleted gap; ```; and used via; ```; char *bufcur = &fBuffer[fKeylen];; ```; so the only extra is `9*nbuffers + 28` which reduces the risk of writing the end since the size is larger than `fObjlen + kHeaderSize` but that leaves 2 additional question:; * why are those added?; * why doesn't RNTuple need it?. 01bb6965557fcc63d5d2e535b89f57e025922731 hints that the compression engine were seen as writing past the end ... it is plausible since the prior delta was ``9*nbuffers + 8` with `nbuffers==0` is common case. (in hindsight, this commit was not investigated long enough and needed a test). The `9*nbuffers` is meant to be for the keys and is now inaccurate (most algorithms have a 9 bytes header but for lz4 we have seemingly 73. This part is missing from the `RNTuple` usage. The consequences is that on data set that is not compressible `TTree` might use a bit more space (header + barely compressed size) vs `RNTuple` (uncompressed size which might be less than header + barely compressed size). This of course assume that the compression algorithm strictly respect the limit given (it would be a serious security risk if not). The `8` is commented as ""8 bytes in case object is placed in a deleted gap"" (the 20 was seemingly added to work-around the bug fixed here) ~and is not clear to me (the 'delete gap' is most likely talking about a space 'freed' inside a ROOT file.~",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14523#issuecomment-1932803605
Testability,test,test,"other compression algorithms already do this,. Indeed. The diffs was made less obvious because:; ZLIB decompression is already doing the right thing.; ZLIB and LZMA use a struct to pass the configuration rather than function argument so the code pattern is slight different.; ; > it seems that all existing code paths in TKey.cxx, TBufferXML.cxx, TMessage.cxx, and TBasket.cxx allocate a buffer that is slightly larger, so it's probably not an as critical problem . Right, the allocations is done:; ```; Int_t buflen = TMath::Max(512,fKeylen + fObjlen + 9*nbuffers + 28); //add 28 bytes in case object is placed in a deleted gap; ```; and used via; ```; char *bufcur = &fBuffer[fKeylen];; ```; so the only extra is `9*nbuffers + 28` which reduces the risk of writing the end since the size is larger than `fObjlen + kHeaderSize` but that leaves 2 additional question:; * why are those added?; * why doesn't RNTuple need it?. 01bb6965557fcc63d5d2e535b89f57e025922731 hints that the compression engine were seen as writing past the end ... it is plausible since the prior delta was ``9*nbuffers + 8` with `nbuffers==0` is common case. (in hindsight, this commit was not investigated long enough and needed a test). The `9*nbuffers` is meant to be for the keys and is now inaccurate (most algorithms have a 9 bytes header but for lz4 we have seemingly 73. This part is missing from the `RNTuple` usage. The consequences is that on data set that is not compressible `TTree` might use a bit more space (header + barely compressed size) vs `RNTuple` (uncompressed size which might be less than header + barely compressed size). This of course assume that the compression algorithm strictly respect the limit given (it would be a serious security risk if not). The `8` is commented as ""8 bytes in case object is placed in a deleted gap"" (the 20 was seemingly added to work-around the bug fixed here) ~and is not clear to me (the 'delete gap' is most likely talking about a space 'freed' inside a ROOT file.~",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14523#issuecomment-1932803605
Usability,clear,clear,"other compression algorithms already do this,. Indeed. The diffs was made less obvious because:; ZLIB decompression is already doing the right thing.; ZLIB and LZMA use a struct to pass the configuration rather than function argument so the code pattern is slight different.; ; > it seems that all existing code paths in TKey.cxx, TBufferXML.cxx, TMessage.cxx, and TBasket.cxx allocate a buffer that is slightly larger, so it's probably not an as critical problem . Right, the allocations is done:; ```; Int_t buflen = TMath::Max(512,fKeylen + fObjlen + 9*nbuffers + 28); //add 28 bytes in case object is placed in a deleted gap; ```; and used via; ```; char *bufcur = &fBuffer[fKeylen];; ```; so the only extra is `9*nbuffers + 28` which reduces the risk of writing the end since the size is larger than `fObjlen + kHeaderSize` but that leaves 2 additional question:; * why are those added?; * why doesn't RNTuple need it?. 01bb6965557fcc63d5d2e535b89f57e025922731 hints that the compression engine were seen as writing past the end ... it is plausible since the prior delta was ``9*nbuffers + 8` with `nbuffers==0` is common case. (in hindsight, this commit was not investigated long enough and needed a test). The `9*nbuffers` is meant to be for the keys and is now inaccurate (most algorithms have a 9 bytes header but for lz4 we have seemingly 73. This part is missing from the `RNTuple` usage. The consequences is that on data set that is not compressible `TTree` might use a bit more space (header + barely compressed size) vs `RNTuple` (uncompressed size which might be less than header + barely compressed size). This of course assume that the compression algorithm strictly respect the limit given (it would be a serious security risk if not). The `8` is commented as ""8 bytes in case object is placed in a deleted gap"" (the 20 was seemingly added to work-around the bug fixed here) ~and is not clear to me (the 'delete gap' is most likely talking about a space 'freed' inside a ROOT file.~",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14523#issuecomment-1932803605
Usability,simpl,simple,"Indeed this has nothing to do with TRatioplot. It can be reproduced with the simple following macro:. ```; void lineonaxis(){; auto c1 = new TCanvas(""c1"", ""c1"",10,53,700,525);; gPad->DrawFrame(-5,-1.25,5,1.25);; TLine *line = new TLine(-5,-0.5,5,-0.5);; line->SetLineStyle(2);; line->Draw();; }; ```; Which, on my Mac, gives:; <img width=""648"" alt=""Screenshot 2024-02-13 at 13 21 33"" src=""https://github.com/root-project/root/assets/4697738/26ecd350-74f0-4529-b84b-decc8c210490"">; It is a precision issue. It might be that on an other machine it will not give the same result.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14546#issuecomment-1941397971
Usability,simpl,simplified,"The problem has been simplified to:; ```; {; double x = 6.25;; double y = 1.5625000232831;; double y1 = -y;; double y2 = y;; double yv = -0.5;. auto c1 = new TCanvas(""c1"", ""c1"", 0, 0, 700, 525);; c1->Range(-x, y1, x, y2);. TLine *line = new TLine();; line->DrawLine(-x, yv, x, yv) ->SetLineColor(kRed);. double r = 1./(y2-y1);; line->DrawLineNDC(0., r*(yv-y1),; 1., r*(yv-y1))->SetLineColor(kBlue);. }; ```; DrawlLine paint a red horizontal line at `yv = 0.5`. DrawLineNDC does the same in NDC coordinates. The 2 lines should overlap but they don't (by 1 pixel). Note that the values defined at the beginning of the macro are those that make the problem. As soon as you change, for instance, `y` the lines will overlap. Same if you change interactively the canvas size.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14546#issuecomment-1943627143
Usability,simpl,simple,"The same problem shows with web canvas (@linev ?) for instance with this simple macro:; ```; void lineonaxis(){; auto c1 = new TCanvas(""c1"", ""c1"", 0, 0, 700, 525);; c1->SetGridy();; TH1F *f = gPad->DrawFrame(-5, -1.25, 5, 1.25);; f->GetYaxis()->SetNdivisions(10);; f->GetXaxis()->SetNdivisions(0);. auto line = new TLine();; line->SetLineColor(kRed);; line->DrawLine(-5, -1., 5 , -1.);; line->DrawLine(-5, -0.5, 5 , -0.5);; line->DrawLine(-5, 0., 5 , 0.);; line->DrawLine(-5, 0.5, 5 , 0.5);; line->DrawLine(-5, 1., 5 , 1.);; }; ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14546#issuecomment-1943905642
Usability,simpl,simple,"Yes, I see same problem in JSROOT. It is because we are using different coordinates inside frame for axes/grids/histogram drawings and for `TLine` which is drawn in the pad coordinates. Main problem here that left/top coordinates of the frame are rounded integer values. ; And then axis position calculated relative to this rounded values.; In this example vertical coordinate of the frame should be `52.5`, but rounded to `52` or `53`.; Drawing will be perfect when canvas vertical size is 500. I see no simple solution here. ; To fix problem we have to change fX1, fY1, fX2, fY2 members of the TPad every time canvas width or height is changing. More easy solution is to provide extra draw option for `TLine` (and similar classes) where coordinates calculated using frame functions. Then it automatically will be adjusted to the rounded position of the frame",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14546#issuecomment-1944053421
Deployability,update,update,"One option is to move it to a users guide chapter.; Other option, copying relevant comment here by @guitargeek:. ```; This is still relevant. I have discussed with Lorenzo what we would have to do to close this issue:. The new users guide is the doxygen reference. The entry point to Minuit 2 is here:; https://root.cern.ch/doc/master/Minuit2Page.html. This doxygen page links to the old Minuit 2 users guide:; https://root.cern.ch/root/htmldoc/guides/minuit2/Minuit2.html. What needs to be done here is to move the old Minuit 2 guide (the source is somewhere in the ROOT repo) to the doxygen directly, and updating it by removing any information that is nowadays irrelevant (like how to build Minuit 2 with Autotools). The reason why we think that this is a meaningful update is that in Doxygen, it would generate automatically the useful links to the functions that are explained.; ```. Source is here: https://github.com/root-project/root/tree/master/documentation/minuit2",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14551#issuecomment-1948896479
Usability,guid,guide,"One option is to move it to a users guide chapter.; Other option, copying relevant comment here by @guitargeek:. ```; This is still relevant. I have discussed with Lorenzo what we would have to do to close this issue:. The new users guide is the doxygen reference. The entry point to Minuit 2 is here:; https://root.cern.ch/doc/master/Minuit2Page.html. This doxygen page links to the old Minuit 2 users guide:; https://root.cern.ch/root/htmldoc/guides/minuit2/Minuit2.html. What needs to be done here is to move the old Minuit 2 guide (the source is somewhere in the ROOT repo) to the doxygen directly, and updating it by removing any information that is nowadays irrelevant (like how to build Minuit 2 with Autotools). The reason why we think that this is a meaningful update is that in Doxygen, it would generate automatically the useful links to the functions that are explained.; ```. Source is here: https://github.com/root-project/root/tree/master/documentation/minuit2",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14551#issuecomment-1948896479
Usability,clear,clear,"In principle, it is clear what needs to happen, but I would like some input from @pcanal how throwing exceptions in these older parts of ROOT can best be handled (for the newer parts we use `ROOT::Experimental::RException`, but we cannot use this here).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14552#issuecomment-1943897509
Usability,clear,clear,"> In principle, it is clear what needs to happen, but I would like some input from @pcanal how throwing exceptions in these older parts of ROOT can best be handled (for the newer parts we use `ROOT::Experimental::RException`, but we cannot use this here). I think ""Fatal"" is the recommended way, see https://github.com/root-project/root/pull/14627#discussion_r1492987421. I just proposed a PR with that.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14552#issuecomment-1952072544
Availability,down,down,"> As a logical extension, the same happens for any additional branch that later files have, for example:. Thanks for the example. I simplified it further down to:. ```; #include ""TTree.h""; #include ""TFileMerger.h""; #include ""TFile.h""; #include ""TFileMergeInfo.h"". void printBranches(TTree *const tree) {; printf(""PrintBranches:\n"");; for (auto *branch : TRangeDynCast<TBranch>(tree->GetListOfBranches())) {; printf("" %s\n"", branch->GetName());; }; }. void ROOT_4716() {; TTree atree(""tree"", ""title"");; int value;; atree.Branch(""a"", &value);; printBranches(&atree);. TTree abtree(""tree"", ""title"");; abtree.Branch(""a"", &value);; abtree.Branch(""b"", &value);; value = 42;; abtree.Fill();; printBranches(&abtree);. TTree dummy;; TList treelist;; treelist.Add(&atree);; treelist.Add(&abtree);; std::unique_ptr<TFile> file(TFile::Open(""c.root"", ""RECREATE""));; TFileMergeInfo info(file.get());; dummy.Merge(&treelist, &info);; printBranches(&dummy);. treelist.Clear();; treelist.Add(&abtree);; std::unique_ptr<TFile> file2(TFile::Open(""d.root"", ""RECREATE""));; TFileMergeInfo info2(file2.get());; atree.Merge(&treelist, &info2);; printBranches(&atree);; }; ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14558#issuecomment-2022610545
Testability,log,logical,"> As a logical extension, the same happens for any additional branch that later files have, for example:. Thanks for the example. I simplified it further down to:. ```; #include ""TTree.h""; #include ""TFileMerger.h""; #include ""TFile.h""; #include ""TFileMergeInfo.h"". void printBranches(TTree *const tree) {; printf(""PrintBranches:\n"");; for (auto *branch : TRangeDynCast<TBranch>(tree->GetListOfBranches())) {; printf("" %s\n"", branch->GetName());; }; }. void ROOT_4716() {; TTree atree(""tree"", ""title"");; int value;; atree.Branch(""a"", &value);; printBranches(&atree);. TTree abtree(""tree"", ""title"");; abtree.Branch(""a"", &value);; abtree.Branch(""b"", &value);; value = 42;; abtree.Fill();; printBranches(&abtree);. TTree dummy;; TList treelist;; treelist.Add(&atree);; treelist.Add(&abtree);; std::unique_ptr<TFile> file(TFile::Open(""c.root"", ""RECREATE""));; TFileMergeInfo info(file.get());; dummy.Merge(&treelist, &info);; printBranches(&dummy);. treelist.Clear();; treelist.Add(&abtree);; std::unique_ptr<TFile> file2(TFile::Open(""d.root"", ""RECREATE""));; TFileMergeInfo info2(file2.get());; atree.Merge(&treelist, &info2);; printBranches(&atree);; }; ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14558#issuecomment-2022610545
Usability,simpl,simplified,"> As a logical extension, the same happens for any additional branch that later files have, for example:. Thanks for the example. I simplified it further down to:. ```; #include ""TTree.h""; #include ""TFileMerger.h""; #include ""TFile.h""; #include ""TFileMergeInfo.h"". void printBranches(TTree *const tree) {; printf(""PrintBranches:\n"");; for (auto *branch : TRangeDynCast<TBranch>(tree->GetListOfBranches())) {; printf("" %s\n"", branch->GetName());; }; }. void ROOT_4716() {; TTree atree(""tree"", ""title"");; int value;; atree.Branch(""a"", &value);; printBranches(&atree);. TTree abtree(""tree"", ""title"");; abtree.Branch(""a"", &value);; abtree.Branch(""b"", &value);; value = 42;; abtree.Fill();; printBranches(&abtree);. TTree dummy;; TList treelist;; treelist.Add(&atree);; treelist.Add(&abtree);; std::unique_ptr<TFile> file(TFile::Open(""c.root"", ""RECREATE""));; TFileMergeInfo info(file.get());; dummy.Merge(&treelist, &info);; printBranches(&dummy);. treelist.Clear();; treelist.Add(&abtree);; std::unique_ptr<TFile> file2(TFile::Open(""d.root"", ""RECREATE""));; TFileMergeInfo info2(file2.get());; atree.Merge(&treelist, &info2);; printBranches(&atree);; }; ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14558#issuecomment-2022610545
Performance,perform,performed,"Hi,. I started to take a look to this issue: the boundary check is not performed by the `TH1` methods that access a bin, e.g., `TH1C h(""h"","""",10,0,10); h.AddBinContent(12312312); ` and it can lead to undefined behavior (there is a piece of memory spoiled by this action). After reading the methods of TH1S, TH1I, TH1F, TH1D that access a bin content I can say:; * Each histogram class derives from the corresponding TArray class, e.g., TH1F derives from TArrayF; * Internally, the access to the bin is done _a la C_, straight to the element of the array , e.g. `fArray[nbin]` ; * The boundary check is already implemented for the methods `TArray::operator()[]` . A potential solution would be to use `TArray::operator()[]`, which actually check the boundary of the array. Another solution could be a simple `if` to check of the boundary without using the `TArray` features. . It is likely that this methods `SetBin*`, `AddBin*` may be called quite often, and such boundary check could have a great impact in performance. Is there experience of such case? @lmoneta , may I ask for your advice on this issue?. Best,; Alvaro",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14575#issuecomment-1940996892
Security,access,access,"Hi,. I started to take a look to this issue: the boundary check is not performed by the `TH1` methods that access a bin, e.g., `TH1C h(""h"","""",10,0,10); h.AddBinContent(12312312); ` and it can lead to undefined behavior (there is a piece of memory spoiled by this action). After reading the methods of TH1S, TH1I, TH1F, TH1D that access a bin content I can say:; * Each histogram class derives from the corresponding TArray class, e.g., TH1F derives from TArrayF; * Internally, the access to the bin is done _a la C_, straight to the element of the array , e.g. `fArray[nbin]` ; * The boundary check is already implemented for the methods `TArray::operator()[]` . A potential solution would be to use `TArray::operator()[]`, which actually check the boundary of the array. Another solution could be a simple `if` to check of the boundary without using the `TArray` features. . It is likely that this methods `SetBin*`, `AddBin*` may be called quite often, and such boundary check could have a great impact in performance. Is there experience of such case? @lmoneta , may I ask for your advice on this issue?. Best,; Alvaro",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14575#issuecomment-1940996892
Usability,simpl,simple,"Hi,. I started to take a look to this issue: the boundary check is not performed by the `TH1` methods that access a bin, e.g., `TH1C h(""h"","""",10,0,10); h.AddBinContent(12312312); ` and it can lead to undefined behavior (there is a piece of memory spoiled by this action). After reading the methods of TH1S, TH1I, TH1F, TH1D that access a bin content I can say:; * Each histogram class derives from the corresponding TArray class, e.g., TH1F derives from TArrayF; * Internally, the access to the bin is done _a la C_, straight to the element of the array , e.g. `fArray[nbin]` ; * The boundary check is already implemented for the methods `TArray::operator()[]` . A potential solution would be to use `TArray::operator()[]`, which actually check the boundary of the array. Another solution could be a simple `if` to check of the boundary without using the `TArray` features. . It is likely that this methods `SetBin*`, `AddBin*` may be called quite often, and such boundary check could have a great impact in performance. Is there experience of such case? @lmoneta , may I ask for your advice on this issue?. Best,; Alvaro",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14575#issuecomment-1940996892
Deployability,update,updates,"From a user point of view, the text in the ROOT manual now seems sufficiently clear:. - Behaviour for non-TTree objects [1]:. ""By default, existing objects are not replaced when writing new objects with the same name. Instead, a new namecycle is created, denoted by ;2, ;3, etc. When retrieving the object from the file, ROOT will automatically pick the highest namecycle. Some objects, such as histograms, automatically register themselves with the current TDirectory (e.g. the last TFile opened): these objects will appear as OBJ entries, without a namecycle. See also  [Object ownership](https://root.cern/manual/object_ownership). For the particular case of TTree, cycles only store metadata, see [Baskets, clusters and the tree header](https://root.cern/manual/trees/#baskets-clusters-and-the-tree-header)."". - Behaviour for TTree objects [2]:. ""Multiple updates of these headers can often be found in files (treename;1, treename;2 etc, called cycles, see  [Opening and inspecting a ROOT file](https://root.cern/manual/root_files/#opening-and-inspecting-a-root-file)). Only the last one (also accessible as treename) knows about all written baskets."". [1] https://root.cern/manual/root_files/#opening-and-inspecting-a-root-file; [2] https://root.cern/manual/trees/#baskets-clusters-and-the-tree-header",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14584#issuecomment-1943874457
Security,access,accessible,"From a user point of view, the text in the ROOT manual now seems sufficiently clear:. - Behaviour for non-TTree objects [1]:. ""By default, existing objects are not replaced when writing new objects with the same name. Instead, a new namecycle is created, denoted by ;2, ;3, etc. When retrieving the object from the file, ROOT will automatically pick the highest namecycle. Some objects, such as histograms, automatically register themselves with the current TDirectory (e.g. the last TFile opened): these objects will appear as OBJ entries, without a namecycle. See also  [Object ownership](https://root.cern/manual/object_ownership). For the particular case of TTree, cycles only store metadata, see [Baskets, clusters and the tree header](https://root.cern/manual/trees/#baskets-clusters-and-the-tree-header)."". - Behaviour for TTree objects [2]:. ""Multiple updates of these headers can often be found in files (treename;1, treename;2 etc, called cycles, see  [Opening and inspecting a ROOT file](https://root.cern/manual/root_files/#opening-and-inspecting-a-root-file)). Only the last one (also accessible as treename) knows about all written baskets."". [1] https://root.cern/manual/root_files/#opening-and-inspecting-a-root-file; [2] https://root.cern/manual/trees/#baskets-clusters-and-the-tree-header",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14584#issuecomment-1943874457
Usability,clear,clear,"From a user point of view, the text in the ROOT manual now seems sufficiently clear:. - Behaviour for non-TTree objects [1]:. ""By default, existing objects are not replaced when writing new objects with the same name. Instead, a new namecycle is created, denoted by ;2, ;3, etc. When retrieving the object from the file, ROOT will automatically pick the highest namecycle. Some objects, such as histograms, automatically register themselves with the current TDirectory (e.g. the last TFile opened): these objects will appear as OBJ entries, without a namecycle. See also  [Object ownership](https://root.cern/manual/object_ownership). For the particular case of TTree, cycles only store metadata, see [Baskets, clusters and the tree header](https://root.cern/manual/trees/#baskets-clusters-and-the-tree-header)."". - Behaviour for TTree objects [2]:. ""Multiple updates of these headers can often be found in files (treename;1, treename;2 etc, called cycles, see  [Opening and inspecting a ROOT file](https://root.cern/manual/root_files/#opening-and-inspecting-a-root-file)). Only the last one (also accessible as treename) knows about all written baskets."". [1] https://root.cern/manual/root_files/#opening-and-inspecting-a-root-file; [2] https://root.cern/manual/trees/#baskets-clusters-and-the-tree-header",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14584#issuecomment-1943874457
Security,access,access-from-command-shell,@vepadulano . All information is in the description of the PR.; THttpServer implements different kind of http requests.; Most of them described here:. https://root.cern/root/htmldoc/guides/HttpServer/HttpServer.html#data-access-from-command-shell. This PR adds one more.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14614#issuecomment-1931846997
Usability,guid,guides,@vepadulano . All information is in the description of the PR.; THttpServer implements different kind of http requests.; Most of them described here:. https://root.cern/root/htmldoc/guides/HttpServer/HttpServer.html#data-access-from-command-shell. This PR adds one more.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14614#issuecomment-1931846997
Usability,clear,clear,"Right, so this means this PR is adding a new method that allows to address the cases such as the one reported by the linked issue, but it's not a drop-in replacement, the user needs to actively know that the new method exists and use it. All clear now, thanks for the explanation.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14671#issuecomment-1957093709
Usability,simpl,simplifying,Please note that this is a double edge sword. On one hand it is simplifying the tutorials in a way that works well.; On the other hand it removes any demonstration (or did we keep at least one?) of how to use `R__LOAD_LIBRARY` that is necessary in case the library is (intentionally) not on the `LD_LIBRARY_PATH`.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14684#issuecomment-1944897019
Usability,clear,clear,"Ah, one more thing before merging: could you perhaps squash your two commits? Unless there's a clear motivation to keep them separate, but it appears to be both are related to schema compliance.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14690#issuecomment-1943375342
Usability,user experience,user experience,"Thanks @vepadulano for the comment. I agree with your proposal. I went for an approach with addition of new options because I found `SetCompression{Algorithm,Level}` and assumed that it's desirable to have that level of flexibility. But I think since `SetCompressionSettings` takes care of both, the better user experience is to have single option with better documentation. Hence, I'll revert the changes from b5200e148be517112143fcb5e6d489dbc2d86dd4 and improve documentation.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14714#issuecomment-1952406831
Performance,perform,performance-critical,"Thank you! I made the modification. Still not clear to me, why it is necessary. But this is not a (very) performance-critical path, so it's fine.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14731#issuecomment-1948143634
Usability,clear,clear,"Thank you! I made the modification. Still not clear to me, why it is necessary. But this is not a (very) performance-critical path, so it's fine.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14731#issuecomment-1948143634
Usability,simpl,simply,Also simply running `rline.cxx` macro in the docker also works.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14750#issuecomment-1953657976
Usability,clear,clear,"I think the problem is just the name. ""Ptr"" makes people think of a normal non owning pointer. If it would be called ""RResult"", it would be pretty clear to me who owns the payload!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14766#issuecomment-2046793610
Testability,test,tests,"@iarspider Did your tests indicate that this is a regression introduced by that commit specifically, or that this issue was simply not there yet at the time of that commit and it could be any commit since then?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14793#issuecomment-1983530703
Usability,simpl,simply,"@iarspider Did your tests indicate that this is a regression introduced by that commit specifically, or that this issue was simply not there yet at the time of that commit and it could be any commit since then?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14793#issuecomment-1983530703
Integrability,synchroniz,synchronization,"In CMSSW; - we use `oneapi::tbb::global_control` to set the process' maximum number of threads usable by TBB; - we create a top-level `oneapi::tbb::task_arena` (with the same number of threads), and all data processing is run within one `task_arena::execute()` call; - every call to ROOT I/O is isolated with `oneapi::tbb::this_task_arena::isolate()` call. By adding (or using) a global task arena to ROOT, does this mean, if multiple `TFile`s are writing concurrently, can their tasks be intermingled? Our guess is that ROOT's global task arena would trump the use of `this_task_arena::isolate()`, and allow such intermingling, but we don't really know. We are concerned that by sharing one task arena for unrelated activities it would cause synchronization of those activities because of task stealing. (assuming the explicit arena would trump the `this_task_arena::isolate()` call)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14807#issuecomment-1965316725
Performance,concurren,concurrently,"In CMSSW; - we use `oneapi::tbb::global_control` to set the process' maximum number of threads usable by TBB; - we create a top-level `oneapi::tbb::task_arena` (with the same number of threads), and all data processing is run within one `task_arena::execute()` call; - every call to ROOT I/O is isolated with `oneapi::tbb::this_task_arena::isolate()` call. By adding (or using) a global task arena to ROOT, does this mean, if multiple `TFile`s are writing concurrently, can their tasks be intermingled? Our guess is that ROOT's global task arena would trump the use of `this_task_arena::isolate()`, and allow such intermingling, but we don't really know. We are concerned that by sharing one task arena for unrelated activities it would cause synchronization of those activities because of task stealing. (assuming the explicit arena would trump the `this_task_arena::isolate()` call)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14807#issuecomment-1965316725
Usability,usab,usable,"In CMSSW; - we use `oneapi::tbb::global_control` to set the process' maximum number of threads usable by TBB; - we create a top-level `oneapi::tbb::task_arena` (with the same number of threads), and all data processing is run within one `task_arena::execute()` call; - every call to ROOT I/O is isolated with `oneapi::tbb::this_task_arena::isolate()` call. By adding (or using) a global task arena to ROOT, does this mean, if multiple `TFile`s are writing concurrently, can their tasks be intermingled? Our guess is that ROOT's global task arena would trump the use of `this_task_arena::isolate()`, and allow such intermingling, but we don't really know. We are concerned that by sharing one task arena for unrelated activities it would cause synchronization of those activities because of task stealing. (assuming the explicit arena would trump the `this_task_arena::isolate()` call)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14807#issuecomment-1965316725
Energy Efficiency,schedul,scheduling,"@makortel . > In CMSSW; > ; > * we use `oneapi::tbb::global_control` to set the process' maximum number of threads usable by TBB; > ; > * we create a top-level `oneapi::tbb::task_arena` (with the same number of threads), and all data processing is run within one `task_arena::execute()` call; > ; > * every call to ROOT I/O is isolated with `oneapi::tbb::this_task_arena::isolate()` call; > ; > ; > By adding (or using) a global task arena to ROOT, does this mean, if multiple `TFile`s are writing concurrently, can their tasks be intermingled?. Yes, but I think that's already the case right now because we (incorrectly) use the surrounding task arena for everything. That said, `TTaskGroup` and the wrapped TBB's `task_group` prioritize tasks belonging to that group in their `Wait()` / `wait()` functionality. > Our guess is that ROOT's global task arena would trump the use of `this_task_arena::isolate()`, and allow such intermingling, but we don't really know. Possible that ROOT's task arena ""wins"", I don't know enough about TBB's scheduling internals; I see that you opened an issue to investigate what this means. > We are concerned that by sharing one task arena for unrelated activities it would cause synchronization of those activities because of task stealing. (assuming the explicit arena would trump the `this_task_arena::isolate()` call). As argued above, it's not worse than before except that this fixes the bug that ROOT must only use the resources that it was allowed by the user.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14807#issuecomment-1965963868
Integrability,wrap,wrapped,"@makortel . > In CMSSW; > ; > * we use `oneapi::tbb::global_control` to set the process' maximum number of threads usable by TBB; > ; > * we create a top-level `oneapi::tbb::task_arena` (with the same number of threads), and all data processing is run within one `task_arena::execute()` call; > ; > * every call to ROOT I/O is isolated with `oneapi::tbb::this_task_arena::isolate()` call; > ; > ; > By adding (or using) a global task arena to ROOT, does this mean, if multiple `TFile`s are writing concurrently, can their tasks be intermingled?. Yes, but I think that's already the case right now because we (incorrectly) use the surrounding task arena for everything. That said, `TTaskGroup` and the wrapped TBB's `task_group` prioritize tasks belonging to that group in their `Wait()` / `wait()` functionality. > Our guess is that ROOT's global task arena would trump the use of `this_task_arena::isolate()`, and allow such intermingling, but we don't really know. Possible that ROOT's task arena ""wins"", I don't know enough about TBB's scheduling internals; I see that you opened an issue to investigate what this means. > We are concerned that by sharing one task arena for unrelated activities it would cause synchronization of those activities because of task stealing. (assuming the explicit arena would trump the `this_task_arena::isolate()` call). As argued above, it's not worse than before except that this fixes the bug that ROOT must only use the resources that it was allowed by the user.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14807#issuecomment-1965963868
Performance,concurren,concurrently,"@makortel . > In CMSSW; > ; > * we use `oneapi::tbb::global_control` to set the process' maximum number of threads usable by TBB; > ; > * we create a top-level `oneapi::tbb::task_arena` (with the same number of threads), and all data processing is run within one `task_arena::execute()` call; > ; > * every call to ROOT I/O is isolated with `oneapi::tbb::this_task_arena::isolate()` call; > ; > ; > By adding (or using) a global task arena to ROOT, does this mean, if multiple `TFile`s are writing concurrently, can their tasks be intermingled?. Yes, but I think that's already the case right now because we (incorrectly) use the surrounding task arena for everything. That said, `TTaskGroup` and the wrapped TBB's `task_group` prioritize tasks belonging to that group in their `Wait()` / `wait()` functionality. > Our guess is that ROOT's global task arena would trump the use of `this_task_arena::isolate()`, and allow such intermingling, but we don't really know. Possible that ROOT's task arena ""wins"", I don't know enough about TBB's scheduling internals; I see that you opened an issue to investigate what this means. > We are concerned that by sharing one task arena for unrelated activities it would cause synchronization of those activities because of task stealing. (assuming the explicit arena would trump the `this_task_arena::isolate()` call). As argued above, it's not worse than before except that this fixes the bug that ROOT must only use the resources that it was allowed by the user.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14807#issuecomment-1965963868
Usability,usab,usable,"@makortel . > In CMSSW; > ; > * we use `oneapi::tbb::global_control` to set the process' maximum number of threads usable by TBB; > ; > * we create a top-level `oneapi::tbb::task_arena` (with the same number of threads), and all data processing is run within one `task_arena::execute()` call; > ; > * every call to ROOT I/O is isolated with `oneapi::tbb::this_task_arena::isolate()` call; > ; > ; > By adding (or using) a global task arena to ROOT, does this mean, if multiple `TFile`s are writing concurrently, can their tasks be intermingled?. Yes, but I think that's already the case right now because we (incorrectly) use the surrounding task arena for everything. That said, `TTaskGroup` and the wrapped TBB's `task_group` prioritize tasks belonging to that group in their `Wait()` / `wait()` functionality. > Our guess is that ROOT's global task arena would trump the use of `this_task_arena::isolate()`, and allow such intermingling, but we don't really know. Possible that ROOT's task arena ""wins"", I don't know enough about TBB's scheduling internals; I see that you opened an issue to investigate what this means. > We are concerned that by sharing one task arena for unrelated activities it would cause synchronization of those activities because of task stealing. (assuming the explicit arena would trump the `this_task_arena::isolate()` call). As argued above, it's not worse than before except that this fixes the bug that ROOT must only use the resources that it was allowed by the user.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14807#issuecomment-1965963868
Availability,failure,failure,"Thanks for these changes. I apologise for coming back to them so late. ; I would like to hear also what @pcanal has to say about the mechanics of the code, however the change seems a net improvement with respect to the current situation. I would like to start pointing out a few aspects of the PR which could be improved before merging (if consensus in the review is reached):; - There is one test failure, on all platforms but windows: do you need help to figure out why the test is failing?; - The number of commits seem to high, can they be squashed together into fewer commits (one commit) with clear commit messages?; - There is no test for the functionality: can one or more tests be added in roottest? If you need some examples, we can dig them out for you (in the `root/meta/` directory one should have plenty of examples)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14813#issuecomment-2038169206
Integrability,message,messages,"Thanks for these changes. I apologise for coming back to them so late. ; I would like to hear also what @pcanal has to say about the mechanics of the code, however the change seems a net improvement with respect to the current situation. I would like to start pointing out a few aspects of the PR which could be improved before merging (if consensus in the review is reached):; - There is one test failure, on all platforms but windows: do you need help to figure out why the test is failing?; - The number of commits seem to high, can they be squashed together into fewer commits (one commit) with clear commit messages?; - There is no test for the functionality: can one or more tests be added in roottest? If you need some examples, we can dig them out for you (in the `root/meta/` directory one should have plenty of examples)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14813#issuecomment-2038169206
Testability,test,test,"Thanks for these changes. I apologise for coming back to them so late. ; I would like to hear also what @pcanal has to say about the mechanics of the code, however the change seems a net improvement with respect to the current situation. I would like to start pointing out a few aspects of the PR which could be improved before merging (if consensus in the review is reached):; - There is one test failure, on all platforms but windows: do you need help to figure out why the test is failing?; - The number of commits seem to high, can they be squashed together into fewer commits (one commit) with clear commit messages?; - There is no test for the functionality: can one or more tests be added in roottest? If you need some examples, we can dig them out for you (in the `root/meta/` directory one should have plenty of examples)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14813#issuecomment-2038169206
Usability,clear,clear,"Thanks for these changes. I apologise for coming back to them so late. ; I would like to hear also what @pcanal has to say about the mechanics of the code, however the change seems a net improvement with respect to the current situation. I would like to start pointing out a few aspects of the PR which could be improved before merging (if consensus in the review is reached):; - There is one test failure, on all platforms but windows: do you need help to figure out why the test is failing?; - The number of commits seem to high, can they be squashed together into fewer commits (one commit) with clear commit messages?; - There is no test for the functionality: can one or more tests be added in roottest? If you need some examples, we can dig them out for you (in the `root/meta/` directory one should have plenty of examples)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14813#issuecomment-2038169206
Usability,feedback,feedback,@guitargeek @wlav awesome! Thanks for the quick feedback on this! :). I'll mark that item as done! :tada:,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14824#issuecomment-1964640642
Usability,simpl,simply,"And also, apologies for this, should we rename TCutInfo to RCutInfo before making it writeable? I think we simply forgot to rename that ancillary class when TDataFrame was renamed into RDataFrame...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14833#issuecomment-1965918042
Usability,simpl,simply,"> And also, apologies for this, should we rename TCutInfo to RCutInfo before making it writeable? I think we simply forgot to rename that ancillary class when TDataFrame was renamed into RDataFrame... This class has been in the public namespace for years, so I don't think we can do that. What we can do is we can make an `RCutInfo` class, then alias `using TCutInfo = RCutInfo;`. How does that sound?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14833#issuecomment-1966233201
Usability,clear,clear,It is clear ownership problem. @ferdymercury - you can try to fix it if you want.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14855#issuecomment-1970972594
Usability,clear,clear,Is it clear what `ratioplot1->Close()` is supposed to mean?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14855#issuecomment-1974795728
Availability,fault,fault,> Is it clear what ratioplot1->Close() is supposed to mean?. It is just method which is called when canvas closed in interactive mode.; I put it here to demonstrate problem. ; Calling canvas destructor will cause the same seg fault. I tried to fix the problem in #14861 but facing much more problems. ; `RecursiveRemove` is not a solution.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14855#issuecomment-1976051222
Usability,clear,clear,> Is it clear what ratioplot1->Close() is supposed to mean?. It is just method which is called when canvas closed in interactive mode.; I put it here to demonstrate problem. ; Calling canvas destructor will cause the same seg fault. I tried to fix the problem in #14861 but facing much more problems. ; `RecursiveRemove` is not a solution.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14855#issuecomment-1976051222
Integrability,interface,interfaces,"At the time, it was not clear how to introduce the new interfaces for the expression of parallelism within ROOT. This is also why the effort started from within the `Experimental` namespace. As correctly underlined above, the class is not really used nor needed, and it's good that these changes were proposed: thanks for that!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14856#issuecomment-1971063315
Usability,clear,clear,"At the time, it was not clear how to introduce the new interfaces for the expression of parallelism within ROOT. This is also why the effort started from within the `Experimental` namespace. As correctly underlined above, the class is not really used nor needed, and it's good that these changes were proposed: thanks for that!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14856#issuecomment-1971063315
Availability,error,errors,"Since the errors are true and valid, shouldn't we keep them? Or make them more clear as in `you are trying to access a system-protected file"" or something similar?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14865#issuecomment-1973061065
Security,access,access,"Since the errors are true and valid, shouldn't we keep them? Or make them more clear as in `you are trying to access a system-protected file"" or something similar?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14865#issuecomment-1973061065
Usability,clear,clear,"Since the errors are true and valid, shouldn't we keep them? Or make them more clear as in `you are trying to access a system-protected file"" or something similar?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14865#issuecomment-1973061065
Availability,error,errors,"> Since the errors are true and valid, shouldn't we keep them? Or make them more clear as in `you are trying to access a system-protected file"" or something similar?. The user complains about the error message, then I'm not sure changing the text of the message will help in this case. And the error is `ENOENT`, meaning the file doesn't exists, which is not necessarily true, so telling this is a system protected file is not even reflecting the reality on all OSes",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14865#issuecomment-1973063708
Integrability,message,message,"> Since the errors are true and valid, shouldn't we keep them? Or make them more clear as in `you are trying to access a system-protected file"" or something similar?. The user complains about the error message, then I'm not sure changing the text of the message will help in this case. And the error is `ENOENT`, meaning the file doesn't exists, which is not necessarily true, so telling this is a system protected file is not even reflecting the reality on all OSes",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14865#issuecomment-1973063708
Security,access,access,"> Since the errors are true and valid, shouldn't we keep them? Or make them more clear as in `you are trying to access a system-protected file"" or something similar?. The user complains about the error message, then I'm not sure changing the text of the message will help in this case. And the error is `ENOENT`, meaning the file doesn't exists, which is not necessarily true, so telling this is a system protected file is not even reflecting the reality on all OSes",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14865#issuecomment-1973063708
Usability,clear,clear,"> Since the errors are true and valid, shouldn't we keep them? Or make them more clear as in `you are trying to access a system-protected file"" or something similar?. The user complains about the error message, then I'm not sure changing the text of the message will help in this case. And the error is `ENOENT`, meaning the file doesn't exists, which is not necessarily true, so telling this is a system protected file is not even reflecting the reality on all OSes",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14865#issuecomment-1973063708
Availability,down,down,> We should really have a test for this... I absolutely agree! @scott-snyder how involved is the failing test in the ATLAS framework? If it's not too complicated to boil it down to a simple reproducer it would be really helpful here. Otherwise I can try to sketch one myself and then you can tell us how closely it represents your original case.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14887#issuecomment-1980364814
Testability,test,test,> We should really have a test for this... I absolutely agree! @scott-snyder how involved is the failing test in the ATLAS framework? If it's not too complicated to boil it down to a simple reproducer it would be really helpful here. Otherwise I can try to sketch one myself and then you can tell us how closely it represents your original case.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14887#issuecomment-1980364814
Usability,simpl,simple,> We should really have a test for this... I absolutely agree! @scott-snyder how involved is the failing test in the ATLAS framework? If it's not too complicated to boil it down to a simple reproducer it would be really helpful here. Otherwise I can try to sketch one myself and then you can tell us how closely it represents your original case.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14887#issuecomment-1980364814
Usability,simpl,simply,"Thanks for the proposal backed up by a concrete potential solution. I like the idea of having something automated that in case of problems, simply does nothing. One thing that changes though is the squashing. ; This is something to discuss. In your opinion, @vgvassilev , what do we loose by automatically squashing commits intended for backports?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14889#issuecomment-1981051931
Usability,simpl,simply,"I think the squashing of commits is simply a change with respect to what is being done today, it's not negative or a regression per se. I even could see an advantage in having one backport per commit. A good item to be discussed in the team I guess, but this action could be really help us.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14889#issuecomment-1983480977
Usability,simpl,simpler,"@linev I could check how to do that, but isn't there any simpler solution?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14908#issuecomment-1985811465
Usability,simpl,simpler,"@bellenot . > isn't there any simpler solution. I have no idea. While it is not real standard, each linux/mac flawor has own way to provide function to read `/dev/random` or ; `/dev/urandom`",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14908#issuecomment-1985836713
Usability,clear,clear,"ok, I have figured it out, it's because of; >0x01 	64 	Index64 	Mother columns of (nested) collections, counting is relative to the cluster; 0x02 	32 	Index32 	Mother columns of (nested) collections, counting is relative to the cluster. specifically, ""counting is relative to the cluster"" was not clear to me. But what it means is, if you have 2 pages of `Index64` for a column in this cluster, after ""de-split encoding"" you will get these two arrays:. ```julia; first page: [30, 4, 18, 14, 5, 8, 10, 7, 8, 18, ..., 22, 1, 16, 14, 14, 12, 4, 7, 15, 24]; first page after cumsum: [..., 81317, 81318, 81334, 81348, 81362, 81374, 81378, 81385, 81400, 81424]. second page: [81428, 13, 9, 7, 5, 20, 21, 4, 8, 6, ..., 128487, 128505, 128513, 128527, 128543, 128549, 128557, 128564, 128575, 128584]; ``` . you can see that the second page doesn't start with 4, instead, it starts with a huge number `81428`. I guess it means index pages are to be interpreted individually within the cluster.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14949#issuecomment-1999929430
Deployability,install,install,"Hello Sergey,, Danillo. Thank you for your suggestions (that we took into consideration ), feedback and prompt response. There is a new suggestion on how to solve this issue. Please check:. <https://its.cern.ch/jira/browse/SPI-2532>; its.cern.ch<https://its.cern.ch/jira/browse/SPI-2532>; [X]<https://its.cern.ch/jira/browse/SPI-2532>. We will keep you informed.; Best regards,; Ilias. On 14 Mar 2024, at 09:32, Sergey Linev ***@***.***> wrote:. @cogevito<https://github.com/cogevito>. Can you try to install libbsd-dev on your node?. ; Reply to this email directly, view it on GitHub<https://github.com/root-project/root/issues/14958#issuecomment-1996852848>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/ADMB4TR5V47G7UK252MEENDYYFODFAVCNFSM6AAAAABEUNYYK6VHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMYTSOJWHA2TEOBUHA>.; You are receiving this because you were mentioned.Message ID: ***@***.***>",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14958#issuecomment-1996872551
Usability,feedback,feedback,"Hello Sergey,, Danillo. Thank you for your suggestions (that we took into consideration ), feedback and prompt response. There is a new suggestion on how to solve this issue. Please check:. <https://its.cern.ch/jira/browse/SPI-2532>; its.cern.ch<https://its.cern.ch/jira/browse/SPI-2532>; [X]<https://its.cern.ch/jira/browse/SPI-2532>. We will keep you informed.; Best regards,; Ilias. On 14 Mar 2024, at 09:32, Sergey Linev ***@***.***> wrote:. @cogevito<https://github.com/cogevito>. Can you try to install libbsd-dev on your node?. ; Reply to this email directly, view it on GitHub<https://github.com/root-project/root/issues/14958#issuecomment-1996852848>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/ADMB4TR5V47G7UK252MEENDYYFODFAVCNFSM6AAAAABEUNYYK6VHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMYTSOJWHA2TEOBUHA>.; You are receiving this because you were mentioned.Message ID: ***@***.***>",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14958#issuecomment-1996872551
Modifiability,variab,variables,"@vepadulano @pcanal I just noticed that all the 31 bit ugly stuff was due to an outdated documentation. It's no longer the case, minor and major have now independent variables both 64-bits. So this simplifies things significantly.; See https://github.com/root-project/root/commit/19b0ca55fe1643eb07c9bca362b64a4d2111674f",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14967#issuecomment-2013036145
Usability,simpl,simplifies,"@vepadulano @pcanal I just noticed that all the 31 bit ugly stuff was due to an outdated documentation. It's no longer the case, minor and major have now independent variables both 64-bits. So this simplifies things significantly.; See https://github.com/root-project/root/commit/19b0ca55fe1643eb07c9bca362b64a4d2111674f",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14967#issuecomment-2013036145
Availability,failure,failures,"> I believe the current failures are related to the roottest branch not being up-to-date with the latest master. Close but not quite. What is happening in the reverse. Once the CI test are started they pin the `ROOT master` commit that will be use to test. If one simply ""re-run"" the tests they will (this is intentional) use that same commit. To take in consideration new commits in the new CI build we need to do either of these 3 actions:; * Rebase the master onto the new PR branch.; * Add a new commit to the PR branch.; * Close and re-open the PR.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14967#issuecomment-2046265770
Testability,test,test,"> I believe the current failures are related to the roottest branch not being up-to-date with the latest master. Close but not quite. What is happening in the reverse. Once the CI test are started they pin the `ROOT master` commit that will be use to test. If one simply ""re-run"" the tests they will (this is intentional) use that same commit. To take in consideration new commits in the new CI build we need to do either of these 3 actions:; * Rebase the master onto the new PR branch.; * Add a new commit to the PR branch.; * Close and re-open the PR.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14967#issuecomment-2046265770
Usability,simpl,simply,"> I believe the current failures are related to the roottest branch not being up-to-date with the latest master. Close but not quite. What is happening in the reverse. Once the CI test are started they pin the `ROOT master` commit that will be use to test. If one simply ""re-run"" the tests they will (this is intentional) use that same commit. To take in consideration new commits in the new CI build we need to do either of these 3 actions:; * Rebase the master onto the new PR branch.; * Add a new commit to the PR branch.; * Close and re-open the PR.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14967#issuecomment-2046265770
Usability,simpl,simple,"Should be something as simple as:. ```; git clone our/llvm/fork; git clone cling; git checkout cling-latest; cmake -DLLVM_ENABLE_PROJECTS=clang -DCMAKE_BUILD_TYPE=Debug -DLLVM_TARGETS_TO_BUILD=""host;nvptx"" -DLLVM_EXTERNAL_PROJECTS=""cling"" -DLLVM_EXTERNAL_CLING_SOURCE_DIR=/path/to/where/we/cloned/cling ../llvm; make check-cling; ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14972#issuecomment-1998169426
Usability,clear,clearly,Just rebased to see the situation on the macs more clearly.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14974#issuecomment-2010691407
Deployability,update,update,"Hi, some update on this. First, let me try to clear a bit the context. I am not sure why `gc.collect` is being invoked here. Manually invoking the Python garbage collector is not going to give any guarantees on which objects are actually destroyed by the interpreter, it depends on the types and sometimes it's even undefined behaviour, as per the docs https://docs.python.org/3/library/gc.html#gc.collect. Second, even if we had that guarantee, the first and the second loops are doing two wildly different things.; ```; my_data = rvec; ```; Is doing a copy of an `RVec` to another `RVec`, with a thin Python proxy to present it to the user. The copy of an RVec is a well-defined operation in terms of memory management, i.e. it will call the copy-constructor of the `RVec`. Whereas; ```; my_data = numpy.asarray(rvec); ```; Is creating a new numpy array object in memory which is an owning view on the contents of the RVec. The management of the RVec in memory can be clearly seen with this simplified example; ```; process = psutil.Process(). ROOT.gInterpreter.Declare(""""""; auto create_rvec(unsigned int n) {; //return std::array<unsigned int, 3>({n, n, n});; return ROOT::RVec<unsigned int>({n, n, n});; }; """"""); df = ROOT.RDataFrame(100).Define(""my_rvecs"", ""create_rvec(rdfentry_)""); rvecs = df.AsNumpy([""my_rvecs""])[""my_rvecs""]. def get_mem_usage():; return process.memory_info().rss # in kbytes. mem0 = get_mem_usage(); print(mem0). for v2 in rvecs:; n = v2; mem2 = get_mem_usage(); print(mem2); ```. Which doesn't use `gc.collect` but will still show that the memory used is exactly the same at each iteration, no leaks.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14981#issuecomment-2006250778
Integrability,depend,depends,"Hi, some update on this. First, let me try to clear a bit the context. I am not sure why `gc.collect` is being invoked here. Manually invoking the Python garbage collector is not going to give any guarantees on which objects are actually destroyed by the interpreter, it depends on the types and sometimes it's even undefined behaviour, as per the docs https://docs.python.org/3/library/gc.html#gc.collect. Second, even if we had that guarantee, the first and the second loops are doing two wildly different things.; ```; my_data = rvec; ```; Is doing a copy of an `RVec` to another `RVec`, with a thin Python proxy to present it to the user. The copy of an RVec is a well-defined operation in terms of memory management, i.e. it will call the copy-constructor of the `RVec`. Whereas; ```; my_data = numpy.asarray(rvec); ```; Is creating a new numpy array object in memory which is an owning view on the contents of the RVec. The management of the RVec in memory can be clearly seen with this simplified example; ```; process = psutil.Process(). ROOT.gInterpreter.Declare(""""""; auto create_rvec(unsigned int n) {; //return std::array<unsigned int, 3>({n, n, n});; return ROOT::RVec<unsigned int>({n, n, n});; }; """"""); df = ROOT.RDataFrame(100).Define(""my_rvecs"", ""create_rvec(rdfentry_)""); rvecs = df.AsNumpy([""my_rvecs""])[""my_rvecs""]. def get_mem_usage():; return process.memory_info().rss # in kbytes. mem0 = get_mem_usage(); print(mem0). for v2 in rvecs:; n = v2; mem2 = get_mem_usage(); print(mem2); ```. Which doesn't use `gc.collect` but will still show that the memory used is exactly the same at each iteration, no leaks.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14981#issuecomment-2006250778
Usability,clear,clear,"Hi, some update on this. First, let me try to clear a bit the context. I am not sure why `gc.collect` is being invoked here. Manually invoking the Python garbage collector is not going to give any guarantees on which objects are actually destroyed by the interpreter, it depends on the types and sometimes it's even undefined behaviour, as per the docs https://docs.python.org/3/library/gc.html#gc.collect. Second, even if we had that guarantee, the first and the second loops are doing two wildly different things.; ```; my_data = rvec; ```; Is doing a copy of an `RVec` to another `RVec`, with a thin Python proxy to present it to the user. The copy of an RVec is a well-defined operation in terms of memory management, i.e. it will call the copy-constructor of the `RVec`. Whereas; ```; my_data = numpy.asarray(rvec); ```; Is creating a new numpy array object in memory which is an owning view on the contents of the RVec. The management of the RVec in memory can be clearly seen with this simplified example; ```; process = psutil.Process(). ROOT.gInterpreter.Declare(""""""; auto create_rvec(unsigned int n) {; //return std::array<unsigned int, 3>({n, n, n});; return ROOT::RVec<unsigned int>({n, n, n});; }; """"""); df = ROOT.RDataFrame(100).Define(""my_rvecs"", ""create_rvec(rdfentry_)""); rvecs = df.AsNumpy([""my_rvecs""])[""my_rvecs""]. def get_mem_usage():; return process.memory_info().rss # in kbytes. mem0 = get_mem_usage(); print(mem0). for v2 in rvecs:; n = v2; mem2 = get_mem_usage(); print(mem2); ```. Which doesn't use `gc.collect` but will still show that the memory used is exactly the same at each iteration, no leaks.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14981#issuecomment-2006250778
Integrability,depend,dependencies,"I would propose to change the title to ""[ci] Further speedup mac and linux builds by caching dependencies"". The word ""instead"" can be misleading. Our goal is to have feedback from the CI as soon as possible. Having several nodes, allows to scale horizontally. We are not increasing the number of nodes in the CI because we are lazy, we just need many nodes AND fast CI, e.g. through caches or quicker tests :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14987#issuecomment-2001914193
Performance,cache,caches,"I would propose to change the title to ""[ci] Further speedup mac and linux builds by caching dependencies"". The word ""instead"" can be misleading. Our goal is to have feedback from the CI as soon as possible. Having several nodes, allows to scale horizontally. We are not increasing the number of nodes in the CI because we are lazy, we just need many nodes AND fast CI, e.g. through caches or quicker tests :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14987#issuecomment-2001914193
Testability,test,tests,"I would propose to change the title to ""[ci] Further speedup mac and linux builds by caching dependencies"". The word ""instead"" can be misleading. Our goal is to have feedback from the CI as soon as possible. Having several nodes, allows to scale horizontally. We are not increasing the number of nodes in the CI because we are lazy, we just need many nodes AND fast CI, e.g. through caches or quicker tests :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14987#issuecomment-2001914193
Usability,feedback,feedback,"I would propose to change the title to ""[ci] Further speedup mac and linux builds by caching dependencies"". The word ""instead"" can be misleading. Our goal is to have feedback from the CI as soon as possible. Having several nodes, allows to scale horizontally. We are not increasing the number of nodes in the CI because we are lazy, we just need many nodes AND fast CI, e.g. through caches or quicker tests :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14987#issuecomment-2001914193
Integrability,depend,dependencies,"> I would propose to change the title to ""[ci] Further speedup mac and linux builds by caching dependencies"". The word ""instead"" can be misleading. Our goal is to have feedback from the CI as soon as possible. Having several nodes, allows to scale horizontally. We are not increasing the number of nodes in the CI because we are lazy, we just need many nodes AND fast CI, e.g. through caches or quicker tests :). The proposed rename works for me. It's not only for mac and linux, it covers any platform.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14987#issuecomment-2001954686
Performance,cache,caches,"> I would propose to change the title to ""[ci] Further speedup mac and linux builds by caching dependencies"". The word ""instead"" can be misleading. Our goal is to have feedback from the CI as soon as possible. Having several nodes, allows to scale horizontally. We are not increasing the number of nodes in the CI because we are lazy, we just need many nodes AND fast CI, e.g. through caches or quicker tests :). The proposed rename works for me. It's not only for mac and linux, it covers any platform.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14987#issuecomment-2001954686
Testability,test,tests,"> I would propose to change the title to ""[ci] Further speedup mac and linux builds by caching dependencies"". The word ""instead"" can be misleading. Our goal is to have feedback from the CI as soon as possible. Having several nodes, allows to scale horizontally. We are not increasing the number of nodes in the CI because we are lazy, we just need many nodes AND fast CI, e.g. through caches or quicker tests :). The proposed rename works for me. It's not only for mac and linux, it covers any platform.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14987#issuecomment-2001954686
Usability,feedback,feedback,"> I would propose to change the title to ""[ci] Further speedup mac and linux builds by caching dependencies"". The word ""instead"" can be misleading. Our goal is to have feedback from the CI as soon as possible. Having several nodes, allows to scale horizontally. We are not increasing the number of nodes in the CI because we are lazy, we just need many nodes AND fast CI, e.g. through caches or quicker tests :). The proposed rename works for me. It's not only for mac and linux, it covers any platform.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/14987#issuecomment-2001954686
Usability,simpl,simplification,"Great simplification, which matches well the PROOF=OFF by default in master: thanks. This is not very important, but could users rely on some other sort of parallelism, e.g. T{Thread/Process}Executor?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/14993#issuecomment-2002334241
Testability,test,tests,"Thanks a lot @pcanal for this improvement: experiments will appreciate. Given that we still run, with somewhat lower frequency than others, 6.26 builds and tests, would a simple test for 6.26 be of help in roottest?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15006#issuecomment-2010652089
Usability,simpl,simple,"Thanks a lot @pcanal for this improvement: experiments will appreciate. Given that we still run, with somewhat lower frequency than others, 6.26 builds and tests, would a simple test for 6.26 be of help in roottest?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15006#issuecomment-2010652089
Availability,alive,alive,"> One general point regarding the overall design. I wonder if the `RVecDS` data source can be made to have a map/vector of `RVec`s as data member instead of `void *` . Thanks for the review! I have changed the `RVecDS` to take a map to `RVecs`, and not pointers to it. > and those RVecs should be views on the numpy arrays. This would make the design intent clearer and possibly remove the need for a custom deleter that calls into a Python function. This is not possible right now, because RVecs are not true ""views on the numpy arrays"" in the sense that their existence keeps the numpy array alive. This is only hacked into the Python side by adding an `__adopted__` member to the RVec python proxy:; https://github.com/root-project/root/blob/master/bindings/pyroot/pythonizations/python/ROOT/_pythonization/_rvec.py#L135. As soon as the RVec gets passed to the C++ side we are losing this reference. So we can't work around a custom deleter in the `RVecDS`. Well, there would be a way, which is to implement a similar mechanism of implementing a deleter that calls to the Python side in RVec itself! But maybe that's not for this PR :slightly_smiling_face:",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15031#issuecomment-2018028002
Usability,clear,clearer,"> One general point regarding the overall design. I wonder if the `RVecDS` data source can be made to have a map/vector of `RVec`s as data member instead of `void *` . Thanks for the review! I have changed the `RVecDS` to take a map to `RVecs`, and not pointers to it. > and those RVecs should be views on the numpy arrays. This would make the design intent clearer and possibly remove the need for a custom deleter that calls into a Python function. This is not possible right now, because RVecs are not true ""views on the numpy arrays"" in the sense that their existence keeps the numpy array alive. This is only hacked into the Python side by adding an `__adopted__` member to the RVec python proxy:; https://github.com/root-project/root/blob/master/bindings/pyroot/pythonizations/python/ROOT/_pythonization/_rvec.py#L135. As soon as the RVec gets passed to the C++ side we are losing this reference. So we can't work around a custom deleter in the `RVecDS`. Well, there would be a way, which is to implement a similar mechanism of implementing a deleter that calls to the Python side in RVec itself! But maybe that's not for this PR :slightly_smiling_face:",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15031#issuecomment-2018028002
Availability,error,error,"Hi @AlkaidCheng ,. Thanks for reaching out! I am not sure I understand where the problem stands. You are purposely injecting a different namespace at runtime, so I don't see how the package can act in order to prevent the wrong namespace being used. The error is unfortunately not clear as to which call site is provoking the lookup to `ROOT.Math.Internal`. Judging by your short snippet, I can imagine that one place could be [here](https://github.com/root-project/root/blob/a29e81cb1cd217ca2096a44d01fb273e085b4e8b/bindings/experimental/distrdf/python/DistRDF/HeadNode.py#L457), but as you can see the correct full namespace is being called there. Can you give more context as to what is your use case so I can better understand how to help?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/15035#issuecomment-2015329409
Integrability,inject,injecting,"Hi @AlkaidCheng ,. Thanks for reaching out! I am not sure I understand where the problem stands. You are purposely injecting a different namespace at runtime, so I don't see how the package can act in order to prevent the wrong namespace being used. The error is unfortunately not clear as to which call site is provoking the lookup to `ROOT.Math.Internal`. Judging by your short snippet, I can imagine that one place could be [here](https://github.com/root-project/root/blob/a29e81cb1cd217ca2096a44d01fb273e085b4e8b/bindings/experimental/distrdf/python/DistRDF/HeadNode.py#L457), but as you can see the correct full namespace is being called there. Can you give more context as to what is your use case so I can better understand how to help?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/15035#issuecomment-2015329409
Security,inject,injecting,"Hi @AlkaidCheng ,. Thanks for reaching out! I am not sure I understand where the problem stands. You are purposely injecting a different namespace at runtime, so I don't see how the package can act in order to prevent the wrong namespace being used. The error is unfortunately not clear as to which call site is provoking the lookup to `ROOT.Math.Internal`. Judging by your short snippet, I can imagine that one place could be [here](https://github.com/root-project/root/blob/a29e81cb1cd217ca2096a44d01fb273e085b4e8b/bindings/experimental/distrdf/python/DistRDF/HeadNode.py#L457), but as you can see the correct full namespace is being called there. Can you give more context as to what is your use case so I can better understand how to help?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/15035#issuecomment-2015329409
Usability,clear,clear,"Hi @AlkaidCheng ,. Thanks for reaching out! I am not sure I understand where the problem stands. You are purposely injecting a different namespace at runtime, so I don't see how the package can act in order to prevent the wrong namespace being used. The error is unfortunately not clear as to which call site is provoking the lookup to `ROOT.Math.Internal`. Judging by your short snippet, I can imagine that one place could be [here](https://github.com/root-project/root/blob/a29e81cb1cd217ca2096a44d01fb273e085b4e8b/bindings/experimental/distrdf/python/DistRDF/HeadNode.py#L457), but as you can see the correct full namespace is being called there. Can you give more context as to what is your use case so I can better understand how to help?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/15035#issuecomment-2015329409
Usability,simpl,simple,"Thanks! An idea: the KHelpAbout in the browsers, it might be helpful to replace with a simple TGLabel containing gHelpAbout in a Tgtab e.g. or tgwindow",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15056#issuecomment-2042007736
Availability,error,error,"> Are there plans/work in progress for ROOT to move to a newer cppyy anytime soon?. Hi @taehyounpark! We have recently upgraded the cppyy frontend in ROOT, which will be part of ROOT 6.32:; https://github.com/root-project/root/pull/14507. However, it doesn't fix this reproducer. I suspect that this also requires to synchronize the [cppyy-backend](https://github.com/wlav/cppyy-backend/tree). The problem is that this backend is a fork of ROOT itself, including cling. And then, cppyy made patches to this fork of cling/ROOT for e.g. better lambda support and other advanced C++ features and details of the type system. The problem is that we can't take these patches 1 to 1 back to ROOT, because ROOT also used Cling for other things like IO, and the patches in cppyy did not have to consider compatibility with that. We try to make cppyy independent of cling on the long term to solve this conundrum. In the meantime, I can see what we are exactly missing in upstream ROOT or Cling to make the reproducer in this issue work. Maybe it is an uncontroversial patch. This will also take some time though. I worked a lot on PyROOT in the last weeks and have to work on other responsibilities in the next weeks before coming back to this. Or maybe @wlav has a hint?. > In the meantime, might there be anything I could try to ""persuade"" similar quirks, from either C++ or Python to make them work?. Unfortunately not. In ROOT, we don't use complicated template code with type traits in user interfaces. That's maybe my recommendation to you: can you simplify the user-facing interface and hide the templated stuff maybe behind some type-erased types or simplify it a bit? IMHO, templates are great for efficient implementations, but for user interfaces it can be a nightmare (think only about the error messages...).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/15062#issuecomment-2022342966
Deployability,upgrade,upgraded,"> Are there plans/work in progress for ROOT to move to a newer cppyy anytime soon?. Hi @taehyounpark! We have recently upgraded the cppyy frontend in ROOT, which will be part of ROOT 6.32:; https://github.com/root-project/root/pull/14507. However, it doesn't fix this reproducer. I suspect that this also requires to synchronize the [cppyy-backend](https://github.com/wlav/cppyy-backend/tree). The problem is that this backend is a fork of ROOT itself, including cling. And then, cppyy made patches to this fork of cling/ROOT for e.g. better lambda support and other advanced C++ features and details of the type system. The problem is that we can't take these patches 1 to 1 back to ROOT, because ROOT also used Cling for other things like IO, and the patches in cppyy did not have to consider compatibility with that. We try to make cppyy independent of cling on the long term to solve this conundrum. In the meantime, I can see what we are exactly missing in upstream ROOT or Cling to make the reproducer in this issue work. Maybe it is an uncontroversial patch. This will also take some time though. I worked a lot on PyROOT in the last weeks and have to work on other responsibilities in the next weeks before coming back to this. Or maybe @wlav has a hint?. > In the meantime, might there be anything I could try to ""persuade"" similar quirks, from either C++ or Python to make them work?. Unfortunately not. In ROOT, we don't use complicated template code with type traits in user interfaces. That's maybe my recommendation to you: can you simplify the user-facing interface and hide the templated stuff maybe behind some type-erased types or simplify it a bit? IMHO, templates are great for efficient implementations, but for user interfaces it can be a nightmare (think only about the error messages...).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/15062#issuecomment-2022342966
Energy Efficiency,efficient,efficient,"> Are there plans/work in progress for ROOT to move to a newer cppyy anytime soon?. Hi @taehyounpark! We have recently upgraded the cppyy frontend in ROOT, which will be part of ROOT 6.32:; https://github.com/root-project/root/pull/14507. However, it doesn't fix this reproducer. I suspect that this also requires to synchronize the [cppyy-backend](https://github.com/wlav/cppyy-backend/tree). The problem is that this backend is a fork of ROOT itself, including cling. And then, cppyy made patches to this fork of cling/ROOT for e.g. better lambda support and other advanced C++ features and details of the type system. The problem is that we can't take these patches 1 to 1 back to ROOT, because ROOT also used Cling for other things like IO, and the patches in cppyy did not have to consider compatibility with that. We try to make cppyy independent of cling on the long term to solve this conundrum. In the meantime, I can see what we are exactly missing in upstream ROOT or Cling to make the reproducer in this issue work. Maybe it is an uncontroversial patch. This will also take some time though. I worked a lot on PyROOT in the last weeks and have to work on other responsibilities in the next weeks before coming back to this. Or maybe @wlav has a hint?. > In the meantime, might there be anything I could try to ""persuade"" similar quirks, from either C++ or Python to make them work?. Unfortunately not. In ROOT, we don't use complicated template code with type traits in user interfaces. That's maybe my recommendation to you: can you simplify the user-facing interface and hide the templated stuff maybe behind some type-erased types or simplify it a bit? IMHO, templates are great for efficient implementations, but for user interfaces it can be a nightmare (think only about the error messages...).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/15062#issuecomment-2022342966
Integrability,synchroniz,synchronize,"> Are there plans/work in progress for ROOT to move to a newer cppyy anytime soon?. Hi @taehyounpark! We have recently upgraded the cppyy frontend in ROOT, which will be part of ROOT 6.32:; https://github.com/root-project/root/pull/14507. However, it doesn't fix this reproducer. I suspect that this also requires to synchronize the [cppyy-backend](https://github.com/wlav/cppyy-backend/tree). The problem is that this backend is a fork of ROOT itself, including cling. And then, cppyy made patches to this fork of cling/ROOT for e.g. better lambda support and other advanced C++ features and details of the type system. The problem is that we can't take these patches 1 to 1 back to ROOT, because ROOT also used Cling for other things like IO, and the patches in cppyy did not have to consider compatibility with that. We try to make cppyy independent of cling on the long term to solve this conundrum. In the meantime, I can see what we are exactly missing in upstream ROOT or Cling to make the reproducer in this issue work. Maybe it is an uncontroversial patch. This will also take some time though. I worked a lot on PyROOT in the last weeks and have to work on other responsibilities in the next weeks before coming back to this. Or maybe @wlav has a hint?. > In the meantime, might there be anything I could try to ""persuade"" similar quirks, from either C++ or Python to make them work?. Unfortunately not. In ROOT, we don't use complicated template code with type traits in user interfaces. That's maybe my recommendation to you: can you simplify the user-facing interface and hide the templated stuff maybe behind some type-erased types or simplify it a bit? IMHO, templates are great for efficient implementations, but for user interfaces it can be a nightmare (think only about the error messages...).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/15062#issuecomment-2022342966
Usability,simpl,simplify,"> Are there plans/work in progress for ROOT to move to a newer cppyy anytime soon?. Hi @taehyounpark! We have recently upgraded the cppyy frontend in ROOT, which will be part of ROOT 6.32:; https://github.com/root-project/root/pull/14507. However, it doesn't fix this reproducer. I suspect that this also requires to synchronize the [cppyy-backend](https://github.com/wlav/cppyy-backend/tree). The problem is that this backend is a fork of ROOT itself, including cling. And then, cppyy made patches to this fork of cling/ROOT for e.g. better lambda support and other advanced C++ features and details of the type system. The problem is that we can't take these patches 1 to 1 back to ROOT, because ROOT also used Cling for other things like IO, and the patches in cppyy did not have to consider compatibility with that. We try to make cppyy independent of cling on the long term to solve this conundrum. In the meantime, I can see what we are exactly missing in upstream ROOT or Cling to make the reproducer in this issue work. Maybe it is an uncontroversial patch. This will also take some time though. I worked a lot on PyROOT in the last weeks and have to work on other responsibilities in the next weeks before coming back to this. Or maybe @wlav has a hint?. > In the meantime, might there be anything I could try to ""persuade"" similar quirks, from either C++ or Python to make them work?. Unfortunately not. In ROOT, we don't use complicated template code with type traits in user interfaces. That's maybe my recommendation to you: can you simplify the user-facing interface and hide the templated stuff maybe behind some type-erased types or simplify it a bit? IMHO, templates are great for efficient implementations, but for user interfaces it can be a nightmare (think only about the error messages...).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/15062#issuecomment-2022342966
Deployability,upgrade,upgrade,"Hi @VanyaBelyaev!. Can you use C++17? That would simplify the code with `if constexpr`, and also work in the ROOT nightlies thanks to our [cppyy upgrade](https://github.com/root-project/root/pull/14507) last week:. ```c++; // the same with functions; template <unsigned int K,unsigned int N>; auto fun_2 (A<N>&) {; if constexpr(K < N) return ""ququ"";; else return K;; ```. If this is not a solution for you and you absolutely need to support the reproducer above, please also open this issue also in [cppyy upstream](https://github.com/wlav/cppyy) since its also present there. > If I am not mistaken sometime ago the situations was just an opposite - standalone template functions were OK, but template methods were not OK... but now I am not 100% sure... What do you mean by ""sometime ago""? I checked with ROOT 6.30, and the situation is the same as with ROOT master, meaning the cppyy upgrade didn't cause any regression in this regard. Anyway, I can't encourage you enough to move to C++17, implementing the patterns that you implement there is a nightmare without `if constexpr` :slightly_smiling_face:",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/15085#issuecomment-2025083053
Usability,simpl,simplify,"Hi @VanyaBelyaev!. Can you use C++17? That would simplify the code with `if constexpr`, and also work in the ROOT nightlies thanks to our [cppyy upgrade](https://github.com/root-project/root/pull/14507) last week:. ```c++; // the same with functions; template <unsigned int K,unsigned int N>; auto fun_2 (A<N>&) {; if constexpr(K < N) return ""ququ"";; else return K;; ```. If this is not a solution for you and you absolutely need to support the reproducer above, please also open this issue also in [cppyy upstream](https://github.com/wlav/cppyy) since its also present there. > If I am not mistaken sometime ago the situations was just an opposite - standalone template functions were OK, but template methods were not OK... but now I am not 100% sure... What do you mean by ""sometime ago""? I checked with ROOT 6.30, and the situation is the same as with ROOT master, meaning the cppyy upgrade didn't cause any regression in this regard. Anyway, I can't encourage you enough to move to C++17, implementing the patterns that you implement there is a nightmare without `if constexpr` :slightly_smiling_face:",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/15085#issuecomment-2025083053
Availability,error,error,"dear @guitargeek . It seems that my project has one more problem with new cppyy.; While I am trying to prepare ""easy"" reproducer, I need to ask you some advice/recipe.; The issue is with ""python""-RooAbsPdf. I need to have a RooAbdPdf class with the major; method implemented in python. Previously I have such solution, but with new cppyy; I've got two problems - first, and the drawing phase, there are error messages ; that servers are not redirected. ButI have ""correct"" fit results and the plot. ; And, the main problem is that at the end of the script the program stalls -; likely in ROOT finalization. ; It is not easy to make short, simple & easy reproducer, but I'll try to do it asap.; But, might be it is a known issue? ; What is the ""correct/recommended"" way for implementation of such ""hybrid"" pythonic RooAbdPdf?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/15085#issuecomment-2029462023
Integrability,message,messages,"dear @guitargeek . It seems that my project has one more problem with new cppyy.; While I am trying to prepare ""easy"" reproducer, I need to ask you some advice/recipe.; The issue is with ""python""-RooAbsPdf. I need to have a RooAbdPdf class with the major; method implemented in python. Previously I have such solution, but with new cppyy; I've got two problems - first, and the drawing phase, there are error messages ; that servers are not redirected. ButI have ""correct"" fit results and the plot. ; And, the main problem is that at the end of the script the program stalls -; likely in ROOT finalization. ; It is not easy to make short, simple & easy reproducer, but I'll try to do it asap.; But, might be it is a known issue? ; What is the ""correct/recommended"" way for implementation of such ""hybrid"" pythonic RooAbdPdf?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/15085#issuecomment-2029462023
Usability,simpl,simple,"dear @guitargeek . It seems that my project has one more problem with new cppyy.; While I am trying to prepare ""easy"" reproducer, I need to ask you some advice/recipe.; The issue is with ""python""-RooAbsPdf. I need to have a RooAbdPdf class with the major; method implemented in python. Previously I have such solution, but with new cppyy; I've got two problems - first, and the drawing phase, there are error messages ; that servers are not redirected. ButI have ""correct"" fit results and the plot. ; And, the main problem is that at the end of the script the program stalls -; likely in ROOT finalization. ; It is not easy to make short, simple & easy reproducer, but I'll try to do it asap.; But, might be it is a known issue? ; What is the ""correct/recommended"" way for implementation of such ""hybrid"" pythonic RooAbdPdf?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/15085#issuecomment-2029462023
Testability,test,test,"Dear @guitargeek . ... and I have one more problem with another test no my project. It also hangs.. ; Unforunately it i not so simple to isolate,(that's why I am not reporting this problem; since I have no simple reproducer) but since it also involves C++ virtual functions ; reimplemented in python, migth be the unnderlying reason is the same..",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/15085#issuecomment-2036734953
Usability,simpl,simple,"Dear @guitargeek . ... and I have one more problem with another test no my project. It also hangs.. ; Unforunately it i not so simple to isolate,(that's why I am not reporting this problem; since I have no simple reproducer) but since it also involves C++ virtual functions ; reimplemented in python, migth be the unnderlying reason is the same..",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/15085#issuecomment-2036734953
Availability,failure,failure,I restarted the jobs to make sure the failure on Windows was a glitch. A test timedout for a reason which was not clear to me.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15106#issuecomment-2032409208
Testability,test,test,I restarted the jobs to make sure the failure on Windows was a glitch. A test timedout for a reason which was not clear to me.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15106#issuecomment-2032409208
Usability,clear,clear,I restarted the jobs to make sure the failure on Windows was a glitch. A test timedout for a reason which was not clear to me.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15106#issuecomment-2032409208
Security,hash,hashing,"While thinking about collisions and the index storage, one thought that crossed my mind is to template the index based on the index field type(s). I'm not sure if that's a good idea, one of the immediate question being ""do we want `RNTupleIndex<std::string>` and `RNTupleIndex<std::uint64_t>` to be different types?"" But still maybe something to consider, it might simplify the field value storage (if needed) and the entire hashing business...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15116#issuecomment-2242991029
Usability,simpl,simplify,"While thinking about collisions and the index storage, one thought that crossed my mind is to template the index based on the index field type(s). I'm not sure if that's a good idea, one of the immediate question being ""do we want `RNTupleIndex<std::string>` and `RNTupleIndex<std::uint64_t>` to be different types?"" But still maybe something to consider, it might simplify the field value storage (if needed) and the entire hashing business...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15116#issuecomment-2242991029
Integrability,interface,interface,"> While thinking about collisions and the index storage, one thought that crossed my mind is to template the index based on the index field type(s). I'm not sure if that's a good idea, one of the immediate question being ""do we want `RNTupleIndex<std::string>` and `RNTupleIndex<std::uint64_t>` to be different types?"" But still maybe something to consider, it might simplify the field value storage (if needed) and the entire hashing business... This is how I initially implemented it. Indeed it makes the index itself much more straightforward. However, when I started prototyping the actual join/unaligned friends it really didn't work without making that interface overly complicated so in the end I opted for a non-templated version. Perhaps there's some template trickery to still make it play nice with the foreseen interface (or allow for a slightly different but still simple enough interface), I will think about it for a bit.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15116#issuecomment-2285578132
Security,hash,hashing,"> While thinking about collisions and the index storage, one thought that crossed my mind is to template the index based on the index field type(s). I'm not sure if that's a good idea, one of the immediate question being ""do we want `RNTupleIndex<std::string>` and `RNTupleIndex<std::uint64_t>` to be different types?"" But still maybe something to consider, it might simplify the field value storage (if needed) and the entire hashing business... This is how I initially implemented it. Indeed it makes the index itself much more straightforward. However, when I started prototyping the actual join/unaligned friends it really didn't work without making that interface overly complicated so in the end I opted for a non-templated version. Perhaps there's some template trickery to still make it play nice with the foreseen interface (or allow for a slightly different but still simple enough interface), I will think about it for a bit.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15116#issuecomment-2285578132
Usability,simpl,simplify,"> While thinking about collisions and the index storage, one thought that crossed my mind is to template the index based on the index field type(s). I'm not sure if that's a good idea, one of the immediate question being ""do we want `RNTupleIndex<std::string>` and `RNTupleIndex<std::uint64_t>` to be different types?"" But still maybe something to consider, it might simplify the field value storage (if needed) and the entire hashing business... This is how I initially implemented it. Indeed it makes the index itself much more straightforward. However, when I started prototyping the actual join/unaligned friends it really didn't work without making that interface overly complicated so in the end I opted for a non-templated version. Perhaps there's some template trickery to still make it play nice with the foreseen interface (or allow for a slightly different but still simple enough interface), I will think about it for a bit.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15116#issuecomment-2285578132
Modifiability,variab,variables,"> I don't agree with these changes for two reasons:; > ; > * The default is `cuda=OFF`, and if the user passes `cuda=ON` explicitly, it can be annoying if it is switched off at compile time because for example some environment variables were missing. We had complaints about this in the past. That's why I suggested to not have this fallback for features that are by default `OFF`. See also: [[cmake] Some improvements related to feature detection #14834](https://github.com/root-project/root/pull/14834).; > ; > * I would argue that it's not correct to set `cuda=ON` if `all=ON`. Enabling cuda disables TMVA CPU, so clearly you don't get `all` features but different ones. That's why many distros like Arch Linux have a separate `root` and `root-cuda` package. Unless this is fixed, I think the right solution to the problem is to not switch cuda on if `all=ON`. This sounds like a perfectly legitimate solution",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15149#issuecomment-2039583205
Safety,detect,detection,"> I don't agree with these changes for two reasons:; > ; > * The default is `cuda=OFF`, and if the user passes `cuda=ON` explicitly, it can be annoying if it is switched off at compile time because for example some environment variables were missing. We had complaints about this in the past. That's why I suggested to not have this fallback for features that are by default `OFF`. See also: [[cmake] Some improvements related to feature detection #14834](https://github.com/root-project/root/pull/14834).; > ; > * I would argue that it's not correct to set `cuda=ON` if `all=ON`. Enabling cuda disables TMVA CPU, so clearly you don't get `all` features but different ones. That's why many distros like Arch Linux have a separate `root` and `root-cuda` package. Unless this is fixed, I think the right solution to the problem is to not switch cuda on if `all=ON`. This sounds like a perfectly legitimate solution",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15149#issuecomment-2039583205
Usability,clear,clearly,"> I don't agree with these changes for two reasons:; > ; > * The default is `cuda=OFF`, and if the user passes `cuda=ON` explicitly, it can be annoying if it is switched off at compile time because for example some environment variables were missing. We had complaints about this in the past. That's why I suggested to not have this fallback for features that are by default `OFF`. See also: [[cmake] Some improvements related to feature detection #14834](https://github.com/root-project/root/pull/14834).; > ; > * I would argue that it's not correct to set `cuda=ON` if `all=ON`. Enabling cuda disables TMVA CPU, so clearly you don't get `all` features but different ones. That's why many distros like Arch Linux have a separate `root` and `root-cuda` package. Unless this is fixed, I think the right solution to the problem is to not switch cuda on if `all=ON`. This sounds like a perfectly legitimate solution",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15149#issuecomment-2039583205
Modifiability,variab,variables,"> I don't agree with these changes for two reasons:; > ; > * The default is `cuda=OFF`, and if the user passes `cuda=ON` explicitly, it can be annoying if it is switched off at compile time because for example some environment variables were missing. We had complaints about this in the past. That's why I suggested to not have this fallback for features that are by default `OFF`. See also: [[cmake] Some improvements related to feature detection #14834](https://github.com/root-project/root/pull/14834).; > ; > * I would argue that it's not correct to set `cuda=ON` if `all=ON`. Enabling cuda disables TMVA CPU, so clearly you don't get `all` features but different ones. That's why many distros like Arch Linux have a separate `root` and `root-cuda` package. Unless this is fixed, I think the right solution to the problem is to not switch cuda on if `all=ON`. Indeed, I was wrong with the second bullet point here. I remembered it wrongly because when building with `tmva-gpu`, some tutorials use the GPU backend of TMVA by default. This first argument still holds though!. I made an alternative suggestion: https://github.com/root-project/root/pull/15155. This one also fixes the problem that the `cuda` flag is checked before it is set. It simplifies the logic also a bit: the `cuda` flag is not determining anymore if CMake will look for the CUDA language and add it to the project. It only determines if ROOTs CUDA sources are actually built.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15149#issuecomment-2039816688
Safety,detect,detection,"> I don't agree with these changes for two reasons:; > ; > * The default is `cuda=OFF`, and if the user passes `cuda=ON` explicitly, it can be annoying if it is switched off at compile time because for example some environment variables were missing. We had complaints about this in the past. That's why I suggested to not have this fallback for features that are by default `OFF`. See also: [[cmake] Some improvements related to feature detection #14834](https://github.com/root-project/root/pull/14834).; > ; > * I would argue that it's not correct to set `cuda=ON` if `all=ON`. Enabling cuda disables TMVA CPU, so clearly you don't get `all` features but different ones. That's why many distros like Arch Linux have a separate `root` and `root-cuda` package. Unless this is fixed, I think the right solution to the problem is to not switch cuda on if `all=ON`. Indeed, I was wrong with the second bullet point here. I remembered it wrongly because when building with `tmva-gpu`, some tutorials use the GPU backend of TMVA by default. This first argument still holds though!. I made an alternative suggestion: https://github.com/root-project/root/pull/15155. This one also fixes the problem that the `cuda` flag is checked before it is set. It simplifies the logic also a bit: the `cuda` flag is not determining anymore if CMake will look for the CUDA language and add it to the project. It only determines if ROOTs CUDA sources are actually built.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15149#issuecomment-2039816688
Testability,log,logic,"> I don't agree with these changes for two reasons:; > ; > * The default is `cuda=OFF`, and if the user passes `cuda=ON` explicitly, it can be annoying if it is switched off at compile time because for example some environment variables were missing. We had complaints about this in the past. That's why I suggested to not have this fallback for features that are by default `OFF`. See also: [[cmake] Some improvements related to feature detection #14834](https://github.com/root-project/root/pull/14834).; > ; > * I would argue that it's not correct to set `cuda=ON` if `all=ON`. Enabling cuda disables TMVA CPU, so clearly you don't get `all` features but different ones. That's why many distros like Arch Linux have a separate `root` and `root-cuda` package. Unless this is fixed, I think the right solution to the problem is to not switch cuda on if `all=ON`. Indeed, I was wrong with the second bullet point here. I remembered it wrongly because when building with `tmva-gpu`, some tutorials use the GPU backend of TMVA by default. This first argument still holds though!. I made an alternative suggestion: https://github.com/root-project/root/pull/15155. This one also fixes the problem that the `cuda` flag is checked before it is set. It simplifies the logic also a bit: the `cuda` flag is not determining anymore if CMake will look for the CUDA language and add it to the project. It only determines if ROOTs CUDA sources are actually built.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15149#issuecomment-2039816688
Usability,clear,clearly,"> I don't agree with these changes for two reasons:; > ; > * The default is `cuda=OFF`, and if the user passes `cuda=ON` explicitly, it can be annoying if it is switched off at compile time because for example some environment variables were missing. We had complaints about this in the past. That's why I suggested to not have this fallback for features that are by default `OFF`. See also: [[cmake] Some improvements related to feature detection #14834](https://github.com/root-project/root/pull/14834).; > ; > * I would argue that it's not correct to set `cuda=ON` if `all=ON`. Enabling cuda disables TMVA CPU, so clearly you don't get `all` features but different ones. That's why many distros like Arch Linux have a separate `root` and `root-cuda` package. Unless this is fixed, I think the right solution to the problem is to not switch cuda on if `all=ON`. Indeed, I was wrong with the second bullet point here. I remembered it wrongly because when building with `tmva-gpu`, some tutorials use the GPU backend of TMVA by default. This first argument still holds though!. I made an alternative suggestion: https://github.com/root-project/root/pull/15155. This one also fixes the problem that the `cuda` flag is checked before it is set. It simplifies the logic also a bit: the `cuda` flag is not determining anymore if CMake will look for the CUDA language and add it to the project. It only determines if ROOTs CUDA sources are actually built.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15149#issuecomment-2039816688
Integrability,protocol,protocol,"I understand where `PySequence_Check` is coming from (there is e.g. a standard Python `iterator` that will try indexing an object from 0 with integers), but for C++ bound containers (or C++ objects in general), the right question to ask is whether they implement the iterator protocol. E.g. an `std::list` is a sequence and can be iterated over, but not through indexing, as it's not random-access. For `std::map` the same issues exist as for Python, but of course with no special-case exception made in `PySequence_Check` and `std::map<int, T>` is a particular hot mess. Then there's the fact that `operator[](T)` can be redefined in both C++ and Python to mean whatever ... Note that an iterator protocol check would be for `hasattr(obj, '__iter__')` and not `iter(obj)`, as the latter would succeed b/c of that index-based `iterator` mentioned. I'm not really convinced by the `is_sequence()` method proposed, as it would currently fail for this:; ```; import cppyy. cppyy.cppdef(""""""\; struct MyStruct {};; MyStruct* fff = nullptr;; """"""). def is_sequence(obj):; try:; obj[0]; return True; except TypeError as e:; print(e); return False. print(is_sequence(cppyy.gbl.fff)); ```; which prints `True` as all data members are presumed both `*` and `[]`. This should perhaps also be extended to function return types, but returning arrays that way seems to be much less common in practice. Or at least, I've never had that request. Regardless, the problem remains that C++ is simply ambiguous here and I even think it would be fair to assume that `obj[0]` is only every done if `obj` is in fact an array. (Currently not the case, but why not.). Maybe `__getitem__` can be refined to only appear after lookup through `__getattr__`, i.e. to make it fully instance-specific. The result might be confusing as it would still have to be permissive to cover all cases. However, if the check for `__getitem__` is then performed on the class, instead of on the object, it would give you the old behavior back. (I ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/15161#issuecomment-2057616934
Modifiability,extend,extended,"und containers (or C++ objects in general), the right question to ask is whether they implement the iterator protocol. E.g. an `std::list` is a sequence and can be iterated over, but not through indexing, as it's not random-access. For `std::map` the same issues exist as for Python, but of course with no special-case exception made in `PySequence_Check` and `std::map<int, T>` is a particular hot mess. Then there's the fact that `operator[](T)` can be redefined in both C++ and Python to mean whatever ... Note that an iterator protocol check would be for `hasattr(obj, '__iter__')` and not `iter(obj)`, as the latter would succeed b/c of that index-based `iterator` mentioned. I'm not really convinced by the `is_sequence()` method proposed, as it would currently fail for this:; ```; import cppyy. cppyy.cppdef(""""""\; struct MyStruct {};; MyStruct* fff = nullptr;; """"""). def is_sequence(obj):; try:; obj[0]; return True; except TypeError as e:; print(e); return False. print(is_sequence(cppyy.gbl.fff)); ```; which prints `True` as all data members are presumed both `*` and `[]`. This should perhaps also be extended to function return types, but returning arrays that way seems to be much less common in practice. Or at least, I've never had that request. Regardless, the problem remains that C++ is simply ambiguous here and I even think it would be fair to assume that `obj[0]` is only every done if `obj` is in fact an array. (Currently not the case, but why not.). Maybe `__getitem__` can be refined to only appear after lookup through `__getattr__`, i.e. to make it fully instance-specific. The result might be confusing as it would still have to be permissive to cover all cases. However, if the check for `__getitem__` is then performed on the class, instead of on the object, it would give you the old behavior back. (I know that that's not how `PySequence_Check` is supposed to work here, but as already explained, it's not the thing that gives the correct answer in all cases anyhow.)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/15161#issuecomment-2057616934
Performance,perform,performed,"und containers (or C++ objects in general), the right question to ask is whether they implement the iterator protocol. E.g. an `std::list` is a sequence and can be iterated over, but not through indexing, as it's not random-access. For `std::map` the same issues exist as for Python, but of course with no special-case exception made in `PySequence_Check` and `std::map<int, T>` is a particular hot mess. Then there's the fact that `operator[](T)` can be redefined in both C++ and Python to mean whatever ... Note that an iterator protocol check would be for `hasattr(obj, '__iter__')` and not `iter(obj)`, as the latter would succeed b/c of that index-based `iterator` mentioned. I'm not really convinced by the `is_sequence()` method proposed, as it would currently fail for this:; ```; import cppyy. cppyy.cppdef(""""""\; struct MyStruct {};; MyStruct* fff = nullptr;; """"""). def is_sequence(obj):; try:; obj[0]; return True; except TypeError as e:; print(e); return False. print(is_sequence(cppyy.gbl.fff)); ```; which prints `True` as all data members are presumed both `*` and `[]`. This should perhaps also be extended to function return types, but returning arrays that way seems to be much less common in practice. Or at least, I've never had that request. Regardless, the problem remains that C++ is simply ambiguous here and I even think it would be fair to assume that `obj[0]` is only every done if `obj` is in fact an array. (Currently not the case, but why not.). Maybe `__getitem__` can be refined to only appear after lookup through `__getattr__`, i.e. to make it fully instance-specific. The result might be confusing as it would still have to be permissive to cover all cases. However, if the check for `__getitem__` is then performed on the class, instead of on the object, it would give you the old behavior back. (I know that that's not how `PySequence_Check` is supposed to work here, but as already explained, it's not the thing that gives the correct answer in all cases anyhow.)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/15161#issuecomment-2057616934
Security,access,access,"I understand where `PySequence_Check` is coming from (there is e.g. a standard Python `iterator` that will try indexing an object from 0 with integers), but for C++ bound containers (or C++ objects in general), the right question to ask is whether they implement the iterator protocol. E.g. an `std::list` is a sequence and can be iterated over, but not through indexing, as it's not random-access. For `std::map` the same issues exist as for Python, but of course with no special-case exception made in `PySequence_Check` and `std::map<int, T>` is a particular hot mess. Then there's the fact that `operator[](T)` can be redefined in both C++ and Python to mean whatever ... Note that an iterator protocol check would be for `hasattr(obj, '__iter__')` and not `iter(obj)`, as the latter would succeed b/c of that index-based `iterator` mentioned. I'm not really convinced by the `is_sequence()` method proposed, as it would currently fail for this:; ```; import cppyy. cppyy.cppdef(""""""\; struct MyStruct {};; MyStruct* fff = nullptr;; """"""). def is_sequence(obj):; try:; obj[0]; return True; except TypeError as e:; print(e); return False. print(is_sequence(cppyy.gbl.fff)); ```; which prints `True` as all data members are presumed both `*` and `[]`. This should perhaps also be extended to function return types, but returning arrays that way seems to be much less common in practice. Or at least, I've never had that request. Regardless, the problem remains that C++ is simply ambiguous here and I even think it would be fair to assume that `obj[0]` is only every done if `obj` is in fact an array. (Currently not the case, but why not.). Maybe `__getitem__` can be refined to only appear after lookup through `__getattr__`, i.e. to make it fully instance-specific. The result might be confusing as it would still have to be permissive to cover all cases. However, if the check for `__getitem__` is then performed on the class, instead of on the object, it would give you the old behavior back. (I ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/15161#issuecomment-2057616934
Usability,simpl,simply,"und containers (or C++ objects in general), the right question to ask is whether they implement the iterator protocol. E.g. an `std::list` is a sequence and can be iterated over, but not through indexing, as it's not random-access. For `std::map` the same issues exist as for Python, but of course with no special-case exception made in `PySequence_Check` and `std::map<int, T>` is a particular hot mess. Then there's the fact that `operator[](T)` can be redefined in both C++ and Python to mean whatever ... Note that an iterator protocol check would be for `hasattr(obj, '__iter__')` and not `iter(obj)`, as the latter would succeed b/c of that index-based `iterator` mentioned. I'm not really convinced by the `is_sequence()` method proposed, as it would currently fail for this:; ```; import cppyy. cppyy.cppdef(""""""\; struct MyStruct {};; MyStruct* fff = nullptr;; """"""). def is_sequence(obj):; try:; obj[0]; return True; except TypeError as e:; print(e); return False. print(is_sequence(cppyy.gbl.fff)); ```; which prints `True` as all data members are presumed both `*` and `[]`. This should perhaps also be extended to function return types, but returning arrays that way seems to be much less common in practice. Or at least, I've never had that request. Regardless, the problem remains that C++ is simply ambiguous here and I even think it would be fair to assume that `obj[0]` is only every done if `obj` is in fact an array. (Currently not the case, but why not.). Maybe `__getitem__` can be refined to only appear after lookup through `__getattr__`, i.e. to make it fully instance-specific. The result might be confusing as it would still have to be permissive to cover all cases. However, if the check for `__getitem__` is then performed on the class, instead of on the object, it would give you the old behavior back. (I know that that's not how `PySequence_Check` is supposed to work here, but as already explained, it's not the thing that gives the correct answer in all cases anyhow.)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/15161#issuecomment-2057616934
Availability,avail,available,"> In the original reproducer, the __getitem__ attribute check is done for the instance, so this wouldn't help there right?. Right, I know no way around that. Also, it'd be fine for those cases where a pointer is known to be an array, but like the example above, would fail cases where it's simply *likely* to be an array, as a `__getitem__` would be returned. > https://gitlab.cern.ch/atlas/athena/-/merge_requests/70435/diffs. That will give you different answers depending on whether the sequence has 0 or N elements, though. But there are plenty more worrisome things in that code. :). I'm looking at the implementation of `PySequence_Check`, which is:. ```; int; PySequence_Check(PyObject *s); { ; if (PyDict_Check(s)); return 0; ; return Py_TYPE(s)->tp_as_sequence &&; Py_TYPE(s)->tp_as_sequence->sq_item != NULL;; }; ```. The default `__getitem__` is added to the class as part of the `tp_methods` set and I guess it ends up there. A bit strange, though, as `sq_item` is limited to indexing with Py_ssize_t and that's not specified in the method list (only `METH_O`). But it may give us something to work with as `mp_subscript` is also available. Would have to see whether C++-side `operator[]` properly overrides that and still makes `PySequence_Check` work. It's not directly clear to me that it would, but can give it a try.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/15161#issuecomment-2057955720
Integrability,depend,depending,"> In the original reproducer, the __getitem__ attribute check is done for the instance, so this wouldn't help there right?. Right, I know no way around that. Also, it'd be fine for those cases where a pointer is known to be an array, but like the example above, would fail cases where it's simply *likely* to be an array, as a `__getitem__` would be returned. > https://gitlab.cern.ch/atlas/athena/-/merge_requests/70435/diffs. That will give you different answers depending on whether the sequence has 0 or N elements, though. But there are plenty more worrisome things in that code. :). I'm looking at the implementation of `PySequence_Check`, which is:. ```; int; PySequence_Check(PyObject *s); { ; if (PyDict_Check(s)); return 0; ; return Py_TYPE(s)->tp_as_sequence &&; Py_TYPE(s)->tp_as_sequence->sq_item != NULL;; }; ```. The default `__getitem__` is added to the class as part of the `tp_methods` set and I guess it ends up there. A bit strange, though, as `sq_item` is limited to indexing with Py_ssize_t and that's not specified in the method list (only `METH_O`). But it may give us something to work with as `mp_subscript` is also available. Would have to see whether C++-side `operator[]` properly overrides that and still makes `PySequence_Check` work. It's not directly clear to me that it would, but can give it a try.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/15161#issuecomment-2057955720
Usability,simpl,simply,"> In the original reproducer, the __getitem__ attribute check is done for the instance, so this wouldn't help there right?. Right, I know no way around that. Also, it'd be fine for those cases where a pointer is known to be an array, but like the example above, would fail cases where it's simply *likely* to be an array, as a `__getitem__` would be returned. > https://gitlab.cern.ch/atlas/athena/-/merge_requests/70435/diffs. That will give you different answers depending on whether the sequence has 0 or N elements, though. But there are plenty more worrisome things in that code. :). I'm looking at the implementation of `PySequence_Check`, which is:. ```; int; PySequence_Check(PyObject *s); { ; if (PyDict_Check(s)); return 0; ; return Py_TYPE(s)->tp_as_sequence &&; Py_TYPE(s)->tp_as_sequence->sq_item != NULL;; }; ```. The default `__getitem__` is added to the class as part of the `tp_methods` set and I guess it ends up there. A bit strange, though, as `sq_item` is limited to indexing with Py_ssize_t and that's not specified in the method list (only `METH_O`). But it may give us something to work with as `mp_subscript` is also available. Would have to see whether C++-side `operator[]` properly overrides that and still makes `PySequence_Check` work. It's not directly clear to me that it would, but can give it a try.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/15161#issuecomment-2057955720
Security,expose,expose,"Back to an alternative... Myself, I do the following to find out whether a C++ class had an `operator[]`: https://github.com/wlav/CPyCppyy/blob/master/src/Pythonize.cxx#L38 , but it may not work for you as-is, b/c an important point of that code is to not search for `__getitem__` in base classes, which I think you do want. Maybe something much simpler would be something along these lines:. ```; import cppyy; import cppyy.types. cppyy.cppdef(""""""\; struct MyStruct1 {};; struct MyStruct2 {; int operator[](int) { return 42; }; };. #include ""CPyCppyy/API.h"". bool CheckSequence(PyObject* obj, PyObject* base) {; if (CPyCppyy::Instance_Check(obj)) {; PyObject* gi1 = PyObject_GetAttrString((PyObject*)Py_TYPE(obj), ""__getitem__"");; PyObject* gi2 = PyObject_GetAttrString(base, ""__getitem__"");; bool ret = gi1 && gi1 != gi2;; Py_XDECREF(gi2);; Py_XDECREF(gi1);; return ret;; }; return false;; }; """"""). print(cppyy.gbl.CheckSequence(cppyy.gbl.MyStruct1(), cppyy.types.Instance)); print(cppyy.gbl.CheckSequence(cppyy.gbl.MyStruct2(), cppyy.types.Instance)); ```. (Where you'd import `cppyy.types.Instance` on the C-side, not pass it as an argument, but this Q&D code was simpler.). This can be greatly simplified/sped up, by explicitly adding `op_getitem` as a method for `tp_as_sequence` and then do a straight-up pointer comparison. Can probably also expose it as a `CPyCppyy::Sequence_Check` in the API.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/15161#issuecomment-2058191558
Usability,simpl,simpler,"Back to an alternative... Myself, I do the following to find out whether a C++ class had an `operator[]`: https://github.com/wlav/CPyCppyy/blob/master/src/Pythonize.cxx#L38 , but it may not work for you as-is, b/c an important point of that code is to not search for `__getitem__` in base classes, which I think you do want. Maybe something much simpler would be something along these lines:. ```; import cppyy; import cppyy.types. cppyy.cppdef(""""""\; struct MyStruct1 {};; struct MyStruct2 {; int operator[](int) { return 42; }; };. #include ""CPyCppyy/API.h"". bool CheckSequence(PyObject* obj, PyObject* base) {; if (CPyCppyy::Instance_Check(obj)) {; PyObject* gi1 = PyObject_GetAttrString((PyObject*)Py_TYPE(obj), ""__getitem__"");; PyObject* gi2 = PyObject_GetAttrString(base, ""__getitem__"");; bool ret = gi1 && gi1 != gi2;; Py_XDECREF(gi2);; Py_XDECREF(gi1);; return ret;; }; return false;; }; """"""). print(cppyy.gbl.CheckSequence(cppyy.gbl.MyStruct1(), cppyy.types.Instance)); print(cppyy.gbl.CheckSequence(cppyy.gbl.MyStruct2(), cppyy.types.Instance)); ```. (Where you'd import `cppyy.types.Instance` on the C-side, not pass it as an argument, but this Q&D code was simpler.). This can be greatly simplified/sped up, by explicitly adding `op_getitem` as a method for `tp_as_sequence` and then do a straight-up pointer comparison. Can probably also expose it as a `CPyCppyy::Sequence_Check` in the API.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/15161#issuecomment-2058191558
Usability,clear,clearly,"Thanks for the review!. The only tutorial for that feature silently gives wrong results: IMO this is a bugfix, not a new feature. Also considering that there are people who would clearly benefit from this being in 6.32 (analysis grand challenge).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15173#issuecomment-2044568142
Deployability,install,installed,"> My two cents is we should disable the tests . Do you mean short term while we fix the issue or do you mean just ignore the issue?. In this case, unless the tutorial (!) are showing something that the user are very unlikely to do, I think we need to go further and make sure that this same crash/problem won't happen to the user. . > (and stop using Jenkins for PR builds). I agree ... except that they seems to be probing an area of the phase space we are not testing elsewhere. Note: if the issue is as simple as ""the installed version of some dependent product is too old so there is no point in fixing the problem"", we still need to fix the `CMake` configuration to fail when asked to use those older version.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/15211#issuecomment-2050660691
Integrability,depend,dependent,"> My two cents is we should disable the tests . Do you mean short term while we fix the issue or do you mean just ignore the issue?. In this case, unless the tutorial (!) are showing something that the user are very unlikely to do, I think we need to go further and make sure that this same crash/problem won't happen to the user. . > (and stop using Jenkins for PR builds). I agree ... except that they seems to be probing an area of the phase space we are not testing elsewhere. Note: if the issue is as simple as ""the installed version of some dependent product is too old so there is no point in fixing the problem"", we still need to fix the `CMake` configuration to fail when asked to use those older version.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/15211#issuecomment-2050660691
Modifiability,config,configuration,"> My two cents is we should disable the tests . Do you mean short term while we fix the issue or do you mean just ignore the issue?. In this case, unless the tutorial (!) are showing something that the user are very unlikely to do, I think we need to go further and make sure that this same crash/problem won't happen to the user. . > (and stop using Jenkins for PR builds). I agree ... except that they seems to be probing an area of the phase space we are not testing elsewhere. Note: if the issue is as simple as ""the installed version of some dependent product is too old so there is no point in fixing the problem"", we still need to fix the `CMake` configuration to fail when asked to use those older version.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/15211#issuecomment-2050660691
Testability,test,tests,"> My two cents is we should disable the tests . Do you mean short term while we fix the issue or do you mean just ignore the issue?. In this case, unless the tutorial (!) are showing something that the user are very unlikely to do, I think we need to go further and make sure that this same crash/problem won't happen to the user. . > (and stop using Jenkins for PR builds). I agree ... except that they seems to be probing an area of the phase space we are not testing elsewhere. Note: if the issue is as simple as ""the installed version of some dependent product is too old so there is no point in fixing the problem"", we still need to fix the `CMake` configuration to fail when asked to use those older version.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/15211#issuecomment-2050660691
Usability,simpl,simple,"> My two cents is we should disable the tests . Do you mean short term while we fix the issue or do you mean just ignore the issue?. In this case, unless the tutorial (!) are showing something that the user are very unlikely to do, I think we need to go further and make sure that this same crash/problem won't happen to the user. . > (and stop using Jenkins for PR builds). I agree ... except that they seems to be probing an area of the phase space we are not testing elsewhere. Note: if the issue is as simple as ""the installed version of some dependent product is too old so there is no point in fixing the problem"", we still need to fix the `CMake` configuration to fail when asked to use those older version.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/15211#issuecomment-2050660691
Deployability,configurat,configuration,"> If the developer wants to also run Python-based unittests, yes. I don't see any issue with that. Humm .. I thought a bare `ctest` would run it, so it is the opposite, one would know to add a `-E ` to ignore them. > No, they are not. Well they ""appear"" to be because of the test. The jenkins node was configured however it was (and the user could have the exact same configuration) and a run of `ctest` fails and ""clearly"" states that those are requirements :). From my limited view point it seems that we have:; * python support is enabled ; * some optional component is not installed (and I am assuming that the related features are disabled and the actual tests related to those features are not run); * a test still complains that those optional component are not installed. To make an analogy: this sound like we would have the situations:; * `X11` support is enabled.; * The `OpenGL` libraries (`MesaGL`) is not installed and support for `OpenGL` is disabled, no test tries to run `OpenGL` code); * Still ctest fails noting that `MesaGL` is in the list of 'requirements'. How does my analogy fails/differs from the `xgboost` case?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/15212#issuecomment-2052136735
Modifiability,config,configured,"> If the developer wants to also run Python-based unittests, yes. I don't see any issue with that. Humm .. I thought a bare `ctest` would run it, so it is the opposite, one would know to add a `-E ` to ignore them. > No, they are not. Well they ""appear"" to be because of the test. The jenkins node was configured however it was (and the user could have the exact same configuration) and a run of `ctest` fails and ""clearly"" states that those are requirements :). From my limited view point it seems that we have:; * python support is enabled ; * some optional component is not installed (and I am assuming that the related features are disabled and the actual tests related to those features are not run); * a test still complains that those optional component are not installed. To make an analogy: this sound like we would have the situations:; * `X11` support is enabled.; * The `OpenGL` libraries (`MesaGL`) is not installed and support for `OpenGL` is disabled, no test tries to run `OpenGL` code); * Still ctest fails noting that `MesaGL` is in the list of 'requirements'. How does my analogy fails/differs from the `xgboost` case?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/15212#issuecomment-2052136735
Testability,test,test,"> If the developer wants to also run Python-based unittests, yes. I don't see any issue with that. Humm .. I thought a bare `ctest` would run it, so it is the opposite, one would know to add a `-E ` to ignore them. > No, they are not. Well they ""appear"" to be because of the test. The jenkins node was configured however it was (and the user could have the exact same configuration) and a run of `ctest` fails and ""clearly"" states that those are requirements :). From my limited view point it seems that we have:; * python support is enabled ; * some optional component is not installed (and I am assuming that the related features are disabled and the actual tests related to those features are not run); * a test still complains that those optional component are not installed. To make an analogy: this sound like we would have the situations:; * `X11` support is enabled.; * The `OpenGL` libraries (`MesaGL`) is not installed and support for `OpenGL` is disabled, no test tries to run `OpenGL` code); * Still ctest fails noting that `MesaGL` is in the list of 'requirements'. How does my analogy fails/differs from the `xgboost` case?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/15212#issuecomment-2052136735
Usability,clear,clearly,"> If the developer wants to also run Python-based unittests, yes. I don't see any issue with that. Humm .. I thought a bare `ctest` would run it, so it is the opposite, one would know to add a `-E ` to ignore them. > No, they are not. Well they ""appear"" to be because of the test. The jenkins node was configured however it was (and the user could have the exact same configuration) and a run of `ctest` fails and ""clearly"" states that those are requirements :). From my limited view point it seems that we have:; * python support is enabled ; * some optional component is not installed (and I am assuming that the related features are disabled and the actual tests related to those features are not run); * a test still complains that those optional component are not installed. To make an analogy: this sound like we would have the situations:; * `X11` support is enabled.; * The `OpenGL` libraries (`MesaGL`) is not installed and support for `OpenGL` is disabled, no test tries to run `OpenGL` code); * Still ctest fails noting that `MesaGL` is in the list of 'requirements'. How does my analogy fails/differs from the `xgboost` case?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/15212#issuecomment-2052136735
Usability,simpl,simple-function-working-with-,Following https://root-forum.cern.ch/t/simple-function-working-with-6-28-04-but-not-with-6-30-04/58975,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15227#issuecomment-2053932864
Testability,test,test,Can you just add the two commits fixing the test? I have #15236 adding already xgboost and scikit-learn,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15237#issuecomment-2056871254
Usability,learn,learn,Can you just add the two commits fixing the test? I have #15236 adding already xgboost and scikit-learn,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15237#issuecomment-2056871254
Usability,simpl,simple,"Just to confirm: compilation successful for me with the suggested edits to provide the libbsd root dir, which then also links the library. I do hardcode the filename in my suggestion, which I'm not sure will always work, but perhaps we don't need to perfect this if it solves the issue for CentOS 7 + a simple custom build.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15242#issuecomment-2058569594
Usability,clear,clearer,"> Is the intention perhaps that for all other `TFile` subclasses than `TDavixFiles` and `TNetXNGFiles` (and `TFile`) itself the `RRawFileTFile` is used?. Yes, that's what I want to say. I will think about a clearer formulation... (or maybe you have a proposal?)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15246#issuecomment-2059405769
Integrability,message,message,"@makortel apparently the technical term that I was looking for is ""dynamic type"". I reworded the documentation and commit message accordingly, can you have another look if it's clear(er) now?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15246#issuecomment-2068873320
Usability,clear,clear,"@makortel apparently the technical term that I was looking for is ""dynamic type"". I reworded the documentation and commit message accordingly, can you have another look if it's clear(er) now?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15246#issuecomment-2068873320
Integrability,message,message,"> I reworded the documentation and commit message accordingly, can you have another look if it's clear(er) now?. To me the description in ""Ownership Model"" section is now clear. Thanks!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15246#issuecomment-2069794311
Usability,clear,clear,"> I reworded the documentation and commit message accordingly, can you have another look if it's clear(er) now?. To me the description in ""Ownership Model"" section is now clear. Thanks!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15246#issuecomment-2069794311
Integrability,depend,dependencies,From the test results I learned that we already have a mechanism in ROOT to mark Python non-optional test dependencies:; https://github.com/root-project/root/commit/2917c6e7153c426507227d9fdba1937fca7535aa,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15306#issuecomment-2069022427
Testability,test,test,From the test results I learned that we already have a mechanism in ROOT to mark Python non-optional test dependencies:; https://github.com/root-project/root/commit/2917c6e7153c426507227d9fdba1937fca7535aa,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15306#issuecomment-2069022427
Usability,learn,learned,From the test results I learned that we already have a mechanism in ROOT to mark Python non-optional test dependencies:; https://github.com/root-project/root/commit/2917c6e7153c426507227d9fdba1937fca7535aa,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15306#issuecomment-2069022427
Deployability,install,installed,"that will be a challenge. We see this after we package ROOT in an RPM. I can try to setup something but not on lxplus and it will take time. . Meanwhile, could you tell me if there is a way to force ROOT to look for the modulemap.module in a given place ? ; Why would ROOT not find the modulemap installed in an item of `ROOT_INCLUDE_PATH` ? . I can reproduce the issue on a local setup by simply deleting the `module.modulemap`. So it is really just ROOT not finding the module.modulemap.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/15318#issuecomment-2152689664
Usability,simpl,simply,"that will be a challenge. We see this after we package ROOT in an RPM. I can try to setup something but not on lxplus and it will take time. . Meanwhile, could you tell me if there is a way to force ROOT to look for the modulemap.module in a given place ? ; Why would ROOT not find the modulemap installed in an item of `ROOT_INCLUDE_PATH` ? . I can reproduce the issue on a local setup by simply deleting the `module.modulemap`. So it is really just ROOT not finding the module.modulemap.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/15318#issuecomment-2152689664
Usability,feedback,feedback,You're very welcome! And thanks for the feedback!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/15336#issuecomment-2159926070
Integrability,depend,dependencies,"@pcanal right, that seems a possible way forward. That said, it absolutely requires our own `FindGTest.cmake` while I personally think we should rather move towards standard ways of detecting ROOT dependencies (cf the saga around XRootD). For that reason, I would prefer to *not* make the setup more complicated in this PR than it already is - I argue that removing the dead compatibility code is simply acknowledging the fact that we silently depend on GTest 1.10 already.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15355#issuecomment-2082181170
Safety,detect,detecting,"@pcanal right, that seems a possible way forward. That said, it absolutely requires our own `FindGTest.cmake` while I personally think we should rather move towards standard ways of detecting ROOT dependencies (cf the saga around XRootD). For that reason, I would prefer to *not* make the setup more complicated in this PR than it already is - I argue that removing the dead compatibility code is simply acknowledging the fact that we silently depend on GTest 1.10 already.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15355#issuecomment-2082181170
Usability,simpl,simply,"@pcanal right, that seems a possible way forward. That said, it absolutely requires our own `FindGTest.cmake` while I personally think we should rather move towards standard ways of detecting ROOT dependencies (cf the saga around XRootD). For that reason, I would prefer to *not* make the setup more complicated in this PR than it already is - I argue that removing the dead compatibility code is simply acknowledging the fact that we silently depend on GTest 1.10 already.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15355#issuecomment-2082181170
Testability,test,test,I also think a test would be good. @vgvassilev in which subdirectory would you put the simple macro which was crashing in https://github.com/root-project/roottest/tree/master/cling ?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15368#issuecomment-2083610710
Usability,simpl,simple,I also think a test would be good. @vgvassilev in which subdirectory would you put the simple macro which was crashing in https://github.com/root-project/roottest/tree/master/cling ?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15368#issuecomment-2083610710
Availability,failure,failure,"All green now, besides an unrelated failure that @egpbos should learn about",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15376#issuecomment-2099245931
Energy Efficiency,green,green,"All green now, besides an unrelated failure that @egpbos should learn about",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15376#issuecomment-2099245931
Usability,learn,learn,"All green now, besides an unrelated failure that @egpbos should learn about",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15376#issuecomment-2099245931
Security,hash,hash,"Is mangling supposed to address those characters too? Maybe there is something simple which could be done for names of objects in ROOT, for example keeping only letters and numbers and postponing the hash of the name? In the end we need this for autogenerated code, but maybe I am wrong.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15377#issuecomment-2084946546
Usability,simpl,simple,"Is mangling supposed to address those characters too? Maybe there is something simple which could be done for names of objects in ROOT, for example keeping only letters and numbers and postponing the hash of the name? In the end we need this for autogenerated code, but maybe I am wrong.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15377#issuecomment-2084946546
Testability,test,testing,It could be as simple as testing the full function with a new unit here https://github.com/root-project/root/blob/master/core/clingutils/test/TClingUtilsTests.cxx,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15386#issuecomment-2088090746
Usability,simpl,simple,It could be as simple as testing the full function with a new unit here https://github.com/root-project/root/blob/master/core/clingutils/test/TClingUtilsTests.cxx,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15386#issuecomment-2088090746
Usability,simpl,simplify,"cc: @devajithvs, that might also simplify your migration efforts a little..",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15398#issuecomment-2089926061
Deployability,install,installing,"There is no change for the user, but for packaging it makes things easier. See also https://github.com/root-project/root/pull/15402. Actually this is still a draft PR,I first wanted to see if all platforms are happy with the C++ changes. The next step is to move the `JupyROOT` submodule to `ROOT.JupyROOT`. Also this will have no effect on the user, because the user never imports this module themselves: it is implicitly imported by `ROOT` in a notebook environment. The overall goal of these PRs is to have a single python module (`ROOT`) instead of the current 4 (ROOT, JsMVA, JupyROOT, and DistRDF). For packagers, and for Root as a Python package in general, that would make things clearer and easier: from installing root, you get the module `ROOT`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15404#issuecomment-2092457591
Usability,clear,clearer,"There is no change for the user, but for packaging it makes things easier. See also https://github.com/root-project/root/pull/15402. Actually this is still a draft PR,I first wanted to see if all platforms are happy with the C++ changes. The next step is to move the `JupyROOT` submodule to `ROOT.JupyROOT`. Also this will have no effect on the user, because the user never imports this module themselves: it is implicitly imported by `ROOT` in a notebook environment. The overall goal of these PRs is to have a single python module (`ROOT`) instead of the current 4 (ROOT, JsMVA, JupyROOT, and DistRDF). For packagers, and for Root as a Python package in general, that would make things clearer and easier: from installing root, you get the module `ROOT`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15404#issuecomment-2092457591
Usability,simpl,simple,@linev Please check. This is a simple backport with change in digits rendering in RenderCore.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15411#issuecomment-2093332127
Usability,learn,learning,Interesting for learning what would happen.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15438#issuecomment-2099260382
Usability,intuit,intuition,"Maybe we uncovered a problem with the TString move constructor? Any intuition, @pcanal?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15469#issuecomment-2147872231
Deployability,update,updated,"So this problem has been known for 5 years :( https://github.com/root-project/root/pull/4320 but we manage to indeed lose track of it. That PR used the following more concise pattern:; ```; TView() {} // NOLINT: not allowed to use = default because of TObject::kIsOnHeap detection, see ROOT-10300; ```; where both the `NOLINT` is indeed useful to avoid spurious tool recommendation and the wording was clear but should probably be updated (`ROOT-10300` is a ticket number in the JIRA instance which is now read-only). It would be good to add some wording in the `TObject` documentation.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15469#issuecomment-2150303383
Safety,detect,detection,"So this problem has been known for 5 years :( https://github.com/root-project/root/pull/4320 but we manage to indeed lose track of it. That PR used the following more concise pattern:; ```; TView() {} // NOLINT: not allowed to use = default because of TObject::kIsOnHeap detection, see ROOT-10300; ```; where both the `NOLINT` is indeed useful to avoid spurious tool recommendation and the wording was clear but should probably be updated (`ROOT-10300` is a ticket number in the JIRA instance which is now read-only). It would be good to add some wording in the `TObject` documentation.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15469#issuecomment-2150303383
Usability,clear,clear,"So this problem has been known for 5 years :( https://github.com/root-project/root/pull/4320 but we manage to indeed lose track of it. That PR used the following more concise pattern:; ```; TView() {} // NOLINT: not allowed to use = default because of TObject::kIsOnHeap detection, see ROOT-10300; ```; where both the `NOLINT` is indeed useful to avoid spurious tool recommendation and the wording was clear but should probably be updated (`ROOT-10300` is a ticket number in the JIRA instance which is now read-only). It would be good to add some wording in the `TObject` documentation.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15469#issuecomment-2150303383
Modifiability,maintainab,maintainable,"> For the `TObject` documentation I would add something along the line of:; > ; > ```; > Classes derived from `TObject` can not use the `= default` syntax for their constructor as some compilers implement optimizations that prevents the `TObject::kIsOnHeap` detection mechanism from working properly.; > ```. Can we move this into another PR? (I would suggest you opening it), because it's still not clear whether the main target of the current PR is actually desired or not. And TBH, I don't have the resources to perform a proper benchmark, nor do I have good other arguments why the proposed style is better (for example more readable, more maintainable, etc).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15469#issuecomment-2151703325
Performance,optimiz,optimizations,"> For the `TObject` documentation I would add something along the line of:; > ; > ```; > Classes derived from `TObject` can not use the `= default` syntax for their constructor as some compilers implement optimizations that prevents the `TObject::kIsOnHeap` detection mechanism from working properly.; > ```. Can we move this into another PR? (I would suggest you opening it), because it's still not clear whether the main target of the current PR is actually desired or not. And TBH, I don't have the resources to perform a proper benchmark, nor do I have good other arguments why the proposed style is better (for example more readable, more maintainable, etc).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15469#issuecomment-2151703325
Safety,detect,detection,"> For the `TObject` documentation I would add something along the line of:; > ; > ```; > Classes derived from `TObject` can not use the `= default` syntax for their constructor as some compilers implement optimizations that prevents the `TObject::kIsOnHeap` detection mechanism from working properly.; > ```. Can we move this into another PR? (I would suggest you opening it), because it's still not clear whether the main target of the current PR is actually desired or not. And TBH, I don't have the resources to perform a proper benchmark, nor do I have good other arguments why the proposed style is better (for example more readable, more maintainable, etc).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15469#issuecomment-2151703325
Testability,benchmark,benchmark,"> For the `TObject` documentation I would add something along the line of:; > ; > ```; > Classes derived from `TObject` can not use the `= default` syntax for their constructor as some compilers implement optimizations that prevents the `TObject::kIsOnHeap` detection mechanism from working properly.; > ```. Can we move this into another PR? (I would suggest you opening it), because it's still not clear whether the main target of the current PR is actually desired or not. And TBH, I don't have the resources to perform a proper benchmark, nor do I have good other arguments why the proposed style is better (for example more readable, more maintainable, etc).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15469#issuecomment-2151703325
Usability,clear,clear,"> For the `TObject` documentation I would add something along the line of:; > ; > ```; > Classes derived from `TObject` can not use the `= default` syntax for their constructor as some compilers implement optimizations that prevents the `TObject::kIsOnHeap` detection mechanism from working properly.; > ```. Can we move this into another PR? (I would suggest you opening it), because it's still not clear whether the main target of the current PR is actually desired or not. And TBH, I don't have the resources to perform a proper benchmark, nor do I have good other arguments why the proposed style is better (for example more readable, more maintainable, etc).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15469#issuecomment-2151703325
Usability,simpl,simple,"@silverweed could you please propose a simple pr checking for the mold version? I know it's perhaps a niche use case, but also restoring an optimal user experience for it seems rather cheap...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/15473#issuecomment-2258724184
Usability,simpl,simple,"Thanks. I do not understand. I proposed a simple reproducer that illustrates a bad user experience, very bad, that makes the system unusable. What is the strategy to fix this bug?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/15474#issuecomment-2120092013
Energy Efficiency,reduce,reduce,"> I suspect we could reduce the code of the landau pullback quite a lot. I'm not sure there is still room for much improvement: I have already simplified a lot in my initial PR. Maybe we can merge it, and if you and @vaithak feel like simplifying the pullbacks manually, you can do so in a follow-up PR?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15501#issuecomment-2120812575
Usability,simpl,simplified,"> I suspect we could reduce the code of the landau pullback quite a lot. I'm not sure there is still room for much improvement: I have already simplified a lot in my initial PR. Maybe we can merge it, and if you and @vaithak feel like simplifying the pullbacks manually, you can do so in a follow-up PR?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15501#issuecomment-2120812575
Availability,error,errors,"@bellenot, the zlib problem is fixed now also on Windows, but there are sill build errors related to something else:; ```; (compiling source file '../BUILTIN_CFITSIO/eval_y.c'); ; C:\ROOT-CI\build\CFITSIO-prefix\src\BUILTIN_CFITSIO\cfortran.h(280,1): error C1189: #error: ""cfortran.h: Can't find your environment among: - GNU gcc (g77) on Linux. - MIPS cc and f77 2.0. (e.g. Silicon Graphics, DECstations, ...) - IBM AIX XL C and FORTRAN Compiler/6000 Version 01.01.0000.0000 - VAX VMS CC 3.1 and FORTRAN 5.4. - Alpha VMS DEC C 1.3 and DEC FORTRAN 6.0. - Alpha OSF DEC C and DEC Fortran for OSF/1 AXP Version 1.2 - Apollo DomainOS 10.2 (sys5.3) with f77 10.7 and cc 6.7. - CRAY - NEC SX-4 SUPER-UX - CONVEX - Sun - PowerStation Fortran with Visual C++ - HP9000s300/s700/s800 Latest test with: HP-UX A.08.07 A 9000/730 - LynxOS: cc or gcc with f2c. - VAXUltrix: vcc,cc or gcc with f2c. gcc or cc with f77. - f77 with vcc works; but missing link magic for f77 I/O. - NO fort. None of gcc, cc or vcc generate required names. - f2c/g77: Use #define f2cFortran, or cc -Df2cFortran - gfortran: Use #define gFortran, or cc -DgFortran (also necessary for g77 with -fno-f2c option) - NAG f90: Use #define NAGf90Fortran, or cc -DNAGf90Fortran - Absoft UNIX F77: Use #define AbsoftUNIXFortran or cc -DAbsoftUNIXFortran - Absoft Pro Fortran: Use #define AbsoftProFortran - Portland Group Fortran: Use #define pgiFortran - Intel Fortran: Use #define INTEL_COMPILER"" [C:\ROOT-CI\build\CFITSIO-prefix\src\BUILTIN_CFITSIO-build\cfitsio.vcxproj] [C:\ROOT-CI\build\builtins\cfitsio\BUILTIN_CFITSIO.vcxproj]; (compiling source file '../BUILTIN_CFITSIO/f77_wrap1.c'); ```; This PR has been much less trivial than I thought :laughing: . Maybe we can just avoid doing this check, as suggested in the source itself:; https://github.com/HEASARC/cfitsio/blob/f220e6e2c570f19228609ee081f735df0ddb204b/cfortran.h#L254",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15508#issuecomment-2112196842
Safety,avoid,avoid,"@bellenot, the zlib problem is fixed now also on Windows, but there are sill build errors related to something else:; ```; (compiling source file '../BUILTIN_CFITSIO/eval_y.c'); ; C:\ROOT-CI\build\CFITSIO-prefix\src\BUILTIN_CFITSIO\cfortran.h(280,1): error C1189: #error: ""cfortran.h: Can't find your environment among: - GNU gcc (g77) on Linux. - MIPS cc and f77 2.0. (e.g. Silicon Graphics, DECstations, ...) - IBM AIX XL C and FORTRAN Compiler/6000 Version 01.01.0000.0000 - VAX VMS CC 3.1 and FORTRAN 5.4. - Alpha VMS DEC C 1.3 and DEC FORTRAN 6.0. - Alpha OSF DEC C and DEC Fortran for OSF/1 AXP Version 1.2 - Apollo DomainOS 10.2 (sys5.3) with f77 10.7 and cc 6.7. - CRAY - NEC SX-4 SUPER-UX - CONVEX - Sun - PowerStation Fortran with Visual C++ - HP9000s300/s700/s800 Latest test with: HP-UX A.08.07 A 9000/730 - LynxOS: cc or gcc with f2c. - VAXUltrix: vcc,cc or gcc with f2c. gcc or cc with f77. - f77 with vcc works; but missing link magic for f77 I/O. - NO fort. None of gcc, cc or vcc generate required names. - f2c/g77: Use #define f2cFortran, or cc -Df2cFortran - gfortran: Use #define gFortran, or cc -DgFortran (also necessary for g77 with -fno-f2c option) - NAG f90: Use #define NAGf90Fortran, or cc -DNAGf90Fortran - Absoft UNIX F77: Use #define AbsoftUNIXFortran or cc -DAbsoftUNIXFortran - Absoft Pro Fortran: Use #define AbsoftProFortran - Portland Group Fortran: Use #define pgiFortran - Intel Fortran: Use #define INTEL_COMPILER"" [C:\ROOT-CI\build\CFITSIO-prefix\src\BUILTIN_CFITSIO-build\cfitsio.vcxproj] [C:\ROOT-CI\build\builtins\cfitsio\BUILTIN_CFITSIO.vcxproj]; (compiling source file '../BUILTIN_CFITSIO/f77_wrap1.c'); ```; This PR has been much less trivial than I thought :laughing: . Maybe we can just avoid doing this check, as suggested in the source itself:; https://github.com/HEASARC/cfitsio/blob/f220e6e2c570f19228609ee081f735df0ddb204b/cfortran.h#L254",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15508#issuecomment-2112196842
Testability,test,test,"@bellenot, the zlib problem is fixed now also on Windows, but there are sill build errors related to something else:; ```; (compiling source file '../BUILTIN_CFITSIO/eval_y.c'); ; C:\ROOT-CI\build\CFITSIO-prefix\src\BUILTIN_CFITSIO\cfortran.h(280,1): error C1189: #error: ""cfortran.h: Can't find your environment among: - GNU gcc (g77) on Linux. - MIPS cc and f77 2.0. (e.g. Silicon Graphics, DECstations, ...) - IBM AIX XL C and FORTRAN Compiler/6000 Version 01.01.0000.0000 - VAX VMS CC 3.1 and FORTRAN 5.4. - Alpha VMS DEC C 1.3 and DEC FORTRAN 6.0. - Alpha OSF DEC C and DEC Fortran for OSF/1 AXP Version 1.2 - Apollo DomainOS 10.2 (sys5.3) with f77 10.7 and cc 6.7. - CRAY - NEC SX-4 SUPER-UX - CONVEX - Sun - PowerStation Fortran with Visual C++ - HP9000s300/s700/s800 Latest test with: HP-UX A.08.07 A 9000/730 - LynxOS: cc or gcc with f2c. - VAXUltrix: vcc,cc or gcc with f2c. gcc or cc with f77. - f77 with vcc works; but missing link magic for f77 I/O. - NO fort. None of gcc, cc or vcc generate required names. - f2c/g77: Use #define f2cFortran, or cc -Df2cFortran - gfortran: Use #define gFortran, or cc -DgFortran (also necessary for g77 with -fno-f2c option) - NAG f90: Use #define NAGf90Fortran, or cc -DNAGf90Fortran - Absoft UNIX F77: Use #define AbsoftUNIXFortran or cc -DAbsoftUNIXFortran - Absoft Pro Fortran: Use #define AbsoftProFortran - Portland Group Fortran: Use #define pgiFortran - Intel Fortran: Use #define INTEL_COMPILER"" [C:\ROOT-CI\build\CFITSIO-prefix\src\BUILTIN_CFITSIO-build\cfitsio.vcxproj] [C:\ROOT-CI\build\builtins\cfitsio\BUILTIN_CFITSIO.vcxproj]; (compiling source file '../BUILTIN_CFITSIO/f77_wrap1.c'); ```; This PR has been much less trivial than I thought :laughing: . Maybe we can just avoid doing this check, as suggested in the source itself:; https://github.com/HEASARC/cfitsio/blob/f220e6e2c570f19228609ee081f735df0ddb204b/cfortran.h#L254",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15508#issuecomment-2112196842
Usability,UX,UX,"@bellenot, the zlib problem is fixed now also on Windows, but there are sill build errors related to something else:; ```; (compiling source file '../BUILTIN_CFITSIO/eval_y.c'); ; C:\ROOT-CI\build\CFITSIO-prefix\src\BUILTIN_CFITSIO\cfortran.h(280,1): error C1189: #error: ""cfortran.h: Can't find your environment among: - GNU gcc (g77) on Linux. - MIPS cc and f77 2.0. (e.g. Silicon Graphics, DECstations, ...) - IBM AIX XL C and FORTRAN Compiler/6000 Version 01.01.0000.0000 - VAX VMS CC 3.1 and FORTRAN 5.4. - Alpha VMS DEC C 1.3 and DEC FORTRAN 6.0. - Alpha OSF DEC C and DEC Fortran for OSF/1 AXP Version 1.2 - Apollo DomainOS 10.2 (sys5.3) with f77 10.7 and cc 6.7. - CRAY - NEC SX-4 SUPER-UX - CONVEX - Sun - PowerStation Fortran with Visual C++ - HP9000s300/s700/s800 Latest test with: HP-UX A.08.07 A 9000/730 - LynxOS: cc or gcc with f2c. - VAXUltrix: vcc,cc or gcc with f2c. gcc or cc with f77. - f77 with vcc works; but missing link magic for f77 I/O. - NO fort. None of gcc, cc or vcc generate required names. - f2c/g77: Use #define f2cFortran, or cc -Df2cFortran - gfortran: Use #define gFortran, or cc -DgFortran (also necessary for g77 with -fno-f2c option) - NAG f90: Use #define NAGf90Fortran, or cc -DNAGf90Fortran - Absoft UNIX F77: Use #define AbsoftUNIXFortran or cc -DAbsoftUNIXFortran - Absoft Pro Fortran: Use #define AbsoftProFortran - Portland Group Fortran: Use #define pgiFortran - Intel Fortran: Use #define INTEL_COMPILER"" [C:\ROOT-CI\build\CFITSIO-prefix\src\BUILTIN_CFITSIO-build\cfitsio.vcxproj] [C:\ROOT-CI\build\builtins\cfitsio\BUILTIN_CFITSIO.vcxproj]; (compiling source file '../BUILTIN_CFITSIO/f77_wrap1.c'); ```; This PR has been much less trivial than I thought :laughing: . Maybe we can just avoid doing this check, as suggested in the source itself:; https://github.com/HEASARC/cfitsio/blob/f220e6e2c570f19228609ee081f735df0ddb204b/cfortran.h#L254",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15508#issuecomment-2112196842
Usability,guid,guide,"Thank you for the initiative!. You're also replacing `__MAKECINT__` with `__MAKECLING__`, but I'm not sure we should do this. In the guide, it reads that the `__MAKECINT__` macro is deprecated:; documentation/users-guide/Cling.md. Maybe @pcanal can confirm, but from that paragraph I understand that the replacement for `__MAKECING__` in `__ROOTCLING__`, and not `__MAKECLING__`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15513#issuecomment-2111282912
Modifiability,inherit,inheritance,"> Could it be related to empty base class optimization, or in this case the lack thereof due to multiple inheritance? But in this case, why is the padding missing for `std::variant<X>`, with `struct X {int i; bool b;};`?. So it turns out this is due to EBCO, or rather its non-happening: The reason is that both `std::variant` and `std::optional` inherit from `__sfinae_ctor_base` and `__sfinae_assign_base` and EBCO is not allowed to optimize two empty types at the same offset. That's why the inner type has to have at least one byte of padding, which increases to 4 bytes offset due to alignment. A simplified example is; ```c++; class Empty {};; class Inner : private Empty {; int i;; };; class Outer1 {; Inner i;; };; class Outer2 : private Empty {; Inner i;; };. static_assert(sizeof(Outer1) == 4);; static_assert(sizeof(Outer2) == 8);; ```; (https://godbolt.org/z/6dGdTK6ha) where `Outer2` mimics the case of `std::variant<std::optional<...>>`. Naturally, `struct X` on the other hand does not inherit from the same empty base classes and doesn't need the padding. The problem for RNTuple code is that this can happen for other STL (value) containers as well; we should probably check `std::pair`, `std::tuple` and maybe also maps (not familiar with the implementation). `std::vector`s should be fine because we only need to locate the pointer. (Edit: after further investigation, it appears that this problem is specific to the combination of `std::variant` and `std::optional` that are the only ones using the `__sfinae_*` base classes). ~(FWIW I will also report this to the libc++ developers; they can't do much about it without breaking the ABI, but at least I want to make them aware of this inefficiency in the implementation.)~ (edit: does a `std::variant<std::optional<...>>` actually make much sense?)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/15534#issuecomment-2133063596
Performance,optimiz,optimization,"> Could it be related to empty base class optimization, or in this case the lack thereof due to multiple inheritance? But in this case, why is the padding missing for `std::variant<X>`, with `struct X {int i; bool b;};`?. So it turns out this is due to EBCO, or rather its non-happening: The reason is that both `std::variant` and `std::optional` inherit from `__sfinae_ctor_base` and `__sfinae_assign_base` and EBCO is not allowed to optimize two empty types at the same offset. That's why the inner type has to have at least one byte of padding, which increases to 4 bytes offset due to alignment. A simplified example is; ```c++; class Empty {};; class Inner : private Empty {; int i;; };; class Outer1 {; Inner i;; };; class Outer2 : private Empty {; Inner i;; };. static_assert(sizeof(Outer1) == 4);; static_assert(sizeof(Outer2) == 8);; ```; (https://godbolt.org/z/6dGdTK6ha) where `Outer2` mimics the case of `std::variant<std::optional<...>>`. Naturally, `struct X` on the other hand does not inherit from the same empty base classes and doesn't need the padding. The problem for RNTuple code is that this can happen for other STL (value) containers as well; we should probably check `std::pair`, `std::tuple` and maybe also maps (not familiar with the implementation). `std::vector`s should be fine because we only need to locate the pointer. (Edit: after further investigation, it appears that this problem is specific to the combination of `std::variant` and `std::optional` that are the only ones using the `__sfinae_*` base classes). ~(FWIW I will also report this to the libc++ developers; they can't do much about it without breaking the ABI, but at least I want to make them aware of this inefficiency in the implementation.)~ (edit: does a `std::variant<std::optional<...>>` actually make much sense?)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/15534#issuecomment-2133063596
Usability,simpl,simplified,"> Could it be related to empty base class optimization, or in this case the lack thereof due to multiple inheritance? But in this case, why is the padding missing for `std::variant<X>`, with `struct X {int i; bool b;};`?. So it turns out this is due to EBCO, or rather its non-happening: The reason is that both `std::variant` and `std::optional` inherit from `__sfinae_ctor_base` and `__sfinae_assign_base` and EBCO is not allowed to optimize two empty types at the same offset. That's why the inner type has to have at least one byte of padding, which increases to 4 bytes offset due to alignment. A simplified example is; ```c++; class Empty {};; class Inner : private Empty {; int i;; };; class Outer1 {; Inner i;; };; class Outer2 : private Empty {; Inner i;; };. static_assert(sizeof(Outer1) == 4);; static_assert(sizeof(Outer2) == 8);; ```; (https://godbolt.org/z/6dGdTK6ha) where `Outer2` mimics the case of `std::variant<std::optional<...>>`. Naturally, `struct X` on the other hand does not inherit from the same empty base classes and doesn't need the padding. The problem for RNTuple code is that this can happen for other STL (value) containers as well; we should probably check `std::pair`, `std::tuple` and maybe also maps (not familiar with the implementation). `std::vector`s should be fine because we only need to locate the pointer. (Edit: after further investigation, it appears that this problem is specific to the combination of `std::variant` and `std::optional` that are the only ones using the `__sfinae_*` base classes). ~(FWIW I will also report this to the libc++ developers; they can't do much about it without breaking the ABI, but at least I want to make them aware of this inefficiency in the implementation.)~ (edit: does a `std::variant<std::optional<...>>` actually make much sense?)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/15534#issuecomment-2133063596
Usability,simpl,simpler,Doesn't https://github.com/root-project/cling/issues/430 require a simpler fix by adding libSerialization to the list of linked libraries?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15563#issuecomment-2119129084
Usability,simpl,simpler,"> Doesn't [root-project/cling#430](https://github.com/root-project/cling/issues/430) require a simpler fix by adding libSerialization to the list of linked libraries?. That wouldn't be sufficient at least for linking to a shared library LLVM.so. When LLVM is built this way (`-DLLVM_BUILD_LLVM_DYLIB=ON`, which is what LLVM recommends over `BUILD_SHARED_LIBS=ON` these days, the many lib*.so of LLVM are all gone and everything is in a single `LLVM.so` file.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15563#issuecomment-2121573684
Availability,down,down,"> Please think twice about your use-case before building as a shared library. You can get cling as a shared library through the [CppInterOp](https://github.com/compiler-research/CppInterOp) project. Is CppInterOp the future of Cling (that is, will it eventually obsolete it?). I remember reading about some effort integrating Cling or some clang-repl into the LLVM project itself, which would be simplest for users/distributors down the line. As for my use-case, I tried expounding on the rationale here: https://github.com/root-project/root/pull/15563#issuecomment-2125969791",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15563#issuecomment-2125981292
Deployability,integrat,integrating,"> Please think twice about your use-case before building as a shared library. You can get cling as a shared library through the [CppInterOp](https://github.com/compiler-research/CppInterOp) project. Is CppInterOp the future of Cling (that is, will it eventually obsolete it?). I remember reading about some effort integrating Cling or some clang-repl into the LLVM project itself, which would be simplest for users/distributors down the line. As for my use-case, I tried expounding on the rationale here: https://github.com/root-project/root/pull/15563#issuecomment-2125969791",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15563#issuecomment-2125981292
Integrability,integrat,integrating,"> Please think twice about your use-case before building as a shared library. You can get cling as a shared library through the [CppInterOp](https://github.com/compiler-research/CppInterOp) project. Is CppInterOp the future of Cling (that is, will it eventually obsolete it?). I remember reading about some effort integrating Cling or some clang-repl into the LLVM project itself, which would be simplest for users/distributors down the line. As for my use-case, I tried expounding on the rationale here: https://github.com/root-project/root/pull/15563#issuecomment-2125969791",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15563#issuecomment-2125981292
Usability,simpl,simplest,"> Please think twice about your use-case before building as a shared library. You can get cling as a shared library through the [CppInterOp](https://github.com/compiler-research/CppInterOp) project. Is CppInterOp the future of Cling (that is, will it eventually obsolete it?). I remember reading about some effort integrating Cling or some clang-repl into the LLVM project itself, which would be simplest for users/distributors down the line. As for my use-case, I tried expounding on the rationale here: https://github.com/root-project/root/pull/15563#issuecomment-2125969791",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15563#issuecomment-2125981292
Safety,avoid,avoid,"The PR speeds up by factors (5x-7x) the simple reproducer of the issue we now have thanks to @sawenzel : ; ```.cpp; // Inspired by Alice production code, extracted from the surrounding context; #include ""TF1.h"". void Foo(int N) {; double am = 90;; double awidth = 1;; for (int i = 0; i < N; ++i) {; static TF1 rbw(""rbw"", ""pow([1],2)*pow([0],2)/(pow(x*x-[0]*[0],2)+pow(x*x*[1]/[0],2))"", -10, 10);; rbw.SetRange(am - 5 * awidth, am + 5 * awidth);; rbw.SetParameter(0, am);; rbw.SetParameter(1, awidth);; am = rbw.GetRandom();; if (am <-100000000) std::cout << am << std::endl; // to avoid compiler optimisations; }; }. int main(); {; Foo(1000);; return 0;; }; ```; The code is faster because the fast code path is taken in the PluginHandler because the right type is used in the GSLIntegratorPlugin (unsigned long, via the size_t typedef), and not just a compatible one (unsigned int).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/15579#issuecomment-2161409421
Usability,simpl,simple,"The PR speeds up by factors (5x-7x) the simple reproducer of the issue we now have thanks to @sawenzel : ; ```.cpp; // Inspired by Alice production code, extracted from the surrounding context; #include ""TF1.h"". void Foo(int N) {; double am = 90;; double awidth = 1;; for (int i = 0; i < N; ++i) {; static TF1 rbw(""rbw"", ""pow([1],2)*pow([0],2)/(pow(x*x-[0]*[0],2)+pow(x*x*[1]/[0],2))"", -10, 10);; rbw.SetRange(am - 5 * awidth, am + 5 * awidth);; rbw.SetParameter(0, am);; rbw.SetParameter(1, awidth);; am = rbw.GetRandom();; if (am <-100000000) std::cout << am << std::endl; // to avoid compiler optimisations; }; }. int main(); {; Foo(1000);; return 0;; }; ```; The code is faster because the fast code path is taken in the PluginHandler because the right type is used in the GSLIntegratorPlugin (unsigned long, via the size_t typedef), and not just a compatible one (unsigned int).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/15579#issuecomment-2161409421
Deployability,patch,patches,"Dear @guitargeek ,; thanks a lot for your fast feedback! Indeed, v6-32-00-patches builds fine.; I'm building root as part of the ALICE software stack with custom build options. Using pre-packaged versions will not work.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/15585#issuecomment-2123267444
Usability,feedback,feedback,"Dear @guitargeek ,; thanks a lot for your fast feedback! Indeed, v6-32-00-patches builds fine.; I'm building root as part of the ALICE software stack with custom build options. Using pre-packaged versions will not work.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/15585#issuecomment-2123267444
Usability,clear,clearly,Excellent notes. Do we want to include brief mentions of the PoW items which were addressed (clearly w/o linking to the PoW),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15630#issuecomment-2128825206
Usability,clear,clearly,> Excellent notes. Do we want to include brief mentions of the PoW items which were addressed (clearly w/o linking to the PoW). We should mention the zero-copy bulk read option,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15630#issuecomment-2129035749
Availability,avail,available,"> > Could you provide an example of how this can happen? AFAIU, it is not possible to read an entry from a branch of type say std::vector where some entries of the vector are available and some not (how would that even make sense?).; > ; > It is happening when combining 2 columns from 2 distincts collection:; > ; > ```; > tree->Draw(""vec_1.px + Alt$(vec_2.delta_px, 0)"");; > ```; > ; > where `vec_1.size()` happens to be different from `vec_2.sizeI()` but we still want to plot the data for all element of `vec_1`; > ; > A completely related recent post on the forum: https://root-forum.cern.ch/t/dealing-with-columns-of-different-lengths-in-rdf/61642/2. This use case is fairly simple with RDataFrame and has been supported for a very long time, also it is really unrelated to this PR. Here is an example of how to deal with such cases:. ```cpp; #include <ROOT/RDataFrame.hxx>; #include <ROOT/RVec.hxx>; #include <TFile.h>; #include <TTree.h>. struct Dataset; {; constexpr static auto filename{""myfile.root""};; constexpr static auto treename{""mytree""};; Dataset(); {; TFile f{filename, ""recreate""};; TTree t{treename, treename};. std::vector<float> vec1{1.1f, 2.2f, 3.3f, 4.4f, 5.5f};; std::vector<float> vec2{6.6f, 7.7f};. t.Branch(""vec1"", &vec1);; t.Branch(""vec2"", &vec2);; t.Fill();; t.Write();; }. ~Dataset(); {; std::remove(filename);; }; };. int main(); {; Dataset dataset;; ROOT::RDataFrame df{dataset.treename, dataset.filename};; auto display = df.Define(""vec3"", [](const ROOT::RVecF &vec1, const ROOT::RVecF &vec2); { return vec1 + ROOT::VecOps::Take(vec2, vec1.size(), 10.f); }, {""vec1"", ""vec2""}); .Display<ROOT::RVecF, ROOT::RVecF, ROOT::RVecF>({""vec1"", ""vec2"", ""vec3""});; display->Print();; }; ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15641#issuecomment-2352201431
Usability,simpl,simple,"> > Could you provide an example of how this can happen? AFAIU, it is not possible to read an entry from a branch of type say std::vector where some entries of the vector are available and some not (how would that even make sense?).; > ; > It is happening when combining 2 columns from 2 distincts collection:; > ; > ```; > tree->Draw(""vec_1.px + Alt$(vec_2.delta_px, 0)"");; > ```; > ; > where `vec_1.size()` happens to be different from `vec_2.sizeI()` but we still want to plot the data for all element of `vec_1`; > ; > A completely related recent post on the forum: https://root-forum.cern.ch/t/dealing-with-columns-of-different-lengths-in-rdf/61642/2. This use case is fairly simple with RDataFrame and has been supported for a very long time, also it is really unrelated to this PR. Here is an example of how to deal with such cases:. ```cpp; #include <ROOT/RDataFrame.hxx>; #include <ROOT/RVec.hxx>; #include <TFile.h>; #include <TTree.h>. struct Dataset; {; constexpr static auto filename{""myfile.root""};; constexpr static auto treename{""mytree""};; Dataset(); {; TFile f{filename, ""recreate""};; TTree t{treename, treename};. std::vector<float> vec1{1.1f, 2.2f, 3.3f, 4.4f, 5.5f};; std::vector<float> vec2{6.6f, 7.7f};. t.Branch(""vec1"", &vec1);; t.Branch(""vec2"", &vec2);; t.Fill();; t.Write();; }. ~Dataset(); {; std::remove(filename);; }; };. int main(); {; Dataset dataset;; ROOT::RDataFrame df{dataset.treename, dataset.filename};; auto display = df.Define(""vec3"", [](const ROOT::RVecF &vec1, const ROOT::RVecF &vec2); { return vec1 + ROOT::VecOps::Take(vec2, vec1.size(), 10.f); }, {""vec1"", ""vec2""}); .Display<ROOT::RVecF, ROOT::RVecF, ROOT::RVecF>({""vec1"", ""vec2"", ""vec3""});; display->Print();; }; ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15641#issuecomment-2352201431
Usability,simpl,simple,"> This use case is fairly simple with RDataFrame and has been supported for a very long time, also it is really unrelated to this PR. Here is an example of how to deal with such cases: .... Not easy to read/parse but fair enough.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15641#issuecomment-2353530365
Usability,clear,clearly,"> Not easy to read/parse but fair enough. I gave a fully compiled C++ reproducer, clearly the syntax can get as simple as. ```cpp; df.Define(""vec3"", ""vec1 + Take(vec2, vec1.size(), 99)"").Display({""vec3""});; ```. Getting quite close to TTree::Draw's compactness. Although, for the sake of completeness, let me state that it is personally not my preferred way.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15641#issuecomment-2354009946
Usability,simpl,simple,"Ok, I tried to reproduce the situation with a simple C++ example:; ```c++; #include <iostream>; #include <string>; #include <memory>. struct A {; virtual std::string func() { return ""A""; }; };. struct B : public A {; std::string func() { return ""B""; }; std::string func(int) { return ""B""; }; };. struct C : public A {; std::string func(int=0) { return ""C""; }; };. int main() {. std::unique_ptr<A> a = std::make_unique<A>();; std::unique_ptr<A> b = std::make_unique<B>();; std::unique_ptr<A> c = std::make_unique<C>();. std::cout << a->func() << std::endl;; std::cout << b->func() << std::endl;; std::cout << c->func() << std::endl;; }; ```; Output:; ```txt; A; B; A; ```; Interesting. So if you have a method with default parameters, and the signature with the implicit defaults seems to override a base class method, it actually doesn't. So this is a bug in TProfile2D that needs to be fixed:. * https://github.com/root-project/root/pull/15693",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/15688#issuecomment-2142184689
Usability,simpl,simply,"No, you misunderstood the problem! I am not complaining because of the missing splash screen. This is only the symptom with an easily to reproduce command. The problem is, that any graphics (histograms, plots etc. at the end of a long rot analysis simply do not show up when you forgot to issue the xhost + (using snap and wayland). And this is really annoying.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/15723#issuecomment-2145555699
Usability,feedback,feedback,"Hi @wofr06 ,; Thanks for reporting this and for mentioning the `xhost` workaround.; As said above, version 6.32.00 provide as an opt-in a novel version of the graphics and GUIs, based on web browsers for the rendering. While the `TBrowser` visualisation is to be considered basically production-level, the new web-based graphics still misses some functionality - however, it is quite advanced and could be indeed a solution for you. ; In order to activate it you can:; - start ROOT with the `root --web` command; - invoke programmatically `gROOT->SetWebDisplay()` at the startup of your program; - add the line `Canvas.Name: TWebCanvas` to the `.rootrc` file (which can be in your home directory, a bit like `.bashrc` or similar); ROOT also has a new `TBrowser`, as mentioned above, `ROOT::RBrowser` which is web based. In case you are interested to try, we are very interested in your feedback!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/15723#issuecomment-2146597941
Availability,down,downgrade,"This PR is a 'downgrade' is code simplicity that should not be necessary. However the underlying fix is not ready (and won't until August), so we could temporarily merge this if need be.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15733#issuecomment-2194299016
Usability,simpl,simplicity,"This PR is a 'downgrade' is code simplicity that should not be necessary. However the underlying fix is not ready (and won't until August), so we could temporarily merge this if need be.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15733#issuecomment-2194299016
Usability,guid,guide,"Stacks with negative content generally don't function well. They are built by stacking bricks (1D histograms) or bins (1D histograms) on top of each other. If there's a negative brick in the middle, what should we do? This might need more explanation in the reference guide or even a protection to forbid histograms with negative minimum.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/15740#issuecomment-2149906358
Usability,simpl,simply,> Just a comment. The fact we still have to use naked new and things like Clone to make the graphics work looks really bad in tutorials. Main problem is ownership of histograms. They are destroyed by `DF` handle at the end and cannot be used for graphics.; The only chance to draw them - is to clone them. And `new TLegend` required while it referencing same histograms again. ; `TLegend::DrawClone()` is simply wrong - while it will clone all referenced objects and loos reference to original histograms. . I see no other chance to correctly create `THStack` and `TLegend` in such situation.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15758#issuecomment-2149433058
Testability,test,test,"Hi @will-cern, thanks for the report!. I'm a bit surprised by this, because `setData()` on the new likelihoods should already work. I have added a test to also cover this now: https://github.com/root-project/root/pull/16353. But maybe there is a corner case where it doesn't work? Does it have to do something with the global observables in data? For these we have already great test coverage by the way:; https://github.com/root-project/root/blob/master/roofit/roofitcore/test/testGlobalObservables.cxx#L371. I know that data resetting is a bit fragile with the *old* NLL (`EvalBackend(""legacy"")`). Maybe you're doing some workarounds that make it work in that case, but this work around is not applicable to the new NLL where a simple `setData()` call should suffice?. Anyway, please let me know how I can reproduce the issue if it's really there!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/15763#issuecomment-2322862007
Usability,simpl,simple,"Hi @will-cern, thanks for the report!. I'm a bit surprised by this, because `setData()` on the new likelihoods should already work. I have added a test to also cover this now: https://github.com/root-project/root/pull/16353. But maybe there is a corner case where it doesn't work? Does it have to do something with the global observables in data? For these we have already great test coverage by the way:; https://github.com/root-project/root/blob/master/roofit/roofitcore/test/testGlobalObservables.cxx#L371. I know that data resetting is a bit fragile with the *old* NLL (`EvalBackend(""legacy"")`). Maybe you're doing some workarounds that make it work in that case, but this work around is not applicable to the new NLL where a simple `setData()` call should suffice?. Anyway, please let me know how I can reproduce the issue if it's really there!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/15763#issuecomment-2322862007
Usability,clear,clearly,"Hi, thanks for this proposal. PGO has been investigated in detail by some HEP experiments, e.g. CMS https://indico.cern.ch/event/1106990/contributions/4991214/ . There was no symbol coming from ROOT which was really sticking out.; At the moment don' see clearly how a general purpose framework such as ROOT could benefit from PGO, given the variety of workflows that use ROOT - from HLT to Reco, to Simulation and analysis - and all in different experiments, with very different software stacks. Do you have something in particular in mind? Can you invest some time in the topic to prove your point? It would be interesting for us to comment on concrete measurements.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/15778#issuecomment-2154277257
Performance,perform,performance,"> PGO has been investigated in detail by some HEP experiments, e.g. CMS https://indico.cern.ch/event/1106990/contributions/4991214/ . There was no symbol coming from ROOT which was really sticking out. Thanks a lot for sharing the results!. > At the moment don' see clearly how a general purpose framework such as ROOT could benefit from PGO, given the variety of workflows that use ROOT - from HLT to Reco, to Simulation and analysis - and all in different experiments, with very different software stacks. I agree that various workloads can benefit from PGO differently. What we can do is try to measure PGO performance improvements in multiple scenarios (like all the scenarios you mentioned above), and post the results somewhere (e.g. here). If the performance improvement is measurable for some scenarios - put this information into the project's documentation. In this case, users will be aware about additional ways to optimize Root. > Do you have something in particular in mind? Can you invest some time in the topic to prove your point? It would be interesting for us to comment on concrete measurements. Actually, I don't have in mind any specific workload since I don't have enough experience with Root (at least yet). Later maybe I will be able to spend some time on an experiment with PGO and Root. However, my TODO list for such experiments is a bit [huge](https://github.com/zamazan4ik/awesome-pgo/blob/main/are_we_pgo_yet.md) so I cannot promise any results soon.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/15778#issuecomment-2154412824
Usability,clear,clearly,"> PGO has been investigated in detail by some HEP experiments, e.g. CMS https://indico.cern.ch/event/1106990/contributions/4991214/ . There was no symbol coming from ROOT which was really sticking out. Thanks a lot for sharing the results!. > At the moment don' see clearly how a general purpose framework such as ROOT could benefit from PGO, given the variety of workflows that use ROOT - from HLT to Reco, to Simulation and analysis - and all in different experiments, with very different software stacks. I agree that various workloads can benefit from PGO differently. What we can do is try to measure PGO performance improvements in multiple scenarios (like all the scenarios you mentioned above), and post the results somewhere (e.g. here). If the performance improvement is measurable for some scenarios - put this information into the project's documentation. In this case, users will be aware about additional ways to optimize Root. > Do you have something in particular in mind? Can you invest some time in the topic to prove your point? It would be interesting for us to comment on concrete measurements. Actually, I don't have in mind any specific workload since I don't have enough experience with Root (at least yet). Later maybe I will be able to spend some time on an experiment with PGO and Root. However, my TODO list for such experiments is a bit [huge](https://github.com/zamazan4ik/awesome-pgo/blob/main/are_we_pgo_yet.md) so I cannot promise any results soon.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/15778#issuecomment-2154412824
Usability,clear,clear,"Why not just leave the issue open? If anyone from the community finds the issue interesting - they can start working on it. However, I kindly propose enabling the ""Discussion"" functionality for the repository and then moving the issue to the ""Discussions"" under the ""Ideas"" built-in label. Having the issue closed is not clear for newcomers since they at first look at open issues to start work at, not closed issues.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/15778#issuecomment-2154460609
Usability,simpl,simply,"> How?. Sorry, I simply meant `std::byte b{};`",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15787#issuecomment-2154673614
Usability,simpl,simply,"> Sorry, I simply meant `std::byte b{};`. Oh, right, stupid me...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15787#issuecomment-2154679564
Performance,perform,performance," in `ui5/eve7/` folder, one or two fonts as examples in tutorials and provide recipe where other fonts can be found?. Yes, we could do that. Font textures and metrics files are generated from TTF via https://github.com/osschar/sdf_atlas. It's a small tool, easy to build on linux -- so we could provide instructions for this and also a catalog/web-site with a bunch of pre-generated fonts. > 3. If I understand correct, `REveText` rendering will be only supported with RenderCore? That about three.js? Beside fonts support it is easy to implement text rendering there. Yes, I know ... they have a monster implementation(s) of fonts. Seeing that I went looking for something super simple and still good looking :). Now, this is a bit unfortunate ... but I don't think I have the bandwidth to keep Three fully supported. Also, the low-level, renderer- and shader-level support we are getting from RenderCore (in particular, for picking & rendering of instanced objects and the upcoming spline-based line rendering) is making it possible to support features and performance optimizations that I do not think would be doable in Three with the time budget we all have and the level of changes we can do in core Three (zero, unless we can hack over it locally). > 4. Is it possible to support other font formats - like TTF or OTF? ROOT already includes such fonts, is it an option?. This would be nice, sdf_atlas could be incorporated into root (it requires minimal GL support which we already have) -- and one could then generate the missing SDF fonts during the startup of a demo/application. License is free to use in whatever way, just keep the copyright notice. But it only supports TTF, not OTF. Perhaps we should look for another library ... or at least a new TTF/OTF parser -- I don't know much about low-level font things so this maybe already exists in root?. I understand this is not all perfect -- but at this point our priority is to get something usable in for the existing REve applications.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15812#issuecomment-2161600927
Usability,simpl,simple,"Sergey, all good questions, thank you :). > 1. Do we need to include all these fonts into ROOT repository? Font files are big and used only via random generator in tutorial. No, we can remove most of them, rebase and force-push to the branch. > 2. How to deal with other fonts? Maybe one can include one default font in `ui5/eve7/` folder, one or two fonts as examples in tutorials and provide recipe where other fonts can be found?. Yes, we could do that. Font textures and metrics files are generated from TTF via https://github.com/osschar/sdf_atlas. It's a small tool, easy to build on linux -- so we could provide instructions for this and also a catalog/web-site with a bunch of pre-generated fonts. > 3. If I understand correct, `REveText` rendering will be only supported with RenderCore? That about three.js? Beside fonts support it is easy to implement text rendering there. Yes, I know ... they have a monster implementation(s) of fonts. Seeing that I went looking for something super simple and still good looking :). Now, this is a bit unfortunate ... but I don't think I have the bandwidth to keep Three fully supported. Also, the low-level, renderer- and shader-level support we are getting from RenderCore (in particular, for picking & rendering of instanced objects and the upcoming spline-based line rendering) is making it possible to support features and performance optimizations that I do not think would be doable in Three with the time budget we all have and the level of changes we can do in core Three (zero, unless we can hack over it locally). > 4. Is it possible to support other font formats - like TTF or OTF? ROOT already includes such fonts, is it an option?. This would be nice, sdf_atlas could be incorporated into root (it requires minimal GL support which we already have) -- and one could then generate the missing SDF fonts during the startup of a demo/application. License is free to use in whatever way, just keep the copyright notice. But it only supports TTF",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15812#issuecomment-2161600927
Energy Efficiency,reduce,reduce,> but at this point our priority is to get something usable in for the existing REve applications. Then I propose to reduce number of fonts - one or two for now. And think how one can allow to use external fonts - in this PR or may be later.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15812#issuecomment-2162185672
Usability,usab,usable,> but at this point our priority is to get something usable in for the existing REve applications. Then I propose to reduce number of fonts - one or two for now. And think how one can allow to use external fonts - in this PR or may be later.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15812#issuecomment-2162185672
Availability,avail,available,"> There is only one thing I couldn't figure out -- how to link against libpng ... so I just added -lpng into cmake file for graf3d/gl/. Please help me figure out how to do this correctly. Not so simple. Sometime ROOT uses system-wide `libpng`, sometime - builtin version included in `ASImage`.; And they can conflict with each other. Major problem - builtin with ASImage is not available from outside. You have to ensure that your code not linked with `ASImage`. And provide in your CMakeLists.txt file construct like; ```; find_Package(PNG); # handle include directories; ```; Because you may need to use custom include directories. See [here](https://github.com/root-project/root/blob/master/cmake/modules/SearchInstalledSoftware.cmake#L403-L410)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15812#issuecomment-2172410620
Usability,simpl,simple,"> There is only one thing I couldn't figure out -- how to link against libpng ... so I just added -lpng into cmake file for graf3d/gl/. Please help me figure out how to do this correctly. Not so simple. Sometime ROOT uses system-wide `libpng`, sometime - builtin version included in `ASImage`.; And they can conflict with each other. Major problem - builtin with ASImage is not available from outside. You have to ensure that your code not linked with `ASImage`. And provide in your CMakeLists.txt file construct like; ```; find_Package(PNG); # handle include directories; ```; Because you may need to use custom include directories. See [here](https://github.com/root-project/root/blob/master/cmake/modules/SearchInstalledSoftware.cmake#L403-L410)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15812#issuecomment-2172410620
Integrability,depend,dependency,"Hmmh, but then I'd need to stream path information with every REveText object, now only the font name is streamed. It is indeed a reasonable thing to check if the font files exist before object's json is sent over to the client --- but creating a font during the streaming traversal would be pushing it a bit. Is it possible to register custom prefixes and callbacks from REveManager (via RWebWindow) so they can be handled when requests come in? Like: http://server/sdf-fonts/. I went through the code a bit (but clearly do not have the full picture) ... one way would be to add THttpServer::fActiveLocations, where instead of replacement string one provides a lambda [](TString& prefix, TString& reminder, THttpRequest& req, THttpServer &srv) so one can then do appropriate lookup in the callback, potentially generating the font, and then calling srv->SendFile() (or sending back the default font, if the desired one can not be found/generated). I think this functionality could be useful for other cases in REve, where semi-static data needs to be provided. The font-generation code in REveText invokes TGL generator through the interpreter now, via gROOT->ProcessLine(), to avoid dependency of REve on RGL. Is this OK to do from a request handler thread or should cross-thread request to the main thread be made (and request told to try again in N seconds)?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15812#issuecomment-2176441216
Safety,avoid,avoid,"Hmmh, but then I'd need to stream path information with every REveText object, now only the font name is streamed. It is indeed a reasonable thing to check if the font files exist before object's json is sent over to the client --- but creating a font during the streaming traversal would be pushing it a bit. Is it possible to register custom prefixes and callbacks from REveManager (via RWebWindow) so they can be handled when requests come in? Like: http://server/sdf-fonts/. I went through the code a bit (but clearly do not have the full picture) ... one way would be to add THttpServer::fActiveLocations, where instead of replacement string one provides a lambda [](TString& prefix, TString& reminder, THttpRequest& req, THttpServer &srv) so one can then do appropriate lookup in the callback, potentially generating the font, and then calling srv->SendFile() (or sending back the default font, if the desired one can not be found/generated). I think this functionality could be useful for other cases in REve, where semi-static data needs to be provided. The font-generation code in REveText invokes TGL generator through the interpreter now, via gROOT->ProcessLine(), to avoid dependency of REve on RGL. Is this OK to do from a request handler thread or should cross-thread request to the main thread be made (and request told to try again in N seconds)?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15812#issuecomment-2176441216
Usability,clear,clearly,"Hmmh, but then I'd need to stream path information with every REveText object, now only the font name is streamed. It is indeed a reasonable thing to check if the font files exist before object's json is sent over to the client --- but creating a font during the streaming traversal would be pushing it a bit. Is it possible to register custom prefixes and callbacks from REveManager (via RWebWindow) so they can be handled when requests come in? Like: http://server/sdf-fonts/. I went through the code a bit (but clearly do not have the full picture) ... one way would be to add THttpServer::fActiveLocations, where instead of replacement string one provides a lambda [](TString& prefix, TString& reminder, THttpRequest& req, THttpServer &srv) so one can then do appropriate lookup in the callback, potentially generating the font, and then calling srv->SendFile() (or sending back the default font, if the desired one can not be found/generated). I think this functionality could be useful for other cases in REve, where semi-static data needs to be provided. The font-generation code in REveText invokes TGL generator through the interpreter now, via gROOT->ProcessLine(), to avoid dependency of REve on RGL. Is this OK to do from a request handler thread or should cross-thread request to the main thread be made (and request told to try again in N seconds)?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15812#issuecomment-2176441216
Security,access,access,"> Hmmh, so you don't want to give me an active directory? :). For the moment there is no direct support of such feature with `RWebWindow`.; But can be provided - if really necessary. In my mind, solution with direct access of font files via `currentdir/` path is much clear.; And does not require any extra threads locking. You always can implement active directory - but does it necessary with fonts?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15812#issuecomment-2177936944
Usability,clear,clear,"> Hmmh, so you don't want to give me an active directory? :). For the moment there is no direct support of such feature with `RWebWindow`.; But can be provided - if really necessary. In my mind, solution with direct access of font files via `currentdir/` path is much clear.; And does not require any extra threads locking. You always can implement active directory - but does it necessary with fonts?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15812#issuecomment-2177936944
Integrability,depend,depends,"Ok, if `libGL` already depends from `libAfterImage` - then it is fine. You may add simple gtest-based code directly for `libGL` - then it will be automatically tested on all platforms.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15812#issuecomment-2252647669
Testability,test,tested,"Ok, if `libGL` already depends from `libAfterImage` - then it is fine. You may add simple gtest-based code directly for `libGL` - then it will be automatically tested on all platforms.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15812#issuecomment-2252647669
Usability,simpl,simple,"Ok, if `libGL` already depends from `libAfterImage` - then it is fine. You may add simple gtest-based code directly for `libGL` - then it will be automatically tested on all platforms.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15812#issuecomment-2252647669
Usability,guid,guidance,Thank you for your guidance Sergey! I'm glad this got done right :),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15812#issuecomment-2255129356
Safety,avoid,avoid,"The PR speeds up by factors (5x-7x) the simple reproducer of the issue we now have thanks to @sawenzel : ; ```.cpp; // Inspired by Alice production code, extracted from the surrounding context; #include ""TF1.h"". void Foo(int N) {; double am = 90;; double awidth = 1;; for (int i = 0; i < N; ++i) {; static TF1 rbw(""rbw"", ""pow([1],2)*pow([0],2)/(pow(x*x-[0]*[0],2)+pow(x*x*[1]/[0],2))"", -10, 10);; rbw.SetRange(am - 5 * awidth, am + 5 * awidth);; rbw.SetParameter(0, am);; rbw.SetParameter(1, awidth);; am = rbw.GetRandom();; if (am <-100000000) std::cout << am << std::endl; // to avoid compiler optimisations; }; }. int main(); {; Foo(1000);; return 0;; }; ```; The code is faster because the fast code path is taken in the PluginHandler because the right type is used in the GSLIntegratorPlugin (unsigned long, via the size_t typedef), and not just a compatible one (unsigned int).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15816#issuecomment-2161410185
Usability,simpl,simple,"The PR speeds up by factors (5x-7x) the simple reproducer of the issue we now have thanks to @sawenzel : ; ```.cpp; // Inspired by Alice production code, extracted from the surrounding context; #include ""TF1.h"". void Foo(int N) {; double am = 90;; double awidth = 1;; for (int i = 0; i < N; ++i) {; static TF1 rbw(""rbw"", ""pow([1],2)*pow([0],2)/(pow(x*x-[0]*[0],2)+pow(x*x*[1]/[0],2))"", -10, 10);; rbw.SetRange(am - 5 * awidth, am + 5 * awidth);; rbw.SetParameter(0, am);; rbw.SetParameter(1, awidth);; am = rbw.GetRandom();; if (am <-100000000) std::cout << am << std::endl; // to avoid compiler optimisations; }; }. int main(); {; Foo(1000);; return 0;; }; ```; The code is faster because the fast code path is taken in the PluginHandler because the right type is used in the GSLIntegratorPlugin (unsigned long, via the size_t typedef), and not just a compatible one (unsigned int).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15816#issuecomment-2161410185
Usability,clear,clear,"> Yes. But this is *wonderful*! This is a fantastic approach imho! Can I just throw in another suggestion then. Since we are introducing these new API methods from scratch and they do not belong already to any of the base classes of `TVirtualPad`, maybe we can take the opportunity to give them some more meaningful name. For example, `Add` could be `RegisterDrawable` or `AdoptDrawable` or just `Register`/`Adopt`. I would be in this sense very much in favour of having `Adopt(std::shared_ptr<TObject> obj)` so that the memory ownership is clear. This would for example enable any use case where the drawable object is not registered with the list of global cleanups. In the same spirit, I don't see (yet) the need for `AddFirst` and `Remove`. What are the user-side reasons for these?; In the current changes:; * `AddFirst` is defined in the class but never used anywhere else, so it should be removed.; * `Remove` is used only for internal purposes and could be made a private method.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15822#issuecomment-2162805726
Safety,safe,safe,> And again let me ask for providing a modern memory safe API with proper memory management in place by default. This need redesign of pad list of primitives. Finally we just need other pad classes. This PR is not change of `TPad` memory management but simple extension of existing API. I had in mind `df027` tutorial which now looks like:. ```; new TCanvas(); // assign gPad - unreliable; ...; histo->Draw(); ```. I want to avoid gPad - for that I need to write now:; ```; auto c1 = new TCanvas();; ...; if (c1->GetListOfPrimitives()) {; c1->GetListOfPrimitives()->Add(histo);; c1->Modified();; }; ```. This is main pattern for 90% of graphical tutorials which I want to be looking:; ```; auto c1 = new TCanvas();; ...; c1->Add(histo);; ```,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15822#issuecomment-2162904388
Usability,simpl,simple,> And again let me ask for providing a modern memory safe API with proper memory management in place by default. This need redesign of pad list of primitives. Finally we just need other pad classes. This PR is not change of `TPad` memory management but simple extension of existing API. I had in mind `df027` tutorial which now looks like:. ```; new TCanvas(); // assign gPad - unreliable; ...; histo->Draw(); ```. I want to avoid gPad - for that I need to write now:; ```; auto c1 = new TCanvas();; ...; if (c1->GetListOfPrimitives()) {; c1->GetListOfPrimitives()->Add(histo);; c1->Modified();; }; ```. This is main pattern for 90% of graphical tutorials which I want to be looking:; ```; auto c1 = new TCanvas();; ...; c1->Add(histo);; ```,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15822#issuecomment-2162904388
Availability,error,error,"This broke the tests:; ```; 729: Processing /home/jhahnfel/ROOT/src/tutorials/graphs/scatter.C...; 729: In file included from input_line_10:1:; 729: /home/jhahnfel/ROOT/src/tutorials/graphs/scatter.C:39:43: error: use of undeclared identifier 'scat'; 729: TPaletteAxis *palette = (TPaletteAxis*)scat->GetGraph()->GetListOfFunctions()->FindObject(""palette"");; 729: ^; ```. Tutorials are executed as part of the CI and therefore should *never* be merged with `[skip-ci]`! The simple fix is in https://github.com/root-project/root/pull/15923.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15871#issuecomment-2188647929
Testability,test,tests,"This broke the tests:; ```; 729: Processing /home/jhahnfel/ROOT/src/tutorials/graphs/scatter.C...; 729: In file included from input_line_10:1:; 729: /home/jhahnfel/ROOT/src/tutorials/graphs/scatter.C:39:43: error: use of undeclared identifier 'scat'; 729: TPaletteAxis *palette = (TPaletteAxis*)scat->GetGraph()->GetListOfFunctions()->FindObject(""palette"");; 729: ^; ```. Tutorials are executed as part of the CI and therefore should *never* be merged with `[skip-ci]`! The simple fix is in https://github.com/root-project/root/pull/15923.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15871#issuecomment-2188647929
Usability,simpl,simple,"This broke the tests:; ```; 729: Processing /home/jhahnfel/ROOT/src/tutorials/graphs/scatter.C...; 729: In file included from input_line_10:1:; 729: /home/jhahnfel/ROOT/src/tutorials/graphs/scatter.C:39:43: error: use of undeclared identifier 'scat'; 729: TPaletteAxis *palette = (TPaletteAxis*)scat->GetGraph()->GetListOfFunctions()->FindObject(""palette"");; 729: ^; ```. Tutorials are executed as part of the CI and therefore should *never* be merged with `[skip-ci]`! The simple fix is in https://github.com/root-project/root/pull/15923.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15871#issuecomment-2188647929
Availability,error,error,"> e.g. LHC experiments, of this change in case something behaves differently in that context. This move is necessary for the Python environments but there is a clear limitation in its current form, that is it breaks the usage of TPython from C++:. ```; root.exe -l -b -q -x -e 'TPython::Exec(""print(\""1 + 1 =\"", 1+1)"")'. cling::DynamicLibraryManager::loadLibrary(): dlopen(/Users/vpadulan/Programs/rootproject/rootbuild/master-4e3ca10195-pyroot-debug/lib/libROOTTPython.so, 0x0009): symbol not found in flat namespace '_PyBool_Type'; Error in <AutoloadLibraryMU>: Failed to load library /Users/vpadulan/Programs/rootproject/rootbuild/master-4e3ca10195-pyroot-debug/lib/libROOTTPython.socling JIT session error: Failed to materialize symbols: { (main, { __ZN7TPython4ExecEPKc }) }; ```. This is not surprising, we are purposely removing the linking against libPython so TPython cannot find the symbols. From within a Python interpreter, libpython is automatically injected and linked at the global scope, but that doesn't happen when a symbol from libpython is needed from an executable outside of Python itself. Bottom line, we will need to investigate how to properly manage both the requirements of Python packaging systems and embedding libpython in other cases.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15891#issuecomment-2180639835
Integrability,inject,injected,"> e.g. LHC experiments, of this change in case something behaves differently in that context. This move is necessary for the Python environments but there is a clear limitation in its current form, that is it breaks the usage of TPython from C++:. ```; root.exe -l -b -q -x -e 'TPython::Exec(""print(\""1 + 1 =\"", 1+1)"")'. cling::DynamicLibraryManager::loadLibrary(): dlopen(/Users/vpadulan/Programs/rootproject/rootbuild/master-4e3ca10195-pyroot-debug/lib/libROOTTPython.so, 0x0009): symbol not found in flat namespace '_PyBool_Type'; Error in <AutoloadLibraryMU>: Failed to load library /Users/vpadulan/Programs/rootproject/rootbuild/master-4e3ca10195-pyroot-debug/lib/libROOTTPython.socling JIT session error: Failed to materialize symbols: { (main, { __ZN7TPython4ExecEPKc }) }; ```. This is not surprising, we are purposely removing the linking against libPython so TPython cannot find the symbols. From within a Python interpreter, libpython is automatically injected and linked at the global scope, but that doesn't happen when a symbol from libpython is needed from an executable outside of Python itself. Bottom line, we will need to investigate how to properly manage both the requirements of Python packaging systems and embedding libpython in other cases.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15891#issuecomment-2180639835
Performance,load,loadLibrary,"> e.g. LHC experiments, of this change in case something behaves differently in that context. This move is necessary for the Python environments but there is a clear limitation in its current form, that is it breaks the usage of TPython from C++:. ```; root.exe -l -b -q -x -e 'TPython::Exec(""print(\""1 + 1 =\"", 1+1)"")'. cling::DynamicLibraryManager::loadLibrary(): dlopen(/Users/vpadulan/Programs/rootproject/rootbuild/master-4e3ca10195-pyroot-debug/lib/libROOTTPython.so, 0x0009): symbol not found in flat namespace '_PyBool_Type'; Error in <AutoloadLibraryMU>: Failed to load library /Users/vpadulan/Programs/rootproject/rootbuild/master-4e3ca10195-pyroot-debug/lib/libROOTTPython.socling JIT session error: Failed to materialize symbols: { (main, { __ZN7TPython4ExecEPKc }) }; ```. This is not surprising, we are purposely removing the linking against libPython so TPython cannot find the symbols. From within a Python interpreter, libpython is automatically injected and linked at the global scope, but that doesn't happen when a symbol from libpython is needed from an executable outside of Python itself. Bottom line, we will need to investigate how to properly manage both the requirements of Python packaging systems and embedding libpython in other cases.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15891#issuecomment-2180639835
Security,inject,injected,"> e.g. LHC experiments, of this change in case something behaves differently in that context. This move is necessary for the Python environments but there is a clear limitation in its current form, that is it breaks the usage of TPython from C++:. ```; root.exe -l -b -q -x -e 'TPython::Exec(""print(\""1 + 1 =\"", 1+1)"")'. cling::DynamicLibraryManager::loadLibrary(): dlopen(/Users/vpadulan/Programs/rootproject/rootbuild/master-4e3ca10195-pyroot-debug/lib/libROOTTPython.so, 0x0009): symbol not found in flat namespace '_PyBool_Type'; Error in <AutoloadLibraryMU>: Failed to load library /Users/vpadulan/Programs/rootproject/rootbuild/master-4e3ca10195-pyroot-debug/lib/libROOTTPython.socling JIT session error: Failed to materialize symbols: { (main, { __ZN7TPython4ExecEPKc }) }; ```. This is not surprising, we are purposely removing the linking against libPython so TPython cannot find the symbols. From within a Python interpreter, libpython is automatically injected and linked at the global scope, but that doesn't happen when a symbol from libpython is needed from an executable outside of Python itself. Bottom line, we will need to investigate how to properly manage both the requirements of Python packaging systems and embedding libpython in other cases.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15891#issuecomment-2180639835
Usability,clear,clear,"> e.g. LHC experiments, of this change in case something behaves differently in that context. This move is necessary for the Python environments but there is a clear limitation in its current form, that is it breaks the usage of TPython from C++:. ```; root.exe -l -b -q -x -e 'TPython::Exec(""print(\""1 + 1 =\"", 1+1)"")'. cling::DynamicLibraryManager::loadLibrary(): dlopen(/Users/vpadulan/Programs/rootproject/rootbuild/master-4e3ca10195-pyroot-debug/lib/libROOTTPython.so, 0x0009): symbol not found in flat namespace '_PyBool_Type'; Error in <AutoloadLibraryMU>: Failed to load library /Users/vpadulan/Programs/rootproject/rootbuild/master-4e3ca10195-pyroot-debug/lib/libROOTTPython.socling JIT session error: Failed to materialize symbols: { (main, { __ZN7TPython4ExecEPKc }) }; ```. This is not surprising, we are purposely removing the linking against libPython so TPython cannot find the symbols. From within a Python interpreter, libpython is automatically injected and linked at the global scope, but that doesn't happen when a symbol from libpython is needed from an executable outside of Python itself. Bottom line, we will need to investigate how to properly manage both the requirements of Python packaging systems and embedding libpython in other cases.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15891#issuecomment-2180639835
Usability,simpl,simple,"When I naively set `SetLowBottomMargin(gStyle->GetPadBottomMargin())` and `SetUpTopMargin(gStyle->GetPadTopMargin())` they end up being different than for a simple histogram, i.e. axis labels that should fit disappear. The below example also has `SetSeparationMargin(0)` but that does not change the outer margins. ![image](https://github.com/root-project/root/assets/12029880/e0917420-0de3-4723-8ab8-531a4c6ee48f). That is jsroot plot though, on the ""normal"" one the font size for the ratio plot is bigger and even more disappears at the bottom. :(. ![image](https://github.com/root-project/root/assets/12029880/47b9ecd1-b1d5-415a-be88-d99a03a97624). The left/right margins where easy to change and the most annoying ones visually imo, so that is what I did.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15893#issuecomment-2180723430
Security,certificate,certificate,@bellenot : The new executables are signed. ; ![image](https://github.com/root-project/root/assets/73365079/89bf755e-dfd3-4bcd-a70f-e58d6d23b5d4); But they still present an issue. The certificate used to sign was not issued by a trusted root authority. ; ![image](https://github.com/root-project/root/assets/73365079/e101fbfa-4bad-473d-b197-e274431d1147); Code signing certificates must be provided by a Windows approved certificate authority. [They have them listed here](https://learn.microsoft.com/en-us/windows-hardware/drivers/dashboard/code-signing-cert-manage#get-or-renew-a-code-signing-certificate).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/15896#issuecomment-2213690136
Usability,learn,learn,@bellenot : The new executables are signed. ; ![image](https://github.com/root-project/root/assets/73365079/89bf755e-dfd3-4bcd-a70f-e58d6d23b5d4); But they still present an issue. The certificate used to sign was not issued by a trusted root authority. ; ![image](https://github.com/root-project/root/assets/73365079/e101fbfa-4bad-473d-b197-e274431d1147); Code signing certificates must be provided by a Windows approved certificate authority. [They have them listed here](https://learn.microsoft.com/en-us/windows-hardware/drivers/dashboard/code-signing-cert-manage#get-or-renew-a-code-signing-certificate).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/15896#issuecomment-2213690136
Security,certificate,certificate,"OK, thanks for the feedback. The certificate used to sign the binaries is the official CERN one. I'll check with IT but I doubt they will purchase any Windows approved certificate... Isn't the CERN certificate good enough for you?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/15896#issuecomment-2213801755
Usability,feedback,feedback,"OK, thanks for the feedback. The certificate used to sign the binaries is the official CERN one. I'll check with IT but I doubt they will purchase any Windows approved certificate... Isn't the CERN certificate good enough for you?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/15896#issuecomment-2213801755
Testability,test,test,comparing contains was more complex. I went to the simplest way for this simple test,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15897#issuecomment-2182075929
Usability,simpl,simplest,comparing contains was more complex. I went to the simplest way for this simple test,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15897#issuecomment-2182075929
Availability,fault,fault,Yes. Issue is clarified. - I can see the classlist on the browser at home and in the office.; - I cannot see it at the pit .... but this all hints to a funny browser setup there. I have to investigate. Thanks a lot to all for the clarification and please take my apologies for ; creating noise about an issue which was clearly my fault!. Thanks a lot!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/15906#issuecomment-2185817262
Usability,clear,clearly,Yes. Issue is clarified. - I can see the classlist on the browser at home and in the office.; - I cannot see it at the pit .... but this all hints to a funny browser setup there. I have to investigate. Thanks a lot to all for the clarification and please take my apologies for ; creating noise about an issue which was clearly my fault!. Thanks a lot!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/15906#issuecomment-2185817262
Availability,fault,fault,"> But how do you solve the modules.idx creation, can you link to a patch?. The build is actually cross-compiling as requested in the `conda-forge.yml` file (e.g. [here](https://github.com/conda-forge/root-feedstock/blob/1987df5fb087fb149f114dab14f6dd5f99e3156d/conda-forge.yml#L4)). Then the conda forge CI is able to automatically detect that an executable e.g. `rootcling_stage1` that is being invoked during the build was built for a different target platform than the build one. In such cases, it runs that executable via `qemu` (which in turn is enabled by `binfmt_misc`). There's some hint of it in the CI files such as https://github.com/conda-forge/root-feedstock/blob/1987df5fb087fb149f114dab14f6dd5f99e3156d/.azure-pipelines/azure-pipelines-linux.yml#L90-L96 (these are generated automatically by conda-forge). This does not explain alone the fact that there is also a patch to disable `hsimple.root` generation in the conda forge ROOT feedstock. At some point in the past that was generating some other problem at build time (unclear whether that was only fault of ROOT or also a bug in qemu itself, see [this bug report](https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=999421)), so that patch was added. IMHO clearly the better approach is to have less patches and walk towards a fully cross-compilable ROOT build, albeit this PR might be just a very small step.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15930#issuecomment-2205465973
Deployability,patch,patch,"> But how do you solve the modules.idx creation, can you link to a patch?. The build is actually cross-compiling as requested in the `conda-forge.yml` file (e.g. [here](https://github.com/conda-forge/root-feedstock/blob/1987df5fb087fb149f114dab14f6dd5f99e3156d/conda-forge.yml#L4)). Then the conda forge CI is able to automatically detect that an executable e.g. `rootcling_stage1` that is being invoked during the build was built for a different target platform than the build one. In such cases, it runs that executable via `qemu` (which in turn is enabled by `binfmt_misc`). There's some hint of it in the CI files such as https://github.com/conda-forge/root-feedstock/blob/1987df5fb087fb149f114dab14f6dd5f99e3156d/.azure-pipelines/azure-pipelines-linux.yml#L90-L96 (these are generated automatically by conda-forge). This does not explain alone the fact that there is also a patch to disable `hsimple.root` generation in the conda forge ROOT feedstock. At some point in the past that was generating some other problem at build time (unclear whether that was only fault of ROOT or also a bug in qemu itself, see [this bug report](https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=999421)), so that patch was added. IMHO clearly the better approach is to have less patches and walk towards a fully cross-compilable ROOT build, albeit this PR might be just a very small step.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15930#issuecomment-2205465973
Safety,detect,detect,"> But how do you solve the modules.idx creation, can you link to a patch?. The build is actually cross-compiling as requested in the `conda-forge.yml` file (e.g. [here](https://github.com/conda-forge/root-feedstock/blob/1987df5fb087fb149f114dab14f6dd5f99e3156d/conda-forge.yml#L4)). Then the conda forge CI is able to automatically detect that an executable e.g. `rootcling_stage1` that is being invoked during the build was built for a different target platform than the build one. In such cases, it runs that executable via `qemu` (which in turn is enabled by `binfmt_misc`). There's some hint of it in the CI files such as https://github.com/conda-forge/root-feedstock/blob/1987df5fb087fb149f114dab14f6dd5f99e3156d/.azure-pipelines/azure-pipelines-linux.yml#L90-L96 (these are generated automatically by conda-forge). This does not explain alone the fact that there is also a patch to disable `hsimple.root` generation in the conda forge ROOT feedstock. At some point in the past that was generating some other problem at build time (unclear whether that was only fault of ROOT or also a bug in qemu itself, see [this bug report](https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=999421)), so that patch was added. IMHO clearly the better approach is to have less patches and walk towards a fully cross-compilable ROOT build, albeit this PR might be just a very small step.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15930#issuecomment-2205465973
Usability,clear,clearly,"> But how do you solve the modules.idx creation, can you link to a patch?. The build is actually cross-compiling as requested in the `conda-forge.yml` file (e.g. [here](https://github.com/conda-forge/root-feedstock/blob/1987df5fb087fb149f114dab14f6dd5f99e3156d/conda-forge.yml#L4)). Then the conda forge CI is able to automatically detect that an executable e.g. `rootcling_stage1` that is being invoked during the build was built for a different target platform than the build one. In such cases, it runs that executable via `qemu` (which in turn is enabled by `binfmt_misc`). There's some hint of it in the CI files such as https://github.com/conda-forge/root-feedstock/blob/1987df5fb087fb149f114dab14f6dd5f99e3156d/.azure-pipelines/azure-pipelines-linux.yml#L90-L96 (these are generated automatically by conda-forge). This does not explain alone the fact that there is also a patch to disable `hsimple.root` generation in the conda forge ROOT feedstock. At some point in the past that was generating some other problem at build time (unclear whether that was only fault of ROOT or also a bug in qemu itself, see [this bug report](https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=999421)), so that patch was added. IMHO clearly the better approach is to have less patches and walk towards a fully cross-compilable ROOT build, albeit this PR might be just a very small step.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15930#issuecomment-2205465973
Deployability,patch,patches,"> IMHO clearly the better approach is to have less patches. Sure, so can we just remove the patch from the conda forge and see what happens? It's still not clear to me why it is needed. > walk towards a fully cross-compilable ROOT build, albeit this PR might be just a very small step. I agree, but I don't see the bigger picture here: how do you want to achieve this with all of `rootcling` for dictionary and module generation? Personally I don't see a value of starting at the easy leaves with no clear plan how to actually tackle the hard parts.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15930#issuecomment-2205481182
Usability,clear,clearly,"> IMHO clearly the better approach is to have less patches. Sure, so can we just remove the patch from the conda forge and see what happens? It's still not clear to me why it is needed. > walk towards a fully cross-compilable ROOT build, albeit this PR might be just a very small step. I agree, but I don't see the bigger picture here: how do you want to achieve this with all of `rootcling` for dictionary and module generation? Personally I don't see a value of starting at the easy leaves with no clear plan how to actually tackle the hard parts.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15930#issuecomment-2205481182
Availability,robust,robust,I agree we should wait for a more robust solution for cross-compilation of the whole project before removing this simple test. I will close this PR and if in the future we decide what to do we can resume from here ,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15930#issuecomment-2228672121
Testability,test,test,I agree we should wait for a more robust solution for cross-compilation of the whole project before removing this simple test. I will close this PR and if in the future we decide what to do we can resume from here ,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15930#issuecomment-2228672121
Usability,simpl,simple,I agree we should wait for a more robust solution for cross-compilation of the whole project before removing this simple test. I will close this PR and if in the future we decide what to do we can resume from here ,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15930#issuecomment-2228672121
Performance,optimiz,optimization,"> In `AddColumnsFromField` and `CollectColumns` we now produce both, the vector of `RColumnInfo` records and the `RCluster::ColumnSet_t`. To me it seems that the source of truth is the `RColumnInfo` vector, and it may be clearer to generate and `RCluster::ColumnSet_t` from the `RColumnInfo` vector. It was a small optimization to avoid looping over all columns twice and get all the data we need at once. I can separate the loops if you prefer, it should make little difference.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15954#issuecomment-2210678615
Safety,avoid,avoid,"> In `AddColumnsFromField` and `CollectColumns` we now produce both, the vector of `RColumnInfo` records and the `RCluster::ColumnSet_t`. To me it seems that the source of truth is the `RColumnInfo` vector, and it may be clearer to generate and `RCluster::ColumnSet_t` from the `RColumnInfo` vector. It was a small optimization to avoid looping over all columns twice and get all the data we need at once. I can separate the loops if you prefer, it should make little difference.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15954#issuecomment-2210678615
Usability,clear,clearer,"> In `AddColumnsFromField` and `CollectColumns` we now produce both, the vector of `RColumnInfo` records and the `RCluster::ColumnSet_t`. To me it seems that the source of truth is the `RColumnInfo` vector, and it may be clearer to generate and `RCluster::ColumnSet_t` from the `RColumnInfo` vector. It was a small optimization to avoid looping over all columns twice and get all the data we need at once. I can separate the loops if you prefer, it should make little difference.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15954#issuecomment-2210678615
Usability,clear,clear,"Closing, because at this point it's not clear to me whether the functionality should be in TPython or in CPyCppyy.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16019#issuecomment-2388756085
Usability,clear,clear,"Hm, I think it's not quite clear that we want to return a pair of ID and `RColumnRange`, especially given that the column range already contains the ID. Can we have only the `RColumnRange` as a value type?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16022#issuecomment-2227805634
Availability,error,error,"I only did two minor changes to the existing commits, as discussed yesterday evening:; ```diff; diff --git a/tree/ntuple/v7/inc/ROOT/RField.hxx b/tree/ntuple/v7/inc/ROOT/RField.hxx; index 7c9ccebeaa..411ef5733c 100644; --- a/tree/ntuple/v7/inc/ROOT/RField.hxx; +++ b/tree/ntuple/v7/inc/ROOT/RField.hxx; @@ -2179,9 +2179,8 @@ public:; ; template <typename T>; class RIntegralField {; - // Cannot say static_assert(false) because not all compilers implement CWG2518 yet...; - static_assert(std::is_integral_v<T>, ""RIntegralField requires integral type"");; - static_assert(!std::is_integral_v<T>, ""unsupported integral type"");; + // Instantiating this base template definition should never happen and is an error!; + RIntegralField() = delete;; };; ; template <>; @@ -2573,6 +2572,8 @@ template <typename T>; class RField<T, typename std::enable_if<std::is_integral_v<T>>::type> final; : public RIntegralField<typename Internal::RIntegralTypeMap<T>::type> {; using MappedType = typename Internal::RIntegralTypeMap<T>::type;; + static_assert(sizeof(T) == sizeof(MappedType), ""invalid size of mapped type"");; + static_assert(std::is_signed_v<T> == std::is_signed_v<MappedType>, ""invalid signedness of mapped type"");; ; public:; RField(std::string_view name) : RIntegralField<MappedType>(name) {}; ```. Eventually, after implementing the changes, I decided to hold off moving some member functions to the templated `RField` specialization: It didn't work for the `Map[V]` functions because `RColumn::Map[V]` has to be called with the fixed width integer type after mapping. Instead the newly added last commit `reinterpret_cast`s the pointer since we can guarantee that the mapped type has identical storage layout. This solves the problem with `RNTupleView`s, discussed on Mattermost. I still plan to come back to possible deduplications and simplifications in a follow-up PR (now https://github.com/root-project/root/pull/16101).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16039#issuecomment-2247304935
Usability,simpl,simplifications,"I only did two minor changes to the existing commits, as discussed yesterday evening:; ```diff; diff --git a/tree/ntuple/v7/inc/ROOT/RField.hxx b/tree/ntuple/v7/inc/ROOT/RField.hxx; index 7c9ccebeaa..411ef5733c 100644; --- a/tree/ntuple/v7/inc/ROOT/RField.hxx; +++ b/tree/ntuple/v7/inc/ROOT/RField.hxx; @@ -2179,9 +2179,8 @@ public:; ; template <typename T>; class RIntegralField {; - // Cannot say static_assert(false) because not all compilers implement CWG2518 yet...; - static_assert(std::is_integral_v<T>, ""RIntegralField requires integral type"");; - static_assert(!std::is_integral_v<T>, ""unsupported integral type"");; + // Instantiating this base template definition should never happen and is an error!; + RIntegralField() = delete;; };; ; template <>; @@ -2573,6 +2572,8 @@ template <typename T>; class RField<T, typename std::enable_if<std::is_integral_v<T>>::type> final; : public RIntegralField<typename Internal::RIntegralTypeMap<T>::type> {; using MappedType = typename Internal::RIntegralTypeMap<T>::type;; + static_assert(sizeof(T) == sizeof(MappedType), ""invalid size of mapped type"");; + static_assert(std::is_signed_v<T> == std::is_signed_v<MappedType>, ""invalid signedness of mapped type"");; ; public:; RField(std::string_view name) : RIntegralField<MappedType>(name) {}; ```. Eventually, after implementing the changes, I decided to hold off moving some member functions to the templated `RField` specialization: It didn't work for the `Map[V]` functions because `RColumn::Map[V]` has to be called with the fixed width integer type after mapping. Instead the newly added last commit `reinterpret_cast`s the pointer since we can guarantee that the mapped type has identical storage layout. This solves the problem with `RNTupleView`s, discussed on Mattermost. I still plan to come back to possible deduplications and simplifications in a follow-up PR (now https://github.com/root-project/root/pull/16101).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16039#issuecomment-2247304935
Performance,load,loaded,"Many thanks Danilo and Olivier for picking this up so quickly! The issue appears only when `TColorBug.root` is loaded in a new ROOT session. Sorry for not being clear about this in my original post. If I first run `createTestFile();` from Olivier's macro to create the .root file and then close ROOT and start a new ROOT session that only runs `readTestFile();`, `TColor::GetFreeColorIndex();`returns the index of the already defined `myColor`. So the problem seems to be related to how custom colors that are not yet existing in the ROOT session are restored from a .root file.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16051#issuecomment-2256214014
Usability,clear,clear,"Many thanks Danilo and Olivier for picking this up so quickly! The issue appears only when `TColorBug.root` is loaded in a new ROOT session. Sorry for not being clear about this in my original post. If I first run `createTestFile();` from Olivier's macro to create the .root file and then close ROOT and start a new ROOT session that only runs `readTestFile();`, `TColor::GetFreeColorIndex();`returns the index of the already defined `myColor`. So the problem seems to be related to how custom colors that are not yet existing in the ROOT session are restored from a .root file.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16051#issuecomment-2256214014
Integrability,interface,interfaces,"> It is at the same level of usage and encouragement as TTree. . I sincerely hope not. TEntryList is definitely not usable in production contexts as it only scales well for a few entries for its purpose. For RDataFrame we had to move away from it exactly for this reason. . > And if I remember correctly we do not have yet a RNTuple replacement/equivalent). Indeed, and I hope we are not going to develop the same feature. IMHO, for the purpose of `TEntryList`, we have already `TTreeReader::SetEntryRange` and we should have similar interfaces (private/internal) for modern I/O systems.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16074#issuecomment-2242293382
Usability,usab,usable,"> It is at the same level of usage and encouragement as TTree. . I sincerely hope not. TEntryList is definitely not usable in production contexts as it only scales well for a few entries for its purpose. For RDataFrame we had to move away from it exactly for this reason. . > And if I remember correctly we do not have yet a RNTuple replacement/equivalent). Indeed, and I hope we are not going to develop the same feature. IMHO, for the purpose of `TEntryList`, we have already `TTreeReader::SetEntryRange` and we should have similar interfaces (private/internal) for modern I/O systems.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16074#issuecomment-2242293382
Usability,usab,usable,"> IMHO, for the purpose of TEntryList, we have already TTreeReader::SetEntryRange. `SetEntryRange` is small subset of the feature/use of `TEntryList`. The main intent of the `TEntryList` is to store the result of a selection (so a more or sparse list entry numbers) so that further analysis step can read only the already select entries. > TEntryList is definitely not usable in production contexts as it only scales well for a few entries for its purpose. I am not sure I understand 'why'. For `TTree::Draw`, this is not the case as far as I remember. Does `TEventList` scale better for the case you are talking about? (if that is the case we would need to NOT deprecated either of them). Side note: the main intent of `TEntryList` over `TEventList` is that `TEntryList` is supposed to scale better with chain with large number of files. > Indeed, and I hope we are not going to develop the same feature. Humm ... it does not have to be implemented in `RNTuple` and could be implemented in `RDataFrame`; but why don't we want to have the ability to 'store' the result of computational heavy selection to speed-up further analysis by reducing the number of entries needed to be used?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16074#issuecomment-2245984573
Deployability,update,updated,Good catch! indeed the real one is DistancetoPtrimitve (small t). The ones with capital T in the index file are typos I guess. In particular in the old User guide. I guess we can leave it as this guide is obsolete now and not updated anymore. ; But we can also fix them for clarity. Those with capital T in the TGeo code are more suspect I guess @agheata should have a look.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16087#issuecomment-2244578228
Usability,guid,guide,Good catch! indeed the real one is DistancetoPtrimitve (small t). The ones with capital T in the index file are typos I guess. In particular in the old User guide. I guess we can leave it as this guide is obsolete now and not updated anymore. ; But we can also fix them for clarity. Those with capital T in the TGeo code are more suspect I guess @agheata should have a look.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16087#issuecomment-2244578228
Usability,simpl,simplifying,"Good idea! I would even suggest further simplifying it, using this header-only parser: https://github.com/CLIUtils/CLI11",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16090#issuecomment-2244826382
Testability,log,logic,"@ferdymercury is that library already used in ROOT? Considering it's 10k loc, I'd not count it as ""simplifying"" unless we decided to use it in multiple places (ideally all our cpp executables).; Also, we must make sure that the argument parsing logic remains backward-compatible, which is not very clear to me if it would be the case with that lib.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16090#issuecomment-2244858400
Usability,simpl,simplifying,"@ferdymercury is that library already used in ROOT? Considering it's 10k loc, I'd not count it as ""simplifying"" unless we decided to use it in multiple places (ideally all our cpp executables).; Also, we must make sure that the argument parsing logic remains backward-compatible, which is not very clear to me if it would be the case with that lib.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16090#issuecomment-2244858400
Availability,mainten,maintenance,"> @ferdymercury is that library already used in ROOT?. I don't think it's used yet in ROOT, but @henryiii could confirm. . > Considering it's 10k loc, I'd not count it as ""simplifying"" unless we decided to use it in multiple places (ideally all our cpp executables). True. My experience is that there are many places doing CLI parsing over and over again within ROOT, so if we would replace everywhere, then we would remove more than 10k from ROOT's codebase, and reduce maintenance / bugs on ROOT's side, so it would be worth it. Or at least for new interfaces, see e.g. https://github.com/root-project/root/pull/14038. > Also, we must make sure that the argument parsing logic remains backward-compatible, which is not very clear to me if it would be the case with that lib. That lib has many customization options, so a derived parser class could probably do it, but yeah, it's hard to say for sure in advance.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16090#issuecomment-2244874004
Energy Efficiency,reduce,reduce,"> @ferdymercury is that library already used in ROOT?. I don't think it's used yet in ROOT, but @henryiii could confirm. . > Considering it's 10k loc, I'd not count it as ""simplifying"" unless we decided to use it in multiple places (ideally all our cpp executables). True. My experience is that there are many places doing CLI parsing over and over again within ROOT, so if we would replace everywhere, then we would remove more than 10k from ROOT's codebase, and reduce maintenance / bugs on ROOT's side, so it would be worth it. Or at least for new interfaces, see e.g. https://github.com/root-project/root/pull/14038. > Also, we must make sure that the argument parsing logic remains backward-compatible, which is not very clear to me if it would be the case with that lib. That lib has many customization options, so a derived parser class could probably do it, but yeah, it's hard to say for sure in advance.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16090#issuecomment-2244874004
Integrability,interface,interfaces,"> @ferdymercury is that library already used in ROOT?. I don't think it's used yet in ROOT, but @henryiii could confirm. . > Considering it's 10k loc, I'd not count it as ""simplifying"" unless we decided to use it in multiple places (ideally all our cpp executables). True. My experience is that there are many places doing CLI parsing over and over again within ROOT, so if we would replace everywhere, then we would remove more than 10k from ROOT's codebase, and reduce maintenance / bugs on ROOT's side, so it would be worth it. Or at least for new interfaces, see e.g. https://github.com/root-project/root/pull/14038. > Also, we must make sure that the argument parsing logic remains backward-compatible, which is not very clear to me if it would be the case with that lib. That lib has many customization options, so a derived parser class could probably do it, but yeah, it's hard to say for sure in advance.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16090#issuecomment-2244874004
Testability,log,logic,"> @ferdymercury is that library already used in ROOT?. I don't think it's used yet in ROOT, but @henryiii could confirm. . > Considering it's 10k loc, I'd not count it as ""simplifying"" unless we decided to use it in multiple places (ideally all our cpp executables). True. My experience is that there are many places doing CLI parsing over and over again within ROOT, so if we would replace everywhere, then we would remove more than 10k from ROOT's codebase, and reduce maintenance / bugs on ROOT's side, so it would be worth it. Or at least for new interfaces, see e.g. https://github.com/root-project/root/pull/14038. > Also, we must make sure that the argument parsing logic remains backward-compatible, which is not very clear to me if it would be the case with that lib. That lib has many customization options, so a derived parser class could probably do it, but yeah, it's hard to say for sure in advance.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16090#issuecomment-2244874004
Usability,simpl,simplifying,"> @ferdymercury is that library already used in ROOT?. I don't think it's used yet in ROOT, but @henryiii could confirm. . > Considering it's 10k loc, I'd not count it as ""simplifying"" unless we decided to use it in multiple places (ideally all our cpp executables). True. My experience is that there are many places doing CLI parsing over and over again within ROOT, so if we would replace everywhere, then we would remove more than 10k from ROOT's codebase, and reduce maintenance / bugs on ROOT's side, so it would be worth it. Or at least for new interfaces, see e.g. https://github.com/root-project/root/pull/14038. > Also, we must make sure that the argument parsing logic remains backward-compatible, which is not very clear to me if it would be the case with that lib. That lib has many customization options, so a derived parser class could probably do it, but yeah, it's hard to say for sure in advance.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16090#issuecomment-2244874004
Testability,test,tested,"@ferdymercury thanks for the links. I fully agree with Axel's proposal of trying to make all ROOT binaries consistent in their argument parsing and make them POSIX (while keeping the legacy `-long` options valid but hidden). Having never used it, I don't have a strong opinion on the CLI11 library yet. On one hand it seems well maintained and tested on all platforms, which is great, and being header-only certainly makes it convenient to use. On the other hand it's quite big and I wonder if we need enough features from it as to justify its size. . In any case I think we should revive the topic and understand if there were any blockers to it or if it was simply not picked up by anyone in the past 3 years.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16090#issuecomment-2245114452
Usability,simpl,simply,"@ferdymercury thanks for the links. I fully agree with Axel's proposal of trying to make all ROOT binaries consistent in their argument parsing and make them POSIX (while keeping the legacy `-long` options valid but hidden). Having never used it, I don't have a strong opinion on the CLI11 library yet. On one hand it seems well maintained and tested on all platforms, which is great, and being header-only certainly makes it convenient to use. On the other hand it's quite big and I wonder if we need enough features from it as to justify its size. . In any case I think we should revive the topic and understand if there were any blockers to it or if it was simply not picked up by anyone in the past 3 years.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16090#issuecomment-2245114452
Deployability,update,updated,"I have updated the contents of the CERNBox link from the PR description with more memray graphs, it looks clear that the effect of this PR is to properly remove the artifacts generated during the distributed execution, there is no more TTreeCache leaking leftover after the analysis (see any file ending with `_patch` and compare it with the same file ending with `_master`). Now that the main source of memory usage is gone, I have noticed a much smaller contribute that still seems to make the memory increase in the flamegraphs. And it seems to have something to do with the increased number of files, at least on the surface. Let's take the following two files to compare:; * test_agc_9sample_1file_10task_patch.html; * test_agc_9sample_10file_10task_patch.html. They are running exactly the same script, with all 9 RDF samples. In the first case we have 1 file per sample, in the second case 10 files per sample. The memray flamegraph report a total of 253.5 MB used for the first case and 260.9 MB used for the first case (7.4 MB delta). There are two main parts of the graph: the one deriving from the `clone` of the Dask process, where the actual analysis code is run, and the one deriving from the `_start` function where most of the Python code around the analysis is (things like `import`ing packages or the Dask worker-scheduler communication). The difference between the two graphs in the `clone` part is of 0.6 MB, the difference between the two `_start` parts is 6.7 MB, so I focus on that from now on. This 6.7 MB difference is in turn split between a 0.1 MB difference deriving from `_PyObject_VectorcallTState` and 6.6 MB difference deriving from. Finally, the vast majority of these 6.6 MB comes from:; * The metrics gathered by profiling (i.e. memray itself); * Dask communication protocol. [Screencast from 2024-07-26 10-47-18.webm](https://github.com/user-attachments/assets/3a21ea3e-c130-42af-b50b-bb324b06eaaa). TL;DR: After this patch the leftover memory increase may be attri",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16094#issuecomment-2252273470
Energy Efficiency,schedul,scheduler,"tributed execution, there is no more TTreeCache leaking leftover after the analysis (see any file ending with `_patch` and compare it with the same file ending with `_master`). Now that the main source of memory usage is gone, I have noticed a much smaller contribute that still seems to make the memory increase in the flamegraphs. And it seems to have something to do with the increased number of files, at least on the surface. Let's take the following two files to compare:; * test_agc_9sample_1file_10task_patch.html; * test_agc_9sample_10file_10task_patch.html. They are running exactly the same script, with all 9 RDF samples. In the first case we have 1 file per sample, in the second case 10 files per sample. The memray flamegraph report a total of 253.5 MB used for the first case and 260.9 MB used for the first case (7.4 MB delta). There are two main parts of the graph: the one deriving from the `clone` of the Dask process, where the actual analysis code is run, and the one deriving from the `_start` function where most of the Python code around the analysis is (things like `import`ing packages or the Dask worker-scheduler communication). The difference between the two graphs in the `clone` part is of 0.6 MB, the difference between the two `_start` parts is 6.7 MB, so I focus on that from now on. This 6.7 MB difference is in turn split between a 0.1 MB difference deriving from `_PyObject_VectorcallTState` and 6.6 MB difference deriving from. Finally, the vast majority of these 6.6 MB comes from:; * The metrics gathered by profiling (i.e. memray itself); * Dask communication protocol. [Screencast from 2024-07-26 10-47-18.webm](https://github.com/user-attachments/assets/3a21ea3e-c130-42af-b50b-bb324b06eaaa). TL;DR: After this patch the leftover memory increase may be attributed mostly to Dask or memray itself. To confirm this, I have executed the full AGC benchmark on the SWAN platform with 64 workers of the CERN condor pools for 10 times in a row. At the end of the 1",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16094#issuecomment-2252273470
Integrability,protocol,protocol,"king leftover after the analysis (see any file ending with `_patch` and compare it with the same file ending with `_master`). Now that the main source of memory usage is gone, I have noticed a much smaller contribute that still seems to make the memory increase in the flamegraphs. And it seems to have something to do with the increased number of files, at least on the surface. Let's take the following two files to compare:; * test_agc_9sample_1file_10task_patch.html; * test_agc_9sample_10file_10task_patch.html. They are running exactly the same script, with all 9 RDF samples. In the first case we have 1 file per sample, in the second case 10 files per sample. The memray flamegraph report a total of 253.5 MB used for the first case and 260.9 MB used for the first case (7.4 MB delta). There are two main parts of the graph: the one deriving from the `clone` of the Dask process, where the actual analysis code is run, and the one deriving from the `_start` function where most of the Python code around the analysis is (things like `import`ing packages or the Dask worker-scheduler communication). The difference between the two graphs in the `clone` part is of 0.6 MB, the difference between the two `_start` parts is 6.7 MB, so I focus on that from now on. This 6.7 MB difference is in turn split between a 0.1 MB difference deriving from `_PyObject_VectorcallTState` and 6.6 MB difference deriving from. Finally, the vast majority of these 6.6 MB comes from:; * The metrics gathered by profiling (i.e. memray itself); * Dask communication protocol. [Screencast from 2024-07-26 10-47-18.webm](https://github.com/user-attachments/assets/3a21ea3e-c130-42af-b50b-bb324b06eaaa). TL;DR: After this patch the leftover memory increase may be attributed mostly to Dask or memray itself. To confirm this, I have executed the full AGC benchmark on the SWAN platform with 64 workers of the CERN condor pools for 10 times in a row. At the end of the 10th run all the workers have a total RSS of < 1GB.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16094#issuecomment-2252273470
Testability,benchmark,benchmark,"king leftover after the analysis (see any file ending with `_patch` and compare it with the same file ending with `_master`). Now that the main source of memory usage is gone, I have noticed a much smaller contribute that still seems to make the memory increase in the flamegraphs. And it seems to have something to do with the increased number of files, at least on the surface. Let's take the following two files to compare:; * test_agc_9sample_1file_10task_patch.html; * test_agc_9sample_10file_10task_patch.html. They are running exactly the same script, with all 9 RDF samples. In the first case we have 1 file per sample, in the second case 10 files per sample. The memray flamegraph report a total of 253.5 MB used for the first case and 260.9 MB used for the first case (7.4 MB delta). There are two main parts of the graph: the one deriving from the `clone` of the Dask process, where the actual analysis code is run, and the one deriving from the `_start` function where most of the Python code around the analysis is (things like `import`ing packages or the Dask worker-scheduler communication). The difference between the two graphs in the `clone` part is of 0.6 MB, the difference between the two `_start` parts is 6.7 MB, so I focus on that from now on. This 6.7 MB difference is in turn split between a 0.1 MB difference deriving from `_PyObject_VectorcallTState` and 6.6 MB difference deriving from. Finally, the vast majority of these 6.6 MB comes from:; * The metrics gathered by profiling (i.e. memray itself); * Dask communication protocol. [Screencast from 2024-07-26 10-47-18.webm](https://github.com/user-attachments/assets/3a21ea3e-c130-42af-b50b-bb324b06eaaa). TL;DR: After this patch the leftover memory increase may be attributed mostly to Dask or memray itself. To confirm this, I have executed the full AGC benchmark on the SWAN platform with 64 workers of the CERN condor pools for 10 times in a row. At the end of the 10th run all the workers have a total RSS of < 1GB.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16094#issuecomment-2252273470
Usability,clear,clear,"I have updated the contents of the CERNBox link from the PR description with more memray graphs, it looks clear that the effect of this PR is to properly remove the artifacts generated during the distributed execution, there is no more TTreeCache leaking leftover after the analysis (see any file ending with `_patch` and compare it with the same file ending with `_master`). Now that the main source of memory usage is gone, I have noticed a much smaller contribute that still seems to make the memory increase in the flamegraphs. And it seems to have something to do with the increased number of files, at least on the surface. Let's take the following two files to compare:; * test_agc_9sample_1file_10task_patch.html; * test_agc_9sample_10file_10task_patch.html. They are running exactly the same script, with all 9 RDF samples. In the first case we have 1 file per sample, in the second case 10 files per sample. The memray flamegraph report a total of 253.5 MB used for the first case and 260.9 MB used for the first case (7.4 MB delta). There are two main parts of the graph: the one deriving from the `clone` of the Dask process, where the actual analysis code is run, and the one deriving from the `_start` function where most of the Python code around the analysis is (things like `import`ing packages or the Dask worker-scheduler communication). The difference between the two graphs in the `clone` part is of 0.6 MB, the difference between the two `_start` parts is 6.7 MB, so I focus on that from now on. This 6.7 MB difference is in turn split between a 0.1 MB difference deriving from `_PyObject_VectorcallTState` and 6.6 MB difference deriving from. Finally, the vast majority of these 6.6 MB comes from:; * The metrics gathered by profiling (i.e. memray itself); * Dask communication protocol. [Screencast from 2024-07-26 10-47-18.webm](https://github.com/user-attachments/assets/3a21ea3e-c130-42af-b50b-bb324b06eaaa). TL;DR: After this patch the leftover memory increase may be attri",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16094#issuecomment-2252273470
Energy Efficiency,battery,battery,"@linev I'm trying rebuilding from scratch now. I'm afraid I don't have enough battery, so I can't give feedback until some time after my current meeting.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16129#issuecomment-2255350691
Usability,feedback,feedback,"@linev I'm trying rebuilding from scratch now. I'm afraid I don't have enough battery, so I can't give feedback until some time after my current meeting.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16129#issuecomment-2255350691
Usability,simpl,simplest,"Maybe we anyway should enable reading into `signed char` from a `kChar` column, if only for automatic schema evolution. Users should be able to change a member from `char` to `signed char`, and it may be the simplest to enable this through the column representations rather than a field translation.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16136#issuecomment-2257823786
Usability,feedback,feedback,Trying to revive this PR: did we get feedback from ATLAS? @guitargeek,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16175#issuecomment-2309556326
Modifiability,enhance,enhanced,"> So you mean extern template the new ExecImp?. Yes, this what I meant. > because you still have to instantiate the ""front-facing"" template . it is a trivial function, that we could even mark as 'force inline' to make it disappear. > Maybe, but I doubt that it actually achieves the goal of reducing compile time .... and neither [of the functions] seems particularly expensive to generate. . I started from the assumption that the existing code was there for a reason. Indeed if the functions are also simple/trivial, the extern template are not needed, however then the git log need to be enhanced to justify/explain that the existing optimization was in fact not needed (assuming this is the case :) )",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16176#issuecomment-2271543583
Performance,optimiz,optimization,"> So you mean extern template the new ExecImp?. Yes, this what I meant. > because you still have to instantiate the ""front-facing"" template . it is a trivial function, that we could even mark as 'force inline' to make it disappear. > Maybe, but I doubt that it actually achieves the goal of reducing compile time .... and neither [of the functions] seems particularly expensive to generate. . I started from the assumption that the existing code was there for a reason. Indeed if the functions are also simple/trivial, the extern template are not needed, however then the git log need to be enhanced to justify/explain that the existing optimization was in fact not needed (assuming this is the case :) )",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16176#issuecomment-2271543583
Testability,log,log,"> So you mean extern template the new ExecImp?. Yes, this what I meant. > because you still have to instantiate the ""front-facing"" template . it is a trivial function, that we could even mark as 'force inline' to make it disappear. > Maybe, but I doubt that it actually achieves the goal of reducing compile time .... and neither [of the functions] seems particularly expensive to generate. . I started from the assumption that the existing code was there for a reason. Indeed if the functions are also simple/trivial, the extern template are not needed, however then the git log need to be enhanced to justify/explain that the existing optimization was in fact not needed (assuming this is the case :) )",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16176#issuecomment-2271543583
Usability,simpl,simple,"> So you mean extern template the new ExecImp?. Yes, this what I meant. > because you still have to instantiate the ""front-facing"" template . it is a trivial function, that we could even mark as 'force inline' to make it disappear. > Maybe, but I doubt that it actually achieves the goal of reducing compile time .... and neither [of the functions] seems particularly expensive to generate. . I started from the assumption that the existing code was there for a reason. Indeed if the functions are also simple/trivial, the extern template are not needed, however then the git log need to be enhanced to justify/explain that the existing optimization was in fact not needed (assuming this is the case :) )",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16176#issuecomment-2271543583
Usability,simpl,simplify,"Is it possible to get the `QualType` for a template argument without parsing Clang's AST? If so, that would be much easier. I was able to simplify some of this code by implementing the template in the header, but an AST transformer is still needed to get the `QualType` and add it to the template specialization.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16214#issuecomment-2295093885
Usability,feedback,feedback,Thanks for the feedback @will-cern ! The expert is now in the loop.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16244#issuecomment-2291348314
Usability,simpl,simply,@bellenot `build/win/cl.sh			build/win/f77.sh		build/win/ld.sh			build/win/makelib.sh		build/win/makeresource.sh` seems to have only been using in the `Makefile` and seem no longer used. Would we be able to simply removed them?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16271#issuecomment-2298682153
Usability,simpl,simply,"> @bellenot `build/win/cl.sh build/win/f77.sh build/win/ld.sh build/win/makelib.sh build/win/makeresource.sh` seems to have only been using in the `Makefile` and seem no longer used. Would we be able to simply removed them?. Well, they can still be used by people using cygwin (if any...)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16271#issuecomment-2298741171
Safety,avoid,avoid,"Cool, thanks! I don't have a strong opinion on it either, but if it works this should be the simplest solution to avoid replacing `find_package` and we can close #8633.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16274#issuecomment-2298776505
Usability,simpl,simplest,"Cool, thanks! I don't have a strong opinion on it either, but if it works this should be the simplest solution to avoid replacing `find_package` and we can close #8633.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16274#issuecomment-2298776505
Testability,test,test,"This is the manifestation of a known problem with the `std::string_view` converters, that can be reproduced without RDataFrame:; ```Python; import ROOT; import cppyy. cppyy.cppdef(""""""; void foo(std::string_view input) { std::cout << input << std::endl; }; """"""). my_string = cppyy.gbl.std.string(""test""). cppyy.gbl.foo(my_string); ```; You'll see that the output in ROOT 6.32 is empty, meaning the `string_view` is not correctly initialized. This causes the RDF code to crash. This problem was already fixed in upstream cppyy, and we have a PR open to apply these fixes:; https://github.com/root-project/root/pull/16212. However, the fix is breaking some other tests, so we can't apply them yet. Thanks for the report though, because this makes it clearer how #16212 needs to be prioritized. In the meantime, the workaround is to convert your `std::strings` into Python strings, because the conversion to `std::string_view` works for them:; ```python; for col in cols:; print(col); print( tmprdf.GetColumnType(str(col) )); ```; This workaround is also backwards compatible.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16298#issuecomment-2306614607
Usability,clear,clearer,"This is the manifestation of a known problem with the `std::string_view` converters, that can be reproduced without RDataFrame:; ```Python; import ROOT; import cppyy. cppyy.cppdef(""""""; void foo(std::string_view input) { std::cout << input << std::endl; }; """"""). my_string = cppyy.gbl.std.string(""test""). cppyy.gbl.foo(my_string); ```; You'll see that the output in ROOT 6.32 is empty, meaning the `string_view` is not correctly initialized. This causes the RDF code to crash. This problem was already fixed in upstream cppyy, and we have a PR open to apply these fixes:; https://github.com/root-project/root/pull/16212. However, the fix is breaking some other tests, so we can't apply them yet. Thanks for the report though, because this makes it clearer how #16212 needs to be prioritized. In the meantime, the workaround is to convert your `std::strings` into Python strings, because the conversion to `std::string_view` works for them:; ```python; for col in cols:; print(col); print( tmprdf.GetColumnType(str(col) )); ```; This workaround is also backwards compatible.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16298#issuecomment-2306614607
Usability,clear,clear,"> * An important part of this PR is deciding the naming scheme for the new user-facing API. I see two main ways: being pedantic or being coherent. Pedantic would mean that the function for headers should be `IncludeHeaders`, the one for shared libraries probably should be `LoadSharedLibs` etc. Instead if we want to be coherent and also hint at the fact that this is a tool for distributed execution, we could decide to name everything `Distribute*` so that it is already clear in the name of the function that the code/header/file will be uploaded to the workers somehow. Personally, I would go for the `Distribute*` approach but we can discuss this next week in person. . > * I believe we need a section in the docs in `RDataFrame.cxx` describing these functions, with examples of usage. Ideally what I would like to see is something like a transition help guide, just to give an example; > ; > ```python; > # If you do this in your local RDataFrame script; > ROOT.gInterpreter.Declare(""my_code""); > df.Define(...); > ; > # Do this in distributed RDF; > ROOT.RDF.Distributed.DistributeCode(""my_code""); > df.Define(...); > ```. sure, I will do that next. . I implemented all your comments (but the leftover debug statements - on purpose, as there are a few things we still need to debug - see my comments in the roottest PR - especially multiple declarations).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16309#issuecomment-2317916267
Usability,simpl,simply,Do I understand correctly this affects only scoped enums within a vector? Can I simply fix it on my side by moving to `enum class Foo : int {}`?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16312#issuecomment-2320321003
Usability,simpl,simply,"For the record, as you might have seen in https://github.com/AliceO2Group/AliceO2/pull/13464, simply changing the types breaks reading back old files (i.e. two shorts are read in an int). Could you comment when do you expect to have a fix for this on your side which applies to 6.32.2 and if it will allow old code to still read new data (and viceversa new code / old data)?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16312#issuecomment-2333276845
Usability,clear,clear,"The following custom Streamer works around the issue:; ```; template <typename Flags>; inline void CalArray<Flags>::Streamer(TBuffer &R__b); {; // Stream an object of class CalArray<PadFlags>. if (R__b.IsReading()) {; UInt_t R__s, R__c;; Version_t R__v = R__b.ReadVersion(&R__s, &R__c);; if (R__v <= 3) {; {; UInt_t start, count;; Version_t vers = R__b.ReadVersion(&start, &count);. std::vector<int> R__stl;; R__stl.clear();; int R__n;; R__b >> R__n;; R__stl.reserve(R__n);; for (int R__i = 0; R__i < R__n; R__i++) {; Int_t readtemp;; R__b >> readtemp;; R__stl.push_back(readtemp);; }; R__b.CheckByteCount(start, count, ""stl collection of enums"");. mFlags.clear();; auto data = reinterpret_cast<unsigned short*>(R__stl.data());; constexpr size_t delta = sizeof(int)/sizeof(Flags);; for(int i = 0; i < R__n; ++i); mFlags.push_back(static_cast<PadFlags>( data[i] ));; }; int tmp;; R__b >> tmp;; mPadSubset = static_cast<PadSubset>(tmp);. R__b.CheckByteCount(R__s, R__c, CalArray::IsA());; } else {; R__b.ReadClassBuffer(CalArray<Flags>::Class(),this, R__v, R__s, R__c);; }; } else {; R__b.WriteClassBuffer(CalArray<Flags>::Class(),this);; }; }; ```; [Call to `ReadClassBuffer` was corrected to add missing parameters]",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16312#issuecomment-2334928339
Deployability,install,installing,"Pretty much the same motivation of having new headers in ROOTSYS/include/ROOT. The upshot is that the third party codebase will become clearer of that `TList.h` is a ROOT thing; and more importantly we will define away a class of problems we have when installing ROOT. Right now on some systems we install everything in `/usr/include`, which is not a good practice unless one is libc.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16327#issuecomment-2320251654
Usability,clear,clearer,"Pretty much the same motivation of having new headers in ROOTSYS/include/ROOT. The upshot is that the third party codebase will become clearer of that `TList.h` is a ROOT thing; and more importantly we will define away a class of problems we have when installing ROOT. Right now on some systems we install everything in `/usr/include`, which is not a good practice unless one is libc.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16327#issuecomment-2320251654
Integrability,depend,dependencies,Some time ago we adjust cmake files so that when building ROOT libraries we using headers from source directories and not headers from `$ROOTSYS/include`. This makes dependencies between ROOT components more clear. I just checked $ROOTSYS/include - there are 1476 files. And going this way we will double number of files.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16327#issuecomment-2346961309
Usability,clear,clear,Some time ago we adjust cmake files so that when building ROOT libraries we using headers from source directories and not headers from `$ROOTSYS/include`. This makes dependencies between ROOT components more clear. I just checked $ROOTSYS/include - there are 1476 files. And going this way we will double number of files.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16327#issuecomment-2346961309
Usability,simpl,simply,TSVG (old code) is like TPDF or TPostScript is simply producing an SVG file from what is displayed it does not create a new color.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16348#issuecomment-2328279111
Usability,guid,guide,"I agree with Jonas it should stay ""Legacy"" as mentioned in the ref guide: https://root.cern/doc/v632/classTSpectrum.html",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16351#issuecomment-2323919858
Security,access,access,It seems clear that the two name `RNTupleUnownedView` and `RNTupleOwnedView` are too ambiguous (no way to know who the subject of the '[un]owned' is (Is the the user or the system that owns (or not)). Furthermore I am confused by the question itself. A `view` is typically a 'small' object that does not own what it gives access to (e.g. `std::string_view` or its cousin `std::span`). So is `view` even the right term? Completely related can you remind me what information we are trying to pass to the user with the 2 distinct names (what do they need to do differently)?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16363#issuecomment-2327424850
Usability,clear,clear,It seems clear that the two name `RNTupleUnownedView` and `RNTupleOwnedView` are too ambiguous (no way to know who the subject of the '[un]owned' is (Is the the user or the system that owns (or not)). Furthermore I am confused by the question itself. A `view` is typically a 'small' object that does not own what it gives access to (e.g. `std::string_view` or its cousin `std::span`). So is `view` even the right term? Completely related can you remind me what information we are trying to pass to the user with the 2 distinct names (what do they need to do differently)?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16363#issuecomment-2327424850
Usability,clear,clearly,"Just an idea: would it improve the situation if we kept the one name `RNTupleView` with a template parameter that distinguishes between owning and non-owning, but we make that template parameter an enum so that the meaning is clearly spelled out.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16363#issuecomment-2337291204
Usability,clear,clearly,"> Just an idea: would it improve the situation if we kept the one name `RNTupleView` with a template parameter that distinguishes between owning and non-owning, but we make that template parameter an enum so that the meaning is clearly spelled out. I guess we should ask the experiments about this, since this change proposal came from them. ; Personally, I'm not sure how much this would help, given that we would just move the naming problem to the enum values rather than the classes.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16363#issuecomment-2337593312
Usability,clear,clearly,"> > Just an idea: would it improve the situation if we kept the one name `RNTupleView` with a template parameter that distinguishes between owning and non-owning, but we make that template parameter an enum so that the meaning is clearly spelled out.; > ; > I guess we should ask the experiments about this, since this change proposal came from them. Personally, I'm not sure how much this would help, given that we would just move the naming problem to the enum values rather than the classes. I agree that we should discuss it with the API reviewers. The advantage I see is that I find it easier to be verbose in the enum constant names (e.g., `kOwnedByCaller`, `kOwnedByROOT`) than in the class name. Especially, if the non-owning view is the default value. E.g. ```; auto v1 = reader->GetView<float>(...);; auto v2 = reader->GetView<float, EViewType::kOwnedByCaller>(...); ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16363#issuecomment-2337820694
Usability,simpl,simple,> 3. Move the `find_package(OpenSSL) from inside `builtins/xrootd/CMakeLists.txt`to it inclusion point in`SearchInstalledSoftware.cmake`. Sounds like a good and simple solution to me!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16374#issuecomment-2330908221
Availability,redundant,redundant,"Hi, thanks for the question!. The standard way of do this in ROOT is to use [TParameter](https://root.cern.ch/doc/v612/classTParameter.html) or an `std::` container, as also discussed here:; https://root-forum.cern.ch/t/writing-simple-variable-in-root-files/11094/5. For example:; ```C++; void write() {. TParameter<int> x1{""x1"", 5};; std::vector<int> x2{4};. std::unique_ptr<TFile> file{TFile::Open(""myfile.root"", ""RECREATE"")};. file->WriteObject(&x1, ""x1"");; file->WriteObject(&x2, ""x2"");; }; ```; Therefore, having this functionality is redundant as therefore it was removed. If you still need to use `RooInt` in your framework for backwards compatibility, please just copy-paste its source code into your framework. It's very simple:; * https://github.com/root-project/root/blob/v6-28-00-patches/roofit/roofitcore/inc/RooInt.h; * https://github.com/root-project/root/blob/v6-28-00-patches/roofit/roofitcore/src/RooInt.cxx; You can even remove the sorting interface if you don't need it. Are these possible ways forward? I would be very reluctant to bring this class back, because RooFit is for statistical analysis. Using its classes to store metadata in a ROOT file is really not the idea.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16380#issuecomment-2335109569
Deployability,patch,patches,"Hi, thanks for the question!. The standard way of do this in ROOT is to use [TParameter](https://root.cern.ch/doc/v612/classTParameter.html) or an `std::` container, as also discussed here:; https://root-forum.cern.ch/t/writing-simple-variable-in-root-files/11094/5. For example:; ```C++; void write() {. TParameter<int> x1{""x1"", 5};; std::vector<int> x2{4};. std::unique_ptr<TFile> file{TFile::Open(""myfile.root"", ""RECREATE"")};. file->WriteObject(&x1, ""x1"");; file->WriteObject(&x2, ""x2"");; }; ```; Therefore, having this functionality is redundant as therefore it was removed. If you still need to use `RooInt` in your framework for backwards compatibility, please just copy-paste its source code into your framework. It's very simple:; * https://github.com/root-project/root/blob/v6-28-00-patches/roofit/roofitcore/inc/RooInt.h; * https://github.com/root-project/root/blob/v6-28-00-patches/roofit/roofitcore/src/RooInt.cxx; You can even remove the sorting interface if you don't need it. Are these possible ways forward? I would be very reluctant to bring this class back, because RooFit is for statistical analysis. Using its classes to store metadata in a ROOT file is really not the idea.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16380#issuecomment-2335109569
Integrability,interface,interface,"Hi, thanks for the question!. The standard way of do this in ROOT is to use [TParameter](https://root.cern.ch/doc/v612/classTParameter.html) or an `std::` container, as also discussed here:; https://root-forum.cern.ch/t/writing-simple-variable-in-root-files/11094/5. For example:; ```C++; void write() {. TParameter<int> x1{""x1"", 5};; std::vector<int> x2{4};. std::unique_ptr<TFile> file{TFile::Open(""myfile.root"", ""RECREATE"")};. file->WriteObject(&x1, ""x1"");; file->WriteObject(&x2, ""x2"");; }; ```; Therefore, having this functionality is redundant as therefore it was removed. If you still need to use `RooInt` in your framework for backwards compatibility, please just copy-paste its source code into your framework. It's very simple:; * https://github.com/root-project/root/blob/v6-28-00-patches/roofit/roofitcore/inc/RooInt.h; * https://github.com/root-project/root/blob/v6-28-00-patches/roofit/roofitcore/src/RooInt.cxx; You can even remove the sorting interface if you don't need it. Are these possible ways forward? I would be very reluctant to bring this class back, because RooFit is for statistical analysis. Using its classes to store metadata in a ROOT file is really not the idea.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16380#issuecomment-2335109569
Modifiability,variab,variable-in-root-files,"Hi, thanks for the question!. The standard way of do this in ROOT is to use [TParameter](https://root.cern.ch/doc/v612/classTParameter.html) or an `std::` container, as also discussed here:; https://root-forum.cern.ch/t/writing-simple-variable-in-root-files/11094/5. For example:; ```C++; void write() {. TParameter<int> x1{""x1"", 5};; std::vector<int> x2{4};. std::unique_ptr<TFile> file{TFile::Open(""myfile.root"", ""RECREATE"")};. file->WriteObject(&x1, ""x1"");; file->WriteObject(&x2, ""x2"");; }; ```; Therefore, having this functionality is redundant as therefore it was removed. If you still need to use `RooInt` in your framework for backwards compatibility, please just copy-paste its source code into your framework. It's very simple:; * https://github.com/root-project/root/blob/v6-28-00-patches/roofit/roofitcore/inc/RooInt.h; * https://github.com/root-project/root/blob/v6-28-00-patches/roofit/roofitcore/src/RooInt.cxx; You can even remove the sorting interface if you don't need it. Are these possible ways forward? I would be very reluctant to bring this class back, because RooFit is for statistical analysis. Using its classes to store metadata in a ROOT file is really not the idea.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16380#issuecomment-2335109569
Safety,redund,redundant,"Hi, thanks for the question!. The standard way of do this in ROOT is to use [TParameter](https://root.cern.ch/doc/v612/classTParameter.html) or an `std::` container, as also discussed here:; https://root-forum.cern.ch/t/writing-simple-variable-in-root-files/11094/5. For example:; ```C++; void write() {. TParameter<int> x1{""x1"", 5};; std::vector<int> x2{4};. std::unique_ptr<TFile> file{TFile::Open(""myfile.root"", ""RECREATE"")};. file->WriteObject(&x1, ""x1"");; file->WriteObject(&x2, ""x2"");; }; ```; Therefore, having this functionality is redundant as therefore it was removed. If you still need to use `RooInt` in your framework for backwards compatibility, please just copy-paste its source code into your framework. It's very simple:; * https://github.com/root-project/root/blob/v6-28-00-patches/roofit/roofitcore/inc/RooInt.h; * https://github.com/root-project/root/blob/v6-28-00-patches/roofit/roofitcore/src/RooInt.cxx; You can even remove the sorting interface if you don't need it. Are these possible ways forward? I would be very reluctant to bring this class back, because RooFit is for statistical analysis. Using its classes to store metadata in a ROOT file is really not the idea.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16380#issuecomment-2335109569
Usability,simpl,simple-variable-in-root-files,"Hi, thanks for the question!. The standard way of do this in ROOT is to use [TParameter](https://root.cern.ch/doc/v612/classTParameter.html) or an `std::` container, as also discussed here:; https://root-forum.cern.ch/t/writing-simple-variable-in-root-files/11094/5. For example:; ```C++; void write() {. TParameter<int> x1{""x1"", 5};; std::vector<int> x2{4};. std::unique_ptr<TFile> file{TFile::Open(""myfile.root"", ""RECREATE"")};. file->WriteObject(&x1, ""x1"");; file->WriteObject(&x2, ""x2"");; }; ```; Therefore, having this functionality is redundant as therefore it was removed. If you still need to use `RooInt` in your framework for backwards compatibility, please just copy-paste its source code into your framework. It's very simple:; * https://github.com/root-project/root/blob/v6-28-00-patches/roofit/roofitcore/inc/RooInt.h; * https://github.com/root-project/root/blob/v6-28-00-patches/roofit/roofitcore/src/RooInt.cxx; You can even remove the sorting interface if you don't need it. Are these possible ways forward? I would be very reluctant to bring this class back, because RooFit is for statistical analysis. Using its classes to store metadata in a ROOT file is really not the idea.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16380#issuecomment-2335109569
Deployability,update,update,"Thank you for the answer: I wish I had noticed `TParameter` years ago, since `RooInt` did the job but it was clearly not the semantically correct choice.; We'll give a chance to `TParameter` for the future, and try to surrogate `RooInt` (and `RooFloat`) in the new code.; I'll update and eventually close this issue when we see it works.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16380#issuecomment-2336431234
Usability,clear,clearly,"Thank you for the answer: I wish I had noticed `TParameter` years ago, since `RooInt` did the job but it was clearly not the semantically correct choice.; We'll give a chance to `TParameter` for the future, and try to surrogate `RooInt` (and `RooFloat`) in the new code.; I'll update and eventually close this issue when we see it works.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16380#issuecomment-2336431234
Availability,failure,failure,Test failure in `alma9-clang` unrelated:; ```txt; TEST FAILURES:; 470:gtest-tree-dataframe-test-dataframe-simple; ```,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16385#issuecomment-2337861300
Testability,test,test-dataframe-simple,Test failure in `alma9-clang` unrelated:; ```txt; TEST FAILURES:; 470:gtest-tree-dataframe-test-dataframe-simple; ```,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16385#issuecomment-2337861300
Usability,simpl,simple,Test failure in `alma9-clang` unrelated:; ```txt; TEST FAILURES:; 470:gtest-tree-dataframe-test-dataframe-simple; ```,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16385#issuecomment-2337861300
Usability,clear,clearly,> This column type stores floating point values on disk as integers with a user-defined precision (from 3 to 32 bits) and a user-defined value range. . This sounds very similar to Double32 ... We will need to explain clearly the differences and advantages ....,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16390#issuecomment-2352913035
Availability,error,error,"Maybe to be clearer, I would expect the output to be:; ```; TypeError: none of the 2 overloaded methods succeeded. Full details:; void MyClass::MyMethod(const MyClass::MyObj& x, bool another) =>; TypeError: takes at least 2 arguments (1 given); void MyClass::MyMethod(const MyClass::MyObj& x = """") =>; RuntimeError: My exception; ```; I.e. the second method didn't fail because of a conversion type error, it failed because the method threw a runtime exception",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16405#issuecomment-2345639881
Usability,clear,clearer,"Maybe to be clearer, I would expect the output to be:; ```; TypeError: none of the 2 overloaded methods succeeded. Full details:; void MyClass::MyMethod(const MyClass::MyObj& x, bool another) =>; TypeError: takes at least 2 arguments (1 given); void MyClass::MyMethod(const MyClass::MyObj& x = """") =>; RuntimeError: My exception; ```; I.e. the second method didn't fail because of a conversion type error, it failed because the method threw a runtime exception",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16405#issuecomment-2345639881
Deployability,update,update,"We don't update existing ROOT releases. The fix will be in the next ROOT release, which is either 6.32.08 or 6.34.00. And thanks for the feedback! Good that you know about these options already.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16419#issuecomment-2377653005
Usability,feedback,feedback,"We don't update existing ROOT releases. The fix will be in the next ROOT release, which is either 6.32.08 or 6.34.00. And thanks for the feedback! Good that you know about these options already.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16419#issuecomment-2377653005
Deployability,install,install,"Thanks. We have slightly different systems and configs; ```; System: Darwin-24.1.0; ROOT Platform: macosx; ROOT Architecture: macosxarm64; Processor: 8 core Apple M2 (arm64); Build type: Release; Install path: /install/; Compiler: AppleClang 16.0.0.16000026; C++ standard: 20; Compiler flags:; -- ; - C: -m64 -pipe -W -Wall -fsigned-char -fno-common -Qunused-arguments -pthread; - C (build type specific): -O3 -DNDEBUG; - C++: -Wc++11-narrowing -Wsign-compare -Wsometimes-uninitialized -Wconditional-uninitialized -Wheader-guard -Warray-bounds -Wcomment -Wtautological-compare -Wstrncat-size -Wloop-analysis -Wbool-conversion -m64 -pipe -W -Wall -Woverloaded-virtual -fsigned-char -fno-common -Qunused-arguments -pthread -stdlib=libc++; - C++ (build type specific): -O3 -DNDEBUG; -- Linker flags:; - Executable: -mmacosx-version-min=15.1; - Module: ; - Shared: ; ```. For the moment, I cannot yet reproduce the issue on our devel/build nodes. As you saw, I added in the loop our Apple and graphics expert in the loop. Do you manage to start a browser when starting root in batch mode, i.e. `root -b` (as a test, of course it's not overly useful for the user experience)?; I can propose a temporary workaround to unblock you: could you try to boot root enabling web graphics (still experimental): `root --web`?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16428#issuecomment-2350896986
Modifiability,config,configs,"Thanks. We have slightly different systems and configs; ```; System: Darwin-24.1.0; ROOT Platform: macosx; ROOT Architecture: macosxarm64; Processor: 8 core Apple M2 (arm64); Build type: Release; Install path: /install/; Compiler: AppleClang 16.0.0.16000026; C++ standard: 20; Compiler flags:; -- ; - C: -m64 -pipe -W -Wall -fsigned-char -fno-common -Qunused-arguments -pthread; - C (build type specific): -O3 -DNDEBUG; - C++: -Wc++11-narrowing -Wsign-compare -Wsometimes-uninitialized -Wconditional-uninitialized -Wheader-guard -Warray-bounds -Wcomment -Wtautological-compare -Wstrncat-size -Wloop-analysis -Wbool-conversion -m64 -pipe -W -Wall -Woverloaded-virtual -fsigned-char -fno-common -Qunused-arguments -pthread -stdlib=libc++; - C++ (build type specific): -O3 -DNDEBUG; -- Linker flags:; - Executable: -mmacosx-version-min=15.1; - Module: ; - Shared: ; ```. For the moment, I cannot yet reproduce the issue on our devel/build nodes. As you saw, I added in the loop our Apple and graphics expert in the loop. Do you manage to start a browser when starting root in batch mode, i.e. `root -b` (as a test, of course it's not overly useful for the user experience)?; I can propose a temporary workaround to unblock you: could you try to boot root enabling web graphics (still experimental): `root --web`?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16428#issuecomment-2350896986
Testability,test,test,"Thanks. We have slightly different systems and configs; ```; System: Darwin-24.1.0; ROOT Platform: macosx; ROOT Architecture: macosxarm64; Processor: 8 core Apple M2 (arm64); Build type: Release; Install path: /install/; Compiler: AppleClang 16.0.0.16000026; C++ standard: 20; Compiler flags:; -- ; - C: -m64 -pipe -W -Wall -fsigned-char -fno-common -Qunused-arguments -pthread; - C (build type specific): -O3 -DNDEBUG; - C++: -Wc++11-narrowing -Wsign-compare -Wsometimes-uninitialized -Wconditional-uninitialized -Wheader-guard -Warray-bounds -Wcomment -Wtautological-compare -Wstrncat-size -Wloop-analysis -Wbool-conversion -m64 -pipe -W -Wall -Woverloaded-virtual -fsigned-char -fno-common -Qunused-arguments -pthread -stdlib=libc++; - C++ (build type specific): -O3 -DNDEBUG; -- Linker flags:; - Executable: -mmacosx-version-min=15.1; - Module: ; - Shared: ; ```. For the moment, I cannot yet reproduce the issue on our devel/build nodes. As you saw, I added in the loop our Apple and graphics expert in the loop. Do you manage to start a browser when starting root in batch mode, i.e. `root -b` (as a test, of course it's not overly useful for the user experience)?; I can propose a temporary workaround to unblock you: could you try to boot root enabling web graphics (still experimental): `root --web`?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16428#issuecomment-2350896986
Usability,user experience,user experience,"Thanks. We have slightly different systems and configs; ```; System: Darwin-24.1.0; ROOT Platform: macosx; ROOT Architecture: macosxarm64; Processor: 8 core Apple M2 (arm64); Build type: Release; Install path: /install/; Compiler: AppleClang 16.0.0.16000026; C++ standard: 20; Compiler flags:; -- ; - C: -m64 -pipe -W -Wall -fsigned-char -fno-common -Qunused-arguments -pthread; - C (build type specific): -O3 -DNDEBUG; - C++: -Wc++11-narrowing -Wsign-compare -Wsometimes-uninitialized -Wconditional-uninitialized -Wheader-guard -Warray-bounds -Wcomment -Wtautological-compare -Wstrncat-size -Wloop-analysis -Wbool-conversion -m64 -pipe -W -Wall -Woverloaded-virtual -fsigned-char -fno-common -Qunused-arguments -pthread -stdlib=libc++; - C++ (build type specific): -O3 -DNDEBUG; -- Linker flags:; - Executable: -mmacosx-version-min=15.1; - Module: ; - Shared: ; ```. For the moment, I cannot yet reproduce the issue on our devel/build nodes. As you saw, I added in the loop our Apple and graphics expert in the loop. Do you manage to start a browser when starting root in batch mode, i.e. `root -b` (as a test, of course it's not overly useful for the user experience)?; I can propose a temporary workaround to unblock you: could you try to boot root enabling web graphics (still experimental): `root --web`?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16428#issuecomment-2350896986
Deployability,install,installers,"In general, I think this is a good change. Can you confirm that nothing we do in Windows is affected by this change? It is not clear to me what ""creating Windows installers automatically"" actually means.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16433#issuecomment-2354468531
Usability,clear,clear,"In general, I think this is a good change. Can you confirm that nothing we do in Windows is affected by this change? It is not clear to me what ""creating Windows installers automatically"" actually means.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16433#issuecomment-2354468531
Availability,fault,faulty,"The problem is that RDF tries to open the file to check that it's valid. The logic for the file opening is at https://github.com/root-project/root/blob/962009b8c2057199c2229c3ef9938ac4d315d10a/tree/dataframe/src/RLoopManager.cxx#L1133 . In particular, because of the presence of the `?` token, the string is parsed as a glob. Now in many cases that would be harmless albeit a tiny overhead (it would just return the same file name to open), but in this particular case it triggers a faulty behaviour. The glob parsing attempts at traversing the remote xrootd directory (see [here](https://github.com/root-project/root/blob/962009b8c2057199c2229c3ef9938ac4d315d10a/tree/tree/src/InternalTreeUtils.cxx#L471)), but since the permission is just for the single file with the token and not for the entire directory, it leads to the `user access restricted` error you post above. Now, I believe the most sane course of action would be to refine the logic that checks whether the input file name is a glob. I could simply add a check for the `xrd.wantprot` token, but probably we want to have a more authoritative list of all the tokens that should make the file name not be parsed as a glob. This probably includes not only xrootd tokens but also anything https-related. Or we could adopt a different strategy for glob detection altogether. Thoughts @dpiparo @pcanal ?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16475#issuecomment-2365248206
Safety,detect,detection,"The problem is that RDF tries to open the file to check that it's valid. The logic for the file opening is at https://github.com/root-project/root/blob/962009b8c2057199c2229c3ef9938ac4d315d10a/tree/dataframe/src/RLoopManager.cxx#L1133 . In particular, because of the presence of the `?` token, the string is parsed as a glob. Now in many cases that would be harmless albeit a tiny overhead (it would just return the same file name to open), but in this particular case it triggers a faulty behaviour. The glob parsing attempts at traversing the remote xrootd directory (see [here](https://github.com/root-project/root/blob/962009b8c2057199c2229c3ef9938ac4d315d10a/tree/tree/src/InternalTreeUtils.cxx#L471)), but since the permission is just for the single file with the token and not for the entire directory, it leads to the `user access restricted` error you post above. Now, I believe the most sane course of action would be to refine the logic that checks whether the input file name is a glob. I could simply add a check for the `xrd.wantprot` token, but probably we want to have a more authoritative list of all the tokens that should make the file name not be parsed as a glob. This probably includes not only xrootd tokens but also anything https-related. Or we could adopt a different strategy for glob detection altogether. Thoughts @dpiparo @pcanal ?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16475#issuecomment-2365248206
Security,access,access,"The problem is that RDF tries to open the file to check that it's valid. The logic for the file opening is at https://github.com/root-project/root/blob/962009b8c2057199c2229c3ef9938ac4d315d10a/tree/dataframe/src/RLoopManager.cxx#L1133 . In particular, because of the presence of the `?` token, the string is parsed as a glob. Now in many cases that would be harmless albeit a tiny overhead (it would just return the same file name to open), but in this particular case it triggers a faulty behaviour. The glob parsing attempts at traversing the remote xrootd directory (see [here](https://github.com/root-project/root/blob/962009b8c2057199c2229c3ef9938ac4d315d10a/tree/tree/src/InternalTreeUtils.cxx#L471)), but since the permission is just for the single file with the token and not for the entire directory, it leads to the `user access restricted` error you post above. Now, I believe the most sane course of action would be to refine the logic that checks whether the input file name is a glob. I could simply add a check for the `xrd.wantprot` token, but probably we want to have a more authoritative list of all the tokens that should make the file name not be parsed as a glob. This probably includes not only xrootd tokens but also anything https-related. Or we could adopt a different strategy for glob detection altogether. Thoughts @dpiparo @pcanal ?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16475#issuecomment-2365248206
Testability,log,logic,"The problem is that RDF tries to open the file to check that it's valid. The logic for the file opening is at https://github.com/root-project/root/blob/962009b8c2057199c2229c3ef9938ac4d315d10a/tree/dataframe/src/RLoopManager.cxx#L1133 . In particular, because of the presence of the `?` token, the string is parsed as a glob. Now in many cases that would be harmless albeit a tiny overhead (it would just return the same file name to open), but in this particular case it triggers a faulty behaviour. The glob parsing attempts at traversing the remote xrootd directory (see [here](https://github.com/root-project/root/blob/962009b8c2057199c2229c3ef9938ac4d315d10a/tree/tree/src/InternalTreeUtils.cxx#L471)), but since the permission is just for the single file with the token and not for the entire directory, it leads to the `user access restricted` error you post above. Now, I believe the most sane course of action would be to refine the logic that checks whether the input file name is a glob. I could simply add a check for the `xrd.wantprot` token, but probably we want to have a more authoritative list of all the tokens that should make the file name not be parsed as a glob. This probably includes not only xrootd tokens but also anything https-related. Or we could adopt a different strategy for glob detection altogether. Thoughts @dpiparo @pcanal ?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16475#issuecomment-2365248206
Usability,simpl,simply,"The problem is that RDF tries to open the file to check that it's valid. The logic for the file opening is at https://github.com/root-project/root/blob/962009b8c2057199c2229c3ef9938ac4d315d10a/tree/dataframe/src/RLoopManager.cxx#L1133 . In particular, because of the presence of the `?` token, the string is parsed as a glob. Now in many cases that would be harmless albeit a tiny overhead (it would just return the same file name to open), but in this particular case it triggers a faulty behaviour. The glob parsing attempts at traversing the remote xrootd directory (see [here](https://github.com/root-project/root/blob/962009b8c2057199c2229c3ef9938ac4d315d10a/tree/tree/src/InternalTreeUtils.cxx#L471)), but since the permission is just for the single file with the token and not for the entire directory, it leads to the `user access restricted` error you post above. Now, I believe the most sane course of action would be to refine the logic that checks whether the input file name is a glob. I could simply add a check for the `xrd.wantprot` token, but probably we want to have a more authoritative list of all the tokens that should make the file name not be parsed as a glob. This probably includes not only xrootd tokens but also anything https-related. Or we could adopt a different strategy for glob detection altogether. Thoughts @dpiparo @pcanal ?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16475#issuecomment-2365248206
Availability,error,error,"Ah that makes sense. Extending the defintion of strings to add metadata to paths (globbing, the `#` syntax in `TFile::Open`, ...) is always going to be error prone. > but probably we want to have a more authoritative list of all the tokens that should make the file name not be parsed as a glob. This feels like an impossible task to define. Maybe a simplier solution would be to not support `?` when globbing and only apply globbing to the text before the query string? Or maybe just have a dedicated method (or argument type) for creating a RDataFrame from a glob rather than relying on huristics?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16475#issuecomment-2366982360
Usability,simpl,simplier,"Ah that makes sense. Extending the defintion of strings to add metadata to paths (globbing, the `#` syntax in `TFile::Open`, ...) is always going to be error prone. > but probably we want to have a more authoritative list of all the tokens that should make the file name not be parsed as a glob. This feels like an impossible task to define. Maybe a simplier solution would be to not support `?` when globbing and only apply globbing to the text before the query string? Or maybe just have a dedicated method (or argument type) for creating a RDataFrame from a glob rather than relying on huristics?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16475#issuecomment-2366982360
Deployability,update,update,"o-enum-float-conversion -Wno-elaborated-enum-base -Wno-reserved-identifier -Wno-gnu-folding-constant -fdeprecated-macro -fdebug-compilation-dir=/Users/sftnight -ferror-limit 19 -stack-protector 1 -fstack-check -mdarwin-stkchk-strong-link -fblocks -fencode-extended-block-signature -fregister-global-dtors-with-atexit -fgnuc-version=4.2.1 -fno-cxx-modules -fcxx-exceptions -fexceptions -fmax-type-align=16 -fcommon -fcolor-diagnostics -clang-vendor-feature=+disableNonDependentMemberExprInCurrentInstantiation -fno-odr-hash-protocols -clang-vendor-feature=+enableAggressiveVLAFolding -clang-vendor-feature=+revert09abecef7bbf -clang-vendor-feature=+thisNoAlignAttr -clang-vendor-feature=+thisNoNullAttr -clang-vendor-feature=+disableAtImportPrivateFrameworkInImplementationError -D__GCC_HAVE_DWARF2_CFI_ASM=1 -o - -x c++ /dev/null; clang -cc1 version 16.0.0 (clang-1600.0.26.3) default target arm64-apple-darwin24.1.0; ignoring nonexistent directory ""/Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/local/include""; ignoring nonexistent directory ""/Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/Library/Frameworks""; #include ""..."" search starts here:; #include <...> search starts here:; /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1; /Library/Developer/CommandLineTools/usr/lib/clang/16/include; /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include; /Library/Developer/CommandLineTools/usr/include; /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/System/Library/Frameworks (framework directory); End of search list.; # 1 ""/dev/null""; # 1 ""<built-in>"" 1; # 1 ""<built-in>"" 3; # 439 ""<built-in>"" 3; # 1 ""<command line>"" 1; # 1 ""<built-in>"" 2; # 1 ""/dev/null"" 2. ```; </details>. Can you maybe post the output from your systems? Watch out for `/Library/Developer/CommandLineTools/usr/include/c++` - if that directory shows up, then Apple's update process sometimes results in inconsistent installations (which we would have to deal with on our side...)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16494#issuecomment-2373214590
Integrability,contract,contract,"t@macphsft18 ~ % ls -l /Library/Developer/CommandLineTools/SDKs/; total 0; lrwxr-xr-x 1 root wheel 14 19 Sep 13:58 MacOSX.sdk -> MacOSX15.0.sdk; drwxr-xr-x 7 root wheel 224 1 May 00:16 MacOSX14.5.sdk; lrwxr-xr-x 1 root wheel 14 19 Sep 13:57 MacOSX14.sdk -> MacOSX14.5.sdk; drwxr-xr-x 7 root wheel 224 21 Aug 17:15 MacOSX15.0.sdk; lrwxr-xr-x 1 root wheel 14 19 Sep 13:56 MacOSX15.sdk -> MacOSX15.0.sdk; sftnight@macphsft18 ~ % clang++ -x c++ /dev/null -E -v; Apple clang version 16.0.0 (clang-1600.0.26.3); Target: x86_64-apple-darwin23.6.0; Thread model: posix; InstalledDir: /Library/Developer/CommandLineTools/usr/bin; ignoring nonexistent directory ""/Library/Developer/CommandLineTools/usr/bin/../include/c++/v1""; ""/Library/Developer/CommandLineTools/usr/bin/clang"" -cc1 -triple x86_64-apple-macosx14.0.0 -Wundef-prefix=TARGET_OS_ -Wdeprecated-objc-isa-usage -Werror=deprecated-objc-isa-usage -Werror=implicit-function-declaration -E -disable-free -clear-ast-before-backend -disable-llvm-verifier -discard-value-names -main-file-name null -mrelocation-model pic -pic-level 2 -mframe-pointer=all; -fno-strict-return -ffp-contract=on -fno-rounding-math -funwind-tables=2 -target-sdk-version=15.0 -fvisibility-inlines-hidden-static-local-var -fno-modulemap-allow-subdirectory-search -target-cpu penryn -tune-cpu generic -debugger-tuning=lldb -target-linker-version 1115.7.3 -v -fcoverage-compilation-dir=/Users/sftnight -resource-dir /Library/Developer/CommandLineTools/usr/lib/clang/16 -isysroot /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk -I/usr/local/include -internal-isystem /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1 -internal-isystem /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/local/include -internal-isystem /Library/Developer/CommandLineTools/usr/lib/clang/16/include -internal-externc-isystem /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include -internal-externc-isystem /Library/Developer/CommandLineTools/usr/include -Wno-reorde",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16494#issuecomment-2373214590
Modifiability,extend,extended-block-signature,"ar -fno-modulemap-allow-subdirectory-search -target-cpu penryn -tune-cpu generic -debugger-tuning=lldb -target-linker-version 1115.7.3 -v -fcoverage-compilation-dir=/Users/sftnight -resource-dir /Library/Developer/CommandLineTools/usr/lib/clang/16 -isysroot /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk -I/usr/local/include -internal-isystem /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1 -internal-isystem /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/local/include -internal-isystem /Library/Developer/CommandLineTools/usr/lib/clang/16/include -internal-externc-isystem /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include -internal-externc-isystem /Library/Developer/CommandLineTools/usr/include -Wno-reorder-init-list -Wno-implicit-int-float-conversion -Wno-c99-designator -Wno-final-dtor-non-final-class -Wno-extra-semi-stmt -Wno-misleading-indentation -Wno-quoted-include-in-framework-header -Wno-implicit-fallthrough -Wno-enum-enum-conversion -Wno-enum-float-conversion -Wno-elaborated-enum-base -Wno-reserved-identifier -Wno-gnu-folding-constant -fdeprecated-macro -fdebug-compilation-dir=/Users/sftnight -ferror-limit 19 -stack-protector 1 -fstack-check -mdarwin-stkchk-strong-link -fblocks -fencode-extended-block-signature -fregister-global-dtors-with-atexit -fgnuc-version=4.2.1 -fno-cxx-modules -fcxx-exceptions -fexceptions -fmax-type-align=16 -fcommon -fcolor-diagnostics -clang-vendor-feature=+disableNonDependentMemberExprInCurrentInstantiation -fno-odr-hash-protocols -clang-vendor-feature=+enableAggressiveVLAFolding -clang-vendor-feature=+revert09abecef7bbf -clang-vendor-feature=+thisNoAlignAttr -clang-vendor-feature=+thisNoNullAttr -clang-vendor-feature=+disableAtImportPrivateFrameworkInImplementationError -D__GCC_HAVE_DWARF2_CFI_ASM=1 -o - -x c++ /dev/null; clang -cc1 version 16.0.0 (clang-1600.0.26.3) default target x86_64-apple-darwin23.6.0; ignoring nonexistent directory ""/Library/Developer/CommandLineTools/SDKs/Mac",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16494#issuecomment-2373214590
Performance,tune,tune-cpu,"x 7 root wheel 224 21 Aug 17:15 MacOSX15.0.sdk; lrwxr-xr-x 1 root wheel 14 19 Sep 13:56 MacOSX15.sdk -> MacOSX15.0.sdk; sftnight@macphsft18 ~ % clang++ -x c++ /dev/null -E -v; Apple clang version 16.0.0 (clang-1600.0.26.3); Target: x86_64-apple-darwin23.6.0; Thread model: posix; InstalledDir: /Library/Developer/CommandLineTools/usr/bin; ignoring nonexistent directory ""/Library/Developer/CommandLineTools/usr/bin/../include/c++/v1""; ""/Library/Developer/CommandLineTools/usr/bin/clang"" -cc1 -triple x86_64-apple-macosx14.0.0 -Wundef-prefix=TARGET_OS_ -Wdeprecated-objc-isa-usage -Werror=deprecated-objc-isa-usage -Werror=implicit-function-declaration -E -disable-free -clear-ast-before-backend -disable-llvm-verifier -discard-value-names -main-file-name null -mrelocation-model pic -pic-level 2 -mframe-pointer=all; -fno-strict-return -ffp-contract=on -fno-rounding-math -funwind-tables=2 -target-sdk-version=15.0 -fvisibility-inlines-hidden-static-local-var -fno-modulemap-allow-subdirectory-search -target-cpu penryn -tune-cpu generic -debugger-tuning=lldb -target-linker-version 1115.7.3 -v -fcoverage-compilation-dir=/Users/sftnight -resource-dir /Library/Developer/CommandLineTools/usr/lib/clang/16 -isysroot /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk -I/usr/local/include -internal-isystem /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1 -internal-isystem /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/local/include -internal-isystem /Library/Developer/CommandLineTools/usr/lib/clang/16/include -internal-externc-isystem /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include -internal-externc-isystem /Library/Developer/CommandLineTools/usr/include -Wno-reorder-init-list -Wno-implicit-int-float-conversion -Wno-c99-designator -Wno-final-dtor-non-final-class -Wno-extra-semi-stmt -Wno-misleading-indentation -Wno-quoted-include-in-framework-header -Wno-implicit-fallthrough -Wno-enum-enum-conversion -Wno-enum-float-conversion -Wno-elaborated",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16494#issuecomment-2373214590
Security,hash,hash-protocols,"ternc-isystem /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include -internal-externc-isystem /Library/Developer/CommandLineTools/usr/include -Wno-reorder-init-list -Wno-implicit-int-float-conversion -Wno-c99-designator -Wno-final-dtor-non-final-class -Wno-extra-semi-stmt -Wno-misleading-indentation -Wno-quoted-include-in-framework-header -Wno-implicit-fallthrough -Wno-enum-enum-conversion -Wno-enum-float-conversion -Wno-elaborated-enum-base -Wno-reserved-identifier -Wno-gnu-folding-constant -fdeprecated-macro -fdebug-compilation-dir=/Users/sftnight -ferror-limit 19 -stack-protector 1 -fstack-check -mdarwin-stkchk-strong-link -fblocks -fencode-extended-block-signature -fregister-global-dtors-with-atexit -fgnuc-version=4.2.1 -fno-cxx-modules -fcxx-exceptions -fexceptions -fmax-type-align=16 -fcommon -fcolor-diagnostics -clang-vendor-feature=+disableNonDependentMemberExprInCurrentInstantiation -fno-odr-hash-protocols -clang-vendor-feature=+enableAggressiveVLAFolding -clang-vendor-feature=+revert09abecef7bbf -clang-vendor-feature=+thisNoAlignAttr -clang-vendor-feature=+thisNoNullAttr -clang-vendor-feature=+disableAtImportPrivateFrameworkInImplementationError -D__GCC_HAVE_DWARF2_CFI_ASM=1 -o - -x c++ /dev/null; clang -cc1 version 16.0.0 (clang-1600.0.26.3) default target x86_64-apple-darwin23.6.0; ignoring nonexistent directory ""/Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/local/include""; ignoring nonexistent directory ""/Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/Library/Frameworks""; #include ""..."" search starts here:; #include <...> search starts here:; /usr/local/include; /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1; /Library/Developer/CommandLineTools/usr/lib/clang/16/include; /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include; /Library/Developer/CommandLineTools/usr/include; /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/System/Library/Frameworks (framework directory); End of search list.; # 1 """,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16494#issuecomment-2373214590
Testability,stub,stubs,"sdk; drwxr-xr-x 7 root wheel 224 8 Jun 2023 MacOSX12.3.sdk; lrwxr-xr-x 1 root wheel 14 8 Jun 2023 MacOSX12.sdk -> MacOSX12.3.sdk; drwxr-xr-x 7 root wheel 224 1 May 00:16 MacOSX14.5.sdk; lrwxr-xr-x 1 root wheel 14 17 Sep 17:17 MacOSX14.sdk -> MacOSX14.5.sdk; drwxr-xr-x 7 root wheel 224 21 Aug 17:15 MacOSX15.0.sdk; lrwxr-xr-x 1 root wheel 14 17 Sep 17:16 MacOSX15.sdk -> MacOSX15.0.sdk; sftnight@macphsft31 ~ % clang++ -x c++ /dev/null -E -v; Apple clang version 16.0.0 (clang-1600.0.26.3); Target: arm64-apple-darwin24.0.0; Thread model: posix; InstalledDir: /Library/Developer/CommandLineTools/usr/bin; ignoring nonexistent directory ""/Library/Developer/CommandLineTools/usr/bin/../include/c++/v1""; ""/Library/Developer/CommandLineTools/usr/bin/clang"" -cc1 -triple arm64-apple-macosx15.0.0 -Wundef-prefix=TARGET_OS_ -Wdeprecated-objc-isa-usage -Werror=deprecated-objc-isa-usage -Werror=implicit-function-declaration -E -disable-free -clear-ast-before-backend -disable-llvm-verifier -discard-value-names -main-file-name null -mrelocation-model pic -pic-level 2 -mframe-pointer=non-leaf -fno-strict-return -ffp-contract=on -fno-rounding-math -funwind-tables=1 -fobjc-msgsend-selector-stubs -target-sdk-version=15.0 -fvisibility-inlines-hidden-static-local-var -fno-modulemap-allow-subdirectory-search -target-cpu apple-m1 -target-feature +v8.5a -target-feature +aes -target-feature +crc -target-feature +dotprod -target-feature +fp-armv8 -target-feature +fp16fml -target-feature +lse -target-feature +ras -target-feature +rcpc -target-feature +rdm -target-feature +sha2 -target-feature +sha3 -target-feature +neon -target-feature +zcm -target-feature +zcz -target-feature +fullfp16 -target-abi darwinpcs -debugger-tuning=lldb -target-linker-version 1115.7.3 -v -fcoverage-compilation-dir=/Users/sftnight -resource-dir /Library/Developer/CommandLineTools/usr/lib/clang/16 -isysroot /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk -I/usr/local/include -internal-isystem /Library/Developer/CommandLine",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16494#issuecomment-2373214590
Usability,clear,clear-ast-before-backend,"t@macphsft18 ~ % ls -l /Library/Developer/CommandLineTools/SDKs/; total 0; lrwxr-xr-x 1 root wheel 14 19 Sep 13:58 MacOSX.sdk -> MacOSX15.0.sdk; drwxr-xr-x 7 root wheel 224 1 May 00:16 MacOSX14.5.sdk; lrwxr-xr-x 1 root wheel 14 19 Sep 13:57 MacOSX14.sdk -> MacOSX14.5.sdk; drwxr-xr-x 7 root wheel 224 21 Aug 17:15 MacOSX15.0.sdk; lrwxr-xr-x 1 root wheel 14 19 Sep 13:56 MacOSX15.sdk -> MacOSX15.0.sdk; sftnight@macphsft18 ~ % clang++ -x c++ /dev/null -E -v; Apple clang version 16.0.0 (clang-1600.0.26.3); Target: x86_64-apple-darwin23.6.0; Thread model: posix; InstalledDir: /Library/Developer/CommandLineTools/usr/bin; ignoring nonexistent directory ""/Library/Developer/CommandLineTools/usr/bin/../include/c++/v1""; ""/Library/Developer/CommandLineTools/usr/bin/clang"" -cc1 -triple x86_64-apple-macosx14.0.0 -Wundef-prefix=TARGET_OS_ -Wdeprecated-objc-isa-usage -Werror=deprecated-objc-isa-usage -Werror=implicit-function-declaration -E -disable-free -clear-ast-before-backend -disable-llvm-verifier -discard-value-names -main-file-name null -mrelocation-model pic -pic-level 2 -mframe-pointer=all; -fno-strict-return -ffp-contract=on -fno-rounding-math -funwind-tables=2 -target-sdk-version=15.0 -fvisibility-inlines-hidden-static-local-var -fno-modulemap-allow-subdirectory-search -target-cpu penryn -tune-cpu generic -debugger-tuning=lldb -target-linker-version 1115.7.3 -v -fcoverage-compilation-dir=/Users/sftnight -resource-dir /Library/Developer/CommandLineTools/usr/lib/clang/16 -isysroot /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk -I/usr/local/include -internal-isystem /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1 -internal-isystem /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/local/include -internal-isystem /Library/Developer/CommandLineTools/usr/lib/clang/16/include -internal-externc-isystem /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include -internal-externc-isystem /Library/Developer/CommandLineTools/usr/include -Wno-reorde",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16494#issuecomment-2373214590
Integrability,contract,contract,"dk -> MacOSX15.0.sdk; drwxr-xr-x 7 root wheel 224 Apr 30 18:16 MacOSX14.5.sdk; lrwxr-xr-x 1 root wheel 14 Sep 16 20:47 MacOSX14.sdk -> MacOSX14.5.sdk; drwxr-xr-x 7 root wheel 224 Aug 21 11:15 MacOSX15.0.sdk; lrwxr-xr-x 1 root wheel 14 Sep 16 20:47 MacOSX15.sdk -> MacOSX15.0.sdk. $ clang++ -x c++ /dev/null -E -v; Apple clang version 16.0.0 (clang-1600.0.26.3); Target: arm64-apple-darwin24.0.0; Thread model: posix; InstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin; ignoring nonexistent directory ""/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1""; ""/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/clang"" -cc1 -triple arm64-apple-macosx15.0.0 -Wundef-prefix=TARGET_OS_ -Wdeprecated-objc-isa-usage -Werror=deprecated-objc-isa-usage -Werror=implicit-function-declaration -E -disable-free -clear-ast-before-backend -disable-llvm-verifier -discard-value-names -main-file-name null -mrelocation-model pic -pic-level 2 -mframe-pointer=non-leaf -fno-strict-return -ffp-contract=on -fno-rounding-math -funwind-tables=1 -fobjc-msgsend-selector-stubs -target-sdk-version=15.0 -fvisibility-inlines-hidden-static-local-var -fno-modulemap-allow-subdirectory-search -target-cpu apple-m1 -target-feature +v8.5a -target-feature +aes -target-feature +crc -target-feature +dotprod -target-feature +fp-armv8 -target-feature +fp16fml -target-feature +lse -target-feature +ras -target-feature +rcpc -target-feature +rdm -target-feature +sha2 -target-feature +sha3 -target-feature +neon -target-feature +zcm -target-feature +zcz -target-feature +fullfp16 -target-abi darwinpcs -debugger-tuning=lldb -target-linker-version 1115.7.3 -v -fcoverage-compilation-dir=/Users/stognini -resource-dir /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/lib/clang/16 -isysroot /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16494#issuecomment-2374779123
Modifiability,extend,extended-block-signature,"Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX.sdk -I/usr/local/include -internal-isystem /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX.sdk/usr/include/c++/v1 -internal-isystem /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX.sdk/usr/local/include -internal-isystem /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/lib/clang/16/include -internal-externc-isystem /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX.sdk/usr/include -internal-externc-isystem /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include -Wno-reorder-init-list -Wno-implicit-int-float-conversion -Wno-c99-designator -Wno-final-dtor-non-final-class -Wno-extra-semi-stmt -Wno-misleading-indentation -Wno-quoted-include-in-framework-header -Wno-implicit-fallthrough -Wno-enum-enum-conversion -Wno-enum-float-conversion -Wno-elaborated-enum-base -Wno-reserved-identifier -Wno-gnu-folding-constant -fdeprecated-macro -fdebug-compilation-dir=/Users/stognini -ferror-limit 19 -stack-protector 1 -fstack-check -mdarwin-stkchk-strong-link -fblocks -fencode-extended-block-signature -fregister-global-dtors-with-atexit -fgnuc-version=4.2.1 -fno-cxx-modules -fcxx-exceptions -fexceptions -fmax-type-align=16 -fcommon -fcolor-diagnostics -clang-vendor-feature=+disableNonDependentMemberExprInCurrentInstantiation -fno-odr-hash-protocols -clang-vendor-feature=+enableAggressiveVLAFolding -clang-vendor-feature=+revert09abecef7bbf -clang-vendor-feature=+thisNoAlignAttr -clang-vendor-feature=+thisNoNullAttr -clang-vendor-feature=+disableAtImportPrivateFrameworkInImplementationError -D__GCC_HAVE_DWARF2_CFI_ASM=1 -o - -x c++ /dev/null; clang -cc1 version 16.0.0 (clang-1600.0.26.3) default target arm64-apple-darwin24.0.0; ignoring nonexistent directory ""/usr/local/include""; ignoring nonexistent directory ""/Applications/Xcode.app/C",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16494#issuecomment-2374779123
Security,hash,hash-protocols,"eloper/SDKs/MacOSX.sdk/usr/include -internal-externc-isystem /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include -Wno-reorder-init-list -Wno-implicit-int-float-conversion -Wno-c99-designator -Wno-final-dtor-non-final-class -Wno-extra-semi-stmt -Wno-misleading-indentation -Wno-quoted-include-in-framework-header -Wno-implicit-fallthrough -Wno-enum-enum-conversion -Wno-enum-float-conversion -Wno-elaborated-enum-base -Wno-reserved-identifier -Wno-gnu-folding-constant -fdeprecated-macro -fdebug-compilation-dir=/Users/stognini -ferror-limit 19 -stack-protector 1 -fstack-check -mdarwin-stkchk-strong-link -fblocks -fencode-extended-block-signature -fregister-global-dtors-with-atexit -fgnuc-version=4.2.1 -fno-cxx-modules -fcxx-exceptions -fexceptions -fmax-type-align=16 -fcommon -fcolor-diagnostics -clang-vendor-feature=+disableNonDependentMemberExprInCurrentInstantiation -fno-odr-hash-protocols -clang-vendor-feature=+enableAggressiveVLAFolding -clang-vendor-feature=+revert09abecef7bbf -clang-vendor-feature=+thisNoAlignAttr -clang-vendor-feature=+thisNoNullAttr -clang-vendor-feature=+disableAtImportPrivateFrameworkInImplementationError -D__GCC_HAVE_DWARF2_CFI_ASM=1 -o - -x c++ /dev/null; clang -cc1 version 16.0.0 (clang-1600.0.26.3) default target arm64-apple-darwin24.0.0; ignoring nonexistent directory ""/usr/local/include""; ignoring nonexistent directory ""/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX.sdk/usr/local/include""; ignoring nonexistent directory ""/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX.sdk/Library/Frameworks""; #include ""..."" search starts here:; #include <...> search starts here:; /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX.sdk/usr/include/c++/v1; /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/lib/clang/16/include; /Applications/Xcode.app/Contents/Deve",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16494#issuecomment-2374779123
Testability,stub,stubs,"dk -> MacOSX15.0.sdk; drwxr-xr-x 7 root wheel 224 Apr 30 18:16 MacOSX14.5.sdk; lrwxr-xr-x 1 root wheel 14 Sep 16 20:47 MacOSX14.sdk -> MacOSX14.5.sdk; drwxr-xr-x 7 root wheel 224 Aug 21 11:15 MacOSX15.0.sdk; lrwxr-xr-x 1 root wheel 14 Sep 16 20:47 MacOSX15.sdk -> MacOSX15.0.sdk. $ clang++ -x c++ /dev/null -E -v; Apple clang version 16.0.0 (clang-1600.0.26.3); Target: arm64-apple-darwin24.0.0; Thread model: posix; InstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin; ignoring nonexistent directory ""/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1""; ""/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/clang"" -cc1 -triple arm64-apple-macosx15.0.0 -Wundef-prefix=TARGET_OS_ -Wdeprecated-objc-isa-usage -Werror=deprecated-objc-isa-usage -Werror=implicit-function-declaration -E -disable-free -clear-ast-before-backend -disable-llvm-verifier -discard-value-names -main-file-name null -mrelocation-model pic -pic-level 2 -mframe-pointer=non-leaf -fno-strict-return -ffp-contract=on -fno-rounding-math -funwind-tables=1 -fobjc-msgsend-selector-stubs -target-sdk-version=15.0 -fvisibility-inlines-hidden-static-local-var -fno-modulemap-allow-subdirectory-search -target-cpu apple-m1 -target-feature +v8.5a -target-feature +aes -target-feature +crc -target-feature +dotprod -target-feature +fp-armv8 -target-feature +fp16fml -target-feature +lse -target-feature +ras -target-feature +rcpc -target-feature +rdm -target-feature +sha2 -target-feature +sha3 -target-feature +neon -target-feature +zcm -target-feature +zcz -target-feature +fullfp16 -target-abi darwinpcs -debugger-tuning=lldb -target-linker-version 1115.7.3 -v -fcoverage-compilation-dir=/Users/stognini -resource-dir /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/lib/clang/16 -isysroot /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16494#issuecomment-2374779123
Usability,clear,clear-ast-before-backend,"dk -> MacOSX15.0.sdk; drwxr-xr-x 7 root wheel 224 Apr 30 18:16 MacOSX14.5.sdk; lrwxr-xr-x 1 root wheel 14 Sep 16 20:47 MacOSX14.sdk -> MacOSX14.5.sdk; drwxr-xr-x 7 root wheel 224 Aug 21 11:15 MacOSX15.0.sdk; lrwxr-xr-x 1 root wheel 14 Sep 16 20:47 MacOSX15.sdk -> MacOSX15.0.sdk. $ clang++ -x c++ /dev/null -E -v; Apple clang version 16.0.0 (clang-1600.0.26.3); Target: arm64-apple-darwin24.0.0; Thread model: posix; InstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin; ignoring nonexistent directory ""/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1""; ""/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/clang"" -cc1 -triple arm64-apple-macosx15.0.0 -Wundef-prefix=TARGET_OS_ -Wdeprecated-objc-isa-usage -Werror=deprecated-objc-isa-usage -Werror=implicit-function-declaration -E -disable-free -clear-ast-before-backend -disable-llvm-verifier -discard-value-names -main-file-name null -mrelocation-model pic -pic-level 2 -mframe-pointer=non-leaf -fno-strict-return -ffp-contract=on -fno-rounding-math -funwind-tables=1 -fobjc-msgsend-selector-stubs -target-sdk-version=15.0 -fvisibility-inlines-hidden-static-local-var -fno-modulemap-allow-subdirectory-search -target-cpu apple-m1 -target-feature +v8.5a -target-feature +aes -target-feature +crc -target-feature +dotprod -target-feature +fp-armv8 -target-feature +fp16fml -target-feature +lse -target-feature +ras -target-feature +rcpc -target-feature +rdm -target-feature +sha2 -target-feature +sha3 -target-feature +neon -target-feature +zcm -target-feature +zcz -target-feature +fullfp16 -target-abi darwinpcs -debugger-tuning=lldb -target-linker-version 1115.7.3 -v -fcoverage-compilation-dir=/Users/stognini -resource-dir /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/lib/clang/16 -isysroot /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16494#issuecomment-2374779123
Deployability,patch,patch,"And mine for the record -- confirmed to work without the patch with commit 58a96e2a8e; ```; + sw_vers; ProductName:		macOS; ProductVersion:		14.7; BuildVersion:		23H124. + clang --version; Apple clang version 16.0.0 (clang-1600.0.26.3); Target: arm64-apple-darwin23.6.0; Thread model: posix; InstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin; + ls -l /Library/Developer/CommandLineTools/SDKs/; total 0; lrwxr-xr-x 1 root wheel 14 Sep 18 14:57 MacOSX.sdk -> MacOSX15.0.sdk; drwxr-xr-x 7 root wheel 224 Jun 1 2023 MacOSX12.3.sdk; lrwxr-xr-x 1 root wheel 14 Jun 1 2023 MacOSX12.sdk -> MacOSX12.3.sdk; drwxr-xr-x 7 root wheel 224 Nov 12 2022 MacOSX13.1.sdk; drwxr-xr-x 7 root wheel 224 Sep 18 15:25 MacOSX14.5.sdk; lrwxr-xr-x 1 root wheel 14 Sep 18 14:57 MacOSX14.sdk -> MacOSX14.5.sdk; drwxr-xr-x 7 root wheel 224 Sep 18 15:25 MacOSX15.0.sdk; lrwxr-xr-x 1 root wheel 14 Sep 18 14:56 MacOSX15.sdk -> MacOSX15.0.sdk; + clang++ -x c++ /dev/null -E -v; Apple clang version 16.0.0 (clang-1600.0.26.3); Target: arm64-apple-darwin23.6.0; Thread model: posix; InstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin; ignoring nonexistent directory ""/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1""; ""/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/clang"" -cc1 -triple arm64-apple-macosx14.0.0 -Wundef-prefix=TARGET_OS_ -Wdeprecated-objc-isa-usage -Werror=deprecated-objc-isa-usage -Werror=implicit-function-declaration -E -disable-free -clear-ast-before-backend -disable-llvm-verifier -discard-value-names -main-file-name null -mrelocation-model pic -pic-level 2 -mframe-pointer=non-leaf -fno-strict-return -ffp-contract=on -fno-rounding-math -funwind-tables=1 -fobjc-msgsend-selector-stubs -target-sdk-version=15.0 -fvisibility-inlines-hidden-static-local-var -fno-modulemap-allow-subdirectory-search -target-cpu apple-",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16494#issuecomment-2375170248
Integrability,contract,contract," 2022 MacOSX13.1.sdk; drwxr-xr-x 7 root wheel 224 Sep 18 15:25 MacOSX14.5.sdk; lrwxr-xr-x 1 root wheel 14 Sep 18 14:57 MacOSX14.sdk -> MacOSX14.5.sdk; drwxr-xr-x 7 root wheel 224 Sep 18 15:25 MacOSX15.0.sdk; lrwxr-xr-x 1 root wheel 14 Sep 18 14:56 MacOSX15.sdk -> MacOSX15.0.sdk; + clang++ -x c++ /dev/null -E -v; Apple clang version 16.0.0 (clang-1600.0.26.3); Target: arm64-apple-darwin23.6.0; Thread model: posix; InstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin; ignoring nonexistent directory ""/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1""; ""/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/clang"" -cc1 -triple arm64-apple-macosx14.0.0 -Wundef-prefix=TARGET_OS_ -Wdeprecated-objc-isa-usage -Werror=deprecated-objc-isa-usage -Werror=implicit-function-declaration -E -disable-free -clear-ast-before-backend -disable-llvm-verifier -discard-value-names -main-file-name null -mrelocation-model pic -pic-level 2 -mframe-pointer=non-leaf -fno-strict-return -ffp-contract=on -fno-rounding-math -funwind-tables=1 -fobjc-msgsend-selector-stubs -target-sdk-version=15.0 -fvisibility-inlines-hidden-static-local-var -fno-modulemap-allow-subdirectory-search -target-cpu apple-m1 -target-feature +v8.5a -target-feature +aes -target-feature +crc -target-feature +dotprod -target-feature +fp-armv8 -target-feature +fp16fml -target-feature +lse -target-feature +ras -target-feature +rcpc -target-feature +rdm -target-feature +sha2 -target-feature +sha3 -target-feature +neon -target-feature +zcm -target-feature +zcz -target-feature +fullfp16 -target-abi darwinpcs -debugger-tuning=lldb -target-linker-version 1115.7.3 -v -fcoverage-compilation-dir=/Users/pcanal/root_working/builds/master.debug/src/tutorials/v7/ntuple -resource-dir /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/lib/clang/16 -isysroot /Applications/Xcode.app",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16494#issuecomment-2375170248
Modifiability,extend,extended-block-signature,"ntents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX.sdk/usr/local/include -internal-isystem /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/lib/clang/16/include -internal-externc-isystem /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX.sdk/usr/include -internal-externc-isystem /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include -Wno-reorder-init-list -Wno-implicit-int-float-conversion -Wno-c99-designator -Wno-final-dtor-non-final-class -Wno-extra-semi-stmt -Wno-misleading-indentation -Wno-quoted-include-in-framework-header -Wno-implicit-fallthrough -Wno-enum-enum-conversion -Wno-enum-float-conversion -Wno-elaborated-enum-base -Wno-reserved-identifier -Wno-gnu-folding-constant -fdeprecated-macro -fdebug-compilation-dir=/Users/pcanal/root_working/builds/master.debug/src/tutorials/v7/ntuple -ferror-limit 19 -stack-protector 1 -fstack-check -mdarwin-stkchk-strong-link -fblocks -fencode-extended-block-signature -fregister-global-dtors-with-atexit -fgnuc-version=4.2.1 -fno-cxx-modules -fcxx-exceptions -fexceptions -fmax-type-align=16 -fcommon -clang-vendor-feature=+disableNonDependentMemberExprInCurrentInstantiation -fno-odr-hash-protocols -clang-vendor-feature=+enableAggressiveVLAFolding -clang-vendor-feature=+revert09abecef7bbf -clang-vendor-feature=+thisNoAlignAttr -clang-vendor-feature=+thisNoNullAttr -clang-vendor-feature=+disableAtImportPrivateFrameworkInImplementationError -D__GCC_HAVE_DWARF2_CFI_ASM=1 -o - -x c++ /dev/null; clang -cc1 version 16.0.0 (clang-1600.0.26.3) default target arm64-apple-darwin23.6.0; ignoring nonexistent directory ""/usr/local/include""; ignoring nonexistent directory ""/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX.sdk/usr/local/include""; ignoring nonexistent directory ""/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX.sdk/Library",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16494#issuecomment-2375170248
Security,hash,hash-protocols,"externc-isystem /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include -Wno-reorder-init-list -Wno-implicit-int-float-conversion -Wno-c99-designator -Wno-final-dtor-non-final-class -Wno-extra-semi-stmt -Wno-misleading-indentation -Wno-quoted-include-in-framework-header -Wno-implicit-fallthrough -Wno-enum-enum-conversion -Wno-enum-float-conversion -Wno-elaborated-enum-base -Wno-reserved-identifier -Wno-gnu-folding-constant -fdeprecated-macro -fdebug-compilation-dir=/Users/pcanal/root_working/builds/master.debug/src/tutorials/v7/ntuple -ferror-limit 19 -stack-protector 1 -fstack-check -mdarwin-stkchk-strong-link -fblocks -fencode-extended-block-signature -fregister-global-dtors-with-atexit -fgnuc-version=4.2.1 -fno-cxx-modules -fcxx-exceptions -fexceptions -fmax-type-align=16 -fcommon -clang-vendor-feature=+disableNonDependentMemberExprInCurrentInstantiation -fno-odr-hash-protocols -clang-vendor-feature=+enableAggressiveVLAFolding -clang-vendor-feature=+revert09abecef7bbf -clang-vendor-feature=+thisNoAlignAttr -clang-vendor-feature=+thisNoNullAttr -clang-vendor-feature=+disableAtImportPrivateFrameworkInImplementationError -D__GCC_HAVE_DWARF2_CFI_ASM=1 -o - -x c++ /dev/null; clang -cc1 version 16.0.0 (clang-1600.0.26.3) default target arm64-apple-darwin23.6.0; ignoring nonexistent directory ""/usr/local/include""; ignoring nonexistent directory ""/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX.sdk/usr/local/include""; ignoring nonexistent directory ""/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX.sdk/Library/Frameworks""; #include ""..."" search starts here:; #include <...> search starts here:; /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX.sdk/usr/include/c++/v1; /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/lib/clang/16/include; /Applications/Xcode.app/Contents/Developer/Plat",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16494#issuecomment-2375170248
Testability,stub,stubs," 2022 MacOSX13.1.sdk; drwxr-xr-x 7 root wheel 224 Sep 18 15:25 MacOSX14.5.sdk; lrwxr-xr-x 1 root wheel 14 Sep 18 14:57 MacOSX14.sdk -> MacOSX14.5.sdk; drwxr-xr-x 7 root wheel 224 Sep 18 15:25 MacOSX15.0.sdk; lrwxr-xr-x 1 root wheel 14 Sep 18 14:56 MacOSX15.sdk -> MacOSX15.0.sdk; + clang++ -x c++ /dev/null -E -v; Apple clang version 16.0.0 (clang-1600.0.26.3); Target: arm64-apple-darwin23.6.0; Thread model: posix; InstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin; ignoring nonexistent directory ""/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1""; ""/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/clang"" -cc1 -triple arm64-apple-macosx14.0.0 -Wundef-prefix=TARGET_OS_ -Wdeprecated-objc-isa-usage -Werror=deprecated-objc-isa-usage -Werror=implicit-function-declaration -E -disable-free -clear-ast-before-backend -disable-llvm-verifier -discard-value-names -main-file-name null -mrelocation-model pic -pic-level 2 -mframe-pointer=non-leaf -fno-strict-return -ffp-contract=on -fno-rounding-math -funwind-tables=1 -fobjc-msgsend-selector-stubs -target-sdk-version=15.0 -fvisibility-inlines-hidden-static-local-var -fno-modulemap-allow-subdirectory-search -target-cpu apple-m1 -target-feature +v8.5a -target-feature +aes -target-feature +crc -target-feature +dotprod -target-feature +fp-armv8 -target-feature +fp16fml -target-feature +lse -target-feature +ras -target-feature +rcpc -target-feature +rdm -target-feature +sha2 -target-feature +sha3 -target-feature +neon -target-feature +zcm -target-feature +zcz -target-feature +fullfp16 -target-abi darwinpcs -debugger-tuning=lldb -target-linker-version 1115.7.3 -v -fcoverage-compilation-dir=/Users/pcanal/root_working/builds/master.debug/src/tutorials/v7/ntuple -resource-dir /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/lib/clang/16 -isysroot /Applications/Xcode.app",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16494#issuecomment-2375170248
Usability,clear,clear-ast-before-backend," 2022 MacOSX13.1.sdk; drwxr-xr-x 7 root wheel 224 Sep 18 15:25 MacOSX14.5.sdk; lrwxr-xr-x 1 root wheel 14 Sep 18 14:57 MacOSX14.sdk -> MacOSX14.5.sdk; drwxr-xr-x 7 root wheel 224 Sep 18 15:25 MacOSX15.0.sdk; lrwxr-xr-x 1 root wheel 14 Sep 18 14:56 MacOSX15.sdk -> MacOSX15.0.sdk; + clang++ -x c++ /dev/null -E -v; Apple clang version 16.0.0 (clang-1600.0.26.3); Target: arm64-apple-darwin23.6.0; Thread model: posix; InstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin; ignoring nonexistent directory ""/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1""; ""/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/clang"" -cc1 -triple arm64-apple-macosx14.0.0 -Wundef-prefix=TARGET_OS_ -Wdeprecated-objc-isa-usage -Werror=deprecated-objc-isa-usage -Werror=implicit-function-declaration -E -disable-free -clear-ast-before-backend -disable-llvm-verifier -discard-value-names -main-file-name null -mrelocation-model pic -pic-level 2 -mframe-pointer=non-leaf -fno-strict-return -ffp-contract=on -fno-rounding-math -funwind-tables=1 -fobjc-msgsend-selector-stubs -target-sdk-version=15.0 -fvisibility-inlines-hidden-static-local-var -fno-modulemap-allow-subdirectory-search -target-cpu apple-m1 -target-feature +v8.5a -target-feature +aes -target-feature +crc -target-feature +dotprod -target-feature +fp-armv8 -target-feature +fp16fml -target-feature +lse -target-feature +ras -target-feature +rcpc -target-feature +rdm -target-feature +sha2 -target-feature +sha3 -target-feature +neon -target-feature +zcm -target-feature +zcz -target-feature +fullfp16 -target-abi darwinpcs -debugger-tuning=lldb -target-linker-version 1115.7.3 -v -fcoverage-compilation-dir=/Users/pcanal/root_working/builds/master.debug/src/tutorials/v7/ntuple -resource-dir /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/lib/clang/16 -isysroot /Applications/Xcode.app",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16494#issuecomment-2375170248
Deployability,patch,patch,"So I reinstalled the command line tools (see for example https://root-forum.cern.ch/t/root-on-macos-15-xcode-16/61716/9).; and rebuild. With the rebuild worked with the master as-is (commit 55cd181c3d), so the patch is not needed on my machine at this time. The new environment info is:; ```; + sw_vers; ProductName:		macOS; ProductVersion:		14.7; BuildVersion:		23H124; + clang --version; Apple clang version 16.0.0 (clang-1600.0.26.3); Target: arm64-apple-darwin23.6.0; Thread model: posix; InstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin; + ls -l /Library/Developer/CommandLineTools/SDKs/; total 0; lrwxr-xr-x 1 root wheel 14 Sep 25 18:30 MacOSX.sdk -> MacOSX15.0.sdk; drwxr-xr-x 7 root wheel 224 Sep 25 18:33 MacOSX14.5.sdk; lrwxr-xr-x 1 root wheel 14 Sep 25 18:29 MacOSX14.sdk -> MacOSX14.5.sdk; drwxr-xr-x 7 root wheel 224 Sep 25 18:31 MacOSX15.0.sdk; lrwxr-xr-x 1 root wheel 14 Sep 25 18:29 MacOSX15.sdk -> MacOSX15.0.sdk; + clang++ -x c++ /dev/null -E -v; Apple clang version 16.0.0 (clang-1600.0.26.3); Target: arm64-apple-darwin23.6.0; Thread model: posix; InstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin; ignoring nonexistent directory ""/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1""; ""/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/clang"" -cc1 -triple arm64-apple-macosx14.0.0 -Wundef-prefix=TARGET_OS_ -Wdeprecated-objc-isa-usage -Werror=deprecated-objc-isa-usage -Werror=implicit-function-declaration -E -disable-free -clear-ast-before-backend -disable-llvm-verifier -discard-value-names -main-file-name null -mrelocation-model pic -pic-level 2 -mframe-pointer=non-leaf -fno-strict-return -ffp-contract=on -fno-rounding-math -funwind-tables=1 -fobjc-msgsend-selector-stubs -target-sdk-version=15.0 -fvisibility-inlines-hidden-static-local-var -fno-modulemap-allow-subdirectory-searc",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16494#issuecomment-2377172429
Integrability,contract,contract,"dk -> MacOSX15.0.sdk; drwxr-xr-x 7 root wheel 224 Sep 25 18:33 MacOSX14.5.sdk; lrwxr-xr-x 1 root wheel 14 Sep 25 18:29 MacOSX14.sdk -> MacOSX14.5.sdk; drwxr-xr-x 7 root wheel 224 Sep 25 18:31 MacOSX15.0.sdk; lrwxr-xr-x 1 root wheel 14 Sep 25 18:29 MacOSX15.sdk -> MacOSX15.0.sdk; + clang++ -x c++ /dev/null -E -v; Apple clang version 16.0.0 (clang-1600.0.26.3); Target: arm64-apple-darwin23.6.0; Thread model: posix; InstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin; ignoring nonexistent directory ""/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1""; ""/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/clang"" -cc1 -triple arm64-apple-macosx14.0.0 -Wundef-prefix=TARGET_OS_ -Wdeprecated-objc-isa-usage -Werror=deprecated-objc-isa-usage -Werror=implicit-function-declaration -E -disable-free -clear-ast-before-backend -disable-llvm-verifier -discard-value-names -main-file-name null -mrelocation-model pic -pic-level 2 -mframe-pointer=non-leaf -fno-strict-return -ffp-contract=on -fno-rounding-math -funwind-tables=1 -fobjc-msgsend-selector-stubs -target-sdk-version=15.0 -fvisibility-inlines-hidden-static-local-var -fno-modulemap-allow-subdirectory-search -target-cpu apple-m1 -target-feature +v8.5a -target-feature +aes -target-feature +crc -target-feature +dotprod -target-feature +fp-armv8 -target-feature +fp16fml -target-feature +lse -target-feature +ras -target-feature +rcpc -target-feature +rdm -target-feature +sha2 -target-feature +sha3 -target-feature +neon -target-feature +zcm -target-feature +zcz -target-feature +fullfp16 -target-abi darwinpcs -debugger-tuning=lldb -target-linker-version 1115.7.3 -v -fcoverage-compilation-dir=/Users/pcanal/root_working/builds/master.module -resource-dir /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/lib/clang/16 -isysroot /Applications/Xcode.app/Contents/Developer/Pla",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16494#issuecomment-2377172429
Modifiability,extend,extended-block-signature,"Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX.sdk/usr/local/include -internal-isystem /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/lib/clang/16/include -internal-externc-isystem /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX.sdk/usr/include -internal-externc-isystem /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include -Wno-reorder-init-list -Wno-implicit-int-float-conversion -Wno-c99-designator -Wno-final-dtor-non-final-class -Wno-extra-semi-stmt -Wno-misleading-indentation -Wno-quoted-include-in-framework-header -Wno-implicit-fallthrough -Wno-enum-enum-conversion -Wno-enum-float-conversion -Wno-elaborated-enum-base -Wno-reserved-identifier -Wno-gnu-folding-constant -fdeprecated-macro -fdebug-compilation-dir=/Users/pcanal/root_working/builds/master.module -ferror-limit 19 -stack-protector 1 -fstack-check -mdarwin-stkchk-strong-link -fblocks -fencode-extended-block-signature -fregister-global-dtors-with-atexit -fgnuc-version=4.2.1 -fno-cxx-modules -fcxx-exceptions -fexceptions -fmax-type-align=16 -fcommon -clang-vendor-feature=+disableNonDependentMemberExprInCurrentInstantiation -fno-odr-hash-protocols -clang-vendor-feature=+enableAggressiveVLAFolding -clang-vendor-feature=+revert09abecef7bbf -clang-vendor-feature=+thisNoAlignAttr -clang-vendor-feature=+thisNoNullAttr -clang-vendor-feature=+disableAtImportPrivateFrameworkInImplementationError -D__GCC_HAVE_DWARF2_CFI_ASM=1 -o - -x c++ /dev/null; clang -cc1 version 16.0.0 (clang-1600.0.26.3) default target arm64-apple-darwin23.6.0; ignoring nonexistent directory ""/usr/local/include""; ignoring nonexistent directory ""/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX.sdk/usr/local/include""; ignoring nonexistent directory ""/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX.sdk/Library/Frameworks""",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16494#issuecomment-2377172429
Security,hash,hash-protocols,"/usr/include -internal-externc-isystem /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include -Wno-reorder-init-list -Wno-implicit-int-float-conversion -Wno-c99-designator -Wno-final-dtor-non-final-class -Wno-extra-semi-stmt -Wno-misleading-indentation -Wno-quoted-include-in-framework-header -Wno-implicit-fallthrough -Wno-enum-enum-conversion -Wno-enum-float-conversion -Wno-elaborated-enum-base -Wno-reserved-identifier -Wno-gnu-folding-constant -fdeprecated-macro -fdebug-compilation-dir=/Users/pcanal/root_working/builds/master.module -ferror-limit 19 -stack-protector 1 -fstack-check -mdarwin-stkchk-strong-link -fblocks -fencode-extended-block-signature -fregister-global-dtors-with-atexit -fgnuc-version=4.2.1 -fno-cxx-modules -fcxx-exceptions -fexceptions -fmax-type-align=16 -fcommon -clang-vendor-feature=+disableNonDependentMemberExprInCurrentInstantiation -fno-odr-hash-protocols -clang-vendor-feature=+enableAggressiveVLAFolding -clang-vendor-feature=+revert09abecef7bbf -clang-vendor-feature=+thisNoAlignAttr -clang-vendor-feature=+thisNoNullAttr -clang-vendor-feature=+disableAtImportPrivateFrameworkInImplementationError -D__GCC_HAVE_DWARF2_CFI_ASM=1 -o - -x c++ /dev/null; clang -cc1 version 16.0.0 (clang-1600.0.26.3) default target arm64-apple-darwin23.6.0; ignoring nonexistent directory ""/usr/local/include""; ignoring nonexistent directory ""/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX.sdk/usr/local/include""; ignoring nonexistent directory ""/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX.sdk/Library/Frameworks""; #include ""..."" search starts here:; #include <...> search starts here:; /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX.sdk/usr/include/c++/v1; /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/lib/clang/16/include; /Applications/Xcode.app/Contents/Developer/Plat",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16494#issuecomment-2377172429
Testability,stub,stubs,"dk -> MacOSX15.0.sdk; drwxr-xr-x 7 root wheel 224 Sep 25 18:33 MacOSX14.5.sdk; lrwxr-xr-x 1 root wheel 14 Sep 25 18:29 MacOSX14.sdk -> MacOSX14.5.sdk; drwxr-xr-x 7 root wheel 224 Sep 25 18:31 MacOSX15.0.sdk; lrwxr-xr-x 1 root wheel 14 Sep 25 18:29 MacOSX15.sdk -> MacOSX15.0.sdk; + clang++ -x c++ /dev/null -E -v; Apple clang version 16.0.0 (clang-1600.0.26.3); Target: arm64-apple-darwin23.6.0; Thread model: posix; InstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin; ignoring nonexistent directory ""/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1""; ""/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/clang"" -cc1 -triple arm64-apple-macosx14.0.0 -Wundef-prefix=TARGET_OS_ -Wdeprecated-objc-isa-usage -Werror=deprecated-objc-isa-usage -Werror=implicit-function-declaration -E -disable-free -clear-ast-before-backend -disable-llvm-verifier -discard-value-names -main-file-name null -mrelocation-model pic -pic-level 2 -mframe-pointer=non-leaf -fno-strict-return -ffp-contract=on -fno-rounding-math -funwind-tables=1 -fobjc-msgsend-selector-stubs -target-sdk-version=15.0 -fvisibility-inlines-hidden-static-local-var -fno-modulemap-allow-subdirectory-search -target-cpu apple-m1 -target-feature +v8.5a -target-feature +aes -target-feature +crc -target-feature +dotprod -target-feature +fp-armv8 -target-feature +fp16fml -target-feature +lse -target-feature +ras -target-feature +rcpc -target-feature +rdm -target-feature +sha2 -target-feature +sha3 -target-feature +neon -target-feature +zcm -target-feature +zcz -target-feature +fullfp16 -target-abi darwinpcs -debugger-tuning=lldb -target-linker-version 1115.7.3 -v -fcoverage-compilation-dir=/Users/pcanal/root_working/builds/master.module -resource-dir /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/lib/clang/16 -isysroot /Applications/Xcode.app/Contents/Developer/Pla",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16494#issuecomment-2377172429
Usability,clear,clear-ast-before-backend,"dk -> MacOSX15.0.sdk; drwxr-xr-x 7 root wheel 224 Sep 25 18:33 MacOSX14.5.sdk; lrwxr-xr-x 1 root wheel 14 Sep 25 18:29 MacOSX14.sdk -> MacOSX14.5.sdk; drwxr-xr-x 7 root wheel 224 Sep 25 18:31 MacOSX15.0.sdk; lrwxr-xr-x 1 root wheel 14 Sep 25 18:29 MacOSX15.sdk -> MacOSX15.0.sdk; + clang++ -x c++ /dev/null -E -v; Apple clang version 16.0.0 (clang-1600.0.26.3); Target: arm64-apple-darwin23.6.0; Thread model: posix; InstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin; ignoring nonexistent directory ""/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1""; ""/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/clang"" -cc1 -triple arm64-apple-macosx14.0.0 -Wundef-prefix=TARGET_OS_ -Wdeprecated-objc-isa-usage -Werror=deprecated-objc-isa-usage -Werror=implicit-function-declaration -E -disable-free -clear-ast-before-backend -disable-llvm-verifier -discard-value-names -main-file-name null -mrelocation-model pic -pic-level 2 -mframe-pointer=non-leaf -fno-strict-return -ffp-contract=on -fno-rounding-math -funwind-tables=1 -fobjc-msgsend-selector-stubs -target-sdk-version=15.0 -fvisibility-inlines-hidden-static-local-var -fno-modulemap-allow-subdirectory-search -target-cpu apple-m1 -target-feature +v8.5a -target-feature +aes -target-feature +crc -target-feature +dotprod -target-feature +fp-armv8 -target-feature +fp16fml -target-feature +lse -target-feature +ras -target-feature +rcpc -target-feature +rdm -target-feature +sha2 -target-feature +sha3 -target-feature +neon -target-feature +zcm -target-feature +zcz -target-feature +fullfp16 -target-abi darwinpcs -debugger-tuning=lldb -target-linker-version 1115.7.3 -v -fcoverage-compilation-dir=/Users/pcanal/root_working/builds/master.module -resource-dir /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/lib/clang/16 -isysroot /Applications/Xcode.app/Contents/Developer/Pla",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16494#issuecomment-2377172429
Usability,simpl,simply,"Dear @xkzl ,. Thanks for your report. As a first attempt at fixing it, could you try specifying the pragma for the enum as simply. ```; #pragma link C++ enum MyEnum;; ```. Note the removal of the `class` keyword.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16496#issuecomment-2365047420
Deployability,configurat,configuration,"Dear @xkzl ,. Indeed, I can see the same thing with the following simple example ; ```cpp; // myheader.hxx; #ifndef myheader; #define myheader. enum class MyEnum; {; kFirst,; kSecond,; kThird; };. template <MyEnum T>; class MyClass; {; };. #endif ; ```. ```cpp; // LinkDef.h; #ifdef __CLING__; #pragma link C++ enum MyEnum;; #pragma link C++ class MyClass < MyEnum::kFirst> + ;; #pragma link C++ class MyClass < MyEnum::kSecond> + ;; #pragma link C++ class MyClass < MyEnum::kThird> + ;; #endif; ```. ```; $: rootcling -f myheaderdict.cxx myheader.hxx LinkDef.h -rmf myheader.rootmap; ```. ```; # myheader.rootmap; { decls }; template <MyEnum> class MyClass;. [ ]; # List of selected classes; class MyClass<(MyEnum)0>; class MyClass<(MyEnum)1>; class MyClass<(MyEnum)2>; class MyClass<MyEnum::kFirst>; class MyClass<MyEnum::kSecond>; class MyClass<MyEnum::kThird>; # List of selected enums and outer classes; enum MyEnum; ```. I am unsure whether we are missing some different configuration or spelling. @pcanal might be able to help here.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16496#issuecomment-2365069147
Modifiability,config,configuration,"Dear @xkzl ,. Indeed, I can see the same thing with the following simple example ; ```cpp; // myheader.hxx; #ifndef myheader; #define myheader. enum class MyEnum; {; kFirst,; kSecond,; kThird; };. template <MyEnum T>; class MyClass; {; };. #endif ; ```. ```cpp; // LinkDef.h; #ifdef __CLING__; #pragma link C++ enum MyEnum;; #pragma link C++ class MyClass < MyEnum::kFirst> + ;; #pragma link C++ class MyClass < MyEnum::kSecond> + ;; #pragma link C++ class MyClass < MyEnum::kThird> + ;; #endif; ```. ```; $: rootcling -f myheaderdict.cxx myheader.hxx LinkDef.h -rmf myheader.rootmap; ```. ```; # myheader.rootmap; { decls }; template <MyEnum> class MyClass;. [ ]; # List of selected classes; class MyClass<(MyEnum)0>; class MyClass<(MyEnum)1>; class MyClass<(MyEnum)2>; class MyClass<MyEnum::kFirst>; class MyClass<MyEnum::kSecond>; class MyClass<MyEnum::kThird>; # List of selected enums and outer classes; enum MyEnum; ```. I am unsure whether we are missing some different configuration or spelling. @pcanal might be able to help here.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16496#issuecomment-2365069147
Usability,simpl,simple,"Dear @xkzl ,. Indeed, I can see the same thing with the following simple example ; ```cpp; // myheader.hxx; #ifndef myheader; #define myheader. enum class MyEnum; {; kFirst,; kSecond,; kThird; };. template <MyEnum T>; class MyClass; {; };. #endif ; ```. ```cpp; // LinkDef.h; #ifdef __CLING__; #pragma link C++ enum MyEnum;; #pragma link C++ class MyClass < MyEnum::kFirst> + ;; #pragma link C++ class MyClass < MyEnum::kSecond> + ;; #pragma link C++ class MyClass < MyEnum::kThird> + ;; #endif; ```. ```; $: rootcling -f myheaderdict.cxx myheader.hxx LinkDef.h -rmf myheader.rootmap; ```. ```; # myheader.rootmap; { decls }; template <MyEnum> class MyClass;. [ ]; # List of selected classes; class MyClass<(MyEnum)0>; class MyClass<(MyEnum)1>; class MyClass<(MyEnum)2>; class MyClass<MyEnum::kFirst>; class MyClass<MyEnum::kSecond>; class MyClass<MyEnum::kThird>; # List of selected enums and outer classes; enum MyEnum; ```. I am unsure whether we are missing some different configuration or spelling. @pcanal might be able to help here.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16496#issuecomment-2365069147
Usability,simpl,simpler,I think instead of `#url[link]{label}` we might also use a simpler syntax like in markdown. something like `[label](link)`. No need for a special `#url` keyword. Then it will be enough to look for the string `](http` to know that there is a text with some link.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16512#issuecomment-2390634640
Availability,failure,failure,"This is really good stuff. ARM nodes are appearing on WLCG and testing on that platform will automatically improve the sw stacks of LHC experiments. The test failure needs some thinking but it does not seem a complex issue. If I may suggest this, I would also make sure that a clear indicator of the platform appears in the label of the build (""ARM"", ""Aarch""...)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16526#issuecomment-2375944990
Testability,test,testing,"This is really good stuff. ARM nodes are appearing on WLCG and testing on that platform will automatically improve the sw stacks of LHC experiments. The test failure needs some thinking but it does not seem a complex issue. If I may suggest this, I would also make sure that a clear indicator of the platform appears in the label of the build (""ARM"", ""Aarch""...)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16526#issuecomment-2375944990
Usability,clear,clear,"This is really good stuff. ARM nodes are appearing on WLCG and testing on that platform will automatically improve the sw stacks of LHC experiments. The test failure needs some thinking but it does not seem a complex issue. If I may suggest this, I would also make sure that a clear indicator of the platform appears in the label of the build (""ARM"", ""Aarch""...)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16526#issuecomment-2375944990
Usability,simpl,simplified,"Hi @Dr15Jones @makortel @siliataider, this PR aims to provide a tutorial how we (ROOT) envision frameworks could use the RNTuple API for writing. If you have some time, it would be great if you could check whether it makes sense and demonstrates the relevant use cases. The ""framework code"" is obviously very much simplified and the goal is not to code a full production framework, but I hope it's close enough to what the ""real"" experiment frameworks are doing. Thanks in advance!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16536#issuecomment-2378502691
Integrability,depend,dependencies,"Thanks for the comment. At this point this issue seems to conflate two things: ; 1. The dependencies of python tests. This should have been addressed by #16555 ; 2. The missing symbols. If 1. is confirmed to be solved, I would say that at least this issue ought to be closed and one about missing symbols opened. However, even if an issue dedicated to the missing symbols is opened, it's not clear, at least to me, how the problem can be reproduced. So far we have no indication of it in our CI: can it be due to a somewhat imprecise formulation of the python dependencies in the `requirements.txt` file that affects your platform?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16553#issuecomment-2384870116
Testability,test,tests,"Thanks for the comment. At this point this issue seems to conflate two things: ; 1. The dependencies of python tests. This should have been addressed by #16555 ; 2. The missing symbols. If 1. is confirmed to be solved, I would say that at least this issue ought to be closed and one about missing symbols opened. However, even if an issue dedicated to the missing symbols is opened, it's not clear, at least to me, how the problem can be reproduced. So far we have no indication of it in our CI: can it be due to a somewhat imprecise formulation of the python dependencies in the `requirements.txt` file that affects your platform?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16553#issuecomment-2384870116
Usability,clear,clear,"Thanks for the comment. At this point this issue seems to conflate two things: ; 1. The dependencies of python tests. This should have been addressed by #16555 ; 2. The missing symbols. If 1. is confirmed to be solved, I would say that at least this issue ought to be closed and one about missing symbols opened. However, even if an issue dedicated to the missing symbols is opened, it's not clear, at least to me, how the problem can be reproduced. So far we have no indication of it in our CI: can it be due to a somewhat imprecise formulation of the python dependencies in the `requirements.txt` file that affects your platform?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16553#issuecomment-2384870116
Availability,error,error,"Small update to give further context, the following seemingly similar but subtly different snippet works also for ROOT 6.32. ```python; import ROOT. def main():; ROOT.gInterpreter.ProcessLine(""const auto myvec = TVectorT<float>();""); print(ROOT.myvec). if __name__ == ""__main__"":; raise SystemExit(main()); ```. And it is clear that in this case ProcessLine tries much harder than Declare to automatically load libraries that might be necessary to evaluate the line. Also, the reproducer from the issue description fails with the same error in ROOT latest master.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16601#issuecomment-2393259545
Deployability,update,update,"Small update to give further context, the following seemingly similar but subtly different snippet works also for ROOT 6.32. ```python; import ROOT. def main():; ROOT.gInterpreter.ProcessLine(""const auto myvec = TVectorT<float>();""); print(ROOT.myvec). if __name__ == ""__main__"":; raise SystemExit(main()); ```. And it is clear that in this case ProcessLine tries much harder than Declare to automatically load libraries that might be necessary to evaluate the line. Also, the reproducer from the issue description fails with the same error in ROOT latest master.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16601#issuecomment-2393259545
Performance,load,load,"Small update to give further context, the following seemingly similar but subtly different snippet works also for ROOT 6.32. ```python; import ROOT. def main():; ROOT.gInterpreter.ProcessLine(""const auto myvec = TVectorT<float>();""); print(ROOT.myvec). if __name__ == ""__main__"":; raise SystemExit(main()); ```. And it is clear that in this case ProcessLine tries much harder than Declare to automatically load libraries that might be necessary to evaluate the line. Also, the reproducer from the issue description fails with the same error in ROOT latest master.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16601#issuecomment-2393259545
Usability,clear,clear,"Small update to give further context, the following seemingly similar but subtly different snippet works also for ROOT 6.32. ```python; import ROOT. def main():; ROOT.gInterpreter.ProcessLine(""const auto myvec = TVectorT<float>();""); print(ROOT.myvec). if __name__ == ""__main__"":; raise SystemExit(main()); ```. And it is clear that in this case ProcessLine tries much harder than Declare to automatically load libraries that might be necessary to evaluate the line. Also, the reproducer from the issue description fails with the same error in ROOT latest master.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16601#issuecomment-2393259545
Availability,down,downstream,"That will be hard to respect, because that means unless we introduce a new `testsupport=OFF` configuration flag, gtest would always be a dependency of ROOT with `-fail-on-missing=ON` then. I don't see at the moment how I can respect all of these constraints:. 1. Keep configuration simple by not introducing new build flags; 2. Make `ROOT_ADD_GTEST` fully usable in downstream code even if ROOT was not built with unit tests; 3. Don't add `gtest` as an unavoidable build dependency of ROOT if you have `fail-on-missin=ON`; 4. Respect `fail-on-missing`. Which of these constraints should be relaxed?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16612#issuecomment-2396463790
Deployability,configurat,configuration,"That will be hard to respect, because that means unless we introduce a new `testsupport=OFF` configuration flag, gtest would always be a dependency of ROOT with `-fail-on-missing=ON` then. I don't see at the moment how I can respect all of these constraints:. 1. Keep configuration simple by not introducing new build flags; 2. Make `ROOT_ADD_GTEST` fully usable in downstream code even if ROOT was not built with unit tests; 3. Don't add `gtest` as an unavoidable build dependency of ROOT if you have `fail-on-missin=ON`; 4. Respect `fail-on-missing`. Which of these constraints should be relaxed?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16612#issuecomment-2396463790
Integrability,depend,dependency,"That will be hard to respect, because that means unless we introduce a new `testsupport=OFF` configuration flag, gtest would always be a dependency of ROOT with `-fail-on-missing=ON` then. I don't see at the moment how I can respect all of these constraints:. 1. Keep configuration simple by not introducing new build flags; 2. Make `ROOT_ADD_GTEST` fully usable in downstream code even if ROOT was not built with unit tests; 3. Don't add `gtest` as an unavoidable build dependency of ROOT if you have `fail-on-missin=ON`; 4. Respect `fail-on-missing`. Which of these constraints should be relaxed?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16612#issuecomment-2396463790
Modifiability,config,configuration,"That will be hard to respect, because that means unless we introduce a new `testsupport=OFF` configuration flag, gtest would always be a dependency of ROOT with `-fail-on-missing=ON` then. I don't see at the moment how I can respect all of these constraints:. 1. Keep configuration simple by not introducing new build flags; 2. Make `ROOT_ADD_GTEST` fully usable in downstream code even if ROOT was not built with unit tests; 3. Don't add `gtest` as an unavoidable build dependency of ROOT if you have `fail-on-missin=ON`; 4. Respect `fail-on-missing`. Which of these constraints should be relaxed?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16612#issuecomment-2396463790
Testability,test,testsupport,"That will be hard to respect, because that means unless we introduce a new `testsupport=OFF` configuration flag, gtest would always be a dependency of ROOT with `-fail-on-missing=ON` then. I don't see at the moment how I can respect all of these constraints:. 1. Keep configuration simple by not introducing new build flags; 2. Make `ROOT_ADD_GTEST` fully usable in downstream code even if ROOT was not built with unit tests; 3. Don't add `gtest` as an unavoidable build dependency of ROOT if you have `fail-on-missin=ON`; 4. Respect `fail-on-missing`. Which of these constraints should be relaxed?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16612#issuecomment-2396463790
Usability,simpl,simple,"That will be hard to respect, because that means unless we introduce a new `testsupport=OFF` configuration flag, gtest would always be a dependency of ROOT with `-fail-on-missing=ON` then. I don't see at the moment how I can respect all of these constraints:. 1. Keep configuration simple by not introducing new build flags; 2. Make `ROOT_ADD_GTEST` fully usable in downstream code even if ROOT was not built with unit tests; 3. Don't add `gtest` as an unavoidable build dependency of ROOT if you have `fail-on-missin=ON`; 4. Respect `fail-on-missing`. Which of these constraints should be relaxed?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16612#issuecomment-2396463790
Integrability,interface,interface,"@ktf (I can reproduce the problem now). Commit b2c6904bf458d5149e3955881d0054ba256a4110 seems to have broken the expectation of only one basket in flight, I also wonder how it interact with the interface, in particular, it is clear that this PR removes the crashs but does it lead to correct data being read through the bulk interface?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16640#issuecomment-2400792247
Usability,clear,clear,"@ktf (I can reproduce the problem now). Commit b2c6904bf458d5149e3955881d0054ba256a4110 seems to have broken the expectation of only one basket in flight, I also wonder how it interact with the interface, in particular, it is clear that this PR removes the crashs but does it lead to correct data being read through the bulk interface?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16640#issuecomment-2400792247
Deployability,patch,patch,"I was enabling SetClusterPrefetch as part of the attempt to reduce read_calls when processing our AODs. Indeed I now notice that it's enough to simply do:. ```C++; // Was affected by https://github.com/root-project/root/issues/8962; // Re-enabling this seems to cut the number of IOPS in half; tree->SetCacheSize(25000000);; //tree->SetClusterPrefetch(true);; for (auto& reader : mBranchReaders) {; tree->AddBranchToCache(reader->branch());; }; tree->StopCacheLearningPhase();; ```. to obtain the same result, so I am fine to simply disable it for now. Do I understand correctly that I still need this patch, though, in case there is more than one basket?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16640#issuecomment-2406804701
Energy Efficiency,reduce,reduce,"I was enabling SetClusterPrefetch as part of the attempt to reduce read_calls when processing our AODs. Indeed I now notice that it's enough to simply do:. ```C++; // Was affected by https://github.com/root-project/root/issues/8962; // Re-enabling this seems to cut the number of IOPS in half; tree->SetCacheSize(25000000);; //tree->SetClusterPrefetch(true);; for (auto& reader : mBranchReaders) {; tree->AddBranchToCache(reader->branch());; }; tree->StopCacheLearningPhase();; ```. to obtain the same result, so I am fine to simply disable it for now. Do I understand correctly that I still need this patch, though, in case there is more than one basket?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16640#issuecomment-2406804701
Usability,simpl,simply,"I was enabling SetClusterPrefetch as part of the attempt to reduce read_calls when processing our AODs. Indeed I now notice that it's enough to simply do:. ```C++; // Was affected by https://github.com/root-project/root/issues/8962; // Re-enabling this seems to cut the number of IOPS in half; tree->SetCacheSize(25000000);; //tree->SetClusterPrefetch(true);; for (auto& reader : mBranchReaders) {; tree->AddBranchToCache(reader->branch());; }; tree->StopCacheLearningPhase();; ```. to obtain the same result, so I am fine to simply disable it for now. Do I understand correctly that I still need this patch, though, in case there is more than one basket?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16640#issuecomment-2406804701
Energy Efficiency,reduce,reduce,> I was enabling SetClusterPrefetch as part of the attempt to reduce read_calls when processing our AODs. Apriori it does not intend have an effect on that. > Indeed I now notice that it's enough to simply do:. What is the change (increase of the cache size or explicit cache learning or both)?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16640#issuecomment-2406995100
Performance,cache,cache,> I was enabling SetClusterPrefetch as part of the attempt to reduce read_calls when processing our AODs. Apriori it does not intend have an effect on that. > Indeed I now notice that it's enough to simply do:. What is the change (increase of the cache size or explicit cache learning or both)?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16640#issuecomment-2406995100
Usability,simpl,simply,> I was enabling SetClusterPrefetch as part of the attempt to reduce read_calls when processing our AODs. Apriori it does not intend have an effect on that. > Indeed I now notice that it's enough to simply do:. What is the change (increase of the cache size or explicit cache learning or both)?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16640#issuecomment-2406995100
Performance,cache,cache,"> What is the change (increase of the cache size or explicit cache learning or both)?. Doing the caching at all. I thought prefetching was part of it, but apparently it is not.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16640#issuecomment-2407188475
Usability,learn,learning,"> What is the change (increase of the cache size or explicit cache learning or both)?. Doing the caching at all. I thought prefetching was part of it, but apparently it is not.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16640#issuecomment-2407188475
Deployability,upgrade,upgrades,"> (Most likely) To reproduce build with https://github.com/root-project/root/commit/3e03f7891c07828b32cf7efe4382202ecdca1a79 and then rebuild the same directory commit https://github.com/root-project/root/commit/7f006742bb1d1786d2a8c7c06e4e20cf8900e777 (llvm 18). Incremental rebuilds across LLVM upgrades are (intentionally) not supported - too many things move around. This has always been clearly communicated and I propose to close this issue as ""not planned"" (and I misclicked)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16668#issuecomment-2440788615
Usability,clear,clearly,"> (Most likely) To reproduce build with https://github.com/root-project/root/commit/3e03f7891c07828b32cf7efe4382202ecdca1a79 and then rebuild the same directory commit https://github.com/root-project/root/commit/7f006742bb1d1786d2a8c7c06e4e20cf8900e777 (llvm 18). Incremental rebuilds across LLVM upgrades are (intentionally) not supported - too many things move around. This has always been clearly communicated and I propose to close this issue as ""not planned"" (and I misclicked)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16668#issuecomment-2440788615
Usability,clear,clear,"You are right, extra boilerplate in the tutorials is not good. But This PR is not meant to me merged as is, I did it to explore why `ClearProxiedObjects()` is needed also for hard shutdown. And the set of code that I needed to add to the tutorials made to reason more or less clear: there is some issue with `TH1` specifically.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16671#issuecomment-2410483715
Security,access,access,"Looks good from my point of view, I'll let Jakob have the final say. One point we should clarify at some point (but doesn't need to block this PR) is how subfield access plays with writing: It intuitively makes sense for reading as you can just have the same value multiple times in memory. But I guess we only want to take the top-level fields from the entry for writing? Should we forbid creating a (parallel) writer passing a model with registered subfields?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16693#issuecomment-2443511035
Usability,intuit,intuitively,"Looks good from my point of view, I'll let Jakob have the final say. One point we should clarify at some point (but doesn't need to block this PR) is how subfield access plays with writing: It intuitively makes sense for reading as you can just have the same value multiple times in memory. But I guess we only want to take the top-level fields from the entry for writing? Should we forbid creating a (parallel) writer passing a model with registered subfields?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16693#issuecomment-2443511035
Security,access,access,"> Looks good from my point of view, I'll let Jakob have the final say. One point we should clarify at some point (but doesn't need to block this PR) is how subfield access plays with writing: It intuitively makes sense for reading as you can just have the same value multiple times in memory. But I guess we only want to take the top-level fields from the entry for writing? Should we forbid creating a (parallel) writer passing a model with registered subfields?. This is a very good point, I've only considered the reading side of things. I would be in favor of the last possibility and just completely disallow creating writers from models with registered subfields.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16693#issuecomment-2443706354
Usability,intuit,intuitively,"> Looks good from my point of view, I'll let Jakob have the final say. One point we should clarify at some point (but doesn't need to block this PR) is how subfield access plays with writing: It intuitively makes sense for reading as you can just have the same value multiple times in memory. But I guess we only want to take the top-level fields from the entry for writing? Should we forbid creating a (parallel) writer passing a model with registered subfields?. This is a very good point, I've only considered the reading side of things. I would be in favor of the last possibility and just completely disallow creating writers from models with registered subfields.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16693#issuecomment-2443706354
Availability,error,error,"The summary is simple (and still the same after applying [`38b0d88` (#16722)](https://github.com/root-project/root/pull/16722/commits/38b0d88d1d51fe914a6aff3645f03a483e31588a):. On first run in a clean directory with `BLAS` missing, we get:; ```; ctest -R gtest-tmva-pymva-TestRModelParserPyTorch; Test project /home/pcanal/root_working/build/quick-devel; Start 349: gtest-tmva-pymva-TestRModelParserPyTorch; 1/1 Test #349: gtest-tmva-pymva-TestRModelParserPyTorch ... Passed 16.11 sec. 100% tests passed, 0 tests failed out of 1. Total Test time (real) = 16.37 sec; ```; and if we immediately re-run we get:; ```; ctest -R gtest-tmva-pymva-TestRModelParserPyTorch; Test project /home/pcanal/root_working/build/quick-devel; Start 349: gtest-tmva-pymva-TestRModelParserPyTorch; 1/1 Test #349: gtest-tmva-pymva-TestRModelParserPyTorch ...***Failed 9.10 sec; ```; and the error is:; ```; [ RUN ] RModelParser_PyTorch.SEQUENTIAL_MODEL; IncrementalExecutor::executeFunction: symbol 'sgemm_' unresolved while linking [cling interface function]!; ```; indicates that on the 2nd runs, the test want symbols from the `BLAS` library.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16719#issuecomment-2427294206
Integrability,interface,interface,"The summary is simple (and still the same after applying [`38b0d88` (#16722)](https://github.com/root-project/root/pull/16722/commits/38b0d88d1d51fe914a6aff3645f03a483e31588a):. On first run in a clean directory with `BLAS` missing, we get:; ```; ctest -R gtest-tmva-pymva-TestRModelParserPyTorch; Test project /home/pcanal/root_working/build/quick-devel; Start 349: gtest-tmva-pymva-TestRModelParserPyTorch; 1/1 Test #349: gtest-tmva-pymva-TestRModelParserPyTorch ... Passed 16.11 sec. 100% tests passed, 0 tests failed out of 1. Total Test time (real) = 16.37 sec; ```; and if we immediately re-run we get:; ```; ctest -R gtest-tmva-pymva-TestRModelParserPyTorch; Test project /home/pcanal/root_working/build/quick-devel; Start 349: gtest-tmva-pymva-TestRModelParserPyTorch; 1/1 Test #349: gtest-tmva-pymva-TestRModelParserPyTorch ...***Failed 9.10 sec; ```; and the error is:; ```; [ RUN ] RModelParser_PyTorch.SEQUENTIAL_MODEL; IncrementalExecutor::executeFunction: symbol 'sgemm_' unresolved while linking [cling interface function]!; ```; indicates that on the 2nd runs, the test want symbols from the `BLAS` library.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16719#issuecomment-2427294206
Testability,test,tests,"The summary is simple (and still the same after applying [`38b0d88` (#16722)](https://github.com/root-project/root/pull/16722/commits/38b0d88d1d51fe914a6aff3645f03a483e31588a):. On first run in a clean directory with `BLAS` missing, we get:; ```; ctest -R gtest-tmva-pymva-TestRModelParserPyTorch; Test project /home/pcanal/root_working/build/quick-devel; Start 349: gtest-tmva-pymva-TestRModelParserPyTorch; 1/1 Test #349: gtest-tmva-pymva-TestRModelParserPyTorch ... Passed 16.11 sec. 100% tests passed, 0 tests failed out of 1. Total Test time (real) = 16.37 sec; ```; and if we immediately re-run we get:; ```; ctest -R gtest-tmva-pymva-TestRModelParserPyTorch; Test project /home/pcanal/root_working/build/quick-devel; Start 349: gtest-tmva-pymva-TestRModelParserPyTorch; 1/1 Test #349: gtest-tmva-pymva-TestRModelParserPyTorch ...***Failed 9.10 sec; ```; and the error is:; ```; [ RUN ] RModelParser_PyTorch.SEQUENTIAL_MODEL; IncrementalExecutor::executeFunction: symbol 'sgemm_' unresolved while linking [cling interface function]!; ```; indicates that on the 2nd runs, the test want symbols from the `BLAS` library.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16719#issuecomment-2427294206
Usability,simpl,simple,"The summary is simple (and still the same after applying [`38b0d88` (#16722)](https://github.com/root-project/root/pull/16722/commits/38b0d88d1d51fe914a6aff3645f03a483e31588a):. On first run in a clean directory with `BLAS` missing, we get:; ```; ctest -R gtest-tmva-pymva-TestRModelParserPyTorch; Test project /home/pcanal/root_working/build/quick-devel; Start 349: gtest-tmva-pymva-TestRModelParserPyTorch; 1/1 Test #349: gtest-tmva-pymva-TestRModelParserPyTorch ... Passed 16.11 sec. 100% tests passed, 0 tests failed out of 1. Total Test time (real) = 16.37 sec; ```; and if we immediately re-run we get:; ```; ctest -R gtest-tmva-pymva-TestRModelParserPyTorch; Test project /home/pcanal/root_working/build/quick-devel; Start 349: gtest-tmva-pymva-TestRModelParserPyTorch; 1/1 Test #349: gtest-tmva-pymva-TestRModelParserPyTorch ...***Failed 9.10 sec; ```; and the error is:; ```; [ RUN ] RModelParser_PyTorch.SEQUENTIAL_MODEL; IncrementalExecutor::executeFunction: symbol 'sgemm_' unresolved while linking [cling interface function]!; ```; indicates that on the 2nd runs, the test want symbols from the `BLAS` library.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16719#issuecomment-2427294206
Availability,failure,failure,"Yes, it is clearly a difference is setup. In the failing one the `BLAS` library is not installed (or not found) and the real problem is that this result in a very obscure and hard to understand failure:; ```; IncrementalExecutor::executeFunction: symbol 'saxpy_' unresolved while linking [cling interface function]!; IncrementalExecutor::executeFunction: symbol 'sgemm_' unresolved while linking [cling interface function]!; ```; Instead we should either; * fail to configure if BLAS is missing; or ; * disable the components that require BLAS when configuring whe BLAS is missing; or; * disable the test that require BLAS when BLAS is not there. and at the very least we should list somewhere (if not already done so, but I don't see it) that the `BLAS` library is required to successfully run the tests and some of the features.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16720#issuecomment-2425048725
Deployability,install,installed,"Yes, it is clearly a difference is setup. In the failing one the `BLAS` library is not installed (or not found) and the real problem is that this result in a very obscure and hard to understand failure:; ```; IncrementalExecutor::executeFunction: symbol 'saxpy_' unresolved while linking [cling interface function]!; IncrementalExecutor::executeFunction: symbol 'sgemm_' unresolved while linking [cling interface function]!; ```; Instead we should either; * fail to configure if BLAS is missing; or ; * disable the components that require BLAS when configuring whe BLAS is missing; or; * disable the test that require BLAS when BLAS is not there. and at the very least we should list somewhere (if not already done so, but I don't see it) that the `BLAS` library is required to successfully run the tests and some of the features.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16720#issuecomment-2425048725
Integrability,interface,interface,"Yes, it is clearly a difference is setup. In the failing one the `BLAS` library is not installed (or not found) and the real problem is that this result in a very obscure and hard to understand failure:; ```; IncrementalExecutor::executeFunction: symbol 'saxpy_' unresolved while linking [cling interface function]!; IncrementalExecutor::executeFunction: symbol 'sgemm_' unresolved while linking [cling interface function]!; ```; Instead we should either; * fail to configure if BLAS is missing; or ; * disable the components that require BLAS when configuring whe BLAS is missing; or; * disable the test that require BLAS when BLAS is not there. and at the very least we should list somewhere (if not already done so, but I don't see it) that the `BLAS` library is required to successfully run the tests and some of the features.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16720#issuecomment-2425048725
Modifiability,config,configure,"Yes, it is clearly a difference is setup. In the failing one the `BLAS` library is not installed (or not found) and the real problem is that this result in a very obscure and hard to understand failure:; ```; IncrementalExecutor::executeFunction: symbol 'saxpy_' unresolved while linking [cling interface function]!; IncrementalExecutor::executeFunction: symbol 'sgemm_' unresolved while linking [cling interface function]!; ```; Instead we should either; * fail to configure if BLAS is missing; or ; * disable the components that require BLAS when configuring whe BLAS is missing; or; * disable the test that require BLAS when BLAS is not there. and at the very least we should list somewhere (if not already done so, but I don't see it) that the `BLAS` library is required to successfully run the tests and some of the features.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16720#issuecomment-2425048725
Testability,test,test,"Yes, it is clearly a difference is setup. In the failing one the `BLAS` library is not installed (or not found) and the real problem is that this result in a very obscure and hard to understand failure:; ```; IncrementalExecutor::executeFunction: symbol 'saxpy_' unresolved while linking [cling interface function]!; IncrementalExecutor::executeFunction: symbol 'sgemm_' unresolved while linking [cling interface function]!; ```; Instead we should either; * fail to configure if BLAS is missing; or ; * disable the components that require BLAS when configuring whe BLAS is missing; or; * disable the test that require BLAS when BLAS is not there. and at the very least we should list somewhere (if not already done so, but I don't see it) that the `BLAS` library is required to successfully run the tests and some of the features.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16720#issuecomment-2425048725
Usability,clear,clearly,"Yes, it is clearly a difference is setup. In the failing one the `BLAS` library is not installed (or not found) and the real problem is that this result in a very obscure and hard to understand failure:; ```; IncrementalExecutor::executeFunction: symbol 'saxpy_' unresolved while linking [cling interface function]!; IncrementalExecutor::executeFunction: symbol 'sgemm_' unresolved while linking [cling interface function]!; ```; Instead we should either; * fail to configure if BLAS is missing; or ; * disable the components that require BLAS when configuring whe BLAS is missing; or; * disable the test that require BLAS when BLAS is not there. and at the very least we should list somewhere (if not already done so, but I don't see it) that the `BLAS` library is required to successfully run the tests and some of the features.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16720#issuecomment-2425048725
Testability,log,log,"OK, so simply disabling the `LOG_CONFIGURE`, `LOG_BUILD`, `LOG_INSTALL` when using `CONFIGURE_COMMAND`, `BUILD_COMMNAD`, `INSTALL_COMMAND` seems to fix the issue (i.e. no `BUILD_JOB_SERVER_AWARE` involved), but then we have no log...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16733#issuecomment-2435320448
Usability,simpl,simply,"OK, so simply disabling the `LOG_CONFIGURE`, `LOG_BUILD`, `LOG_INSTALL` when using `CONFIGURE_COMMAND`, `BUILD_COMMNAD`, `INSTALL_COMMAND` seems to fix the issue (i.e. no `BUILD_JOB_SERVER_AWARE` involved), but then we have no log...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16733#issuecomment-2435320448
Availability,error,errors,"Typically, disparate errors that are all kinda the same mean an error was set prior by some other operation and not cleared. What then happens is that the next (any) Python operation fails, setting its own error. This is something that's new:; ```; +Exception ignored in PyObject_HasAttr(); consider using PyObject_HasAttrWithError(), PyObject_GetOptionalAttr() or PyObject_GetAttr():; ```; and may help narrow it down.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16748#issuecomment-2442692217
Usability,clear,cleared,"Typically, disparate errors that are all kinda the same mean an error was set prior by some other operation and not cleared. What then happens is that the next (any) Python operation fails, setting its own error. This is something that's new:; ```; +Exception ignored in PyObject_HasAttr(); consider using PyObject_HasAttrWithError(), PyObject_GetOptionalAttr() or PyObject_GetAttr():; ```; and may help narrow it down.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16748#issuecomment-2442692217
Energy Efficiency,allocate,allocate,"Some other fields try to get this right, for example `RRecordField`. We should investigate if we can make `std::vector<char>` allocate over-aligned memory areas. The other option is to forbid over-aligned types (and possibly simplify some other code).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16757#issuecomment-2440928601
Usability,simpl,simplify,"Some other fields try to get this right, for example `RRecordField`. We should investigate if we can make `std::vector<char>` allocate over-aligned memory areas. The other option is to forbid over-aligned types (and possibly simplify some other code).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16757#issuecomment-2440928601
Usability,feedback,feedback,@GiacomoXT thanks for the feedback. Let us know how that goes!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16774#issuecomment-2447782541
Deployability,release,release,"Oh. Missed GetCumulative. The thing that probably bothers me is the description of GetQuantiles or rather what is the use case of GetQuantiles with p==nullptr. When you say ""If p is null, it calculates F-1(F(bin_edges)) = bin_edges"", the bin_edges are already known (if it really calculates them inside, that is quite surprising). The really new thing (although maybe not a product, but side-effect) is the p. I understand that removing the default would break backward compatibility, so I am not advocating just removing the thing in the next release. It's just that if there is a default argument, normally it represents a frequent use case, so it brings attention while learning about a given method. Here it brings confusion (to me and to my student at least).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16784#issuecomment-2444638572
Usability,learn,learning,"Oh. Missed GetCumulative. The thing that probably bothers me is the description of GetQuantiles or rather what is the use case of GetQuantiles with p==nullptr. When you say ""If p is null, it calculates F-1(F(bin_edges)) = bin_edges"", the bin_edges are already known (if it really calculates them inside, that is quite surprising). The really new thing (although maybe not a product, but side-effect) is the p. I understand that removing the default would break backward compatibility, so I am not advocating just removing the thing in the next release. It's just that if there is a default argument, normally it represents a frequent use case, so it brings attention while learning about a given method. Here it brings confusion (to me and to my student at least).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16784#issuecomment-2444638572
Modifiability,variab,variable,"> he really new thing (although maybe not a product, but side-effect) is the p. But p stays null. F(x) is stored to a temporary variable, p is not set to F(x). > (if it really calculates them inside, that is quite surprising). It does. It's a technical workaround to have both paths to follow the same code. > It's just that if there is a default argument, normally it represents a frequent use case, so it brings attention while learning about a given method. Here it brings confusion (to me and to my student at least). I agree with you. So I would suggest to remove from your title ""add new method to handle this case"".; Making it non-default would force everyone to pass an argument. If one wants the old behavior, it will pass nullptr and get the bin edges as before, so no new extra method is needed.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16784#issuecomment-2444656410
Usability,learn,learning,"> he really new thing (although maybe not a product, but side-effect) is the p. But p stays null. F(x) is stored to a temporary variable, p is not set to F(x). > (if it really calculates them inside, that is quite surprising). It does. It's a technical workaround to have both paths to follow the same code. > It's just that if there is a default argument, normally it represents a frequent use case, so it brings attention while learning about a given method. Here it brings confusion (to me and to my student at least). I agree with you. So I would suggest to remove from your title ""add new method to handle this case"".; Making it non-default would force everyone to pass an argument. If one wants the old behavior, it will pass nullptr and get the bin edges as before, so no new extra method is needed.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16784#issuecomment-2444656410
Modifiability,evolve,evolve,"> @dpiparo, since you wrote this code last year: #13532; > ; > You have any idea why `Py_GetProgramName` was necessary?. I think I was simply trying to evolve the existing Python 2 code existing at the time, there is no sophisticated strategy behind. If the usage of the deprecated function can be avoided, great.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16785#issuecomment-2446725220
Safety,avoid,avoided,"> @dpiparo, since you wrote this code last year: #13532; > ; > You have any idea why `Py_GetProgramName` was necessary?. I think I was simply trying to evolve the existing Python 2 code existing at the time, there is no sophisticated strategy behind. If the usage of the deprecated function can be avoided, great.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16785#issuecomment-2446725220
Usability,simpl,simply,"> @dpiparo, since you wrote this code last year: #13532; > ; > You have any idea why `Py_GetProgramName` was necessary?. I think I was simply trying to evolve the existing Python 2 code existing at the time, there is no sophisticated strategy behind. If the usage of the deprecated function can be avoided, great.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16785#issuecomment-2446725220
Energy Efficiency,power,power,"@vepadulano the idea here is to separate ""regular"" users just using the RNTuple API from ""power"" users that want to reimplement parts thereof. I'm admittedly not sure if that's a clear enough distinction to warrant the use of the `Internal` namespace; we certainly want the public API to guide the regular user as much as possible to the correct usage of RNTuple and I think ""power"" users are fine with navigating the internals if they need to solve a very specific problem. ; I don't know if @jblomer has more to say about this, but I don't have a strong opinion either way.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16786#issuecomment-2446318660
Usability,clear,clear,"@vepadulano the idea here is to separate ""regular"" users just using the RNTuple API from ""power"" users that want to reimplement parts thereof. I'm admittedly not sure if that's a clear enough distinction to warrant the use of the `Internal` namespace; we certainly want the public API to guide the regular user as much as possible to the correct usage of RNTuple and I think ""power"" users are fine with navigating the internals if they need to solve a very specific problem. ; I don't know if @jblomer has more to say about this, but I don't have a strong opinion either way.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16786#issuecomment-2446318660
