id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/root-project/root/pull/2:543,Availability,Error,Error,543,"So here are the changes that I needed to make from the comments of the last pull request and some other changes:; 1) I've added the name for a enum constant because I realised when declaring kMyConstant = 42 that I didn't save the name.; 2) I've added some checks in the TCling to see if the TEnum and TEnumConstants are actually created, because when I run the test:; // MyEnumComment; enum EMyEnum {; kMyEnumConstant = 42 // enumConstantComment; };. int assertTEnum(); {. ```; if (!(TEnum*)gROOT->GetListOfEnums()->FindObject(""EMyEnum"")) {; Error (""TEnum"", ""Constructor of TEnum failure."");; return -1;; ```. }; It does return and Error. I tried that on the root[0] promp as well and the address of GetListOfEnum is not NULL(because the HashTable is created), but the address of FindObject is 0x0. ; Now I don't get the Errors of TEnum and TEnumConstant are not created..I wanted to check whether they are added to the fEnums and fGlobals, but Add() for TCollection is a void function. My best guess is that they are not added to the lists, maybe you can see why...",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/2
https://github.com/root-project/root/pull/2:581,Availability,failure,failure,581,"So here are the changes that I needed to make from the comments of the last pull request and some other changes:; 1) I've added the name for a enum constant because I realised when declaring kMyConstant = 42 that I didn't save the name.; 2) I've added some checks in the TCling to see if the TEnum and TEnumConstants are actually created, because when I run the test:; // MyEnumComment; enum EMyEnum {; kMyEnumConstant = 42 // enumConstantComment; };. int assertTEnum(); {. ```; if (!(TEnum*)gROOT->GetListOfEnums()->FindObject(""EMyEnum"")) {; Error (""TEnum"", ""Constructor of TEnum failure."");; return -1;; ```. }; It does return and Error. I tried that on the root[0] promp as well and the address of GetListOfEnum is not NULL(because the HashTable is created), but the address of FindObject is 0x0. ; Now I don't get the Errors of TEnum and TEnumConstant are not created..I wanted to check whether they are added to the fEnums and fGlobals, but Add() for TCollection is a void function. My best guess is that they are not added to the lists, maybe you can see why...",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/2
https://github.com/root-project/root/pull/2:633,Availability,Error,Error,633,"So here are the changes that I needed to make from the comments of the last pull request and some other changes:; 1) I've added the name for a enum constant because I realised when declaring kMyConstant = 42 that I didn't save the name.; 2) I've added some checks in the TCling to see if the TEnum and TEnumConstants are actually created, because when I run the test:; // MyEnumComment; enum EMyEnum {; kMyEnumConstant = 42 // enumConstantComment; };. int assertTEnum(); {. ```; if (!(TEnum*)gROOT->GetListOfEnums()->FindObject(""EMyEnum"")) {; Error (""TEnum"", ""Constructor of TEnum failure."");; return -1;; ```. }; It does return and Error. I tried that on the root[0] promp as well and the address of GetListOfEnum is not NULL(because the HashTable is created), but the address of FindObject is 0x0. ; Now I don't get the Errors of TEnum and TEnumConstant are not created..I wanted to check whether they are added to the fEnums and fGlobals, but Add() for TCollection is a void function. My best guess is that they are not added to the lists, maybe you can see why...",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/2
https://github.com/root-project/root/pull/2:822,Availability,Error,Errors,822,"So here are the changes that I needed to make from the comments of the last pull request and some other changes:; 1) I've added the name for a enum constant because I realised when declaring kMyConstant = 42 that I didn't save the name.; 2) I've added some checks in the TCling to see if the TEnum and TEnumConstants are actually created, because when I run the test:; // MyEnumComment; enum EMyEnum {; kMyEnumConstant = 42 // enumConstantComment; };. int assertTEnum(); {. ```; if (!(TEnum*)gROOT->GetListOfEnums()->FindObject(""EMyEnum"")) {; Error (""TEnum"", ""Constructor of TEnum failure."");; return -1;; ```. }; It does return and Error. I tried that on the root[0] promp as well and the address of GetListOfEnum is not NULL(because the HashTable is created), but the address of FindObject is 0x0. ; Now I don't get the Errors of TEnum and TEnumConstant are not created..I wanted to check whether they are added to the fEnums and fGlobals, but Add() for TCollection is a void function. My best guess is that they are not added to the lists, maybe you can see why...",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/2
https://github.com/root-project/root/pull/2:739,Security,Hash,HashTable,739,"So here are the changes that I needed to make from the comments of the last pull request and some other changes:; 1) I've added the name for a enum constant because I realised when declaring kMyConstant = 42 that I didn't save the name.; 2) I've added some checks in the TCling to see if the TEnum and TEnumConstants are actually created, because when I run the test:; // MyEnumComment; enum EMyEnum {; kMyEnumConstant = 42 // enumConstantComment; };. int assertTEnum(); {. ```; if (!(TEnum*)gROOT->GetListOfEnums()->FindObject(""EMyEnum"")) {; Error (""TEnum"", ""Constructor of TEnum failure."");; return -1;; ```. }; It does return and Error. I tried that on the root[0] promp as well and the address of GetListOfEnum is not NULL(because the HashTable is created), but the address of FindObject is 0x0. ; Now I don't get the Errors of TEnum and TEnumConstant are not created..I wanted to check whether they are added to the fEnums and fGlobals, but Add() for TCollection is a void function. My best guess is that they are not added to the lists, maybe you can see why...",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/2
https://github.com/root-project/root/pull/2:362,Testability,test,test,362,"So here are the changes that I needed to make from the comments of the last pull request and some other changes:; 1) I've added the name for a enum constant because I realised when declaring kMyConstant = 42 that I didn't save the name.; 2) I've added some checks in the TCling to see if the TEnum and TEnumConstants are actually created, because when I run the test:; // MyEnumComment; enum EMyEnum {; kMyEnumConstant = 42 // enumConstantComment; };. int assertTEnum(); {. ```; if (!(TEnum*)gROOT->GetListOfEnums()->FindObject(""EMyEnum"")) {; Error (""TEnum"", ""Constructor of TEnum failure."");; return -1;; ```. }; It does return and Error. I tried that on the root[0] promp as well and the address of GetListOfEnum is not NULL(because the HashTable is created), but the address of FindObject is 0x0. ; Now I don't get the Errors of TEnum and TEnumConstant are not created..I wanted to check whether they are added to the fEnums and fGlobals, but Add() for TCollection is a void function. My best guess is that they are not added to the lists, maybe you can see why...",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/2
https://github.com/root-project/root/pull/2:456,Testability,assert,assertTEnum,456,"So here are the changes that I needed to make from the comments of the last pull request and some other changes:; 1) I've added the name for a enum constant because I realised when declaring kMyConstant = 42 that I didn't save the name.; 2) I've added some checks in the TCling to see if the TEnum and TEnumConstants are actually created, because when I run the test:; // MyEnumComment; enum EMyEnum {; kMyEnumConstant = 42 // enumConstantComment; };. int assertTEnum(); {. ```; if (!(TEnum*)gROOT->GetListOfEnums()->FindObject(""EMyEnum"")) {; Error (""TEnum"", ""Constructor of TEnum failure."");; return -1;; ```. }; It does return and Error. I tried that on the root[0] promp as well and the address of GetListOfEnum is not NULL(because the HashTable is created), but the address of FindObject is 0x0. ; Now I don't get the Errors of TEnum and TEnumConstant are not created..I wanted to check whether they are added to the fEnums and fGlobals, but Add() for TCollection is a void function. My best guess is that they are not added to the lists, maybe you can see why...",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/2
https://github.com/root-project/root/pull/4:128,Availability,Recover,RecoveryPath,128,"... and TCling__SplitAclicMode. The FileNotFound() method of TPPClingCallbacks is called via; Callbacks->FileNotFound(Filename, RecoveryPath) in; Preprocessor::HandleIncludeDirective(), allowing to compile code via; ACLiC when specifying #include ""myfile.C+"", and hence suppressing; preprocessor error message like:; input_line_23:1:10: fatal error: 'myfile.C+' file not found",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4
https://github.com/root-project/root/pull/4:296,Availability,error,error,296,"... and TCling__SplitAclicMode. The FileNotFound() method of TPPClingCallbacks is called via; Callbacks->FileNotFound(Filename, RecoveryPath) in; Preprocessor::HandleIncludeDirective(), allowing to compile code via; ACLiC when specifying #include ""myfile.C+"", and hence suppressing; preprocessor error message like:; input_line_23:1:10: fatal error: 'myfile.C+' file not found",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4
https://github.com/root-project/root/pull/4:343,Availability,error,error,343,"... and TCling__SplitAclicMode. The FileNotFound() method of TPPClingCallbacks is called via; Callbacks->FileNotFound(Filename, RecoveryPath) in; Preprocessor::HandleIncludeDirective(), allowing to compile code via; ACLiC when specifying #include ""myfile.C+"", and hence suppressing; preprocessor error message like:; input_line_23:1:10: fatal error: 'myfile.C+' file not found",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4
https://github.com/root-project/root/pull/4:302,Integrability,message,message,302,"... and TCling__SplitAclicMode. The FileNotFound() method of TPPClingCallbacks is called via; Callbacks->FileNotFound(Filename, RecoveryPath) in; Preprocessor::HandleIncludeDirective(), allowing to compile code via; ACLiC when specifying #include ""myfile.C+"", and hence suppressing; preprocessor error message like:; input_line_23:1:10: fatal error: 'myfile.C+' file not found",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4
https://github.com/root-project/root/pull/4:128,Safety,Recover,RecoveryPath,128,"... and TCling__SplitAclicMode. The FileNotFound() method of TPPClingCallbacks is called via; Callbacks->FileNotFound(Filename, RecoveryPath) in; Preprocessor::HandleIncludeDirective(), allowing to compile code via; ACLiC when specifying #include ""myfile.C+"", and hence suppressing; preprocessor error message like:; input_line_23:1:10: fatal error: 'myfile.C+' file not found",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4
https://github.com/root-project/root/pull/11:12,Safety,avoid,avoid,12,"In order to avoid thread-safety issues, the static class member; TClass::fgCallingNew is no longer a class member and is instead; a file scoped static declared thread_local. It was necessary to; not have it is a class member since CINT could not parse the new; thread_local keyword.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11
https://github.com/root-project/root/pull/11:25,Safety,safe,safety,25,"In order to avoid thread-safety issues, the static class member; TClass::fgCallingNew is no longer a class member and is instead; a file scoped static declared thread_local. It was necessary to; not have it is a class member since CINT could not parse the new; thread_local keyword.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11
https://github.com/root-project/root/pull/12:7,Safety,safe,safe,7,Thread-safe changes specifically affecting reading/writing different ROOT files from different threads. These changes require the use of C++11.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12
https://github.com/root-project/root/pull/13:157,Integrability,Depend,Depends,157,Fixes a problem with using genreflex to create a dictionary for a class that inherits from TObject. The problem was triggered by the thread-safety changes.; Depends on previous pull request (#12).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13
https://github.com/root-project/root/pull/13:77,Modifiability,inherit,inherits,77,Fixes a problem with using genreflex to create a dictionary for a class that inherits from TObject. The problem was triggered by the thread-safety changes.; Depends on previous pull request (#12).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13
https://github.com/root-project/root/pull/13:140,Safety,safe,safety,140,Fixes a problem with using genreflex to create a dictionary for a class that inherits from TObject. The problem was triggered by the thread-safety changes.; Depends on previous pull request (#12).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/13
https://github.com/root-project/root/pull/15:68,Integrability,message,message,68,- fix ROOTTest executions problem : remove failed word from warning message; - gridMode considers now CAPath correctly; - correct problem related to X509_CERT_DIR and gridmode,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/15
https://github.com/root-project/root/pull/16:68,Integrability,message,message,68,- fix ROOTTest executions problem : remove failed word from warning message; - gridMode considers now CAPath correctly; - correct problem related to X509_CERT_DIR and gridmode,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16
https://github.com/root-project/root/pull/19:61,Availability,error,errors,61,Summary of the changes in Vc 0.7.4:; - fixed several compile errors / warnings with newer or old C++; compilers; - support clean compilation with more -W flags; - fixed compilation when compiling without optimization; - added operator-- to Vector<T>; - Copying Memory now uses SIMD move instructions; - Vc::Allocator<T> now uses a minimum alignment of the SIMD types of; the chosen Vc implementation. Thus making it useable for containers of; builtin types. Signed-off-by: Matthias Kretz kretz@kde.org,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/19
https://github.com/root-project/root/pull/19:204,Performance,optimiz,optimization,204,Summary of the changes in Vc 0.7.4:; - fixed several compile errors / warnings with newer or old C++; compilers; - support clean compilation with more -W flags; - fixed compilation when compiling without optimization; - added operator-- to Vector<T>; - Copying Memory now uses SIMD move instructions; - Vc::Allocator<T> now uses a minimum alignment of the SIMD types of; the chosen Vc implementation. Thus making it useable for containers of; builtin types. Signed-off-by: Matthias Kretz kretz@kde.org,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/19
https://github.com/root-project/root/pull/20:19,Modifiability,variab,variables,19,Changed all static variables which were only being used as local variables to be local variables. This avoids threading problems.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/20
https://github.com/root-project/root/pull/20:65,Modifiability,variab,variables,65,Changed all static variables which were only being used as local variables to be local variables. This avoids threading problems.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/20
https://github.com/root-project/root/pull/20:87,Modifiability,variab,variables,87,Changed all static variables which were only being used as local variables to be local variables. This avoids threading problems.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/20
https://github.com/root-project/root/pull/20:103,Safety,avoid,avoids,103,Changed all static variables which were only being used as local variables to be local variables. This avoids threading problems.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/20
https://github.com/root-project/root/pull/23:30,Deployability,patch,patches,30,These are changes for 5-34-00-patches branch,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/23
https://github.com/root-project/root/pull/24:77,Performance,concurren,concurrent,77,The list returned from TROOT::GetListOfFunctions needs to be protected; from concurrent access to allow use of TFormulas on different; threads.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/24
https://github.com/root-project/root/pull/24:88,Security,access,access,88,The list returned from TROOT::GetListOfFunctions needs to be protected; from concurrent access to allow use of TFormulas on different; threads.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/24
https://github.com/root-project/root/pull/25:251,Performance,multi-thread,multi-threaded,251,"It is now possible to create independent TMVA::Readers and use; them simultaneously on different threads.; Training of MVAs is still only safe single-threaded. In addition,; it is not safe to use multiple instances of MethodCFMlpANN either; single or multi-threaded because of a global 'this' pointer.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/25
https://github.com/root-project/root/pull/25:138,Safety,safe,safe,138,"It is now possible to create independent TMVA::Readers and use; them simultaneously on different threads.; Training of MVAs is still only safe single-threaded. In addition,; it is not safe to use multiple instances of MethodCFMlpANN either; single or multi-threaded because of a global 'this' pointer.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/25
https://github.com/root-project/root/pull/25:184,Safety,safe,safe,184,"It is now possible to create independent TMVA::Readers and use; them simultaneously on different threads.; Training of MVAs is still only safe single-threaded. In addition,; it is not safe to use multiple instances of MethodCFMlpANN either; single or multi-threaded because of a global 'this' pointer.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/25
https://github.com/root-project/root/pull/27:29,Safety,safe,safely,29,Additional changes needed to safely use different TFormula on different threads while I/O is occurring on another thread.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/27
https://github.com/root-project/root/pull/28:138,Performance,concurren,concurrently,138,Caching and initialization of TClass::fIsAMethod have been changed; to make them thread safe and for calls to the TMethodCall can happen; concurrently.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/28
https://github.com/root-project/root/pull/28:88,Safety,safe,safe,88,Caching and initialization of TClass::fIsAMethod have been changed; to make them thread safe and for calls to the TMethodCall can happen; concurrently.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/28
https://github.com/root-project/root/pull/29:449,Availability,failure,failure,449,See the following 5 years old commit in Clang:. ```; https://github.com/llvm-mirror/clang/commit/; a78c5c34fbd20fde02261c3f3e21933cd58fcc04; ```. Clang forces '(' token after reference to dtor. Reflex uses an extra; parentheses around dtor reference. It force Clang 3.5 to diagnose and fail. A thread in cfe-dev (Clang) mainling-list was started:. ```; http://lists.cs.uiuc.edu/pipermail/cfe-dev/; 2014-October/039371.html; ```. The following fixes failure in CMSSW with Clang 3.5: https://cmssdt.cern.ch/SDT/cgi-bin/buildlogs/slc6_amd64_gcc481/CMSSW_7_3_CLANG_X_2014-10-01-0200/AnalysisDataFormats/TopObjects. Signed-off-by: David Abdurachmanov davidlt@cern.ch,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/29
https://github.com/root-project/root/pull/31:67,Safety,safe,safely,67,"TFormula indirectly accesses gROOT->fGlobalFunctions. Therefore to safely call different TFormula on different threads, access to the global function list must be serialized.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/31
https://github.com/root-project/root/pull/31:20,Security,access,accesses,20,"TFormula indirectly accesses gROOT->fGlobalFunctions. Therefore to safely call different TFormula on different threads, access to the global function list must be serialized.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/31
https://github.com/root-project/root/pull/31:120,Security,access,access,120,"TFormula indirectly accesses gROOT->fGlobalFunctions. Therefore to safely call different TFormula on different threads, access to the global function list must be serialized.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/31
https://github.com/root-project/root/pull/32:340,Availability,error,error,340,"These changes fix a periodic crash which was occuring while running the threaded version of CMS' reconstruction code. The problem was a bad interaction between rebinning of a TProfile while being filled and the cloning of a TFormula. The problem stemmed from insufficient locking of cint data structures.; As part of the change, additional error reporting for the case where cloning fails was added. These reports were extremely useful in tracking down the problem and may prove useful in the future if a similar problem surfaces again.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/32
https://github.com/root-project/root/pull/32:448,Availability,down,down,448,"These changes fix a periodic crash which was occuring while running the threaded version of CMS' reconstruction code. The problem was a bad interaction between rebinning of a TProfile while being filled and the cloning of a TFormula. The problem stemmed from insufficient locking of cint data structures.; As part of the change, additional error reporting for the case where cloning fails was added. These reports were extremely useful in tracking down the problem and may prove useful in the future if a similar problem surfaces again.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/32
https://github.com/root-project/root/pull/33:55,Deployability,update,updates,55,Helgrind found that TCint::CallFunc_Factory indirectly updates; global cint state. Therefore one must take the cint lock before; calling the function. This was the only place (other than; TSelectorCint::Build) which calls this function without first; taking the lock.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/33
https://github.com/root-project/root/pull/34:22,Performance,cache,cache,22,"When using C++11, the cache used by G__FastAllocString utilizes; a non-locking thread safe circular buffer.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/34
https://github.com/root-project/root/pull/34:86,Safety,safe,safe,86,"When using C++11, the cache used by G__FastAllocString utilizes; a non-locking thread safe circular buffer.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/34
https://github.com/root-project/root/pull/37:176,Availability,error,error,176,"1. Equip TCanvas::Streamer to provide data members information for TBufferJSON/TBufferXML/TBufferSQL2 classes; 2. Fix problem with streamer infos reading from TXMLFile; 3. Fix error in TBufferXML/TBufferJSON/TBufferSQL2 when equipted streamers are used; Reported also here: http://root.cern.ch/phpBB3/viewtopic.php?f=3&t=18802; Error was introduced by modifications in I/O between 5-34/19 and 5-34/20; 4. Implement TBufferJSON::CheckObject(), enable correct storage of colors palete in JSON with TCanvas; 5. Provide missing documentation for some methods in TBufferXML/TBufferSQL2/TBufferJSON; 6. Modification in THttpServer class - one could now access any objects memeber; 7. Significant redesign of JSROOT - now everything can be redrawn and resize",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/37
https://github.com/root-project/root/pull/37:328,Availability,Error,Error,328,"1. Equip TCanvas::Streamer to provide data members information for TBufferJSON/TBufferXML/TBufferSQL2 classes; 2. Fix problem with streamer infos reading from TXMLFile; 3. Fix error in TBufferXML/TBufferJSON/TBufferSQL2 when equipted streamers are used; Reported also here: http://root.cern.ch/phpBB3/viewtopic.php?f=3&t=18802; Error was introduced by modifications in I/O between 5-34/19 and 5-34/20; 4. Implement TBufferJSON::CheckObject(), enable correct storage of colors palete in JSON with TCanvas; 5. Provide missing documentation for some methods in TBufferXML/TBufferSQL2/TBufferJSON; 6. Modification in THttpServer class - one could now access any objects memeber; 7. Significant redesign of JSROOT - now everything can be redrawn and resize",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/37
https://github.com/root-project/root/pull/37:647,Security,access,access,647,"1. Equip TCanvas::Streamer to provide data members information for TBufferJSON/TBufferXML/TBufferSQL2 classes; 2. Fix problem with streamer infos reading from TXMLFile; 3. Fix error in TBufferXML/TBufferJSON/TBufferSQL2 when equipted streamers are used; Reported also here: http://root.cern.ch/phpBB3/viewtopic.php?f=3&t=18802; Error was introduced by modifications in I/O between 5-34/19 and 5-34/20; 4. Implement TBufferJSON::CheckObject(), enable correct storage of colors palete in JSON with TCanvas; 5. Provide missing documentation for some methods in TBufferXML/TBufferSQL2/TBufferJSON; 6. Modification in THttpServer class - one could now access any objects memeber; 7. Significant redesign of JSROOT - now everything can be redrawn and resize",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/37
https://github.com/root-project/root/pull/38:49,Performance,concurren,concurrent,49,Use the gRootMutex to protect access to possible concurrent accesses; to gROOT->GetListOfFiles().,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/38
https://github.com/root-project/root/pull/38:30,Security,access,access,30,Use the gRootMutex to protect access to possible concurrent accesses; to gROOT->GetListOfFiles().,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/38
https://github.com/root-project/root/pull/38:60,Security,access,accesses,60,Use the gRootMutex to protect access to possible concurrent accesses; to gROOT->GetListOfFiles().,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/38
https://github.com/root-project/root/pull/39:281,Deployability,patch,patch,281,"Hi,. I added 2 convenient methods for TGraph:; - AppendPoint adds a new point at the ""end"" of the graph.; - RemoveAllPoints calls RemovePoint(0) until there are no points left. This probably could also be done (faster) by deleting the fX and fY arrays, so feel free to change this patch. Benni",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/39
https://github.com/root-project/root/pull/40:1710,Availability,avail,available,1710,"iz/libcmaes), a novel high performance C++11 (with Python bindings) library for blackbox optimization. The new minimizer yields better results than Minuit2 for most problems, though for an higher computation cost on average. See below for links to relevant benchmarks backing up these claims. This implementation is on behalf of [Inria Saclay Research group TAO](http://www.inria.fr/en/teams/tao), [Laboratoire de l'Accelerateur Lineaire, group AppStat](http://appstat.lal.in2p3.fr/) and [University Paris-Sud LRI](https://www.lri.fr/index_en.php?lang=EN). ===Features===; - Seamless replacement for Minuit, Minuit2 and Fumili; - Seamless support for RooFit; - Relying on libcmaes allows for best performances known for CMA-ES + access to several flavors of the original algorithm, yielding best results with a trade off for computational cost, as needed; - Compilation support for both Autotools and CMake; - Included tutorial files, tests, and a special benchmark vs Minuit2. ===Documentation===; - Main documentation for building and using the new minimizer is here: https://github.com/beniz/libcmaes/wiki/using-CMA-ES-in-CERN's-ROOT. ===Performances===; - On-par with Minuit2 on low dimensional problems (< 10-D), consistently beats Minuit2 in higher dimension, leading to better fits. These claims are backed by two benchmarks and two experiments on real world data (we are still waiting from some results from usage at CERN); - Benchmark CMA-ES vs Minuit on [BBOB](http://coco.gforge.inria.fr/doku.php?id=bbob-2013) available here: https://drive.google.com/open?id=0B3J1vWYhta9ibktXc2JLRUExUTA&authuser=0; - In-ROOT benchmark vs Minuit2 on low-dimensional problems, results available here: https://drive.google.com/open?id=0B3J1vWYhta9iTmR0T0hnN21lSGM&authuser=0; - Beats out Minuit2 up to 98% of the time on some experiments (data + code available on demand from Auger group, ask me). I am available for help in testing and possibly integrating and maintaining this addition, just let me know.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:1868,Availability,avail,available,1868,"iz/libcmaes), a novel high performance C++11 (with Python bindings) library for blackbox optimization. The new minimizer yields better results than Minuit2 for most problems, though for an higher computation cost on average. See below for links to relevant benchmarks backing up these claims. This implementation is on behalf of [Inria Saclay Research group TAO](http://www.inria.fr/en/teams/tao), [Laboratoire de l'Accelerateur Lineaire, group AppStat](http://appstat.lal.in2p3.fr/) and [University Paris-Sud LRI](https://www.lri.fr/index_en.php?lang=EN). ===Features===; - Seamless replacement for Minuit, Minuit2 and Fumili; - Seamless support for RooFit; - Relying on libcmaes allows for best performances known for CMA-ES + access to several flavors of the original algorithm, yielding best results with a trade off for computational cost, as needed; - Compilation support for both Autotools and CMake; - Included tutorial files, tests, and a special benchmark vs Minuit2. ===Documentation===; - Main documentation for building and using the new minimizer is here: https://github.com/beniz/libcmaes/wiki/using-CMA-ES-in-CERN's-ROOT. ===Performances===; - On-par with Minuit2 on low dimensional problems (< 10-D), consistently beats Minuit2 in higher dimension, leading to better fits. These claims are backed by two benchmarks and two experiments on real world data (we are still waiting from some results from usage at CERN); - Benchmark CMA-ES vs Minuit on [BBOB](http://coco.gforge.inria.fr/doku.php?id=bbob-2013) available here: https://drive.google.com/open?id=0B3J1vWYhta9ibktXc2JLRUExUTA&authuser=0; - In-ROOT benchmark vs Minuit2 on low-dimensional problems, results available here: https://drive.google.com/open?id=0B3J1vWYhta9iTmR0T0hnN21lSGM&authuser=0; - Beats out Minuit2 up to 98% of the time on some experiments (data + code available on demand from Auger group, ask me). I am available for help in testing and possibly integrating and maintaining this addition, just let me know.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:2033,Availability,avail,available,2033,"iz/libcmaes), a novel high performance C++11 (with Python bindings) library for blackbox optimization. The new minimizer yields better results than Minuit2 for most problems, though for an higher computation cost on average. See below for links to relevant benchmarks backing up these claims. This implementation is on behalf of [Inria Saclay Research group TAO](http://www.inria.fr/en/teams/tao), [Laboratoire de l'Accelerateur Lineaire, group AppStat](http://appstat.lal.in2p3.fr/) and [University Paris-Sud LRI](https://www.lri.fr/index_en.php?lang=EN). ===Features===; - Seamless replacement for Minuit, Minuit2 and Fumili; - Seamless support for RooFit; - Relying on libcmaes allows for best performances known for CMA-ES + access to several flavors of the original algorithm, yielding best results with a trade off for computational cost, as needed; - Compilation support for both Autotools and CMake; - Included tutorial files, tests, and a special benchmark vs Minuit2. ===Documentation===; - Main documentation for building and using the new minimizer is here: https://github.com/beniz/libcmaes/wiki/using-CMA-ES-in-CERN's-ROOT. ===Performances===; - On-par with Minuit2 on low dimensional problems (< 10-D), consistently beats Minuit2 in higher dimension, leading to better fits. These claims are backed by two benchmarks and two experiments on real world data (we are still waiting from some results from usage at CERN); - Benchmark CMA-ES vs Minuit on [BBOB](http://coco.gforge.inria.fr/doku.php?id=bbob-2013) available here: https://drive.google.com/open?id=0B3J1vWYhta9ibktXc2JLRUExUTA&authuser=0; - In-ROOT benchmark vs Minuit2 on low-dimensional problems, results available here: https://drive.google.com/open?id=0B3J1vWYhta9iTmR0T0hnN21lSGM&authuser=0; - Beats out Minuit2 up to 98% of the time on some experiments (data + code available on demand from Auger group, ask me). I am available for help in testing and possibly integrating and maintaining this addition, just let me know.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:2085,Availability,avail,available,2085,"iz/libcmaes), a novel high performance C++11 (with Python bindings) library for blackbox optimization. The new minimizer yields better results than Minuit2 for most problems, though for an higher computation cost on average. See below for links to relevant benchmarks backing up these claims. This implementation is on behalf of [Inria Saclay Research group TAO](http://www.inria.fr/en/teams/tao), [Laboratoire de l'Accelerateur Lineaire, group AppStat](http://appstat.lal.in2p3.fr/) and [University Paris-Sud LRI](https://www.lri.fr/index_en.php?lang=EN). ===Features===; - Seamless replacement for Minuit, Minuit2 and Fumili; - Seamless support for RooFit; - Relying on libcmaes allows for best performances known for CMA-ES + access to several flavors of the original algorithm, yielding best results with a trade off for computational cost, as needed; - Compilation support for both Autotools and CMake; - Included tutorial files, tests, and a special benchmark vs Minuit2. ===Documentation===; - Main documentation for building and using the new minimizer is here: https://github.com/beniz/libcmaes/wiki/using-CMA-ES-in-CERN's-ROOT. ===Performances===; - On-par with Minuit2 on low dimensional problems (< 10-D), consistently beats Minuit2 in higher dimension, leading to better fits. These claims are backed by two benchmarks and two experiments on real world data (we are still waiting from some results from usage at CERN); - Benchmark CMA-ES vs Minuit on [BBOB](http://coco.gforge.inria.fr/doku.php?id=bbob-2013) available here: https://drive.google.com/open?id=0B3J1vWYhta9ibktXc2JLRUExUTA&authuser=0; - In-ROOT benchmark vs Minuit2 on low-dimensional problems, results available here: https://drive.google.com/open?id=0B3J1vWYhta9iTmR0T0hnN21lSGM&authuser=0; - Beats out Minuit2 up to 98% of the time on some experiments (data + code available on demand from Auger group, ask me). I am available for help in testing and possibly integrating and maintaining this addition, just let me know.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:2128,Deployability,integrat,integrating,2128,"iz/libcmaes), a novel high performance C++11 (with Python bindings) library for blackbox optimization. The new minimizer yields better results than Minuit2 for most problems, though for an higher computation cost on average. See below for links to relevant benchmarks backing up these claims. This implementation is on behalf of [Inria Saclay Research group TAO](http://www.inria.fr/en/teams/tao), [Laboratoire de l'Accelerateur Lineaire, group AppStat](http://appstat.lal.in2p3.fr/) and [University Paris-Sud LRI](https://www.lri.fr/index_en.php?lang=EN). ===Features===; - Seamless replacement for Minuit, Minuit2 and Fumili; - Seamless support for RooFit; - Relying on libcmaes allows for best performances known for CMA-ES + access to several flavors of the original algorithm, yielding best results with a trade off for computational cost, as needed; - Compilation support for both Autotools and CMake; - Included tutorial files, tests, and a special benchmark vs Minuit2. ===Documentation===; - Main documentation for building and using the new minimizer is here: https://github.com/beniz/libcmaes/wiki/using-CMA-ES-in-CERN's-ROOT. ===Performances===; - On-par with Minuit2 on low dimensional problems (< 10-D), consistently beats Minuit2 in higher dimension, leading to better fits. These claims are backed by two benchmarks and two experiments on real world data (we are still waiting from some results from usage at CERN); - Benchmark CMA-ES vs Minuit on [BBOB](http://coco.gforge.inria.fr/doku.php?id=bbob-2013) available here: https://drive.google.com/open?id=0B3J1vWYhta9ibktXc2JLRUExUTA&authuser=0; - In-ROOT benchmark vs Minuit2 on low-dimensional problems, results available here: https://drive.google.com/open?id=0B3J1vWYhta9iTmR0T0hnN21lSGM&authuser=0; - Beats out Minuit2 up to 98% of the time on some experiments (data + code available on demand from Auger group, ask me). I am available for help in testing and possibly integrating and maintaining this addition, just let me know.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:2128,Integrability,integrat,integrating,2128,"iz/libcmaes), a novel high performance C++11 (with Python bindings) library for blackbox optimization. The new minimizer yields better results than Minuit2 for most problems, though for an higher computation cost on average. See below for links to relevant benchmarks backing up these claims. This implementation is on behalf of [Inria Saclay Research group TAO](http://www.inria.fr/en/teams/tao), [Laboratoire de l'Accelerateur Lineaire, group AppStat](http://appstat.lal.in2p3.fr/) and [University Paris-Sud LRI](https://www.lri.fr/index_en.php?lang=EN). ===Features===; - Seamless replacement for Minuit, Minuit2 and Fumili; - Seamless support for RooFit; - Relying on libcmaes allows for best performances known for CMA-ES + access to several flavors of the original algorithm, yielding best results with a trade off for computational cost, as needed; - Compilation support for both Autotools and CMake; - Included tutorial files, tests, and a special benchmark vs Minuit2. ===Documentation===; - Main documentation for building and using the new minimizer is here: https://github.com/beniz/libcmaes/wiki/using-CMA-ES-in-CERN's-ROOT. ===Performances===; - On-par with Minuit2 on low dimensional problems (< 10-D), consistently beats Minuit2 in higher dimension, leading to better fits. These claims are backed by two benchmarks and two experiments on real world data (we are still waiting from some results from usage at CERN); - Benchmark CMA-ES vs Minuit on [BBOB](http://coco.gforge.inria.fr/doku.php?id=bbob-2013) available here: https://drive.google.com/open?id=0B3J1vWYhta9ibktXc2JLRUExUTA&authuser=0; - In-ROOT benchmark vs Minuit2 on low-dimensional problems, results available here: https://drive.google.com/open?id=0B3J1vWYhta9iTmR0T0hnN21lSGM&authuser=0; - Beats out Minuit2 up to 98% of the time on some experiments (data + code available on demand from Auger group, ask me). I am available for help in testing and possibly integrating and maintaining this addition, just let me know.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:215,Performance,perform,performance,215,"This is ROOT6 support for [CMA-ES](https://www.lri.fr/~hansen/cmaesintro.html), a state-of-the-art black box stochastic minimizer. The implementation uses [libcmaes](https://github.com/beniz/libcmaes), a novel high performance C++11 (with Python bindings) library for blackbox optimization. The new minimizer yields better results than Minuit2 for most problems, though for an higher computation cost on average. See below for links to relevant benchmarks backing up these claims. This implementation is on behalf of [Inria Saclay Research group TAO](http://www.inria.fr/en/teams/tao), [Laboratoire de l'Accelerateur Lineaire, group AppStat](http://appstat.lal.in2p3.fr/) and [University Paris-Sud LRI](https://www.lri.fr/index_en.php?lang=EN). ===Features===; - Seamless replacement for Minuit, Minuit2 and Fumili; - Seamless support for RooFit; - Relying on libcmaes allows for best performances known for CMA-ES + access to several flavors of the original algorithm, yielding best results with a trade off for computational cost, as needed; - Compilation support for both Autotools and CMake; - Included tutorial files, tests, and a special benchmark vs Minuit2. ===Documentation===; - Main documentation for building and using the new minimizer is here: https://github.com/beniz/libcmaes/wiki/using-CMA-ES-in-CERN's-ROOT. ===Performances===; - On-par with Minuit2 on low dimensional problems (< 10-D), consistently beats Minuit2 in higher dimension, leading to better fits. These claims are backed by two benchmarks and two experiments on real world data (we are still waiting from some results from usage at CERN); - Benchmark CMA-ES vs Minuit on [BBOB](http://coco.gforge.inria.fr/doku.php?id=bbob-2013) available here: https://drive.google.com/open?id=0B3J1vWYhta9ibktXc2JLRUExUTA&authuser=0; - In-ROOT benchmark vs Minuit2 on low-dimensional problems, results available here: https://drive.google.com/open?id=0B3J1vWYhta9iTmR0T0hnN21lSGM&authuser=0; - Beats out Minuit2 up to 98% of the time o",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:277,Performance,optimiz,optimization,277,"This is ROOT6 support for [CMA-ES](https://www.lri.fr/~hansen/cmaesintro.html), a state-of-the-art black box stochastic minimizer. The implementation uses [libcmaes](https://github.com/beniz/libcmaes), a novel high performance C++11 (with Python bindings) library for blackbox optimization. The new minimizer yields better results than Minuit2 for most problems, though for an higher computation cost on average. See below for links to relevant benchmarks backing up these claims. This implementation is on behalf of [Inria Saclay Research group TAO](http://www.inria.fr/en/teams/tao), [Laboratoire de l'Accelerateur Lineaire, group AppStat](http://appstat.lal.in2p3.fr/) and [University Paris-Sud LRI](https://www.lri.fr/index_en.php?lang=EN). ===Features===; - Seamless replacement for Minuit, Minuit2 and Fumili; - Seamless support for RooFit; - Relying on libcmaes allows for best performances known for CMA-ES + access to several flavors of the original algorithm, yielding best results with a trade off for computational cost, as needed; - Compilation support for both Autotools and CMake; - Included tutorial files, tests, and a special benchmark vs Minuit2. ===Documentation===; - Main documentation for building and using the new minimizer is here: https://github.com/beniz/libcmaes/wiki/using-CMA-ES-in-CERN's-ROOT. ===Performances===; - On-par with Minuit2 on low dimensional problems (< 10-D), consistently beats Minuit2 in higher dimension, leading to better fits. These claims are backed by two benchmarks and two experiments on real world data (we are still waiting from some results from usage at CERN); - Benchmark CMA-ES vs Minuit on [BBOB](http://coco.gforge.inria.fr/doku.php?id=bbob-2013) available here: https://drive.google.com/open?id=0B3J1vWYhta9ibktXc2JLRUExUTA&authuser=0; - In-ROOT benchmark vs Minuit2 on low-dimensional problems, results available here: https://drive.google.com/open?id=0B3J1vWYhta9iTmR0T0hnN21lSGM&authuser=0; - Beats out Minuit2 up to 98% of the time o",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:885,Performance,perform,performances,885,"This is ROOT6 support for [CMA-ES](https://www.lri.fr/~hansen/cmaesintro.html), a state-of-the-art black box stochastic minimizer. The implementation uses [libcmaes](https://github.com/beniz/libcmaes), a novel high performance C++11 (with Python bindings) library for blackbox optimization. The new minimizer yields better results than Minuit2 for most problems, though for an higher computation cost on average. See below for links to relevant benchmarks backing up these claims. This implementation is on behalf of [Inria Saclay Research group TAO](http://www.inria.fr/en/teams/tao), [Laboratoire de l'Accelerateur Lineaire, group AppStat](http://appstat.lal.in2p3.fr/) and [University Paris-Sud LRI](https://www.lri.fr/index_en.php?lang=EN). ===Features===; - Seamless replacement for Minuit, Minuit2 and Fumili; - Seamless support for RooFit; - Relying on libcmaes allows for best performances known for CMA-ES + access to several flavors of the original algorithm, yielding best results with a trade off for computational cost, as needed; - Compilation support for both Autotools and CMake; - Included tutorial files, tests, and a special benchmark vs Minuit2. ===Documentation===; - Main documentation for building and using the new minimizer is here: https://github.com/beniz/libcmaes/wiki/using-CMA-ES-in-CERN's-ROOT. ===Performances===; - On-par with Minuit2 on low dimensional problems (< 10-D), consistently beats Minuit2 in higher dimension, leading to better fits. These claims are backed by two benchmarks and two experiments on real world data (we are still waiting from some results from usage at CERN); - Benchmark CMA-ES vs Minuit on [BBOB](http://coco.gforge.inria.fr/doku.php?id=bbob-2013) available here: https://drive.google.com/open?id=0B3J1vWYhta9ibktXc2JLRUExUTA&authuser=0; - In-ROOT benchmark vs Minuit2 on low-dimensional problems, results available here: https://drive.google.com/open?id=0B3J1vWYhta9iTmR0T0hnN21lSGM&authuser=0; - Beats out Minuit2 up to 98% of the time o",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:1329,Performance,Perform,Performances,1329,"iz/libcmaes), a novel high performance C++11 (with Python bindings) library for blackbox optimization. The new minimizer yields better results than Minuit2 for most problems, though for an higher computation cost on average. See below for links to relevant benchmarks backing up these claims. This implementation is on behalf of [Inria Saclay Research group TAO](http://www.inria.fr/en/teams/tao), [Laboratoire de l'Accelerateur Lineaire, group AppStat](http://appstat.lal.in2p3.fr/) and [University Paris-Sud LRI](https://www.lri.fr/index_en.php?lang=EN). ===Features===; - Seamless replacement for Minuit, Minuit2 and Fumili; - Seamless support for RooFit; - Relying on libcmaes allows for best performances known for CMA-ES + access to several flavors of the original algorithm, yielding best results with a trade off for computational cost, as needed; - Compilation support for both Autotools and CMake; - Included tutorial files, tests, and a special benchmark vs Minuit2. ===Documentation===; - Main documentation for building and using the new minimizer is here: https://github.com/beniz/libcmaes/wiki/using-CMA-ES-in-CERN's-ROOT. ===Performances===; - On-par with Minuit2 on low dimensional problems (< 10-D), consistently beats Minuit2 in higher dimension, leading to better fits. These claims are backed by two benchmarks and two experiments on real world data (we are still waiting from some results from usage at CERN); - Benchmark CMA-ES vs Minuit on [BBOB](http://coco.gforge.inria.fr/doku.php?id=bbob-2013) available here: https://drive.google.com/open?id=0B3J1vWYhta9ibktXc2JLRUExUTA&authuser=0; - In-ROOT benchmark vs Minuit2 on low-dimensional problems, results available here: https://drive.google.com/open?id=0B3J1vWYhta9iTmR0T0hnN21lSGM&authuser=0; - Beats out Minuit2 up to 98% of the time on some experiments (data + code available on demand from Auger group, ask me). I am available for help in testing and possibly integrating and maintaining this addition, just let me know.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:917,Security,access,access,917,"This is ROOT6 support for [CMA-ES](https://www.lri.fr/~hansen/cmaesintro.html), a state-of-the-art black box stochastic minimizer. The implementation uses [libcmaes](https://github.com/beniz/libcmaes), a novel high performance C++11 (with Python bindings) library for blackbox optimization. The new minimizer yields better results than Minuit2 for most problems, though for an higher computation cost on average. See below for links to relevant benchmarks backing up these claims. This implementation is on behalf of [Inria Saclay Research group TAO](http://www.inria.fr/en/teams/tao), [Laboratoire de l'Accelerateur Lineaire, group AppStat](http://appstat.lal.in2p3.fr/) and [University Paris-Sud LRI](https://www.lri.fr/index_en.php?lang=EN). ===Features===; - Seamless replacement for Minuit, Minuit2 and Fumili; - Seamless support for RooFit; - Relying on libcmaes allows for best performances known for CMA-ES + access to several flavors of the original algorithm, yielding best results with a trade off for computational cost, as needed; - Compilation support for both Autotools and CMake; - Included tutorial files, tests, and a special benchmark vs Minuit2. ===Documentation===; - Main documentation for building and using the new minimizer is here: https://github.com/beniz/libcmaes/wiki/using-CMA-ES-in-CERN's-ROOT. ===Performances===; - On-par with Minuit2 on low dimensional problems (< 10-D), consistently beats Minuit2 in higher dimension, leading to better fits. These claims are backed by two benchmarks and two experiments on real world data (we are still waiting from some results from usage at CERN); - Benchmark CMA-ES vs Minuit on [BBOB](http://coco.gforge.inria.fr/doku.php?id=bbob-2013) available here: https://drive.google.com/open?id=0B3J1vWYhta9ibktXc2JLRUExUTA&authuser=0; - In-ROOT benchmark vs Minuit2 on low-dimensional problems, results available here: https://drive.google.com/open?id=0B3J1vWYhta9iTmR0T0hnN21lSGM&authuser=0; - Beats out Minuit2 up to 98% of the time o",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:445,Testability,benchmark,benchmarks,445,"This is ROOT6 support for [CMA-ES](https://www.lri.fr/~hansen/cmaesintro.html), a state-of-the-art black box stochastic minimizer. The implementation uses [libcmaes](https://github.com/beniz/libcmaes), a novel high performance C++11 (with Python bindings) library for blackbox optimization. The new minimizer yields better results than Minuit2 for most problems, though for an higher computation cost on average. See below for links to relevant benchmarks backing up these claims. This implementation is on behalf of [Inria Saclay Research group TAO](http://www.inria.fr/en/teams/tao), [Laboratoire de l'Accelerateur Lineaire, group AppStat](http://appstat.lal.in2p3.fr/) and [University Paris-Sud LRI](https://www.lri.fr/index_en.php?lang=EN). ===Features===; - Seamless replacement for Minuit, Minuit2 and Fumili; - Seamless support for RooFit; - Relying on libcmaes allows for best performances known for CMA-ES + access to several flavors of the original algorithm, yielding best results with a trade off for computational cost, as needed; - Compilation support for both Autotools and CMake; - Included tutorial files, tests, and a special benchmark vs Minuit2. ===Documentation===; - Main documentation for building and using the new minimizer is here: https://github.com/beniz/libcmaes/wiki/using-CMA-ES-in-CERN's-ROOT. ===Performances===; - On-par with Minuit2 on low dimensional problems (< 10-D), consistently beats Minuit2 in higher dimension, leading to better fits. These claims are backed by two benchmarks and two experiments on real world data (we are still waiting from some results from usage at CERN); - Benchmark CMA-ES vs Minuit on [BBOB](http://coco.gforge.inria.fr/doku.php?id=bbob-2013) available here: https://drive.google.com/open?id=0B3J1vWYhta9ibktXc2JLRUExUTA&authuser=0; - In-ROOT benchmark vs Minuit2 on low-dimensional problems, results available here: https://drive.google.com/open?id=0B3J1vWYhta9iTmR0T0hnN21lSGM&authuser=0; - Beats out Minuit2 up to 98% of the time o",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:1123,Testability,test,tests,1123,"This is ROOT6 support for [CMA-ES](https://www.lri.fr/~hansen/cmaesintro.html), a state-of-the-art black box stochastic minimizer. The implementation uses [libcmaes](https://github.com/beniz/libcmaes), a novel high performance C++11 (with Python bindings) library for blackbox optimization. The new minimizer yields better results than Minuit2 for most problems, though for an higher computation cost on average. See below for links to relevant benchmarks backing up these claims. This implementation is on behalf of [Inria Saclay Research group TAO](http://www.inria.fr/en/teams/tao), [Laboratoire de l'Accelerateur Lineaire, group AppStat](http://appstat.lal.in2p3.fr/) and [University Paris-Sud LRI](https://www.lri.fr/index_en.php?lang=EN). ===Features===; - Seamless replacement for Minuit, Minuit2 and Fumili; - Seamless support for RooFit; - Relying on libcmaes allows for best performances known for CMA-ES + access to several flavors of the original algorithm, yielding best results with a trade off for computational cost, as needed; - Compilation support for both Autotools and CMake; - Included tutorial files, tests, and a special benchmark vs Minuit2. ===Documentation===; - Main documentation for building and using the new minimizer is here: https://github.com/beniz/libcmaes/wiki/using-CMA-ES-in-CERN's-ROOT. ===Performances===; - On-par with Minuit2 on low dimensional problems (< 10-D), consistently beats Minuit2 in higher dimension, leading to better fits. These claims are backed by two benchmarks and two experiments on real world data (we are still waiting from some results from usage at CERN); - Benchmark CMA-ES vs Minuit on [BBOB](http://coco.gforge.inria.fr/doku.php?id=bbob-2013) available here: https://drive.google.com/open?id=0B3J1vWYhta9ibktXc2JLRUExUTA&authuser=0; - In-ROOT benchmark vs Minuit2 on low-dimensional problems, results available here: https://drive.google.com/open?id=0B3J1vWYhta9iTmR0T0hnN21lSGM&authuser=0; - Beats out Minuit2 up to 98% of the time o",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:1144,Testability,benchmark,benchmark,1144,"This is ROOT6 support for [CMA-ES](https://www.lri.fr/~hansen/cmaesintro.html), a state-of-the-art black box stochastic minimizer. The implementation uses [libcmaes](https://github.com/beniz/libcmaes), a novel high performance C++11 (with Python bindings) library for blackbox optimization. The new minimizer yields better results than Minuit2 for most problems, though for an higher computation cost on average. See below for links to relevant benchmarks backing up these claims. This implementation is on behalf of [Inria Saclay Research group TAO](http://www.inria.fr/en/teams/tao), [Laboratoire de l'Accelerateur Lineaire, group AppStat](http://appstat.lal.in2p3.fr/) and [University Paris-Sud LRI](https://www.lri.fr/index_en.php?lang=EN). ===Features===; - Seamless replacement for Minuit, Minuit2 and Fumili; - Seamless support for RooFit; - Relying on libcmaes allows for best performances known for CMA-ES + access to several flavors of the original algorithm, yielding best results with a trade off for computational cost, as needed; - Compilation support for both Autotools and CMake; - Included tutorial files, tests, and a special benchmark vs Minuit2. ===Documentation===; - Main documentation for building and using the new minimizer is here: https://github.com/beniz/libcmaes/wiki/using-CMA-ES-in-CERN's-ROOT. ===Performances===; - On-par with Minuit2 on low dimensional problems (< 10-D), consistently beats Minuit2 in higher dimension, leading to better fits. These claims are backed by two benchmarks and two experiments on real world data (we are still waiting from some results from usage at CERN); - Benchmark CMA-ES vs Minuit on [BBOB](http://coco.gforge.inria.fr/doku.php?id=bbob-2013) available here: https://drive.google.com/open?id=0B3J1vWYhta9ibktXc2JLRUExUTA&authuser=0; - In-ROOT benchmark vs Minuit2 on low-dimensional problems, results available here: https://drive.google.com/open?id=0B3J1vWYhta9iTmR0T0hnN21lSGM&authuser=0; - Beats out Minuit2 up to 98% of the time o",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:1509,Testability,benchmark,benchmarks,1509,"iz/libcmaes), a novel high performance C++11 (with Python bindings) library for blackbox optimization. The new minimizer yields better results than Minuit2 for most problems, though for an higher computation cost on average. See below for links to relevant benchmarks backing up these claims. This implementation is on behalf of [Inria Saclay Research group TAO](http://www.inria.fr/en/teams/tao), [Laboratoire de l'Accelerateur Lineaire, group AppStat](http://appstat.lal.in2p3.fr/) and [University Paris-Sud LRI](https://www.lri.fr/index_en.php?lang=EN). ===Features===; - Seamless replacement for Minuit, Minuit2 and Fumili; - Seamless support for RooFit; - Relying on libcmaes allows for best performances known for CMA-ES + access to several flavors of the original algorithm, yielding best results with a trade off for computational cost, as needed; - Compilation support for both Autotools and CMake; - Included tutorial files, tests, and a special benchmark vs Minuit2. ===Documentation===; - Main documentation for building and using the new minimizer is here: https://github.com/beniz/libcmaes/wiki/using-CMA-ES-in-CERN's-ROOT. ===Performances===; - On-par with Minuit2 on low dimensional problems (< 10-D), consistently beats Minuit2 in higher dimension, leading to better fits. These claims are backed by two benchmarks and two experiments on real world data (we are still waiting from some results from usage at CERN); - Benchmark CMA-ES vs Minuit on [BBOB](http://coco.gforge.inria.fr/doku.php?id=bbob-2013) available here: https://drive.google.com/open?id=0B3J1vWYhta9ibktXc2JLRUExUTA&authuser=0; - In-ROOT benchmark vs Minuit2 on low-dimensional problems, results available here: https://drive.google.com/open?id=0B3J1vWYhta9iTmR0T0hnN21lSGM&authuser=0; - Beats out Minuit2 up to 98% of the time on some experiments (data + code available on demand from Auger group, ask me). I am available for help in testing and possibly integrating and maintaining this addition, just let me know.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:1622,Testability,Benchmark,Benchmark,1622,"iz/libcmaes), a novel high performance C++11 (with Python bindings) library for blackbox optimization. The new minimizer yields better results than Minuit2 for most problems, though for an higher computation cost on average. See below for links to relevant benchmarks backing up these claims. This implementation is on behalf of [Inria Saclay Research group TAO](http://www.inria.fr/en/teams/tao), [Laboratoire de l'Accelerateur Lineaire, group AppStat](http://appstat.lal.in2p3.fr/) and [University Paris-Sud LRI](https://www.lri.fr/index_en.php?lang=EN). ===Features===; - Seamless replacement for Minuit, Minuit2 and Fumili; - Seamless support for RooFit; - Relying on libcmaes allows for best performances known for CMA-ES + access to several flavors of the original algorithm, yielding best results with a trade off for computational cost, as needed; - Compilation support for both Autotools and CMake; - Included tutorial files, tests, and a special benchmark vs Minuit2. ===Documentation===; - Main documentation for building and using the new minimizer is here: https://github.com/beniz/libcmaes/wiki/using-CMA-ES-in-CERN's-ROOT. ===Performances===; - On-par with Minuit2 on low dimensional problems (< 10-D), consistently beats Minuit2 in higher dimension, leading to better fits. These claims are backed by two benchmarks and two experiments on real world data (we are still waiting from some results from usage at CERN); - Benchmark CMA-ES vs Minuit on [BBOB](http://coco.gforge.inria.fr/doku.php?id=bbob-2013) available here: https://drive.google.com/open?id=0B3J1vWYhta9ibktXc2JLRUExUTA&authuser=0; - In-ROOT benchmark vs Minuit2 on low-dimensional problems, results available here: https://drive.google.com/open?id=0B3J1vWYhta9iTmR0T0hnN21lSGM&authuser=0; - Beats out Minuit2 up to 98% of the time on some experiments (data + code available on demand from Auger group, ask me). I am available for help in testing and possibly integrating and maintaining this addition, just let me know.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:1810,Testability,benchmark,benchmark,1810,"iz/libcmaes), a novel high performance C++11 (with Python bindings) library for blackbox optimization. The new minimizer yields better results than Minuit2 for most problems, though for an higher computation cost on average. See below for links to relevant benchmarks backing up these claims. This implementation is on behalf of [Inria Saclay Research group TAO](http://www.inria.fr/en/teams/tao), [Laboratoire de l'Accelerateur Lineaire, group AppStat](http://appstat.lal.in2p3.fr/) and [University Paris-Sud LRI](https://www.lri.fr/index_en.php?lang=EN). ===Features===; - Seamless replacement for Minuit, Minuit2 and Fumili; - Seamless support for RooFit; - Relying on libcmaes allows for best performances known for CMA-ES + access to several flavors of the original algorithm, yielding best results with a trade off for computational cost, as needed; - Compilation support for both Autotools and CMake; - Included tutorial files, tests, and a special benchmark vs Minuit2. ===Documentation===; - Main documentation for building and using the new minimizer is here: https://github.com/beniz/libcmaes/wiki/using-CMA-ES-in-CERN's-ROOT. ===Performances===; - On-par with Minuit2 on low dimensional problems (< 10-D), consistently beats Minuit2 in higher dimension, leading to better fits. These claims are backed by two benchmarks and two experiments on real world data (we are still waiting from some results from usage at CERN); - Benchmark CMA-ES vs Minuit on [BBOB](http://coco.gforge.inria.fr/doku.php?id=bbob-2013) available here: https://drive.google.com/open?id=0B3J1vWYhta9ibktXc2JLRUExUTA&authuser=0; - In-ROOT benchmark vs Minuit2 on low-dimensional problems, results available here: https://drive.google.com/open?id=0B3J1vWYhta9iTmR0T0hnN21lSGM&authuser=0; - Beats out Minuit2 up to 98% of the time on some experiments (data + code available on demand from Auger group, ask me). I am available for help in testing and possibly integrating and maintaining this addition, just let me know.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:2107,Testability,test,testing,2107,"iz/libcmaes), a novel high performance C++11 (with Python bindings) library for blackbox optimization. The new minimizer yields better results than Minuit2 for most problems, though for an higher computation cost on average. See below for links to relevant benchmarks backing up these claims. This implementation is on behalf of [Inria Saclay Research group TAO](http://www.inria.fr/en/teams/tao), [Laboratoire de l'Accelerateur Lineaire, group AppStat](http://appstat.lal.in2p3.fr/) and [University Paris-Sud LRI](https://www.lri.fr/index_en.php?lang=EN). ===Features===; - Seamless replacement for Minuit, Minuit2 and Fumili; - Seamless support for RooFit; - Relying on libcmaes allows for best performances known for CMA-ES + access to several flavors of the original algorithm, yielding best results with a trade off for computational cost, as needed; - Compilation support for both Autotools and CMake; - Included tutorial files, tests, and a special benchmark vs Minuit2. ===Documentation===; - Main documentation for building and using the new minimizer is here: https://github.com/beniz/libcmaes/wiki/using-CMA-ES-in-CERN's-ROOT. ===Performances===; - On-par with Minuit2 on low dimensional problems (< 10-D), consistently beats Minuit2 in higher dimension, leading to better fits. These claims are backed by two benchmarks and two experiments on real world data (we are still waiting from some results from usage at CERN); - Benchmark CMA-ES vs Minuit on [BBOB](http://coco.gforge.inria.fr/doku.php?id=bbob-2013) available here: https://drive.google.com/open?id=0B3J1vWYhta9ibktXc2JLRUExUTA&authuser=0; - In-ROOT benchmark vs Minuit2 on low-dimensional problems, results available here: https://drive.google.com/open?id=0B3J1vWYhta9iTmR0T0hnN21lSGM&authuser=0; - Beats out Minuit2 up to 98% of the time on some experiments (data + code available on demand from Auger group, ask me). I am available for help in testing and possibly integrating and maintaining this addition, just let me know.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/41:92,Energy Efficiency,Green,Greenwich,92,"This commit improves the functionality of TTimeStamp class by adding 4 methods to calculate Greenwich/local mean/apparent sidereal time. Calculation was referenced from. Aoki et. al. Astron. Astrophys. 105, 359-362 (1982), http://adsabs.harvard.edu/abs/1982A%26A...105..359A. and. http://aa.usno.navy.mil/faq/docs/GAST.php. In the future, it would be helpful to add a class that pulls the UTC-UT1 offset times from the below repository for enhanced accuracy:. ftp://ftp.iers.org/products/eop/bulletinb/format_2009/",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/41
https://github.com/root-project/root/pull/41:440,Modifiability,enhance,enhanced,440,"This commit improves the functionality of TTimeStamp class by adding 4 methods to calculate Greenwich/local mean/apparent sidereal time. Calculation was referenced from. Aoki et. al. Astron. Astrophys. 105, 359-362 (1982), http://adsabs.harvard.edu/abs/1982A%26A...105..359A. and. http://aa.usno.navy.mil/faq/docs/GAST.php. In the future, it would be helpful to add a class that pulls the UTC-UT1 offset times from the below repository for enhanced accuracy:. ftp://ftp.iers.org/products/eop/bulletinb/format_2009/",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/41
https://github.com/root-project/root/pull/42:87,Usability,simpl,simpler,87,These changes let to reimplement string streamers in derived classes to provide better simpler representation of string in JSON/XML/SQL,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/42
https://github.com/root-project/root/pull/45:49,Performance,concurren,concurrent,49,Use the gROOTMutex to protect access to possible concurrent accesses; to gROOT->GetListOfFiles().,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/45
https://github.com/root-project/root/pull/45:30,Security,access,access,30,Use the gROOTMutex to protect access to possible concurrent accesses; to gROOT->GetListOfFiles().,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/45
https://github.com/root-project/root/pull/45:60,Security,access,accesses,60,Use the gROOTMutex to protect access to possible concurrent accesses; to gROOT->GetListOfFiles().,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/45
https://github.com/root-project/root/pull/46:7,Safety,safe,safety,7,Thread safety issues with TListOfFunctions was found using the CMS threaded framework. These changes were done in consultation with Philippe Canal.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/46
https://github.com/root-project/root/pull/48:36,Modifiability,variab,variable,36,"Initialization of a function static variable is guaranteed to be; done in a thread safe manner by the C++11 standard. Previously, the; static was initialized to 0 and then reset which lead to a data race.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/48
https://github.com/root-project/root/pull/48:83,Safety,safe,safe,83,"Initialization of a function static variable is guaranteed to be; done in a thread safe manner by the C++11 standard. Previously, the; static was initialized to 0 and then reset which lead to a data race.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/48
https://github.com/root-project/root/pull/49:95,Safety,safe,safe,95,"The TIsAProxy does late initialization and caching, both of which; need to be done in a thread-safe manner.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/49
https://github.com/root-project/root/pull/53:36,Availability,avail,available,36,"Fixes the method-independent macros available from TMVAGui.C to work with cling. Correlation scatter plots are still broken because of "")"" in strings passed to other macros (reported to D. Piparo)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/53
https://github.com/root-project/root/pull/54:98,Availability,error,error,98,Fixes compilation with xrootd v4:. ```; /Users/veprbl/root/net/netxng/src/TNetXNGFile.cxx:670:26: error: no member named 'GetDataServer' in 'XrdCl::File'; URL dataServer(fFile->GetDataServer());; ~~~~~ ^; 1 error generated.; ```,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/54
https://github.com/root-project/root/pull/54:207,Availability,error,error,207,Fixes compilation with xrootd v4:. ```; /Users/veprbl/root/net/netxng/src/TNetXNGFile.cxx:670:26: error: no member named 'GetDataServer' in 'XrdCl::File'; URL dataServer(fFile->GetDataServer());; ~~~~~ ^; 1 error generated.; ```,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/54
https://github.com/root-project/root/pull/55:54,Safety,safe,safe,54,"Made obtaining the list of enums from a TClass thread safe. As part of that, made all the statics used as return values by TCling to be thread_local.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/55
https://github.com/root-project/root/pull/56:5,Modifiability,extend,extends,5,This extends the previous work on enum thread-safety to encompass; all the ways the enums can be scoped.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/56
https://github.com/root-project/root/pull/56:46,Safety,safe,safety,46,This extends the previous work on enum thread-safety to encompass; all the ways the enums can be scoped.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/56
https://github.com/root-project/root/pull/57:183,Safety,safe,safe,183,"Although each thread will get its own copy of TGenCollectionStreamer,; that copy is made by calling Generate on a global instance of the class.; Therefore Generate needs to be thread safe. This translates to requiring; TGenCollectionProxy::Initialize be thread safe. This required that; TGenCollectionProxy::fValue be atomic and be the last value to be set; in TGenCollectionProxy::InitializeEx.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/57
https://github.com/root-project/root/pull/57:261,Safety,safe,safe,261,"Although each thread will get its own copy of TGenCollectionStreamer,; that copy is made by calling Generate on a global instance of the class.; Therefore Generate needs to be thread safe. This translates to requiring; TGenCollectionProxy::Initialize be thread safe. This required that; TGenCollectionProxy::fValue be atomic and be the last value to be set; in TGenCollectionProxy::InitializeEx.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/57
https://github.com/root-project/root/pull/58:183,Safety,safe,safe,183,"Although each thread will get its own copy of TGenCollectionStreamer,; that copy is made by calling Generate on a global instance of the class.; Therefore Generate needs to be thread safe. This translates to requiring; TGenCollectionProxy::Initialize be thread safe. This required that; TGenCollectionProxy::fValue be atomic and be the last value to be set; in TGenCollectionProxy::InitializeEx.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/58
https://github.com/root-project/root/pull/58:261,Safety,safe,safe,261,"Although each thread will get its own copy of TGenCollectionStreamer,; that copy is made by calling Generate on a global instance of the class.; Therefore Generate needs to be thread safe. This translates to requiring; TGenCollectionProxy::Initialize be thread safe. This required that; TGenCollectionProxy::fValue be atomic and be the last value to be set; in TGenCollectionProxy::InitializeEx.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/58
https://github.com/root-project/root/pull/59:656,Modifiability,extend,extend,656,"This pull request adds support for the LZ4 compression algorithm (https://code.google.com/p/lz4/). The code is BSD-licensed. The pull-request includes a source tarball (allowing a ""builtin_lz4"" option in CMake analogous to ""builtin_lzma""). I am unable to test this on Windows currently. The LZ4 algorithm focuses on decompression speed while sacrificing compression ratio. Compression level < 4 uses the ""LZ4 compression"" algorithm while compression level >= 4 uses ""LZ4HC"" (HC = high compression) variant. LZ4HC is comparable to zlib in speeds, but has approximately 20% larger file size. To evaluate, I use the Event executable in the test/ directory. I extend this to allow the compression algorithm be specified via CLI. Example invocation:. time ./Event 4000 6 99 1 1000 4; time ./Event 4000 4 99 0 1000 4. Here, the CLI arguments are:; - 1: Number of events (4000); - 2: Compression ratio (6); - 3: Split level (99); - 4: 1 for write, 0 for read.; - 5: Number of tracks per event (1000).; - 6: Compression algorithm (1 = zlib, 2 = lzma, 4 = lz4. 3 is the deprecated zlib-like algorithm). I extended MainEvent.cxx to include TTreePerfStats information, which gives us access to the compression-time-only rates. Performance results (testing on a 2.6GHz Intel Westmere E56xx-based VM) summary:. LZ4HC compression:; - File size: 231MB; - 14.7MB/s CPU time for writing. ZLIB level-6 compression:; - File size: 189MB; - 10.5MB/s CPU time for writing.; Summary: LZ4HC compression resulted in a file 20% larger. Compression time was 44% faster. LZMA level-6 compression:; - File size: 163MB; - .62MB/s CPU time for writing.; Summary: LZMA compression resulted in a file 13% smaller. Compression time was 16x slower than ZLIB level-6. LZ4 decompression:; - 233MB/s CPU time for decompression only.; - 189MB/s CPU time for reading. ZLIB decompression:; - 118MB/s CPU time for decompression only; - 104MB/s CPU time for reading.; Summary: LZ4 decompression was 97% faster, resulting in 81% faster reading f",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/59
https://github.com/root-project/root/pull/59:1096,Modifiability,extend,extended,1096,"ode is BSD-licensed. The pull-request includes a source tarball (allowing a ""builtin_lz4"" option in CMake analogous to ""builtin_lzma""). I am unable to test this on Windows currently. The LZ4 algorithm focuses on decompression speed while sacrificing compression ratio. Compression level < 4 uses the ""LZ4 compression"" algorithm while compression level >= 4 uses ""LZ4HC"" (HC = high compression) variant. LZ4HC is comparable to zlib in speeds, but has approximately 20% larger file size. To evaluate, I use the Event executable in the test/ directory. I extend this to allow the compression algorithm be specified via CLI. Example invocation:. time ./Event 4000 6 99 1 1000 4; time ./Event 4000 4 99 0 1000 4. Here, the CLI arguments are:; - 1: Number of events (4000); - 2: Compression ratio (6); - 3: Split level (99); - 4: 1 for write, 0 for read.; - 5: Number of tracks per event (1000).; - 6: Compression algorithm (1 = zlib, 2 = lzma, 4 = lz4. 3 is the deprecated zlib-like algorithm). I extended MainEvent.cxx to include TTreePerfStats information, which gives us access to the compression-time-only rates. Performance results (testing on a 2.6GHz Intel Westmere E56xx-based VM) summary:. LZ4HC compression:; - File size: 231MB; - 14.7MB/s CPU time for writing. ZLIB level-6 compression:; - File size: 189MB; - 10.5MB/s CPU time for writing.; Summary: LZ4HC compression resulted in a file 20% larger. Compression time was 44% faster. LZMA level-6 compression:; - File size: 163MB; - .62MB/s CPU time for writing.; Summary: LZMA compression resulted in a file 13% smaller. Compression time was 16x slower than ZLIB level-6. LZ4 decompression:; - 233MB/s CPU time for decompression only.; - 189MB/s CPU time for reading. ZLIB decompression:; - 118MB/s CPU time for decompression only; - 104MB/s CPU time for reading.; Summary: LZ4 decompression was 97% faster, resulting in 81% faster reading for this case. LZMA decompression:; - 15.4MB/s CPU time for decompression only; - 14.7MB/s CPU time for ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/59
https://github.com/root-project/root/pull/59:1216,Performance,Perform,Performance,1216,"l (allowing a ""builtin_lz4"" option in CMake analogous to ""builtin_lzma""). I am unable to test this on Windows currently. The LZ4 algorithm focuses on decompression speed while sacrificing compression ratio. Compression level < 4 uses the ""LZ4 compression"" algorithm while compression level >= 4 uses ""LZ4HC"" (HC = high compression) variant. LZ4HC is comparable to zlib in speeds, but has approximately 20% larger file size. To evaluate, I use the Event executable in the test/ directory. I extend this to allow the compression algorithm be specified via CLI. Example invocation:. time ./Event 4000 6 99 1 1000 4; time ./Event 4000 4 99 0 1000 4. Here, the CLI arguments are:; - 1: Number of events (4000); - 2: Compression ratio (6); - 3: Split level (99); - 4: 1 for write, 0 for read.; - 5: Number of tracks per event (1000).; - 6: Compression algorithm (1 = zlib, 2 = lzma, 4 = lz4. 3 is the deprecated zlib-like algorithm). I extended MainEvent.cxx to include TTreePerfStats information, which gives us access to the compression-time-only rates. Performance results (testing on a 2.6GHz Intel Westmere E56xx-based VM) summary:. LZ4HC compression:; - File size: 231MB; - 14.7MB/s CPU time for writing. ZLIB level-6 compression:; - File size: 189MB; - 10.5MB/s CPU time for writing.; Summary: LZ4HC compression resulted in a file 20% larger. Compression time was 44% faster. LZMA level-6 compression:; - File size: 163MB; - .62MB/s CPU time for writing.; Summary: LZMA compression resulted in a file 13% smaller. Compression time was 16x slower than ZLIB level-6. LZ4 decompression:; - 233MB/s CPU time for decompression only.; - 189MB/s CPU time for reading. ZLIB decompression:; - 118MB/s CPU time for decompression only; - 104MB/s CPU time for reading.; Summary: LZ4 decompression was 97% faster, resulting in 81% faster reading for this case. LZMA decompression:; - 15.4MB/s CPU time for decompression only; - 14.7MB/s CPU time for reading.; Summary: LZMA decompression was 7x slower than zlib.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/59
https://github.com/root-project/root/pull/59:1173,Security,access,access,1173,"ll (allowing a ""builtin_lz4"" option in CMake analogous to ""builtin_lzma""). I am unable to test this on Windows currently. The LZ4 algorithm focuses on decompression speed while sacrificing compression ratio. Compression level < 4 uses the ""LZ4 compression"" algorithm while compression level >= 4 uses ""LZ4HC"" (HC = high compression) variant. LZ4HC is comparable to zlib in speeds, but has approximately 20% larger file size. To evaluate, I use the Event executable in the test/ directory. I extend this to allow the compression algorithm be specified via CLI. Example invocation:. time ./Event 4000 6 99 1 1000 4; time ./Event 4000 4 99 0 1000 4. Here, the CLI arguments are:; - 1: Number of events (4000); - 2: Compression ratio (6); - 3: Split level (99); - 4: 1 for write, 0 for read.; - 5: Number of tracks per event (1000).; - 6: Compression algorithm (1 = zlib, 2 = lzma, 4 = lz4. 3 is the deprecated zlib-like algorithm). I extended MainEvent.cxx to include TTreePerfStats information, which gives us access to the compression-time-only rates. Performance results (testing on a 2.6GHz Intel Westmere E56xx-based VM) summary:. LZ4HC compression:; - File size: 231MB; - 14.7MB/s CPU time for writing. ZLIB level-6 compression:; - File size: 189MB; - 10.5MB/s CPU time for writing.; Summary: LZ4HC compression resulted in a file 20% larger. Compression time was 44% faster. LZMA level-6 compression:; - File size: 163MB; - .62MB/s CPU time for writing.; Summary: LZMA compression resulted in a file 13% smaller. Compression time was 16x slower than ZLIB level-6. LZ4 decompression:; - 233MB/s CPU time for decompression only.; - 189MB/s CPU time for reading. ZLIB decompression:; - 118MB/s CPU time for decompression only; - 104MB/s CPU time for reading.; Summary: LZ4 decompression was 97% faster, resulting in 81% faster reading for this case. LZMA decompression:; - 15.4MB/s CPU time for decompression only; - 14.7MB/s CPU time for reading.; Summary: LZMA decompression was 7x slower than zlib",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/59
https://github.com/root-project/root/pull/59:255,Testability,test,test,255,"This pull request adds support for the LZ4 compression algorithm (https://code.google.com/p/lz4/). The code is BSD-licensed. The pull-request includes a source tarball (allowing a ""builtin_lz4"" option in CMake analogous to ""builtin_lzma""). I am unable to test this on Windows currently. The LZ4 algorithm focuses on decompression speed while sacrificing compression ratio. Compression level < 4 uses the ""LZ4 compression"" algorithm while compression level >= 4 uses ""LZ4HC"" (HC = high compression) variant. LZ4HC is comparable to zlib in speeds, but has approximately 20% larger file size. To evaluate, I use the Event executable in the test/ directory. I extend this to allow the compression algorithm be specified via CLI. Example invocation:. time ./Event 4000 6 99 1 1000 4; time ./Event 4000 4 99 0 1000 4. Here, the CLI arguments are:; - 1: Number of events (4000); - 2: Compression ratio (6); - 3: Split level (99); - 4: 1 for write, 0 for read.; - 5: Number of tracks per event (1000).; - 6: Compression algorithm (1 = zlib, 2 = lzma, 4 = lz4. 3 is the deprecated zlib-like algorithm). I extended MainEvent.cxx to include TTreePerfStats information, which gives us access to the compression-time-only rates. Performance results (testing on a 2.6GHz Intel Westmere E56xx-based VM) summary:. LZ4HC compression:; - File size: 231MB; - 14.7MB/s CPU time for writing. ZLIB level-6 compression:; - File size: 189MB; - 10.5MB/s CPU time for writing.; Summary: LZ4HC compression resulted in a file 20% larger. Compression time was 44% faster. LZMA level-6 compression:; - File size: 163MB; - .62MB/s CPU time for writing.; Summary: LZMA compression resulted in a file 13% smaller. Compression time was 16x slower than ZLIB level-6. LZ4 decompression:; - 233MB/s CPU time for decompression only.; - 189MB/s CPU time for reading. ZLIB decompression:; - 118MB/s CPU time for decompression only; - 104MB/s CPU time for reading.; Summary: LZ4 decompression was 97% faster, resulting in 81% faster reading f",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/59
https://github.com/root-project/root/pull/59:637,Testability,test,test,637,"This pull request adds support for the LZ4 compression algorithm (https://code.google.com/p/lz4/). The code is BSD-licensed. The pull-request includes a source tarball (allowing a ""builtin_lz4"" option in CMake analogous to ""builtin_lzma""). I am unable to test this on Windows currently. The LZ4 algorithm focuses on decompression speed while sacrificing compression ratio. Compression level < 4 uses the ""LZ4 compression"" algorithm while compression level >= 4 uses ""LZ4HC"" (HC = high compression) variant. LZ4HC is comparable to zlib in speeds, but has approximately 20% larger file size. To evaluate, I use the Event executable in the test/ directory. I extend this to allow the compression algorithm be specified via CLI. Example invocation:. time ./Event 4000 6 99 1 1000 4; time ./Event 4000 4 99 0 1000 4. Here, the CLI arguments are:; - 1: Number of events (4000); - 2: Compression ratio (6); - 3: Split level (99); - 4: 1 for write, 0 for read.; - 5: Number of tracks per event (1000).; - 6: Compression algorithm (1 = zlib, 2 = lzma, 4 = lz4. 3 is the deprecated zlib-like algorithm). I extended MainEvent.cxx to include TTreePerfStats information, which gives us access to the compression-time-only rates. Performance results (testing on a 2.6GHz Intel Westmere E56xx-based VM) summary:. LZ4HC compression:; - File size: 231MB; - 14.7MB/s CPU time for writing. ZLIB level-6 compression:; - File size: 189MB; - 10.5MB/s CPU time for writing.; Summary: LZ4HC compression resulted in a file 20% larger. Compression time was 44% faster. LZMA level-6 compression:; - File size: 163MB; - .62MB/s CPU time for writing.; Summary: LZMA compression resulted in a file 13% smaller. Compression time was 16x slower than ZLIB level-6. LZ4 decompression:; - 233MB/s CPU time for decompression only.; - 189MB/s CPU time for reading. ZLIB decompression:; - 118MB/s CPU time for decompression only; - 104MB/s CPU time for reading.; Summary: LZ4 decompression was 97% faster, resulting in 81% faster reading f",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/59
https://github.com/root-project/root/pull/59:1237,Testability,test,testing,1237,"l (allowing a ""builtin_lz4"" option in CMake analogous to ""builtin_lzma""). I am unable to test this on Windows currently. The LZ4 algorithm focuses on decompression speed while sacrificing compression ratio. Compression level < 4 uses the ""LZ4 compression"" algorithm while compression level >= 4 uses ""LZ4HC"" (HC = high compression) variant. LZ4HC is comparable to zlib in speeds, but has approximately 20% larger file size. To evaluate, I use the Event executable in the test/ directory. I extend this to allow the compression algorithm be specified via CLI. Example invocation:. time ./Event 4000 6 99 1 1000 4; time ./Event 4000 4 99 0 1000 4. Here, the CLI arguments are:; - 1: Number of events (4000); - 2: Compression ratio (6); - 3: Split level (99); - 4: 1 for write, 0 for read.; - 5: Number of tracks per event (1000).; - 6: Compression algorithm (1 = zlib, 2 = lzma, 4 = lz4. 3 is the deprecated zlib-like algorithm). I extended MainEvent.cxx to include TTreePerfStats information, which gives us access to the compression-time-only rates. Performance results (testing on a 2.6GHz Intel Westmere E56xx-based VM) summary:. LZ4HC compression:; - File size: 231MB; - 14.7MB/s CPU time for writing. ZLIB level-6 compression:; - File size: 189MB; - 10.5MB/s CPU time for writing.; Summary: LZ4HC compression resulted in a file 20% larger. Compression time was 44% faster. LZMA level-6 compression:; - File size: 163MB; - .62MB/s CPU time for writing.; Summary: LZMA compression resulted in a file 13% smaller. Compression time was 16x slower than ZLIB level-6. LZ4 decompression:; - 233MB/s CPU time for decompression only.; - 189MB/s CPU time for reading. ZLIB decompression:; - 118MB/s CPU time for decompression only; - 104MB/s CPU time for reading.; Summary: LZ4 decompression was 97% faster, resulting in 81% faster reading for this case. LZMA decompression:; - 15.4MB/s CPU time for decompression only; - 14.7MB/s CPU time for reading.; Summary: LZMA decompression was 7x slower than zlib.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/59
https://github.com/root-project/root/pull/61:96,Availability,avail,available,96,"Previously, it tried to use the clear method which does not exist. Corresponding unit tests are available on this branch:. https://github.com/bbockelm/roottest/tree/makeproject_bitset. @pcanal",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/61
https://github.com/root-project/root/pull/61:86,Testability,test,tests,86,"Previously, it tried to use the clear method which does not exist. Corresponding unit tests are available on this branch:. https://github.com/bbockelm/roottest/tree/makeproject_bitset. @pcanal",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/61
https://github.com/root-project/root/pull/61:32,Usability,clear,clear,32,"Previously, it tried to use the clear method which does not exist. Corresponding unit tests are available on this branch:. https://github.com/bbockelm/roottest/tree/makeproject_bitset. @pcanal",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/61
https://github.com/root-project/root/pull/64:102,Availability,error,error,102,When building with gcc49 on osx a linker assertion happens when linking interpreter module. Trial and error reveal that setting -O0 removes the linker assertion. Dan Riley found that adding the flag -fno-omit-frame-pointer also removed the linker assertion without removing other optimizations.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/64
https://github.com/root-project/root/pull/64:280,Performance,optimiz,optimizations,280,When building with gcc49 on osx a linker assertion happens when linking interpreter module. Trial and error reveal that setting -O0 removes the linker assertion. Dan Riley found that adding the flag -fno-omit-frame-pointer also removed the linker assertion without removing other optimizations.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/64
https://github.com/root-project/root/pull/64:41,Testability,assert,assertion,41,When building with gcc49 on osx a linker assertion happens when linking interpreter module. Trial and error reveal that setting -O0 removes the linker assertion. Dan Riley found that adding the flag -fno-omit-frame-pointer also removed the linker assertion without removing other optimizations.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/64
https://github.com/root-project/root/pull/64:151,Testability,assert,assertion,151,When building with gcc49 on osx a linker assertion happens when linking interpreter module. Trial and error reveal that setting -O0 removes the linker assertion. Dan Riley found that adding the flag -fno-omit-frame-pointer also removed the linker assertion without removing other optimizations.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/64
https://github.com/root-project/root/pull/64:247,Testability,assert,assertion,247,When building with gcc49 on osx a linker assertion happens when linking interpreter module. Trial and error reveal that setting -O0 removes the linker assertion. Dan Riley found that adding the flag -fno-omit-frame-pointer also removed the linker assertion without removing other optimizations.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/64
https://github.com/root-project/root/pull/65:102,Availability,error,error,102,When building with gcc49 on osx a linker assertion happens when linking interpreter module. Trial and error reveal that setting -O0 removes the linker assertion. Dan Riley found that adding the flag -fno-omit-frame-pointer also removed the linker assertion without removing other optimizations.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/65
https://github.com/root-project/root/pull/65:280,Performance,optimiz,optimizations,280,When building with gcc49 on osx a linker assertion happens when linking interpreter module. Trial and error reveal that setting -O0 removes the linker assertion. Dan Riley found that adding the flag -fno-omit-frame-pointer also removed the linker assertion without removing other optimizations.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/65
https://github.com/root-project/root/pull/65:41,Testability,assert,assertion,41,When building with gcc49 on osx a linker assertion happens when linking interpreter module. Trial and error reveal that setting -O0 removes the linker assertion. Dan Riley found that adding the flag -fno-omit-frame-pointer also removed the linker assertion without removing other optimizations.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/65
https://github.com/root-project/root/pull/65:151,Testability,assert,assertion,151,When building with gcc49 on osx a linker assertion happens when linking interpreter module. Trial and error reveal that setting -O0 removes the linker assertion. Dan Riley found that adding the flag -fno-omit-frame-pointer also removed the linker assertion without removing other optimizations.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/65
https://github.com/root-project/root/pull/65:247,Testability,assert,assertion,247,When building with gcc49 on osx a linker assertion happens when linking interpreter module. Trial and error reveal that setting -O0 removes the linker assertion. Dan Riley found that adding the flag -fno-omit-frame-pointer also removed the linker assertion without removing other optimizations.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/65
https://github.com/root-project/root/pull/68:36,Testability,assert,assert,36,This is a workaround for the linker assert when building with gcc on osx.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/68
https://github.com/root-project/root/pull/73:5,Deployability,patch,patch,5,"This patch installs python modules to python site-dir standard location (see some doc here:https://docs.python.org/2/library/site.html), see https://sft.its.cern.ch/jira/browse/ROOT-3316. It avoids to have to set PYTHONPATH when installing to a system folder /usr or /usr/local, and even the user site-dir ~/.local. Packaging may have to be reworked though (https://www.debian.org/doc/packaging-manuals/python-policy/ch-python.html#s-paths)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:11,Deployability,install,installs,11,"This patch installs python modules to python site-dir standard location (see some doc here:https://docs.python.org/2/library/site.html), see https://sft.its.cern.ch/jira/browse/ROOT-3316. It avoids to have to set PYTHONPATH when installing to a system folder /usr or /usr/local, and even the user site-dir ~/.local. Packaging may have to be reworked though (https://www.debian.org/doc/packaging-manuals/python-policy/ch-python.html#s-paths)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:229,Deployability,install,installing,229,"This patch installs python modules to python site-dir standard location (see some doc here:https://docs.python.org/2/library/site.html), see https://sft.its.cern.ch/jira/browse/ROOT-3316. It avoids to have to set PYTHONPATH when installing to a system folder /usr or /usr/local, and even the user site-dir ~/.local. Packaging may have to be reworked though (https://www.debian.org/doc/packaging-manuals/python-policy/ch-python.html#s-paths)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:191,Safety,avoid,avoids,191,"This patch installs python modules to python site-dir standard location (see some doc here:https://docs.python.org/2/library/site.html), see https://sft.its.cern.ch/jira/browse/ROOT-3316. It avoids to have to set PYTHONPATH when installing to a system folder /usr or /usr/local, and even the user site-dir ~/.local. Packaging may have to be reworked though (https://www.debian.org/doc/packaging-manuals/python-policy/ch-python.html#s-paths)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/74:263,Deployability,update,updated,263,"Code from ROOT R project,; -> New features added. now you can use R functions in C++ very easy using the class TRFunctionImport, that have overloaded operators to use objects like functions that receives template arguments and return TRObjects.; -> Documentation updated in http://oproject.org/tiki-index.php?page=ROOT+R+Users+Guide#Import. Best Regards",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/74
https://github.com/root-project/root/pull/74:327,Usability,Guid,Guide,327,"Code from ROOT R project,; -> New features added. now you can use R functions in C++ very easy using the class TRFunctionImport, that have overloaded operators to use objects like functions that receives template arguments and return TRObjects.; -> Documentation updated in http://oproject.org/tiki-index.php?page=ROOT+R+Users+Guide#Import. Best Regards",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/74
https://github.com/root-project/root/pull/75:585,Deployability,integrat,integration,585,"**1st commit:** Do not randomly add to lookup results during <code>EvaluateT()</code>; Axel fixed the notorious bug which prevented having templated <code>printValue()</code> functions in the ""RuntimePrintValue.h"" header which is declared programmatically on the first <code>printValue()</code>invocation. Runtime resolving of some identifiers was used when it shouldn't be. Moving the checking of this condition to the beginning of the function fixed the issue. **2nd commit:** Removed old <code>printValue</code> from TDatime and TString. **3rd commit:** New <code>printValue</code> integration. **4th commit:** Re-added <code>printValue</code> functionality to TString and TDatime. **5th, final commit:** Minor fix",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/75
https://github.com/root-project/root/pull/75:585,Integrability,integrat,integration,585,"**1st commit:** Do not randomly add to lookup results during <code>EvaluateT()</code>; Axel fixed the notorious bug which prevented having templated <code>printValue()</code> functions in the ""RuntimePrintValue.h"" header which is declared programmatically on the first <code>printValue()</code>invocation. Runtime resolving of some identifiers was used when it shouldn't be. Moving the checking of this condition to the beginning of the function fixed the issue. **2nd commit:** Removed old <code>printValue</code> from TDatime and TString. **3rd commit:** New <code>printValue</code> integration. **4th commit:** Re-added <code>printValue</code> functionality to TString and TDatime. **5th, final commit:** Minor fix",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/75
https://github.com/root-project/root/pull/76:141,Usability,simpl,simpler,141,Print value fixes introduced based on comments after the first pull request.; Removed the old code and made various changes to make the code simpler.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/76
https://github.com/root-project/root/pull/78:371,Availability,error,error,371,"Catch-all printValue implementation changed to enable correct invocation if only parent type overload exists (ex. if there is no overload for TF1*, compiler invokes the overload to its best parent overload match, in the worst case void*). Argument changed from reference to pointer to support this.; isEnumType Coverity bug changed from if to assert (coding, not runtime error); Changed the way printValue is invoked in order to correctly cast Value to the needed value (e.g. LL -> short). Extracted value stays in scope while we execute printValue, because we use the address.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/78
https://github.com/root-project/root/pull/78:343,Testability,assert,assert,343,"Catch-all printValue implementation changed to enable correct invocation if only parent type overload exists (ex. if there is no overload for TF1*, compiler invokes the overload to its best parent overload match, in the worst case void*). Argument changed from reference to pointer to support this.; isEnumType Coverity bug changed from if to assert (coding, not runtime error); Changed the way printValue is invoked in order to correctly cast Value to the needed value (e.g. LL -> short). Extracted value stays in scope while we execute printValue, because we use the address.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/78
https://github.com/root-project/root/pull/81:10,Deployability,update,updated,10,"This is a updated pull request from #59 The same experiments have been run and performance results are shown here:. | Algorithm | compression(write) | decompression(read) | Compressed File Size |; | --- | --- | --- | --- |; | zlib | 11.74 MB/s | 131.06 MB/s | 181 MB |; | lzma | 0.86 MB/s | 17.36 MB/s | 157 MB |; | lz4 | 5.22 MB/s | 143.81 MB/s | 221 MB |. The following performance is from the root file @pcanal's ticket (https://root.cern.ch/files/CMS_7250E9A5-682D-DF11-8701-002618943934.root). The file is 1.9 GB large, and I tried to decompressed it and it seems its original size is 6.4 GB. The following compression/decompression speeds are calculated by dividing 6.4 GB by the time each test run. @bbockelm , we could discuss implementation details of my tests tomorrow. . | Algorithm | compression(write) | decompression(read) | Compressed File Size |; | --- | --- | --- | --- |; | zlib | 15.83 MB/s | 63.23 MB/s | 1.6 GB |; | lzma | 1.28 MB/s | 22.62 MB/s | 1.2 GB |; | lz4 | 8.32 MB/s | 66.53 MB/s | 1.8 GB |",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:79,Performance,perform,performance,79,"This is a updated pull request from #59 The same experiments have been run and performance results are shown here:. | Algorithm | compression(write) | decompression(read) | Compressed File Size |; | --- | --- | --- | --- |; | zlib | 11.74 MB/s | 131.06 MB/s | 181 MB |; | lzma | 0.86 MB/s | 17.36 MB/s | 157 MB |; | lz4 | 5.22 MB/s | 143.81 MB/s | 221 MB |. The following performance is from the root file @pcanal's ticket (https://root.cern.ch/files/CMS_7250E9A5-682D-DF11-8701-002618943934.root). The file is 1.9 GB large, and I tried to decompressed it and it seems its original size is 6.4 GB. The following compression/decompression speeds are calculated by dividing 6.4 GB by the time each test run. @bbockelm , we could discuss implementation details of my tests tomorrow. . | Algorithm | compression(write) | decompression(read) | Compressed File Size |; | --- | --- | --- | --- |; | zlib | 15.83 MB/s | 63.23 MB/s | 1.6 GB |; | lzma | 1.28 MB/s | 22.62 MB/s | 1.2 GB |; | lz4 | 8.32 MB/s | 66.53 MB/s | 1.8 GB |",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:372,Performance,perform,performance,372,"This is a updated pull request from #59 The same experiments have been run and performance results are shown here:. | Algorithm | compression(write) | decompression(read) | Compressed File Size |; | --- | --- | --- | --- |; | zlib | 11.74 MB/s | 131.06 MB/s | 181 MB |; | lzma | 0.86 MB/s | 17.36 MB/s | 157 MB |; | lz4 | 5.22 MB/s | 143.81 MB/s | 221 MB |. The following performance is from the root file @pcanal's ticket (https://root.cern.ch/files/CMS_7250E9A5-682D-DF11-8701-002618943934.root). The file is 1.9 GB large, and I tried to decompressed it and it seems its original size is 6.4 GB. The following compression/decompression speeds are calculated by dividing 6.4 GB by the time each test run. @bbockelm , we could discuss implementation details of my tests tomorrow. . | Algorithm | compression(write) | decompression(read) | Compressed File Size |; | --- | --- | --- | --- |; | zlib | 15.83 MB/s | 63.23 MB/s | 1.6 GB |; | lzma | 1.28 MB/s | 22.62 MB/s | 1.2 GB |; | lz4 | 8.32 MB/s | 66.53 MB/s | 1.8 GB |",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:696,Testability,test,test,696,"This is a updated pull request from #59 The same experiments have been run and performance results are shown here:. | Algorithm | compression(write) | decompression(read) | Compressed File Size |; | --- | --- | --- | --- |; | zlib | 11.74 MB/s | 131.06 MB/s | 181 MB |; | lzma | 0.86 MB/s | 17.36 MB/s | 157 MB |; | lz4 | 5.22 MB/s | 143.81 MB/s | 221 MB |. The following performance is from the root file @pcanal's ticket (https://root.cern.ch/files/CMS_7250E9A5-682D-DF11-8701-002618943934.root). The file is 1.9 GB large, and I tried to decompressed it and it seems its original size is 6.4 GB. The following compression/decompression speeds are calculated by dividing 6.4 GB by the time each test run. @bbockelm , we could discuss implementation details of my tests tomorrow. . | Algorithm | compression(write) | decompression(read) | Compressed File Size |; | --- | --- | --- | --- |; | zlib | 15.83 MB/s | 63.23 MB/s | 1.6 GB |; | lzma | 1.28 MB/s | 22.62 MB/s | 1.2 GB |; | lz4 | 8.32 MB/s | 66.53 MB/s | 1.8 GB |",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:764,Testability,test,tests,764,"This is a updated pull request from #59 The same experiments have been run and performance results are shown here:. | Algorithm | compression(write) | decompression(read) | Compressed File Size |; | --- | --- | --- | --- |; | zlib | 11.74 MB/s | 131.06 MB/s | 181 MB |; | lzma | 0.86 MB/s | 17.36 MB/s | 157 MB |; | lz4 | 5.22 MB/s | 143.81 MB/s | 221 MB |. The following performance is from the root file @pcanal's ticket (https://root.cern.ch/files/CMS_7250E9A5-682D-DF11-8701-002618943934.root). The file is 1.9 GB large, and I tried to decompressed it and it seems its original size is 6.4 GB. The following compression/decompression speeds are calculated by dividing 6.4 GB by the time each test run. @bbockelm , we could discuss implementation details of my tests tomorrow. . | Algorithm | compression(write) | decompression(read) | Compressed File Size |; | --- | --- | --- | --- |; | zlib | 15.83 MB/s | 63.23 MB/s | 1.6 GB |; | lzma | 1.28 MB/s | 22.62 MB/s | 1.2 GB |; | lz4 | 8.32 MB/s | 66.53 MB/s | 1.8 GB |",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/82:13,Testability,test,test,13,Passes cling test and roottest.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/82
https://github.com/root-project/root/pull/83:333,Deployability,update,updated,333,"Hi Axel and Lorenzo,. I take the code and I put it in one commit to let review it easy.; In resume the changes are ; -> Now you can use R functions in C++ very easy using the class TRFunctionImport, that have overloaded operators to use objects like functions that receives template arguments and return TRObjects.; -> Documentation updated in http://oproject.org/tiki-index.php?page=ROOT+R+Users+Guide#Import; -> added documentation in doxygen; -> new propieties for TRDataFrame with operators. You can see the output of documentation in; http://files.oproject.org/root/rootdoc/html/group___r.html; users guide in markdown integrate to doxygen ; http://files.oproject.org/root/rootdoc/html/md__home_omazapa_root_bindings_r_doc_users-guide__r_o_o_t_r__users__guide.html. I have the code now in http://github.com/oprojects/root. Best Regards; O.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/83
https://github.com/root-project/root/pull/83:624,Deployability,integrat,integrate,624,"Hi Axel and Lorenzo,. I take the code and I put it in one commit to let review it easy.; In resume the changes are ; -> Now you can use R functions in C++ very easy using the class TRFunctionImport, that have overloaded operators to use objects like functions that receives template arguments and return TRObjects.; -> Documentation updated in http://oproject.org/tiki-index.php?page=ROOT+R+Users+Guide#Import; -> added documentation in doxygen; -> new propieties for TRDataFrame with operators. You can see the output of documentation in; http://files.oproject.org/root/rootdoc/html/group___r.html; users guide in markdown integrate to doxygen ; http://files.oproject.org/root/rootdoc/html/md__home_omazapa_root_bindings_r_doc_users-guide__r_o_o_t_r__users__guide.html. I have the code now in http://github.com/oprojects/root. Best Regards; O.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/83
https://github.com/root-project/root/pull/83:624,Integrability,integrat,integrate,624,"Hi Axel and Lorenzo,. I take the code and I put it in one commit to let review it easy.; In resume the changes are ; -> Now you can use R functions in C++ very easy using the class TRFunctionImport, that have overloaded operators to use objects like functions that receives template arguments and return TRObjects.; -> Documentation updated in http://oproject.org/tiki-index.php?page=ROOT+R+Users+Guide#Import; -> added documentation in doxygen; -> new propieties for TRDataFrame with operators. You can see the output of documentation in; http://files.oproject.org/root/rootdoc/html/group___r.html; users guide in markdown integrate to doxygen ; http://files.oproject.org/root/rootdoc/html/md__home_omazapa_root_bindings_r_doc_users-guide__r_o_o_t_r__users__guide.html. I have the code now in http://github.com/oprojects/root. Best Regards; O.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/83
https://github.com/root-project/root/pull/83:92,Usability,resume,resume,92,"Hi Axel and Lorenzo,. I take the code and I put it in one commit to let review it easy.; In resume the changes are ; -> Now you can use R functions in C++ very easy using the class TRFunctionImport, that have overloaded operators to use objects like functions that receives template arguments and return TRObjects.; -> Documentation updated in http://oproject.org/tiki-index.php?page=ROOT+R+Users+Guide#Import; -> added documentation in doxygen; -> new propieties for TRDataFrame with operators. You can see the output of documentation in; http://files.oproject.org/root/rootdoc/html/group___r.html; users guide in markdown integrate to doxygen ; http://files.oproject.org/root/rootdoc/html/md__home_omazapa_root_bindings_r_doc_users-guide__r_o_o_t_r__users__guide.html. I have the code now in http://github.com/oprojects/root. Best Regards; O.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/83
https://github.com/root-project/root/pull/83:397,Usability,Guid,Guide,397,"Hi Axel and Lorenzo,. I take the code and I put it in one commit to let review it easy.; In resume the changes are ; -> Now you can use R functions in C++ very easy using the class TRFunctionImport, that have overloaded operators to use objects like functions that receives template arguments and return TRObjects.; -> Documentation updated in http://oproject.org/tiki-index.php?page=ROOT+R+Users+Guide#Import; -> added documentation in doxygen; -> new propieties for TRDataFrame with operators. You can see the output of documentation in; http://files.oproject.org/root/rootdoc/html/group___r.html; users guide in markdown integrate to doxygen ; http://files.oproject.org/root/rootdoc/html/md__home_omazapa_root_bindings_r_doc_users-guide__r_o_o_t_r__users__guide.html. I have the code now in http://github.com/oprojects/root. Best Regards; O.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/83
https://github.com/root-project/root/pull/83:606,Usability,guid,guide,606,"Hi Axel and Lorenzo,. I take the code and I put it in one commit to let review it easy.; In resume the changes are ; -> Now you can use R functions in C++ very easy using the class TRFunctionImport, that have overloaded operators to use objects like functions that receives template arguments and return TRObjects.; -> Documentation updated in http://oproject.org/tiki-index.php?page=ROOT+R+Users+Guide#Import; -> added documentation in doxygen; -> new propieties for TRDataFrame with operators. You can see the output of documentation in; http://files.oproject.org/root/rootdoc/html/group___r.html; users guide in markdown integrate to doxygen ; http://files.oproject.org/root/rootdoc/html/md__home_omazapa_root_bindings_r_doc_users-guide__r_o_o_t_r__users__guide.html. I have the code now in http://github.com/oprojects/root. Best Regards; O.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/83
https://github.com/root-project/root/pull/84:90,Availability,error,error,90,"cin is not seekable. Temporary stringstream is created to store cin. This patch fixes the error. But I am afraid using intermediate stringstream is not an efficient way, especially it costs a lot of memory if the input file is large. Any suggestion? @bbockelm",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:74,Deployability,patch,patch,74,"cin is not seekable. Temporary stringstream is created to store cin. This patch fixes the error. But I am afraid using intermediate stringstream is not an efficient way, especially it costs a lot of memory if the input file is large. Any suggestion? @bbockelm",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:155,Energy Efficiency,efficient,efficient,155,"cin is not seekable. Temporary stringstream is created to store cin. This patch fixes the error. But I am afraid using intermediate stringstream is not an efficient way, especially it costs a lot of memory if the input file is large. Any suggestion? @bbockelm",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/85:219,Usability,intuit,intuitive,219,"Implemented corresponding print behavior.; Maybe revise this meta command's behavior in the case of a missing argument (print out the current value, instead of toggling between two defaults), if it turns out to be more intuitive.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/85
https://github.com/root-project/root/pull/88:382,Availability,error,error,382,"This is a pull request based on the patch in https://sft.its.cern.ch/jira/browse/ROOT-7541. The public (installed) header TXSocket.h #includes the private (not installed) header XrdProofConn.h. This means it can not be used in compilations:. g++ -I/usr/include/root -x c++ - <<< '#include ""TXSocket.h""'; In file included from <stdin>:1:0:; /usr/include/root/TXSocket.h:47:26: fatal error: XrdProofConn.h: No such file or directory; compilation terminated. A possible fix is provided in the attached patch.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/88
https://github.com/root-project/root/pull/88:36,Deployability,patch,patch,36,"This is a pull request based on the patch in https://sft.its.cern.ch/jira/browse/ROOT-7541. The public (installed) header TXSocket.h #includes the private (not installed) header XrdProofConn.h. This means it can not be used in compilations:. g++ -I/usr/include/root -x c++ - <<< '#include ""TXSocket.h""'; In file included from <stdin>:1:0:; /usr/include/root/TXSocket.h:47:26: fatal error: XrdProofConn.h: No such file or directory; compilation terminated. A possible fix is provided in the attached patch.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/88
https://github.com/root-project/root/pull/88:104,Deployability,install,installed,104,"This is a pull request based on the patch in https://sft.its.cern.ch/jira/browse/ROOT-7541. The public (installed) header TXSocket.h #includes the private (not installed) header XrdProofConn.h. This means it can not be used in compilations:. g++ -I/usr/include/root -x c++ - <<< '#include ""TXSocket.h""'; In file included from <stdin>:1:0:; /usr/include/root/TXSocket.h:47:26: fatal error: XrdProofConn.h: No such file or directory; compilation terminated. A possible fix is provided in the attached patch.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/88
https://github.com/root-project/root/pull/88:160,Deployability,install,installed,160,"This is a pull request based on the patch in https://sft.its.cern.ch/jira/browse/ROOT-7541. The public (installed) header TXSocket.h #includes the private (not installed) header XrdProofConn.h. This means it can not be used in compilations:. g++ -I/usr/include/root -x c++ - <<< '#include ""TXSocket.h""'; In file included from <stdin>:1:0:; /usr/include/root/TXSocket.h:47:26: fatal error: XrdProofConn.h: No such file or directory; compilation terminated. A possible fix is provided in the attached patch.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/88
https://github.com/root-project/root/pull/88:499,Deployability,patch,patch,499,"This is a pull request based on the patch in https://sft.its.cern.ch/jira/browse/ROOT-7541. The public (installed) header TXSocket.h #includes the private (not installed) header XrdProofConn.h. This means it can not be used in compilations:. g++ -I/usr/include/root -x c++ - <<< '#include ""TXSocket.h""'; In file included from <stdin>:1:0:; /usr/include/root/TXSocket.h:47:26: fatal error: XrdProofConn.h: No such file or directory; compilation terminated. A possible fix is provided in the attached patch.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/88
https://github.com/root-project/root/pull/89:110,Availability,error,errors,110,This is a pull request based on the patch in https://sft.its.cern.ch/jira/browse/ROOT-5494. Fixes compilation errors and warnings in the THDFS module.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/89
https://github.com/root-project/root/pull/89:36,Deployability,patch,patch,36,This is a pull request based on the patch in https://sft.its.cern.ch/jira/browse/ROOT-5494. Fixes compilation errors and warnings in the THDFS module.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/89
https://github.com/root-project/root/pull/90:36,Deployability,patch,patches,36,"This is a pull request based on the patches in https://sft.its.cern.ch/jira/browse/ROOT-7457. There are two problem with the code. Looking at a hexdump of a Type 1 font:. ```; 00000000 80 01 fb 15 00 00 25 21 50 53 2d 41 64 6f 62 65 |......%!PS-Adobe|; 00000010 46 6f 6e 74 2d 31 2e 30 3a 20 53 74 61 6e 64 61 |Font-1.0: Standa|; [ ... ]; 00008390 30 30 30 30 30 30 30 30 30 30 30 30 30 30 0d 63 |00000000000000.c|; 000083a0 6c 65 61 72 74 6f 6d 61 72 6b 0a 80 03 |leartomark...|; ```. The code currently reads beyond the 80 03 at the end of the file by trying to determing the length of the following block - but an end of file block does not have a length, the file ends right after the end of file block tag 08 03. The length is in little endian format - as can be seen in the beginning of the file. The ascii block tag 80 01 is followed by fb 15 00 00 which is little endian for 000015fb. So it is big endian architectures that needs to do a byte swap, not little endian ones as in the current code. The first attached patch addresses these issues. The second patch implements returning the fontname for Type 1 embedding.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/90
https://github.com/root-project/root/pull/90:1023,Deployability,patch,patch,1023,"This is a pull request based on the patches in https://sft.its.cern.ch/jira/browse/ROOT-7457. There are two problem with the code. Looking at a hexdump of a Type 1 font:. ```; 00000000 80 01 fb 15 00 00 25 21 50 53 2d 41 64 6f 62 65 |......%!PS-Adobe|; 00000010 46 6f 6e 74 2d 31 2e 30 3a 20 53 74 61 6e 64 61 |Font-1.0: Standa|; [ ... ]; 00008390 30 30 30 30 30 30 30 30 30 30 30 30 30 30 0d 63 |00000000000000.c|; 000083a0 6c 65 61 72 74 6f 6d 61 72 6b 0a 80 03 |leartomark...|; ```. The code currently reads beyond the 80 03 at the end of the file by trying to determing the length of the following block - but an end of file block does not have a length, the file ends right after the end of file block tag 08 03. The length is in little endian format - as can be seen in the beginning of the file. The ascii block tag 80 01 is followed by fb 15 00 00 which is little endian for 000015fb. So it is big endian architectures that needs to do a byte swap, not little endian ones as in the current code. The first attached patch addresses these issues. The second patch implements returning the fontname for Type 1 embedding.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/90
https://github.com/root-project/root/pull/90:1064,Deployability,patch,patch,1064,"This is a pull request based on the patches in https://sft.its.cern.ch/jira/browse/ROOT-7457. There are two problem with the code. Looking at a hexdump of a Type 1 font:. ```; 00000000 80 01 fb 15 00 00 25 21 50 53 2d 41 64 6f 62 65 |......%!PS-Adobe|; 00000010 46 6f 6e 74 2d 31 2e 30 3a 20 53 74 61 6e 64 61 |Font-1.0: Standa|; [ ... ]; 00008390 30 30 30 30 30 30 30 30 30 30 30 30 30 30 0d 63 |00000000000000.c|; 000083a0 6c 65 61 72 74 6f 6d 61 72 6b 0a 80 03 |leartomark...|; ```. The code currently reads beyond the 80 03 at the end of the file by trying to determing the length of the following block - but an end of file block does not have a length, the file ends right after the end of file block tag 08 03. The length is in little endian format - as can be seen in the beginning of the file. The ascii block tag 80 01 is followed by fb 15 00 00 which is little endian for 000015fb. So it is big endian architectures that needs to do a byte swap, not little endian ones as in the current code. The first attached patch addresses these issues. The second patch implements returning the fontname for Type 1 embedding.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/90
https://github.com/root-project/root/pull/91:273,Deployability,patch,patch,273,"The bonjour support in xrootd (XrdOuc/XrdOucBonjour.hh) was dropped in xrootd 3.2.0, which is now a long time ago. The code in root that requires this header is therefore now dead code since a long time. The test in configure to enable it newer worked anyway. The attached patch removes the dead code.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/91
https://github.com/root-project/root/pull/91:216,Modifiability,config,configure,216,"The bonjour support in xrootd (XrdOuc/XrdOucBonjour.hh) was dropped in xrootd 3.2.0, which is now a long time ago. The code in root that requires this header is therefore now dead code since a long time. The test in configure to enable it newer worked anyway. The attached patch removes the dead code.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/91
https://github.com/root-project/root/pull/91:208,Testability,test,test,208,"The bonjour support in xrootd (XrdOuc/XrdOucBonjour.hh) was dropped in xrootd 3.2.0, which is now a long time ago. The code in root that requires this header is therefore now dead code since a long time. The test in configure to enable it newer worked anyway. The attached patch removes the dead code.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/91
https://github.com/root-project/root/pull/93:37,Performance,cache,cached,37,If the GetCheckSum value was already cached then the argument passed; to the function was not set. This now properly sets the value.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/93
https://github.com/root-project/root/pull/94:12,Deployability,patch,patches,12,"This set of patches makes THDFSFile work again. ; It also enables CMake build and allows linking against libhdfs3 (experimental native HDFS client implementation). Kind of major change: HDFS URLs are now absolute instead of relative as it was before. I.e. one have to use ""hdfs:///user/username/dir1/file2.root"" notation to access file in the home directory. ; This makes HDFS URLs somewhat standard in the sense that they could be used interchangeably between ROOT and Hadoop API and command-line utilities.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/94
https://github.com/root-project/root/pull/94:324,Security,access,access,324,"This set of patches makes THDFSFile work again. ; It also enables CMake build and allows linking against libhdfs3 (experimental native HDFS client implementation). Kind of major change: HDFS URLs are now absolute instead of relative as it was before. I.e. one have to use ""hdfs:///user/username/dir1/file2.root"" notation to access file in the home directory. ; This makes HDFS URLs somewhat standard in the sense that they could be used interchangeably between ROOT and Hadoop API and command-line utilities.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/94
https://github.com/root-project/root/pull/95:25,Deployability,release,release-indices,25,"User-visible places: Old release-indices, informative output of hadd.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/95
https://github.com/root-project/root/pull/96:5,Deployability,patch,patch,5,"This patch reimplemented signal handling in CMSSW. It avoids async-unsafe functions in signal handler. For reference, see the link https://github.com/bbockelm/cmssw/blob/stacktrace_handler_revisit/FWCore/Services/src/InitRootHandlers.cc. I tried this patch with some simple multi-thread test cases and it worked fine. Is there any complicated test cases I can run? I think this patch is not very ready to merge, but it achieved basic functions. Any criticisms are welcome.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/96
https://github.com/root-project/root/pull/96:251,Deployability,patch,patch,251,"This patch reimplemented signal handling in CMSSW. It avoids async-unsafe functions in signal handler. For reference, see the link https://github.com/bbockelm/cmssw/blob/stacktrace_handler_revisit/FWCore/Services/src/InitRootHandlers.cc. I tried this patch with some simple multi-thread test cases and it worked fine. Is there any complicated test cases I can run? I think this patch is not very ready to merge, but it achieved basic functions. Any criticisms are welcome.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/96
https://github.com/root-project/root/pull/96:378,Deployability,patch,patch,378,"This patch reimplemented signal handling in CMSSW. It avoids async-unsafe functions in signal handler. For reference, see the link https://github.com/bbockelm/cmssw/blob/stacktrace_handler_revisit/FWCore/Services/src/InitRootHandlers.cc. I tried this patch with some simple multi-thread test cases and it worked fine. Is there any complicated test cases I can run? I think this patch is not very ready to merge, but it achieved basic functions. Any criticisms are welcome.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/96
https://github.com/root-project/root/pull/96:274,Performance,multi-thread,multi-thread,274,"This patch reimplemented signal handling in CMSSW. It avoids async-unsafe functions in signal handler. For reference, see the link https://github.com/bbockelm/cmssw/blob/stacktrace_handler_revisit/FWCore/Services/src/InitRootHandlers.cc. I tried this patch with some simple multi-thread test cases and it worked fine. Is there any complicated test cases I can run? I think this patch is not very ready to merge, but it achieved basic functions. Any criticisms are welcome.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/96
https://github.com/root-project/root/pull/96:54,Safety,avoid,avoids,54,"This patch reimplemented signal handling in CMSSW. It avoids async-unsafe functions in signal handler. For reference, see the link https://github.com/bbockelm/cmssw/blob/stacktrace_handler_revisit/FWCore/Services/src/InitRootHandlers.cc. I tried this patch with some simple multi-thread test cases and it worked fine. Is there any complicated test cases I can run? I think this patch is not very ready to merge, but it achieved basic functions. Any criticisms are welcome.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/96
https://github.com/root-project/root/pull/96:67,Safety,unsafe,unsafe,67,"This patch reimplemented signal handling in CMSSW. It avoids async-unsafe functions in signal handler. For reference, see the link https://github.com/bbockelm/cmssw/blob/stacktrace_handler_revisit/FWCore/Services/src/InitRootHandlers.cc. I tried this patch with some simple multi-thread test cases and it worked fine. Is there any complicated test cases I can run? I think this patch is not very ready to merge, but it achieved basic functions. Any criticisms are welcome.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/96
https://github.com/root-project/root/pull/96:287,Testability,test,test,287,"This patch reimplemented signal handling in CMSSW. It avoids async-unsafe functions in signal handler. For reference, see the link https://github.com/bbockelm/cmssw/blob/stacktrace_handler_revisit/FWCore/Services/src/InitRootHandlers.cc. I tried this patch with some simple multi-thread test cases and it worked fine. Is there any complicated test cases I can run? I think this patch is not very ready to merge, but it achieved basic functions. Any criticisms are welcome.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/96
https://github.com/root-project/root/pull/96:343,Testability,test,test,343,"This patch reimplemented signal handling in CMSSW. It avoids async-unsafe functions in signal handler. For reference, see the link https://github.com/bbockelm/cmssw/blob/stacktrace_handler_revisit/FWCore/Services/src/InitRootHandlers.cc. I tried this patch with some simple multi-thread test cases and it worked fine. Is there any complicated test cases I can run? I think this patch is not very ready to merge, but it achieved basic functions. Any criticisms are welcome.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/96
https://github.com/root-project/root/pull/96:267,Usability,simpl,simple,267,"This patch reimplemented signal handling in CMSSW. It avoids async-unsafe functions in signal handler. For reference, see the link https://github.com/bbockelm/cmssw/blob/stacktrace_handler_revisit/FWCore/Services/src/InitRootHandlers.cc. I tried this patch with some simple multi-thread test cases and it worked fine. Is there any complicated test cases I can run? I think this patch is not very ready to merge, but it achieved basic functions. Any criticisms are welcome.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/96
https://github.com/root-project/root/pull/97:23,Deployability,patch,patch,23,"@bbockelm @pcanal This patch copies the code of signal handling in CMSSW. It avoids async-unsafe functions in signal handler functions. . For reference, see the link https://github.com/bbockelm/cmssw/blob/stacktrace_handler_revisit/FWCore/Services/src/InitRootHandlers.cc. I tried this patch with some simple multi-thread test cases and it worked fine. Is there any complicated test cases I can run? I think this patch is not very ready to merge, but it achieved basic functions. Any criticisms are welcome.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/97
https://github.com/root-project/root/pull/97:286,Deployability,patch,patch,286,"@bbockelm @pcanal This patch copies the code of signal handling in CMSSW. It avoids async-unsafe functions in signal handler functions. . For reference, see the link https://github.com/bbockelm/cmssw/blob/stacktrace_handler_revisit/FWCore/Services/src/InitRootHandlers.cc. I tried this patch with some simple multi-thread test cases and it worked fine. Is there any complicated test cases I can run? I think this patch is not very ready to merge, but it achieved basic functions. Any criticisms are welcome.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/97
https://github.com/root-project/root/pull/97:413,Deployability,patch,patch,413,"@bbockelm @pcanal This patch copies the code of signal handling in CMSSW. It avoids async-unsafe functions in signal handler functions. . For reference, see the link https://github.com/bbockelm/cmssw/blob/stacktrace_handler_revisit/FWCore/Services/src/InitRootHandlers.cc. I tried this patch with some simple multi-thread test cases and it worked fine. Is there any complicated test cases I can run? I think this patch is not very ready to merge, but it achieved basic functions. Any criticisms are welcome.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/97
https://github.com/root-project/root/pull/97:309,Performance,multi-thread,multi-thread,309,"@bbockelm @pcanal This patch copies the code of signal handling in CMSSW. It avoids async-unsafe functions in signal handler functions. . For reference, see the link https://github.com/bbockelm/cmssw/blob/stacktrace_handler_revisit/FWCore/Services/src/InitRootHandlers.cc. I tried this patch with some simple multi-thread test cases and it worked fine. Is there any complicated test cases I can run? I think this patch is not very ready to merge, but it achieved basic functions. Any criticisms are welcome.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/97
https://github.com/root-project/root/pull/97:77,Safety,avoid,avoids,77,"@bbockelm @pcanal This patch copies the code of signal handling in CMSSW. It avoids async-unsafe functions in signal handler functions. . For reference, see the link https://github.com/bbockelm/cmssw/blob/stacktrace_handler_revisit/FWCore/Services/src/InitRootHandlers.cc. I tried this patch with some simple multi-thread test cases and it worked fine. Is there any complicated test cases I can run? I think this patch is not very ready to merge, but it achieved basic functions. Any criticisms are welcome.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/97
https://github.com/root-project/root/pull/97:90,Safety,unsafe,unsafe,90,"@bbockelm @pcanal This patch copies the code of signal handling in CMSSW. It avoids async-unsafe functions in signal handler functions. . For reference, see the link https://github.com/bbockelm/cmssw/blob/stacktrace_handler_revisit/FWCore/Services/src/InitRootHandlers.cc. I tried this patch with some simple multi-thread test cases and it worked fine. Is there any complicated test cases I can run? I think this patch is not very ready to merge, but it achieved basic functions. Any criticisms are welcome.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/97
https://github.com/root-project/root/pull/97:322,Testability,test,test,322,"@bbockelm @pcanal This patch copies the code of signal handling in CMSSW. It avoids async-unsafe functions in signal handler functions. . For reference, see the link https://github.com/bbockelm/cmssw/blob/stacktrace_handler_revisit/FWCore/Services/src/InitRootHandlers.cc. I tried this patch with some simple multi-thread test cases and it worked fine. Is there any complicated test cases I can run? I think this patch is not very ready to merge, but it achieved basic functions. Any criticisms are welcome.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/97
https://github.com/root-project/root/pull/97:378,Testability,test,test,378,"@bbockelm @pcanal This patch copies the code of signal handling in CMSSW. It avoids async-unsafe functions in signal handler functions. . For reference, see the link https://github.com/bbockelm/cmssw/blob/stacktrace_handler_revisit/FWCore/Services/src/InitRootHandlers.cc. I tried this patch with some simple multi-thread test cases and it worked fine. Is there any complicated test cases I can run? I think this patch is not very ready to merge, but it achieved basic functions. Any criticisms are welcome.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/97
https://github.com/root-project/root/pull/97:302,Usability,simpl,simple,302,"@bbockelm @pcanal This patch copies the code of signal handling in CMSSW. It avoids async-unsafe functions in signal handler functions. . For reference, see the link https://github.com/bbockelm/cmssw/blob/stacktrace_handler_revisit/FWCore/Services/src/InitRootHandlers.cc. I tried this patch with some simple multi-thread test cases and it worked fine. Is there any complicated test cases I can run? I think this patch is not very ready to merge, but it achieved basic functions. Any criticisms are welcome.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/97
https://github.com/root-project/root/pull/98:210,Safety,avoid,avoiding,210,It is a minor fix but I though it would be nice to have the complete list since; I always forget the style names for polymarkers and use this documentation as; a reference. May also save someone else's time by avoiding a lookup in the; header file.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/98
https://github.com/root-project/root/pull/99:565,Integrability,interface,interface,565,"Parts of this were accessed through redefining private/protected as public; which, besides of being a nasty hack, does not work with gcc-5. TColor had a static bool member fgInitDone that is now a local static in InitializeColors(). I just added a bool argument force=kFALSE as this was a minimal change. If desired, I can do the following:; . Split InitializeColors() into initial part that does the check is-init-done and the actual initialization code that is private.; . Introduce new static function InitializeColorsForce() that skips the check.; This way the interface to InitializeColors() will not change.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/99
https://github.com/root-project/root/pull/99:19,Security,access,accessed,19,"Parts of this were accessed through redefining private/protected as public; which, besides of being a nasty hack, does not work with gcc-5. TColor had a static bool member fgInitDone that is now a local static in InitializeColors(). I just added a bool argument force=kFALSE as this was a minimal change. If desired, I can do the following:; . Split InitializeColors() into initial part that does the check is-init-done and the actual initialization code that is private.; . Introduce new static function InitializeColorsForce() that skips the check.; This way the interface to InitializeColors() will not change.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/99
https://github.com/root-project/root/pull/100:134,Integrability,depend,depends,134,"Increase the speed of BDT training. For regression analysis with Grad boosting, the speed gain is almost 2x.; For multiclass the gain depends on the number of multiclasses.; For classification: haven't done the test. Non BDT algorithms will also be faster (assuming the progress bar is enabled).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/100
https://github.com/root-project/root/pull/100:211,Testability,test,test,211,"Increase the speed of BDT training. For regression analysis with Grad boosting, the speed gain is almost 2x.; For multiclass the gain depends on the number of multiclasses.; For classification: haven't done the test. Non BDT algorithms will also be faster (assuming the progress bar is enabled).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/100
https://github.com/root-project/root/pull/100:270,Usability,progress bar,progress bar,270,"Increase the speed of BDT training. For regression analysis with Grad boosting, the speed gain is almost 2x.; For multiclass the gain depends on the number of multiclasses.; For classification: haven't done the test. Non BDT algorithms will also be faster (assuming the progress bar is enabled).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/100
https://github.com/root-project/root/pull/102:49,Deployability,patch,patches,49,@pcanal @davidlt -- this is the backport to 6.04-patches.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/102
https://github.com/root-project/root/pull/103:49,Deployability,patch,patches,49,@pcanal @davidlt -- this is the backport to 6.02-patches.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/103
https://github.com/root-project/root/pull/108:112,Integrability,Protocol,Protocols,112,"According to the RFC 2616, a 301 Status Code only ""SHOULD"" return; the new URI -- not ""MUST"". http://www.w3.org/Protocols/rfc2616/rfc2616-sec10.html#sec10.3.2. Jira #7809: https://sft.its.cern.ch/jira/browse/ROOT-7809",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/108
https://github.com/root-project/root/pull/109:29,Availability,error,error,29,required to suppress warning/error when compiling with -Werror=effc++,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/109
https://github.com/root-project/root/pull/110:65,Security,Secur,Security,65,"Hi,. Amazon has this concept of short-lived credentials via the ""Security Token Service"" (https://aws.amazon.com/documentation/iam/). In addition to generating the usual access and secure keys, the STS also generates a session token that needs to be used. This adds support for this. . I made fToken public instead of a do-nothing getter, but that's a trivial change if you prefer it the other way. (Also I should ask Georgios and friends to add this to davix - I didn't see it from a cursory glance at the code.)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/110
https://github.com/root-project/root/pull/110:170,Security,access,access,170,"Hi,. Amazon has this concept of short-lived credentials via the ""Security Token Service"" (https://aws.amazon.com/documentation/iam/). In addition to generating the usual access and secure keys, the STS also generates a session token that needs to be used. This adds support for this. . I made fToken public instead of a do-nothing getter, but that's a trivial change if you prefer it the other way. (Also I should ask Georgios and friends to add this to davix - I didn't see it from a cursory glance at the code.)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/110
https://github.com/root-project/root/pull/110:181,Security,secur,secure,181,"Hi,. Amazon has this concept of short-lived credentials via the ""Security Token Service"" (https://aws.amazon.com/documentation/iam/). In addition to generating the usual access and secure keys, the STS also generates a session token that needs to be used. This adds support for this. . I made fToken public instead of a do-nothing getter, but that's a trivial change if you prefer it the other way. (Also I should ask Georgios and friends to add this to davix - I didn't see it from a cursory glance at the code.)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/110
https://github.com/root-project/root/pull/115:43,Deployability,update,updated,43,"This is a fix for ROOT-7121. If a cache is updated in RooVectorDataStore and the cache has more than 1000 elements to be updated, an array on the stack will overrun and smash the stack. roofit will therefore crash. Solution: RooVectorDataStore uses a std::vector instead of an array[1000] to hold the pointers to the cache elements. Comments on the speed of the fix:; Using a std::vector placed on the stack (mimicking the original implementation), the fits would get slower. Therefore I added the vector as a member of RooVectorDataStore. This saves the time of constantly having to reallocate the vector. I tested with my (private) workspace: The crash is fixed. Unfortunately, I cannot provide this workspace.; To give a more meaningful test for you guys, I ran all the roofit/roostats tutorials and diffed the logs to check if roofit gives the same results. The diffs are attached. Apart from out-of-order execution and time measurements, there is no difference.; From the time measurements you can also see that the fixed version is not slower. [tutorials_roofit.diff.txt](https://github.com/root-mirror/root/files/56528/tutorials_roofit.diff.txt); [tutorials_roostats.diff.txt](https://github.com/root-mirror/root/files/56529/tutorials_roostats.diff.txt)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/115
https://github.com/root-project/root/pull/115:121,Deployability,update,updated,121,"This is a fix for ROOT-7121. If a cache is updated in RooVectorDataStore and the cache has more than 1000 elements to be updated, an array on the stack will overrun and smash the stack. roofit will therefore crash. Solution: RooVectorDataStore uses a std::vector instead of an array[1000] to hold the pointers to the cache elements. Comments on the speed of the fix:; Using a std::vector placed on the stack (mimicking the original implementation), the fits would get slower. Therefore I added the vector as a member of RooVectorDataStore. This saves the time of constantly having to reallocate the vector. I tested with my (private) workspace: The crash is fixed. Unfortunately, I cannot provide this workspace.; To give a more meaningful test for you guys, I ran all the roofit/roostats tutorials and diffed the logs to check if roofit gives the same results. The diffs are attached. Apart from out-of-order execution and time measurements, there is no difference.; From the time measurements you can also see that the fixed version is not slower. [tutorials_roofit.diff.txt](https://github.com/root-mirror/root/files/56528/tutorials_roofit.diff.txt); [tutorials_roostats.diff.txt](https://github.com/root-mirror/root/files/56529/tutorials_roostats.diff.txt)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/115
https://github.com/root-project/root/pull/115:34,Performance,cache,cache,34,"This is a fix for ROOT-7121. If a cache is updated in RooVectorDataStore and the cache has more than 1000 elements to be updated, an array on the stack will overrun and smash the stack. roofit will therefore crash. Solution: RooVectorDataStore uses a std::vector instead of an array[1000] to hold the pointers to the cache elements. Comments on the speed of the fix:; Using a std::vector placed on the stack (mimicking the original implementation), the fits would get slower. Therefore I added the vector as a member of RooVectorDataStore. This saves the time of constantly having to reallocate the vector. I tested with my (private) workspace: The crash is fixed. Unfortunately, I cannot provide this workspace.; To give a more meaningful test for you guys, I ran all the roofit/roostats tutorials and diffed the logs to check if roofit gives the same results. The diffs are attached. Apart from out-of-order execution and time measurements, there is no difference.; From the time measurements you can also see that the fixed version is not slower. [tutorials_roofit.diff.txt](https://github.com/root-mirror/root/files/56528/tutorials_roofit.diff.txt); [tutorials_roostats.diff.txt](https://github.com/root-mirror/root/files/56529/tutorials_roostats.diff.txt)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/115
https://github.com/root-project/root/pull/115:81,Performance,cache,cache,81,"This is a fix for ROOT-7121. If a cache is updated in RooVectorDataStore and the cache has more than 1000 elements to be updated, an array on the stack will overrun and smash the stack. roofit will therefore crash. Solution: RooVectorDataStore uses a std::vector instead of an array[1000] to hold the pointers to the cache elements. Comments on the speed of the fix:; Using a std::vector placed on the stack (mimicking the original implementation), the fits would get slower. Therefore I added the vector as a member of RooVectorDataStore. This saves the time of constantly having to reallocate the vector. I tested with my (private) workspace: The crash is fixed. Unfortunately, I cannot provide this workspace.; To give a more meaningful test for you guys, I ran all the roofit/roostats tutorials and diffed the logs to check if roofit gives the same results. The diffs are attached. Apart from out-of-order execution and time measurements, there is no difference.; From the time measurements you can also see that the fixed version is not slower. [tutorials_roofit.diff.txt](https://github.com/root-mirror/root/files/56528/tutorials_roofit.diff.txt); [tutorials_roostats.diff.txt](https://github.com/root-mirror/root/files/56529/tutorials_roostats.diff.txt)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/115
https://github.com/root-project/root/pull/115:317,Performance,cache,cache,317,"This is a fix for ROOT-7121. If a cache is updated in RooVectorDataStore and the cache has more than 1000 elements to be updated, an array on the stack will overrun and smash the stack. roofit will therefore crash. Solution: RooVectorDataStore uses a std::vector instead of an array[1000] to hold the pointers to the cache elements. Comments on the speed of the fix:; Using a std::vector placed on the stack (mimicking the original implementation), the fits would get slower. Therefore I added the vector as a member of RooVectorDataStore. This saves the time of constantly having to reallocate the vector. I tested with my (private) workspace: The crash is fixed. Unfortunately, I cannot provide this workspace.; To give a more meaningful test for you guys, I ran all the roofit/roostats tutorials and diffed the logs to check if roofit gives the same results. The diffs are attached. Apart from out-of-order execution and time measurements, there is no difference.; From the time measurements you can also see that the fixed version is not slower. [tutorials_roofit.diff.txt](https://github.com/root-mirror/root/files/56528/tutorials_roofit.diff.txt); [tutorials_roostats.diff.txt](https://github.com/root-mirror/root/files/56529/tutorials_roostats.diff.txt)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/115
https://github.com/root-project/root/pull/115:609,Testability,test,tested,609,"This is a fix for ROOT-7121. If a cache is updated in RooVectorDataStore and the cache has more than 1000 elements to be updated, an array on the stack will overrun and smash the stack. roofit will therefore crash. Solution: RooVectorDataStore uses a std::vector instead of an array[1000] to hold the pointers to the cache elements. Comments on the speed of the fix:; Using a std::vector placed on the stack (mimicking the original implementation), the fits would get slower. Therefore I added the vector as a member of RooVectorDataStore. This saves the time of constantly having to reallocate the vector. I tested with my (private) workspace: The crash is fixed. Unfortunately, I cannot provide this workspace.; To give a more meaningful test for you guys, I ran all the roofit/roostats tutorials and diffed the logs to check if roofit gives the same results. The diffs are attached. Apart from out-of-order execution and time measurements, there is no difference.; From the time measurements you can also see that the fixed version is not slower. [tutorials_roofit.diff.txt](https://github.com/root-mirror/root/files/56528/tutorials_roofit.diff.txt); [tutorials_roostats.diff.txt](https://github.com/root-mirror/root/files/56529/tutorials_roostats.diff.txt)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/115
https://github.com/root-project/root/pull/115:740,Testability,test,test,740,"This is a fix for ROOT-7121. If a cache is updated in RooVectorDataStore and the cache has more than 1000 elements to be updated, an array on the stack will overrun and smash the stack. roofit will therefore crash. Solution: RooVectorDataStore uses a std::vector instead of an array[1000] to hold the pointers to the cache elements. Comments on the speed of the fix:; Using a std::vector placed on the stack (mimicking the original implementation), the fits would get slower. Therefore I added the vector as a member of RooVectorDataStore. This saves the time of constantly having to reallocate the vector. I tested with my (private) workspace: The crash is fixed. Unfortunately, I cannot provide this workspace.; To give a more meaningful test for you guys, I ran all the roofit/roostats tutorials and diffed the logs to check if roofit gives the same results. The diffs are attached. Apart from out-of-order execution and time measurements, there is no difference.; From the time measurements you can also see that the fixed version is not slower. [tutorials_roofit.diff.txt](https://github.com/root-mirror/root/files/56528/tutorials_roofit.diff.txt); [tutorials_roostats.diff.txt](https://github.com/root-mirror/root/files/56529/tutorials_roostats.diff.txt)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/115
https://github.com/root-project/root/pull/115:814,Testability,log,logs,814,"This is a fix for ROOT-7121. If a cache is updated in RooVectorDataStore and the cache has more than 1000 elements to be updated, an array on the stack will overrun and smash the stack. roofit will therefore crash. Solution: RooVectorDataStore uses a std::vector instead of an array[1000] to hold the pointers to the cache elements. Comments on the speed of the fix:; Using a std::vector placed on the stack (mimicking the original implementation), the fits would get slower. Therefore I added the vector as a member of RooVectorDataStore. This saves the time of constantly having to reallocate the vector. I tested with my (private) workspace: The crash is fixed. Unfortunately, I cannot provide this workspace.; To give a more meaningful test for you guys, I ran all the roofit/roostats tutorials and diffed the logs to check if roofit gives the same results. The diffs are attached. Apart from out-of-order execution and time measurements, there is no difference.; From the time measurements you can also see that the fixed version is not slower. [tutorials_roofit.diff.txt](https://github.com/root-mirror/root/files/56528/tutorials_roofit.diff.txt); [tutorials_roostats.diff.txt](https://github.com/root-mirror/root/files/56529/tutorials_roostats.diff.txt)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/115
https://github.com/root-project/root/pull/116:43,Deployability,update,updated,43,"This is a fix for ROOT-7121. If a cache is updated in RooVectorDataStore and the cache has more than 1000 elements to be updated, an array on the stack will overrun and smash the stack. roofit will therefore crash. Solution: RooVectorDataStore uses a std::vector instead of an array[1000] to hold the pointers to the cache elements. Comments on the speed of the fix:; Using a std::vector placed on the stack (mimicking the original implementation), the fits would get slower. Therefore I added the vector as a member of RooVectorDataStore. This saves the time of constantly having to reallocate the vector. I tested with my (private) workspace: The crash is fixed. Unfortunately, I cannot provide this workspace.; To give a more meaningful test for you guys, I ran all the roofit/roostats tutorials and diffed the logs to check if roofit gives the same results. The diffs are attached. Apart from out-of-order execution and time measurements, there is no difference.; From the time measurements you can also see that the fixed version is not slower. [tutorials_roofit.diff.txt](https://github.com/root-mirror/root/files/56546/tutorials_roofit.diff.txt); [tutorials_roostats.diff.txt](https://github.com/root-mirror/root/files/56547/tutorials_roostats.diff.txt)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/116
https://github.com/root-project/root/pull/116:121,Deployability,update,updated,121,"This is a fix for ROOT-7121. If a cache is updated in RooVectorDataStore and the cache has more than 1000 elements to be updated, an array on the stack will overrun and smash the stack. roofit will therefore crash. Solution: RooVectorDataStore uses a std::vector instead of an array[1000] to hold the pointers to the cache elements. Comments on the speed of the fix:; Using a std::vector placed on the stack (mimicking the original implementation), the fits would get slower. Therefore I added the vector as a member of RooVectorDataStore. This saves the time of constantly having to reallocate the vector. I tested with my (private) workspace: The crash is fixed. Unfortunately, I cannot provide this workspace.; To give a more meaningful test for you guys, I ran all the roofit/roostats tutorials and diffed the logs to check if roofit gives the same results. The diffs are attached. Apart from out-of-order execution and time measurements, there is no difference.; From the time measurements you can also see that the fixed version is not slower. [tutorials_roofit.diff.txt](https://github.com/root-mirror/root/files/56546/tutorials_roofit.diff.txt); [tutorials_roostats.diff.txt](https://github.com/root-mirror/root/files/56547/tutorials_roostats.diff.txt)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/116
https://github.com/root-project/root/pull/116:34,Performance,cache,cache,34,"This is a fix for ROOT-7121. If a cache is updated in RooVectorDataStore and the cache has more than 1000 elements to be updated, an array on the stack will overrun and smash the stack. roofit will therefore crash. Solution: RooVectorDataStore uses a std::vector instead of an array[1000] to hold the pointers to the cache elements. Comments on the speed of the fix:; Using a std::vector placed on the stack (mimicking the original implementation), the fits would get slower. Therefore I added the vector as a member of RooVectorDataStore. This saves the time of constantly having to reallocate the vector. I tested with my (private) workspace: The crash is fixed. Unfortunately, I cannot provide this workspace.; To give a more meaningful test for you guys, I ran all the roofit/roostats tutorials and diffed the logs to check if roofit gives the same results. The diffs are attached. Apart from out-of-order execution and time measurements, there is no difference.; From the time measurements you can also see that the fixed version is not slower. [tutorials_roofit.diff.txt](https://github.com/root-mirror/root/files/56546/tutorials_roofit.diff.txt); [tutorials_roostats.diff.txt](https://github.com/root-mirror/root/files/56547/tutorials_roostats.diff.txt)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/116
https://github.com/root-project/root/pull/116:81,Performance,cache,cache,81,"This is a fix for ROOT-7121. If a cache is updated in RooVectorDataStore and the cache has more than 1000 elements to be updated, an array on the stack will overrun and smash the stack. roofit will therefore crash. Solution: RooVectorDataStore uses a std::vector instead of an array[1000] to hold the pointers to the cache elements. Comments on the speed of the fix:; Using a std::vector placed on the stack (mimicking the original implementation), the fits would get slower. Therefore I added the vector as a member of RooVectorDataStore. This saves the time of constantly having to reallocate the vector. I tested with my (private) workspace: The crash is fixed. Unfortunately, I cannot provide this workspace.; To give a more meaningful test for you guys, I ran all the roofit/roostats tutorials and diffed the logs to check if roofit gives the same results. The diffs are attached. Apart from out-of-order execution and time measurements, there is no difference.; From the time measurements you can also see that the fixed version is not slower. [tutorials_roofit.diff.txt](https://github.com/root-mirror/root/files/56546/tutorials_roofit.diff.txt); [tutorials_roostats.diff.txt](https://github.com/root-mirror/root/files/56547/tutorials_roostats.diff.txt)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/116
https://github.com/root-project/root/pull/116:317,Performance,cache,cache,317,"This is a fix for ROOT-7121. If a cache is updated in RooVectorDataStore and the cache has more than 1000 elements to be updated, an array on the stack will overrun and smash the stack. roofit will therefore crash. Solution: RooVectorDataStore uses a std::vector instead of an array[1000] to hold the pointers to the cache elements. Comments on the speed of the fix:; Using a std::vector placed on the stack (mimicking the original implementation), the fits would get slower. Therefore I added the vector as a member of RooVectorDataStore. This saves the time of constantly having to reallocate the vector. I tested with my (private) workspace: The crash is fixed. Unfortunately, I cannot provide this workspace.; To give a more meaningful test for you guys, I ran all the roofit/roostats tutorials and diffed the logs to check if roofit gives the same results. The diffs are attached. Apart from out-of-order execution and time measurements, there is no difference.; From the time measurements you can also see that the fixed version is not slower. [tutorials_roofit.diff.txt](https://github.com/root-mirror/root/files/56546/tutorials_roofit.diff.txt); [tutorials_roostats.diff.txt](https://github.com/root-mirror/root/files/56547/tutorials_roostats.diff.txt)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/116
https://github.com/root-project/root/pull/116:609,Testability,test,tested,609,"This is a fix for ROOT-7121. If a cache is updated in RooVectorDataStore and the cache has more than 1000 elements to be updated, an array on the stack will overrun and smash the stack. roofit will therefore crash. Solution: RooVectorDataStore uses a std::vector instead of an array[1000] to hold the pointers to the cache elements. Comments on the speed of the fix:; Using a std::vector placed on the stack (mimicking the original implementation), the fits would get slower. Therefore I added the vector as a member of RooVectorDataStore. This saves the time of constantly having to reallocate the vector. I tested with my (private) workspace: The crash is fixed. Unfortunately, I cannot provide this workspace.; To give a more meaningful test for you guys, I ran all the roofit/roostats tutorials and diffed the logs to check if roofit gives the same results. The diffs are attached. Apart from out-of-order execution and time measurements, there is no difference.; From the time measurements you can also see that the fixed version is not slower. [tutorials_roofit.diff.txt](https://github.com/root-mirror/root/files/56546/tutorials_roofit.diff.txt); [tutorials_roostats.diff.txt](https://github.com/root-mirror/root/files/56547/tutorials_roostats.diff.txt)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/116
https://github.com/root-project/root/pull/116:740,Testability,test,test,740,"This is a fix for ROOT-7121. If a cache is updated in RooVectorDataStore and the cache has more than 1000 elements to be updated, an array on the stack will overrun and smash the stack. roofit will therefore crash. Solution: RooVectorDataStore uses a std::vector instead of an array[1000] to hold the pointers to the cache elements. Comments on the speed of the fix:; Using a std::vector placed on the stack (mimicking the original implementation), the fits would get slower. Therefore I added the vector as a member of RooVectorDataStore. This saves the time of constantly having to reallocate the vector. I tested with my (private) workspace: The crash is fixed. Unfortunately, I cannot provide this workspace.; To give a more meaningful test for you guys, I ran all the roofit/roostats tutorials and diffed the logs to check if roofit gives the same results. The diffs are attached. Apart from out-of-order execution and time measurements, there is no difference.; From the time measurements you can also see that the fixed version is not slower. [tutorials_roofit.diff.txt](https://github.com/root-mirror/root/files/56546/tutorials_roofit.diff.txt); [tutorials_roostats.diff.txt](https://github.com/root-mirror/root/files/56547/tutorials_roostats.diff.txt)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/116
https://github.com/root-project/root/pull/116:814,Testability,log,logs,814,"This is a fix for ROOT-7121. If a cache is updated in RooVectorDataStore and the cache has more than 1000 elements to be updated, an array on the stack will overrun and smash the stack. roofit will therefore crash. Solution: RooVectorDataStore uses a std::vector instead of an array[1000] to hold the pointers to the cache elements. Comments on the speed of the fix:; Using a std::vector placed on the stack (mimicking the original implementation), the fits would get slower. Therefore I added the vector as a member of RooVectorDataStore. This saves the time of constantly having to reallocate the vector. I tested with my (private) workspace: The crash is fixed. Unfortunately, I cannot provide this workspace.; To give a more meaningful test for you guys, I ran all the roofit/roostats tutorials and diffed the logs to check if roofit gives the same results. The diffs are attached. Apart from out-of-order execution and time measurements, there is no difference.; From the time measurements you can also see that the fixed version is not slower. [tutorials_roofit.diff.txt](https://github.com/root-mirror/root/files/56546/tutorials_roofit.diff.txt); [tutorials_roostats.diff.txt](https://github.com/root-mirror/root/files/56547/tutorials_roostats.diff.txt)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/116
https://github.com/root-project/root/pull/119:96,Deployability,update,updated,96,"Hello,; This is the Implementation of DataLoader for TMVA according to new design.; - Tutorials updated; - Variable Importance implemented and tested.; - New ROC algorithm implemented; - PyMVA now support python 3. Cheers,; Omar.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/119
https://github.com/root-project/root/pull/119:107,Modifiability,Variab,Variable,107,"Hello,; This is the Implementation of DataLoader for TMVA according to new design.; - Tutorials updated; - Variable Importance implemented and tested.; - New ROC algorithm implemented; - PyMVA now support python 3. Cheers,; Omar.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/119
https://github.com/root-project/root/pull/119:143,Testability,test,tested,143,"Hello,; This is the Implementation of DataLoader for TMVA according to new design.; - Tutorials updated; - Variable Importance implemented and tested.; - New ROC algorithm implemented; - PyMVA now support python 3. Cheers,; Omar.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/119
https://github.com/root-project/root/pull/120:31,Deployability,install,installed,31,"If only the OpenGL headers are installed, but not GLU, the cmake check for OpenGL/GLU succeeds, but compile will fail at some point, because the GLU headers are needed.; This pull request fixes this inconsistency by explicitly checking also for GLU in the cmake script.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/120
https://github.com/root-project/root/pull/121:463,Safety,avoid,avoided,463,"I ported the changes from [pseyfert/tmva-mlp](https://github.com/pseyfert/tmva-mlp) to the code generation. As a test I just ran the class.C network resulting from tutorials/tmva/TMVAClassification.C (with ""MLP"") and evaluated it similar to tutorials/tmva/TMVAClassificationApplication.C. According to callgrind the network evaluation is ~17% cpu cycles faster.; NB: i did not port all changes from pseyfert/tmva-mlp - I did not import the SSE/AVX intrinsics and avoided what seemed too difficult (optimising the putIndices and getIndices out)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:113,Testability,test,test,113,"I ported the changes from [pseyfert/tmva-mlp](https://github.com/pseyfert/tmva-mlp) to the code generation. As a test I just ran the class.C network resulting from tutorials/tmva/TMVAClassification.C (with ""MLP"") and evaluated it similar to tutorials/tmva/TMVAClassificationApplication.C. According to callgrind the network evaluation is ~17% cpu cycles faster.; NB: i did not port all changes from pseyfert/tmva-mlp - I did not import the SSE/AVX intrinsics and avoided what seemed too difficult (optimising the putIndices and getIndices out)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/124:345,Deployability,patch,patch,345,https://sft.its.cern.ch/jira/browse/ROOT-7818; https://sft.its.cern.ch/jira/browse/ROOT-7721; https://sft.its.cern.ch/jira/browse/ROOT-7654; https://sft.its.cern.ch/jira/browse/ROOT-7319; https://sft.its.cern.ch/jira/browse/ROOT-7285; Possibly more... Adapted from:; http://pkgs.fedoraproject.org/cgit/llvm.git/tree/0001-add-gcc-abi_tag-support.patch,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/124
https://github.com/root-project/root/pull/124:252,Energy Efficiency,Adapt,Adapted,252,https://sft.its.cern.ch/jira/browse/ROOT-7818; https://sft.its.cern.ch/jira/browse/ROOT-7721; https://sft.its.cern.ch/jira/browse/ROOT-7654; https://sft.its.cern.ch/jira/browse/ROOT-7319; https://sft.its.cern.ch/jira/browse/ROOT-7285; Possibly more... Adapted from:; http://pkgs.fedoraproject.org/cgit/llvm.git/tree/0001-add-gcc-abi_tag-support.patch,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/124
https://github.com/root-project/root/pull/124:252,Modifiability,Adapt,Adapted,252,https://sft.its.cern.ch/jira/browse/ROOT-7818; https://sft.its.cern.ch/jira/browse/ROOT-7721; https://sft.its.cern.ch/jira/browse/ROOT-7654; https://sft.its.cern.ch/jira/browse/ROOT-7319; https://sft.its.cern.ch/jira/browse/ROOT-7285; Possibly more... Adapted from:; http://pkgs.fedoraproject.org/cgit/llvm.git/tree/0001-add-gcc-abi_tag-support.patch,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/124
https://github.com/root-project/root/pull/128:152,Availability,failure,failure,152,"If the user disables fortran but a fortran compiler is actually; present, then hist/CMakeLists.txt will still try to compile; hbook (which results in a failure). This patch explicitly sets the fortran compiler to not found; in order to prevent this from occurring.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/128
https://github.com/root-project/root/pull/128:167,Deployability,patch,patch,167,"If the user disables fortran but a fortran compiler is actually; present, then hist/CMakeLists.txt will still try to compile; hbook (which results in a failure). This patch explicitly sets the fortran compiler to not found; in order to prevent this from occurring.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/128
https://github.com/root-project/root/pull/129:0,Deployability,Update,Updated,0,"Updated code the test unit, all tests for TMVA are OK!. Cheers,; Omar.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/129
https://github.com/root-project/root/pull/129:17,Testability,test,test,17,"Updated code the test unit, all tests for TMVA are OK!. Cheers,; Omar.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/129
https://github.com/root-project/root/pull/129:32,Testability,test,tests,32,"Updated code the test unit, all tests for TMVA are OK!. Cheers,; Omar.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/129
https://github.com/root-project/root/pull/131:0,Deployability,Update,Updated,0,Updated markdown documentation(user guide) for ROOT-R. Cheers.; Omar.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/131
https://github.com/root-project/root/pull/131:36,Usability,guid,guide,36,Updated markdown documentation(user guide) for ROOT-R. Cheers.; Omar.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/131
https://github.com/root-project/root/pull/133:948,Deployability,patch,patch,948,"@bbockelm ; 1. I move signal handling from TSystem to a new class called TSigHandling and use gSigHandling as a global signal handling object in ROOT.; 2. To comply with some function calls like ""gSystem->ResetSignals()"". I move old ResetSignals() to the new class so TUnixSystem::ResetSignals() just call gSigHandling->ResetSignals(). I could also go over all such function calls and replace them with gSigHandling->(functions) if necessary.; 2. I replace old unsafe functions in signal handlers with thread-safe ones.; 3. I only implement StackTrace functions for SIGBUS, SIGSEGV, SIGILL. Other signals are still using default StackTrace functions. kSigAlarm and kSigChild are ignored for my current implementation. Do we need to change other signal handlers?; 4. @pcanal I have some problem with running roottest. I asked a question here:; https://github.com/root-mirror/root/pull/84; Could you take a look at it and I will write test case this patch also.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/133
https://github.com/root-project/root/pull/133:461,Safety,unsafe,unsafe,461,"@bbockelm ; 1. I move signal handling from TSystem to a new class called TSigHandling and use gSigHandling as a global signal handling object in ROOT.; 2. To comply with some function calls like ""gSystem->ResetSignals()"". I move old ResetSignals() to the new class so TUnixSystem::ResetSignals() just call gSigHandling->ResetSignals(). I could also go over all such function calls and replace them with gSigHandling->(functions) if necessary.; 2. I replace old unsafe functions in signal handlers with thread-safe ones.; 3. I only implement StackTrace functions for SIGBUS, SIGSEGV, SIGILL. Other signals are still using default StackTrace functions. kSigAlarm and kSigChild are ignored for my current implementation. Do we need to change other signal handlers?; 4. @pcanal I have some problem with running roottest. I asked a question here:; https://github.com/root-mirror/root/pull/84; Could you take a look at it and I will write test case this patch also.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/133
https://github.com/root-project/root/pull/133:509,Safety,safe,safe,509,"@bbockelm ; 1. I move signal handling from TSystem to a new class called TSigHandling and use gSigHandling as a global signal handling object in ROOT.; 2. To comply with some function calls like ""gSystem->ResetSignals()"". I move old ResetSignals() to the new class so TUnixSystem::ResetSignals() just call gSigHandling->ResetSignals(). I could also go over all such function calls and replace them with gSigHandling->(functions) if necessary.; 2. I replace old unsafe functions in signal handlers with thread-safe ones.; 3. I only implement StackTrace functions for SIGBUS, SIGSEGV, SIGILL. Other signals are still using default StackTrace functions. kSigAlarm and kSigChild are ignored for my current implementation. Do we need to change other signal handlers?; 4. @pcanal I have some problem with running roottest. I asked a question here:; https://github.com/root-mirror/root/pull/84; Could you take a look at it and I will write test case this patch also.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/133
https://github.com/root-project/root/pull/133:933,Testability,test,test,933,"@bbockelm ; 1. I move signal handling from TSystem to a new class called TSigHandling and use gSigHandling as a global signal handling object in ROOT.; 2. To comply with some function calls like ""gSystem->ResetSignals()"". I move old ResetSignals() to the new class so TUnixSystem::ResetSignals() just call gSigHandling->ResetSignals(). I could also go over all such function calls and replace them with gSigHandling->(functions) if necessary.; 2. I replace old unsafe functions in signal handlers with thread-safe ones.; 3. I only implement StackTrace functions for SIGBUS, SIGSEGV, SIGILL. Other signals are still using default StackTrace functions. kSigAlarm and kSigChild are ignored for my current implementation. Do we need to change other signal handlers?; 4. @pcanal I have some problem with running roottest. I asked a question here:; https://github.com/root-mirror/root/pull/84; Could you take a look at it and I will write test case this patch also.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/133
https://github.com/root-project/root/pull/134:964,Deployability,patch,patch,964,"@bbockelm I am submitting a new pull request for signal handling:; 1. I move signal handling from TSystem to a new class called TSigHandling and use gSigHandling as a global signal handling object in ROOT.; 2. To comply with some function calls like ""gSystem->ResetSignals()"". I move old ResetSignals() to the new class so TUnixSystem::ResetSignals() just call gSigHandling->ResetSignals(). I could also go over all gSystem->(functions) and replace them with gSigHandling->(functions) if necessary.; 3. I replace old unsafe functions in signal handlers with thread-safe ones.; 4. I only implement StackTrace functions for SIGBUS, SIGSEGV, SIGILL. Other signals are still using default StackTrace functions. kSigAlarm and kSigChild are ignored for my current implementation. Do we need to change other signal handlers?; 5. @pcanal I have some problem with running roottest. I asked a question here:; #84; Could you take a look at it and I will write test case this patch also.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:517,Safety,unsafe,unsafe,517,"@bbockelm I am submitting a new pull request for signal handling:; 1. I move signal handling from TSystem to a new class called TSigHandling and use gSigHandling as a global signal handling object in ROOT.; 2. To comply with some function calls like ""gSystem->ResetSignals()"". I move old ResetSignals() to the new class so TUnixSystem::ResetSignals() just call gSigHandling->ResetSignals(). I could also go over all gSystem->(functions) and replace them with gSigHandling->(functions) if necessary.; 3. I replace old unsafe functions in signal handlers with thread-safe ones.; 4. I only implement StackTrace functions for SIGBUS, SIGSEGV, SIGILL. Other signals are still using default StackTrace functions. kSigAlarm and kSigChild are ignored for my current implementation. Do we need to change other signal handlers?; 5. @pcanal I have some problem with running roottest. I asked a question here:; #84; Could you take a look at it and I will write test case this patch also.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:565,Safety,safe,safe,565,"@bbockelm I am submitting a new pull request for signal handling:; 1. I move signal handling from TSystem to a new class called TSigHandling and use gSigHandling as a global signal handling object in ROOT.; 2. To comply with some function calls like ""gSystem->ResetSignals()"". I move old ResetSignals() to the new class so TUnixSystem::ResetSignals() just call gSigHandling->ResetSignals(). I could also go over all gSystem->(functions) and replace them with gSigHandling->(functions) if necessary.; 3. I replace old unsafe functions in signal handlers with thread-safe ones.; 4. I only implement StackTrace functions for SIGBUS, SIGSEGV, SIGILL. Other signals are still using default StackTrace functions. kSigAlarm and kSigChild are ignored for my current implementation. Do we need to change other signal handlers?; 5. @pcanal I have some problem with running roottest. I asked a question here:; #84; Could you take a look at it and I will write test case this patch also.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:949,Testability,test,test,949,"@bbockelm I am submitting a new pull request for signal handling:; 1. I move signal handling from TSystem to a new class called TSigHandling and use gSigHandling as a global signal handling object in ROOT.; 2. To comply with some function calls like ""gSystem->ResetSignals()"". I move old ResetSignals() to the new class so TUnixSystem::ResetSignals() just call gSigHandling->ResetSignals(). I could also go over all gSystem->(functions) and replace them with gSigHandling->(functions) if necessary.; 3. I replace old unsafe functions in signal handlers with thread-safe ones.; 4. I only implement StackTrace functions for SIGBUS, SIGSEGV, SIGILL. Other signals are still using default StackTrace functions. kSigAlarm and kSigChild are ignored for my current implementation. Do we need to change other signal handlers?; 5. @pcanal I have some problem with running roottest. I asked a question here:; #84; Could you take a look at it and I will write test case this patch also.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/136:324,Deployability,update,update,324,"Hi, @pcanal @bbockelm . This branch implements little endian in TBuffer. The code is not ready to be merged and I hope it would be more convenient to discuss it on github. There is still a design issue. This is the link: https://sft.its.cern.ch/jira/browse/ROOT-5073. Let's take an example of writing to a TFile, we need to update header (TFile::WriteHeader), streamer info (TFile::WriteStreamerInfo) and free segments (TFile::WriteFree). ; 1. TFile::WriteHeader creates a TKey but does not stream its buffer. When you read or write header, it is always stored as big endian.; 2. TFile::WriteFree works in the same way with TFile::WriteHeader.; 3. TFile::WriteStreamerInfo is quite different from above two cases. It creates a TKey but uses streaming function to change streamer info object TList to little endian. The problem is that all of three information are read by TFile::ReadBuffer or TFile::ReadKeyBuffer without converting the endianesss. header and free segments can be processed without any problems. But streamer info is read in reversed endianess. . To address this issue, one way is adding a fBit in TFile class and change all meta data (header, free segments and streamer info) to little endian. Another way is modifying the read function for streamer info and convert its endianess before read it from buffer. Zhe",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/136
https://github.com/root-project/root/pull/139:83,Availability,error,error,83,"Hello!. ROOT-R is now supported with JupyROOT, the problem was a message from ; R ""error c stack usage is too close to the limit"".; It was fixed using module resource from python to set unlimited stack size in multithread execution,; anyway the stack in OS will be the limit. ""see ulimit -s"" for Gnu/Linux. Best.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/139
https://github.com/root-project/root/pull/139:65,Integrability,message,message,65,"Hello!. ROOT-R is now supported with JupyROOT, the problem was a message from ; R ""error c stack usage is too close to the limit"".; It was fixed using module resource from python to set unlimited stack size in multithread execution,; anyway the stack in OS will be the limit. ""see ulimit -s"" for Gnu/Linux. Best.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/139
https://github.com/root-project/root/pull/143:112,Deployability,update,update,112,"Hi Guys,. According to the new design of TMVA the interfaces TMVAGui, TMVAMultiClassGui and TMVARegGui needs an update to support the new format that is stored the results.; In this pull requests I have the code to updated TMVAGui to do visualization of two class classification.; lets see http://oproject.org/tiki-index.php?page=TMVA#TMVAGuis. I will continue working to updated TMVAMultiClassGui and TMVARegGui.; NOTE: all requirements accorded in the meeting was implemented. Best Regards. Omar.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/143
https://github.com/root-project/root/pull/143:215,Deployability,update,updated,215,"Hi Guys,. According to the new design of TMVA the interfaces TMVAGui, TMVAMultiClassGui and TMVARegGui needs an update to support the new format that is stored the results.; In this pull requests I have the code to updated TMVAGui to do visualization of two class classification.; lets see http://oproject.org/tiki-index.php?page=TMVA#TMVAGuis. I will continue working to updated TMVAMultiClassGui and TMVARegGui.; NOTE: all requirements accorded in the meeting was implemented. Best Regards. Omar.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/143
https://github.com/root-project/root/pull/143:372,Deployability,update,updated,372,"Hi Guys,. According to the new design of TMVA the interfaces TMVAGui, TMVAMultiClassGui and TMVARegGui needs an update to support the new format that is stored the results.; In this pull requests I have the code to updated TMVAGui to do visualization of two class classification.; lets see http://oproject.org/tiki-index.php?page=TMVA#TMVAGuis. I will continue working to updated TMVAMultiClassGui and TMVARegGui.; NOTE: all requirements accorded in the meeting was implemented. Best Regards. Omar.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/143
https://github.com/root-project/root/pull/143:50,Integrability,interface,interfaces,50,"Hi Guys,. According to the new design of TMVA the interfaces TMVAGui, TMVAMultiClassGui and TMVARegGui needs an update to support the new format that is stored the results.; In this pull requests I have the code to updated TMVAGui to do visualization of two class classification.; lets see http://oproject.org/tiki-index.php?page=TMVA#TMVAGuis. I will continue working to updated TMVAMultiClassGui and TMVARegGui.; NOTE: all requirements accorded in the meeting was implemented. Best Regards. Omar.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/143
https://github.com/root-project/root/pull/144:4,Deployability,patch,patch,4,"The patch which I suggested on https://sft.its.cern.ch/jira/browse/ROOT-8056.; If the user uses GREP_OPTIONS which add characters to the output of grep (colors, but also filenames or line numbers), root cannot be started anymore. Ideally users would prefer an alias for `grep` over `GREP_OPTIONS` but the crash can also be avoided on the root side.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/144
https://github.com/root-project/root/pull/144:323,Safety,avoid,avoided,323,"The patch which I suggested on https://sft.its.cern.ch/jira/browse/ROOT-8056.; If the user uses GREP_OPTIONS which add characters to the output of grep (colors, but also filenames or line numbers), root cannot be started anymore. Ideally users would prefer an alias for `grep` over `GREP_OPTIONS` but the crash can also be avoided on the root side.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/144
https://github.com/root-project/root/pull/145:5,Usability,learn,learning,5,Deep learning code from Peter; with some fixes. Best; Omar,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/145
https://github.com/root-project/root/pull/146:693,Availability,down,download,693,"This pull request adds an intermediate buffering mode between ""normal ROOT IO"" and the prefetching system. When enabled, it will cache a remote file to the local disk (uses the same logic as prefetching to determine what is ""remote"") for as long as it is opened and automatically cleans up afterward. This is useful in cases where you want to hide the effects of network latency (for various use cases which work poorly with `TTreeCache`, such as when an unpredictable set of branches are used or non-sequential scans) but do not want to set aside a directory to use as a persistent cache or have a cache-unfriendly workflow. The approach has been ported from CMSSW (there, it is called `lazy-download`) where it has been in use for several years.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/146
https://github.com/root-project/root/pull/146:129,Performance,cache,cache,129,"This pull request adds an intermediate buffering mode between ""normal ROOT IO"" and the prefetching system. When enabled, it will cache a remote file to the local disk (uses the same logic as prefetching to determine what is ""remote"") for as long as it is opened and automatically cleans up afterward. This is useful in cases where you want to hide the effects of network latency (for various use cases which work poorly with `TTreeCache`, such as when an unpredictable set of branches are used or non-sequential scans) but do not want to set aside a directory to use as a persistent cache or have a cache-unfriendly workflow. The approach has been ported from CMSSW (there, it is called `lazy-download`) where it has been in use for several years.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/146
https://github.com/root-project/root/pull/146:371,Performance,latency,latency,371,"This pull request adds an intermediate buffering mode between ""normal ROOT IO"" and the prefetching system. When enabled, it will cache a remote file to the local disk (uses the same logic as prefetching to determine what is ""remote"") for as long as it is opened and automatically cleans up afterward. This is useful in cases where you want to hide the effects of network latency (for various use cases which work poorly with `TTreeCache`, such as when an unpredictable set of branches are used or non-sequential scans) but do not want to set aside a directory to use as a persistent cache or have a cache-unfriendly workflow. The approach has been ported from CMSSW (there, it is called `lazy-download`) where it has been in use for several years.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/146
https://github.com/root-project/root/pull/146:583,Performance,cache,cache,583,"This pull request adds an intermediate buffering mode between ""normal ROOT IO"" and the prefetching system. When enabled, it will cache a remote file to the local disk (uses the same logic as prefetching to determine what is ""remote"") for as long as it is opened and automatically cleans up afterward. This is useful in cases where you want to hide the effects of network latency (for various use cases which work poorly with `TTreeCache`, such as when an unpredictable set of branches are used or non-sequential scans) but do not want to set aside a directory to use as a persistent cache or have a cache-unfriendly workflow. The approach has been ported from CMSSW (there, it is called `lazy-download`) where it has been in use for several years.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/146
https://github.com/root-project/root/pull/146:599,Performance,cache,cache-unfriendly,599,"This pull request adds an intermediate buffering mode between ""normal ROOT IO"" and the prefetching system. When enabled, it will cache a remote file to the local disk (uses the same logic as prefetching to determine what is ""remote"") for as long as it is opened and automatically cleans up afterward. This is useful in cases where you want to hide the effects of network latency (for various use cases which work poorly with `TTreeCache`, such as when an unpredictable set of branches are used or non-sequential scans) but do not want to set aside a directory to use as a persistent cache or have a cache-unfriendly workflow. The approach has been ported from CMSSW (there, it is called `lazy-download`) where it has been in use for several years.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/146
https://github.com/root-project/root/pull/146:182,Testability,log,logic,182,"This pull request adds an intermediate buffering mode between ""normal ROOT IO"" and the prefetching system. When enabled, it will cache a remote file to the local disk (uses the same logic as prefetching to determine what is ""remote"") for as long as it is opened and automatically cleans up afterward. This is useful in cases where you want to hide the effects of network latency (for various use cases which work poorly with `TTreeCache`, such as when an unpredictable set of branches are used or non-sequential scans) but do not want to set aside a directory to use as a persistent cache or have a cache-unfriendly workflow. The approach has been ported from CMSSW (there, it is called `lazy-download`) where it has been in use for several years.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/146
https://github.com/root-project/root/pull/148:80,Modifiability,Refactor,Refactored,80,Added the new ThreadPool class sharing TProcPool's MapReduce methods signature. Refactored the code so ThreadPool and TProcPool inherit from the new parent TPool.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/148
https://github.com/root-project/root/pull/148:128,Modifiability,inherit,inherit,128,Added the new ThreadPool class sharing TProcPool's MapReduce methods signature. Refactored the code so ThreadPool and TProcPool inherit from the new parent TPool.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/148
https://github.com/root-project/root/pull/149:59,Deployability,release,releases,59,"Hi all,. I love the new command line utils included in the releases in root/main/python/. However, I found the rooteventselector command to be lacking in some functionality, so I added the ability for it to skim based on a selection string (a la a TCut). I hope this is useful for others!. -Larry",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/149
https://github.com/root-project/root/pull/150:245,Deployability,update,updated,245,"Hi all,. I've added a new command-line tool called rootslimtree which will remove branches from an input tree and write out a new file. This is actually implemented in cmdLineUtils.rootEventselector() and the rooteventselector function has been updated to also have this ability, so in case a user wants to remove both branches and events, this can be done in a single step. . Related to #149. Thanks!; -Larry",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/150
https://github.com/root-project/root/pull/151:102,Deployability,Update,Update,102,"1. Remove unused `SetResolution` function and `fResolution` member from the `TSpectrum*` classes.; 2. Update and add references to external documentation, such as the `*.ps.gz` papers and the ""manual"".",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/151
https://github.com/root-project/root/pull/152:40,Security,access,access,40,"This is a new feature to support random access compression. For details, please take a look at this link:; https://sft.its.cern.ch/jira/browse/ROOT-5076",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/152
https://github.com/root-project/root/pull/153:679,Deployability,integrat,integrates,679,"Root has two different ways to configure the build - the traditional configure script and cmake. The builds generated by the two systems are similar, but far from equivalent. Historically the configure script has been more feature complete and some things that the configure script is able to do are either missing or broken in the cmake build. However, new features are often only added to the cmake build. This has resulted in that today neither of the two is able to build root with a complete set of features. The cmake build is more standard and behaves in a more predictive way, e.g. it understands CFLAGS, LDFLAGS and friends which the configure script never did. It also integrates the test suite in the build and allows for running ""make test"", a feature that the configure script is missing. So the cmake build is in many ways better, if it wasn't for those missing and broken things mentioned earlier. This pull request is an attempt to address those missing and broken issues (though it fixes a few things for the configure script as well). Also contains a fix for ROOT-7326.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/153
https://github.com/root-project/root/pull/153:679,Integrability,integrat,integrates,679,"Root has two different ways to configure the build - the traditional configure script and cmake. The builds generated by the two systems are similar, but far from equivalent. Historically the configure script has been more feature complete and some things that the configure script is able to do are either missing or broken in the cmake build. However, new features are often only added to the cmake build. This has resulted in that today neither of the two is able to build root with a complete set of features. The cmake build is more standard and behaves in a more predictive way, e.g. it understands CFLAGS, LDFLAGS and friends which the configure script never did. It also integrates the test suite in the build and allows for running ""make test"", a feature that the configure script is missing. So the cmake build is in many ways better, if it wasn't for those missing and broken things mentioned earlier. This pull request is an attempt to address those missing and broken issues (though it fixes a few things for the configure script as well). Also contains a fix for ROOT-7326.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/153
https://github.com/root-project/root/pull/153:31,Modifiability,config,configure,31,"Root has two different ways to configure the build - the traditional configure script and cmake. The builds generated by the two systems are similar, but far from equivalent. Historically the configure script has been more feature complete and some things that the configure script is able to do are either missing or broken in the cmake build. However, new features are often only added to the cmake build. This has resulted in that today neither of the two is able to build root with a complete set of features. The cmake build is more standard and behaves in a more predictive way, e.g. it understands CFLAGS, LDFLAGS and friends which the configure script never did. It also integrates the test suite in the build and allows for running ""make test"", a feature that the configure script is missing. So the cmake build is in many ways better, if it wasn't for those missing and broken things mentioned earlier. This pull request is an attempt to address those missing and broken issues (though it fixes a few things for the configure script as well). Also contains a fix for ROOT-7326.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/153
https://github.com/root-project/root/pull/153:69,Modifiability,config,configure,69,"Root has two different ways to configure the build - the traditional configure script and cmake. The builds generated by the two systems are similar, but far from equivalent. Historically the configure script has been more feature complete and some things that the configure script is able to do are either missing or broken in the cmake build. However, new features are often only added to the cmake build. This has resulted in that today neither of the two is able to build root with a complete set of features. The cmake build is more standard and behaves in a more predictive way, e.g. it understands CFLAGS, LDFLAGS and friends which the configure script never did. It also integrates the test suite in the build and allows for running ""make test"", a feature that the configure script is missing. So the cmake build is in many ways better, if it wasn't for those missing and broken things mentioned earlier. This pull request is an attempt to address those missing and broken issues (though it fixes a few things for the configure script as well). Also contains a fix for ROOT-7326.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/153
https://github.com/root-project/root/pull/153:192,Modifiability,config,configure,192,"Root has two different ways to configure the build - the traditional configure script and cmake. The builds generated by the two systems are similar, but far from equivalent. Historically the configure script has been more feature complete and some things that the configure script is able to do are either missing or broken in the cmake build. However, new features are often only added to the cmake build. This has resulted in that today neither of the two is able to build root with a complete set of features. The cmake build is more standard and behaves in a more predictive way, e.g. it understands CFLAGS, LDFLAGS and friends which the configure script never did. It also integrates the test suite in the build and allows for running ""make test"", a feature that the configure script is missing. So the cmake build is in many ways better, if it wasn't for those missing and broken things mentioned earlier. This pull request is an attempt to address those missing and broken issues (though it fixes a few things for the configure script as well). Also contains a fix for ROOT-7326.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/153
https://github.com/root-project/root/pull/153:265,Modifiability,config,configure,265,"Root has two different ways to configure the build - the traditional configure script and cmake. The builds generated by the two systems are similar, but far from equivalent. Historically the configure script has been more feature complete and some things that the configure script is able to do are either missing or broken in the cmake build. However, new features are often only added to the cmake build. This has resulted in that today neither of the two is able to build root with a complete set of features. The cmake build is more standard and behaves in a more predictive way, e.g. it understands CFLAGS, LDFLAGS and friends which the configure script never did. It also integrates the test suite in the build and allows for running ""make test"", a feature that the configure script is missing. So the cmake build is in many ways better, if it wasn't for those missing and broken things mentioned earlier. This pull request is an attempt to address those missing and broken issues (though it fixes a few things for the configure script as well). Also contains a fix for ROOT-7326.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/153
https://github.com/root-project/root/pull/153:643,Modifiability,config,configure,643,"Root has two different ways to configure the build - the traditional configure script and cmake. The builds generated by the two systems are similar, but far from equivalent. Historically the configure script has been more feature complete and some things that the configure script is able to do are either missing or broken in the cmake build. However, new features are often only added to the cmake build. This has resulted in that today neither of the two is able to build root with a complete set of features. The cmake build is more standard and behaves in a more predictive way, e.g. it understands CFLAGS, LDFLAGS and friends which the configure script never did. It also integrates the test suite in the build and allows for running ""make test"", a feature that the configure script is missing. So the cmake build is in many ways better, if it wasn't for those missing and broken things mentioned earlier. This pull request is an attempt to address those missing and broken issues (though it fixes a few things for the configure script as well). Also contains a fix for ROOT-7326.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/153
https://github.com/root-project/root/pull/153:773,Modifiability,config,configure,773,"Root has two different ways to configure the build - the traditional configure script and cmake. The builds generated by the two systems are similar, but far from equivalent. Historically the configure script has been more feature complete and some things that the configure script is able to do are either missing or broken in the cmake build. However, new features are often only added to the cmake build. This has resulted in that today neither of the two is able to build root with a complete set of features. The cmake build is more standard and behaves in a more predictive way, e.g. it understands CFLAGS, LDFLAGS and friends which the configure script never did. It also integrates the test suite in the build and allows for running ""make test"", a feature that the configure script is missing. So the cmake build is in many ways better, if it wasn't for those missing and broken things mentioned earlier. This pull request is an attempt to address those missing and broken issues (though it fixes a few things for the configure script as well). Also contains a fix for ROOT-7326.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/153
https://github.com/root-project/root/pull/153:1026,Modifiability,config,configure,1026,"Root has two different ways to configure the build - the traditional configure script and cmake. The builds generated by the two systems are similar, but far from equivalent. Historically the configure script has been more feature complete and some things that the configure script is able to do are either missing or broken in the cmake build. However, new features are often only added to the cmake build. This has resulted in that today neither of the two is able to build root with a complete set of features. The cmake build is more standard and behaves in a more predictive way, e.g. it understands CFLAGS, LDFLAGS and friends which the configure script never did. It also integrates the test suite in the build and allows for running ""make test"", a feature that the configure script is missing. So the cmake build is in many ways better, if it wasn't for those missing and broken things mentioned earlier. This pull request is an attempt to address those missing and broken issues (though it fixes a few things for the configure script as well). Also contains a fix for ROOT-7326.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/153
https://github.com/root-project/root/pull/153:569,Safety,predict,predictive,569,"Root has two different ways to configure the build - the traditional configure script and cmake. The builds generated by the two systems are similar, but far from equivalent. Historically the configure script has been more feature complete and some things that the configure script is able to do are either missing or broken in the cmake build. However, new features are often only added to the cmake build. This has resulted in that today neither of the two is able to build root with a complete set of features. The cmake build is more standard and behaves in a more predictive way, e.g. it understands CFLAGS, LDFLAGS and friends which the configure script never did. It also integrates the test suite in the build and allows for running ""make test"", a feature that the configure script is missing. So the cmake build is in many ways better, if it wasn't for those missing and broken things mentioned earlier. This pull request is an attempt to address those missing and broken issues (though it fixes a few things for the configure script as well). Also contains a fix for ROOT-7326.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/153
https://github.com/root-project/root/pull/153:694,Testability,test,test,694,"Root has two different ways to configure the build - the traditional configure script and cmake. The builds generated by the two systems are similar, but far from equivalent. Historically the configure script has been more feature complete and some things that the configure script is able to do are either missing or broken in the cmake build. However, new features are often only added to the cmake build. This has resulted in that today neither of the two is able to build root with a complete set of features. The cmake build is more standard and behaves in a more predictive way, e.g. it understands CFLAGS, LDFLAGS and friends which the configure script never did. It also integrates the test suite in the build and allows for running ""make test"", a feature that the configure script is missing. So the cmake build is in many ways better, if it wasn't for those missing and broken things mentioned earlier. This pull request is an attempt to address those missing and broken issues (though it fixes a few things for the configure script as well). Also contains a fix for ROOT-7326.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/153
https://github.com/root-project/root/pull/153:747,Testability,test,test,747,"Root has two different ways to configure the build - the traditional configure script and cmake. The builds generated by the two systems are similar, but far from equivalent. Historically the configure script has been more feature complete and some things that the configure script is able to do are either missing or broken in the cmake build. However, new features are often only added to the cmake build. This has resulted in that today neither of the two is able to build root with a complete set of features. The cmake build is more standard and behaves in a more predictive way, e.g. it understands CFLAGS, LDFLAGS and friends which the configure script never did. It also integrates the test suite in the build and allows for running ""make test"", a feature that the configure script is missing. So the cmake build is in many ways better, if it wasn't for those missing and broken things mentioned earlier. This pull request is an attempt to address those missing and broken issues (though it fixes a few things for the configure script as well). Also contains a fix for ROOT-7326.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/153
https://github.com/root-project/root/pull/155:27,Testability,test,tests,27,Here are some fixes to the tests.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/155
https://github.com/root-project/root/pull/156:156,Integrability,interface,interface,156,"Added support for the VecGeom library as external package (-Dvecgeom). Creating new library libConverterVG within geom module. This contains the conversion interface for ROOT shapes into vecgeom ones, activated using the plugin mechanism from ROOT. Included also the class TGeoVGShape bridging TGeoShape methods to either VecGeom solid (navigation) or existing ROOT shape (visualisation and the rest). The conversion can be done once a ROOT geometry is in memory using:; TVirtualGeoConverter::Instance()->ConvertGeometry(); Once this is done, all TGeo functionality and tests can be accessed as for a standard TGeo geometry.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/156
https://github.com/root-project/root/pull/156:285,Integrability,bridg,bridging,285,"Added support for the VecGeom library as external package (-Dvecgeom). Creating new library libConverterVG within geom module. This contains the conversion interface for ROOT shapes into vecgeom ones, activated using the plugin mechanism from ROOT. Included also the class TGeoVGShape bridging TGeoShape methods to either VecGeom solid (navigation) or existing ROOT shape (visualisation and the rest). The conversion can be done once a ROOT geometry is in memory using:; TVirtualGeoConverter::Instance()->ConvertGeometry(); Once this is done, all TGeo functionality and tests can be accessed as for a standard TGeo geometry.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/156
https://github.com/root-project/root/pull/156:221,Modifiability,plugin,plugin,221,"Added support for the VecGeom library as external package (-Dvecgeom). Creating new library libConverterVG within geom module. This contains the conversion interface for ROOT shapes into vecgeom ones, activated using the plugin mechanism from ROOT. Included also the class TGeoVGShape bridging TGeoShape methods to either VecGeom solid (navigation) or existing ROOT shape (visualisation and the rest). The conversion can be done once a ROOT geometry is in memory using:; TVirtualGeoConverter::Instance()->ConvertGeometry(); Once this is done, all TGeo functionality and tests can be accessed as for a standard TGeo geometry.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/156
https://github.com/root-project/root/pull/156:583,Security,access,accessed,583,"Added support for the VecGeom library as external package (-Dvecgeom). Creating new library libConverterVG within geom module. This contains the conversion interface for ROOT shapes into vecgeom ones, activated using the plugin mechanism from ROOT. Included also the class TGeoVGShape bridging TGeoShape methods to either VecGeom solid (navigation) or existing ROOT shape (visualisation and the rest). The conversion can be done once a ROOT geometry is in memory using:; TVirtualGeoConverter::Instance()->ConvertGeometry(); Once this is done, all TGeo functionality and tests can be accessed as for a standard TGeo geometry.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/156
https://github.com/root-project/root/pull/156:570,Testability,test,tests,570,"Added support for the VecGeom library as external package (-Dvecgeom). Creating new library libConverterVG within geom module. This contains the conversion interface for ROOT shapes into vecgeom ones, activated using the plugin mechanism from ROOT. Included also the class TGeoVGShape bridging TGeoShape methods to either VecGeom solid (navigation) or existing ROOT shape (visualisation and the rest). The conversion can be done once a ROOT geometry is in memory using:; TVirtualGeoConverter::Instance()->ConvertGeometry(); Once this is done, all TGeo functionality and tests can be accessed as for a standard TGeo geometry.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/156
https://github.com/root-project/root/pull/157:156,Integrability,interface,interface,156,"Added support for the VecGeom library as external package (-Dvecgeom). Creating new library libConverterVG within geom module. This contains the conversion interface for ROOT shapes into vecgeom ones, activated using the plugin mechanism from ROOT. Included also the class TGeoVGShape bridging TGeoShape methods to either VecGeom solid (navigation) or existing ROOT shape (visualisation and the rest). The conversion can be done once a ROOT geometry is in memory using:; TVirtualGeoConverter::Instance()->ConvertGeometry(); Once this is done, all TGeo functionality and tests can be accessed as for a standard TGeo geometry.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/157
https://github.com/root-project/root/pull/157:285,Integrability,bridg,bridging,285,"Added support for the VecGeom library as external package (-Dvecgeom). Creating new library libConverterVG within geom module. This contains the conversion interface for ROOT shapes into vecgeom ones, activated using the plugin mechanism from ROOT. Included also the class TGeoVGShape bridging TGeoShape methods to either VecGeom solid (navigation) or existing ROOT shape (visualisation and the rest). The conversion can be done once a ROOT geometry is in memory using:; TVirtualGeoConverter::Instance()->ConvertGeometry(); Once this is done, all TGeo functionality and tests can be accessed as for a standard TGeo geometry.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/157
https://github.com/root-project/root/pull/157:221,Modifiability,plugin,plugin,221,"Added support for the VecGeom library as external package (-Dvecgeom). Creating new library libConverterVG within geom module. This contains the conversion interface for ROOT shapes into vecgeom ones, activated using the plugin mechanism from ROOT. Included also the class TGeoVGShape bridging TGeoShape methods to either VecGeom solid (navigation) or existing ROOT shape (visualisation and the rest). The conversion can be done once a ROOT geometry is in memory using:; TVirtualGeoConverter::Instance()->ConvertGeometry(); Once this is done, all TGeo functionality and tests can be accessed as for a standard TGeo geometry.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/157
https://github.com/root-project/root/pull/157:583,Security,access,accessed,583,"Added support for the VecGeom library as external package (-Dvecgeom). Creating new library libConverterVG within geom module. This contains the conversion interface for ROOT shapes into vecgeom ones, activated using the plugin mechanism from ROOT. Included also the class TGeoVGShape bridging TGeoShape methods to either VecGeom solid (navigation) or existing ROOT shape (visualisation and the rest). The conversion can be done once a ROOT geometry is in memory using:; TVirtualGeoConverter::Instance()->ConvertGeometry(); Once this is done, all TGeo functionality and tests can be accessed as for a standard TGeo geometry.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/157
https://github.com/root-project/root/pull/157:570,Testability,test,tests,570,"Added support for the VecGeom library as external package (-Dvecgeom). Creating new library libConverterVG within geom module. This contains the conversion interface for ROOT shapes into vecgeom ones, activated using the plugin mechanism from ROOT. Included also the class TGeoVGShape bridging TGeoShape methods to either VecGeom solid (navigation) or existing ROOT shape (visualisation and the rest). The conversion can be done once a ROOT geometry is in memory using:; TVirtualGeoConverter::Instance()->ConvertGeometry(); Once this is done, all TGeo functionality and tests can be accessed as for a standard TGeo geometry.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/157
https://github.com/root-project/root/pull/159:550,Availability,failure,failure,550,"This slightly changes lookup order: Namely, the system-folder ""/usr/include/postgresql""; is now preferred over ""/usr/include/"" even if both container libpq-fe.h.; This finds the correct path on a standard Gentoo installation, where ""/usr/include/postgresql""; is a symlink to the folder with all include-files for the user-selected postgresql-version,; while ""/usr/include/libpq-fe.h"" is a single symlink provided for backwards-compatibility. Since ROOT uses also e.g. ""pg_config.h"", selecting ""/usr/include/"" over ""/usr/include/postgresql""; leads to failure on Gentoo. I hope this will not break any other existing setups but I don't see how it should. ; That should prevent any downstream-patching which Gentoo is doing right now for old-style configure once it has moved to cmake.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/159
https://github.com/root-project/root/pull/159:679,Availability,down,downstream-patching,679,"This slightly changes lookup order: Namely, the system-folder ""/usr/include/postgresql""; is now preferred over ""/usr/include/"" even if both container libpq-fe.h.; This finds the correct path on a standard Gentoo installation, where ""/usr/include/postgresql""; is a symlink to the folder with all include-files for the user-selected postgresql-version,; while ""/usr/include/libpq-fe.h"" is a single symlink provided for backwards-compatibility. Since ROOT uses also e.g. ""pg_config.h"", selecting ""/usr/include/"" over ""/usr/include/postgresql""; leads to failure on Gentoo. I hope this will not break any other existing setups but I don't see how it should. ; That should prevent any downstream-patching which Gentoo is doing right now for old-style configure once it has moved to cmake.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/159
https://github.com/root-project/root/pull/159:212,Deployability,install,installation,212,"This slightly changes lookup order: Namely, the system-folder ""/usr/include/postgresql""; is now preferred over ""/usr/include/"" even if both container libpq-fe.h.; This finds the correct path on a standard Gentoo installation, where ""/usr/include/postgresql""; is a symlink to the folder with all include-files for the user-selected postgresql-version,; while ""/usr/include/libpq-fe.h"" is a single symlink provided for backwards-compatibility. Since ROOT uses also e.g. ""pg_config.h"", selecting ""/usr/include/"" over ""/usr/include/postgresql""; leads to failure on Gentoo. I hope this will not break any other existing setups but I don't see how it should. ; That should prevent any downstream-patching which Gentoo is doing right now for old-style configure once it has moved to cmake.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/159
https://github.com/root-project/root/pull/159:690,Deployability,patch,patching,690,"This slightly changes lookup order: Namely, the system-folder ""/usr/include/postgresql""; is now preferred over ""/usr/include/"" even if both container libpq-fe.h.; This finds the correct path on a standard Gentoo installation, where ""/usr/include/postgresql""; is a symlink to the folder with all include-files for the user-selected postgresql-version,; while ""/usr/include/libpq-fe.h"" is a single symlink provided for backwards-compatibility. Since ROOT uses also e.g. ""pg_config.h"", selecting ""/usr/include/"" over ""/usr/include/postgresql""; leads to failure on Gentoo. I hope this will not break any other existing setups but I don't see how it should. ; That should prevent any downstream-patching which Gentoo is doing right now for old-style configure once it has moved to cmake.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/159
https://github.com/root-project/root/pull/159:745,Modifiability,config,configure,745,"This slightly changes lookup order: Namely, the system-folder ""/usr/include/postgresql""; is now preferred over ""/usr/include/"" even if both container libpq-fe.h.; This finds the correct path on a standard Gentoo installation, where ""/usr/include/postgresql""; is a symlink to the folder with all include-files for the user-selected postgresql-version,; while ""/usr/include/libpq-fe.h"" is a single symlink provided for backwards-compatibility. Since ROOT uses also e.g. ""pg_config.h"", selecting ""/usr/include/"" over ""/usr/include/postgresql""; leads to failure on Gentoo. I hope this will not break any other existing setups but I don't see how it should. ; That should prevent any downstream-patching which Gentoo is doing right now for old-style configure once it has moved to cmake.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/159
https://github.com/root-project/root/pull/164:194,Availability,Error,Error,194,Deleted two empty files that were just including the header and made; some cosmetic changes to root/multiproc and TPool derived classes:; - #include reordering.; - standarize the use of TError::Error as the way of throwing error; messages instead of mixing it with std::cerr here and there.; - added missing copyright notices and module identification lines.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/164
https://github.com/root-project/root/pull/164:223,Availability,error,error,223,Deleted two empty files that were just including the header and made; some cosmetic changes to root/multiproc and TPool derived classes:; - #include reordering.; - standarize the use of TError::Error as the way of throwing error; messages instead of mixing it with std::cerr here and there.; - added missing copyright notices and module identification lines.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/164
https://github.com/root-project/root/pull/164:230,Integrability,message,messages,230,Deleted two empty files that were just including the header and made; some cosmetic changes to root/multiproc and TPool derived classes:; - #include reordering.; - standarize the use of TError::Error as the way of throwing error; messages instead of mixing it with std::cerr here and there.; - added missing copyright notices and module identification lines.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/164
https://github.com/root-project/root/pull/165:142,Performance,optimiz,optimize,142,"- move important functions (constructors,destructors,accessors) to header; to avoid overhead in creating and accessing these small objects; - optimize access to TLorentzVector by avoiding a double switch statement; (switch on direction in TLorentzVector followed by same switch in TVector3). This merge request is result of profiling work in the AliRoot framework where simple accesses to the mentioned objects are considerable (on the 2% level).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/165
https://github.com/root-project/root/pull/165:78,Safety,avoid,avoid,78,"- move important functions (constructors,destructors,accessors) to header; to avoid overhead in creating and accessing these small objects; - optimize access to TLorentzVector by avoiding a double switch statement; (switch on direction in TLorentzVector followed by same switch in TVector3). This merge request is result of profiling work in the AliRoot framework where simple accesses to the mentioned objects are considerable (on the 2% level).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/165
https://github.com/root-project/root/pull/165:179,Safety,avoid,avoiding,179,"- move important functions (constructors,destructors,accessors) to header; to avoid overhead in creating and accessing these small objects; - optimize access to TLorentzVector by avoiding a double switch statement; (switch on direction in TLorentzVector followed by same switch in TVector3). This merge request is result of profiling work in the AliRoot framework where simple accesses to the mentioned objects are considerable (on the 2% level).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/165
https://github.com/root-project/root/pull/165:53,Security,access,accessors,53,"- move important functions (constructors,destructors,accessors) to header; to avoid overhead in creating and accessing these small objects; - optimize access to TLorentzVector by avoiding a double switch statement; (switch on direction in TLorentzVector followed by same switch in TVector3). This merge request is result of profiling work in the AliRoot framework where simple accesses to the mentioned objects are considerable (on the 2% level).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/165
https://github.com/root-project/root/pull/165:109,Security,access,accessing,109,"- move important functions (constructors,destructors,accessors) to header; to avoid overhead in creating and accessing these small objects; - optimize access to TLorentzVector by avoiding a double switch statement; (switch on direction in TLorentzVector followed by same switch in TVector3). This merge request is result of profiling work in the AliRoot framework where simple accesses to the mentioned objects are considerable (on the 2% level).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/165
https://github.com/root-project/root/pull/165:151,Security,access,access,151,"- move important functions (constructors,destructors,accessors) to header; to avoid overhead in creating and accessing these small objects; - optimize access to TLorentzVector by avoiding a double switch statement; (switch on direction in TLorentzVector followed by same switch in TVector3). This merge request is result of profiling work in the AliRoot framework where simple accesses to the mentioned objects are considerable (on the 2% level).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/165
https://github.com/root-project/root/pull/165:377,Security,access,accesses,377,"- move important functions (constructors,destructors,accessors) to header; to avoid overhead in creating and accessing these small objects; - optimize access to TLorentzVector by avoiding a double switch statement; (switch on direction in TLorentzVector followed by same switch in TVector3). This merge request is result of profiling work in the AliRoot framework where simple accesses to the mentioned objects are considerable (on the 2% level).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/165
https://github.com/root-project/root/pull/165:370,Usability,simpl,simple,370,"- move important functions (constructors,destructors,accessors) to header; to avoid overhead in creating and accessing these small objects; - optimize access to TLorentzVector by avoiding a double switch statement; (switch on direction in TLorentzVector followed by same switch in TVector3). This merge request is result of profiling work in the AliRoot framework where simple accesses to the mentioned objects are considerable (on the 2% level).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/165
https://github.com/root-project/root/pull/166:142,Performance,optimiz,optimize,142,"- move important functions (constructors,destructors,accessors) to header; to avoid overhead in creating and accessing these small objects; - optimize access to TLorentzVector by avoiding a double switch statement; (switch on direction in TLorentzVector followed by same switch in TVector3)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/166
https://github.com/root-project/root/pull/166:78,Safety,avoid,avoid,78,"- move important functions (constructors,destructors,accessors) to header; to avoid overhead in creating and accessing these small objects; - optimize access to TLorentzVector by avoiding a double switch statement; (switch on direction in TLorentzVector followed by same switch in TVector3)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/166
https://github.com/root-project/root/pull/166:179,Safety,avoid,avoiding,179,"- move important functions (constructors,destructors,accessors) to header; to avoid overhead in creating and accessing these small objects; - optimize access to TLorentzVector by avoiding a double switch statement; (switch on direction in TLorentzVector followed by same switch in TVector3)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/166
https://github.com/root-project/root/pull/166:53,Security,access,accessors,53,"- move important functions (constructors,destructors,accessors) to header; to avoid overhead in creating and accessing these small objects; - optimize access to TLorentzVector by avoiding a double switch statement; (switch on direction in TLorentzVector followed by same switch in TVector3)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/166
https://github.com/root-project/root/pull/166:109,Security,access,accessing,109,"- move important functions (constructors,destructors,accessors) to header; to avoid overhead in creating and accessing these small objects; - optimize access to TLorentzVector by avoiding a double switch statement; (switch on direction in TLorentzVector followed by same switch in TVector3)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/166
https://github.com/root-project/root/pull/166:151,Security,access,access,151,"- move important functions (constructors,destructors,accessors) to header; to avoid overhead in creating and accessing these small objects; - optimize access to TLorentzVector by avoiding a double switch statement; (switch on direction in TLorentzVector followed by same switch in TVector3)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/166
https://github.com/root-project/root/pull/169:1236,Availability,error,error,1236,"This somewhat huge commit mainly demotes many class-versions to 0. . If wanted, I can for sure squash some things (right now, the commit messages contain the underlying reasoning). . In ROOT, a lot of classes were equipped with class-versions > 0 even though they are not meant for IO / streaming. ; This produces unnecessary overhead (creation of Streamer() functions) and might be misleading for users (especially if they believe streaming of these classes would be ok and then lose parts of their data). That's even more helpful when testing framework's dataobject-code. . These classes were identified by https://github.com/olifre/rootStaticAnalyzer (a new project still in early stages) and I have created this PR to fix almost all these issues. . The last commit in the series also explicitly marks two members (of TSeqCollection and THashList) as transient, even though these classes are already class-version 0. This is purely to make it more explicit that these are not streamed - and allow for programmatic testing (since then the `kTransient` bit of the `TRealData` will be set correctly). . Several issues alerted by `rootStaticAnalyzer` still remain which are probably real bugs in ROOT 6. . Examples: . ```; TMVA/PDF.h:0: error: Data object class 'TMVA::PDF' will not stream the following indirect members: members 'fConfigName, fConfigDescription, fReferenceFile' from class 'TMVA::Configurable' (class-version 0)!; ```. It seems like `TMVA::PDF` is meant for streaming, but inherits from a base which is not. . Similar to that:. ```; include/TTreeResult.h:0: error: Data object class 'TTreeResult' will not stream the following indirect members: members 'fRowCount' from class 'TSQLResult' (class-version 0)!; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/169
https://github.com/root-project/root/pull/169:1575,Availability,error,error,1575,"This somewhat huge commit mainly demotes many class-versions to 0. . If wanted, I can for sure squash some things (right now, the commit messages contain the underlying reasoning). . In ROOT, a lot of classes were equipped with class-versions > 0 even though they are not meant for IO / streaming. ; This produces unnecessary overhead (creation of Streamer() functions) and might be misleading for users (especially if they believe streaming of these classes would be ok and then lose parts of their data). That's even more helpful when testing framework's dataobject-code. . These classes were identified by https://github.com/olifre/rootStaticAnalyzer (a new project still in early stages) and I have created this PR to fix almost all these issues. . The last commit in the series also explicitly marks two members (of TSeqCollection and THashList) as transient, even though these classes are already class-version 0. This is purely to make it more explicit that these are not streamed - and allow for programmatic testing (since then the `kTransient` bit of the `TRealData` will be set correctly). . Several issues alerted by `rootStaticAnalyzer` still remain which are probably real bugs in ROOT 6. . Examples: . ```; TMVA/PDF.h:0: error: Data object class 'TMVA::PDF' will not stream the following indirect members: members 'fConfigName, fConfigDescription, fReferenceFile' from class 'TMVA::Configurable' (class-version 0)!; ```. It seems like `TMVA::PDF` is meant for streaming, but inherits from a base which is not. . Similar to that:. ```; include/TTreeResult.h:0: error: Data object class 'TTreeResult' will not stream the following indirect members: members 'fRowCount' from class 'TSQLResult' (class-version 0)!; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/169
https://github.com/root-project/root/pull/169:137,Integrability,message,messages,137,"This somewhat huge commit mainly demotes many class-versions to 0. . If wanted, I can for sure squash some things (right now, the commit messages contain the underlying reasoning). . In ROOT, a lot of classes were equipped with class-versions > 0 even though they are not meant for IO / streaming. ; This produces unnecessary overhead (creation of Streamer() functions) and might be misleading for users (especially if they believe streaming of these classes would be ok and then lose parts of their data). That's even more helpful when testing framework's dataobject-code. . These classes were identified by https://github.com/olifre/rootStaticAnalyzer (a new project still in early stages) and I have created this PR to fix almost all these issues. . The last commit in the series also explicitly marks two members (of TSeqCollection and THashList) as transient, even though these classes are already class-version 0. This is purely to make it more explicit that these are not streamed - and allow for programmatic testing (since then the `kTransient` bit of the `TRealData` will be set correctly). . Several issues alerted by `rootStaticAnalyzer` still remain which are probably real bugs in ROOT 6. . Examples: . ```; TMVA/PDF.h:0: error: Data object class 'TMVA::PDF' will not stream the following indirect members: members 'fConfigName, fConfigDescription, fReferenceFile' from class 'TMVA::Configurable' (class-version 0)!; ```. It seems like `TMVA::PDF` is meant for streaming, but inherits from a base which is not. . Similar to that:. ```; include/TTreeResult.h:0: error: Data object class 'TTreeResult' will not stream the following indirect members: members 'fRowCount' from class 'TSQLResult' (class-version 0)!; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/169
https://github.com/root-project/root/pull/169:1397,Modifiability,Config,Configurable,1397,"This somewhat huge commit mainly demotes many class-versions to 0. . If wanted, I can for sure squash some things (right now, the commit messages contain the underlying reasoning). . In ROOT, a lot of classes were equipped with class-versions > 0 even though they are not meant for IO / streaming. ; This produces unnecessary overhead (creation of Streamer() functions) and might be misleading for users (especially if they believe streaming of these classes would be ok and then lose parts of their data). That's even more helpful when testing framework's dataobject-code. . These classes were identified by https://github.com/olifre/rootStaticAnalyzer (a new project still in early stages) and I have created this PR to fix almost all these issues. . The last commit in the series also explicitly marks two members (of TSeqCollection and THashList) as transient, even though these classes are already class-version 0. This is purely to make it more explicit that these are not streamed - and allow for programmatic testing (since then the `kTransient` bit of the `TRealData` will be set correctly). . Several issues alerted by `rootStaticAnalyzer` still remain which are probably real bugs in ROOT 6. . Examples: . ```; TMVA/PDF.h:0: error: Data object class 'TMVA::PDF' will not stream the following indirect members: members 'fConfigName, fConfigDescription, fReferenceFile' from class 'TMVA::Configurable' (class-version 0)!; ```. It seems like `TMVA::PDF` is meant for streaming, but inherits from a base which is not. . Similar to that:. ```; include/TTreeResult.h:0: error: Data object class 'TTreeResult' will not stream the following indirect members: members 'fRowCount' from class 'TSQLResult' (class-version 0)!; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/169
https://github.com/root-project/root/pull/169:1490,Modifiability,inherit,inherits,1490,"This somewhat huge commit mainly demotes many class-versions to 0. . If wanted, I can for sure squash some things (right now, the commit messages contain the underlying reasoning). . In ROOT, a lot of classes were equipped with class-versions > 0 even though they are not meant for IO / streaming. ; This produces unnecessary overhead (creation of Streamer() functions) and might be misleading for users (especially if they believe streaming of these classes would be ok and then lose parts of their data). That's even more helpful when testing framework's dataobject-code. . These classes were identified by https://github.com/olifre/rootStaticAnalyzer (a new project still in early stages) and I have created this PR to fix almost all these issues. . The last commit in the series also explicitly marks two members (of TSeqCollection and THashList) as transient, even though these classes are already class-version 0. This is purely to make it more explicit that these are not streamed - and allow for programmatic testing (since then the `kTransient` bit of the `TRealData` will be set correctly). . Several issues alerted by `rootStaticAnalyzer` still remain which are probably real bugs in ROOT 6. . Examples: . ```; TMVA/PDF.h:0: error: Data object class 'TMVA::PDF' will not stream the following indirect members: members 'fConfigName, fConfigDescription, fReferenceFile' from class 'TMVA::Configurable' (class-version 0)!; ```. It seems like `TMVA::PDF` is meant for streaming, but inherits from a base which is not. . Similar to that:. ```; include/TTreeResult.h:0: error: Data object class 'TTreeResult' will not stream the following indirect members: members 'fRowCount' from class 'TSQLResult' (class-version 0)!; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/169
https://github.com/root-project/root/pull/169:537,Testability,test,testing,537,"This somewhat huge commit mainly demotes many class-versions to 0. . If wanted, I can for sure squash some things (right now, the commit messages contain the underlying reasoning). . In ROOT, a lot of classes were equipped with class-versions > 0 even though they are not meant for IO / streaming. ; This produces unnecessary overhead (creation of Streamer() functions) and might be misleading for users (especially if they believe streaming of these classes would be ok and then lose parts of their data). That's even more helpful when testing framework's dataobject-code. . These classes were identified by https://github.com/olifre/rootStaticAnalyzer (a new project still in early stages) and I have created this PR to fix almost all these issues. . The last commit in the series also explicitly marks two members (of TSeqCollection and THashList) as transient, even though these classes are already class-version 0. This is purely to make it more explicit that these are not streamed - and allow for programmatic testing (since then the `kTransient` bit of the `TRealData` will be set correctly). . Several issues alerted by `rootStaticAnalyzer` still remain which are probably real bugs in ROOT 6. . Examples: . ```; TMVA/PDF.h:0: error: Data object class 'TMVA::PDF' will not stream the following indirect members: members 'fConfigName, fConfigDescription, fReferenceFile' from class 'TMVA::Configurable' (class-version 0)!; ```. It seems like `TMVA::PDF` is meant for streaming, but inherits from a base which is not. . Similar to that:. ```; include/TTreeResult.h:0: error: Data object class 'TTreeResult' will not stream the following indirect members: members 'fRowCount' from class 'TSQLResult' (class-version 0)!; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/169
https://github.com/root-project/root/pull/169:1017,Testability,test,testing,1017,"This somewhat huge commit mainly demotes many class-versions to 0. . If wanted, I can for sure squash some things (right now, the commit messages contain the underlying reasoning). . In ROOT, a lot of classes were equipped with class-versions > 0 even though they are not meant for IO / streaming. ; This produces unnecessary overhead (creation of Streamer() functions) and might be misleading for users (especially if they believe streaming of these classes would be ok and then lose parts of their data). That's even more helpful when testing framework's dataobject-code. . These classes were identified by https://github.com/olifre/rootStaticAnalyzer (a new project still in early stages) and I have created this PR to fix almost all these issues. . The last commit in the series also explicitly marks two members (of TSeqCollection and THashList) as transient, even though these classes are already class-version 0. This is purely to make it more explicit that these are not streamed - and allow for programmatic testing (since then the `kTransient` bit of the `TRealData` will be set correctly). . Several issues alerted by `rootStaticAnalyzer` still remain which are probably real bugs in ROOT 6. . Examples: . ```; TMVA/PDF.h:0: error: Data object class 'TMVA::PDF' will not stream the following indirect members: members 'fConfigName, fConfigDescription, fReferenceFile' from class 'TMVA::Configurable' (class-version 0)!; ```. It seems like `TMVA::PDF` is meant for streaming, but inherits from a base which is not. . Similar to that:. ```; include/TTreeResult.h:0: error: Data object class 'TTreeResult' will not stream the following indirect members: members 'fRowCount' from class 'TSQLResult' (class-version 0)!; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/169
https://github.com/root-project/root/pull/170:492,Availability,Error,Error,492,"This goes hand-in-hand with #169 . ; These were found in a different way, though: ; By creating them with their default constructor and trying to stream them to a memory buffer (the ""StreamingTest"" of https://github.com/olifre/rootStaticAnalyzer ). . This PR demotes some class-versions for classes which break when streamed (and which are not supposed to be streamed) and makes one more member transient which should be transient (in TTreeFormula). . There's one more remaining issue:. ```; Error in <TStreamerInfo::Build>: TRandom1, discarding: const unsigned int* fTheSeeds, no [dimension]; ```. I'm not sure what the ""dimension"" should be for this member - it's not so clear from the ranlux code to me. . More issues are probably still there since rootStaticAnalyzer right now excludes some classes from testing completely if their construction / destruction using the default constructor fails.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/170
https://github.com/root-project/root/pull/170:808,Testability,test,testing,808,"This goes hand-in-hand with #169 . ; These were found in a different way, though: ; By creating them with their default constructor and trying to stream them to a memory buffer (the ""StreamingTest"" of https://github.com/olifre/rootStaticAnalyzer ). . This PR demotes some class-versions for classes which break when streamed (and which are not supposed to be streamed) and makes one more member transient which should be transient (in TTreeFormula). . There's one more remaining issue:. ```; Error in <TStreamerInfo::Build>: TRandom1, discarding: const unsigned int* fTheSeeds, no [dimension]; ```. I'm not sure what the ""dimension"" should be for this member - it's not so clear from the ranlux code to me. . More issues are probably still there since rootStaticAnalyzer right now excludes some classes from testing completely if their construction / destruction using the default constructor fails.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/170
https://github.com/root-project/root/pull/170:673,Usability,clear,clear,673,"This goes hand-in-hand with #169 . ; These were found in a different way, though: ; By creating them with their default constructor and trying to stream them to a memory buffer (the ""StreamingTest"" of https://github.com/olifre/rootStaticAnalyzer ). . This PR demotes some class-versions for classes which break when streamed (and which are not supposed to be streamed) and makes one more member transient which should be transient (in TTreeFormula). . There's one more remaining issue:. ```; Error in <TStreamerInfo::Build>: TRandom1, discarding: const unsigned int* fTheSeeds, no [dimension]; ```. I'm not sure what the ""dimension"" should be for this member - it's not so clear from the ranlux code to me. . More issues are probably still there since rootStaticAnalyzer right now excludes some classes from testing completely if their construction / destruction using the default constructor fails.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/170
https://github.com/root-project/root/pull/171:150,Availability,error,error,150,"This was missing in the default constructor. . Found automatically by https://github.com/olifre/rootStaticAnalyzer : . ```; include/TProtoClass.h:78: error: Streamed member 'unsigned int fCheckSum' of dataobject 'TProtoClass' not initialized by constructor!; ```. using the new test https://github.com/olifre/rootStaticAnalyzer/blob/master/src/tests/testStreamingUninitialized.cpp which identifies to-be-streamed members which are not initialized by the default constructors. ; There are likely more, but the other cases seem a bit more complex - I'm still working on improving the test.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/171
https://github.com/root-project/root/pull/171:278,Testability,test,test,278,"This was missing in the default constructor. . Found automatically by https://github.com/olifre/rootStaticAnalyzer : . ```; include/TProtoClass.h:78: error: Streamed member 'unsigned int fCheckSum' of dataobject 'TProtoClass' not initialized by constructor!; ```. using the new test https://github.com/olifre/rootStaticAnalyzer/blob/master/src/tests/testStreamingUninitialized.cpp which identifies to-be-streamed members which are not initialized by the default constructors. ; There are likely more, but the other cases seem a bit more complex - I'm still working on improving the test.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/171
https://github.com/root-project/root/pull/171:344,Testability,test,tests,344,"This was missing in the default constructor. . Found automatically by https://github.com/olifre/rootStaticAnalyzer : . ```; include/TProtoClass.h:78: error: Streamed member 'unsigned int fCheckSum' of dataobject 'TProtoClass' not initialized by constructor!; ```. using the new test https://github.com/olifre/rootStaticAnalyzer/blob/master/src/tests/testStreamingUninitialized.cpp which identifies to-be-streamed members which are not initialized by the default constructors. ; There are likely more, but the other cases seem a bit more complex - I'm still working on improving the test.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/171
https://github.com/root-project/root/pull/171:350,Testability,test,testStreamingUninitialized,350,"This was missing in the default constructor. . Found automatically by https://github.com/olifre/rootStaticAnalyzer : . ```; include/TProtoClass.h:78: error: Streamed member 'unsigned int fCheckSum' of dataobject 'TProtoClass' not initialized by constructor!; ```. using the new test https://github.com/olifre/rootStaticAnalyzer/blob/master/src/tests/testStreamingUninitialized.cpp which identifies to-be-streamed members which are not initialized by the default constructors. ; There are likely more, but the other cases seem a bit more complex - I'm still working on improving the test.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/171
https://github.com/root-project/root/pull/171:582,Testability,test,test,582,"This was missing in the default constructor. . Found automatically by https://github.com/olifre/rootStaticAnalyzer : . ```; include/TProtoClass.h:78: error: Streamed member 'unsigned int fCheckSum' of dataobject 'TProtoClass' not initialized by constructor!; ```. using the new test https://github.com/olifre/rootStaticAnalyzer/blob/master/src/tests/testStreamingUninitialized.cpp which identifies to-be-streamed members which are not initialized by the default constructors. ; There are likely more, but the other cases seem a bit more complex - I'm still working on improving the test.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/171
https://github.com/root-project/root/pull/172:24,Availability,error,error,24,seems like a copy&paste error (picked from #81),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/172
https://github.com/root-project/root/pull/173:173,Availability,error,error,173,ROOT won't compile because of changes in the Python 3 API together with; GCC 6.1 release. The code changes fixes the issues on my machine running; Arch Linux (except for an error in Python 3.5 numpy/__multiarray_api.h),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/173
https://github.com/root-project/root/pull/173:81,Deployability,release,release,81,ROOT won't compile because of changes in the Python 3 API together with; GCC 6.1 release. The code changes fixes the issues on my machine running; Arch Linux (except for an error in Python 3.5 numpy/__multiarray_api.h),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/173
https://github.com/root-project/root/pull/177:240,Testability,benchmark,benchmarks,240,"include lzo, lz4, zopfli, and brotli as compression algorithms in root. Essentially what is in [pseyfert/root-compression](https://github.com/pseyfert/root-compression) but built into root instead of as LD_PRELOAD hack. open issues:; - run benchmarks in this version; - extensive testing (e.g. various platforms); - decide which parts are worth pursuing; - review license compatibilities (LZO is GPL, i.e. incompatible with root; LZ4 is BSD; ZOPFLI is APACHE; BROTLI is MIT); - for lz4, there is also #81. It is worth reviewing the differences. notable features:; - zopfli compresses in the zlib format and can thus be read even with root versions w/o zopfli",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/177
https://github.com/root-project/root/pull/177:280,Testability,test,testing,280,"include lzo, lz4, zopfli, and brotli as compression algorithms in root. Essentially what is in [pseyfert/root-compression](https://github.com/pseyfert/root-compression) but built into root instead of as LD_PRELOAD hack. open issues:; - run benchmarks in this version; - extensive testing (e.g. various platforms); - decide which parts are worth pursuing; - review license compatibilities (LZO is GPL, i.e. incompatible with root; LZ4 is BSD; ZOPFLI is APACHE; BROTLI is MIT); - for lz4, there is also #81. It is worth reviewing the differences. notable features:; - zopfli compresses in the zlib format and can thus be read even with root versions w/o zopfli",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/177
https://github.com/root-project/root/pull/179:2,Modifiability,variab,variable,2,A variable transformation method Variance Threshold (VT) has been added in DataLoader class which computes the variance of all variables and return a new DataLoader with the selected variables which lie above a specific threshold. I have also created a Jupyter [notebook](https://github.com/abhinavmoudgil95/tmva-notebooks/blob/master/VarianceThreshold.ipynb) to demonstrate it. . Kindly review. ; cc: @omazapa @lmoneta,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/179
https://github.com/root-project/root/pull/179:127,Modifiability,variab,variables,127,A variable transformation method Variance Threshold (VT) has been added in DataLoader class which computes the variance of all variables and return a new DataLoader with the selected variables which lie above a specific threshold. I have also created a Jupyter [notebook](https://github.com/abhinavmoudgil95/tmva-notebooks/blob/master/VarianceThreshold.ipynb) to demonstrate it. . Kindly review. ; cc: @omazapa @lmoneta,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/179
https://github.com/root-project/root/pull/179:183,Modifiability,variab,variables,183,A variable transformation method Variance Threshold (VT) has been added in DataLoader class which computes the variance of all variables and return a new DataLoader with the selected variables which lie above a specific threshold. I have also created a Jupyter [notebook](https://github.com/abhinavmoudgil95/tmva-notebooks/blob/master/VarianceThreshold.ipynb) to demonstrate it. . Kindly review. ; cc: @omazapa @lmoneta,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/179
https://github.com/root-project/root/pull/180:205,Modifiability,Config,Configurable,205,"Hi Enric,. The next 3 items was applied.; - DefaultDataSetInfo: Omar will add a public method to DataLoader for getting a const reference to the DataSetInfo. This is needed by both Attila and Georgios.; - Configurable::Log: Omar will make it public. Attila needs this.; - MethodBase::CreateVariableTransforms: make it public. Attila needs this. The last one is an static method in the class MethodBase, then may you can call it in python; from ROOT import TMVA; TMVA.MethodBase.CreateVariableTransforms. Best ; Omar.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/180
https://github.com/root-project/root/pull/180:219,Testability,Log,Log,219,"Hi Enric,. The next 3 items was applied.; - DefaultDataSetInfo: Omar will add a public method to DataLoader for getting a const reference to the DataSetInfo. This is needed by both Attila and Georgios.; - Configurable::Log: Omar will make it public. Attila needs this.; - MethodBase::CreateVariableTransforms: make it public. Attila needs this. The last one is an static method in the class MethodBase, then may you can call it in python; from ROOT import TMVA; TMVA.MethodBase.CreateVariableTransforms. Best ; Omar.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/180
https://github.com/root-project/root/pull/185:1274,Deployability,release,release-area,1274,"The idea is to catch branch names, which will lead to problems when using the tree with `Draw` or `MakeClass`.; This can either be the member variables (branch names and `b_`branch names) which have to keep the generated code compilable (and ensure it does what it is expected to do). And the variable names should not lead to confusion with formula evaluation in Draw (e.g. branch names which are pure numbers). The tests suggested here are:; - test if branch name is a valid c++ variable name (w/o testing keywords).; - test if branch name begins with ""b_"" (potential problem with MakeClass). on top of that, I also have a [black list](https://github.com/pseyfert/tmva-branch-adder/blob/master/src/blacklist.cpp) of unfortunate branch names: methods of TTrees, which would clash in MakeClass, c++ keywords, variable types, and things TTree::Draw can parse (though I don't see how `TTree::Draw(""cos(x)"")` would clash with `TTree::Draw(""cos"")` if there is a variable named `cos`. Because the function `cos` wouldn't work without argument, and the variable `cos` wouldn't work with argument). I only warn here and don't abort the branch initialisation, not to break third party code (variables with `.` are probably common [e.g. dynamically generated from float](http://lhcb-release-area.web.cern.ch/LHCb-release-area/DOC/davinci/latest_doxygen/d9/d80/_tuple_tool_cone_isolation_8cpp_source.html#l00204) ). Feedback request:; I'm unsure if putting the blacklist into TBranch.cxx is really the best solution to apply here.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/185
https://github.com/root-project/root/pull/185:1304,Deployability,release,release-area,1304,"The idea is to catch branch names, which will lead to problems when using the tree with `Draw` or `MakeClass`.; This can either be the member variables (branch names and `b_`branch names) which have to keep the generated code compilable (and ensure it does what it is expected to do). And the variable names should not lead to confusion with formula evaluation in Draw (e.g. branch names which are pure numbers). The tests suggested here are:; - test if branch name is a valid c++ variable name (w/o testing keywords).; - test if branch name begins with ""b_"" (potential problem with MakeClass). on top of that, I also have a [black list](https://github.com/pseyfert/tmva-branch-adder/blob/master/src/blacklist.cpp) of unfortunate branch names: methods of TTrees, which would clash in MakeClass, c++ keywords, variable types, and things TTree::Draw can parse (though I don't see how `TTree::Draw(""cos(x)"")` would clash with `TTree::Draw(""cos"")` if there is a variable named `cos`. Because the function `cos` wouldn't work without argument, and the variable `cos` wouldn't work with argument). I only warn here and don't abort the branch initialisation, not to break third party code (variables with `.` are probably common [e.g. dynamically generated from float](http://lhcb-release-area.web.cern.ch/LHCb-release-area/DOC/davinci/latest_doxygen/d9/d80/_tuple_tool_cone_isolation_8cpp_source.html#l00204) ). Feedback request:; I'm unsure if putting the blacklist into TBranch.cxx is really the best solution to apply here.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/185
https://github.com/root-project/root/pull/185:142,Modifiability,variab,variables,142,"The idea is to catch branch names, which will lead to problems when using the tree with `Draw` or `MakeClass`.; This can either be the member variables (branch names and `b_`branch names) which have to keep the generated code compilable (and ensure it does what it is expected to do). And the variable names should not lead to confusion with formula evaluation in Draw (e.g. branch names which are pure numbers). The tests suggested here are:; - test if branch name is a valid c++ variable name (w/o testing keywords).; - test if branch name begins with ""b_"" (potential problem with MakeClass). on top of that, I also have a [black list](https://github.com/pseyfert/tmva-branch-adder/blob/master/src/blacklist.cpp) of unfortunate branch names: methods of TTrees, which would clash in MakeClass, c++ keywords, variable types, and things TTree::Draw can parse (though I don't see how `TTree::Draw(""cos(x)"")` would clash with `TTree::Draw(""cos"")` if there is a variable named `cos`. Because the function `cos` wouldn't work without argument, and the variable `cos` wouldn't work with argument). I only warn here and don't abort the branch initialisation, not to break third party code (variables with `.` are probably common [e.g. dynamically generated from float](http://lhcb-release-area.web.cern.ch/LHCb-release-area/DOC/davinci/latest_doxygen/d9/d80/_tuple_tool_cone_isolation_8cpp_source.html#l00204) ). Feedback request:; I'm unsure if putting the blacklist into TBranch.cxx is really the best solution to apply here.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/185
https://github.com/root-project/root/pull/185:293,Modifiability,variab,variable,293,"The idea is to catch branch names, which will lead to problems when using the tree with `Draw` or `MakeClass`.; This can either be the member variables (branch names and `b_`branch names) which have to keep the generated code compilable (and ensure it does what it is expected to do). And the variable names should not lead to confusion with formula evaluation in Draw (e.g. branch names which are pure numbers). The tests suggested here are:; - test if branch name is a valid c++ variable name (w/o testing keywords).; - test if branch name begins with ""b_"" (potential problem with MakeClass). on top of that, I also have a [black list](https://github.com/pseyfert/tmva-branch-adder/blob/master/src/blacklist.cpp) of unfortunate branch names: methods of TTrees, which would clash in MakeClass, c++ keywords, variable types, and things TTree::Draw can parse (though I don't see how `TTree::Draw(""cos(x)"")` would clash with `TTree::Draw(""cos"")` if there is a variable named `cos`. Because the function `cos` wouldn't work without argument, and the variable `cos` wouldn't work with argument). I only warn here and don't abort the branch initialisation, not to break third party code (variables with `.` are probably common [e.g. dynamically generated from float](http://lhcb-release-area.web.cern.ch/LHCb-release-area/DOC/davinci/latest_doxygen/d9/d80/_tuple_tool_cone_isolation_8cpp_source.html#l00204) ). Feedback request:; I'm unsure if putting the blacklist into TBranch.cxx is really the best solution to apply here.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/185
https://github.com/root-project/root/pull/185:481,Modifiability,variab,variable,481,"The idea is to catch branch names, which will lead to problems when using the tree with `Draw` or `MakeClass`.; This can either be the member variables (branch names and `b_`branch names) which have to keep the generated code compilable (and ensure it does what it is expected to do). And the variable names should not lead to confusion with formula evaluation in Draw (e.g. branch names which are pure numbers). The tests suggested here are:; - test if branch name is a valid c++ variable name (w/o testing keywords).; - test if branch name begins with ""b_"" (potential problem with MakeClass). on top of that, I also have a [black list](https://github.com/pseyfert/tmva-branch-adder/blob/master/src/blacklist.cpp) of unfortunate branch names: methods of TTrees, which would clash in MakeClass, c++ keywords, variable types, and things TTree::Draw can parse (though I don't see how `TTree::Draw(""cos(x)"")` would clash with `TTree::Draw(""cos"")` if there is a variable named `cos`. Because the function `cos` wouldn't work without argument, and the variable `cos` wouldn't work with argument). I only warn here and don't abort the branch initialisation, not to break third party code (variables with `.` are probably common [e.g. dynamically generated from float](http://lhcb-release-area.web.cern.ch/LHCb-release-area/DOC/davinci/latest_doxygen/d9/d80/_tuple_tool_cone_isolation_8cpp_source.html#l00204) ). Feedback request:; I'm unsure if putting the blacklist into TBranch.cxx is really the best solution to apply here.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/185
https://github.com/root-project/root/pull/185:809,Modifiability,variab,variable,809,"The idea is to catch branch names, which will lead to problems when using the tree with `Draw` or `MakeClass`.; This can either be the member variables (branch names and `b_`branch names) which have to keep the generated code compilable (and ensure it does what it is expected to do). And the variable names should not lead to confusion with formula evaluation in Draw (e.g. branch names which are pure numbers). The tests suggested here are:; - test if branch name is a valid c++ variable name (w/o testing keywords).; - test if branch name begins with ""b_"" (potential problem with MakeClass). on top of that, I also have a [black list](https://github.com/pseyfert/tmva-branch-adder/blob/master/src/blacklist.cpp) of unfortunate branch names: methods of TTrees, which would clash in MakeClass, c++ keywords, variable types, and things TTree::Draw can parse (though I don't see how `TTree::Draw(""cos(x)"")` would clash with `TTree::Draw(""cos"")` if there is a variable named `cos`. Because the function `cos` wouldn't work without argument, and the variable `cos` wouldn't work with argument). I only warn here and don't abort the branch initialisation, not to break third party code (variables with `.` are probably common [e.g. dynamically generated from float](http://lhcb-release-area.web.cern.ch/LHCb-release-area/DOC/davinci/latest_doxygen/d9/d80/_tuple_tool_cone_isolation_8cpp_source.html#l00204) ). Feedback request:; I'm unsure if putting the blacklist into TBranch.cxx is really the best solution to apply here.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/185
https://github.com/root-project/root/pull/185:958,Modifiability,variab,variable,958,"The idea is to catch branch names, which will lead to problems when using the tree with `Draw` or `MakeClass`.; This can either be the member variables (branch names and `b_`branch names) which have to keep the generated code compilable (and ensure it does what it is expected to do). And the variable names should not lead to confusion with formula evaluation in Draw (e.g. branch names which are pure numbers). The tests suggested here are:; - test if branch name is a valid c++ variable name (w/o testing keywords).; - test if branch name begins with ""b_"" (potential problem with MakeClass). on top of that, I also have a [black list](https://github.com/pseyfert/tmva-branch-adder/blob/master/src/blacklist.cpp) of unfortunate branch names: methods of TTrees, which would clash in MakeClass, c++ keywords, variable types, and things TTree::Draw can parse (though I don't see how `TTree::Draw(""cos(x)"")` would clash with `TTree::Draw(""cos"")` if there is a variable named `cos`. Because the function `cos` wouldn't work without argument, and the variable `cos` wouldn't work with argument). I only warn here and don't abort the branch initialisation, not to break third party code (variables with `.` are probably common [e.g. dynamically generated from float](http://lhcb-release-area.web.cern.ch/LHCb-release-area/DOC/davinci/latest_doxygen/d9/d80/_tuple_tool_cone_isolation_8cpp_source.html#l00204) ). Feedback request:; I'm unsure if putting the blacklist into TBranch.cxx is really the best solution to apply here.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/185
https://github.com/root-project/root/pull/185:1047,Modifiability,variab,variable,1047,"The idea is to catch branch names, which will lead to problems when using the tree with `Draw` or `MakeClass`.; This can either be the member variables (branch names and `b_`branch names) which have to keep the generated code compilable (and ensure it does what it is expected to do). And the variable names should not lead to confusion with formula evaluation in Draw (e.g. branch names which are pure numbers). The tests suggested here are:; - test if branch name is a valid c++ variable name (w/o testing keywords).; - test if branch name begins with ""b_"" (potential problem with MakeClass). on top of that, I also have a [black list](https://github.com/pseyfert/tmva-branch-adder/blob/master/src/blacklist.cpp) of unfortunate branch names: methods of TTrees, which would clash in MakeClass, c++ keywords, variable types, and things TTree::Draw can parse (though I don't see how `TTree::Draw(""cos(x)"")` would clash with `TTree::Draw(""cos"")` if there is a variable named `cos`. Because the function `cos` wouldn't work without argument, and the variable `cos` wouldn't work with argument). I only warn here and don't abort the branch initialisation, not to break third party code (variables with `.` are probably common [e.g. dynamically generated from float](http://lhcb-release-area.web.cern.ch/LHCb-release-area/DOC/davinci/latest_doxygen/d9/d80/_tuple_tool_cone_isolation_8cpp_source.html#l00204) ). Feedback request:; I'm unsure if putting the blacklist into TBranch.cxx is really the best solution to apply here.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/185
https://github.com/root-project/root/pull/185:1183,Modifiability,variab,variables,1183,"The idea is to catch branch names, which will lead to problems when using the tree with `Draw` or `MakeClass`.; This can either be the member variables (branch names and `b_`branch names) which have to keep the generated code compilable (and ensure it does what it is expected to do). And the variable names should not lead to confusion with formula evaluation in Draw (e.g. branch names which are pure numbers). The tests suggested here are:; - test if branch name is a valid c++ variable name (w/o testing keywords).; - test if branch name begins with ""b_"" (potential problem with MakeClass). on top of that, I also have a [black list](https://github.com/pseyfert/tmva-branch-adder/blob/master/src/blacklist.cpp) of unfortunate branch names: methods of TTrees, which would clash in MakeClass, c++ keywords, variable types, and things TTree::Draw can parse (though I don't see how `TTree::Draw(""cos(x)"")` would clash with `TTree::Draw(""cos"")` if there is a variable named `cos`. Because the function `cos` wouldn't work without argument, and the variable `cos` wouldn't work with argument). I only warn here and don't abort the branch initialisation, not to break third party code (variables with `.` are probably common [e.g. dynamically generated from float](http://lhcb-release-area.web.cern.ch/LHCb-release-area/DOC/davinci/latest_doxygen/d9/d80/_tuple_tool_cone_isolation_8cpp_source.html#l00204) ). Feedback request:; I'm unsure if putting the blacklist into TBranch.cxx is really the best solution to apply here.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/185
https://github.com/root-project/root/pull/185:1119,Safety,abort,abort,1119,"The idea is to catch branch names, which will lead to problems when using the tree with `Draw` or `MakeClass`.; This can either be the member variables (branch names and `b_`branch names) which have to keep the generated code compilable (and ensure it does what it is expected to do). And the variable names should not lead to confusion with formula evaluation in Draw (e.g. branch names which are pure numbers). The tests suggested here are:; - test if branch name is a valid c++ variable name (w/o testing keywords).; - test if branch name begins with ""b_"" (potential problem with MakeClass). on top of that, I also have a [black list](https://github.com/pseyfert/tmva-branch-adder/blob/master/src/blacklist.cpp) of unfortunate branch names: methods of TTrees, which would clash in MakeClass, c++ keywords, variable types, and things TTree::Draw can parse (though I don't see how `TTree::Draw(""cos(x)"")` would clash with `TTree::Draw(""cos"")` if there is a variable named `cos`. Because the function `cos` wouldn't work without argument, and the variable `cos` wouldn't work with argument). I only warn here and don't abort the branch initialisation, not to break third party code (variables with `.` are probably common [e.g. dynamically generated from float](http://lhcb-release-area.web.cern.ch/LHCb-release-area/DOC/davinci/latest_doxygen/d9/d80/_tuple_tool_cone_isolation_8cpp_source.html#l00204) ). Feedback request:; I'm unsure if putting the blacklist into TBranch.cxx is really the best solution to apply here.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/185
https://github.com/root-project/root/pull/185:417,Testability,test,tests,417,"The idea is to catch branch names, which will lead to problems when using the tree with `Draw` or `MakeClass`.; This can either be the member variables (branch names and `b_`branch names) which have to keep the generated code compilable (and ensure it does what it is expected to do). And the variable names should not lead to confusion with formula evaluation in Draw (e.g. branch names which are pure numbers). The tests suggested here are:; - test if branch name is a valid c++ variable name (w/o testing keywords).; - test if branch name begins with ""b_"" (potential problem with MakeClass). on top of that, I also have a [black list](https://github.com/pseyfert/tmva-branch-adder/blob/master/src/blacklist.cpp) of unfortunate branch names: methods of TTrees, which would clash in MakeClass, c++ keywords, variable types, and things TTree::Draw can parse (though I don't see how `TTree::Draw(""cos(x)"")` would clash with `TTree::Draw(""cos"")` if there is a variable named `cos`. Because the function `cos` wouldn't work without argument, and the variable `cos` wouldn't work with argument). I only warn here and don't abort the branch initialisation, not to break third party code (variables with `.` are probably common [e.g. dynamically generated from float](http://lhcb-release-area.web.cern.ch/LHCb-release-area/DOC/davinci/latest_doxygen/d9/d80/_tuple_tool_cone_isolation_8cpp_source.html#l00204) ). Feedback request:; I'm unsure if putting the blacklist into TBranch.cxx is really the best solution to apply here.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/185
https://github.com/root-project/root/pull/185:446,Testability,test,test,446,"The idea is to catch branch names, which will lead to problems when using the tree with `Draw` or `MakeClass`.; This can either be the member variables (branch names and `b_`branch names) which have to keep the generated code compilable (and ensure it does what it is expected to do). And the variable names should not lead to confusion with formula evaluation in Draw (e.g. branch names which are pure numbers). The tests suggested here are:; - test if branch name is a valid c++ variable name (w/o testing keywords).; - test if branch name begins with ""b_"" (potential problem with MakeClass). on top of that, I also have a [black list](https://github.com/pseyfert/tmva-branch-adder/blob/master/src/blacklist.cpp) of unfortunate branch names: methods of TTrees, which would clash in MakeClass, c++ keywords, variable types, and things TTree::Draw can parse (though I don't see how `TTree::Draw(""cos(x)"")` would clash with `TTree::Draw(""cos"")` if there is a variable named `cos`. Because the function `cos` wouldn't work without argument, and the variable `cos` wouldn't work with argument). I only warn here and don't abort the branch initialisation, not to break third party code (variables with `.` are probably common [e.g. dynamically generated from float](http://lhcb-release-area.web.cern.ch/LHCb-release-area/DOC/davinci/latest_doxygen/d9/d80/_tuple_tool_cone_isolation_8cpp_source.html#l00204) ). Feedback request:; I'm unsure if putting the blacklist into TBranch.cxx is really the best solution to apply here.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/185
https://github.com/root-project/root/pull/185:500,Testability,test,testing,500,"The idea is to catch branch names, which will lead to problems when using the tree with `Draw` or `MakeClass`.; This can either be the member variables (branch names and `b_`branch names) which have to keep the generated code compilable (and ensure it does what it is expected to do). And the variable names should not lead to confusion with formula evaluation in Draw (e.g. branch names which are pure numbers). The tests suggested here are:; - test if branch name is a valid c++ variable name (w/o testing keywords).; - test if branch name begins with ""b_"" (potential problem with MakeClass). on top of that, I also have a [black list](https://github.com/pseyfert/tmva-branch-adder/blob/master/src/blacklist.cpp) of unfortunate branch names: methods of TTrees, which would clash in MakeClass, c++ keywords, variable types, and things TTree::Draw can parse (though I don't see how `TTree::Draw(""cos(x)"")` would clash with `TTree::Draw(""cos"")` if there is a variable named `cos`. Because the function `cos` wouldn't work without argument, and the variable `cos` wouldn't work with argument). I only warn here and don't abort the branch initialisation, not to break third party code (variables with `.` are probably common [e.g. dynamically generated from float](http://lhcb-release-area.web.cern.ch/LHCb-release-area/DOC/davinci/latest_doxygen/d9/d80/_tuple_tool_cone_isolation_8cpp_source.html#l00204) ). Feedback request:; I'm unsure if putting the blacklist into TBranch.cxx is really the best solution to apply here.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/185
https://github.com/root-project/root/pull/185:522,Testability,test,test,522,"The idea is to catch branch names, which will lead to problems when using the tree with `Draw` or `MakeClass`.; This can either be the member variables (branch names and `b_`branch names) which have to keep the generated code compilable (and ensure it does what it is expected to do). And the variable names should not lead to confusion with formula evaluation in Draw (e.g. branch names which are pure numbers). The tests suggested here are:; - test if branch name is a valid c++ variable name (w/o testing keywords).; - test if branch name begins with ""b_"" (potential problem with MakeClass). on top of that, I also have a [black list](https://github.com/pseyfert/tmva-branch-adder/blob/master/src/blacklist.cpp) of unfortunate branch names: methods of TTrees, which would clash in MakeClass, c++ keywords, variable types, and things TTree::Draw can parse (though I don't see how `TTree::Draw(""cos(x)"")` would clash with `TTree::Draw(""cos"")` if there is a variable named `cos`. Because the function `cos` wouldn't work without argument, and the variable `cos` wouldn't work with argument). I only warn here and don't abort the branch initialisation, not to break third party code (variables with `.` are probably common [e.g. dynamically generated from float](http://lhcb-release-area.web.cern.ch/LHCb-release-area/DOC/davinci/latest_doxygen/d9/d80/_tuple_tool_cone_isolation_8cpp_source.html#l00204) ). Feedback request:; I'm unsure if putting the blacklist into TBranch.cxx is really the best solution to apply here.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/185
https://github.com/root-project/root/pull/185:1406,Usability,Feedback,Feedback,1406,"The idea is to catch branch names, which will lead to problems when using the tree with `Draw` or `MakeClass`.; This can either be the member variables (branch names and `b_`branch names) which have to keep the generated code compilable (and ensure it does what it is expected to do). And the variable names should not lead to confusion with formula evaluation in Draw (e.g. branch names which are pure numbers). The tests suggested here are:; - test if branch name is a valid c++ variable name (w/o testing keywords).; - test if branch name begins with ""b_"" (potential problem with MakeClass). on top of that, I also have a [black list](https://github.com/pseyfert/tmva-branch-adder/blob/master/src/blacklist.cpp) of unfortunate branch names: methods of TTrees, which would clash in MakeClass, c++ keywords, variable types, and things TTree::Draw can parse (though I don't see how `TTree::Draw(""cos(x)"")` would clash with `TTree::Draw(""cos"")` if there is a variable named `cos`. Because the function `cos` wouldn't work without argument, and the variable `cos` wouldn't work with argument). I only warn here and don't abort the branch initialisation, not to break third party code (variables with `.` are probably common [e.g. dynamically generated from float](http://lhcb-release-area.web.cern.ch/LHCb-release-area/DOC/davinci/latest_doxygen/d9/d80/_tuple_tool_cone_isolation_8cpp_source.html#l00204) ). Feedback request:; I'm unsure if putting the blacklist into TBranch.cxx is really the best solution to apply here.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/185
https://github.com/root-project/root/pull/188:94,Deployability,patch,patches,94,See https://sft.its.cern.ch/jira/browse/ROOT-8180 ; This pull request implements the proposed patches there.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/188
https://github.com/root-project/root/pull/194:203,Energy Efficiency,allocate,allocated,203,"LZMA by default creates very large hash tables for its dictionaries, e.g., at compression level 4, the hash table is 4Mi 4 byte entries, 16 MiB total. The hash table has to be zeroed before use so it is allocated via calloc(), which means all the pages have to be allocated, mapped and written. ROOT baskets are often much smaller than the default LZMA dictionaries; for small baskets, the large dictionary has very little compression benefit, while zeroing the hash table can be more expensive than the actual compression operation. Since R__zipLZMA() is actually being used to compress a buffer of known size, not a stream, we can use the size of the buffer to estimate an appropriate size for the dictionary. This PR uses a slightly more advanced part of the LZMA API to set the dictionary size to 1/4 the size of the input buffer, if that is smaller than the default size from the selected preset compression level. In tests with CMS data, this results in less than 1% increase in the output size and (in one test job) a 25% reduction in job total run time, with LZMA compression time reduced by 80% (all of that time that was being spent in memset() zeroing the hash table). I also tested this with the ""Event"" test program with Brian's changes from #59. With the same test parameters as Brian (""./Event 4000 6 99 1 1000 2""), I get. ZLIB level-6: 14.4 MB/s; Original LZMA level-6: 2.3 MB/s; Modified LZMA level-6: 3.0 MB/s. With 100 tracks per event (and hence smaller baskets) the improvement is from 2.2 MB/s to 3.9 MB/s. This change should be fully transparent and backwards compatible.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/194
https://github.com/root-project/root/pull/194:264,Energy Efficiency,allocate,allocated,264,"LZMA by default creates very large hash tables for its dictionaries, e.g., at compression level 4, the hash table is 4Mi 4 byte entries, 16 MiB total. The hash table has to be zeroed before use so it is allocated via calloc(), which means all the pages have to be allocated, mapped and written. ROOT baskets are often much smaller than the default LZMA dictionaries; for small baskets, the large dictionary has very little compression benefit, while zeroing the hash table can be more expensive than the actual compression operation. Since R__zipLZMA() is actually being used to compress a buffer of known size, not a stream, we can use the size of the buffer to estimate an appropriate size for the dictionary. This PR uses a slightly more advanced part of the LZMA API to set the dictionary size to 1/4 the size of the input buffer, if that is smaller than the default size from the selected preset compression level. In tests with CMS data, this results in less than 1% increase in the output size and (in one test job) a 25% reduction in job total run time, with LZMA compression time reduced by 80% (all of that time that was being spent in memset() zeroing the hash table). I also tested this with the ""Event"" test program with Brian's changes from #59. With the same test parameters as Brian (""./Event 4000 6 99 1 1000 2""), I get. ZLIB level-6: 14.4 MB/s; Original LZMA level-6: 2.3 MB/s; Modified LZMA level-6: 3.0 MB/s. With 100 tracks per event (and hence smaller baskets) the improvement is from 2.2 MB/s to 3.9 MB/s. This change should be fully transparent and backwards compatible.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/194
https://github.com/root-project/root/pull/194:1089,Energy Efficiency,reduce,reduced,1089,"LZMA by default creates very large hash tables for its dictionaries, e.g., at compression level 4, the hash table is 4Mi 4 byte entries, 16 MiB total. The hash table has to be zeroed before use so it is allocated via calloc(), which means all the pages have to be allocated, mapped and written. ROOT baskets are often much smaller than the default LZMA dictionaries; for small baskets, the large dictionary has very little compression benefit, while zeroing the hash table can be more expensive than the actual compression operation. Since R__zipLZMA() is actually being used to compress a buffer of known size, not a stream, we can use the size of the buffer to estimate an appropriate size for the dictionary. This PR uses a slightly more advanced part of the LZMA API to set the dictionary size to 1/4 the size of the input buffer, if that is smaller than the default size from the selected preset compression level. In tests with CMS data, this results in less than 1% increase in the output size and (in one test job) a 25% reduction in job total run time, with LZMA compression time reduced by 80% (all of that time that was being spent in memset() zeroing the hash table). I also tested this with the ""Event"" test program with Brian's changes from #59. With the same test parameters as Brian (""./Event 4000 6 99 1 1000 2""), I get. ZLIB level-6: 14.4 MB/s; Original LZMA level-6: 2.3 MB/s; Modified LZMA level-6: 3.0 MB/s. With 100 tracks per event (and hence smaller baskets) the improvement is from 2.2 MB/s to 3.9 MB/s. This change should be fully transparent and backwards compatible.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/194
https://github.com/root-project/root/pull/194:35,Security,hash,hash,35,"LZMA by default creates very large hash tables for its dictionaries, e.g., at compression level 4, the hash table is 4Mi 4 byte entries, 16 MiB total. The hash table has to be zeroed before use so it is allocated via calloc(), which means all the pages have to be allocated, mapped and written. ROOT baskets are often much smaller than the default LZMA dictionaries; for small baskets, the large dictionary has very little compression benefit, while zeroing the hash table can be more expensive than the actual compression operation. Since R__zipLZMA() is actually being used to compress a buffer of known size, not a stream, we can use the size of the buffer to estimate an appropriate size for the dictionary. This PR uses a slightly more advanced part of the LZMA API to set the dictionary size to 1/4 the size of the input buffer, if that is smaller than the default size from the selected preset compression level. In tests with CMS data, this results in less than 1% increase in the output size and (in one test job) a 25% reduction in job total run time, with LZMA compression time reduced by 80% (all of that time that was being spent in memset() zeroing the hash table). I also tested this with the ""Event"" test program with Brian's changes from #59. With the same test parameters as Brian (""./Event 4000 6 99 1 1000 2""), I get. ZLIB level-6: 14.4 MB/s; Original LZMA level-6: 2.3 MB/s; Modified LZMA level-6: 3.0 MB/s. With 100 tracks per event (and hence smaller baskets) the improvement is from 2.2 MB/s to 3.9 MB/s. This change should be fully transparent and backwards compatible.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/194
https://github.com/root-project/root/pull/194:103,Security,hash,hash,103,"LZMA by default creates very large hash tables for its dictionaries, e.g., at compression level 4, the hash table is 4Mi 4 byte entries, 16 MiB total. The hash table has to be zeroed before use so it is allocated via calloc(), which means all the pages have to be allocated, mapped and written. ROOT baskets are often much smaller than the default LZMA dictionaries; for small baskets, the large dictionary has very little compression benefit, while zeroing the hash table can be more expensive than the actual compression operation. Since R__zipLZMA() is actually being used to compress a buffer of known size, not a stream, we can use the size of the buffer to estimate an appropriate size for the dictionary. This PR uses a slightly more advanced part of the LZMA API to set the dictionary size to 1/4 the size of the input buffer, if that is smaller than the default size from the selected preset compression level. In tests with CMS data, this results in less than 1% increase in the output size and (in one test job) a 25% reduction in job total run time, with LZMA compression time reduced by 80% (all of that time that was being spent in memset() zeroing the hash table). I also tested this with the ""Event"" test program with Brian's changes from #59. With the same test parameters as Brian (""./Event 4000 6 99 1 1000 2""), I get. ZLIB level-6: 14.4 MB/s; Original LZMA level-6: 2.3 MB/s; Modified LZMA level-6: 3.0 MB/s. With 100 tracks per event (and hence smaller baskets) the improvement is from 2.2 MB/s to 3.9 MB/s. This change should be fully transparent and backwards compatible.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/194
https://github.com/root-project/root/pull/194:155,Security,hash,hash,155,"LZMA by default creates very large hash tables for its dictionaries, e.g., at compression level 4, the hash table is 4Mi 4 byte entries, 16 MiB total. The hash table has to be zeroed before use so it is allocated via calloc(), which means all the pages have to be allocated, mapped and written. ROOT baskets are often much smaller than the default LZMA dictionaries; for small baskets, the large dictionary has very little compression benefit, while zeroing the hash table can be more expensive than the actual compression operation. Since R__zipLZMA() is actually being used to compress a buffer of known size, not a stream, we can use the size of the buffer to estimate an appropriate size for the dictionary. This PR uses a slightly more advanced part of the LZMA API to set the dictionary size to 1/4 the size of the input buffer, if that is smaller than the default size from the selected preset compression level. In tests with CMS data, this results in less than 1% increase in the output size and (in one test job) a 25% reduction in job total run time, with LZMA compression time reduced by 80% (all of that time that was being spent in memset() zeroing the hash table). I also tested this with the ""Event"" test program with Brian's changes from #59. With the same test parameters as Brian (""./Event 4000 6 99 1 1000 2""), I get. ZLIB level-6: 14.4 MB/s; Original LZMA level-6: 2.3 MB/s; Modified LZMA level-6: 3.0 MB/s. With 100 tracks per event (and hence smaller baskets) the improvement is from 2.2 MB/s to 3.9 MB/s. This change should be fully transparent and backwards compatible.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/194
https://github.com/root-project/root/pull/194:462,Security,hash,hash,462,"LZMA by default creates very large hash tables for its dictionaries, e.g., at compression level 4, the hash table is 4Mi 4 byte entries, 16 MiB total. The hash table has to be zeroed before use so it is allocated via calloc(), which means all the pages have to be allocated, mapped and written. ROOT baskets are often much smaller than the default LZMA dictionaries; for small baskets, the large dictionary has very little compression benefit, while zeroing the hash table can be more expensive than the actual compression operation. Since R__zipLZMA() is actually being used to compress a buffer of known size, not a stream, we can use the size of the buffer to estimate an appropriate size for the dictionary. This PR uses a slightly more advanced part of the LZMA API to set the dictionary size to 1/4 the size of the input buffer, if that is smaller than the default size from the selected preset compression level. In tests with CMS data, this results in less than 1% increase in the output size and (in one test job) a 25% reduction in job total run time, with LZMA compression time reduced by 80% (all of that time that was being spent in memset() zeroing the hash table). I also tested this with the ""Event"" test program with Brian's changes from #59. With the same test parameters as Brian (""./Event 4000 6 99 1 1000 2""), I get. ZLIB level-6: 14.4 MB/s; Original LZMA level-6: 2.3 MB/s; Modified LZMA level-6: 3.0 MB/s. With 100 tracks per event (and hence smaller baskets) the improvement is from 2.2 MB/s to 3.9 MB/s. This change should be fully transparent and backwards compatible.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/194
https://github.com/root-project/root/pull/194:1167,Security,hash,hash,1167,"LZMA by default creates very large hash tables for its dictionaries, e.g., at compression level 4, the hash table is 4Mi 4 byte entries, 16 MiB total. The hash table has to be zeroed before use so it is allocated via calloc(), which means all the pages have to be allocated, mapped and written. ROOT baskets are often much smaller than the default LZMA dictionaries; for small baskets, the large dictionary has very little compression benefit, while zeroing the hash table can be more expensive than the actual compression operation. Since R__zipLZMA() is actually being used to compress a buffer of known size, not a stream, we can use the size of the buffer to estimate an appropriate size for the dictionary. This PR uses a slightly more advanced part of the LZMA API to set the dictionary size to 1/4 the size of the input buffer, if that is smaller than the default size from the selected preset compression level. In tests with CMS data, this results in less than 1% increase in the output size and (in one test job) a 25% reduction in job total run time, with LZMA compression time reduced by 80% (all of that time that was being spent in memset() zeroing the hash table). I also tested this with the ""Event"" test program with Brian's changes from #59. With the same test parameters as Brian (""./Event 4000 6 99 1 1000 2""), I get. ZLIB level-6: 14.4 MB/s; Original LZMA level-6: 2.3 MB/s; Modified LZMA level-6: 3.0 MB/s. With 100 tracks per event (and hence smaller baskets) the improvement is from 2.2 MB/s to 3.9 MB/s. This change should be fully transparent and backwards compatible.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/194
https://github.com/root-project/root/pull/194:923,Testability,test,tests,923,"LZMA by default creates very large hash tables for its dictionaries, e.g., at compression level 4, the hash table is 4Mi 4 byte entries, 16 MiB total. The hash table has to be zeroed before use so it is allocated via calloc(), which means all the pages have to be allocated, mapped and written. ROOT baskets are often much smaller than the default LZMA dictionaries; for small baskets, the large dictionary has very little compression benefit, while zeroing the hash table can be more expensive than the actual compression operation. Since R__zipLZMA() is actually being used to compress a buffer of known size, not a stream, we can use the size of the buffer to estimate an appropriate size for the dictionary. This PR uses a slightly more advanced part of the LZMA API to set the dictionary size to 1/4 the size of the input buffer, if that is smaller than the default size from the selected preset compression level. In tests with CMS data, this results in less than 1% increase in the output size and (in one test job) a 25% reduction in job total run time, with LZMA compression time reduced by 80% (all of that time that was being spent in memset() zeroing the hash table). I also tested this with the ""Event"" test program with Brian's changes from #59. With the same test parameters as Brian (""./Event 4000 6 99 1 1000 2""), I get. ZLIB level-6: 14.4 MB/s; Original LZMA level-6: 2.3 MB/s; Modified LZMA level-6: 3.0 MB/s. With 100 tracks per event (and hence smaller baskets) the improvement is from 2.2 MB/s to 3.9 MB/s. This change should be fully transparent and backwards compatible.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/194
https://github.com/root-project/root/pull/194:1013,Testability,test,test,1013,"LZMA by default creates very large hash tables for its dictionaries, e.g., at compression level 4, the hash table is 4Mi 4 byte entries, 16 MiB total. The hash table has to be zeroed before use so it is allocated via calloc(), which means all the pages have to be allocated, mapped and written. ROOT baskets are often much smaller than the default LZMA dictionaries; for small baskets, the large dictionary has very little compression benefit, while zeroing the hash table can be more expensive than the actual compression operation. Since R__zipLZMA() is actually being used to compress a buffer of known size, not a stream, we can use the size of the buffer to estimate an appropriate size for the dictionary. This PR uses a slightly more advanced part of the LZMA API to set the dictionary size to 1/4 the size of the input buffer, if that is smaller than the default size from the selected preset compression level. In tests with CMS data, this results in less than 1% increase in the output size and (in one test job) a 25% reduction in job total run time, with LZMA compression time reduced by 80% (all of that time that was being spent in memset() zeroing the hash table). I also tested this with the ""Event"" test program with Brian's changes from #59. With the same test parameters as Brian (""./Event 4000 6 99 1 1000 2""), I get. ZLIB level-6: 14.4 MB/s; Original LZMA level-6: 2.3 MB/s; Modified LZMA level-6: 3.0 MB/s. With 100 tracks per event (and hence smaller baskets) the improvement is from 2.2 MB/s to 3.9 MB/s. This change should be fully transparent and backwards compatible.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/194
https://github.com/root-project/root/pull/194:1187,Testability,test,tested,1187,"LZMA by default creates very large hash tables for its dictionaries, e.g., at compression level 4, the hash table is 4Mi 4 byte entries, 16 MiB total. The hash table has to be zeroed before use so it is allocated via calloc(), which means all the pages have to be allocated, mapped and written. ROOT baskets are often much smaller than the default LZMA dictionaries; for small baskets, the large dictionary has very little compression benefit, while zeroing the hash table can be more expensive than the actual compression operation. Since R__zipLZMA() is actually being used to compress a buffer of known size, not a stream, we can use the size of the buffer to estimate an appropriate size for the dictionary. This PR uses a slightly more advanced part of the LZMA API to set the dictionary size to 1/4 the size of the input buffer, if that is smaller than the default size from the selected preset compression level. In tests with CMS data, this results in less than 1% increase in the output size and (in one test job) a 25% reduction in job total run time, with LZMA compression time reduced by 80% (all of that time that was being spent in memset() zeroing the hash table). I also tested this with the ""Event"" test program with Brian's changes from #59. With the same test parameters as Brian (""./Event 4000 6 99 1 1000 2""), I get. ZLIB level-6: 14.4 MB/s; Original LZMA level-6: 2.3 MB/s; Modified LZMA level-6: 3.0 MB/s. With 100 tracks per event (and hence smaller baskets) the improvement is from 2.2 MB/s to 3.9 MB/s. This change should be fully transparent and backwards compatible.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/194
https://github.com/root-project/root/pull/194:1216,Testability,test,test,1216,"LZMA by default creates very large hash tables for its dictionaries, e.g., at compression level 4, the hash table is 4Mi 4 byte entries, 16 MiB total. The hash table has to be zeroed before use so it is allocated via calloc(), which means all the pages have to be allocated, mapped and written. ROOT baskets are often much smaller than the default LZMA dictionaries; for small baskets, the large dictionary has very little compression benefit, while zeroing the hash table can be more expensive than the actual compression operation. Since R__zipLZMA() is actually being used to compress a buffer of known size, not a stream, we can use the size of the buffer to estimate an appropriate size for the dictionary. This PR uses a slightly more advanced part of the LZMA API to set the dictionary size to 1/4 the size of the input buffer, if that is smaller than the default size from the selected preset compression level. In tests with CMS data, this results in less than 1% increase in the output size and (in one test job) a 25% reduction in job total run time, with LZMA compression time reduced by 80% (all of that time that was being spent in memset() zeroing the hash table). I also tested this with the ""Event"" test program with Brian's changes from #59. With the same test parameters as Brian (""./Event 4000 6 99 1 1000 2""), I get. ZLIB level-6: 14.4 MB/s; Original LZMA level-6: 2.3 MB/s; Modified LZMA level-6: 3.0 MB/s. With 100 tracks per event (and hence smaller baskets) the improvement is from 2.2 MB/s to 3.9 MB/s. This change should be fully transparent and backwards compatible.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/194
https://github.com/root-project/root/pull/194:1274,Testability,test,test,1274,"LZMA by default creates very large hash tables for its dictionaries, e.g., at compression level 4, the hash table is 4Mi 4 byte entries, 16 MiB total. The hash table has to be zeroed before use so it is allocated via calloc(), which means all the pages have to be allocated, mapped and written. ROOT baskets are often much smaller than the default LZMA dictionaries; for small baskets, the large dictionary has very little compression benefit, while zeroing the hash table can be more expensive than the actual compression operation. Since R__zipLZMA() is actually being used to compress a buffer of known size, not a stream, we can use the size of the buffer to estimate an appropriate size for the dictionary. This PR uses a slightly more advanced part of the LZMA API to set the dictionary size to 1/4 the size of the input buffer, if that is smaller than the default size from the selected preset compression level. In tests with CMS data, this results in less than 1% increase in the output size and (in one test job) a 25% reduction in job total run time, with LZMA compression time reduced by 80% (all of that time that was being spent in memset() zeroing the hash table). I also tested this with the ""Event"" test program with Brian's changes from #59. With the same test parameters as Brian (""./Event 4000 6 99 1 1000 2""), I get. ZLIB level-6: 14.4 MB/s; Original LZMA level-6: 2.3 MB/s; Modified LZMA level-6: 3.0 MB/s. With 100 tracks per event (and hence smaller baskets) the improvement is from 2.2 MB/s to 3.9 MB/s. This change should be fully transparent and backwards compatible.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/194
https://github.com/root-project/root/pull/195:0,Usability,Simpl,Simple,0,Simple fix to force LLVM to use CXX1Y when cxx14 is enabled.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/195
https://github.com/root-project/root/pull/196:0,Integrability,Depend,Depends,0,"Depends on label size of the axis, but now the lower limit is the default label size. That way, zero size label axes are still click and draggable",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/196
https://github.com/root-project/root/pull/200:57,Safety,Safe,Safe,57,"Based on [1]. [1] Neri, C, ""Twisting the RTTI System for Safe Dynamic Casts of void\* in C++"", Dr.Dobb's Journal, April 05, 2011. http://drdobbs.com/cpp/229401004",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/200
https://github.com/root-project/root/pull/202:211,Deployability,update,updated,211,"The link system to the notebooks was modified to appear in the brief description. The brief description and link to source files were removed from the documentation for files type ""file"". Several tutorials were updated to create notebooks.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/202
https://github.com/root-project/root/pull/205:497,Deployability,patch,patch,497,"Based on `TClass::DynamicCast()`.; `root` script to check it working https://gist.github.com/BerserkerTroll/b94c2d3e3a5848be7c7dd53e323e1cdb. Besides different cast method, some bugs were fixed, so #200 was actually broken, despite it compiles (nobody has instantiated broken templates). Consider @a885623b7f04d193b299097b189bbb1fd45139e1 (exception-based cast, without bugs) if you want to get rid of `TClass` or apply this https://gist.github.com/BerserkerTroll/b6624c5f74b71293bc9c2059b4e5236a patch to this PR.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/205
https://github.com/root-project/root/pull/209:197,Availability,error,error,197,Filter doesn't display command line option `-js` and `-nodraw` in the description anymore. Tutorials now use `gROOT->GetTutorialsDir()` to access tutorial files. converttonotebooks now displays an error message that is picked up by jenkins when nbconvert fails.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/209
https://github.com/root-project/root/pull/209:203,Integrability,message,message,203,Filter doesn't display command line option `-js` and `-nodraw` in the description anymore. Tutorials now use `gROOT->GetTutorialsDir()` to access tutorial files. converttonotebooks now displays an error message that is picked up by jenkins when nbconvert fails.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/209
https://github.com/root-project/root/pull/209:139,Security,access,access,139,Filter doesn't display command line option `-js` and `-nodraw` in the description anymore. Tutorials now use `gROOT->GetTutorialsDir()` to access tutorial files. converttonotebooks now displays an error message that is picked up by jenkins when nbconvert fails.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/209
https://github.com/root-project/root/pull/212:133,Deployability,patch,patch,133,This allows to interactively adjust histogram parameters before; performing a projection to a lower dimensional representation. This patch implements ROOT-4515. A unit test is being added in root-mirror/roottest/pull/6.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/212
https://github.com/root-project/root/pull/212:65,Performance,perform,performing,65,This allows to interactively adjust histogram parameters before; performing a projection to a lower dimensional representation. This patch implements ROOT-4515. A unit test is being added in root-mirror/roottest/pull/6.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/212
https://github.com/root-project/root/pull/212:168,Testability,test,test,168,This allows to interactively adjust histogram parameters before; performing a projection to a lower dimensional representation. This patch implements ROOT-4515. A unit test is being added in root-mirror/roottest/pull/6.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/212
https://github.com/root-project/root/pull/216:144,Usability,simpl,simple,144,"Several changes were made. Firstly, several bugs were fixed in converttonotebook.py. The filter was modified to replace the \notebook line in a simple manner. Many tutorials were modified slightly, either ensuring tabs were three spaces as well as adding `-js`or `-nodraw` options. Finally, preprocessor statements involving `__CINT__` were removed from the tutorials, as well as `gStyle->SetPalette(1)`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/216
https://github.com/root-project/root/pull/217:46,Modifiability,variab,variable,46,"A couple broken tutorials were fixed. Several variable names were changed for improved clarity as a well as compatibility with the older version of the interpreter. The syntax `~~~` was replaced with the more universal Markdown syntax ``` ``` ```. Several bug fixes and improvements were made to the convertonotebook script. this includes capitalizing the first letter in every Markdown cell, and ensuring the link in the header is reproduced appropriately. Lastly, many aesthetic improvements were made to the tutorials, including ensuring tabs are three spaces, and styling important comments with Markdown.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/217
https://github.com/root-project/root/pull/219:132,Availability,error,error,132,"CMake versions 2.4 and below silently removed leading and trailing; whitespace from libraries linked with code. This was raising an error; for newer CMake versions, according to new CMake policy CMP004; https://cmake.org/cmake/help/v3.0/policy/CMP0004.html",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/219
https://github.com/root-project/root/pull/220:29,Security,Hash,HashedNets,29,This is an implementation of HashedNets (https://arxiv.org/pdf/1504.04788.pdf) in ROOT. It is built over the existing implementation of DNNs in TMVA and supports multithreading.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/220
https://github.com/root-project/root/pull/224:37,Modifiability,config,config,37,This allows doing. ```; source `root-config --prefix`/bin/thisroot.sh; ```. instead of. ```; cd `root-config --prefix` && source bin/thisroot.sh; ```,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/224
https://github.com/root-project/root/pull/224:102,Modifiability,config,config,102,This allows doing. ```; source `root-config --prefix`/bin/thisroot.sh; ```. instead of. ```; cd `root-config --prefix` && source bin/thisroot.sh; ```,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/224
https://github.com/root-project/root/pull/233:0,Testability,Test,Tests,0,"Tests and documentation for the converttonotebook script are improved. Also, the new ratioplot tutorials were converted to notebooks.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/233
https://github.com/root-project/root/pull/235:9,Usability,clear,clear,9,… and to clear the TLines instances used for the dashed lines. This is needed to trigger recreation after a pad clear from the outside. @couet,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/235
https://github.com/root-project/root/pull/235:112,Usability,clear,clear,112,… and to clear the TLines instances used for the dashed lines. This is needed to trigger recreation after a pad clear from the outside. @couet,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/235
https://github.com/root-project/root/pull/238:250,Availability,down,down,250,"This is work done by Alex Saperstein, and ANL SULI who worked with me. While working on TTreeCache learning, our Summer Intern (Alex Saperstein) observed that for simple TTrees, the basket size optimization isn’t optimal for two reasons: 1) rounding down to 512 byte blocks 2) neglecting to accommodate for ROOT offsets stored in the baskets. As a result, e.g. with simple (constant size) float array branches the basket size is to small resulting in two baskets per auto-flush. The change would be pretty straight-forward: tree/tree/src/TTree.cxx. Line; -6583 newBsize = newBsize - newBsize%512;. Should become:; +6583 if (pass) { // only on the second pass so that it doesn't interfere with scaling; +6583 Int_t nevbuf = branch->GetBasket(0)->GetNevBuf();; +6583 newBsize = newBsize + (nevbuf \* sizeof(Int_t) \* 2); // make room for meta data; +6583 newBsize = newBsize - newBsize%512 + 512; // rounds up; +6583 }. Tests on simple data show that with this the baskets end up more appropriately sized so that all the auto-flush data fits.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/238
https://github.com/root-project/root/pull/238:194,Performance,optimiz,optimization,194,"This is work done by Alex Saperstein, and ANL SULI who worked with me. While working on TTreeCache learning, our Summer Intern (Alex Saperstein) observed that for simple TTrees, the basket size optimization isn’t optimal for two reasons: 1) rounding down to 512 byte blocks 2) neglecting to accommodate for ROOT offsets stored in the baskets. As a result, e.g. with simple (constant size) float array branches the basket size is to small resulting in two baskets per auto-flush. The change would be pretty straight-forward: tree/tree/src/TTree.cxx. Line; -6583 newBsize = newBsize - newBsize%512;. Should become:; +6583 if (pass) { // only on the second pass so that it doesn't interfere with scaling; +6583 Int_t nevbuf = branch->GetBasket(0)->GetNevBuf();; +6583 newBsize = newBsize + (nevbuf \* sizeof(Int_t) \* 2); // make room for meta data; +6583 newBsize = newBsize - newBsize%512 + 512; // rounds up; +6583 }. Tests on simple data show that with this the baskets end up more appropriately sized so that all the auto-flush data fits.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/238
https://github.com/root-project/root/pull/238:918,Testability,Test,Tests,918,"This is work done by Alex Saperstein, and ANL SULI who worked with me. While working on TTreeCache learning, our Summer Intern (Alex Saperstein) observed that for simple TTrees, the basket size optimization isn’t optimal for two reasons: 1) rounding down to 512 byte blocks 2) neglecting to accommodate for ROOT offsets stored in the baskets. As a result, e.g. with simple (constant size) float array branches the basket size is to small resulting in two baskets per auto-flush. The change would be pretty straight-forward: tree/tree/src/TTree.cxx. Line; -6583 newBsize = newBsize - newBsize%512;. Should become:; +6583 if (pass) { // only on the second pass so that it doesn't interfere with scaling; +6583 Int_t nevbuf = branch->GetBasket(0)->GetNevBuf();; +6583 newBsize = newBsize + (nevbuf \* sizeof(Int_t) \* 2); // make room for meta data; +6583 newBsize = newBsize - newBsize%512 + 512; // rounds up; +6583 }. Tests on simple data show that with this the baskets end up more appropriately sized so that all the auto-flush data fits.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/238
https://github.com/root-project/root/pull/238:99,Usability,learn,learning,99,"This is work done by Alex Saperstein, and ANL SULI who worked with me. While working on TTreeCache learning, our Summer Intern (Alex Saperstein) observed that for simple TTrees, the basket size optimization isn’t optimal for two reasons: 1) rounding down to 512 byte blocks 2) neglecting to accommodate for ROOT offsets stored in the baskets. As a result, e.g. with simple (constant size) float array branches the basket size is to small resulting in two baskets per auto-flush. The change would be pretty straight-forward: tree/tree/src/TTree.cxx. Line; -6583 newBsize = newBsize - newBsize%512;. Should become:; +6583 if (pass) { // only on the second pass so that it doesn't interfere with scaling; +6583 Int_t nevbuf = branch->GetBasket(0)->GetNevBuf();; +6583 newBsize = newBsize + (nevbuf \* sizeof(Int_t) \* 2); // make room for meta data; +6583 newBsize = newBsize - newBsize%512 + 512; // rounds up; +6583 }. Tests on simple data show that with this the baskets end up more appropriately sized so that all the auto-flush data fits.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/238
https://github.com/root-project/root/pull/238:163,Usability,simpl,simple,163,"This is work done by Alex Saperstein, and ANL SULI who worked with me. While working on TTreeCache learning, our Summer Intern (Alex Saperstein) observed that for simple TTrees, the basket size optimization isn’t optimal for two reasons: 1) rounding down to 512 byte blocks 2) neglecting to accommodate for ROOT offsets stored in the baskets. As a result, e.g. with simple (constant size) float array branches the basket size is to small resulting in two baskets per auto-flush. The change would be pretty straight-forward: tree/tree/src/TTree.cxx. Line; -6583 newBsize = newBsize - newBsize%512;. Should become:; +6583 if (pass) { // only on the second pass so that it doesn't interfere with scaling; +6583 Int_t nevbuf = branch->GetBasket(0)->GetNevBuf();; +6583 newBsize = newBsize + (nevbuf \* sizeof(Int_t) \* 2); // make room for meta data; +6583 newBsize = newBsize - newBsize%512 + 512; // rounds up; +6583 }. Tests on simple data show that with this the baskets end up more appropriately sized so that all the auto-flush data fits.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/238
https://github.com/root-project/root/pull/238:366,Usability,simpl,simple,366,"This is work done by Alex Saperstein, and ANL SULI who worked with me. While working on TTreeCache learning, our Summer Intern (Alex Saperstein) observed that for simple TTrees, the basket size optimization isn’t optimal for two reasons: 1) rounding down to 512 byte blocks 2) neglecting to accommodate for ROOT offsets stored in the baskets. As a result, e.g. with simple (constant size) float array branches the basket size is to small resulting in two baskets per auto-flush. The change would be pretty straight-forward: tree/tree/src/TTree.cxx. Line; -6583 newBsize = newBsize - newBsize%512;. Should become:; +6583 if (pass) { // only on the second pass so that it doesn't interfere with scaling; +6583 Int_t nevbuf = branch->GetBasket(0)->GetNevBuf();; +6583 newBsize = newBsize + (nevbuf \* sizeof(Int_t) \* 2); // make room for meta data; +6583 newBsize = newBsize - newBsize%512 + 512; // rounds up; +6583 }. Tests on simple data show that with this the baskets end up more appropriately sized so that all the auto-flush data fits.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/238
https://github.com/root-project/root/pull/238:927,Usability,simpl,simple,927,"This is work done by Alex Saperstein, and ANL SULI who worked with me. While working on TTreeCache learning, our Summer Intern (Alex Saperstein) observed that for simple TTrees, the basket size optimization isn’t optimal for two reasons: 1) rounding down to 512 byte blocks 2) neglecting to accommodate for ROOT offsets stored in the baskets. As a result, e.g. with simple (constant size) float array branches the basket size is to small resulting in two baskets per auto-flush. The change would be pretty straight-forward: tree/tree/src/TTree.cxx. Line; -6583 newBsize = newBsize - newBsize%512;. Should become:; +6583 if (pass) { // only on the second pass so that it doesn't interfere with scaling; +6583 Int_t nevbuf = branch->GetBasket(0)->GetNevBuf();; +6583 newBsize = newBsize + (nevbuf \* sizeof(Int_t) \* 2); // make room for meta data; +6583 newBsize = newBsize - newBsize%512 + 512; // rounds up; +6583 }. Tests on simple data show that with this the baskets end up more appropriately sized so that all the auto-flush data fits.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/238
https://github.com/root-project/root/pull/239:258,Modifiability,variab,variables,258,"For GDML files without arithmetic expressions in them this should be just as fast and give the same behaviour as before. Parsing is implemented by TFormula, including a pre-processing step to mark constant names with ""[]"" so that TFormula recognizes them as variables. Tested by importing and re-exporting a GDML file used by the NOvA experiment in root5 and root6 and checking that the results were identical, except for the naming of the volumes.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/239
https://github.com/root-project/root/pull/239:269,Testability,Test,Tested,269,"For GDML files without arithmetic expressions in them this should be just as fast and give the same behaviour as before. Parsing is implemented by TFormula, including a pre-processing step to mark constant names with ""[]"" so that TFormula recognizes them as variables. Tested by importing and re-exporting a GDML file used by the NOvA experiment in root5 and root6 and checking that the results were identical, except for the naming of the volumes.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/239
https://github.com/root-project/root/pull/240:66,Performance,optimiz,optimization,66,"The _miss cache_, implemented in this pull request, implements an optimization when the TTreeCache fails to work. The miss cache will keep track of any branch that has been accessed; when there is a TTC miss, it automatically fetches the current basket for all active branches. This should have a worst case read size equal to the size of the file's cluster size, but potentially a significant savings in the number of IO operations. The latter is extremely useful if we're doing IO on high-latency links. This optimization works well for the ""trigger pattern,"" where the user may examine a number of branches and, when the event contents for those branches passes a particular filter, reads out the remaining branches. If there are 100 additional branches, this would do all reads in a single network round-trip as opposed to 100 round trips. The approach has served us well in CMS and been utilized as a layer on top of ROOT for about 3 years. Unfortunately, we must iterate through a set of branches and find the correct basket. This is not necessarily a cheap CPU operation and may be too expensive if the underlying filesystem is SSD-based. Hence, we turn this optimization off by default.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/240
https://github.com/root-project/root/pull/240:123,Performance,cache,cache,123,"The _miss cache_, implemented in this pull request, implements an optimization when the TTreeCache fails to work. The miss cache will keep track of any branch that has been accessed; when there is a TTC miss, it automatically fetches the current basket for all active branches. This should have a worst case read size equal to the size of the file's cluster size, but potentially a significant savings in the number of IO operations. The latter is extremely useful if we're doing IO on high-latency links. This optimization works well for the ""trigger pattern,"" where the user may examine a number of branches and, when the event contents for those branches passes a particular filter, reads out the remaining branches. If there are 100 additional branches, this would do all reads in a single network round-trip as opposed to 100 round trips. The approach has served us well in CMS and been utilized as a layer on top of ROOT for about 3 years. Unfortunately, we must iterate through a set of branches and find the correct basket. This is not necessarily a cheap CPU operation and may be too expensive if the underlying filesystem is SSD-based. Hence, we turn this optimization off by default.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/240
https://github.com/root-project/root/pull/240:491,Performance,latency,latency,491,"The _miss cache_, implemented in this pull request, implements an optimization when the TTreeCache fails to work. The miss cache will keep track of any branch that has been accessed; when there is a TTC miss, it automatically fetches the current basket for all active branches. This should have a worst case read size equal to the size of the file's cluster size, but potentially a significant savings in the number of IO operations. The latter is extremely useful if we're doing IO on high-latency links. This optimization works well for the ""trigger pattern,"" where the user may examine a number of branches and, when the event contents for those branches passes a particular filter, reads out the remaining branches. If there are 100 additional branches, this would do all reads in a single network round-trip as opposed to 100 round trips. The approach has served us well in CMS and been utilized as a layer on top of ROOT for about 3 years. Unfortunately, we must iterate through a set of branches and find the correct basket. This is not necessarily a cheap CPU operation and may be too expensive if the underlying filesystem is SSD-based. Hence, we turn this optimization off by default.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/240
https://github.com/root-project/root/pull/240:511,Performance,optimiz,optimization,511,"The _miss cache_, implemented in this pull request, implements an optimization when the TTreeCache fails to work. The miss cache will keep track of any branch that has been accessed; when there is a TTC miss, it automatically fetches the current basket for all active branches. This should have a worst case read size equal to the size of the file's cluster size, but potentially a significant savings in the number of IO operations. The latter is extremely useful if we're doing IO on high-latency links. This optimization works well for the ""trigger pattern,"" where the user may examine a number of branches and, when the event contents for those branches passes a particular filter, reads out the remaining branches. If there are 100 additional branches, this would do all reads in a single network round-trip as opposed to 100 round trips. The approach has served us well in CMS and been utilized as a layer on top of ROOT for about 3 years. Unfortunately, we must iterate through a set of branches and find the correct basket. This is not necessarily a cheap CPU operation and may be too expensive if the underlying filesystem is SSD-based. Hence, we turn this optimization off by default.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/240
https://github.com/root-project/root/pull/240:1166,Performance,optimiz,optimization,1166,"The _miss cache_, implemented in this pull request, implements an optimization when the TTreeCache fails to work. The miss cache will keep track of any branch that has been accessed; when there is a TTC miss, it automatically fetches the current basket for all active branches. This should have a worst case read size equal to the size of the file's cluster size, but potentially a significant savings in the number of IO operations. The latter is extremely useful if we're doing IO on high-latency links. This optimization works well for the ""trigger pattern,"" where the user may examine a number of branches and, when the event contents for those branches passes a particular filter, reads out the remaining branches. If there are 100 additional branches, this would do all reads in a single network round-trip as opposed to 100 round trips. The approach has served us well in CMS and been utilized as a layer on top of ROOT for about 3 years. Unfortunately, we must iterate through a set of branches and find the correct basket. This is not necessarily a cheap CPU operation and may be too expensive if the underlying filesystem is SSD-based. Hence, we turn this optimization off by default.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/240
https://github.com/root-project/root/pull/240:173,Security,access,accessed,173,"The _miss cache_, implemented in this pull request, implements an optimization when the TTreeCache fails to work. The miss cache will keep track of any branch that has been accessed; when there is a TTC miss, it automatically fetches the current basket for all active branches. This should have a worst case read size equal to the size of the file's cluster size, but potentially a significant savings in the number of IO operations. The latter is extremely useful if we're doing IO on high-latency links. This optimization works well for the ""trigger pattern,"" where the user may examine a number of branches and, when the event contents for those branches passes a particular filter, reads out the remaining branches. If there are 100 additional branches, this would do all reads in a single network round-trip as opposed to 100 round trips. The approach has served us well in CMS and been utilized as a layer on top of ROOT for about 3 years. Unfortunately, we must iterate through a set of branches and find the correct basket. This is not necessarily a cheap CPU operation and may be too expensive if the underlying filesystem is SSD-based. Hence, we turn this optimization off by default.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/240
https://github.com/root-project/root/pull/242:22,Modifiability,refactor,refactoring,22,"@pcanal - this is the refactoring you requested in #240 . Since it's now more visible, I also added a few small comments in `RConfig.h` about when these macros should be utilized.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/242
https://github.com/root-project/root/pull/243:233,Availability,avail,available,233,"Updating MethodBDT so that it can use different loss functions for regression. Edited MethodBDT.cxx, MethodBDT.h and added LossFunction.h and LossFunction.cxx to make this happen. Huber, Least Squares, and Absolute Deviation are now available for use.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/243
https://github.com/root-project/root/pull/244:381,Deployability,release,release,381,"We are working on LCFIPlus, a flavor tagging software used for linear collider (ILC/CLIC) studies.; We use multi-class BDT with output of b-tag, c-tag, and uds-tag (3 outputs).; We also separate events into four categories according to number of reconstructed vertices; (0-vtx, 1-vtx, 1-vtx+1-partial-vtx, and 2-vtx) which are trained and evaluated independently.; In the previous release with TMVA 4.1.0 we can use the output of BDTs as variables common to ; all categories, because the average value of eg. b-tag output from each BDT; over full training samples reflects the fraction of b events in the training samples.; (eg. if we have 80% of b and 20% of c + uds, we have the avarage value of .8 for b-tag output.); We found this feature is not preserved in the latest releases (after TMVA 4.1.2); due to the normalization procedure introduced in that version.; In result this causes significant degradation of our flavor tagging performance,; which was reported from a user using latest ROOT/TMVA.; We also found that just switching off the normalization procedure in the ROOT 6.06/TMVA 4.2.1; gives very similar performance to the ROOT 5.28/TMVA 4.1.0.; Therefore, we need to switch off the normalization to keep the performance,; which is realized in an option implemented in this pull request.; We hope this will be accepted, to avoid us from patching this to every release of ROOT; we use for studies using LCFIPlus flavor tagging feature.; We set this option to non-default, so current users should not be affected by this change.; ![btag-100k-root-6 06 02-skipnorm](https://cloud.githubusercontent.com/assets/7939934/18453216/0f501eb0-78f3-11e6-892c-912f9b68553d.png); B-tag performance with the SkipNormalization option; ![btag-100k-root-6 06 02-noskipnorm](https://cloud.githubusercontent.com/assets/7939934/18453215/0f4e6b60-78f3-11e6-94bd-b4be9631937d.png); B-tag performance without the SkipNormalization option",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/244
https://github.com/root-project/root/pull/244:774,Deployability,release,releases,774,"We are working on LCFIPlus, a flavor tagging software used for linear collider (ILC/CLIC) studies.; We use multi-class BDT with output of b-tag, c-tag, and uds-tag (3 outputs).; We also separate events into four categories according to number of reconstructed vertices; (0-vtx, 1-vtx, 1-vtx+1-partial-vtx, and 2-vtx) which are trained and evaluated independently.; In the previous release with TMVA 4.1.0 we can use the output of BDTs as variables common to ; all categories, because the average value of eg. b-tag output from each BDT; over full training samples reflects the fraction of b events in the training samples.; (eg. if we have 80% of b and 20% of c + uds, we have the avarage value of .8 for b-tag output.); We found this feature is not preserved in the latest releases (after TMVA 4.1.2); due to the normalization procedure introduced in that version.; In result this causes significant degradation of our flavor tagging performance,; which was reported from a user using latest ROOT/TMVA.; We also found that just switching off the normalization procedure in the ROOT 6.06/TMVA 4.2.1; gives very similar performance to the ROOT 5.28/TMVA 4.1.0.; Therefore, we need to switch off the normalization to keep the performance,; which is realized in an option implemented in this pull request.; We hope this will be accepted, to avoid us from patching this to every release of ROOT; we use for studies using LCFIPlus flavor tagging feature.; We set this option to non-default, so current users should not be affected by this change.; ![btag-100k-root-6 06 02-skipnorm](https://cloud.githubusercontent.com/assets/7939934/18453216/0f501eb0-78f3-11e6-892c-912f9b68553d.png); B-tag performance with the SkipNormalization option; ![btag-100k-root-6 06 02-noskipnorm](https://cloud.githubusercontent.com/assets/7939934/18453215/0f4e6b60-78f3-11e6-94bd-b4be9631937d.png); B-tag performance without the SkipNormalization option",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/244
https://github.com/root-project/root/pull/244:1352,Deployability,patch,patching,1352,"We are working on LCFIPlus, a flavor tagging software used for linear collider (ILC/CLIC) studies.; We use multi-class BDT with output of b-tag, c-tag, and uds-tag (3 outputs).; We also separate events into four categories according to number of reconstructed vertices; (0-vtx, 1-vtx, 1-vtx+1-partial-vtx, and 2-vtx) which are trained and evaluated independently.; In the previous release with TMVA 4.1.0 we can use the output of BDTs as variables common to ; all categories, because the average value of eg. b-tag output from each BDT; over full training samples reflects the fraction of b events in the training samples.; (eg. if we have 80% of b and 20% of c + uds, we have the avarage value of .8 for b-tag output.); We found this feature is not preserved in the latest releases (after TMVA 4.1.2); due to the normalization procedure introduced in that version.; In result this causes significant degradation of our flavor tagging performance,; which was reported from a user using latest ROOT/TMVA.; We also found that just switching off the normalization procedure in the ROOT 6.06/TMVA 4.2.1; gives very similar performance to the ROOT 5.28/TMVA 4.1.0.; Therefore, we need to switch off the normalization to keep the performance,; which is realized in an option implemented in this pull request.; We hope this will be accepted, to avoid us from patching this to every release of ROOT; we use for studies using LCFIPlus flavor tagging feature.; We set this option to non-default, so current users should not be affected by this change.; ![btag-100k-root-6 06 02-skipnorm](https://cloud.githubusercontent.com/assets/7939934/18453216/0f501eb0-78f3-11e6-892c-912f9b68553d.png); B-tag performance with the SkipNormalization option; ![btag-100k-root-6 06 02-noskipnorm](https://cloud.githubusercontent.com/assets/7939934/18453215/0f4e6b60-78f3-11e6-94bd-b4be9631937d.png); B-tag performance without the SkipNormalization option",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/244
https://github.com/root-project/root/pull/244:1375,Deployability,release,release,1375,"We are working on LCFIPlus, a flavor tagging software used for linear collider (ILC/CLIC) studies.; We use multi-class BDT with output of b-tag, c-tag, and uds-tag (3 outputs).; We also separate events into four categories according to number of reconstructed vertices; (0-vtx, 1-vtx, 1-vtx+1-partial-vtx, and 2-vtx) which are trained and evaluated independently.; In the previous release with TMVA 4.1.0 we can use the output of BDTs as variables common to ; all categories, because the average value of eg. b-tag output from each BDT; over full training samples reflects the fraction of b events in the training samples.; (eg. if we have 80% of b and 20% of c + uds, we have the avarage value of .8 for b-tag output.); We found this feature is not preserved in the latest releases (after TMVA 4.1.2); due to the normalization procedure introduced in that version.; In result this causes significant degradation of our flavor tagging performance,; which was reported from a user using latest ROOT/TMVA.; We also found that just switching off the normalization procedure in the ROOT 6.06/TMVA 4.2.1; gives very similar performance to the ROOT 5.28/TMVA 4.1.0.; Therefore, we need to switch off the normalization to keep the performance,; which is realized in an option implemented in this pull request.; We hope this will be accepted, to avoid us from patching this to every release of ROOT; we use for studies using LCFIPlus flavor tagging feature.; We set this option to non-default, so current users should not be affected by this change.; ![btag-100k-root-6 06 02-skipnorm](https://cloud.githubusercontent.com/assets/7939934/18453216/0f501eb0-78f3-11e6-892c-912f9b68553d.png); B-tag performance with the SkipNormalization option; ![btag-100k-root-6 06 02-noskipnorm](https://cloud.githubusercontent.com/assets/7939934/18453215/0f4e6b60-78f3-11e6-94bd-b4be9631937d.png); B-tag performance without the SkipNormalization option",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/244
https://github.com/root-project/root/pull/244:438,Modifiability,variab,variables,438,"We are working on LCFIPlus, a flavor tagging software used for linear collider (ILC/CLIC) studies.; We use multi-class BDT with output of b-tag, c-tag, and uds-tag (3 outputs).; We also separate events into four categories according to number of reconstructed vertices; (0-vtx, 1-vtx, 1-vtx+1-partial-vtx, and 2-vtx) which are trained and evaluated independently.; In the previous release with TMVA 4.1.0 we can use the output of BDTs as variables common to ; all categories, because the average value of eg. b-tag output from each BDT; over full training samples reflects the fraction of b events in the training samples.; (eg. if we have 80% of b and 20% of c + uds, we have the avarage value of .8 for b-tag output.); We found this feature is not preserved in the latest releases (after TMVA 4.1.2); due to the normalization procedure introduced in that version.; In result this causes significant degradation of our flavor tagging performance,; which was reported from a user using latest ROOT/TMVA.; We also found that just switching off the normalization procedure in the ROOT 6.06/TMVA 4.2.1; gives very similar performance to the ROOT 5.28/TMVA 4.1.0.; Therefore, we need to switch off the normalization to keep the performance,; which is realized in an option implemented in this pull request.; We hope this will be accepted, to avoid us from patching this to every release of ROOT; we use for studies using LCFIPlus flavor tagging feature.; We set this option to non-default, so current users should not be affected by this change.; ![btag-100k-root-6 06 02-skipnorm](https://cloud.githubusercontent.com/assets/7939934/18453216/0f501eb0-78f3-11e6-892c-912f9b68553d.png); B-tag performance with the SkipNormalization option; ![btag-100k-root-6 06 02-noskipnorm](https://cloud.githubusercontent.com/assets/7939934/18453215/0f4e6b60-78f3-11e6-94bd-b4be9631937d.png); B-tag performance without the SkipNormalization option",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/244
https://github.com/root-project/root/pull/244:935,Performance,perform,performance,935,"We are working on LCFIPlus, a flavor tagging software used for linear collider (ILC/CLIC) studies.; We use multi-class BDT with output of b-tag, c-tag, and uds-tag (3 outputs).; We also separate events into four categories according to number of reconstructed vertices; (0-vtx, 1-vtx, 1-vtx+1-partial-vtx, and 2-vtx) which are trained and evaluated independently.; In the previous release with TMVA 4.1.0 we can use the output of BDTs as variables common to ; all categories, because the average value of eg. b-tag output from each BDT; over full training samples reflects the fraction of b events in the training samples.; (eg. if we have 80% of b and 20% of c + uds, we have the avarage value of .8 for b-tag output.); We found this feature is not preserved in the latest releases (after TMVA 4.1.2); due to the normalization procedure introduced in that version.; In result this causes significant degradation of our flavor tagging performance,; which was reported from a user using latest ROOT/TMVA.; We also found that just switching off the normalization procedure in the ROOT 6.06/TMVA 4.2.1; gives very similar performance to the ROOT 5.28/TMVA 4.1.0.; Therefore, we need to switch off the normalization to keep the performance,; which is realized in an option implemented in this pull request.; We hope this will be accepted, to avoid us from patching this to every release of ROOT; we use for studies using LCFIPlus flavor tagging feature.; We set this option to non-default, so current users should not be affected by this change.; ![btag-100k-root-6 06 02-skipnorm](https://cloud.githubusercontent.com/assets/7939934/18453216/0f501eb0-78f3-11e6-892c-912f9b68553d.png); B-tag performance with the SkipNormalization option; ![btag-100k-root-6 06 02-noskipnorm](https://cloud.githubusercontent.com/assets/7939934/18453215/0f4e6b60-78f3-11e6-94bd-b4be9631937d.png); B-tag performance without the SkipNormalization option",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/244
https://github.com/root-project/root/pull/244:1119,Performance,perform,performance,1119,"We are working on LCFIPlus, a flavor tagging software used for linear collider (ILC/CLIC) studies.; We use multi-class BDT with output of b-tag, c-tag, and uds-tag (3 outputs).; We also separate events into four categories according to number of reconstructed vertices; (0-vtx, 1-vtx, 1-vtx+1-partial-vtx, and 2-vtx) which are trained and evaluated independently.; In the previous release with TMVA 4.1.0 we can use the output of BDTs as variables common to ; all categories, because the average value of eg. b-tag output from each BDT; over full training samples reflects the fraction of b events in the training samples.; (eg. if we have 80% of b and 20% of c + uds, we have the avarage value of .8 for b-tag output.); We found this feature is not preserved in the latest releases (after TMVA 4.1.2); due to the normalization procedure introduced in that version.; In result this causes significant degradation of our flavor tagging performance,; which was reported from a user using latest ROOT/TMVA.; We also found that just switching off the normalization procedure in the ROOT 6.06/TMVA 4.2.1; gives very similar performance to the ROOT 5.28/TMVA 4.1.0.; Therefore, we need to switch off the normalization to keep the performance,; which is realized in an option implemented in this pull request.; We hope this will be accepted, to avoid us from patching this to every release of ROOT; we use for studies using LCFIPlus flavor tagging feature.; We set this option to non-default, so current users should not be affected by this change.; ![btag-100k-root-6 06 02-skipnorm](https://cloud.githubusercontent.com/assets/7939934/18453216/0f501eb0-78f3-11e6-892c-912f9b68553d.png); B-tag performance with the SkipNormalization option; ![btag-100k-root-6 06 02-noskipnorm](https://cloud.githubusercontent.com/assets/7939934/18453215/0f4e6b60-78f3-11e6-94bd-b4be9631937d.png); B-tag performance without the SkipNormalization option",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/244
https://github.com/root-project/root/pull/244:1224,Performance,perform,performance,1224,"We are working on LCFIPlus, a flavor tagging software used for linear collider (ILC/CLIC) studies.; We use multi-class BDT with output of b-tag, c-tag, and uds-tag (3 outputs).; We also separate events into four categories according to number of reconstructed vertices; (0-vtx, 1-vtx, 1-vtx+1-partial-vtx, and 2-vtx) which are trained and evaluated independently.; In the previous release with TMVA 4.1.0 we can use the output of BDTs as variables common to ; all categories, because the average value of eg. b-tag output from each BDT; over full training samples reflects the fraction of b events in the training samples.; (eg. if we have 80% of b and 20% of c + uds, we have the avarage value of .8 for b-tag output.); We found this feature is not preserved in the latest releases (after TMVA 4.1.2); due to the normalization procedure introduced in that version.; In result this causes significant degradation of our flavor tagging performance,; which was reported from a user using latest ROOT/TMVA.; We also found that just switching off the normalization procedure in the ROOT 6.06/TMVA 4.2.1; gives very similar performance to the ROOT 5.28/TMVA 4.1.0.; Therefore, we need to switch off the normalization to keep the performance,; which is realized in an option implemented in this pull request.; We hope this will be accepted, to avoid us from patching this to every release of ROOT; we use for studies using LCFIPlus flavor tagging feature.; We set this option to non-default, so current users should not be affected by this change.; ![btag-100k-root-6 06 02-skipnorm](https://cloud.githubusercontent.com/assets/7939934/18453216/0f501eb0-78f3-11e6-892c-912f9b68553d.png); B-tag performance with the SkipNormalization option; ![btag-100k-root-6 06 02-noskipnorm](https://cloud.githubusercontent.com/assets/7939934/18453215/0f4e6b60-78f3-11e6-94bd-b4be9631937d.png); B-tag performance without the SkipNormalization option",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/244
https://github.com/root-project/root/pull/244:1687,Performance,perform,performance,1687,"We are working on LCFIPlus, a flavor tagging software used for linear collider (ILC/CLIC) studies.; We use multi-class BDT with output of b-tag, c-tag, and uds-tag (3 outputs).; We also separate events into four categories according to number of reconstructed vertices; (0-vtx, 1-vtx, 1-vtx+1-partial-vtx, and 2-vtx) which are trained and evaluated independently.; In the previous release with TMVA 4.1.0 we can use the output of BDTs as variables common to ; all categories, because the average value of eg. b-tag output from each BDT; over full training samples reflects the fraction of b events in the training samples.; (eg. if we have 80% of b and 20% of c + uds, we have the avarage value of .8 for b-tag output.); We found this feature is not preserved in the latest releases (after TMVA 4.1.2); due to the normalization procedure introduced in that version.; In result this causes significant degradation of our flavor tagging performance,; which was reported from a user using latest ROOT/TMVA.; We also found that just switching off the normalization procedure in the ROOT 6.06/TMVA 4.2.1; gives very similar performance to the ROOT 5.28/TMVA 4.1.0.; Therefore, we need to switch off the normalization to keep the performance,; which is realized in an option implemented in this pull request.; We hope this will be accepted, to avoid us from patching this to every release of ROOT; we use for studies using LCFIPlus flavor tagging feature.; We set this option to non-default, so current users should not be affected by this change.; ![btag-100k-root-6 06 02-skipnorm](https://cloud.githubusercontent.com/assets/7939934/18453216/0f501eb0-78f3-11e6-892c-912f9b68553d.png); B-tag performance with the SkipNormalization option; ![btag-100k-root-6 06 02-noskipnorm](https://cloud.githubusercontent.com/assets/7939934/18453215/0f4e6b60-78f3-11e6-94bd-b4be9631937d.png); B-tag performance without the SkipNormalization option",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/244
https://github.com/root-project/root/pull/244:1880,Performance,perform,performance,1880,"We are working on LCFIPlus, a flavor tagging software used for linear collider (ILC/CLIC) studies.; We use multi-class BDT with output of b-tag, c-tag, and uds-tag (3 outputs).; We also separate events into four categories according to number of reconstructed vertices; (0-vtx, 1-vtx, 1-vtx+1-partial-vtx, and 2-vtx) which are trained and evaluated independently.; In the previous release with TMVA 4.1.0 we can use the output of BDTs as variables common to ; all categories, because the average value of eg. b-tag output from each BDT; over full training samples reflects the fraction of b events in the training samples.; (eg. if we have 80% of b and 20% of c + uds, we have the avarage value of .8 for b-tag output.); We found this feature is not preserved in the latest releases (after TMVA 4.1.2); due to the normalization procedure introduced in that version.; In result this causes significant degradation of our flavor tagging performance,; which was reported from a user using latest ROOT/TMVA.; We also found that just switching off the normalization procedure in the ROOT 6.06/TMVA 4.2.1; gives very similar performance to the ROOT 5.28/TMVA 4.1.0.; Therefore, we need to switch off the normalization to keep the performance,; which is realized in an option implemented in this pull request.; We hope this will be accepted, to avoid us from patching this to every release of ROOT; we use for studies using LCFIPlus flavor tagging feature.; We set this option to non-default, so current users should not be affected by this change.; ![btag-100k-root-6 06 02-skipnorm](https://cloud.githubusercontent.com/assets/7939934/18453216/0f501eb0-78f3-11e6-892c-912f9b68553d.png); B-tag performance with the SkipNormalization option; ![btag-100k-root-6 06 02-noskipnorm](https://cloud.githubusercontent.com/assets/7939934/18453215/0f4e6b60-78f3-11e6-94bd-b4be9631937d.png); B-tag performance without the SkipNormalization option",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/244
https://github.com/root-project/root/pull/244:1338,Safety,avoid,avoid,1338,"We are working on LCFIPlus, a flavor tagging software used for linear collider (ILC/CLIC) studies.; We use multi-class BDT with output of b-tag, c-tag, and uds-tag (3 outputs).; We also separate events into four categories according to number of reconstructed vertices; (0-vtx, 1-vtx, 1-vtx+1-partial-vtx, and 2-vtx) which are trained and evaluated independently.; In the previous release with TMVA 4.1.0 we can use the output of BDTs as variables common to ; all categories, because the average value of eg. b-tag output from each BDT; over full training samples reflects the fraction of b events in the training samples.; (eg. if we have 80% of b and 20% of c + uds, we have the avarage value of .8 for b-tag output.); We found this feature is not preserved in the latest releases (after TMVA 4.1.2); due to the normalization procedure introduced in that version.; In result this causes significant degradation of our flavor tagging performance,; which was reported from a user using latest ROOT/TMVA.; We also found that just switching off the normalization procedure in the ROOT 6.06/TMVA 4.2.1; gives very similar performance to the ROOT 5.28/TMVA 4.1.0.; Therefore, we need to switch off the normalization to keep the performance,; which is realized in an option implemented in this pull request.; We hope this will be accepted, to avoid us from patching this to every release of ROOT; we use for studies using LCFIPlus flavor tagging feature.; We set this option to non-default, so current users should not be affected by this change.; ![btag-100k-root-6 06 02-skipnorm](https://cloud.githubusercontent.com/assets/7939934/18453216/0f501eb0-78f3-11e6-892c-912f9b68553d.png); B-tag performance with the SkipNormalization option; ![btag-100k-root-6 06 02-noskipnorm](https://cloud.githubusercontent.com/assets/7939934/18453215/0f4e6b60-78f3-11e6-94bd-b4be9631937d.png); B-tag performance without the SkipNormalization option",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/244
https://github.com/root-project/root/pull/245:54,Security,validat,validation,54,Classes with the basic functionality for k-fold cross-validation and hyper parameter optimisation have been added. Also there were some changes made to the dataloader to allow for the splitting of the input dataset into k-folds.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/245
https://github.com/root-project/root/pull/246:17,Modifiability,refactor,refactored,17,"When testing the refactored signal handler, I noticed that a few obscure (but not impossible!) Unix signals cause ROOT to exit without reseting the TTY state back to its original state. This PR simply adds a few extra signals to `TerminalConfigUnix` and bumps the signal count as appropriate.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/246
https://github.com/root-project/root/pull/246:5,Testability,test,testing,5,"When testing the refactored signal handler, I noticed that a few obscure (but not impossible!) Unix signals cause ROOT to exit without reseting the TTY state back to its original state. This PR simply adds a few extra signals to `TerminalConfigUnix` and bumps the signal count as appropriate.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/246
https://github.com/root-project/root/pull/246:194,Usability,simpl,simply,194,"When testing the refactored signal handler, I noticed that a few obscure (but not impossible!) Unix signals cause ROOT to exit without reseting the TTY state back to its original state. This PR simply adds a few extra signals to `TerminalConfigUnix` and bumps the signal count as appropriate.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/246
https://github.com/root-project/root/pull/248:59,Availability,redundant,redundant,59,"I think `if (demangledEnumName)` was meant here, but it is redundant, because behaviour of `free`ing a null pointer is defined and it is no-op.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/248
https://github.com/root-project/root/pull/248:59,Safety,redund,redundant,59,"I think `if (demangledEnumName)` was meant here, but it is redundant, because behaviour of `free`ing a null pointer is defined and it is no-op.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/248
https://github.com/root-project/root/pull/249:5,Safety,Safe,SafeDelete,5,"See [SafeDelete definition](https://github.com/root-mirror/root/blob/edfa4cc5d8c02c626dbc3f0e9283f8fd9b28698b/core/base/inc/RConfig.h#L465). It seems that new static analyzer exhumes lots of ancient legacy. Do I (we) need to give attention to such cases?. And it seems that there is no ""Issues"" tab in this repository. I have got some suspicious places and I'm not sure how to fix them.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/249
https://github.com/root-project/root/pull/255:27,Security,validat,validation,27,Fix typo in the tmva cross validation evaluation code,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/255
https://github.com/root-project/root/pull/262:0,Energy Efficiency,Reduce,Reduce,0,Reduce the amount of memory which is allocated by the minimizer in the standard DNN algorithm.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/262
https://github.com/root-project/root/pull/262:37,Energy Efficiency,allocate,allocated,37,Reduce the amount of memory which is allocated by the minimizer in the standard DNN algorithm.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/262
https://github.com/root-project/root/pull/267:5,Availability,error,error,5,`int error = fSocket->Send(fMessage) <= 0` is evaluated as ; `int error = (fSocket->Send(fMessage) <= 0)` and not as; `(int error = fSocket->Send(fMessage)) <= 0`,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/267
https://github.com/root-project/root/pull/267:66,Availability,error,error,66,`int error = fSocket->Send(fMessage) <= 0` is evaluated as ; `int error = (fSocket->Send(fMessage) <= 0)` and not as; `(int error = fSocket->Send(fMessage)) <= 0`,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/267
https://github.com/root-project/root/pull/267:124,Availability,error,error,124,`int error = fSocket->Send(fMessage) <= 0` is evaluated as ; `int error = (fSocket->Send(fMessage) <= 0)` and not as; `(int error = fSocket->Send(fMessage)) <= 0`,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/267
https://github.com/root-project/root/pull/268:70,Availability,error,errors,70,copy and pasting the tgraph example from doxygen i ran into two minor errors.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/268
https://github.com/root-project/root/pull/270:28,Availability,error,errors,28,In order to avoid packaging errors from rpmlint:; root.x86_64: E: incorrect-fsf-address /usr/share/emacs/site-lisp/root/root-help.el,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/270
https://github.com/root-project/root/pull/270:12,Safety,avoid,avoid,12,In order to avoid packaging errors from rpmlint:; root.x86_64: E: incorrect-fsf-address /usr/share/emacs/site-lisp/root/root-help.el,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/270
https://github.com/root-project/root/pull/272:13,Integrability,message,message,13,"Print status message during cmake if PyMVA is not build and python is activated but numpy is not found. Otherwise, a missing numpy drops PyMVA silently (and confuses the user).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/272
https://github.com/root-project/root/pull/273:36,Testability,Test,TestAllMethods,36,"Add bold header to TrainAllmethods, TestAllMethods and EvaluateAllMethods",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/273
https://github.com/root-project/root/pull/277:409,Security,access,access,409,"This is based on @dpiparo 's work to parallelize `GetEntry`. The basic idea is, when we are flushing all active branches, we do each branch in parallel. We have to maintain mutual exclusion when interacting with the `TTree` or `TFile`, but we can parallelize the compression of the baskets (which is a significant amount of CPU time). Note the least satisfactory part of this work is having to use a mutex to access the byte-counters in `TTree`; this is because these fields are serialized and `std::atomic<>` is not serializable. Any hints as to how to get around this?. Setting `MainEvent.cxx` in the `test` sub-directory to use this (with LZMA as the compression algorithm), I get:. ```; RealTime=76.340815 seconds, CpuTime=131.770000 seconds; ```. @pcanal @Dr15Jones - this spun off from our discussion about CMSSW efficiency. It's really easy to parallelize `FlushBaskets` using a `tbb::task_group` that I later wait for. However, continuation-style programming is difficult here because `FlushBaskets` is called from deep callstacks. Further, there's a lot of state in the basket itself we'd need to unravel. Looking at stack traces for the sample `Event` program, the next most advantageous place to parallelize compression is here:. ```; #11 0x00007f00743e80fe in R__zipMultipleAlgorithm ; #12 0x00007f00729aec25 in TBasket::WriteBuffer ; #13 0x00007f00729b53f3 in TBranch::WriteBasket ; #14 0x00007f00729b5c95 in TBranch::Fill ; #15 0x00007f00729cb630 in TBranchElement::Fill; #16 0x00007f00729cb418 in TBranchElement::Fill ; #17 0x00007f00729cb418 in TBranchElement::Fill ; #18 0x00007f0072a063f3 in TTree::Fill; ```. The idea would be to make `WriteBuffer` kick off a separate task, but block `TBranch::Fill` (and a handful of other functions, such as anything that can change the branch's `TFile`) from being called until the `WriteBuffer` task was completed. Harder than this approach, but not impossible.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/277
https://github.com/root-project/root/pull/277:604,Testability,test,test,604,"This is based on @dpiparo 's work to parallelize `GetEntry`. The basic idea is, when we are flushing all active branches, we do each branch in parallel. We have to maintain mutual exclusion when interacting with the `TTree` or `TFile`, but we can parallelize the compression of the baskets (which is a significant amount of CPU time). Note the least satisfactory part of this work is having to use a mutex to access the byte-counters in `TTree`; this is because these fields are serialized and `std::atomic<>` is not serializable. Any hints as to how to get around this?. Setting `MainEvent.cxx` in the `test` sub-directory to use this (with LZMA as the compression algorithm), I get:. ```; RealTime=76.340815 seconds, CpuTime=131.770000 seconds; ```. @pcanal @Dr15Jones - this spun off from our discussion about CMSSW efficiency. It's really easy to parallelize `FlushBaskets` using a `tbb::task_group` that I later wait for. However, continuation-style programming is difficult here because `FlushBaskets` is called from deep callstacks. Further, there's a lot of state in the basket itself we'd need to unravel. Looking at stack traces for the sample `Event` program, the next most advantageous place to parallelize compression is here:. ```; #11 0x00007f00743e80fe in R__zipMultipleAlgorithm ; #12 0x00007f00729aec25 in TBasket::WriteBuffer ; #13 0x00007f00729b53f3 in TBranch::WriteBasket ; #14 0x00007f00729b5c95 in TBranch::Fill ; #15 0x00007f00729cb630 in TBranchElement::Fill; #16 0x00007f00729cb418 in TBranchElement::Fill ; #17 0x00007f00729cb418 in TBranchElement::Fill ; #18 0x00007f0072a063f3 in TTree::Fill; ```. The idea would be to make `WriteBuffer` kick off a separate task, but block `TBranch::Fill` (and a handful of other functions, such as anything that can change the branch's `TFile`) from being called until the `WriteBuffer` task was completed. Harder than this approach, but not impossible.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/277
https://github.com/root-project/root/pull/278:130,Availability,error,error,130,Provide helper function `PyRunString` in class `PyMethodBase` to call python code from string in local namespace with appropriate error handling,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/278
https://github.com/root-project/root/pull/279:25,Availability,error,error,25,"Fixed one missing header error, limited parallel reduction to floats and doubles ¯_(ツ)_/¯",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/279
https://github.com/root-project/root/pull/280:56,Testability,test,tests,56,Add PyMVA method PyKeras and enable PyMVA specific unit-tests,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/280
https://github.com/root-project/root/pull/281:58,Availability,error,error-handling,58,"Changes:; - Clean-up coding style and add comments; - Add error-handling for the cases; - No method booked before calling `Evaluate` (`methodName` is empty string, prevents segfault which is hard to interpret for users); - No `Evaluate` run before calling `GetResults` (map size of ROCs is zero). @lmoneta @omazapa Only merge if nobody is currently working on this code! The coding style fixes will make merging horrible ;)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/281
https://github.com/root-project/root/pull/282:159,Performance,perform,performance,159,- Added multi-class support for CUDA and CPU backend; - Added multi-class support to MethodDNN; - Switched floating point types to single precision for better performance; - Disabled log output in interactive mode; - Removed regularization contribution in loss computation,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/282
https://github.com/root-project/root/pull/282:183,Testability,log,log,183,- Added multi-class support for CUDA and CPU backend; - Added multi-class support to MethodDNN; - Switched floating point types to single precision for better performance; - Disabled log output in interactive mode; - Removed regularization contribution in loss computation,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/282
https://github.com/root-project/root/pull/283:88,Integrability,depend,dependent,88,- Set minimum CUDA version to 8.0 (doesn't build otherwise); - Fix include path of CUDA dependent library `dnn_cuda` (previously used path `ROOT_INCLUDE_DIRS` is not in local scope),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/283
https://github.com/root-project/root/pull/286:111,Modifiability,Variab,VariableImportance,111,Allow the training to be done multiple times for the BDT by setting a flag to false.; Clear the methods map in VariableImportance to allow for the next training to be made.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/286
https://github.com/root-project/root/pull/286:86,Usability,Clear,Clear,86,Allow the training to be done multiple times for the BDT by setting a flag to false.; Clear the methods map in VariableImportance to allow for the next training to be made.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/286
https://github.com/root-project/root/pull/290:209,Deployability,patch,patch,209,"While the `TTreeReaderValue` is indeed not copyable for good reason, I don't see why it shouldn't be moveable (deleting the copy constructor appears to implicitly delete the move constructor). With this small patch, the following works:. ```; TFile *tf = TFile::Open(""somefile.root"");; TTreeReader reader(""T"", tf);; auto foo = std::make_tuple( TTreeReaderValue<int>(reader, ""branchname"") );; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/290
https://github.com/root-project/root/pull/291:120,Energy Efficiency,Reduce,Reduce,120,"- TThreadExecutor's task pool initializer is now a unique_ptr.; - Removed useless Reduction resolver.; - Change the way Reduce was inherited + overloaded. It was working due; to a GCC bug. See https://gcc.gnu.org/bugzilla/show_bug.cgi?id=78308; (thanks, Axel); - Chunked Map is now protected.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/291
https://github.com/root-project/root/pull/291:131,Modifiability,inherit,inherited,131,"- TThreadExecutor's task pool initializer is now a unique_ptr.; - Removed useless Reduction resolver.; - Change the way Reduce was inherited + overloaded. It was working due; to a GCC bug. See https://gcc.gnu.org/bugzilla/show_bug.cgi?id=78308; (thanks, Axel); - Chunked Map is now protected.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/291
https://github.com/root-project/root/pull/299:45,Deployability,INSTALL,INSTALL,45,"As requested by Vassil, I replaced the cmake INSTALL directive with the ROOT_INSTALL_HEADERS; directive and added EXCLUDE options for the BLAS and CUDA dependent headers.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/299
https://github.com/root-project/root/pull/299:152,Integrability,depend,dependent,152,"As requested by Vassil, I replaced the cmake INSTALL directive with the ROOT_INSTALL_HEADERS; directive and added EXCLUDE options for the BLAS and CUDA dependent headers.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/299
https://github.com/root-project/root/pull/303:268,Availability,error,error,268,"This has been changed:. - Refactor PyRandomForest (coding style, smoother python integration, easier multi-class integration); - Enable multi-class classification; - Create unit-test usable with `ctest -V -R PyMVA-RandomForest` for binary classification; - Add return error codes to `PyMethodBase::Unserialize()` function; - Mark ` tmva/pymva/test/Classification.C` as deprecated (lacks dataloader, I'll remove it if PyGTB is ported as well to ctest unit-test)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/303
https://github.com/root-project/root/pull/303:81,Deployability,integrat,integration,81,"This has been changed:. - Refactor PyRandomForest (coding style, smoother python integration, easier multi-class integration); - Enable multi-class classification; - Create unit-test usable with `ctest -V -R PyMVA-RandomForest` for binary classification; - Add return error codes to `PyMethodBase::Unserialize()` function; - Mark ` tmva/pymva/test/Classification.C` as deprecated (lacks dataloader, I'll remove it if PyGTB is ported as well to ctest unit-test)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/303
https://github.com/root-project/root/pull/303:113,Deployability,integrat,integration,113,"This has been changed:. - Refactor PyRandomForest (coding style, smoother python integration, easier multi-class integration); - Enable multi-class classification; - Create unit-test usable with `ctest -V -R PyMVA-RandomForest` for binary classification; - Add return error codes to `PyMethodBase::Unserialize()` function; - Mark ` tmva/pymva/test/Classification.C` as deprecated (lacks dataloader, I'll remove it if PyGTB is ported as well to ctest unit-test)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/303
https://github.com/root-project/root/pull/303:81,Integrability,integrat,integration,81,"This has been changed:. - Refactor PyRandomForest (coding style, smoother python integration, easier multi-class integration); - Enable multi-class classification; - Create unit-test usable with `ctest -V -R PyMVA-RandomForest` for binary classification; - Add return error codes to `PyMethodBase::Unserialize()` function; - Mark ` tmva/pymva/test/Classification.C` as deprecated (lacks dataloader, I'll remove it if PyGTB is ported as well to ctest unit-test)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/303
https://github.com/root-project/root/pull/303:113,Integrability,integrat,integration,113,"This has been changed:. - Refactor PyRandomForest (coding style, smoother python integration, easier multi-class integration); - Enable multi-class classification; - Create unit-test usable with `ctest -V -R PyMVA-RandomForest` for binary classification; - Add return error codes to `PyMethodBase::Unserialize()` function; - Mark ` tmva/pymva/test/Classification.C` as deprecated (lacks dataloader, I'll remove it if PyGTB is ported as well to ctest unit-test)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/303
https://github.com/root-project/root/pull/303:26,Modifiability,Refactor,Refactor,26,"This has been changed:. - Refactor PyRandomForest (coding style, smoother python integration, easier multi-class integration); - Enable multi-class classification; - Create unit-test usable with `ctest -V -R PyMVA-RandomForest` for binary classification; - Add return error codes to `PyMethodBase::Unserialize()` function; - Mark ` tmva/pymva/test/Classification.C` as deprecated (lacks dataloader, I'll remove it if PyGTB is ported as well to ctest unit-test)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/303
https://github.com/root-project/root/pull/303:178,Testability,test,test,178,"This has been changed:. - Refactor PyRandomForest (coding style, smoother python integration, easier multi-class integration); - Enable multi-class classification; - Create unit-test usable with `ctest -V -R PyMVA-RandomForest` for binary classification; - Add return error codes to `PyMethodBase::Unserialize()` function; - Mark ` tmva/pymva/test/Classification.C` as deprecated (lacks dataloader, I'll remove it if PyGTB is ported as well to ctest unit-test)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/303
https://github.com/root-project/root/pull/303:343,Testability,test,test,343,"This has been changed:. - Refactor PyRandomForest (coding style, smoother python integration, easier multi-class integration); - Enable multi-class classification; - Create unit-test usable with `ctest -V -R PyMVA-RandomForest` for binary classification; - Add return error codes to `PyMethodBase::Unserialize()` function; - Mark ` tmva/pymva/test/Classification.C` as deprecated (lacks dataloader, I'll remove it if PyGTB is ported as well to ctest unit-test)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/303
https://github.com/root-project/root/pull/303:455,Testability,test,test,455,"This has been changed:. - Refactor PyRandomForest (coding style, smoother python integration, easier multi-class integration); - Enable multi-class classification; - Create unit-test usable with `ctest -V -R PyMVA-RandomForest` for binary classification; - Add return error codes to `PyMethodBase::Unserialize()` function; - Mark ` tmva/pymva/test/Classification.C` as deprecated (lacks dataloader, I'll remove it if PyGTB is ported as well to ctest unit-test)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/303
https://github.com/root-project/root/pull/303:183,Usability,usab,usable,183,"This has been changed:. - Refactor PyRandomForest (coding style, smoother python integration, easier multi-class integration); - Enable multi-class classification; - Create unit-test usable with `ctest -V -R PyMVA-RandomForest` for binary classification; - Add return error codes to `PyMethodBase::Unserialize()` function; - Mark ` tmva/pymva/test/Classification.C` as deprecated (lacks dataloader, I'll remove it if PyGTB is ported as well to ctest unit-test)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/303
https://github.com/root-project/root/pull/304:109,Availability,error,error,109,"As per Jira ticket ROOT-8483:. Creating a TTreeReaderValue after having looped over a TTreeReader prompts an error message at runtime. This error mentions calling `TTreeReader::Reset` as a solution, but said method does not exist.; Assuming `TTreeReader::Restart` was meant, the patch is trivial.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/304
https://github.com/root-project/root/pull/304:140,Availability,error,error,140,"As per Jira ticket ROOT-8483:. Creating a TTreeReaderValue after having looped over a TTreeReader prompts an error message at runtime. This error mentions calling `TTreeReader::Reset` as a solution, but said method does not exist.; Assuming `TTreeReader::Restart` was meant, the patch is trivial.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/304
https://github.com/root-project/root/pull/304:279,Deployability,patch,patch,279,"As per Jira ticket ROOT-8483:. Creating a TTreeReaderValue after having looped over a TTreeReader prompts an error message at runtime. This error mentions calling `TTreeReader::Reset` as a solution, but said method does not exist.; Assuming `TTreeReader::Restart` was meant, the patch is trivial.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/304
https://github.com/root-project/root/pull/304:115,Integrability,message,message,115,"As per Jira ticket ROOT-8483:. Creating a TTreeReaderValue after having looped over a TTreeReader prompts an error message at runtime. This error mentions calling `TTreeReader::Reset` as a solution, but said method does not exist.; Assuming `TTreeReader::Restart` was meant, the patch is trivial.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/304
https://github.com/root-project/root/pull/308:40,Integrability,interface,interface,40,"The current implementation of the PyMVA interface in `PyMethodBase` has following problem:. We are using currently a global local python namespace for **all** instances of **all** PyMVA method. So you can easily interfere with an other method running in the same factory. Most likely, this happens if you book two instances of the same method in one factory. We can solve this by introducing **private** local python namespaces. In this version, we are sharing the global namespaces with all instances of a PyMVA method (and ofc the running python instance), but create a seperate local namespace for each instance. So you can do whatever you want in your method/instance and you don't interfere with others.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/308
https://github.com/root-project/root/pull/309:61,Testability,test,test,61,On some platforms there is a HZ macro defined that makes the test fail. This pull request undefines the HZ macro if it is defined allowing the test to succeed.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/309
https://github.com/root-project/root/pull/309:143,Testability,test,test,143,On some platforms there is a HZ macro defined that makes the test fail. This pull request undefines the HZ macro if it is defined allowing the test to succeed.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/309
https://github.com/root-project/root/pull/310:104,Availability,error,errors,104,When this tutorial is run as part of the documentation generation it fails with global name not defined errors. This results in this page being incomplete:; https://root.cern/doc/master/zdemo_8py.html. This pull reqest addresses this problem.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/310
https://github.com/root-project/root/pull/312:468,Availability,Error,Error,468,This is the log of the failed test:; ```; Test 38: TGraph2D 1 (TRI2 and P0).................................. OK; PDF output................................................ OK; GIF output................................................ OK; JPG output................................................ OK; PNG output................................................ OK; C file result...................................... 38 FAILED; Result = 1456040; Reference = 1463263; Error = 7223 (was 7000); ```,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/312
https://github.com/root-project/root/pull/312:12,Testability,log,log,12,This is the log of the failed test:; ```; Test 38: TGraph2D 1 (TRI2 and P0).................................. OK; PDF output................................................ OK; GIF output................................................ OK; JPG output................................................ OK; PNG output................................................ OK; C file result...................................... 38 FAILED; Result = 1456040; Reference = 1463263; Error = 7223 (was 7000); ```,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/312
https://github.com/root-project/root/pull/312:30,Testability,test,test,30,This is the log of the failed test:; ```; Test 38: TGraph2D 1 (TRI2 and P0).................................. OK; PDF output................................................ OK; GIF output................................................ OK; JPG output................................................ OK; PNG output................................................ OK; C file result...................................... 38 FAILED; Result = 1456040; Reference = 1463263; Error = 7223 (was 7000); ```,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/312
https://github.com/root-project/root/pull/312:42,Testability,Test,Test,42,This is the log of the failed test:; ```; Test 38: TGraph2D 1 (TRI2 and P0).................................. OK; PDF output................................................ OK; GIF output................................................ OK; JPG output................................................ OK; PNG output................................................ OK; C file result...................................... 38 FAILED; Result = 1456040; Reference = 1463263; Error = 7223 (was 7000); ```,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/312
https://github.com/root-project/root/pull/313:71,Integrability,depend,depending,71,There is no such thing as ROOT_unfold_FOUND. It is built conditionally depending on whether there is xml support or not. From hist/CMakeLists.txt:; ~~~; if(xml); add_subdirectory(unfold); endif(); ~~~; The veto for the tutorials should therefore also depend on the xml support.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/313
https://github.com/root-project/root/pull/313:251,Integrability,depend,depend,251,There is no such thing as ROOT_unfold_FOUND. It is built conditionally depending on whether there is xml support or not. From hist/CMakeLists.txt:; ~~~; if(xml); add_subdirectory(unfold); endif(); ~~~; The veto for the tutorials should therefore also depend on the xml support.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/313
https://github.com/root-project/root/pull/314:40,Integrability,depend,dependent,40,**NOTE:** This PR needs a rebase and is dependent on #303,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/314
https://github.com/root-project/root/pull/315:172,Integrability,depend,dependent,172,- Refactor AdaBoost; - Add multi-class support; - Add ranking feature; - Remove deprecated file `tmva/pymva/test/Classification.C`. **NOTE:** This PR needs a rebase and is dependent on #303,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/315
https://github.com/root-project/root/pull/315:2,Modifiability,Refactor,Refactor,2,- Refactor AdaBoost; - Add multi-class support; - Add ranking feature; - Remove deprecated file `tmva/pymva/test/Classification.C`. **NOTE:** This PR needs a rebase and is dependent on #303,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/315
https://github.com/root-project/root/pull/315:108,Testability,test,test,108,- Refactor AdaBoost; - Add multi-class support; - Add ranking feature; - Remove deprecated file `tmva/pymva/test/Classification.C`. **NOTE:** This PR needs a rebase and is dependent on #303,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/315
https://github.com/root-project/root/pull/319:111,Availability,error,error,111,"@pcanal @bbockelm . This pull request fix the bug here https://sft.its.cern.ch/jira/browse/ROOT-8468. The fist error is due to the dangling pointer. ""buffer"" never gets to be allocated in the function GetUnzipBuffer. The second error is deallocating the memory ""ptr"" point to. Therefore, fUnzipChunks[idxtounzip] becomes null pointer. It should work now. To test the parallel unzipping, simply random generate events and read them. /PATH/TO/TEST/eventexe 1000 6 99 1 1000 (generate 1000 events with zlib); /PATH/TO/TEST/eventexe 1000 6 99 20 1000 (unzip and read 1000 events in sequential manner); /PATH/TO/TEST/eventexe 1000 6 99 21 1000 (unzip and read 1000 events in parallel)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/319
https://github.com/root-project/root/pull/319:228,Availability,error,error,228,"@pcanal @bbockelm . This pull request fix the bug here https://sft.its.cern.ch/jira/browse/ROOT-8468. The fist error is due to the dangling pointer. ""buffer"" never gets to be allocated in the function GetUnzipBuffer. The second error is deallocating the memory ""ptr"" point to. Therefore, fUnzipChunks[idxtounzip] becomes null pointer. It should work now. To test the parallel unzipping, simply random generate events and read them. /PATH/TO/TEST/eventexe 1000 6 99 1 1000 (generate 1000 events with zlib); /PATH/TO/TEST/eventexe 1000 6 99 20 1000 (unzip and read 1000 events in sequential manner); /PATH/TO/TEST/eventexe 1000 6 99 21 1000 (unzip and read 1000 events in parallel)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/319
https://github.com/root-project/root/pull/319:175,Energy Efficiency,allocate,allocated,175,"@pcanal @bbockelm . This pull request fix the bug here https://sft.its.cern.ch/jira/browse/ROOT-8468. The fist error is due to the dangling pointer. ""buffer"" never gets to be allocated in the function GetUnzipBuffer. The second error is deallocating the memory ""ptr"" point to. Therefore, fUnzipChunks[idxtounzip] becomes null pointer. It should work now. To test the parallel unzipping, simply random generate events and read them. /PATH/TO/TEST/eventexe 1000 6 99 1 1000 (generate 1000 events with zlib); /PATH/TO/TEST/eventexe 1000 6 99 20 1000 (unzip and read 1000 events in sequential manner); /PATH/TO/TEST/eventexe 1000 6 99 21 1000 (unzip and read 1000 events in parallel)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/319
https://github.com/root-project/root/pull/319:358,Testability,test,test,358,"@pcanal @bbockelm . This pull request fix the bug here https://sft.its.cern.ch/jira/browse/ROOT-8468. The fist error is due to the dangling pointer. ""buffer"" never gets to be allocated in the function GetUnzipBuffer. The second error is deallocating the memory ""ptr"" point to. Therefore, fUnzipChunks[idxtounzip] becomes null pointer. It should work now. To test the parallel unzipping, simply random generate events and read them. /PATH/TO/TEST/eventexe 1000 6 99 1 1000 (generate 1000 events with zlib); /PATH/TO/TEST/eventexe 1000 6 99 20 1000 (unzip and read 1000 events in sequential manner); /PATH/TO/TEST/eventexe 1000 6 99 21 1000 (unzip and read 1000 events in parallel)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/319
https://github.com/root-project/root/pull/319:441,Testability,TEST,TEST,441,"@pcanal @bbockelm . This pull request fix the bug here https://sft.its.cern.ch/jira/browse/ROOT-8468. The fist error is due to the dangling pointer. ""buffer"" never gets to be allocated in the function GetUnzipBuffer. The second error is deallocating the memory ""ptr"" point to. Therefore, fUnzipChunks[idxtounzip] becomes null pointer. It should work now. To test the parallel unzipping, simply random generate events and read them. /PATH/TO/TEST/eventexe 1000 6 99 1 1000 (generate 1000 events with zlib); /PATH/TO/TEST/eventexe 1000 6 99 20 1000 (unzip and read 1000 events in sequential manner); /PATH/TO/TEST/eventexe 1000 6 99 21 1000 (unzip and read 1000 events in parallel)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/319
https://github.com/root-project/root/pull/319:515,Testability,TEST,TEST,515,"@pcanal @bbockelm . This pull request fix the bug here https://sft.its.cern.ch/jira/browse/ROOT-8468. The fist error is due to the dangling pointer. ""buffer"" never gets to be allocated in the function GetUnzipBuffer. The second error is deallocating the memory ""ptr"" point to. Therefore, fUnzipChunks[idxtounzip] becomes null pointer. It should work now. To test the parallel unzipping, simply random generate events and read them. /PATH/TO/TEST/eventexe 1000 6 99 1 1000 (generate 1000 events with zlib); /PATH/TO/TEST/eventexe 1000 6 99 20 1000 (unzip and read 1000 events in sequential manner); /PATH/TO/TEST/eventexe 1000 6 99 21 1000 (unzip and read 1000 events in parallel)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/319
https://github.com/root-project/root/pull/319:607,Testability,TEST,TEST,607,"@pcanal @bbockelm . This pull request fix the bug here https://sft.its.cern.ch/jira/browse/ROOT-8468. The fist error is due to the dangling pointer. ""buffer"" never gets to be allocated in the function GetUnzipBuffer. The second error is deallocating the memory ""ptr"" point to. Therefore, fUnzipChunks[idxtounzip] becomes null pointer. It should work now. To test the parallel unzipping, simply random generate events and read them. /PATH/TO/TEST/eventexe 1000 6 99 1 1000 (generate 1000 events with zlib); /PATH/TO/TEST/eventexe 1000 6 99 20 1000 (unzip and read 1000 events in sequential manner); /PATH/TO/TEST/eventexe 1000 6 99 21 1000 (unzip and read 1000 events in parallel)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/319
https://github.com/root-project/root/pull/319:387,Usability,simpl,simply,387,"@pcanal @bbockelm . This pull request fix the bug here https://sft.its.cern.ch/jira/browse/ROOT-8468. The fist error is due to the dangling pointer. ""buffer"" never gets to be allocated in the function GetUnzipBuffer. The second error is deallocating the memory ""ptr"" point to. Therefore, fUnzipChunks[idxtounzip] becomes null pointer. It should work now. To test the parallel unzipping, simply random generate events and read them. /PATH/TO/TEST/eventexe 1000 6 99 1 1000 (generate 1000 events with zlib); /PATH/TO/TEST/eventexe 1000 6 99 20 1000 (unzip and read 1000 events in sequential manner); /PATH/TO/TEST/eventexe 1000 6 99 21 1000 (unzip and read 1000 events in parallel)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/319
https://github.com/root-project/root/pull/321:339,Integrability,rout,routines,339,"Now, we create TBB tasks for compression whenever `TTree::Fill` is called and a basket must be compressed. In CMS, we saw significant speedup on KNL and high-core-count Xeons by doing this over the existing basic write IMT (likely because we have some branches that are flushed to disk much more frequently than targeted by the auto-flush routines).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/321
https://github.com/root-project/root/pull/322:50,Testability,test,tests,50,The documentation generation hangs and one of the tests in the test suite times out. This PR fixes that.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/322
https://github.com/root-project/root/pull/322:63,Testability,test,test,63,The documentation generation hangs and one of the tests in the test suite times out. This PR fixes that.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/322
https://github.com/root-project/root/pull/323:237,Deployability,patch,patch,237,"The builtin Vdt and Vc builds, when enabled, cause some targets to depend on libraries (`libvdt.so`, `libVc.a`) that are the output of the `ExternalProject` command. However, unless they are explicitly listed as outputs (as done in this patch), the build tool may not know how to generate them. Typically, this isn't a problem because the builtins are done sufficiently early in the build and it's nearly impossible to hit the Vc dependency before the library is installed. `make` is satisfied as long the library is on disk by time it hits the later rule, even if it has no clue how it got there. However, some build tools (such as `ninja`) explicitly check for missing libraries and refuse to attempt the build because no rule explicitly builds the missing library. As far as I can tell, the `BUILD_BYPRODUCTS` attribute was added in CMake 3.2; as ROOT already requires 3.4.3, this patch should not be a problem. @pcanal @karies",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/323
https://github.com/root-project/root/pull/323:463,Deployability,install,installed,463,"The builtin Vdt and Vc builds, when enabled, cause some targets to depend on libraries (`libvdt.so`, `libVc.a`) that are the output of the `ExternalProject` command. However, unless they are explicitly listed as outputs (as done in this patch), the build tool may not know how to generate them. Typically, this isn't a problem because the builtins are done sufficiently early in the build and it's nearly impossible to hit the Vc dependency before the library is installed. `make` is satisfied as long the library is on disk by time it hits the later rule, even if it has no clue how it got there. However, some build tools (such as `ninja`) explicitly check for missing libraries and refuse to attempt the build because no rule explicitly builds the missing library. As far as I can tell, the `BUILD_BYPRODUCTS` attribute was added in CMake 3.2; as ROOT already requires 3.4.3, this patch should not be a problem. @pcanal @karies",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/323
https://github.com/root-project/root/pull/323:884,Deployability,patch,patch,884,"The builtin Vdt and Vc builds, when enabled, cause some targets to depend on libraries (`libvdt.so`, `libVc.a`) that are the output of the `ExternalProject` command. However, unless they are explicitly listed as outputs (as done in this patch), the build tool may not know how to generate them. Typically, this isn't a problem because the builtins are done sufficiently early in the build and it's nearly impossible to hit the Vc dependency before the library is installed. `make` is satisfied as long the library is on disk by time it hits the later rule, even if it has no clue how it got there. However, some build tools (such as `ninja`) explicitly check for missing libraries and refuse to attempt the build because no rule explicitly builds the missing library. As far as I can tell, the `BUILD_BYPRODUCTS` attribute was added in CMake 3.2; as ROOT already requires 3.4.3, this patch should not be a problem. @pcanal @karies",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/323
https://github.com/root-project/root/pull/323:67,Integrability,depend,depend,67,"The builtin Vdt and Vc builds, when enabled, cause some targets to depend on libraries (`libvdt.so`, `libVc.a`) that are the output of the `ExternalProject` command. However, unless they are explicitly listed as outputs (as done in this patch), the build tool may not know how to generate them. Typically, this isn't a problem because the builtins are done sufficiently early in the build and it's nearly impossible to hit the Vc dependency before the library is installed. `make` is satisfied as long the library is on disk by time it hits the later rule, even if it has no clue how it got there. However, some build tools (such as `ninja`) explicitly check for missing libraries and refuse to attempt the build because no rule explicitly builds the missing library. As far as I can tell, the `BUILD_BYPRODUCTS` attribute was added in CMake 3.2; as ROOT already requires 3.4.3, this patch should not be a problem. @pcanal @karies",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/323
https://github.com/root-project/root/pull/323:430,Integrability,depend,dependency,430,"The builtin Vdt and Vc builds, when enabled, cause some targets to depend on libraries (`libvdt.so`, `libVc.a`) that are the output of the `ExternalProject` command. However, unless they are explicitly listed as outputs (as done in this patch), the build tool may not know how to generate them. Typically, this isn't a problem because the builtins are done sufficiently early in the build and it's nearly impossible to hit the Vc dependency before the library is installed. `make` is satisfied as long the library is on disk by time it hits the later rule, even if it has no clue how it got there. However, some build tools (such as `ninja`) explicitly check for missing libraries and refuse to attempt the build because no rule explicitly builds the missing library. As far as I can tell, the `BUILD_BYPRODUCTS` attribute was added in CMake 3.2; as ROOT already requires 3.4.3, this patch should not be a problem. @pcanal @karies",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/323
https://github.com/root-project/root/pull/325:420,Modifiability,inherit,inherits,420,"This PR adds 'add' functions to RooArgSet again, that were removed in 6.06/00. ### Problem. This pyROOT code. ```python; import ROOT; set1 = ROOT.RooArgSet(); set2 = ROOT.RooArgSet(); set1.add(set2); ```. worked until 6.05/02 (included) and raises an exception since 6.06/00:. ```shell; TypeError: bool RooArgSet::add(const RooAbsArg& var, bool silent = kFALSE) =>; could not convert argument 1; ```. ### Fix. RooArgSet inherits from RooAbsCollection, so it should be possible to add a RootArgSet instance to an other RootArgSet instance via `add()`. This used to work in versions prior to 6.06/00. From [`RooArgSet.h in 6.05/02`](https://github.com/root-mirror/root/blob/v6-05-02/roofit/roofitcore/inc/RooArgSet.h#L90):. ```cpp; class RooArgSet : public RooAbsCollection {; public:; ...; virtual Bool_t add(const RooAbsCollection& list, Bool_t silent=kFALSE) {...}; };; ```. This was changed in commit 283f080, where e.g. the above `add` function was replaced by. ```cpp; using RooAbsCollection::add;; ```. However, this only seems to work when the *used* function is implemented in the base class' header or re-implemented by the inheriting class' which both is not the case. Therefore, I added the functions again to the RooArgSet header.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/325
https://github.com/root-project/root/pull/325:1132,Modifiability,inherit,inheriting,1132,"This PR adds 'add' functions to RooArgSet again, that were removed in 6.06/00. ### Problem. This pyROOT code. ```python; import ROOT; set1 = ROOT.RooArgSet(); set2 = ROOT.RooArgSet(); set1.add(set2); ```. worked until 6.05/02 (included) and raises an exception since 6.06/00:. ```shell; TypeError: bool RooArgSet::add(const RooAbsArg& var, bool silent = kFALSE) =>; could not convert argument 1; ```. ### Fix. RooArgSet inherits from RooAbsCollection, so it should be possible to add a RootArgSet instance to an other RootArgSet instance via `add()`. This used to work in versions prior to 6.06/00. From [`RooArgSet.h in 6.05/02`](https://github.com/root-mirror/root/blob/v6-05-02/roofit/roofitcore/inc/RooArgSet.h#L90):. ```cpp; class RooArgSet : public RooAbsCollection {; public:; ...; virtual Bool_t add(const RooAbsCollection& list, Bool_t silent=kFALSE) {...}; };; ```. This was changed in commit 283f080, where e.g. the above `add` function was replaced by. ```cpp; using RooAbsCollection::add;; ```. However, this only seems to work when the *used* function is implemented in the base class' header or re-implemented by the inheriting class' which both is not the case. Therefore, I added the functions again to the RooArgSet header.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/325
https://github.com/root-project/root/pull/326:147,Deployability,patch,patch,147,"Both EnableEmplicitMT and TThreadExecutor implementations share the; same task scheduler and the number of threads it has been set to run on. This patch modifies TThreadExecutor so it:. * avoids the termination (from TThreadExecutor) of the scheduler; initialized by EnableEmplicitMT.; * warns the user if she/he tries to change an already-set number of; threads, as the scheduler will always take the value of its first; initialization.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/326
https://github.com/root-project/root/pull/326:79,Energy Efficiency,schedul,scheduler,79,"Both EnableEmplicitMT and TThreadExecutor implementations share the; same task scheduler and the number of threads it has been set to run on. This patch modifies TThreadExecutor so it:. * avoids the termination (from TThreadExecutor) of the scheduler; initialized by EnableEmplicitMT.; * warns the user if she/he tries to change an already-set number of; threads, as the scheduler will always take the value of its first; initialization.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/326
https://github.com/root-project/root/pull/326:241,Energy Efficiency,schedul,scheduler,241,"Both EnableEmplicitMT and TThreadExecutor implementations share the; same task scheduler and the number of threads it has been set to run on. This patch modifies TThreadExecutor so it:. * avoids the termination (from TThreadExecutor) of the scheduler; initialized by EnableEmplicitMT.; * warns the user if she/he tries to change an already-set number of; threads, as the scheduler will always take the value of its first; initialization.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/326
https://github.com/root-project/root/pull/326:371,Energy Efficiency,schedul,scheduler,371,"Both EnableEmplicitMT and TThreadExecutor implementations share the; same task scheduler and the number of threads it has been set to run on. This patch modifies TThreadExecutor so it:. * avoids the termination (from TThreadExecutor) of the scheduler; initialized by EnableEmplicitMT.; * warns the user if she/he tries to change an already-set number of; threads, as the scheduler will always take the value of its first; initialization.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/326
https://github.com/root-project/root/pull/326:188,Safety,avoid,avoids,188,"Both EnableEmplicitMT and TThreadExecutor implementations share the; same task scheduler and the number of threads it has been set to run on. This patch modifies TThreadExecutor so it:. * avoids the termination (from TThreadExecutor) of the scheduler; initialized by EnableEmplicitMT.; * warns the user if she/he tries to change an already-set number of; threads, as the scheduler will always take the value of its first; initialization.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/326
https://github.com/root-project/root/pull/327:346,Deployability,patch,patches,346,Following discussions in TMVA developers meetings. Callgrind reports large (factor 2ish) reduction of CPU cycles for BDT evaluation. TODO: careful review if mixed trees can actually occur!. Credits to F. Lemaitre for the suggestion to remove the dynamic_casts in this way (as opposed to the implementation I was working on). PS: filed PR against patches v6-08-00-patches to keep the diff readable for now.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/327
https://github.com/root-project/root/pull/327:363,Deployability,patch,patches,363,Following discussions in TMVA developers meetings. Callgrind reports large (factor 2ish) reduction of CPU cycles for BDT evaluation. TODO: careful review if mixed trees can actually occur!. Credits to F. Lemaitre for the suggestion to remove the dynamic_casts in this way (as opposed to the implementation I was working on). PS: filed PR against patches v6-08-00-patches to keep the diff readable for now.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/327
https://github.com/root-project/root/pull/328:5,Deployability,patch,patch,5,"Port patch by @bircoph to support giflib-5, as well as some minor build system updates. Since the bundled version of libAfterImage in ROOT got some updates of its own, an effort was made to; keep those changes intact. For more information, please refer to the bug report at https://bugs.gentoo.org/571654. Fixes [ROOT-7904](https://sft.its.cern.ch/jira/browse/ROOT-7904).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/328
https://github.com/root-project/root/pull/328:79,Deployability,update,updates,79,"Port patch by @bircoph to support giflib-5, as well as some minor build system updates. Since the bundled version of libAfterImage in ROOT got some updates of its own, an effort was made to; keep those changes intact. For more information, please refer to the bug report at https://bugs.gentoo.org/571654. Fixes [ROOT-7904](https://sft.its.cern.ch/jira/browse/ROOT-7904).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/328
https://github.com/root-project/root/pull/328:148,Deployability,update,updates,148,"Port patch by @bircoph to support giflib-5, as well as some minor build system updates. Since the bundled version of libAfterImage in ROOT got some updates of its own, an effort was made to; keep those changes intact. For more information, please refer to the bug report at https://bugs.gentoo.org/571654. Fixes [ROOT-7904](https://sft.its.cern.ch/jira/browse/ROOT-7904).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/328
https://github.com/root-project/root/pull/332:112,Deployability,patch,patch,112,Currently we write into the overlay file all libc++ header paths (e.g. /usr/include/libc++:/another/path). This patch selects the first path from this list to produce a valid overlay.yaml when configuring.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/332
https://github.com/root-project/root/pull/332:193,Modifiability,config,configuring,193,Currently we write into the overlay file all libc++ header paths (e.g. /usr/include/libc++:/another/path). This patch selects the first path from this list to produce a valid overlay.yaml when configuring.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/332
https://github.com/root-project/root/pull/333:43,Deployability,integrat,integrate,43,"Fix a few minor things and pave the way to integrate cutflow reports in TDataFrame. * TDFAction ctor can take a shared_ptr instead of a weak_ptr: TDFAction; can safely assume that the previous node in the chain still exists when it is; being constructed; * fPrevData is now a reference instead of a raw pointer in all classes:; a reference better indicates that we always expect fPrevData to be a valid; node of the chain. In fact, the only case when this condition might not be; met is when the TDataFrameImpl object goes out-of-scope before other nodes; of the chain; we detect this case and throw before trying to access; invalid fPrevData pointers/references.; * use `Long64_t` instead of `int` for all entry variables",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/333
https://github.com/root-project/root/pull/333:43,Integrability,integrat,integrate,43,"Fix a few minor things and pave the way to integrate cutflow reports in TDataFrame. * TDFAction ctor can take a shared_ptr instead of a weak_ptr: TDFAction; can safely assume that the previous node in the chain still exists when it is; being constructed; * fPrevData is now a reference instead of a raw pointer in all classes:; a reference better indicates that we always expect fPrevData to be a valid; node of the chain. In fact, the only case when this condition might not be; met is when the TDataFrameImpl object goes out-of-scope before other nodes; of the chain; we detect this case and throw before trying to access; invalid fPrevData pointers/references.; * use `Long64_t` instead of `int` for all entry variables",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/333
https://github.com/root-project/root/pull/333:713,Modifiability,variab,variables,713,"Fix a few minor things and pave the way to integrate cutflow reports in TDataFrame. * TDFAction ctor can take a shared_ptr instead of a weak_ptr: TDFAction; can safely assume that the previous node in the chain still exists when it is; being constructed; * fPrevData is now a reference instead of a raw pointer in all classes:; a reference better indicates that we always expect fPrevData to be a valid; node of the chain. In fact, the only case when this condition might not be; met is when the TDataFrameImpl object goes out-of-scope before other nodes; of the chain; we detect this case and throw before trying to access; invalid fPrevData pointers/references.; * use `Long64_t` instead of `int` for all entry variables",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/333
https://github.com/root-project/root/pull/333:161,Safety,safe,safely,161,"Fix a few minor things and pave the way to integrate cutflow reports in TDataFrame. * TDFAction ctor can take a shared_ptr instead of a weak_ptr: TDFAction; can safely assume that the previous node in the chain still exists when it is; being constructed; * fPrevData is now a reference instead of a raw pointer in all classes:; a reference better indicates that we always expect fPrevData to be a valid; node of the chain. In fact, the only case when this condition might not be; met is when the TDataFrameImpl object goes out-of-scope before other nodes; of the chain; we detect this case and throw before trying to access; invalid fPrevData pointers/references.; * use `Long64_t` instead of `int` for all entry variables",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/333
https://github.com/root-project/root/pull/333:573,Safety,detect,detect,573,"Fix a few minor things and pave the way to integrate cutflow reports in TDataFrame. * TDFAction ctor can take a shared_ptr instead of a weak_ptr: TDFAction; can safely assume that the previous node in the chain still exists when it is; being constructed; * fPrevData is now a reference instead of a raw pointer in all classes:; a reference better indicates that we always expect fPrevData to be a valid; node of the chain. In fact, the only case when this condition might not be; met is when the TDataFrameImpl object goes out-of-scope before other nodes; of the chain; we detect this case and throw before trying to access; invalid fPrevData pointers/references.; * use `Long64_t` instead of `int` for all entry variables",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/333
https://github.com/root-project/root/pull/333:617,Security,access,access,617,"Fix a few minor things and pave the way to integrate cutflow reports in TDataFrame. * TDFAction ctor can take a shared_ptr instead of a weak_ptr: TDFAction; can safely assume that the previous node in the chain still exists when it is; being constructed; * fPrevData is now a reference instead of a raw pointer in all classes:; a reference better indicates that we always expect fPrevData to be a valid; node of the chain. In fact, the only case when this condition might not be; met is when the TDataFrameImpl object goes out-of-scope before other nodes; of the chain; we detect this case and throw before trying to access; invalid fPrevData pointers/references.; * use `Long64_t` instead of `int` for all entry variables",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/333
https://github.com/root-project/root/pull/335:26,Deployability,configurat,configuration,26,We use a dummy map during configuration to pass the CMake compiler steps; with the enabled modulemap overlay. We later configure this overlay file; correctly to actually use the STL modulemap.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/335
https://github.com/root-project/root/pull/335:26,Modifiability,config,configuration,26,We use a dummy map during configuration to pass the CMake compiler steps; with the enabled modulemap overlay. We later configure this overlay file; correctly to actually use the STL modulemap.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/335
https://github.com/root-project/root/pull/335:119,Modifiability,config,configure,119,We use a dummy map during configuration to pass the CMake compiler steps; with the enabled modulemap overlay. We later configure this overlay file; correctly to actually use the STL modulemap.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/335
https://github.com/root-project/root/pull/336:16,Modifiability,variab,variable,16,"* remove unused variable fTmpBranches from TDataFrameImpl; * inizialize fLastCheckedEntry to -1 for all threads; * total size of collection returned by Take is now a ULong64_t; * {Ret,Arg}Type_t -> {Ret,Args}_t: more readable, no redundancy; * minor text fixes",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/336
https://github.com/root-project/root/pull/336:230,Safety,redund,redundancy,230,"* remove unused variable fTmpBranches from TDataFrameImpl; * inizialize fLastCheckedEntry to -1 for all threads; * total size of collection returned by Take is now a ULong64_t; * {Ret,Arg}Type_t -> {Ret,Args}_t: more readable, no redundancy; * minor text fixes",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/336
https://github.com/root-project/root/pull/337:46,Integrability,depend,depending,46,Solves conflicting behaviours between classes depending on tbb. See more here: https://indico.cern.ch/event/607814/contributions/2466931/attachments/1409778/2155811/TScheduler.pdf,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/337
https://github.com/root-project/root/pull/340:0,Testability,Test,Testing,0,Testing whether bot actually comments on PRs of users that are not in the admin list of the bot.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/340
https://github.com/root-project/root/pull/341:21,Availability,redundant,redundant,21,"Some headers contain redundant header guards around #include directives like this:. #ifndef ROOT_TTree; #include ""TTree.h""; #endif. This patch removes the #ifndef's around these includes as they don't serve any practical purpose and are no longer part of the current ROOT coding convention. This patch also fixes the 153 typos that are contained in the symbols of the #ifndef directives.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/341
https://github.com/root-project/root/pull/341:137,Deployability,patch,patch,137,"Some headers contain redundant header guards around #include directives like this:. #ifndef ROOT_TTree; #include ""TTree.h""; #endif. This patch removes the #ifndef's around these includes as they don't serve any practical purpose and are no longer part of the current ROOT coding convention. This patch also fixes the 153 typos that are contained in the symbols of the #ifndef directives.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/341
https://github.com/root-project/root/pull/341:296,Deployability,patch,patch,296,"Some headers contain redundant header guards around #include directives like this:. #ifndef ROOT_TTree; #include ""TTree.h""; #endif. This patch removes the #ifndef's around these includes as they don't serve any practical purpose and are no longer part of the current ROOT coding convention. This patch also fixes the 153 typos that are contained in the symbols of the #ifndef directives.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/341
https://github.com/root-project/root/pull/341:21,Safety,redund,redundant,21,"Some headers contain redundant header guards around #include directives like this:. #ifndef ROOT_TTree; #include ""TTree.h""; #endif. This patch removes the #ifndef's around these includes as they don't serve any practical purpose and are no longer part of the current ROOT coding convention. This patch also fixes the 153 typos that are contained in the symbols of the #ifndef directives.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/341
https://github.com/root-project/root/pull/343:62,Modifiability,Refactor,Refactor,62,"This is a rebase and combination of the PRs #303 #314 #315. - Refactor PyRandomForest, PyGTB, PyAdaBoost; - Add variable ranking to these classifiers; - Add unit-tests for the sklearn classifiers; - Add unit-test for PyKeras multiclass classification; - Move `GetMvaValues` implementation from base class to method to stay independent from sklearn. You can test the changes with `ctest -V -R PyMVA`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/343
https://github.com/root-project/root/pull/343:112,Modifiability,variab,variable,112,"This is a rebase and combination of the PRs #303 #314 #315. - Refactor PyRandomForest, PyGTB, PyAdaBoost; - Add variable ranking to these classifiers; - Add unit-tests for the sklearn classifiers; - Add unit-test for PyKeras multiclass classification; - Move `GetMvaValues` implementation from base class to method to stay independent from sklearn. You can test the changes with `ctest -V -R PyMVA`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/343
https://github.com/root-project/root/pull/343:162,Testability,test,tests,162,"This is a rebase and combination of the PRs #303 #314 #315. - Refactor PyRandomForest, PyGTB, PyAdaBoost; - Add variable ranking to these classifiers; - Add unit-tests for the sklearn classifiers; - Add unit-test for PyKeras multiclass classification; - Move `GetMvaValues` implementation from base class to method to stay independent from sklearn. You can test the changes with `ctest -V -R PyMVA`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/343
https://github.com/root-project/root/pull/343:208,Testability,test,test,208,"This is a rebase and combination of the PRs #303 #314 #315. - Refactor PyRandomForest, PyGTB, PyAdaBoost; - Add variable ranking to these classifiers; - Add unit-tests for the sklearn classifiers; - Add unit-test for PyKeras multiclass classification; - Move `GetMvaValues` implementation from base class to method to stay independent from sklearn. You can test the changes with `ctest -V -R PyMVA`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/343
https://github.com/root-project/root/pull/343:357,Testability,test,test,357,"This is a rebase and combination of the PRs #303 #314 #315. - Refactor PyRandomForest, PyGTB, PyAdaBoost; - Add variable ranking to these classifiers; - Add unit-tests for the sklearn classifiers; - Add unit-test for PyKeras multiclass classification; - Move `GetMvaValues` implementation from base class to method to stay independent from sklearn. You can test the changes with `ctest -V -R PyMVA`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/343
https://github.com/root-project/root/pull/346:157,Deployability,integrat,integration,157,Template WrappedMultiTF1 keeping backwards compatibility and adding a templated std::function interface for TF1. This is the first in a series of PR for the integration of the vectorization + parallelization of the fit in ROOT.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/346
https://github.com/root-project/root/pull/346:94,Integrability,interface,interface,94,Template WrappedMultiTF1 keeping backwards compatibility and adding a templated std::function interface for TF1. This is the first in a series of PR for the integration of the vectorization + parallelization of the fit in ROOT.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/346
https://github.com/root-project/root/pull/346:157,Integrability,integrat,integration,157,Template WrappedMultiTF1 keeping backwards compatibility and adding a templated std::function interface for TF1. This is the first in a series of PR for the integration of the vectorization + parallelization of the fit in ROOT.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/346
https://github.com/root-project/root/pull/347:5,Energy Efficiency,reduce,reduces,5,This reduces the different specializations of TDFInterface that have to be instantiated to three.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/347
https://github.com/root-project/root/pull/348:577,Performance,perform,perform,577,"- removed nested template struct SimpleAction; - TDataFrameInterface::SimpleAction::BuildAndBook is now TDataFrameInterface::BuildAndBook; - BuildAndBook now only takes one template parameter instead of three; - the default type of histogram weights is now `void` (which signals that we are; not filling a weighted histogram); - `enum EActionType` has been replaced by `namespace ActionTypes`. With a few exceptions, actions are now created by calling `CreateAction`, which; in turn calls `BuildAndBook`. Two template overloads of `CreateAction` are used; to decide whether to perform runtime type guessing or not. Multiple overloads of; `BuildAndBook` take care of building the correct operation for each action.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/348
https://github.com/root-project/root/pull/348:33,Usability,Simpl,SimpleAction,33,"- removed nested template struct SimpleAction; - TDataFrameInterface::SimpleAction::BuildAndBook is now TDataFrameInterface::BuildAndBook; - BuildAndBook now only takes one template parameter instead of three; - the default type of histogram weights is now `void` (which signals that we are; not filling a weighted histogram); - `enum EActionType` has been replaced by `namespace ActionTypes`. With a few exceptions, actions are now created by calling `CreateAction`, which; in turn calls `BuildAndBook`. Two template overloads of `CreateAction` are used; to decide whether to perform runtime type guessing or not. Multiple overloads of; `BuildAndBook` take care of building the correct operation for each action.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/348
https://github.com/root-project/root/pull/348:70,Usability,Simpl,SimpleAction,70,"- removed nested template struct SimpleAction; - TDataFrameInterface::SimpleAction::BuildAndBook is now TDataFrameInterface::BuildAndBook; - BuildAndBook now only takes one template parameter instead of three; - the default type of histogram weights is now `void` (which signals that we are; not filling a weighted histogram); - `enum EActionType` has been replaced by `namespace ActionTypes`. With a few exceptions, actions are now created by calling `CreateAction`, which; in turn calls `BuildAndBook`. Two template overloads of `CreateAction` are used; to decide whether to perform runtime type guessing or not. Multiple overloads of; `BuildAndBook` take care of building the correct operation for each action.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/348
https://github.com/root-project/root/pull/349:13,Testability,log,logic,13,The previous logic was such that the warning about suppressed further; warnings never executed. This commit also improves formatting according; to the coding conventions. Fixes: https://sft.its.cern.ch/jira/browse/ROOT-8572,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/349
https://github.com/root-project/root/pull/352:334,Availability,error,error,334,"RooArgSet allows to create a file with the information from the arguments stored in the set with the method RooArgSet::writeToFile(...).; Unfortunately, when using the corresponding RooArgSet::readFromFile function, there is a parsing problems for numbers in the form Xe+YZ, and the information gets lost in the import. The following error is produced:. ```; [#0] ERROR:InputArguments -- RooRealVar::readFromStream(x): parse error, cannot convert '1e' to double precision; ```; You can test yourself with this script: [root-prob.py](https://root.cern.ch/phpBB3/download/file.php?id=13191&sid=a39a5dc5dc04a4c2be38081286650206). I’ve tracked the problem down to a forgotten case in RooStreamParser::readToken(). And after fixing it I made the script work as expected ([after.txt](https://root.cern.ch/phpBB3/download/file.php?id=13192&sid=a39a5dc5dc04a4c2be38081286650206)). Apologies for the trailing whitespace removed. Only real change at line 230.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/352
https://github.com/root-project/root/pull/352:364,Availability,ERROR,ERROR,364,"RooArgSet allows to create a file with the information from the arguments stored in the set with the method RooArgSet::writeToFile(...).; Unfortunately, when using the corresponding RooArgSet::readFromFile function, there is a parsing problems for numbers in the form Xe+YZ, and the information gets lost in the import. The following error is produced:. ```; [#0] ERROR:InputArguments -- RooRealVar::readFromStream(x): parse error, cannot convert '1e' to double precision; ```; You can test yourself with this script: [root-prob.py](https://root.cern.ch/phpBB3/download/file.php?id=13191&sid=a39a5dc5dc04a4c2be38081286650206). I’ve tracked the problem down to a forgotten case in RooStreamParser::readToken(). And after fixing it I made the script work as expected ([after.txt](https://root.cern.ch/phpBB3/download/file.php?id=13192&sid=a39a5dc5dc04a4c2be38081286650206)). Apologies for the trailing whitespace removed. Only real change at line 230.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/352
https://github.com/root-project/root/pull/352:425,Availability,error,error,425,"RooArgSet allows to create a file with the information from the arguments stored in the set with the method RooArgSet::writeToFile(...).; Unfortunately, when using the corresponding RooArgSet::readFromFile function, there is a parsing problems for numbers in the form Xe+YZ, and the information gets lost in the import. The following error is produced:. ```; [#0] ERROR:InputArguments -- RooRealVar::readFromStream(x): parse error, cannot convert '1e' to double precision; ```; You can test yourself with this script: [root-prob.py](https://root.cern.ch/phpBB3/download/file.php?id=13191&sid=a39a5dc5dc04a4c2be38081286650206). I’ve tracked the problem down to a forgotten case in RooStreamParser::readToken(). And after fixing it I made the script work as expected ([after.txt](https://root.cern.ch/phpBB3/download/file.php?id=13192&sid=a39a5dc5dc04a4c2be38081286650206)). Apologies for the trailing whitespace removed. Only real change at line 230.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/352
https://github.com/root-project/root/pull/352:561,Availability,down,download,561,"RooArgSet allows to create a file with the information from the arguments stored in the set with the method RooArgSet::writeToFile(...).; Unfortunately, when using the corresponding RooArgSet::readFromFile function, there is a parsing problems for numbers in the form Xe+YZ, and the information gets lost in the import. The following error is produced:. ```; [#0] ERROR:InputArguments -- RooRealVar::readFromStream(x): parse error, cannot convert '1e' to double precision; ```; You can test yourself with this script: [root-prob.py](https://root.cern.ch/phpBB3/download/file.php?id=13191&sid=a39a5dc5dc04a4c2be38081286650206). I’ve tracked the problem down to a forgotten case in RooStreamParser::readToken(). And after fixing it I made the script work as expected ([after.txt](https://root.cern.ch/phpBB3/download/file.php?id=13192&sid=a39a5dc5dc04a4c2be38081286650206)). Apologies for the trailing whitespace removed. Only real change at line 230.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/352
https://github.com/root-project/root/pull/352:652,Availability,down,down,652,"RooArgSet allows to create a file with the information from the arguments stored in the set with the method RooArgSet::writeToFile(...).; Unfortunately, when using the corresponding RooArgSet::readFromFile function, there is a parsing problems for numbers in the form Xe+YZ, and the information gets lost in the import. The following error is produced:. ```; [#0] ERROR:InputArguments -- RooRealVar::readFromStream(x): parse error, cannot convert '1e' to double precision; ```; You can test yourself with this script: [root-prob.py](https://root.cern.ch/phpBB3/download/file.php?id=13191&sid=a39a5dc5dc04a4c2be38081286650206). I’ve tracked the problem down to a forgotten case in RooStreamParser::readToken(). And after fixing it I made the script work as expected ([after.txt](https://root.cern.ch/phpBB3/download/file.php?id=13192&sid=a39a5dc5dc04a4c2be38081286650206)). Apologies for the trailing whitespace removed. Only real change at line 230.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/352
https://github.com/root-project/root/pull/352:806,Availability,down,download,806,"RooArgSet allows to create a file with the information from the arguments stored in the set with the method RooArgSet::writeToFile(...).; Unfortunately, when using the corresponding RooArgSet::readFromFile function, there is a parsing problems for numbers in the form Xe+YZ, and the information gets lost in the import. The following error is produced:. ```; [#0] ERROR:InputArguments -- RooRealVar::readFromStream(x): parse error, cannot convert '1e' to double precision; ```; You can test yourself with this script: [root-prob.py](https://root.cern.ch/phpBB3/download/file.php?id=13191&sid=a39a5dc5dc04a4c2be38081286650206). I’ve tracked the problem down to a forgotten case in RooStreamParser::readToken(). And after fixing it I made the script work as expected ([after.txt](https://root.cern.ch/phpBB3/download/file.php?id=13192&sid=a39a5dc5dc04a4c2be38081286650206)). Apologies for the trailing whitespace removed. Only real change at line 230.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/352
https://github.com/root-project/root/pull/352:486,Testability,test,test,486,"RooArgSet allows to create a file with the information from the arguments stored in the set with the method RooArgSet::writeToFile(...).; Unfortunately, when using the corresponding RooArgSet::readFromFile function, there is a parsing problems for numbers in the form Xe+YZ, and the information gets lost in the import. The following error is produced:. ```; [#0] ERROR:InputArguments -- RooRealVar::readFromStream(x): parse error, cannot convert '1e' to double precision; ```; You can test yourself with this script: [root-prob.py](https://root.cern.ch/phpBB3/download/file.php?id=13191&sid=a39a5dc5dc04a4c2be38081286650206). I’ve tracked the problem down to a forgotten case in RooStreamParser::readToken(). And after fixing it I made the script work as expected ([after.txt](https://root.cern.ch/phpBB3/download/file.php?id=13192&sid=a39a5dc5dc04a4c2be38081286650206)). Apologies for the trailing whitespace removed. Only real change at line 230.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/352
https://github.com/root-project/root/pull/353:68,Availability,error,error,68,"/builddir/build/BUILD/root-6.08.04/test/stressEntryList.cxx:616:42: error: 'function' is not a member of 'std'; using fcnCharPtrPair = std::pair<std::function<bool()>,const char*>;",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/353
https://github.com/root-project/root/pull/353:35,Testability,test,test,35,"/builddir/build/BUILD/root-6.08.04/test/stressEntryList.cxx:616:42: error: 'function' is not a member of 'std'; using fcnCharPtrPair = std::pair<std::function<bool()>,const char*>;",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/353
https://github.com/root-project/root/pull/354:37,Integrability,interface,interface,37,"This is an internal change. The user interface remains unchanged, as we probably want to copy callables passed to `TDataFrame` by value in all cases.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/354
https://github.com/root-project/root/pull/357:58,Energy Efficiency,reduce,reduceTree,58,"example usage:. ```c++; ROOT::Experimental::TDataFrame d(""reduceTree"", &f, {""i""});; auto r = d.Reduce([](int a, int b) { return a + b; }, {""i""}); // sum all branch values; auto rDefBranch = d.Filter([]() { return true; }); .Reduce([](int a, int b) { return a*b; }, {}, 1); // multiply all branch values. ```. A PR with a unit test has been submitted to the roottest repo.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/357
https://github.com/root-project/root/pull/357:95,Energy Efficiency,Reduce,Reduce,95,"example usage:. ```c++; ROOT::Experimental::TDataFrame d(""reduceTree"", &f, {""i""});; auto r = d.Reduce([](int a, int b) { return a + b; }, {""i""}); // sum all branch values; auto rDefBranch = d.Filter([]() { return true; }); .Reduce([](int a, int b) { return a*b; }, {}, 1); // multiply all branch values. ```. A PR with a unit test has been submitted to the roottest repo.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/357
https://github.com/root-project/root/pull/357:224,Energy Efficiency,Reduce,Reduce,224,"example usage:. ```c++; ROOT::Experimental::TDataFrame d(""reduceTree"", &f, {""i""});; auto r = d.Reduce([](int a, int b) { return a + b; }, {""i""}); // sum all branch values; auto rDefBranch = d.Filter([]() { return true; }); .Reduce([](int a, int b) { return a*b; }, {}, 1); // multiply all branch values. ```. A PR with a unit test has been submitted to the roottest repo.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/357
https://github.com/root-project/root/pull/357:326,Testability,test,test,326,"example usage:. ```c++; ROOT::Experimental::TDataFrame d(""reduceTree"", &f, {""i""});; auto r = d.Reduce([](int a, int b) { return a + b; }, {""i""}); // sum all branch values; auto rDefBranch = d.Filter([]() { return true; }); .Reduce([](int a, int b) { return a*b; }, {}, 1); // multiply all branch values. ```. A PR with a unit test has been submitted to the roottest repo.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/357
https://github.com/root-project/root/pull/359:1404,Availability,Error,Error,1404,7/602 Test #11: mathcore-testSampleQuantiles ...............................***Failed 2.24 sec; Test ordered data ....; Testing for type 7 :		.............	 OK !; Testing for type 1 :		.............	 OK !; Testing for type 2 :		.... Failed for prob = 0.3 - R gives 0.85 TMath gives 0.7; .. Failed for prob = 0.6 - R gives 1.65 TMath gives 1.5; Failed for prob = 0.7 - R gives 1.9 TMath gives 1.8; ....; Test Failed for type 2; Testing for type 3 :		.............	 OK !; Testing for type 4 :		.............	 OK !; Testing for type 5 :		.............	 OK !; Testing for type 6 :		.............	 OK !; Testing for type 7 :		.............	 OK !; Testing for type 8 :		.............	 OK !; Testing for type 9 :		.............	 OK !; Test data in random order....; Testing for type 7 :		.............	 OK !; Testing for type 1 :		.............	 OK !; Testing for type 2 :		.... Failed for prob = 0.3 - R gives 0.85 TMath gives 0.7; .. Failed for prob = 0.6 - R gives 1.65 TMath gives 1.5; Failed for prob = 0.7 - R gives 1.9 TMath gives 1.8; ....; Test Failed for type 2; Testing for type 3 :		.............	 OK !; Testing for type 4 :		.............	 OK !; Testing for type 5 :		.............	 OK !; Testing for type 6 :		.............	 OK !; Testing for type 7 :		.............	 OK !; Testing for type 8 :		.............	 OK !; Testing for type 9 :		.............	 OK !; Test sample quantiles FAILED ; CMake Error at /builddir/build/BUILD/root-6.08.04/cmake/modules/RootTestDriver.cmake:196 (message):; error code: 255. The PR implements the same check for type < 4 that is done later in the else clause for type >= 4. So this treats all types the same and the test failure goes away.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/359
https://github.com/root-project/root/pull/359:1499,Availability,error,error,1499,7/602 Test #11: mathcore-testSampleQuantiles ...............................***Failed 2.24 sec; Test ordered data ....; Testing for type 7 :		.............	 OK !; Testing for type 1 :		.............	 OK !; Testing for type 2 :		.... Failed for prob = 0.3 - R gives 0.85 TMath gives 0.7; .. Failed for prob = 0.6 - R gives 1.65 TMath gives 1.5; Failed for prob = 0.7 - R gives 1.9 TMath gives 1.8; ....; Test Failed for type 2; Testing for type 3 :		.............	 OK !; Testing for type 4 :		.............	 OK !; Testing for type 5 :		.............	 OK !; Testing for type 6 :		.............	 OK !; Testing for type 7 :		.............	 OK !; Testing for type 8 :		.............	 OK !; Testing for type 9 :		.............	 OK !; Test data in random order....; Testing for type 7 :		.............	 OK !; Testing for type 1 :		.............	 OK !; Testing for type 2 :		.... Failed for prob = 0.3 - R gives 0.85 TMath gives 0.7; .. Failed for prob = 0.6 - R gives 1.65 TMath gives 1.5; Failed for prob = 0.7 - R gives 1.9 TMath gives 1.8; ....; Test Failed for type 2; Testing for type 3 :		.............	 OK !; Testing for type 4 :		.............	 OK !; Testing for type 5 :		.............	 OK !; Testing for type 6 :		.............	 OK !; Testing for type 7 :		.............	 OK !; Testing for type 8 :		.............	 OK !; Testing for type 9 :		.............	 OK !; Test sample quantiles FAILED ; CMake Error at /builddir/build/BUILD/root-6.08.04/cmake/modules/RootTestDriver.cmake:196 (message):; error code: 255. The PR implements the same check for type < 4 that is done later in the else clause for type >= 4. So this treats all types the same and the test failure goes away.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/359
https://github.com/root-project/root/pull/359:1662,Availability,failure,failure,1662,7/602 Test #11: mathcore-testSampleQuantiles ...............................***Failed 2.24 sec; Test ordered data ....; Testing for type 7 :		.............	 OK !; Testing for type 1 :		.............	 OK !; Testing for type 2 :		.... Failed for prob = 0.3 - R gives 0.85 TMath gives 0.7; .. Failed for prob = 0.6 - R gives 1.65 TMath gives 1.5; Failed for prob = 0.7 - R gives 1.9 TMath gives 1.8; ....; Test Failed for type 2; Testing for type 3 :		.............	 OK !; Testing for type 4 :		.............	 OK !; Testing for type 5 :		.............	 OK !; Testing for type 6 :		.............	 OK !; Testing for type 7 :		.............	 OK !; Testing for type 8 :		.............	 OK !; Testing for type 9 :		.............	 OK !; Test data in random order....; Testing for type 7 :		.............	 OK !; Testing for type 1 :		.............	 OK !; Testing for type 2 :		.... Failed for prob = 0.3 - R gives 0.85 TMath gives 0.7; .. Failed for prob = 0.6 - R gives 1.65 TMath gives 1.5; Failed for prob = 0.7 - R gives 1.9 TMath gives 1.8; ....; Test Failed for type 2; Testing for type 3 :		.............	 OK !; Testing for type 4 :		.............	 OK !; Testing for type 5 :		.............	 OK !; Testing for type 6 :		.............	 OK !; Testing for type 7 :		.............	 OK !; Testing for type 8 :		.............	 OK !; Testing for type 9 :		.............	 OK !; Test sample quantiles FAILED ; CMake Error at /builddir/build/BUILD/root-6.08.04/cmake/modules/RootTestDriver.cmake:196 (message):; error code: 255. The PR implements the same check for type < 4 that is done later in the else clause for type >= 4. So this treats all types the same and the test failure goes away.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/359
https://github.com/root-project/root/pull/359:1488,Integrability,message,message,1488,7/602 Test #11: mathcore-testSampleQuantiles ...............................***Failed 2.24 sec; Test ordered data ....; Testing for type 7 :		.............	 OK !; Testing for type 1 :		.............	 OK !; Testing for type 2 :		.... Failed for prob = 0.3 - R gives 0.85 TMath gives 0.7; .. Failed for prob = 0.6 - R gives 1.65 TMath gives 1.5; Failed for prob = 0.7 - R gives 1.9 TMath gives 1.8; ....; Test Failed for type 2; Testing for type 3 :		.............	 OK !; Testing for type 4 :		.............	 OK !; Testing for type 5 :		.............	 OK !; Testing for type 6 :		.............	 OK !; Testing for type 7 :		.............	 OK !; Testing for type 8 :		.............	 OK !; Testing for type 9 :		.............	 OK !; Test data in random order....; Testing for type 7 :		.............	 OK !; Testing for type 1 :		.............	 OK !; Testing for type 2 :		.... Failed for prob = 0.3 - R gives 0.85 TMath gives 0.7; .. Failed for prob = 0.6 - R gives 1.65 TMath gives 1.5; Failed for prob = 0.7 - R gives 1.9 TMath gives 1.8; ....; Test Failed for type 2; Testing for type 3 :		.............	 OK !; Testing for type 4 :		.............	 OK !; Testing for type 5 :		.............	 OK !; Testing for type 6 :		.............	 OK !; Testing for type 7 :		.............	 OK !; Testing for type 8 :		.............	 OK !; Testing for type 9 :		.............	 OK !; Test sample quantiles FAILED ; CMake Error at /builddir/build/BUILD/root-6.08.04/cmake/modules/RootTestDriver.cmake:196 (message):; error code: 255. The PR implements the same check for type < 4 that is done later in the else clause for type >= 4. So this treats all types the same and the test failure goes away.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/359
https://github.com/root-project/root/pull/359:6,Testability,Test,Test,6,7/602 Test #11: mathcore-testSampleQuantiles ...............................***Failed 2.24 sec; Test ordered data ....; Testing for type 7 :		.............	 OK !; Testing for type 1 :		.............	 OK !; Testing for type 2 :		.... Failed for prob = 0.3 - R gives 0.85 TMath gives 0.7; .. Failed for prob = 0.6 - R gives 1.65 TMath gives 1.5; Failed for prob = 0.7 - R gives 1.9 TMath gives 1.8; ....; Test Failed for type 2; Testing for type 3 :		.............	 OK !; Testing for type 4 :		.............	 OK !; Testing for type 5 :		.............	 OK !; Testing for type 6 :		.............	 OK !; Testing for type 7 :		.............	 OK !; Testing for type 8 :		.............	 OK !; Testing for type 9 :		.............	 OK !; Test data in random order....; Testing for type 7 :		.............	 OK !; Testing for type 1 :		.............	 OK !; Testing for type 2 :		.... Failed for prob = 0.3 - R gives 0.85 TMath gives 0.7; .. Failed for prob = 0.6 - R gives 1.65 TMath gives 1.5; Failed for prob = 0.7 - R gives 1.9 TMath gives 1.8; ....; Test Failed for type 2; Testing for type 3 :		.............	 OK !; Testing for type 4 :		.............	 OK !; Testing for type 5 :		.............	 OK !; Testing for type 6 :		.............	 OK !; Testing for type 7 :		.............	 OK !; Testing for type 8 :		.............	 OK !; Testing for type 9 :		.............	 OK !; Test sample quantiles FAILED ; CMake Error at /builddir/build/BUILD/root-6.08.04/cmake/modules/RootTestDriver.cmake:196 (message):; error code: 255. The PR implements the same check for type < 4 that is done later in the else clause for type >= 4. So this treats all types the same and the test failure goes away.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/359
https://github.com/root-project/root/pull/359:25,Testability,test,testSampleQuantiles,25,7/602 Test #11: mathcore-testSampleQuantiles ...............................***Failed 2.24 sec; Test ordered data ....; Testing for type 7 :		.............	 OK !; Testing for type 1 :		.............	 OK !; Testing for type 2 :		.... Failed for prob = 0.3 - R gives 0.85 TMath gives 0.7; .. Failed for prob = 0.6 - R gives 1.65 TMath gives 1.5; Failed for prob = 0.7 - R gives 1.9 TMath gives 1.8; ....; Test Failed for type 2; Testing for type 3 :		.............	 OK !; Testing for type 4 :		.............	 OK !; Testing for type 5 :		.............	 OK !; Testing for type 6 :		.............	 OK !; Testing for type 7 :		.............	 OK !; Testing for type 8 :		.............	 OK !; Testing for type 9 :		.............	 OK !; Test data in random order....; Testing for type 7 :		.............	 OK !; Testing for type 1 :		.............	 OK !; Testing for type 2 :		.... Failed for prob = 0.3 - R gives 0.85 TMath gives 0.7; .. Failed for prob = 0.6 - R gives 1.65 TMath gives 1.5; Failed for prob = 0.7 - R gives 1.9 TMath gives 1.8; ....; Test Failed for type 2; Testing for type 3 :		.............	 OK !; Testing for type 4 :		.............	 OK !; Testing for type 5 :		.............	 OK !; Testing for type 6 :		.............	 OK !; Testing for type 7 :		.............	 OK !; Testing for type 8 :		.............	 OK !; Testing for type 9 :		.............	 OK !; Test sample quantiles FAILED ; CMake Error at /builddir/build/BUILD/root-6.08.04/cmake/modules/RootTestDriver.cmake:196 (message):; error code: 255. The PR implements the same check for type < 4 that is done later in the else clause for type >= 4. So this treats all types the same and the test failure goes away.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/359
https://github.com/root-project/root/pull/359:96,Testability,Test,Test,96,7/602 Test #11: mathcore-testSampleQuantiles ...............................***Failed 2.24 sec; Test ordered data ....; Testing for type 7 :		.............	 OK !; Testing for type 1 :		.............	 OK !; Testing for type 2 :		.... Failed for prob = 0.3 - R gives 0.85 TMath gives 0.7; .. Failed for prob = 0.6 - R gives 1.65 TMath gives 1.5; Failed for prob = 0.7 - R gives 1.9 TMath gives 1.8; ....; Test Failed for type 2; Testing for type 3 :		.............	 OK !; Testing for type 4 :		.............	 OK !; Testing for type 5 :		.............	 OK !; Testing for type 6 :		.............	 OK !; Testing for type 7 :		.............	 OK !; Testing for type 8 :		.............	 OK !; Testing for type 9 :		.............	 OK !; Test data in random order....; Testing for type 7 :		.............	 OK !; Testing for type 1 :		.............	 OK !; Testing for type 2 :		.... Failed for prob = 0.3 - R gives 0.85 TMath gives 0.7; .. Failed for prob = 0.6 - R gives 1.65 TMath gives 1.5; Failed for prob = 0.7 - R gives 1.9 TMath gives 1.8; ....; Test Failed for type 2; Testing for type 3 :		.............	 OK !; Testing for type 4 :		.............	 OK !; Testing for type 5 :		.............	 OK !; Testing for type 6 :		.............	 OK !; Testing for type 7 :		.............	 OK !; Testing for type 8 :		.............	 OK !; Testing for type 9 :		.............	 OK !; Test sample quantiles FAILED ; CMake Error at /builddir/build/BUILD/root-6.08.04/cmake/modules/RootTestDriver.cmake:196 (message):; error code: 255. The PR implements the same check for type < 4 that is done later in the else clause for type >= 4. So this treats all types the same and the test failure goes away.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/359
https://github.com/root-project/root/pull/359:120,Testability,Test,Testing,120,7/602 Test #11: mathcore-testSampleQuantiles ...............................***Failed 2.24 sec; Test ordered data ....; Testing for type 7 :		.............	 OK !; Testing for type 1 :		.............	 OK !; Testing for type 2 :		.... Failed for prob = 0.3 - R gives 0.85 TMath gives 0.7; .. Failed for prob = 0.6 - R gives 1.65 TMath gives 1.5; Failed for prob = 0.7 - R gives 1.9 TMath gives 1.8; ....; Test Failed for type 2; Testing for type 3 :		.............	 OK !; Testing for type 4 :		.............	 OK !; Testing for type 5 :		.............	 OK !; Testing for type 6 :		.............	 OK !; Testing for type 7 :		.............	 OK !; Testing for type 8 :		.............	 OK !; Testing for type 9 :		.............	 OK !; Test data in random order....; Testing for type 7 :		.............	 OK !; Testing for type 1 :		.............	 OK !; Testing for type 2 :		.... Failed for prob = 0.3 - R gives 0.85 TMath gives 0.7; .. Failed for prob = 0.6 - R gives 1.65 TMath gives 1.5; Failed for prob = 0.7 - R gives 1.9 TMath gives 1.8; ....; Test Failed for type 2; Testing for type 3 :		.............	 OK !; Testing for type 4 :		.............	 OK !; Testing for type 5 :		.............	 OK !; Testing for type 6 :		.............	 OK !; Testing for type 7 :		.............	 OK !; Testing for type 8 :		.............	 OK !; Testing for type 9 :		.............	 OK !; Test sample quantiles FAILED ; CMake Error at /builddir/build/BUILD/root-6.08.04/cmake/modules/RootTestDriver.cmake:196 (message):; error code: 255. The PR implements the same check for type < 4 that is done later in the else clause for type >= 4. So this treats all types the same and the test failure goes away.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/359
https://github.com/root-project/root/pull/359:163,Testability,Test,Testing,163,7/602 Test #11: mathcore-testSampleQuantiles ...............................***Failed 2.24 sec; Test ordered data ....; Testing for type 7 :		.............	 OK !; Testing for type 1 :		.............	 OK !; Testing for type 2 :		.... Failed for prob = 0.3 - R gives 0.85 TMath gives 0.7; .. Failed for prob = 0.6 - R gives 1.65 TMath gives 1.5; Failed for prob = 0.7 - R gives 1.9 TMath gives 1.8; ....; Test Failed for type 2; Testing for type 3 :		.............	 OK !; Testing for type 4 :		.............	 OK !; Testing for type 5 :		.............	 OK !; Testing for type 6 :		.............	 OK !; Testing for type 7 :		.............	 OK !; Testing for type 8 :		.............	 OK !; Testing for type 9 :		.............	 OK !; Test data in random order....; Testing for type 7 :		.............	 OK !; Testing for type 1 :		.............	 OK !; Testing for type 2 :		.... Failed for prob = 0.3 - R gives 0.85 TMath gives 0.7; .. Failed for prob = 0.6 - R gives 1.65 TMath gives 1.5; Failed for prob = 0.7 - R gives 1.9 TMath gives 1.8; ....; Test Failed for type 2; Testing for type 3 :		.............	 OK !; Testing for type 4 :		.............	 OK !; Testing for type 5 :		.............	 OK !; Testing for type 6 :		.............	 OK !; Testing for type 7 :		.............	 OK !; Testing for type 8 :		.............	 OK !; Testing for type 9 :		.............	 OK !; Test sample quantiles FAILED ; CMake Error at /builddir/build/BUILD/root-6.08.04/cmake/modules/RootTestDriver.cmake:196 (message):; error code: 255. The PR implements the same check for type < 4 that is done later in the else clause for type >= 4. So this treats all types the same and the test failure goes away.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/359
https://github.com/root-project/root/pull/359:206,Testability,Test,Testing,206,7/602 Test #11: mathcore-testSampleQuantiles ...............................***Failed 2.24 sec; Test ordered data ....; Testing for type 7 :		.............	 OK !; Testing for type 1 :		.............	 OK !; Testing for type 2 :		.... Failed for prob = 0.3 - R gives 0.85 TMath gives 0.7; .. Failed for prob = 0.6 - R gives 1.65 TMath gives 1.5; Failed for prob = 0.7 - R gives 1.9 TMath gives 1.8; ....; Test Failed for type 2; Testing for type 3 :		.............	 OK !; Testing for type 4 :		.............	 OK !; Testing for type 5 :		.............	 OK !; Testing for type 6 :		.............	 OK !; Testing for type 7 :		.............	 OK !; Testing for type 8 :		.............	 OK !; Testing for type 9 :		.............	 OK !; Test data in random order....; Testing for type 7 :		.............	 OK !; Testing for type 1 :		.............	 OK !; Testing for type 2 :		.... Failed for prob = 0.3 - R gives 0.85 TMath gives 0.7; .. Failed for prob = 0.6 - R gives 1.65 TMath gives 1.5; Failed for prob = 0.7 - R gives 1.9 TMath gives 1.8; ....; Test Failed for type 2; Testing for type 3 :		.............	 OK !; Testing for type 4 :		.............	 OK !; Testing for type 5 :		.............	 OK !; Testing for type 6 :		.............	 OK !; Testing for type 7 :		.............	 OK !; Testing for type 8 :		.............	 OK !; Testing for type 9 :		.............	 OK !; Test sample quantiles FAILED ; CMake Error at /builddir/build/BUILD/root-6.08.04/cmake/modules/RootTestDriver.cmake:196 (message):; error code: 255. The PR implements the same check for type < 4 that is done later in the else clause for type >= 4. So this treats all types the same and the test failure goes away.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/359
https://github.com/root-project/root/pull/359:403,Testability,Test,Test,403,7/602 Test #11: mathcore-testSampleQuantiles ...............................***Failed 2.24 sec; Test ordered data ....; Testing for type 7 :		.............	 OK !; Testing for type 1 :		.............	 OK !; Testing for type 2 :		.... Failed for prob = 0.3 - R gives 0.85 TMath gives 0.7; .. Failed for prob = 0.6 - R gives 1.65 TMath gives 1.5; Failed for prob = 0.7 - R gives 1.9 TMath gives 1.8; ....; Test Failed for type 2; Testing for type 3 :		.............	 OK !; Testing for type 4 :		.............	 OK !; Testing for type 5 :		.............	 OK !; Testing for type 6 :		.............	 OK !; Testing for type 7 :		.............	 OK !; Testing for type 8 :		.............	 OK !; Testing for type 9 :		.............	 OK !; Test data in random order....; Testing for type 7 :		.............	 OK !; Testing for type 1 :		.............	 OK !; Testing for type 2 :		.... Failed for prob = 0.3 - R gives 0.85 TMath gives 0.7; .. Failed for prob = 0.6 - R gives 1.65 TMath gives 1.5; Failed for prob = 0.7 - R gives 1.9 TMath gives 1.8; ....; Test Failed for type 2; Testing for type 3 :		.............	 OK !; Testing for type 4 :		.............	 OK !; Testing for type 5 :		.............	 OK !; Testing for type 6 :		.............	 OK !; Testing for type 7 :		.............	 OK !; Testing for type 8 :		.............	 OK !; Testing for type 9 :		.............	 OK !; Test sample quantiles FAILED ; CMake Error at /builddir/build/BUILD/root-6.08.04/cmake/modules/RootTestDriver.cmake:196 (message):; error code: 255. The PR implements the same check for type < 4 that is done later in the else clause for type >= 4. So this treats all types the same and the test failure goes away.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/359
https://github.com/root-project/root/pull/359:427,Testability,Test,Testing,427,7/602 Test #11: mathcore-testSampleQuantiles ...............................***Failed 2.24 sec; Test ordered data ....; Testing for type 7 :		.............	 OK !; Testing for type 1 :		.............	 OK !; Testing for type 2 :		.... Failed for prob = 0.3 - R gives 0.85 TMath gives 0.7; .. Failed for prob = 0.6 - R gives 1.65 TMath gives 1.5; Failed for prob = 0.7 - R gives 1.9 TMath gives 1.8; ....; Test Failed for type 2; Testing for type 3 :		.............	 OK !; Testing for type 4 :		.............	 OK !; Testing for type 5 :		.............	 OK !; Testing for type 6 :		.............	 OK !; Testing for type 7 :		.............	 OK !; Testing for type 8 :		.............	 OK !; Testing for type 9 :		.............	 OK !; Test data in random order....; Testing for type 7 :		.............	 OK !; Testing for type 1 :		.............	 OK !; Testing for type 2 :		.... Failed for prob = 0.3 - R gives 0.85 TMath gives 0.7; .. Failed for prob = 0.6 - R gives 1.65 TMath gives 1.5; Failed for prob = 0.7 - R gives 1.9 TMath gives 1.8; ....; Test Failed for type 2; Testing for type 3 :		.............	 OK !; Testing for type 4 :		.............	 OK !; Testing for type 5 :		.............	 OK !; Testing for type 6 :		.............	 OK !; Testing for type 7 :		.............	 OK !; Testing for type 8 :		.............	 OK !; Testing for type 9 :		.............	 OK !; Test sample quantiles FAILED ; CMake Error at /builddir/build/BUILD/root-6.08.04/cmake/modules/RootTestDriver.cmake:196 (message):; error code: 255. The PR implements the same check for type < 4 that is done later in the else clause for type >= 4. So this treats all types the same and the test failure goes away.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/359
https://github.com/root-project/root/pull/359:470,Testability,Test,Testing,470,7/602 Test #11: mathcore-testSampleQuantiles ...............................***Failed 2.24 sec; Test ordered data ....; Testing for type 7 :		.............	 OK !; Testing for type 1 :		.............	 OK !; Testing for type 2 :		.... Failed for prob = 0.3 - R gives 0.85 TMath gives 0.7; .. Failed for prob = 0.6 - R gives 1.65 TMath gives 1.5; Failed for prob = 0.7 - R gives 1.9 TMath gives 1.8; ....; Test Failed for type 2; Testing for type 3 :		.............	 OK !; Testing for type 4 :		.............	 OK !; Testing for type 5 :		.............	 OK !; Testing for type 6 :		.............	 OK !; Testing for type 7 :		.............	 OK !; Testing for type 8 :		.............	 OK !; Testing for type 9 :		.............	 OK !; Test data in random order....; Testing for type 7 :		.............	 OK !; Testing for type 1 :		.............	 OK !; Testing for type 2 :		.... Failed for prob = 0.3 - R gives 0.85 TMath gives 0.7; .. Failed for prob = 0.6 - R gives 1.65 TMath gives 1.5; Failed for prob = 0.7 - R gives 1.9 TMath gives 1.8; ....; Test Failed for type 2; Testing for type 3 :		.............	 OK !; Testing for type 4 :		.............	 OK !; Testing for type 5 :		.............	 OK !; Testing for type 6 :		.............	 OK !; Testing for type 7 :		.............	 OK !; Testing for type 8 :		.............	 OK !; Testing for type 9 :		.............	 OK !; Test sample quantiles FAILED ; CMake Error at /builddir/build/BUILD/root-6.08.04/cmake/modules/RootTestDriver.cmake:196 (message):; error code: 255. The PR implements the same check for type < 4 that is done later in the else clause for type >= 4. So this treats all types the same and the test failure goes away.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/359
https://github.com/root-project/root/pull/359:513,Testability,Test,Testing,513,7/602 Test #11: mathcore-testSampleQuantiles ...............................***Failed 2.24 sec; Test ordered data ....; Testing for type 7 :		.............	 OK !; Testing for type 1 :		.............	 OK !; Testing for type 2 :		.... Failed for prob = 0.3 - R gives 0.85 TMath gives 0.7; .. Failed for prob = 0.6 - R gives 1.65 TMath gives 1.5; Failed for prob = 0.7 - R gives 1.9 TMath gives 1.8; ....; Test Failed for type 2; Testing for type 3 :		.............	 OK !; Testing for type 4 :		.............	 OK !; Testing for type 5 :		.............	 OK !; Testing for type 6 :		.............	 OK !; Testing for type 7 :		.............	 OK !; Testing for type 8 :		.............	 OK !; Testing for type 9 :		.............	 OK !; Test data in random order....; Testing for type 7 :		.............	 OK !; Testing for type 1 :		.............	 OK !; Testing for type 2 :		.... Failed for prob = 0.3 - R gives 0.85 TMath gives 0.7; .. Failed for prob = 0.6 - R gives 1.65 TMath gives 1.5; Failed for prob = 0.7 - R gives 1.9 TMath gives 1.8; ....; Test Failed for type 2; Testing for type 3 :		.............	 OK !; Testing for type 4 :		.............	 OK !; Testing for type 5 :		.............	 OK !; Testing for type 6 :		.............	 OK !; Testing for type 7 :		.............	 OK !; Testing for type 8 :		.............	 OK !; Testing for type 9 :		.............	 OK !; Test sample quantiles FAILED ; CMake Error at /builddir/build/BUILD/root-6.08.04/cmake/modules/RootTestDriver.cmake:196 (message):; error code: 255. The PR implements the same check for type < 4 that is done later in the else clause for type >= 4. So this treats all types the same and the test failure goes away.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/359
https://github.com/root-project/root/pull/359:556,Testability,Test,Testing,556,7/602 Test #11: mathcore-testSampleQuantiles ...............................***Failed 2.24 sec; Test ordered data ....; Testing for type 7 :		.............	 OK !; Testing for type 1 :		.............	 OK !; Testing for type 2 :		.... Failed for prob = 0.3 - R gives 0.85 TMath gives 0.7; .. Failed for prob = 0.6 - R gives 1.65 TMath gives 1.5; Failed for prob = 0.7 - R gives 1.9 TMath gives 1.8; ....; Test Failed for type 2; Testing for type 3 :		.............	 OK !; Testing for type 4 :		.............	 OK !; Testing for type 5 :		.............	 OK !; Testing for type 6 :		.............	 OK !; Testing for type 7 :		.............	 OK !; Testing for type 8 :		.............	 OK !; Testing for type 9 :		.............	 OK !; Test data in random order....; Testing for type 7 :		.............	 OK !; Testing for type 1 :		.............	 OK !; Testing for type 2 :		.... Failed for prob = 0.3 - R gives 0.85 TMath gives 0.7; .. Failed for prob = 0.6 - R gives 1.65 TMath gives 1.5; Failed for prob = 0.7 - R gives 1.9 TMath gives 1.8; ....; Test Failed for type 2; Testing for type 3 :		.............	 OK !; Testing for type 4 :		.............	 OK !; Testing for type 5 :		.............	 OK !; Testing for type 6 :		.............	 OK !; Testing for type 7 :		.............	 OK !; Testing for type 8 :		.............	 OK !; Testing for type 9 :		.............	 OK !; Test sample quantiles FAILED ; CMake Error at /builddir/build/BUILD/root-6.08.04/cmake/modules/RootTestDriver.cmake:196 (message):; error code: 255. The PR implements the same check for type < 4 that is done later in the else clause for type >= 4. So this treats all types the same and the test failure goes away.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/359
https://github.com/root-project/root/pull/359:599,Testability,Test,Testing,599,7/602 Test #11: mathcore-testSampleQuantiles ...............................***Failed 2.24 sec; Test ordered data ....; Testing for type 7 :		.............	 OK !; Testing for type 1 :		.............	 OK !; Testing for type 2 :		.... Failed for prob = 0.3 - R gives 0.85 TMath gives 0.7; .. Failed for prob = 0.6 - R gives 1.65 TMath gives 1.5; Failed for prob = 0.7 - R gives 1.9 TMath gives 1.8; ....; Test Failed for type 2; Testing for type 3 :		.............	 OK !; Testing for type 4 :		.............	 OK !; Testing for type 5 :		.............	 OK !; Testing for type 6 :		.............	 OK !; Testing for type 7 :		.............	 OK !; Testing for type 8 :		.............	 OK !; Testing for type 9 :		.............	 OK !; Test data in random order....; Testing for type 7 :		.............	 OK !; Testing for type 1 :		.............	 OK !; Testing for type 2 :		.... Failed for prob = 0.3 - R gives 0.85 TMath gives 0.7; .. Failed for prob = 0.6 - R gives 1.65 TMath gives 1.5; Failed for prob = 0.7 - R gives 1.9 TMath gives 1.8; ....; Test Failed for type 2; Testing for type 3 :		.............	 OK !; Testing for type 4 :		.............	 OK !; Testing for type 5 :		.............	 OK !; Testing for type 6 :		.............	 OK !; Testing for type 7 :		.............	 OK !; Testing for type 8 :		.............	 OK !; Testing for type 9 :		.............	 OK !; Test sample quantiles FAILED ; CMake Error at /builddir/build/BUILD/root-6.08.04/cmake/modules/RootTestDriver.cmake:196 (message):; error code: 255. The PR implements the same check for type < 4 that is done later in the else clause for type >= 4. So this treats all types the same and the test failure goes away.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/359
https://github.com/root-project/root/pull/359:642,Testability,Test,Testing,642,7/602 Test #11: mathcore-testSampleQuantiles ...............................***Failed 2.24 sec; Test ordered data ....; Testing for type 7 :		.............	 OK !; Testing for type 1 :		.............	 OK !; Testing for type 2 :		.... Failed for prob = 0.3 - R gives 0.85 TMath gives 0.7; .. Failed for prob = 0.6 - R gives 1.65 TMath gives 1.5; Failed for prob = 0.7 - R gives 1.9 TMath gives 1.8; ....; Test Failed for type 2; Testing for type 3 :		.............	 OK !; Testing for type 4 :		.............	 OK !; Testing for type 5 :		.............	 OK !; Testing for type 6 :		.............	 OK !; Testing for type 7 :		.............	 OK !; Testing for type 8 :		.............	 OK !; Testing for type 9 :		.............	 OK !; Test data in random order....; Testing for type 7 :		.............	 OK !; Testing for type 1 :		.............	 OK !; Testing for type 2 :		.... Failed for prob = 0.3 - R gives 0.85 TMath gives 0.7; .. Failed for prob = 0.6 - R gives 1.65 TMath gives 1.5; Failed for prob = 0.7 - R gives 1.9 TMath gives 1.8; ....; Test Failed for type 2; Testing for type 3 :		.............	 OK !; Testing for type 4 :		.............	 OK !; Testing for type 5 :		.............	 OK !; Testing for type 6 :		.............	 OK !; Testing for type 7 :		.............	 OK !; Testing for type 8 :		.............	 OK !; Testing for type 9 :		.............	 OK !; Test sample quantiles FAILED ; CMake Error at /builddir/build/BUILD/root-6.08.04/cmake/modules/RootTestDriver.cmake:196 (message):; error code: 255. The PR implements the same check for type < 4 that is done later in the else clause for type >= 4. So this treats all types the same and the test failure goes away.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/359
https://github.com/root-project/root/pull/359:685,Testability,Test,Testing,685,7/602 Test #11: mathcore-testSampleQuantiles ...............................***Failed 2.24 sec; Test ordered data ....; Testing for type 7 :		.............	 OK !; Testing for type 1 :		.............	 OK !; Testing for type 2 :		.... Failed for prob = 0.3 - R gives 0.85 TMath gives 0.7; .. Failed for prob = 0.6 - R gives 1.65 TMath gives 1.5; Failed for prob = 0.7 - R gives 1.9 TMath gives 1.8; ....; Test Failed for type 2; Testing for type 3 :		.............	 OK !; Testing for type 4 :		.............	 OK !; Testing for type 5 :		.............	 OK !; Testing for type 6 :		.............	 OK !; Testing for type 7 :		.............	 OK !; Testing for type 8 :		.............	 OK !; Testing for type 9 :		.............	 OK !; Test data in random order....; Testing for type 7 :		.............	 OK !; Testing for type 1 :		.............	 OK !; Testing for type 2 :		.... Failed for prob = 0.3 - R gives 0.85 TMath gives 0.7; .. Failed for prob = 0.6 - R gives 1.65 TMath gives 1.5; Failed for prob = 0.7 - R gives 1.9 TMath gives 1.8; ....; Test Failed for type 2; Testing for type 3 :		.............	 OK !; Testing for type 4 :		.............	 OK !; Testing for type 5 :		.............	 OK !; Testing for type 6 :		.............	 OK !; Testing for type 7 :		.............	 OK !; Testing for type 8 :		.............	 OK !; Testing for type 9 :		.............	 OK !; Test sample quantiles FAILED ; CMake Error at /builddir/build/BUILD/root-6.08.04/cmake/modules/RootTestDriver.cmake:196 (message):; error code: 255. The PR implements the same check for type < 4 that is done later in the else clause for type >= 4. So this treats all types the same and the test failure goes away.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/359
https://github.com/root-project/root/pull/359:728,Testability,Test,Test,728,7/602 Test #11: mathcore-testSampleQuantiles ...............................***Failed 2.24 sec; Test ordered data ....; Testing for type 7 :		.............	 OK !; Testing for type 1 :		.............	 OK !; Testing for type 2 :		.... Failed for prob = 0.3 - R gives 0.85 TMath gives 0.7; .. Failed for prob = 0.6 - R gives 1.65 TMath gives 1.5; Failed for prob = 0.7 - R gives 1.9 TMath gives 1.8; ....; Test Failed for type 2; Testing for type 3 :		.............	 OK !; Testing for type 4 :		.............	 OK !; Testing for type 5 :		.............	 OK !; Testing for type 6 :		.............	 OK !; Testing for type 7 :		.............	 OK !; Testing for type 8 :		.............	 OK !; Testing for type 9 :		.............	 OK !; Test data in random order....; Testing for type 7 :		.............	 OK !; Testing for type 1 :		.............	 OK !; Testing for type 2 :		.... Failed for prob = 0.3 - R gives 0.85 TMath gives 0.7; .. Failed for prob = 0.6 - R gives 1.65 TMath gives 1.5; Failed for prob = 0.7 - R gives 1.9 TMath gives 1.8; ....; Test Failed for type 2; Testing for type 3 :		.............	 OK !; Testing for type 4 :		.............	 OK !; Testing for type 5 :		.............	 OK !; Testing for type 6 :		.............	 OK !; Testing for type 7 :		.............	 OK !; Testing for type 8 :		.............	 OK !; Testing for type 9 :		.............	 OK !; Test sample quantiles FAILED ; CMake Error at /builddir/build/BUILD/root-6.08.04/cmake/modules/RootTestDriver.cmake:196 (message):; error code: 255. The PR implements the same check for type < 4 that is done later in the else clause for type >= 4. So this treats all types the same and the test failure goes away.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/359
https://github.com/root-project/root/pull/359:759,Testability,Test,Testing,759,7/602 Test #11: mathcore-testSampleQuantiles ...............................***Failed 2.24 sec; Test ordered data ....; Testing for type 7 :		.............	 OK !; Testing for type 1 :		.............	 OK !; Testing for type 2 :		.... Failed for prob = 0.3 - R gives 0.85 TMath gives 0.7; .. Failed for prob = 0.6 - R gives 1.65 TMath gives 1.5; Failed for prob = 0.7 - R gives 1.9 TMath gives 1.8; ....; Test Failed for type 2; Testing for type 3 :		.............	 OK !; Testing for type 4 :		.............	 OK !; Testing for type 5 :		.............	 OK !; Testing for type 6 :		.............	 OK !; Testing for type 7 :		.............	 OK !; Testing for type 8 :		.............	 OK !; Testing for type 9 :		.............	 OK !; Test data in random order....; Testing for type 7 :		.............	 OK !; Testing for type 1 :		.............	 OK !; Testing for type 2 :		.... Failed for prob = 0.3 - R gives 0.85 TMath gives 0.7; .. Failed for prob = 0.6 - R gives 1.65 TMath gives 1.5; Failed for prob = 0.7 - R gives 1.9 TMath gives 1.8; ....; Test Failed for type 2; Testing for type 3 :		.............	 OK !; Testing for type 4 :		.............	 OK !; Testing for type 5 :		.............	 OK !; Testing for type 6 :		.............	 OK !; Testing for type 7 :		.............	 OK !; Testing for type 8 :		.............	 OK !; Testing for type 9 :		.............	 OK !; Test sample quantiles FAILED ; CMake Error at /builddir/build/BUILD/root-6.08.04/cmake/modules/RootTestDriver.cmake:196 (message):; error code: 255. The PR implements the same check for type < 4 that is done later in the else clause for type >= 4. So this treats all types the same and the test failure goes away.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/359
https://github.com/root-project/root/pull/359:802,Testability,Test,Testing,802,7/602 Test #11: mathcore-testSampleQuantiles ...............................***Failed 2.24 sec; Test ordered data ....; Testing for type 7 :		.............	 OK !; Testing for type 1 :		.............	 OK !; Testing for type 2 :		.... Failed for prob = 0.3 - R gives 0.85 TMath gives 0.7; .. Failed for prob = 0.6 - R gives 1.65 TMath gives 1.5; Failed for prob = 0.7 - R gives 1.9 TMath gives 1.8; ....; Test Failed for type 2; Testing for type 3 :		.............	 OK !; Testing for type 4 :		.............	 OK !; Testing for type 5 :		.............	 OK !; Testing for type 6 :		.............	 OK !; Testing for type 7 :		.............	 OK !; Testing for type 8 :		.............	 OK !; Testing for type 9 :		.............	 OK !; Test data in random order....; Testing for type 7 :		.............	 OK !; Testing for type 1 :		.............	 OK !; Testing for type 2 :		.... Failed for prob = 0.3 - R gives 0.85 TMath gives 0.7; .. Failed for prob = 0.6 - R gives 1.65 TMath gives 1.5; Failed for prob = 0.7 - R gives 1.9 TMath gives 1.8; ....; Test Failed for type 2; Testing for type 3 :		.............	 OK !; Testing for type 4 :		.............	 OK !; Testing for type 5 :		.............	 OK !; Testing for type 6 :		.............	 OK !; Testing for type 7 :		.............	 OK !; Testing for type 8 :		.............	 OK !; Testing for type 9 :		.............	 OK !; Test sample quantiles FAILED ; CMake Error at /builddir/build/BUILD/root-6.08.04/cmake/modules/RootTestDriver.cmake:196 (message):; error code: 255. The PR implements the same check for type < 4 that is done later in the else clause for type >= 4. So this treats all types the same and the test failure goes away.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/359
https://github.com/root-project/root/pull/359:845,Testability,Test,Testing,845,7/602 Test #11: mathcore-testSampleQuantiles ...............................***Failed 2.24 sec; Test ordered data ....; Testing for type 7 :		.............	 OK !; Testing for type 1 :		.............	 OK !; Testing for type 2 :		.... Failed for prob = 0.3 - R gives 0.85 TMath gives 0.7; .. Failed for prob = 0.6 - R gives 1.65 TMath gives 1.5; Failed for prob = 0.7 - R gives 1.9 TMath gives 1.8; ....; Test Failed for type 2; Testing for type 3 :		.............	 OK !; Testing for type 4 :		.............	 OK !; Testing for type 5 :		.............	 OK !; Testing for type 6 :		.............	 OK !; Testing for type 7 :		.............	 OK !; Testing for type 8 :		.............	 OK !; Testing for type 9 :		.............	 OK !; Test data in random order....; Testing for type 7 :		.............	 OK !; Testing for type 1 :		.............	 OK !; Testing for type 2 :		.... Failed for prob = 0.3 - R gives 0.85 TMath gives 0.7; .. Failed for prob = 0.6 - R gives 1.65 TMath gives 1.5; Failed for prob = 0.7 - R gives 1.9 TMath gives 1.8; ....; Test Failed for type 2; Testing for type 3 :		.............	 OK !; Testing for type 4 :		.............	 OK !; Testing for type 5 :		.............	 OK !; Testing for type 6 :		.............	 OK !; Testing for type 7 :		.............	 OK !; Testing for type 8 :		.............	 OK !; Testing for type 9 :		.............	 OK !; Test sample quantiles FAILED ; CMake Error at /builddir/build/BUILD/root-6.08.04/cmake/modules/RootTestDriver.cmake:196 (message):; error code: 255. The PR implements the same check for type < 4 that is done later in the else clause for type >= 4. So this treats all types the same and the test failure goes away.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/359
https://github.com/root-project/root/pull/359:1042,Testability,Test,Test,1042,7/602 Test #11: mathcore-testSampleQuantiles ...............................***Failed 2.24 sec; Test ordered data ....; Testing for type 7 :		.............	 OK !; Testing for type 1 :		.............	 OK !; Testing for type 2 :		.... Failed for prob = 0.3 - R gives 0.85 TMath gives 0.7; .. Failed for prob = 0.6 - R gives 1.65 TMath gives 1.5; Failed for prob = 0.7 - R gives 1.9 TMath gives 1.8; ....; Test Failed for type 2; Testing for type 3 :		.............	 OK !; Testing for type 4 :		.............	 OK !; Testing for type 5 :		.............	 OK !; Testing for type 6 :		.............	 OK !; Testing for type 7 :		.............	 OK !; Testing for type 8 :		.............	 OK !; Testing for type 9 :		.............	 OK !; Test data in random order....; Testing for type 7 :		.............	 OK !; Testing for type 1 :		.............	 OK !; Testing for type 2 :		.... Failed for prob = 0.3 - R gives 0.85 TMath gives 0.7; .. Failed for prob = 0.6 - R gives 1.65 TMath gives 1.5; Failed for prob = 0.7 - R gives 1.9 TMath gives 1.8; ....; Test Failed for type 2; Testing for type 3 :		.............	 OK !; Testing for type 4 :		.............	 OK !; Testing for type 5 :		.............	 OK !; Testing for type 6 :		.............	 OK !; Testing for type 7 :		.............	 OK !; Testing for type 8 :		.............	 OK !; Testing for type 9 :		.............	 OK !; Test sample quantiles FAILED ; CMake Error at /builddir/build/BUILD/root-6.08.04/cmake/modules/RootTestDriver.cmake:196 (message):; error code: 255. The PR implements the same check for type < 4 that is done later in the else clause for type >= 4. So this treats all types the same and the test failure goes away.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/359
https://github.com/root-project/root/pull/359:1066,Testability,Test,Testing,1066,7/602 Test #11: mathcore-testSampleQuantiles ...............................***Failed 2.24 sec; Test ordered data ....; Testing for type 7 :		.............	 OK !; Testing for type 1 :		.............	 OK !; Testing for type 2 :		.... Failed for prob = 0.3 - R gives 0.85 TMath gives 0.7; .. Failed for prob = 0.6 - R gives 1.65 TMath gives 1.5; Failed for prob = 0.7 - R gives 1.9 TMath gives 1.8; ....; Test Failed for type 2; Testing for type 3 :		.............	 OK !; Testing for type 4 :		.............	 OK !; Testing for type 5 :		.............	 OK !; Testing for type 6 :		.............	 OK !; Testing for type 7 :		.............	 OK !; Testing for type 8 :		.............	 OK !; Testing for type 9 :		.............	 OK !; Test data in random order....; Testing for type 7 :		.............	 OK !; Testing for type 1 :		.............	 OK !; Testing for type 2 :		.... Failed for prob = 0.3 - R gives 0.85 TMath gives 0.7; .. Failed for prob = 0.6 - R gives 1.65 TMath gives 1.5; Failed for prob = 0.7 - R gives 1.9 TMath gives 1.8; ....; Test Failed for type 2; Testing for type 3 :		.............	 OK !; Testing for type 4 :		.............	 OK !; Testing for type 5 :		.............	 OK !; Testing for type 6 :		.............	 OK !; Testing for type 7 :		.............	 OK !; Testing for type 8 :		.............	 OK !; Testing for type 9 :		.............	 OK !; Test sample quantiles FAILED ; CMake Error at /builddir/build/BUILD/root-6.08.04/cmake/modules/RootTestDriver.cmake:196 (message):; error code: 255. The PR implements the same check for type < 4 that is done later in the else clause for type >= 4. So this treats all types the same and the test failure goes away.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/359
https://github.com/root-project/root/pull/359:1109,Testability,Test,Testing,1109,7/602 Test #11: mathcore-testSampleQuantiles ...............................***Failed 2.24 sec; Test ordered data ....; Testing for type 7 :		.............	 OK !; Testing for type 1 :		.............	 OK !; Testing for type 2 :		.... Failed for prob = 0.3 - R gives 0.85 TMath gives 0.7; .. Failed for prob = 0.6 - R gives 1.65 TMath gives 1.5; Failed for prob = 0.7 - R gives 1.9 TMath gives 1.8; ....; Test Failed for type 2; Testing for type 3 :		.............	 OK !; Testing for type 4 :		.............	 OK !; Testing for type 5 :		.............	 OK !; Testing for type 6 :		.............	 OK !; Testing for type 7 :		.............	 OK !; Testing for type 8 :		.............	 OK !; Testing for type 9 :		.............	 OK !; Test data in random order....; Testing for type 7 :		.............	 OK !; Testing for type 1 :		.............	 OK !; Testing for type 2 :		.... Failed for prob = 0.3 - R gives 0.85 TMath gives 0.7; .. Failed for prob = 0.6 - R gives 1.65 TMath gives 1.5; Failed for prob = 0.7 - R gives 1.9 TMath gives 1.8; ....; Test Failed for type 2; Testing for type 3 :		.............	 OK !; Testing for type 4 :		.............	 OK !; Testing for type 5 :		.............	 OK !; Testing for type 6 :		.............	 OK !; Testing for type 7 :		.............	 OK !; Testing for type 8 :		.............	 OK !; Testing for type 9 :		.............	 OK !; Test sample quantiles FAILED ; CMake Error at /builddir/build/BUILD/root-6.08.04/cmake/modules/RootTestDriver.cmake:196 (message):; error code: 255. The PR implements the same check for type < 4 that is done later in the else clause for type >= 4. So this treats all types the same and the test failure goes away.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/359
https://github.com/root-project/root/pull/359:1152,Testability,Test,Testing,1152,7/602 Test #11: mathcore-testSampleQuantiles ...............................***Failed 2.24 sec; Test ordered data ....; Testing for type 7 :		.............	 OK !; Testing for type 1 :		.............	 OK !; Testing for type 2 :		.... Failed for prob = 0.3 - R gives 0.85 TMath gives 0.7; .. Failed for prob = 0.6 - R gives 1.65 TMath gives 1.5; Failed for prob = 0.7 - R gives 1.9 TMath gives 1.8; ....; Test Failed for type 2; Testing for type 3 :		.............	 OK !; Testing for type 4 :		.............	 OK !; Testing for type 5 :		.............	 OK !; Testing for type 6 :		.............	 OK !; Testing for type 7 :		.............	 OK !; Testing for type 8 :		.............	 OK !; Testing for type 9 :		.............	 OK !; Test data in random order....; Testing for type 7 :		.............	 OK !; Testing for type 1 :		.............	 OK !; Testing for type 2 :		.... Failed for prob = 0.3 - R gives 0.85 TMath gives 0.7; .. Failed for prob = 0.6 - R gives 1.65 TMath gives 1.5; Failed for prob = 0.7 - R gives 1.9 TMath gives 1.8; ....; Test Failed for type 2; Testing for type 3 :		.............	 OK !; Testing for type 4 :		.............	 OK !; Testing for type 5 :		.............	 OK !; Testing for type 6 :		.............	 OK !; Testing for type 7 :		.............	 OK !; Testing for type 8 :		.............	 OK !; Testing for type 9 :		.............	 OK !; Test sample quantiles FAILED ; CMake Error at /builddir/build/BUILD/root-6.08.04/cmake/modules/RootTestDriver.cmake:196 (message):; error code: 255. The PR implements the same check for type < 4 that is done later in the else clause for type >= 4. So this treats all types the same and the test failure goes away.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/359
https://github.com/root-project/root/pull/359:1195,Testability,Test,Testing,1195,7/602 Test #11: mathcore-testSampleQuantiles ...............................***Failed 2.24 sec; Test ordered data ....; Testing for type 7 :		.............	 OK !; Testing for type 1 :		.............	 OK !; Testing for type 2 :		.... Failed for prob = 0.3 - R gives 0.85 TMath gives 0.7; .. Failed for prob = 0.6 - R gives 1.65 TMath gives 1.5; Failed for prob = 0.7 - R gives 1.9 TMath gives 1.8; ....; Test Failed for type 2; Testing for type 3 :		.............	 OK !; Testing for type 4 :		.............	 OK !; Testing for type 5 :		.............	 OK !; Testing for type 6 :		.............	 OK !; Testing for type 7 :		.............	 OK !; Testing for type 8 :		.............	 OK !; Testing for type 9 :		.............	 OK !; Test data in random order....; Testing for type 7 :		.............	 OK !; Testing for type 1 :		.............	 OK !; Testing for type 2 :		.... Failed for prob = 0.3 - R gives 0.85 TMath gives 0.7; .. Failed for prob = 0.6 - R gives 1.65 TMath gives 1.5; Failed for prob = 0.7 - R gives 1.9 TMath gives 1.8; ....; Test Failed for type 2; Testing for type 3 :		.............	 OK !; Testing for type 4 :		.............	 OK !; Testing for type 5 :		.............	 OK !; Testing for type 6 :		.............	 OK !; Testing for type 7 :		.............	 OK !; Testing for type 8 :		.............	 OK !; Testing for type 9 :		.............	 OK !; Test sample quantiles FAILED ; CMake Error at /builddir/build/BUILD/root-6.08.04/cmake/modules/RootTestDriver.cmake:196 (message):; error code: 255. The PR implements the same check for type < 4 that is done later in the else clause for type >= 4. So this treats all types the same and the test failure goes away.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/359
https://github.com/root-project/root/pull/359:1238,Testability,Test,Testing,1238,7/602 Test #11: mathcore-testSampleQuantiles ...............................***Failed 2.24 sec; Test ordered data ....; Testing for type 7 :		.............	 OK !; Testing for type 1 :		.............	 OK !; Testing for type 2 :		.... Failed for prob = 0.3 - R gives 0.85 TMath gives 0.7; .. Failed for prob = 0.6 - R gives 1.65 TMath gives 1.5; Failed for prob = 0.7 - R gives 1.9 TMath gives 1.8; ....; Test Failed for type 2; Testing for type 3 :		.............	 OK !; Testing for type 4 :		.............	 OK !; Testing for type 5 :		.............	 OK !; Testing for type 6 :		.............	 OK !; Testing for type 7 :		.............	 OK !; Testing for type 8 :		.............	 OK !; Testing for type 9 :		.............	 OK !; Test data in random order....; Testing for type 7 :		.............	 OK !; Testing for type 1 :		.............	 OK !; Testing for type 2 :		.... Failed for prob = 0.3 - R gives 0.85 TMath gives 0.7; .. Failed for prob = 0.6 - R gives 1.65 TMath gives 1.5; Failed for prob = 0.7 - R gives 1.9 TMath gives 1.8; ....; Test Failed for type 2; Testing for type 3 :		.............	 OK !; Testing for type 4 :		.............	 OK !; Testing for type 5 :		.............	 OK !; Testing for type 6 :		.............	 OK !; Testing for type 7 :		.............	 OK !; Testing for type 8 :		.............	 OK !; Testing for type 9 :		.............	 OK !; Test sample quantiles FAILED ; CMake Error at /builddir/build/BUILD/root-6.08.04/cmake/modules/RootTestDriver.cmake:196 (message):; error code: 255. The PR implements the same check for type < 4 that is done later in the else clause for type >= 4. So this treats all types the same and the test failure goes away.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/359
https://github.com/root-project/root/pull/359:1281,Testability,Test,Testing,1281,7/602 Test #11: mathcore-testSampleQuantiles ...............................***Failed 2.24 sec; Test ordered data ....; Testing for type 7 :		.............	 OK !; Testing for type 1 :		.............	 OK !; Testing for type 2 :		.... Failed for prob = 0.3 - R gives 0.85 TMath gives 0.7; .. Failed for prob = 0.6 - R gives 1.65 TMath gives 1.5; Failed for prob = 0.7 - R gives 1.9 TMath gives 1.8; ....; Test Failed for type 2; Testing for type 3 :		.............	 OK !; Testing for type 4 :		.............	 OK !; Testing for type 5 :		.............	 OK !; Testing for type 6 :		.............	 OK !; Testing for type 7 :		.............	 OK !; Testing for type 8 :		.............	 OK !; Testing for type 9 :		.............	 OK !; Test data in random order....; Testing for type 7 :		.............	 OK !; Testing for type 1 :		.............	 OK !; Testing for type 2 :		.... Failed for prob = 0.3 - R gives 0.85 TMath gives 0.7; .. Failed for prob = 0.6 - R gives 1.65 TMath gives 1.5; Failed for prob = 0.7 - R gives 1.9 TMath gives 1.8; ....; Test Failed for type 2; Testing for type 3 :		.............	 OK !; Testing for type 4 :		.............	 OK !; Testing for type 5 :		.............	 OK !; Testing for type 6 :		.............	 OK !; Testing for type 7 :		.............	 OK !; Testing for type 8 :		.............	 OK !; Testing for type 9 :		.............	 OK !; Test sample quantiles FAILED ; CMake Error at /builddir/build/BUILD/root-6.08.04/cmake/modules/RootTestDriver.cmake:196 (message):; error code: 255. The PR implements the same check for type < 4 that is done later in the else clause for type >= 4. So this treats all types the same and the test failure goes away.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/359
https://github.com/root-project/root/pull/359:1324,Testability,Test,Testing,1324,7/602 Test #11: mathcore-testSampleQuantiles ...............................***Failed 2.24 sec; Test ordered data ....; Testing for type 7 :		.............	 OK !; Testing for type 1 :		.............	 OK !; Testing for type 2 :		.... Failed for prob = 0.3 - R gives 0.85 TMath gives 0.7; .. Failed for prob = 0.6 - R gives 1.65 TMath gives 1.5; Failed for prob = 0.7 - R gives 1.9 TMath gives 1.8; ....; Test Failed for type 2; Testing for type 3 :		.............	 OK !; Testing for type 4 :		.............	 OK !; Testing for type 5 :		.............	 OK !; Testing for type 6 :		.............	 OK !; Testing for type 7 :		.............	 OK !; Testing for type 8 :		.............	 OK !; Testing for type 9 :		.............	 OK !; Test data in random order....; Testing for type 7 :		.............	 OK !; Testing for type 1 :		.............	 OK !; Testing for type 2 :		.... Failed for prob = 0.3 - R gives 0.85 TMath gives 0.7; .. Failed for prob = 0.6 - R gives 1.65 TMath gives 1.5; Failed for prob = 0.7 - R gives 1.9 TMath gives 1.8; ....; Test Failed for type 2; Testing for type 3 :		.............	 OK !; Testing for type 4 :		.............	 OK !; Testing for type 5 :		.............	 OK !; Testing for type 6 :		.............	 OK !; Testing for type 7 :		.............	 OK !; Testing for type 8 :		.............	 OK !; Testing for type 9 :		.............	 OK !; Test sample quantiles FAILED ; CMake Error at /builddir/build/BUILD/root-6.08.04/cmake/modules/RootTestDriver.cmake:196 (message):; error code: 255. The PR implements the same check for type < 4 that is done later in the else clause for type >= 4. So this treats all types the same and the test failure goes away.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/359
https://github.com/root-project/root/pull/359:1367,Testability,Test,Test,1367,7/602 Test #11: mathcore-testSampleQuantiles ...............................***Failed 2.24 sec; Test ordered data ....; Testing for type 7 :		.............	 OK !; Testing for type 1 :		.............	 OK !; Testing for type 2 :		.... Failed for prob = 0.3 - R gives 0.85 TMath gives 0.7; .. Failed for prob = 0.6 - R gives 1.65 TMath gives 1.5; Failed for prob = 0.7 - R gives 1.9 TMath gives 1.8; ....; Test Failed for type 2; Testing for type 3 :		.............	 OK !; Testing for type 4 :		.............	 OK !; Testing for type 5 :		.............	 OK !; Testing for type 6 :		.............	 OK !; Testing for type 7 :		.............	 OK !; Testing for type 8 :		.............	 OK !; Testing for type 9 :		.............	 OK !; Test data in random order....; Testing for type 7 :		.............	 OK !; Testing for type 1 :		.............	 OK !; Testing for type 2 :		.... Failed for prob = 0.3 - R gives 0.85 TMath gives 0.7; .. Failed for prob = 0.6 - R gives 1.65 TMath gives 1.5; Failed for prob = 0.7 - R gives 1.9 TMath gives 1.8; ....; Test Failed for type 2; Testing for type 3 :		.............	 OK !; Testing for type 4 :		.............	 OK !; Testing for type 5 :		.............	 OK !; Testing for type 6 :		.............	 OK !; Testing for type 7 :		.............	 OK !; Testing for type 8 :		.............	 OK !; Testing for type 9 :		.............	 OK !; Test sample quantiles FAILED ; CMake Error at /builddir/build/BUILD/root-6.08.04/cmake/modules/RootTestDriver.cmake:196 (message):; error code: 255. The PR implements the same check for type < 4 that is done later in the else clause for type >= 4. So this treats all types the same and the test failure goes away.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/359
https://github.com/root-project/root/pull/359:1657,Testability,test,test,1657,7/602 Test #11: mathcore-testSampleQuantiles ...............................***Failed 2.24 sec; Test ordered data ....; Testing for type 7 :		.............	 OK !; Testing for type 1 :		.............	 OK !; Testing for type 2 :		.... Failed for prob = 0.3 - R gives 0.85 TMath gives 0.7; .. Failed for prob = 0.6 - R gives 1.65 TMath gives 1.5; Failed for prob = 0.7 - R gives 1.9 TMath gives 1.8; ....; Test Failed for type 2; Testing for type 3 :		.............	 OK !; Testing for type 4 :		.............	 OK !; Testing for type 5 :		.............	 OK !; Testing for type 6 :		.............	 OK !; Testing for type 7 :		.............	 OK !; Testing for type 8 :		.............	 OK !; Testing for type 9 :		.............	 OK !; Test data in random order....; Testing for type 7 :		.............	 OK !; Testing for type 1 :		.............	 OK !; Testing for type 2 :		.... Failed for prob = 0.3 - R gives 0.85 TMath gives 0.7; .. Failed for prob = 0.6 - R gives 1.65 TMath gives 1.5; Failed for prob = 0.7 - R gives 1.9 TMath gives 1.8; ....; Test Failed for type 2; Testing for type 3 :		.............	 OK !; Testing for type 4 :		.............	 OK !; Testing for type 5 :		.............	 OK !; Testing for type 6 :		.............	 OK !; Testing for type 7 :		.............	 OK !; Testing for type 8 :		.............	 OK !; Testing for type 9 :		.............	 OK !; Test sample quantiles FAILED ; CMake Error at /builddir/build/BUILD/root-6.08.04/cmake/modules/RootTestDriver.cmake:196 (message):; error code: 255. The PR implements the same check for type < 4 that is done later in the else clause for type >= 4. So this treats all types the same and the test failure goes away.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/359
https://github.com/root-project/root/pull/360:32,Availability,Down,Download,32,- Update Vc to version 1.3.0; - Download from LCG at CERN (Vc-1.3.0 not yet available at service-spi.web.cern.ch); - Use same compiler options and installation prefix as ROOT; - Configure and install Vc into CMake binary directory; - Install at the end with the rest of ROOT,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/360
https://github.com/root-project/root/pull/360:76,Availability,avail,available,76,- Update Vc to version 1.3.0; - Download from LCG at CERN (Vc-1.3.0 not yet available at service-spi.web.cern.ch); - Use same compiler options and installation prefix as ROOT; - Configure and install Vc into CMake binary directory; - Install at the end with the rest of ROOT,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/360
https://github.com/root-project/root/pull/360:2,Deployability,Update,Update,2,- Update Vc to version 1.3.0; - Download from LCG at CERN (Vc-1.3.0 not yet available at service-spi.web.cern.ch); - Use same compiler options and installation prefix as ROOT; - Configure and install Vc into CMake binary directory; - Install at the end with the rest of ROOT,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/360
https://github.com/root-project/root/pull/360:147,Deployability,install,installation,147,- Update Vc to version 1.3.0; - Download from LCG at CERN (Vc-1.3.0 not yet available at service-spi.web.cern.ch); - Use same compiler options and installation prefix as ROOT; - Configure and install Vc into CMake binary directory; - Install at the end with the rest of ROOT,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/360
https://github.com/root-project/root/pull/360:192,Deployability,install,install,192,- Update Vc to version 1.3.0; - Download from LCG at CERN (Vc-1.3.0 not yet available at service-spi.web.cern.ch); - Use same compiler options and installation prefix as ROOT; - Configure and install Vc into CMake binary directory; - Install at the end with the rest of ROOT,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/360
https://github.com/root-project/root/pull/360:234,Deployability,Install,Install,234,- Update Vc to version 1.3.0; - Download from LCG at CERN (Vc-1.3.0 not yet available at service-spi.web.cern.ch); - Use same compiler options and installation prefix as ROOT; - Configure and install Vc into CMake binary directory; - Install at the end with the rest of ROOT,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/360
https://github.com/root-project/root/pull/360:178,Modifiability,Config,Configure,178,- Update Vc to version 1.3.0; - Download from LCG at CERN (Vc-1.3.0 not yet available at service-spi.web.cern.ch); - Use same compiler options and installation prefix as ROOT; - Configure and install Vc into CMake binary directory; - Install at the end with the rest of ROOT,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/360
https://github.com/root-project/root/pull/362:219,Performance,race condition,race condition,219,"Some of the tests in `tutorials/roostats/` uses the file `example_combined_GaussExample_model.root`. If this file does not exist, one of the tests will create it. As these are executed in parallel, there is a chance of race condition and one of the tests might fail, as seen in this build: http://cdash.cern.ch/testDetails.php?test=22401472&build=324697; This PR attempts to fix this by executing all tests sequentially that uses the file `example_combined_GaussExample_model.root`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/362
https://github.com/root-project/root/pull/362:12,Testability,test,tests,12,"Some of the tests in `tutorials/roostats/` uses the file `example_combined_GaussExample_model.root`. If this file does not exist, one of the tests will create it. As these are executed in parallel, there is a chance of race condition and one of the tests might fail, as seen in this build: http://cdash.cern.ch/testDetails.php?test=22401472&build=324697; This PR attempts to fix this by executing all tests sequentially that uses the file `example_combined_GaussExample_model.root`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/362
https://github.com/root-project/root/pull/362:141,Testability,test,tests,141,"Some of the tests in `tutorials/roostats/` uses the file `example_combined_GaussExample_model.root`. If this file does not exist, one of the tests will create it. As these are executed in parallel, there is a chance of race condition and one of the tests might fail, as seen in this build: http://cdash.cern.ch/testDetails.php?test=22401472&build=324697; This PR attempts to fix this by executing all tests sequentially that uses the file `example_combined_GaussExample_model.root`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/362
https://github.com/root-project/root/pull/362:249,Testability,test,tests,249,"Some of the tests in `tutorials/roostats/` uses the file `example_combined_GaussExample_model.root`. If this file does not exist, one of the tests will create it. As these are executed in parallel, there is a chance of race condition and one of the tests might fail, as seen in this build: http://cdash.cern.ch/testDetails.php?test=22401472&build=324697; This PR attempts to fix this by executing all tests sequentially that uses the file `example_combined_GaussExample_model.root`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/362
https://github.com/root-project/root/pull/362:311,Testability,test,testDetails,311,"Some of the tests in `tutorials/roostats/` uses the file `example_combined_GaussExample_model.root`. If this file does not exist, one of the tests will create it. As these are executed in parallel, there is a chance of race condition and one of the tests might fail, as seen in this build: http://cdash.cern.ch/testDetails.php?test=22401472&build=324697; This PR attempts to fix this by executing all tests sequentially that uses the file `example_combined_GaussExample_model.root`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/362
https://github.com/root-project/root/pull/362:327,Testability,test,test,327,"Some of the tests in `tutorials/roostats/` uses the file `example_combined_GaussExample_model.root`. If this file does not exist, one of the tests will create it. As these are executed in parallel, there is a chance of race condition and one of the tests might fail, as seen in this build: http://cdash.cern.ch/testDetails.php?test=22401472&build=324697; This PR attempts to fix this by executing all tests sequentially that uses the file `example_combined_GaussExample_model.root`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/362
https://github.com/root-project/root/pull/362:401,Testability,test,tests,401,"Some of the tests in `tutorials/roostats/` uses the file `example_combined_GaussExample_model.root`. If this file does not exist, one of the tests will create it. As these are executed in parallel, there is a chance of race condition and one of the tests might fail, as seen in this build: http://cdash.cern.ch/testDetails.php?test=22401472&build=324697; This PR attempts to fix this by executing all tests sequentially that uses the file `example_combined_GaussExample_model.root`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/362
https://github.com/root-project/root/pull/363:423,Deployability,patch,patch,423,"Hi,. not entirely sure if this has been discussed already, i just noticed i hadn't pushed this one to a public server yet. RooDataSets can already be converted from Tree to Vector storage, but to export RooFit data to a standard root TTree and then do ""normal root things"" with it, the reverse direction is also needed and at to my best knowledge a bit cumbersome (juggeling with DataStore classes, as encapsulated in this patch). for the record `RooDataSet::setDefaultStorageType(RooAbsData::Tree)` exists, though i assume there are cases where one only doesn't want to globally flip the switch. What probably should be thought over is the ownership management: i let the dataset keep ownership with `tree()` (and a reference is passed). and transfer ownership with `export_tree()` and a copy of the data is passed. Therefore `tree()` will still return a `nullptr` if vector storage is used and the user has to explicitly trigger the conversion if they want a reference to the internal tree. (the name `export_tree()` can be changed into something more coherent with method naming conventions.). Cheers,; Paul",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/363
https://github.com/root-project/root/pull/365:90,Integrability,depend,dependency,90,Extracted the code that makes generates an example file into its own file and made this a dependency of the others.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/365
https://github.com/root-project/root/pull/367:115,Deployability,integrat,integration,115,"Change the structure of BinData, FitData to a more data-oriented one. This is the second in a series of PR for the integration of the vectorization + parallelization of the fit in ROOT.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/367
https://github.com/root-project/root/pull/367:115,Integrability,integrat,integration,115,"Change the structure of BinData, FitData to a more data-oriented one. This is the second in a series of PR for the integration of the vectorization + parallelization of the fit in ROOT.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/367
https://github.com/root-project/root/pull/368:39,Testability,test,testSummary,39,Fixes this issue: http://cdash.cern.ch/testSummary.php?project=1&name=tutorial-hist-candlehisto&date=2017-02-24,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/368
https://github.com/root-project/root/pull/369:41,Performance,Optimiz,OptimizeBaskets,41,"Hi,. when doing some more testing on the OptimizeBaskets() changes made last year, I found that getting the numbers of entries in the basket causes a disc read for each branch. This could be expensive and it is better to use the numbers of entries in the tree instead, as OptimizeBaskets() is called only on the first flush and most branches will have only one basket. Larger branches, may have more baskets, but overestimating their size by a few bytes is still a good approximation (and much better than an additional 4,000 disc reads (e.g. for ATLAS xAOD)). Thanks, Peter",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/369
https://github.com/root-project/root/pull/369:272,Performance,Optimiz,OptimizeBaskets,272,"Hi,. when doing some more testing on the OptimizeBaskets() changes made last year, I found that getting the numbers of entries in the basket causes a disc read for each branch. This could be expensive and it is better to use the numbers of entries in the tree instead, as OptimizeBaskets() is called only on the first flush and most branches will have only one basket. Larger branches, may have more baskets, but overestimating their size by a few bytes is still a good approximation (and much better than an additional 4,000 disc reads (e.g. for ATLAS xAOD)). Thanks, Peter",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/369
https://github.com/root-project/root/pull/369:26,Testability,test,testing,26,"Hi,. when doing some more testing on the OptimizeBaskets() changes made last year, I found that getting the numbers of entries in the basket causes a disc read for each branch. This could be expensive and it is better to use the numbers of entries in the tree instead, as OptimizeBaskets() is called only on the first flush and most branches will have only one basket. Larger branches, may have more baskets, but overestimating their size by a few bytes is still a good approximation (and much better than an additional 4,000 disc reads (e.g. for ATLAS xAOD)). Thanks, Peter",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/369
https://github.com/root-project/root/pull/370:182,Availability,error,error,182,"- using references instead of const shared pointers in the constructors of filters, temporary branches and actions (thanks @karies); - the output of tdf001_introduction contained an error due to a branch name mismatch",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/370
https://github.com/root-project/root/pull/375:12,Deployability,update,updated,12,"Hi guys,; * updated PyMVA with support for scikit-learn >= 0.18; * support for python 2 and 3. Best; Omar.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/375
https://github.com/root-project/root/pull/375:50,Usability,learn,learn,50,"Hi guys,; * updated PyMVA with support for scikit-learn >= 0.18; * support for python 2 and 3. Best; Omar.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/375
https://github.com/root-project/root/pull/376:1694,Availability,error,error,1694,"/builddir/build/BUILD/root-6.08.04/net/globusauth/src/GlobusAuth.cxx:143:26: warning: format '%x' expects argument of type 'unsigned int', but argument 3 has type 'gss_cred_id_t {aka gss_cred_id_desc_struct*}' [-Wformat=]; /builddir/build/BUILD/root-6.08.04/net/globusauth/src/GlobusAuth.cxx:196:40: warning: format '%d' expects argument of type 'int', but argument 4 has type 'size_t {aka long unsigned int}' [-Wformat=]; /builddir/build/BUILD/root-6.08.04/net/globusauth/src/GlobusAuth.cxx:243:47: warning: format '%d' expects argument of type 'int', but argument 3 has type 'size_t {aka long unsigned int}' [-Wformat=]; /builddir/build/BUILD/root-6.08.04/net/globusauth/src/GlobusAuth.cxx:265:79: warning: format '%p' expects argument of type 'void*', but argument 3 has type 'OM_uint32 {aka unsigned int}' [-Wformat=]; /builddir/build/BUILD/root-6.08.04/net/globusauth/src/GlobusAuth.cxx:421:29: warning: format '%x' expects argument of type 'unsigned int', but argument 3 has type 'gss_cred_id_t {aka gss_cred_id_desc_struct*}' [-Wformat=]; /builddir/build/BUILD/root-6.08.04/net/globusauth/src/GlobusAuth.cxx:498:35: warning: format '%x' expects argument of type 'unsigned int', but argument 3 has type 'gss_cred_id_t {aka gss_cred_id_desc_struct*}' [-Wformat=]; /builddir/build/BUILD/root-6.08.04/net/globusauth/src/GlobusAuth.cxx:666:53: warning: format '%s' expects a matching 'char*' argument [-Wformat=]; /builddir/build/BUILD/root-6.08.04/net/globusauth/src/GlobusAuth.cxx:733:72: warning: format '%d' expects argument of type 'int', but argument 4 has type 'size_t {aka long unsigned int}' [-Wformat=]; /builddir/build/BUILD/root-6.08.04/net/globusauth/src/GlobusAuth.cxx:1013:47: error: format not a string literal and no format arguments [-Werror=format-security]",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/376
https://github.com/root-project/root/pull/376:1769,Security,secur,security,1769,"/builddir/build/BUILD/root-6.08.04/net/globusauth/src/GlobusAuth.cxx:143:26: warning: format '%x' expects argument of type 'unsigned int', but argument 3 has type 'gss_cred_id_t {aka gss_cred_id_desc_struct*}' [-Wformat=]; /builddir/build/BUILD/root-6.08.04/net/globusauth/src/GlobusAuth.cxx:196:40: warning: format '%d' expects argument of type 'int', but argument 4 has type 'size_t {aka long unsigned int}' [-Wformat=]; /builddir/build/BUILD/root-6.08.04/net/globusauth/src/GlobusAuth.cxx:243:47: warning: format '%d' expects argument of type 'int', but argument 3 has type 'size_t {aka long unsigned int}' [-Wformat=]; /builddir/build/BUILD/root-6.08.04/net/globusauth/src/GlobusAuth.cxx:265:79: warning: format '%p' expects argument of type 'void*', but argument 3 has type 'OM_uint32 {aka unsigned int}' [-Wformat=]; /builddir/build/BUILD/root-6.08.04/net/globusauth/src/GlobusAuth.cxx:421:29: warning: format '%x' expects argument of type 'unsigned int', but argument 3 has type 'gss_cred_id_t {aka gss_cred_id_desc_struct*}' [-Wformat=]; /builddir/build/BUILD/root-6.08.04/net/globusauth/src/GlobusAuth.cxx:498:35: warning: format '%x' expects argument of type 'unsigned int', but argument 3 has type 'gss_cred_id_t {aka gss_cred_id_desc_struct*}' [-Wformat=]; /builddir/build/BUILD/root-6.08.04/net/globusauth/src/GlobusAuth.cxx:666:53: warning: format '%s' expects a matching 'char*' argument [-Wformat=]; /builddir/build/BUILD/root-6.08.04/net/globusauth/src/GlobusAuth.cxx:733:72: warning: format '%d' expects argument of type 'int', but argument 4 has type 'size_t {aka long unsigned int}' [-Wformat=]; /builddir/build/BUILD/root-6.08.04/net/globusauth/src/GlobusAuth.cxx:1013:47: error: format not a string literal and no format arguments [-Werror=format-security]",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/376
https://github.com/root-project/root/pull/377:143,Testability,test,test,143,"When it tries to draw the last diagram, it freezes on some builds. Instead, ignore drawing if we are in batch mode. This PR fixes this failing test:; http://cdash.cern.ch/testDetails.php?test=22567643&build=326532",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/377
https://github.com/root-project/root/pull/377:171,Testability,test,testDetails,171,"When it tries to draw the last diagram, it freezes on some builds. Instead, ignore drawing if we are in batch mode. This PR fixes this failing test:; http://cdash.cern.ch/testDetails.php?test=22567643&build=326532",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/377
https://github.com/root-project/root/pull/377:187,Testability,test,test,187,"When it tries to draw the last diagram, it freezes on some builds. Instead, ignore drawing if we are in batch mode. This PR fixes this failing test:; http://cdash.cern.ch/testDetails.php?test=22567643&build=326532",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/377
https://github.com/root-project/root/pull/380:97,Testability,test,testing,97,"Adding support for generation of multiclass 1 vs. all ROC curve plots. I also have two files for testing the binary and multiclass code paths, but am unsure of where to put these if anywhere. They are 2 standalone cxx files to generate data, train classifiers, draw the roc curves and succeeds if they do not crash.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/380
https://github.com/root-project/root/pull/384:24,Availability,redundant,redundant,24,coverity 94012: removed redundant unreachable return statement			89a4a67; coverity 82573: fixed copy paste error fXaxis to fZaxis			1f8f137; coverity 82274: fixed uninitialised class members,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/384
https://github.com/root-project/root/pull/384:107,Availability,error,error,107,coverity 94012: removed redundant unreachable return statement			89a4a67; coverity 82573: fixed copy paste error fXaxis to fZaxis			1f8f137; coverity 82274: fixed uninitialised class members,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/384
https://github.com/root-project/root/pull/384:24,Safety,redund,redundant,24,coverity 94012: removed redundant unreachable return statement			89a4a67; coverity 82573: fixed copy paste error fXaxis to fZaxis			1f8f137; coverity 82274: fixed uninitialised class members,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/384
https://github.com/root-project/root/pull/389:94,Availability,echo,echo,94,It seems that execvp can't handle such longs args on the build nodes and; fails when we call `echo $ARGS >> modulemap`. We now first write this to a file and then append it to the actual; modulemap.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/389
https://github.com/root-project/root/pull/391:63,Usability,Guid,Guide,63,- Add PyMVA introduction and Keras documentation to TMVA Users Guide.; - Set default options for PyKeras method correctly.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/391
https://github.com/root-project/root/pull/393:718,Availability,failure,failures,718,"This pull request adds [VecCore](https://gitlab.cern.ch/VecGeom/VecCore) external project and build options to ROOT. Some comments:. Vc is used by VecCore, and since it is not relocatable, it must be built by the VecCore build system in order to avoid the situation in which VecCore finds a broken temporary installed version of Vc in ROOT's `${CMAKE_BINARY_DIR}`. It is perfectly fine to use a builtin VecCore with an externally installed Vc, however. Ideally, though, both should be externally installed. When both are enabled as builtins, they will get installed at the end along with ROOT into the final prefix, with correct configurations. I can not test the build on ARM, please let me know if Jenkins shows any failures. @xvallspl Since you have been using VecCore within ROOT, could you please try this branch out? I did not find any code currently in ROOT that uses VecCore. I've marked this as work in progress to be able to make sure everything is ok prior to merging.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/393
https://github.com/root-project/root/pull/393:308,Deployability,install,installed,308,"This pull request adds [VecCore](https://gitlab.cern.ch/VecGeom/VecCore) external project and build options to ROOT. Some comments:. Vc is used by VecCore, and since it is not relocatable, it must be built by the VecCore build system in order to avoid the situation in which VecCore finds a broken temporary installed version of Vc in ROOT's `${CMAKE_BINARY_DIR}`. It is perfectly fine to use a builtin VecCore with an externally installed Vc, however. Ideally, though, both should be externally installed. When both are enabled as builtins, they will get installed at the end along with ROOT into the final prefix, with correct configurations. I can not test the build on ARM, please let me know if Jenkins shows any failures. @xvallspl Since you have been using VecCore within ROOT, could you please try this branch out? I did not find any code currently in ROOT that uses VecCore. I've marked this as work in progress to be able to make sure everything is ok prior to merging.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/393
https://github.com/root-project/root/pull/393:430,Deployability,install,installed,430,"This pull request adds [VecCore](https://gitlab.cern.ch/VecGeom/VecCore) external project and build options to ROOT. Some comments:. Vc is used by VecCore, and since it is not relocatable, it must be built by the VecCore build system in order to avoid the situation in which VecCore finds a broken temporary installed version of Vc in ROOT's `${CMAKE_BINARY_DIR}`. It is perfectly fine to use a builtin VecCore with an externally installed Vc, however. Ideally, though, both should be externally installed. When both are enabled as builtins, they will get installed at the end along with ROOT into the final prefix, with correct configurations. I can not test the build on ARM, please let me know if Jenkins shows any failures. @xvallspl Since you have been using VecCore within ROOT, could you please try this branch out? I did not find any code currently in ROOT that uses VecCore. I've marked this as work in progress to be able to make sure everything is ok prior to merging.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/393
https://github.com/root-project/root/pull/393:496,Deployability,install,installed,496,"This pull request adds [VecCore](https://gitlab.cern.ch/VecGeom/VecCore) external project and build options to ROOT. Some comments:. Vc is used by VecCore, and since it is not relocatable, it must be built by the VecCore build system in order to avoid the situation in which VecCore finds a broken temporary installed version of Vc in ROOT's `${CMAKE_BINARY_DIR}`. It is perfectly fine to use a builtin VecCore with an externally installed Vc, however. Ideally, though, both should be externally installed. When both are enabled as builtins, they will get installed at the end along with ROOT into the final prefix, with correct configurations. I can not test the build on ARM, please let me know if Jenkins shows any failures. @xvallspl Since you have been using VecCore within ROOT, could you please try this branch out? I did not find any code currently in ROOT that uses VecCore. I've marked this as work in progress to be able to make sure everything is ok prior to merging.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/393
https://github.com/root-project/root/pull/393:556,Deployability,install,installed,556,"This pull request adds [VecCore](https://gitlab.cern.ch/VecGeom/VecCore) external project and build options to ROOT. Some comments:. Vc is used by VecCore, and since it is not relocatable, it must be built by the VecCore build system in order to avoid the situation in which VecCore finds a broken temporary installed version of Vc in ROOT's `${CMAKE_BINARY_DIR}`. It is perfectly fine to use a builtin VecCore with an externally installed Vc, however. Ideally, though, both should be externally installed. When both are enabled as builtins, they will get installed at the end along with ROOT into the final prefix, with correct configurations. I can not test the build on ARM, please let me know if Jenkins shows any failures. @xvallspl Since you have been using VecCore within ROOT, could you please try this branch out? I did not find any code currently in ROOT that uses VecCore. I've marked this as work in progress to be able to make sure everything is ok prior to merging.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/393
https://github.com/root-project/root/pull/393:629,Deployability,configurat,configurations,629,"This pull request adds [VecCore](https://gitlab.cern.ch/VecGeom/VecCore) external project and build options to ROOT. Some comments:. Vc is used by VecCore, and since it is not relocatable, it must be built by the VecCore build system in order to avoid the situation in which VecCore finds a broken temporary installed version of Vc in ROOT's `${CMAKE_BINARY_DIR}`. It is perfectly fine to use a builtin VecCore with an externally installed Vc, however. Ideally, though, both should be externally installed. When both are enabled as builtins, they will get installed at the end along with ROOT into the final prefix, with correct configurations. I can not test the build on ARM, please let me know if Jenkins shows any failures. @xvallspl Since you have been using VecCore within ROOT, could you please try this branch out? I did not find any code currently in ROOT that uses VecCore. I've marked this as work in progress to be able to make sure everything is ok prior to merging.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/393
https://github.com/root-project/root/pull/393:629,Modifiability,config,configurations,629,"This pull request adds [VecCore](https://gitlab.cern.ch/VecGeom/VecCore) external project and build options to ROOT. Some comments:. Vc is used by VecCore, and since it is not relocatable, it must be built by the VecCore build system in order to avoid the situation in which VecCore finds a broken temporary installed version of Vc in ROOT's `${CMAKE_BINARY_DIR}`. It is perfectly fine to use a builtin VecCore with an externally installed Vc, however. Ideally, though, both should be externally installed. When both are enabled as builtins, they will get installed at the end along with ROOT into the final prefix, with correct configurations. I can not test the build on ARM, please let me know if Jenkins shows any failures. @xvallspl Since you have been using VecCore within ROOT, could you please try this branch out? I did not find any code currently in ROOT that uses VecCore. I've marked this as work in progress to be able to make sure everything is ok prior to merging.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/393
https://github.com/root-project/root/pull/393:246,Safety,avoid,avoid,246,"This pull request adds [VecCore](https://gitlab.cern.ch/VecGeom/VecCore) external project and build options to ROOT. Some comments:. Vc is used by VecCore, and since it is not relocatable, it must be built by the VecCore build system in order to avoid the situation in which VecCore finds a broken temporary installed version of Vc in ROOT's `${CMAKE_BINARY_DIR}`. It is perfectly fine to use a builtin VecCore with an externally installed Vc, however. Ideally, though, both should be externally installed. When both are enabled as builtins, they will get installed at the end along with ROOT into the final prefix, with correct configurations. I can not test the build on ARM, please let me know if Jenkins shows any failures. @xvallspl Since you have been using VecCore within ROOT, could you please try this branch out? I did not find any code currently in ROOT that uses VecCore. I've marked this as work in progress to be able to make sure everything is ok prior to merging.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/393
https://github.com/root-project/root/pull/393:655,Testability,test,test,655,"This pull request adds [VecCore](https://gitlab.cern.ch/VecGeom/VecCore) external project and build options to ROOT. Some comments:. Vc is used by VecCore, and since it is not relocatable, it must be built by the VecCore build system in order to avoid the situation in which VecCore finds a broken temporary installed version of Vc in ROOT's `${CMAKE_BINARY_DIR}`. It is perfectly fine to use a builtin VecCore with an externally installed Vc, however. Ideally, though, both should be externally installed. When both are enabled as builtins, they will get installed at the end along with ROOT into the final prefix, with correct configurations. I can not test the build on ARM, please let me know if Jenkins shows any failures. @xvallspl Since you have been using VecCore within ROOT, could you please try this branch out? I did not find any code currently in ROOT that uses VecCore. I've marked this as work in progress to be able to make sure everything is ok prior to merging.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/393
https://github.com/root-project/root/pull/394:520,Availability,mask,masks,520,"This PR extends the type templation that was already present in some classes in the GenVector library to improve support for using vectorised (Vc) types. Specifically it :-. 1. Extends the templation to the Plane3D, Transformation3D and Translation3D types.; 2. Where necessary provides specialised methods for the vector types, when the original code was not generic enough to work in both scalar and vector scenarios. Typically this happens in the case of conditionals, where the differences required (booleans versus masks) are difficult to avoid. This PR is not complete, in that there are still some classes in GenVector that still do not support Vc types, as they are still not templated, such as the Rotation like transformations. It would be nice to add this at some point, but the code associated to these is more extensive (3DConversions.cxx for instance) and that will require some work. My changes pass the built in ROOT tests. In addition I have prepared a simple test case for the Vc types (attached) that I have used to check the scalar and vector types give equivalent results. Tested on OS X with the compilation command. clang++ -O3 -mavx2 -mfma `root-config --cflags` -I/Users/chris/Projects/Vc/install/include main.cpp `root-config --libs` -lGenVector /Users/chris/Projects/Vc/install/lib/libVc.a. [main-cpp.txt](https://github.com/root-project/root/files/820450/main-cpp.txt)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/394
https://github.com/root-project/root/pull/394:1214,Deployability,install,install,1214,"This PR extends the type templation that was already present in some classes in the GenVector library to improve support for using vectorised (Vc) types. Specifically it :-. 1. Extends the templation to the Plane3D, Transformation3D and Translation3D types.; 2. Where necessary provides specialised methods for the vector types, when the original code was not generic enough to work in both scalar and vector scenarios. Typically this happens in the case of conditionals, where the differences required (booleans versus masks) are difficult to avoid. This PR is not complete, in that there are still some classes in GenVector that still do not support Vc types, as they are still not templated, such as the Rotation like transformations. It would be nice to add this at some point, but the code associated to these is more extensive (3DConversions.cxx for instance) and that will require some work. My changes pass the built in ROOT tests. In addition I have prepared a simple test case for the Vc types (attached) that I have used to check the scalar and vector types give equivalent results. Tested on OS X with the compilation command. clang++ -O3 -mavx2 -mfma `root-config --cflags` -I/Users/chris/Projects/Vc/install/include main.cpp `root-config --libs` -lGenVector /Users/chris/Projects/Vc/install/lib/libVc.a. [main-cpp.txt](https://github.com/root-project/root/files/820450/main-cpp.txt)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/394
https://github.com/root-project/root/pull/394:1297,Deployability,install,install,1297,"This PR extends the type templation that was already present in some classes in the GenVector library to improve support for using vectorised (Vc) types. Specifically it :-. 1. Extends the templation to the Plane3D, Transformation3D and Translation3D types.; 2. Where necessary provides specialised methods for the vector types, when the original code was not generic enough to work in both scalar and vector scenarios. Typically this happens in the case of conditionals, where the differences required (booleans versus masks) are difficult to avoid. This PR is not complete, in that there are still some classes in GenVector that still do not support Vc types, as they are still not templated, such as the Rotation like transformations. It would be nice to add this at some point, but the code associated to these is more extensive (3DConversions.cxx for instance) and that will require some work. My changes pass the built in ROOT tests. In addition I have prepared a simple test case for the Vc types (attached) that I have used to check the scalar and vector types give equivalent results. Tested on OS X with the compilation command. clang++ -O3 -mavx2 -mfma `root-config --cflags` -I/Users/chris/Projects/Vc/install/include main.cpp `root-config --libs` -lGenVector /Users/chris/Projects/Vc/install/lib/libVc.a. [main-cpp.txt](https://github.com/root-project/root/files/820450/main-cpp.txt)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/394
https://github.com/root-project/root/pull/394:8,Modifiability,extend,extends,8,"This PR extends the type templation that was already present in some classes in the GenVector library to improve support for using vectorised (Vc) types. Specifically it :-. 1. Extends the templation to the Plane3D, Transformation3D and Translation3D types.; 2. Where necessary provides specialised methods for the vector types, when the original code was not generic enough to work in both scalar and vector scenarios. Typically this happens in the case of conditionals, where the differences required (booleans versus masks) are difficult to avoid. This PR is not complete, in that there are still some classes in GenVector that still do not support Vc types, as they are still not templated, such as the Rotation like transformations. It would be nice to add this at some point, but the code associated to these is more extensive (3DConversions.cxx for instance) and that will require some work. My changes pass the built in ROOT tests. In addition I have prepared a simple test case for the Vc types (attached) that I have used to check the scalar and vector types give equivalent results. Tested on OS X with the compilation command. clang++ -O3 -mavx2 -mfma `root-config --cflags` -I/Users/chris/Projects/Vc/install/include main.cpp `root-config --libs` -lGenVector /Users/chris/Projects/Vc/install/lib/libVc.a. [main-cpp.txt](https://github.com/root-project/root/files/820450/main-cpp.txt)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/394
https://github.com/root-project/root/pull/394:177,Modifiability,Extend,Extends,177,"This PR extends the type templation that was already present in some classes in the GenVector library to improve support for using vectorised (Vc) types. Specifically it :-. 1. Extends the templation to the Plane3D, Transformation3D and Translation3D types.; 2. Where necessary provides specialised methods for the vector types, when the original code was not generic enough to work in both scalar and vector scenarios. Typically this happens in the case of conditionals, where the differences required (booleans versus masks) are difficult to avoid. This PR is not complete, in that there are still some classes in GenVector that still do not support Vc types, as they are still not templated, such as the Rotation like transformations. It would be nice to add this at some point, but the code associated to these is more extensive (3DConversions.cxx for instance) and that will require some work. My changes pass the built in ROOT tests. In addition I have prepared a simple test case for the Vc types (attached) that I have used to check the scalar and vector types give equivalent results. Tested on OS X with the compilation command. clang++ -O3 -mavx2 -mfma `root-config --cflags` -I/Users/chris/Projects/Vc/install/include main.cpp `root-config --libs` -lGenVector /Users/chris/Projects/Vc/install/lib/libVc.a. [main-cpp.txt](https://github.com/root-project/root/files/820450/main-cpp.txt)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/394
https://github.com/root-project/root/pull/394:1170,Modifiability,config,config,1170,"This PR extends the type templation that was already present in some classes in the GenVector library to improve support for using vectorised (Vc) types. Specifically it :-. 1. Extends the templation to the Plane3D, Transformation3D and Translation3D types.; 2. Where necessary provides specialised methods for the vector types, when the original code was not generic enough to work in both scalar and vector scenarios. Typically this happens in the case of conditionals, where the differences required (booleans versus masks) are difficult to avoid. This PR is not complete, in that there are still some classes in GenVector that still do not support Vc types, as they are still not templated, such as the Rotation like transformations. It would be nice to add this at some point, but the code associated to these is more extensive (3DConversions.cxx for instance) and that will require some work. My changes pass the built in ROOT tests. In addition I have prepared a simple test case for the Vc types (attached) that I have used to check the scalar and vector types give equivalent results. Tested on OS X with the compilation command. clang++ -O3 -mavx2 -mfma `root-config --cflags` -I/Users/chris/Projects/Vc/install/include main.cpp `root-config --libs` -lGenVector /Users/chris/Projects/Vc/install/lib/libVc.a. [main-cpp.txt](https://github.com/root-project/root/files/820450/main-cpp.txt)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/394
https://github.com/root-project/root/pull/394:1245,Modifiability,config,config,1245,"This PR extends the type templation that was already present in some classes in the GenVector library to improve support for using vectorised (Vc) types. Specifically it :-. 1. Extends the templation to the Plane3D, Transformation3D and Translation3D types.; 2. Where necessary provides specialised methods for the vector types, when the original code was not generic enough to work in both scalar and vector scenarios. Typically this happens in the case of conditionals, where the differences required (booleans versus masks) are difficult to avoid. This PR is not complete, in that there are still some classes in GenVector that still do not support Vc types, as they are still not templated, such as the Rotation like transformations. It would be nice to add this at some point, but the code associated to these is more extensive (3DConversions.cxx for instance) and that will require some work. My changes pass the built in ROOT tests. In addition I have prepared a simple test case for the Vc types (attached) that I have used to check the scalar and vector types give equivalent results. Tested on OS X with the compilation command. clang++ -O3 -mavx2 -mfma `root-config --cflags` -I/Users/chris/Projects/Vc/install/include main.cpp `root-config --libs` -lGenVector /Users/chris/Projects/Vc/install/lib/libVc.a. [main-cpp.txt](https://github.com/root-project/root/files/820450/main-cpp.txt)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/394
https://github.com/root-project/root/pull/394:544,Safety,avoid,avoid,544,"This PR extends the type templation that was already present in some classes in the GenVector library to improve support for using vectorised (Vc) types. Specifically it :-. 1. Extends the templation to the Plane3D, Transformation3D and Translation3D types.; 2. Where necessary provides specialised methods for the vector types, when the original code was not generic enough to work in both scalar and vector scenarios. Typically this happens in the case of conditionals, where the differences required (booleans versus masks) are difficult to avoid. This PR is not complete, in that there are still some classes in GenVector that still do not support Vc types, as they are still not templated, such as the Rotation like transformations. It would be nice to add this at some point, but the code associated to these is more extensive (3DConversions.cxx for instance) and that will require some work. My changes pass the built in ROOT tests. In addition I have prepared a simple test case for the Vc types (attached) that I have used to check the scalar and vector types give equivalent results. Tested on OS X with the compilation command. clang++ -O3 -mavx2 -mfma `root-config --cflags` -I/Users/chris/Projects/Vc/install/include main.cpp `root-config --libs` -lGenVector /Users/chris/Projects/Vc/install/lib/libVc.a. [main-cpp.txt](https://github.com/root-project/root/files/820450/main-cpp.txt)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/394
https://github.com/root-project/root/pull/394:933,Testability,test,tests,933,"This PR extends the type templation that was already present in some classes in the GenVector library to improve support for using vectorised (Vc) types. Specifically it :-. 1. Extends the templation to the Plane3D, Transformation3D and Translation3D types.; 2. Where necessary provides specialised methods for the vector types, when the original code was not generic enough to work in both scalar and vector scenarios. Typically this happens in the case of conditionals, where the differences required (booleans versus masks) are difficult to avoid. This PR is not complete, in that there are still some classes in GenVector that still do not support Vc types, as they are still not templated, such as the Rotation like transformations. It would be nice to add this at some point, but the code associated to these is more extensive (3DConversions.cxx for instance) and that will require some work. My changes pass the built in ROOT tests. In addition I have prepared a simple test case for the Vc types (attached) that I have used to check the scalar and vector types give equivalent results. Tested on OS X with the compilation command. clang++ -O3 -mavx2 -mfma `root-config --cflags` -I/Users/chris/Projects/Vc/install/include main.cpp `root-config --libs` -lGenVector /Users/chris/Projects/Vc/install/lib/libVc.a. [main-cpp.txt](https://github.com/root-project/root/files/820450/main-cpp.txt)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/394
https://github.com/root-project/root/pull/394:977,Testability,test,test,977,"This PR extends the type templation that was already present in some classes in the GenVector library to improve support for using vectorised (Vc) types. Specifically it :-. 1. Extends the templation to the Plane3D, Transformation3D and Translation3D types.; 2. Where necessary provides specialised methods for the vector types, when the original code was not generic enough to work in both scalar and vector scenarios. Typically this happens in the case of conditionals, where the differences required (booleans versus masks) are difficult to avoid. This PR is not complete, in that there are still some classes in GenVector that still do not support Vc types, as they are still not templated, such as the Rotation like transformations. It would be nice to add this at some point, but the code associated to these is more extensive (3DConversions.cxx for instance) and that will require some work. My changes pass the built in ROOT tests. In addition I have prepared a simple test case for the Vc types (attached) that I have used to check the scalar and vector types give equivalent results. Tested on OS X with the compilation command. clang++ -O3 -mavx2 -mfma `root-config --cflags` -I/Users/chris/Projects/Vc/install/include main.cpp `root-config --libs` -lGenVector /Users/chris/Projects/Vc/install/lib/libVc.a. [main-cpp.txt](https://github.com/root-project/root/files/820450/main-cpp.txt)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/394
https://github.com/root-project/root/pull/394:1094,Testability,Test,Tested,1094,"This PR extends the type templation that was already present in some classes in the GenVector library to improve support for using vectorised (Vc) types. Specifically it :-. 1. Extends the templation to the Plane3D, Transformation3D and Translation3D types.; 2. Where necessary provides specialised methods for the vector types, when the original code was not generic enough to work in both scalar and vector scenarios. Typically this happens in the case of conditionals, where the differences required (booleans versus masks) are difficult to avoid. This PR is not complete, in that there are still some classes in GenVector that still do not support Vc types, as they are still not templated, such as the Rotation like transformations. It would be nice to add this at some point, but the code associated to these is more extensive (3DConversions.cxx for instance) and that will require some work. My changes pass the built in ROOT tests. In addition I have prepared a simple test case for the Vc types (attached) that I have used to check the scalar and vector types give equivalent results. Tested on OS X with the compilation command. clang++ -O3 -mavx2 -mfma `root-config --cflags` -I/Users/chris/Projects/Vc/install/include main.cpp `root-config --libs` -lGenVector /Users/chris/Projects/Vc/install/lib/libVc.a. [main-cpp.txt](https://github.com/root-project/root/files/820450/main-cpp.txt)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/394
https://github.com/root-project/root/pull/394:970,Usability,simpl,simple,970,"This PR extends the type templation that was already present in some classes in the GenVector library to improve support for using vectorised (Vc) types. Specifically it :-. 1. Extends the templation to the Plane3D, Transformation3D and Translation3D types.; 2. Where necessary provides specialised methods for the vector types, when the original code was not generic enough to work in both scalar and vector scenarios. Typically this happens in the case of conditionals, where the differences required (booleans versus masks) are difficult to avoid. This PR is not complete, in that there are still some classes in GenVector that still do not support Vc types, as they are still not templated, such as the Rotation like transformations. It would be nice to add this at some point, but the code associated to these is more extensive (3DConversions.cxx for instance) and that will require some work. My changes pass the built in ROOT tests. In addition I have prepared a simple test case for the Vc types (attached) that I have used to check the scalar and vector types give equivalent results. Tested on OS X with the compilation command. clang++ -O3 -mavx2 -mfma `root-config --cflags` -I/Users/chris/Projects/Vc/install/include main.cpp `root-config --libs` -lGenVector /Users/chris/Projects/Vc/install/lib/libVc.a. [main-cpp.txt](https://github.com/root-project/root/files/820450/main-cpp.txt)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/394
https://github.com/root-project/root/pull/397:17,Integrability,interface,interface,17,This will be the interface to apply for void returning functions (or when you have no need to return the map vector -this implies no reduction- and want to save some space),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/397
https://github.com/root-project/root/pull/398:128,Testability,test,test,128,"We have another class with the name Compare in TMatrixTBase.h, so we add a; anonymous namespace here that we don't fail on this test when building with; enabled modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/398
https://github.com/root-project/root/pull/399:147,Availability,error,error,147,68713: removed dead statement; 67156: set an uninitialised class member fNBins; 67100: set an uninitialised class member fNBins; 67054: copy paste error fixed; 63262: uninitialised class member fFuncPtr,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/399
https://github.com/root-project/root/pull/400:18,Availability,failure,failure,18,"This fixes a test failure on i686:. 95/593 Test #45: mathmore-testSpecFunc ......................................***Failed 0.40 sec; tgamma(9.0) :	 OK; lgamma(0.1) :	 OK; inc_gamma(1,0.001) :	 OK; inc_gamma(100,99) :	 OK; inc_gamma_c(100,99) :	 OK; inc_gamma_c(1000,1000.1) :	 OK; erf(0.5) :	 OK; erfc(-1.0) :	 OK; beta(1.0, 5.0) :	 OK; inc_beta(1,1,1) :	 OK; inc_beta(0.5,0.1,1.0) :	 OK; assoc_laguerre(4, 2, 0.5) :	 OK; assoc_legendre(10, 1, -0.5) :	 OK; comp_ellint_1(0.50) :	 OK; comp_ellint_2(0.50) :	 OK; comp_ellint_3(0.5, 0.5) :	 OK; conf_hyperg(1, 1.5, 1) :	 OK; cyl_bessel_i(1.0, 1.0) :	 OK; cyl_bessel_j(0.75, 1.0) :	 OK; cyl_bessel_k(1.0, 1.0) :	 OK; cyl_neumann(0.75, 1.0) :	 OK; ellint_1(0.50, PI/3.0) :	 OK; ellint_2(0.50, PI/3.0) :	 OK; ellint_3(-0.50, 0.5, PI/3.0) :	 OK; expint(1.0) :	 OK; hyperg(8, -8, 1, 0.5) :	 OK; laguerre(4, 1.) :	 FAILED ; Discrepancy in laguerre(4, 1.) () :; -0.625000000000000555 != -0.625 discr = 1 (Allowed discrepancy is 4.44089209850062616e-16); legendre(10, -0.5) :	 OK; riemann_zeta(-0.5) :	 OK; sph_bessel(1, 10.0) :	 OK; sph_legendre(3, 1, PI/2.) :	 OK; sph_neumann(0, 1.0) :	 OK; airy_Ai(-0.5) :	 OK; airy_Bi(0.5) :	 OK; airy_Ai_deriv(-2) :	 OK; airy_Bi_deriv(-3) :	 OK; airy_zero_Ai(2) :	 OK; airy_zero_Bi(2) :	 OK; airy_zero_Ai_deriv(2) :	 OK; airy_zero_Bi_deriv(2) :	 OK; Error: Special Functions Test FAILED !!!!!; CMake Error at /builddir/build/BUILD/root-6.08.06/cmake/modules/RootTestDriver.cmake:201 (message):; error code: 1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/400
https://github.com/root-project/root/pull/400:1328,Availability,Error,Error,1328,"This fixes a test failure on i686:. 95/593 Test #45: mathmore-testSpecFunc ......................................***Failed 0.40 sec; tgamma(9.0) :	 OK; lgamma(0.1) :	 OK; inc_gamma(1,0.001) :	 OK; inc_gamma(100,99) :	 OK; inc_gamma_c(100,99) :	 OK; inc_gamma_c(1000,1000.1) :	 OK; erf(0.5) :	 OK; erfc(-1.0) :	 OK; beta(1.0, 5.0) :	 OK; inc_beta(1,1,1) :	 OK; inc_beta(0.5,0.1,1.0) :	 OK; assoc_laguerre(4, 2, 0.5) :	 OK; assoc_legendre(10, 1, -0.5) :	 OK; comp_ellint_1(0.50) :	 OK; comp_ellint_2(0.50) :	 OK; comp_ellint_3(0.5, 0.5) :	 OK; conf_hyperg(1, 1.5, 1) :	 OK; cyl_bessel_i(1.0, 1.0) :	 OK; cyl_bessel_j(0.75, 1.0) :	 OK; cyl_bessel_k(1.0, 1.0) :	 OK; cyl_neumann(0.75, 1.0) :	 OK; ellint_1(0.50, PI/3.0) :	 OK; ellint_2(0.50, PI/3.0) :	 OK; ellint_3(-0.50, 0.5, PI/3.0) :	 OK; expint(1.0) :	 OK; hyperg(8, -8, 1, 0.5) :	 OK; laguerre(4, 1.) :	 FAILED ; Discrepancy in laguerre(4, 1.) () :; -0.625000000000000555 != -0.625 discr = 1 (Allowed discrepancy is 4.44089209850062616e-16); legendre(10, -0.5) :	 OK; riemann_zeta(-0.5) :	 OK; sph_bessel(1, 10.0) :	 OK; sph_legendre(3, 1, PI/2.) :	 OK; sph_neumann(0, 1.0) :	 OK; airy_Ai(-0.5) :	 OK; airy_Bi(0.5) :	 OK; airy_Ai_deriv(-2) :	 OK; airy_Bi_deriv(-3) :	 OK; airy_zero_Ai(2) :	 OK; airy_zero_Bi(2) :	 OK; airy_zero_Ai_deriv(2) :	 OK; airy_zero_Bi_deriv(2) :	 OK; Error: Special Functions Test FAILED !!!!!; CMake Error at /builddir/build/BUILD/root-6.08.06/cmake/modules/RootTestDriver.cmake:201 (message):; error code: 1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/400
https://github.com/root-project/root/pull/400:1378,Availability,Error,Error,1378,"This fixes a test failure on i686:. 95/593 Test #45: mathmore-testSpecFunc ......................................***Failed 0.40 sec; tgamma(9.0) :	 OK; lgamma(0.1) :	 OK; inc_gamma(1,0.001) :	 OK; inc_gamma(100,99) :	 OK; inc_gamma_c(100,99) :	 OK; inc_gamma_c(1000,1000.1) :	 OK; erf(0.5) :	 OK; erfc(-1.0) :	 OK; beta(1.0, 5.0) :	 OK; inc_beta(1,1,1) :	 OK; inc_beta(0.5,0.1,1.0) :	 OK; assoc_laguerre(4, 2, 0.5) :	 OK; assoc_legendre(10, 1, -0.5) :	 OK; comp_ellint_1(0.50) :	 OK; comp_ellint_2(0.50) :	 OK; comp_ellint_3(0.5, 0.5) :	 OK; conf_hyperg(1, 1.5, 1) :	 OK; cyl_bessel_i(1.0, 1.0) :	 OK; cyl_bessel_j(0.75, 1.0) :	 OK; cyl_bessel_k(1.0, 1.0) :	 OK; cyl_neumann(0.75, 1.0) :	 OK; ellint_1(0.50, PI/3.0) :	 OK; ellint_2(0.50, PI/3.0) :	 OK; ellint_3(-0.50, 0.5, PI/3.0) :	 OK; expint(1.0) :	 OK; hyperg(8, -8, 1, 0.5) :	 OK; laguerre(4, 1.) :	 FAILED ; Discrepancy in laguerre(4, 1.) () :; -0.625000000000000555 != -0.625 discr = 1 (Allowed discrepancy is 4.44089209850062616e-16); legendre(10, -0.5) :	 OK; riemann_zeta(-0.5) :	 OK; sph_bessel(1, 10.0) :	 OK; sph_legendre(3, 1, PI/2.) :	 OK; sph_neumann(0, 1.0) :	 OK; airy_Ai(-0.5) :	 OK; airy_Bi(0.5) :	 OK; airy_Ai_deriv(-2) :	 OK; airy_Bi_deriv(-3) :	 OK; airy_zero_Ai(2) :	 OK; airy_zero_Bi(2) :	 OK; airy_zero_Ai_deriv(2) :	 OK; airy_zero_Bi_deriv(2) :	 OK; Error: Special Functions Test FAILED !!!!!; CMake Error at /builddir/build/BUILD/root-6.08.06/cmake/modules/RootTestDriver.cmake:201 (message):; error code: 1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/400
https://github.com/root-project/root/pull/400:1473,Availability,error,error,1473,"This fixes a test failure on i686:. 95/593 Test #45: mathmore-testSpecFunc ......................................***Failed 0.40 sec; tgamma(9.0) :	 OK; lgamma(0.1) :	 OK; inc_gamma(1,0.001) :	 OK; inc_gamma(100,99) :	 OK; inc_gamma_c(100,99) :	 OK; inc_gamma_c(1000,1000.1) :	 OK; erf(0.5) :	 OK; erfc(-1.0) :	 OK; beta(1.0, 5.0) :	 OK; inc_beta(1,1,1) :	 OK; inc_beta(0.5,0.1,1.0) :	 OK; assoc_laguerre(4, 2, 0.5) :	 OK; assoc_legendre(10, 1, -0.5) :	 OK; comp_ellint_1(0.50) :	 OK; comp_ellint_2(0.50) :	 OK; comp_ellint_3(0.5, 0.5) :	 OK; conf_hyperg(1, 1.5, 1) :	 OK; cyl_bessel_i(1.0, 1.0) :	 OK; cyl_bessel_j(0.75, 1.0) :	 OK; cyl_bessel_k(1.0, 1.0) :	 OK; cyl_neumann(0.75, 1.0) :	 OK; ellint_1(0.50, PI/3.0) :	 OK; ellint_2(0.50, PI/3.0) :	 OK; ellint_3(-0.50, 0.5, PI/3.0) :	 OK; expint(1.0) :	 OK; hyperg(8, -8, 1, 0.5) :	 OK; laguerre(4, 1.) :	 FAILED ; Discrepancy in laguerre(4, 1.) () :; -0.625000000000000555 != -0.625 discr = 1 (Allowed discrepancy is 4.44089209850062616e-16); legendre(10, -0.5) :	 OK; riemann_zeta(-0.5) :	 OK; sph_bessel(1, 10.0) :	 OK; sph_legendre(3, 1, PI/2.) :	 OK; sph_neumann(0, 1.0) :	 OK; airy_Ai(-0.5) :	 OK; airy_Bi(0.5) :	 OK; airy_Ai_deriv(-2) :	 OK; airy_Bi_deriv(-3) :	 OK; airy_zero_Ai(2) :	 OK; airy_zero_Bi(2) :	 OK; airy_zero_Ai_deriv(2) :	 OK; airy_zero_Bi_deriv(2) :	 OK; Error: Special Functions Test FAILED !!!!!; CMake Error at /builddir/build/BUILD/root-6.08.06/cmake/modules/RootTestDriver.cmake:201 (message):; error code: 1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/400
https://github.com/root-project/root/pull/400:1462,Integrability,message,message,1462,"This fixes a test failure on i686:. 95/593 Test #45: mathmore-testSpecFunc ......................................***Failed 0.40 sec; tgamma(9.0) :	 OK; lgamma(0.1) :	 OK; inc_gamma(1,0.001) :	 OK; inc_gamma(100,99) :	 OK; inc_gamma_c(100,99) :	 OK; inc_gamma_c(1000,1000.1) :	 OK; erf(0.5) :	 OK; erfc(-1.0) :	 OK; beta(1.0, 5.0) :	 OK; inc_beta(1,1,1) :	 OK; inc_beta(0.5,0.1,1.0) :	 OK; assoc_laguerre(4, 2, 0.5) :	 OK; assoc_legendre(10, 1, -0.5) :	 OK; comp_ellint_1(0.50) :	 OK; comp_ellint_2(0.50) :	 OK; comp_ellint_3(0.5, 0.5) :	 OK; conf_hyperg(1, 1.5, 1) :	 OK; cyl_bessel_i(1.0, 1.0) :	 OK; cyl_bessel_j(0.75, 1.0) :	 OK; cyl_bessel_k(1.0, 1.0) :	 OK; cyl_neumann(0.75, 1.0) :	 OK; ellint_1(0.50, PI/3.0) :	 OK; ellint_2(0.50, PI/3.0) :	 OK; ellint_3(-0.50, 0.5, PI/3.0) :	 OK; expint(1.0) :	 OK; hyperg(8, -8, 1, 0.5) :	 OK; laguerre(4, 1.) :	 FAILED ; Discrepancy in laguerre(4, 1.) () :; -0.625000000000000555 != -0.625 discr = 1 (Allowed discrepancy is 4.44089209850062616e-16); legendre(10, -0.5) :	 OK; riemann_zeta(-0.5) :	 OK; sph_bessel(1, 10.0) :	 OK; sph_legendre(3, 1, PI/2.) :	 OK; sph_neumann(0, 1.0) :	 OK; airy_Ai(-0.5) :	 OK; airy_Bi(0.5) :	 OK; airy_Ai_deriv(-2) :	 OK; airy_Bi_deriv(-3) :	 OK; airy_zero_Ai(2) :	 OK; airy_zero_Bi(2) :	 OK; airy_zero_Ai_deriv(2) :	 OK; airy_zero_Bi_deriv(2) :	 OK; Error: Special Functions Test FAILED !!!!!; CMake Error at /builddir/build/BUILD/root-6.08.06/cmake/modules/RootTestDriver.cmake:201 (message):; error code: 1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/400
https://github.com/root-project/root/pull/400:13,Testability,test,test,13,"This fixes a test failure on i686:. 95/593 Test #45: mathmore-testSpecFunc ......................................***Failed 0.40 sec; tgamma(9.0) :	 OK; lgamma(0.1) :	 OK; inc_gamma(1,0.001) :	 OK; inc_gamma(100,99) :	 OK; inc_gamma_c(100,99) :	 OK; inc_gamma_c(1000,1000.1) :	 OK; erf(0.5) :	 OK; erfc(-1.0) :	 OK; beta(1.0, 5.0) :	 OK; inc_beta(1,1,1) :	 OK; inc_beta(0.5,0.1,1.0) :	 OK; assoc_laguerre(4, 2, 0.5) :	 OK; assoc_legendre(10, 1, -0.5) :	 OK; comp_ellint_1(0.50) :	 OK; comp_ellint_2(0.50) :	 OK; comp_ellint_3(0.5, 0.5) :	 OK; conf_hyperg(1, 1.5, 1) :	 OK; cyl_bessel_i(1.0, 1.0) :	 OK; cyl_bessel_j(0.75, 1.0) :	 OK; cyl_bessel_k(1.0, 1.0) :	 OK; cyl_neumann(0.75, 1.0) :	 OK; ellint_1(0.50, PI/3.0) :	 OK; ellint_2(0.50, PI/3.0) :	 OK; ellint_3(-0.50, 0.5, PI/3.0) :	 OK; expint(1.0) :	 OK; hyperg(8, -8, 1, 0.5) :	 OK; laguerre(4, 1.) :	 FAILED ; Discrepancy in laguerre(4, 1.) () :; -0.625000000000000555 != -0.625 discr = 1 (Allowed discrepancy is 4.44089209850062616e-16); legendre(10, -0.5) :	 OK; riemann_zeta(-0.5) :	 OK; sph_bessel(1, 10.0) :	 OK; sph_legendre(3, 1, PI/2.) :	 OK; sph_neumann(0, 1.0) :	 OK; airy_Ai(-0.5) :	 OK; airy_Bi(0.5) :	 OK; airy_Ai_deriv(-2) :	 OK; airy_Bi_deriv(-3) :	 OK; airy_zero_Ai(2) :	 OK; airy_zero_Bi(2) :	 OK; airy_zero_Ai_deriv(2) :	 OK; airy_zero_Bi_deriv(2) :	 OK; Error: Special Functions Test FAILED !!!!!; CMake Error at /builddir/build/BUILD/root-6.08.06/cmake/modules/RootTestDriver.cmake:201 (message):; error code: 1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/400
https://github.com/root-project/root/pull/400:43,Testability,Test,Test,43,"This fixes a test failure on i686:. 95/593 Test #45: mathmore-testSpecFunc ......................................***Failed 0.40 sec; tgamma(9.0) :	 OK; lgamma(0.1) :	 OK; inc_gamma(1,0.001) :	 OK; inc_gamma(100,99) :	 OK; inc_gamma_c(100,99) :	 OK; inc_gamma_c(1000,1000.1) :	 OK; erf(0.5) :	 OK; erfc(-1.0) :	 OK; beta(1.0, 5.0) :	 OK; inc_beta(1,1,1) :	 OK; inc_beta(0.5,0.1,1.0) :	 OK; assoc_laguerre(4, 2, 0.5) :	 OK; assoc_legendre(10, 1, -0.5) :	 OK; comp_ellint_1(0.50) :	 OK; comp_ellint_2(0.50) :	 OK; comp_ellint_3(0.5, 0.5) :	 OK; conf_hyperg(1, 1.5, 1) :	 OK; cyl_bessel_i(1.0, 1.0) :	 OK; cyl_bessel_j(0.75, 1.0) :	 OK; cyl_bessel_k(1.0, 1.0) :	 OK; cyl_neumann(0.75, 1.0) :	 OK; ellint_1(0.50, PI/3.0) :	 OK; ellint_2(0.50, PI/3.0) :	 OK; ellint_3(-0.50, 0.5, PI/3.0) :	 OK; expint(1.0) :	 OK; hyperg(8, -8, 1, 0.5) :	 OK; laguerre(4, 1.) :	 FAILED ; Discrepancy in laguerre(4, 1.) () :; -0.625000000000000555 != -0.625 discr = 1 (Allowed discrepancy is 4.44089209850062616e-16); legendre(10, -0.5) :	 OK; riemann_zeta(-0.5) :	 OK; sph_bessel(1, 10.0) :	 OK; sph_legendre(3, 1, PI/2.) :	 OK; sph_neumann(0, 1.0) :	 OK; airy_Ai(-0.5) :	 OK; airy_Bi(0.5) :	 OK; airy_Ai_deriv(-2) :	 OK; airy_Bi_deriv(-3) :	 OK; airy_zero_Ai(2) :	 OK; airy_zero_Bi(2) :	 OK; airy_zero_Ai_deriv(2) :	 OK; airy_zero_Bi_deriv(2) :	 OK; Error: Special Functions Test FAILED !!!!!; CMake Error at /builddir/build/BUILD/root-6.08.06/cmake/modules/RootTestDriver.cmake:201 (message):; error code: 1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/400
https://github.com/root-project/root/pull/400:62,Testability,test,testSpecFunc,62,"This fixes a test failure on i686:. 95/593 Test #45: mathmore-testSpecFunc ......................................***Failed 0.40 sec; tgamma(9.0) :	 OK; lgamma(0.1) :	 OK; inc_gamma(1,0.001) :	 OK; inc_gamma(100,99) :	 OK; inc_gamma_c(100,99) :	 OK; inc_gamma_c(1000,1000.1) :	 OK; erf(0.5) :	 OK; erfc(-1.0) :	 OK; beta(1.0, 5.0) :	 OK; inc_beta(1,1,1) :	 OK; inc_beta(0.5,0.1,1.0) :	 OK; assoc_laguerre(4, 2, 0.5) :	 OK; assoc_legendre(10, 1, -0.5) :	 OK; comp_ellint_1(0.50) :	 OK; comp_ellint_2(0.50) :	 OK; comp_ellint_3(0.5, 0.5) :	 OK; conf_hyperg(1, 1.5, 1) :	 OK; cyl_bessel_i(1.0, 1.0) :	 OK; cyl_bessel_j(0.75, 1.0) :	 OK; cyl_bessel_k(1.0, 1.0) :	 OK; cyl_neumann(0.75, 1.0) :	 OK; ellint_1(0.50, PI/3.0) :	 OK; ellint_2(0.50, PI/3.0) :	 OK; ellint_3(-0.50, 0.5, PI/3.0) :	 OK; expint(1.0) :	 OK; hyperg(8, -8, 1, 0.5) :	 OK; laguerre(4, 1.) :	 FAILED ; Discrepancy in laguerre(4, 1.) () :; -0.625000000000000555 != -0.625 discr = 1 (Allowed discrepancy is 4.44089209850062616e-16); legendre(10, -0.5) :	 OK; riemann_zeta(-0.5) :	 OK; sph_bessel(1, 10.0) :	 OK; sph_legendre(3, 1, PI/2.) :	 OK; sph_neumann(0, 1.0) :	 OK; airy_Ai(-0.5) :	 OK; airy_Bi(0.5) :	 OK; airy_Ai_deriv(-2) :	 OK; airy_Bi_deriv(-3) :	 OK; airy_zero_Ai(2) :	 OK; airy_zero_Bi(2) :	 OK; airy_zero_Ai_deriv(2) :	 OK; airy_zero_Bi_deriv(2) :	 OK; Error: Special Functions Test FAILED !!!!!; CMake Error at /builddir/build/BUILD/root-6.08.06/cmake/modules/RootTestDriver.cmake:201 (message):; error code: 1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/400
https://github.com/root-project/root/pull/400:1353,Testability,Test,Test,1353,"This fixes a test failure on i686:. 95/593 Test #45: mathmore-testSpecFunc ......................................***Failed 0.40 sec; tgamma(9.0) :	 OK; lgamma(0.1) :	 OK; inc_gamma(1,0.001) :	 OK; inc_gamma(100,99) :	 OK; inc_gamma_c(100,99) :	 OK; inc_gamma_c(1000,1000.1) :	 OK; erf(0.5) :	 OK; erfc(-1.0) :	 OK; beta(1.0, 5.0) :	 OK; inc_beta(1,1,1) :	 OK; inc_beta(0.5,0.1,1.0) :	 OK; assoc_laguerre(4, 2, 0.5) :	 OK; assoc_legendre(10, 1, -0.5) :	 OK; comp_ellint_1(0.50) :	 OK; comp_ellint_2(0.50) :	 OK; comp_ellint_3(0.5, 0.5) :	 OK; conf_hyperg(1, 1.5, 1) :	 OK; cyl_bessel_i(1.0, 1.0) :	 OK; cyl_bessel_j(0.75, 1.0) :	 OK; cyl_bessel_k(1.0, 1.0) :	 OK; cyl_neumann(0.75, 1.0) :	 OK; ellint_1(0.50, PI/3.0) :	 OK; ellint_2(0.50, PI/3.0) :	 OK; ellint_3(-0.50, 0.5, PI/3.0) :	 OK; expint(1.0) :	 OK; hyperg(8, -8, 1, 0.5) :	 OK; laguerre(4, 1.) :	 FAILED ; Discrepancy in laguerre(4, 1.) () :; -0.625000000000000555 != -0.625 discr = 1 (Allowed discrepancy is 4.44089209850062616e-16); legendre(10, -0.5) :	 OK; riemann_zeta(-0.5) :	 OK; sph_bessel(1, 10.0) :	 OK; sph_legendre(3, 1, PI/2.) :	 OK; sph_neumann(0, 1.0) :	 OK; airy_Ai(-0.5) :	 OK; airy_Bi(0.5) :	 OK; airy_Ai_deriv(-2) :	 OK; airy_Bi_deriv(-3) :	 OK; airy_zero_Ai(2) :	 OK; airy_zero_Bi(2) :	 OK; airy_zero_Ai_deriv(2) :	 OK; airy_zero_Bi_deriv(2) :	 OK; Error: Special Functions Test FAILED !!!!!; CMake Error at /builddir/build/BUILD/root-6.08.06/cmake/modules/RootTestDriver.cmake:201 (message):; error code: 1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/400
https://github.com/root-project/root/pull/401:18,Availability,failure,failure,18,This fixes a test failure on i686:. 17/593 Test #94: test-stressmathcore ........................................***Failed Error regular expression found in output. Regex=[FAILED|Error in] 3.21 sec; Beta distribution 		................ OK; Gamma distribution 		................ OK; Chisquare distribution 		................ OK; Normal distribution 		................ OK; BreitWigner distribution 		................ OK; F distribution 		................ OK; lognormal distribution 		................ OK; Exponential distribution 		................ OK; Landau distribution 		................ OK; Uniform distribution 		................ OK; ******************************************************************************; 	Test of Physics Vector (GenVector package); ******************************************************************************; XYVector creation 		................ OK; XYVector addition 		................ OK; XYVector creation 		................ OK; XYVector setting 		................ OK; XYVector -> Polar2DVector 		................ OK; Vector conversion 		................ OK; XYVector operations 		..............; Polar2DVector operations 		................ OK; XYVector delta values 		..............; Polar2DVector delta values 		................ OK; XYVector write 		................ OK; XYVector read 		................ OK; XYVector after read 		................ OK; Polar2DVector write 		................ OK; Polar2DVector read 		................ OK; Polar2DVector after read 		................ OK; XYZVector creation 		................ OK; XYZVector addition 		................ OK; XYZVector creation 		................ OK; XYZVector setting 		................ OK; XYZVector -> Polar3DVector 		................ OK; Vector conversion 		................ OK; XYZVector operations 		..............; Polar3DVector operations 		................ OK; XYZVector delta values 		..............; Polar3DVector delta values 		................ OK; XYZVector write 		................ OK; XYZ,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/401
https://github.com/root-project/root/pull/401:123,Availability,Error,Error,123,This fixes a test failure on i686:. 17/593 Test #94: test-stressmathcore ........................................***Failed Error regular expression found in output. Regex=[FAILED|Error in] 3.21 sec; Beta distribution 		................ OK; Gamma distribution 		................ OK; Chisquare distribution 		................ OK; Normal distribution 		................ OK; BreitWigner distribution 		................ OK; F distribution 		................ OK; lognormal distribution 		................ OK; Exponential distribution 		................ OK; Landau distribution 		................ OK; Uniform distribution 		................ OK; ******************************************************************************; 	Test of Physics Vector (GenVector package); ******************************************************************************; XYVector creation 		................ OK; XYVector addition 		................ OK; XYVector creation 		................ OK; XYVector setting 		................ OK; XYVector -> Polar2DVector 		................ OK; Vector conversion 		................ OK; XYVector operations 		..............; Polar2DVector operations 		................ OK; XYVector delta values 		..............; Polar2DVector delta values 		................ OK; XYVector write 		................ OK; XYVector read 		................ OK; XYVector after read 		................ OK; Polar2DVector write 		................ OK; Polar2DVector read 		................ OK; Polar2DVector after read 		................ OK; XYZVector creation 		................ OK; XYZVector addition 		................ OK; XYZVector creation 		................ OK; XYZVector setting 		................ OK; XYZVector -> Polar3DVector 		................ OK; Vector conversion 		................ OK; XYZVector operations 		..............; Polar3DVector operations 		................ OK; XYZVector delta values 		..............; Polar3DVector delta values 		................ OK; XYZVector write 		................ OK; XYZ,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/401
https://github.com/root-project/root/pull/401:179,Availability,Error,Error,179,This fixes a test failure on i686:. 17/593 Test #94: test-stressmathcore ........................................***Failed Error regular expression found in output. Regex=[FAILED|Error in] 3.21 sec; Beta distribution 		................ OK; Gamma distribution 		................ OK; Chisquare distribution 		................ OK; Normal distribution 		................ OK; BreitWigner distribution 		................ OK; F distribution 		................ OK; lognormal distribution 		................ OK; Exponential distribution 		................ OK; Landau distribution 		................ OK; Uniform distribution 		................ OK; ******************************************************************************; 	Test of Physics Vector (GenVector package); ******************************************************************************; XYVector creation 		................ OK; XYVector addition 		................ OK; XYVector creation 		................ OK; XYVector setting 		................ OK; XYVector -> Polar2DVector 		................ OK; Vector conversion 		................ OK; XYVector operations 		..............; Polar2DVector operations 		................ OK; XYVector delta values 		..............; Polar2DVector delta values 		................ OK; XYVector write 		................ OK; XYVector read 		................ OK; XYVector after read 		................ OK; Polar2DVector write 		................ OK; Polar2DVector read 		................ OK; Polar2DVector after read 		................ OK; XYZVector creation 		................ OK; XYZVector addition 		................ OK; XYZVector creation 		................ OK; XYZVector setting 		................ OK; XYZVector -> Polar3DVector 		................ OK; Vector conversion 		................ OK; XYZVector operations 		..............; Polar3DVector operations 		................ OK; XYZVector delta values 		..............; Polar3DVector delta values 		................ OK; XYZVector write 		................ OK; XYZ,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/401
https://github.com/root-project/root/pull/401:11403,Availability,Error,Error,11403,est of a Composite Object (containing Vector's and Matrices); ******************************************************************************; Test Using CINT library; TrackD creation 		................ OK; TrackD addition 		................ OK; TrackD write 		................ OK; TrackD read 		................ OK; TrackD after read 		................ OK; TrackD32 creation 		................ OK; TrackD32 addition 		................ OK; TrackD32 write 		................ OK; TrackD32 read 		................ OK; TrackD32 after read 		................ OK; TrackD32 Double32 test 		................ OK; TrackErrD creation 		................ OK; TrackErrD addition 		................ OK; TrackErrD write 		................ OK; TrackErrD read 		................ OK; TrackErrD after read 		................ OK; TrackErrD32 creation 		................ OK; TrackErrD32 addition 		................ OK; TrackErrD32 write 		................ OK; TrackErrD32 read 		................ OK; TrackErrD32 after read 		................ OK; TrackErrD32 Double32 test 		................ OK; VecTrack<TrackD> creation 		................ OK; VecTrack<TrackD> addition 		................ OK; VecTrack<TrackD> write 		................ OK; VecTrack<TrackD> read 		................ OK; VecTrack<TrackD> after read 		................ OK; VecTrack<TrackErrD> creation 		................ OK; VecTrack<TrackErrD> addition 		................ OK; VecTrack<TrackErrD> write 		................ OK; VecTrack<TrackErrD> read 		................ OK; VecTrack<TrackErrD> after read 		................ OK; ******************************************************************************; stressMathCore: Real Time = 2.70 seconds Cpu Time = 2.02 seconds; ROOTMARKS = 3022.77 ROOT version: 6.08/06	v6-08-06@v6-08-06; *******************************************************************************; stressMathCore Test Failed !!; CMake Error at /builddir/build/BUILD/root-6.08.06/cmake/modules/RootTestDriver.cmake:201 (message):; error code: 1,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/401
https://github.com/root-project/root/pull/401:11498,Availability,error,error,11498,est of a Composite Object (containing Vector's and Matrices); ******************************************************************************; Test Using CINT library; TrackD creation 		................ OK; TrackD addition 		................ OK; TrackD write 		................ OK; TrackD read 		................ OK; TrackD after read 		................ OK; TrackD32 creation 		................ OK; TrackD32 addition 		................ OK; TrackD32 write 		................ OK; TrackD32 read 		................ OK; TrackD32 after read 		................ OK; TrackD32 Double32 test 		................ OK; TrackErrD creation 		................ OK; TrackErrD addition 		................ OK; TrackErrD write 		................ OK; TrackErrD read 		................ OK; TrackErrD after read 		................ OK; TrackErrD32 creation 		................ OK; TrackErrD32 addition 		................ OK; TrackErrD32 write 		................ OK; TrackErrD32 read 		................ OK; TrackErrD32 after read 		................ OK; TrackErrD32 Double32 test 		................ OK; VecTrack<TrackD> creation 		................ OK; VecTrack<TrackD> addition 		................ OK; VecTrack<TrackD> write 		................ OK; VecTrack<TrackD> read 		................ OK; VecTrack<TrackD> after read 		................ OK; VecTrack<TrackErrD> creation 		................ OK; VecTrack<TrackErrD> addition 		................ OK; VecTrack<TrackErrD> write 		................ OK; VecTrack<TrackErrD> read 		................ OK; VecTrack<TrackErrD> after read 		................ OK; ******************************************************************************; stressMathCore: Real Time = 2.70 seconds Cpu Time = 2.02 seconds; ROOTMARKS = 3022.77 ROOT version: 6.08/06	v6-08-06@v6-08-06; *******************************************************************************; stressMathCore Test Failed !!; CMake Error at /builddir/build/BUILD/root-6.08.06/cmake/modules/RootTestDriver.cmake:201 (message):; error code: 1,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/401
https://github.com/root-project/root/pull/401:11487,Integrability,message,message,11487,est of a Composite Object (containing Vector's and Matrices); ******************************************************************************; Test Using CINT library; TrackD creation 		................ OK; TrackD addition 		................ OK; TrackD write 		................ OK; TrackD read 		................ OK; TrackD after read 		................ OK; TrackD32 creation 		................ OK; TrackD32 addition 		................ OK; TrackD32 write 		................ OK; TrackD32 read 		................ OK; TrackD32 after read 		................ OK; TrackD32 Double32 test 		................ OK; TrackErrD creation 		................ OK; TrackErrD addition 		................ OK; TrackErrD write 		................ OK; TrackErrD read 		................ OK; TrackErrD after read 		................ OK; TrackErrD32 creation 		................ OK; TrackErrD32 addition 		................ OK; TrackErrD32 write 		................ OK; TrackErrD32 read 		................ OK; TrackErrD32 after read 		................ OK; TrackErrD32 Double32 test 		................ OK; VecTrack<TrackD> creation 		................ OK; VecTrack<TrackD> addition 		................ OK; VecTrack<TrackD> write 		................ OK; VecTrack<TrackD> read 		................ OK; VecTrack<TrackD> after read 		................ OK; VecTrack<TrackErrD> creation 		................ OK; VecTrack<TrackErrD> addition 		................ OK; VecTrack<TrackErrD> write 		................ OK; VecTrack<TrackErrD> read 		................ OK; VecTrack<TrackErrD> after read 		................ OK; ******************************************************************************; stressMathCore: Real Time = 2.70 seconds Cpu Time = 2.02 seconds; ROOTMARKS = 3022.77 ROOT version: 6.08/06	v6-08-06@v6-08-06; *******************************************************************************; stressMathCore Test Failed !!; CMake Error at /builddir/build/BUILD/root-6.08.06/cmake/modules/RootTestDriver.cmake:201 (message):; error code: 1,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/401
https://github.com/root-project/root/pull/401:13,Testability,test,test,13,This fixes a test failure on i686:. 17/593 Test #94: test-stressmathcore ........................................***Failed Error regular expression found in output. Regex=[FAILED|Error in] 3.21 sec; Beta distribution 		................ OK; Gamma distribution 		................ OK; Chisquare distribution 		................ OK; Normal distribution 		................ OK; BreitWigner distribution 		................ OK; F distribution 		................ OK; lognormal distribution 		................ OK; Exponential distribution 		................ OK; Landau distribution 		................ OK; Uniform distribution 		................ OK; ******************************************************************************; 	Test of Physics Vector (GenVector package); ******************************************************************************; XYVector creation 		................ OK; XYVector addition 		................ OK; XYVector creation 		................ OK; XYVector setting 		................ OK; XYVector -> Polar2DVector 		................ OK; Vector conversion 		................ OK; XYVector operations 		..............; Polar2DVector operations 		................ OK; XYVector delta values 		..............; Polar2DVector delta values 		................ OK; XYVector write 		................ OK; XYVector read 		................ OK; XYVector after read 		................ OK; Polar2DVector write 		................ OK; Polar2DVector read 		................ OK; Polar2DVector after read 		................ OK; XYZVector creation 		................ OK; XYZVector addition 		................ OK; XYZVector creation 		................ OK; XYZVector setting 		................ OK; XYZVector -> Polar3DVector 		................ OK; Vector conversion 		................ OK; XYZVector operations 		..............; Polar3DVector operations 		................ OK; XYZVector delta values 		..............; Polar3DVector delta values 		................ OK; XYZVector write 		................ OK; XYZ,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/401
https://github.com/root-project/root/pull/401:43,Testability,Test,Test,43,This fixes a test failure on i686:. 17/593 Test #94: test-stressmathcore ........................................***Failed Error regular expression found in output. Regex=[FAILED|Error in] 3.21 sec; Beta distribution 		................ OK; Gamma distribution 		................ OK; Chisquare distribution 		................ OK; Normal distribution 		................ OK; BreitWigner distribution 		................ OK; F distribution 		................ OK; lognormal distribution 		................ OK; Exponential distribution 		................ OK; Landau distribution 		................ OK; Uniform distribution 		................ OK; ******************************************************************************; 	Test of Physics Vector (GenVector package); ******************************************************************************; XYVector creation 		................ OK; XYVector addition 		................ OK; XYVector creation 		................ OK; XYVector setting 		................ OK; XYVector -> Polar2DVector 		................ OK; Vector conversion 		................ OK; XYVector operations 		..............; Polar2DVector operations 		................ OK; XYVector delta values 		..............; Polar2DVector delta values 		................ OK; XYVector write 		................ OK; XYVector read 		................ OK; XYVector after read 		................ OK; Polar2DVector write 		................ OK; Polar2DVector read 		................ OK; Polar2DVector after read 		................ OK; XYZVector creation 		................ OK; XYZVector addition 		................ OK; XYZVector creation 		................ OK; XYZVector setting 		................ OK; XYZVector -> Polar3DVector 		................ OK; Vector conversion 		................ OK; XYZVector operations 		..............; Polar3DVector operations 		................ OK; XYZVector delta values 		..............; Polar3DVector delta values 		................ OK; XYZVector write 		................ OK; XYZ,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/401
https://github.com/root-project/root/pull/401:53,Testability,test,test-stressmathcore,53,This fixes a test failure on i686:. 17/593 Test #94: test-stressmathcore ........................................***Failed Error regular expression found in output. Regex=[FAILED|Error in] 3.21 sec; Beta distribution 		................ OK; Gamma distribution 		................ OK; Chisquare distribution 		................ OK; Normal distribution 		................ OK; BreitWigner distribution 		................ OK; F distribution 		................ OK; lognormal distribution 		................ OK; Exponential distribution 		................ OK; Landau distribution 		................ OK; Uniform distribution 		................ OK; ******************************************************************************; 	Test of Physics Vector (GenVector package); ******************************************************************************; XYVector creation 		................ OK; XYVector addition 		................ OK; XYVector creation 		................ OK; XYVector setting 		................ OK; XYVector -> Polar2DVector 		................ OK; Vector conversion 		................ OK; XYVector operations 		..............; Polar2DVector operations 		................ OK; XYVector delta values 		..............; Polar2DVector delta values 		................ OK; XYVector write 		................ OK; XYVector read 		................ OK; XYVector after read 		................ OK; Polar2DVector write 		................ OK; Polar2DVector read 		................ OK; Polar2DVector after read 		................ OK; XYZVector creation 		................ OK; XYZVector addition 		................ OK; XYZVector creation 		................ OK; XYZVector setting 		................ OK; XYZVector -> Polar3DVector 		................ OK; Vector conversion 		................ OK; XYZVector operations 		..............; Polar3DVector operations 		................ OK; XYZVector delta values 		..............; Polar3DVector delta values 		................ OK; XYZVector write 		................ OK; XYZ,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/401
https://github.com/root-project/root/pull/401:457,Testability,log,lognormal,457,This fixes a test failure on i686:. 17/593 Test #94: test-stressmathcore ........................................***Failed Error regular expression found in output. Regex=[FAILED|Error in] 3.21 sec; Beta distribution 		................ OK; Gamma distribution 		................ OK; Chisquare distribution 		................ OK; Normal distribution 		................ OK; BreitWigner distribution 		................ OK; F distribution 		................ OK; lognormal distribution 		................ OK; Exponential distribution 		................ OK; Landau distribution 		................ OK; Uniform distribution 		................ OK; ******************************************************************************; 	Test of Physics Vector (GenVector package); ******************************************************************************; XYVector creation 		................ OK; XYVector addition 		................ OK; XYVector creation 		................ OK; XYVector setting 		................ OK; XYVector -> Polar2DVector 		................ OK; Vector conversion 		................ OK; XYVector operations 		..............; Polar2DVector operations 		................ OK; XYVector delta values 		..............; Polar2DVector delta values 		................ OK; XYVector write 		................ OK; XYVector read 		................ OK; XYVector after read 		................ OK; Polar2DVector write 		................ OK; Polar2DVector read 		................ OK; Polar2DVector after read 		................ OK; XYZVector creation 		................ OK; XYZVector addition 		................ OK; XYZVector creation 		................ OK; XYZVector setting 		................ OK; XYZVector -> Polar3DVector 		................ OK; Vector conversion 		................ OK; XYZVector operations 		..............; Polar3DVector operations 		................ OK; XYZVector delta values 		..............; Polar3DVector delta values 		................ OK; XYZVector write 		................ OK; XYZ,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/401
https://github.com/root-project/root/pull/401:719,Testability,Test,Test,719,This fixes a test failure on i686:. 17/593 Test #94: test-stressmathcore ........................................***Failed Error regular expression found in output. Regex=[FAILED|Error in] 3.21 sec; Beta distribution 		................ OK; Gamma distribution 		................ OK; Chisquare distribution 		................ OK; Normal distribution 		................ OK; BreitWigner distribution 		................ OK; F distribution 		................ OK; lognormal distribution 		................ OK; Exponential distribution 		................ OK; Landau distribution 		................ OK; Uniform distribution 		................ OK; ******************************************************************************; 	Test of Physics Vector (GenVector package); ******************************************************************************; XYVector creation 		................ OK; XYVector addition 		................ OK; XYVector creation 		................ OK; XYVector setting 		................ OK; XYVector -> Polar2DVector 		................ OK; Vector conversion 		................ OK; XYVector operations 		..............; Polar2DVector operations 		................ OK; XYVector delta values 		..............; Polar2DVector delta values 		................ OK; XYVector write 		................ OK; XYVector read 		................ OK; XYVector after read 		................ OK; Polar2DVector write 		................ OK; Polar2DVector read 		................ OK; Polar2DVector after read 		................ OK; XYZVector creation 		................ OK; XYZVector addition 		................ OK; XYZVector creation 		................ OK; XYZVector setting 		................ OK; XYZVector -> Polar3DVector 		................ OK; Vector conversion 		................ OK; XYZVector operations 		..............; Polar3DVector operations 		................ OK; XYZVector delta values 		..............; Polar3DVector delta values 		................ OK; XYZVector write 		................ OK; XYZ,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/401
https://github.com/root-project/root/pull/401:6887,Testability,Test,Test,6887,"............... OK; PxPyPzEVector creation 		................ OK; PxPyPzEVector addition 		................ OK; PxPyPzEVector creation 		................ OK; PxPyPzEVector setting 		................ OK; PxPyPzEVector -> PxPyPzMVector 		................ OK; Vector conversion 		................ OK; PxPyPzEVector operations 		..............; PxPyPzMVector operations 		................ OK; PxPyPzEVector delta values 		..............; PxPyPzMVector delta values 		................ OK; PxPyPzEVector write 		................ OK; PxPyPzEVector read 		................ OK; PxPyPzEVector after read 		................ OK; PxPyPzMVector write 		................ OK; PxPyPzMVector read 		................ OK; PxPyPzMVector after read 		................ OK; PxPyPzEVector_D32 write 		................ OK; PxPyPzEVector_D32 read 		................ OK; PxPyPzEVector_D32 after read 		................ OK; ******************************************************************************; 	Test of SMatrix package; ******************************************************************************; SVector<double,3> creation 		................ OK; SVector<double,3> addition 		................ OK; SVector<double,3> write 		................ OK; SVector<double,3> read 		................ OK; SVector<double,3> after read 		................ OK; SVector3_D32 write 		................ OK; SVector3_D32 read 		................ OK; SVector3_D32 after read 		................ OK; SVector<double,4> creation 		................ OK; SVector<double,4> addition 		................ OK; SVector<double,4> write 		................ OK; SVector<double,4> read 		................ OK; SVector<double,4> after read 		................ OK; SVector4_D32 write 		................ OK; SVector4_D32 read 		................ OK; SVector4_D32 after read 		................ OK; SVector<double,6> creation 		................ OK; SVector<double,6> addition 		................ OK; SVector<double,6> write 		................ OK; SVector<double,6> read ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/401
https://github.com/root-project/root/pull/401:9510,Testability,Test,Test,9510,"SMatrix<double,3,3,> addition 		................ OK; SMatrix<double,3,3,> write 		................ OK; SMatrix<double,3,3,> read 		................ OK; SMatrix<double,3,3,> after read 		................ OK; SMatrix<Double32_t,3,3,> write 		................ OK; SMatrix<Double32_t,3,3,> read 		................ OK; SMatrix<Double32_t,3,3,> after read 		................ OK; SMatrix<double,5,5,MatRepSym> creation 		................ OK; SMatrix<double,5,5,MatRepSym> addition 		................ OK; SMatrix<double,5,5,MatRepSym> write 		................ OK; SMatrix<double,5,5,MatRepSym> read 		................ OK; SMatrix<double,5,5,MatRepSym> after read		................ OK; SMatrix<Double32_t,5,5,MatRepSym> write 		................ OK; SMatrix<Double32_t,5,5,MatRepSym> read 		................ OK; SMatrix<Double32_t,5,5,MatRepSym> after read		................ OK; ******************************************************************************; 	Test of a Composite Object (containing Vector's and Matrices); ******************************************************************************; Test Using CINT library; TrackD creation 		................ OK; TrackD addition 		................ OK; TrackD write 		................ OK; TrackD read 		................ OK; TrackD after read 		................ OK; TrackD32 creation 		................ OK; TrackD32 addition 		................ OK; TrackD32 write 		................ OK; TrackD32 read 		................ OK; TrackD32 after read 		................ OK; TrackD32 Double32 test 		................ OK; TrackErrD creation 		................ OK; TrackErrD addition 		................ OK; TrackErrD write 		................ OK; TrackErrD read 		................ OK; TrackErrD after read 		................ OK; TrackErrD32 creation 		................ OK; TrackErrD32 addition 		................ OK; TrackErrD32 write 		................ OK; TrackErrD32 read 		................ OK; TrackErrD32 after read 		................ OK; TrackErrD32 Double32 test 	",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/401
https://github.com/root-project/root/pull/401:9653,Testability,Test,Test,9653,"SMatrix<double,3,3,> addition 		................ OK; SMatrix<double,3,3,> write 		................ OK; SMatrix<double,3,3,> read 		................ OK; SMatrix<double,3,3,> after read 		................ OK; SMatrix<Double32_t,3,3,> write 		................ OK; SMatrix<Double32_t,3,3,> read 		................ OK; SMatrix<Double32_t,3,3,> after read 		................ OK; SMatrix<double,5,5,MatRepSym> creation 		................ OK; SMatrix<double,5,5,MatRepSym> addition 		................ OK; SMatrix<double,5,5,MatRepSym> write 		................ OK; SMatrix<double,5,5,MatRepSym> read 		................ OK; SMatrix<double,5,5,MatRepSym> after read		................ OK; SMatrix<Double32_t,5,5,MatRepSym> write 		................ OK; SMatrix<Double32_t,5,5,MatRepSym> read 		................ OK; SMatrix<Double32_t,5,5,MatRepSym> after read		................ OK; ******************************************************************************; 	Test of a Composite Object (containing Vector's and Matrices); ******************************************************************************; Test Using CINT library; TrackD creation 		................ OK; TrackD addition 		................ OK; TrackD write 		................ OK; TrackD read 		................ OK; TrackD after read 		................ OK; TrackD32 creation 		................ OK; TrackD32 addition 		................ OK; TrackD32 write 		................ OK; TrackD32 read 		................ OK; TrackD32 after read 		................ OK; TrackD32 Double32 test 		................ OK; TrackErrD creation 		................ OK; TrackErrD addition 		................ OK; TrackErrD write 		................ OK; TrackErrD read 		................ OK; TrackErrD after read 		................ OK; TrackErrD32 creation 		................ OK; TrackErrD32 addition 		................ OK; TrackErrD32 write 		................ OK; TrackErrD32 read 		................ OK; TrackErrD32 after read 		................ OK; TrackErrD32 Double32 test 	",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/401
https://github.com/root-project/root/pull/401:10086,Testability,test,test,10086,"tRepSym> write 		................ OK; SMatrix<double,5,5,MatRepSym> read 		................ OK; SMatrix<double,5,5,MatRepSym> after read		................ OK; SMatrix<Double32_t,5,5,MatRepSym> write 		................ OK; SMatrix<Double32_t,5,5,MatRepSym> read 		................ OK; SMatrix<Double32_t,5,5,MatRepSym> after read		................ OK; ******************************************************************************; 	Test of a Composite Object (containing Vector's and Matrices); ******************************************************************************; Test Using CINT library; TrackD creation 		................ OK; TrackD addition 		................ OK; TrackD write 		................ OK; TrackD read 		................ OK; TrackD after read 		................ OK; TrackD32 creation 		................ OK; TrackD32 addition 		................ OK; TrackD32 write 		................ OK; TrackD32 read 		................ OK; TrackD32 after read 		................ OK; TrackD32 Double32 test 		................ OK; TrackErrD creation 		................ OK; TrackErrD addition 		................ OK; TrackErrD write 		................ OK; TrackErrD read 		................ OK; TrackErrD after read 		................ OK; TrackErrD32 creation 		................ OK; TrackErrD32 addition 		................ OK; TrackErrD32 write 		................ OK; TrackErrD32 read 		................ OK; TrackErrD32 after read 		................ OK; TrackErrD32 Double32 test 		................ OK; VecTrack<TrackD> creation 		................ OK; VecTrack<TrackD> addition 		................ OK; VecTrack<TrackD> write 		................ OK; VecTrack<TrackD> read 		................ OK; VecTrack<TrackD> after read 		................ OK; VecTrack<TrackErrD> creation 		................ OK; VecTrack<TrackErrD> addition 		................ OK; VecTrack<TrackErrD> write 		................ OK; VecTrack<TrackErrD> read 		................ OK; VecTrack<TrackErrD> after read 		................ OK; *",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/401
https://github.com/root-project/root/pull/401:10555,Testability,test,test,10555,est of a Composite Object (containing Vector's and Matrices); ******************************************************************************; Test Using CINT library; TrackD creation 		................ OK; TrackD addition 		................ OK; TrackD write 		................ OK; TrackD read 		................ OK; TrackD after read 		................ OK; TrackD32 creation 		................ OK; TrackD32 addition 		................ OK; TrackD32 write 		................ OK; TrackD32 read 		................ OK; TrackD32 after read 		................ OK; TrackD32 Double32 test 		................ OK; TrackErrD creation 		................ OK; TrackErrD addition 		................ OK; TrackErrD write 		................ OK; TrackErrD read 		................ OK; TrackErrD after read 		................ OK; TrackErrD32 creation 		................ OK; TrackErrD32 addition 		................ OK; TrackErrD32 write 		................ OK; TrackErrD32 read 		................ OK; TrackErrD32 after read 		................ OK; TrackErrD32 Double32 test 		................ OK; VecTrack<TrackD> creation 		................ OK; VecTrack<TrackD> addition 		................ OK; VecTrack<TrackD> write 		................ OK; VecTrack<TrackD> read 		................ OK; VecTrack<TrackD> after read 		................ OK; VecTrack<TrackErrD> creation 		................ OK; VecTrack<TrackErrD> addition 		................ OK; VecTrack<TrackErrD> write 		................ OK; VecTrack<TrackErrD> read 		................ OK; VecTrack<TrackErrD> after read 		................ OK; ******************************************************************************; stressMathCore: Real Time = 2.70 seconds Cpu Time = 2.02 seconds; ROOTMARKS = 3022.77 ROOT version: 6.08/06	v6-08-06@v6-08-06; *******************************************************************************; stressMathCore Test Failed !!; CMake Error at /builddir/build/BUILD/root-6.08.06/cmake/modules/RootTestDriver.cmake:201 (message):; error code: 1,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/401
https://github.com/root-project/root/pull/401:11381,Testability,Test,Test,11381,est of a Composite Object (containing Vector's and Matrices); ******************************************************************************; Test Using CINT library; TrackD creation 		................ OK; TrackD addition 		................ OK; TrackD write 		................ OK; TrackD read 		................ OK; TrackD after read 		................ OK; TrackD32 creation 		................ OK; TrackD32 addition 		................ OK; TrackD32 write 		................ OK; TrackD32 read 		................ OK; TrackD32 after read 		................ OK; TrackD32 Double32 test 		................ OK; TrackErrD creation 		................ OK; TrackErrD addition 		................ OK; TrackErrD write 		................ OK; TrackErrD read 		................ OK; TrackErrD after read 		................ OK; TrackErrD32 creation 		................ OK; TrackErrD32 addition 		................ OK; TrackErrD32 write 		................ OK; TrackErrD32 read 		................ OK; TrackErrD32 after read 		................ OK; TrackErrD32 Double32 test 		................ OK; VecTrack<TrackD> creation 		................ OK; VecTrack<TrackD> addition 		................ OK; VecTrack<TrackD> write 		................ OK; VecTrack<TrackD> read 		................ OK; VecTrack<TrackD> after read 		................ OK; VecTrack<TrackErrD> creation 		................ OK; VecTrack<TrackErrD> addition 		................ OK; VecTrack<TrackErrD> write 		................ OK; VecTrack<TrackErrD> read 		................ OK; VecTrack<TrackErrD> after read 		................ OK; ******************************************************************************; stressMathCore: Real Time = 2.70 seconds Cpu Time = 2.02 seconds; ROOTMARKS = 3022.77 ROOT version: 6.08/06	v6-08-06@v6-08-06; *******************************************************************************; stressMathCore Test Failed !!; CMake Error at /builddir/build/BUILD/root-6.08.06/cmake/modules/RootTestDriver.cmake:201 (message):; error code: 1,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/401
https://github.com/root-project/root/pull/402:121,Availability,down,downloads,121,"The TestData target is currently declared ALL, which means it is always executed during the build.; However, the data it downloads is only used for running the stressProof test, so if this test is not run the downloaded data files are not needed. By removing the TestData target from ALL and making it a requirement of the test-stressproof target instead, the files are only downloaded if they are needed. Disabling the stressProof test now also disables the download of the data files. This is important when building in an environment without network access.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/402
https://github.com/root-project/root/pull/402:209,Availability,down,downloaded,209,"The TestData target is currently declared ALL, which means it is always executed during the build.; However, the data it downloads is only used for running the stressProof test, so if this test is not run the downloaded data files are not needed. By removing the TestData target from ALL and making it a requirement of the test-stressproof target instead, the files are only downloaded if they are needed. Disabling the stressProof test now also disables the download of the data files. This is important when building in an environment without network access.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/402
https://github.com/root-project/root/pull/402:375,Availability,down,downloaded,375,"The TestData target is currently declared ALL, which means it is always executed during the build.; However, the data it downloads is only used for running the stressProof test, so if this test is not run the downloaded data files are not needed. By removing the TestData target from ALL and making it a requirement of the test-stressproof target instead, the files are only downloaded if they are needed. Disabling the stressProof test now also disables the download of the data files. This is important when building in an environment without network access.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/402
https://github.com/root-project/root/pull/402:459,Availability,down,download,459,"The TestData target is currently declared ALL, which means it is always executed during the build.; However, the data it downloads is only used for running the stressProof test, so if this test is not run the downloaded data files are not needed. By removing the TestData target from ALL and making it a requirement of the test-stressproof target instead, the files are only downloaded if they are needed. Disabling the stressProof test now also disables the download of the data files. This is important when building in an environment without network access.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/402
https://github.com/root-project/root/pull/402:553,Security,access,access,553,"The TestData target is currently declared ALL, which means it is always executed during the build.; However, the data it downloads is only used for running the stressProof test, so if this test is not run the downloaded data files are not needed. By removing the TestData target from ALL and making it a requirement of the test-stressproof target instead, the files are only downloaded if they are needed. Disabling the stressProof test now also disables the download of the data files. This is important when building in an environment without network access.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/402
https://github.com/root-project/root/pull/402:4,Testability,Test,TestData,4,"The TestData target is currently declared ALL, which means it is always executed during the build.; However, the data it downloads is only used for running the stressProof test, so if this test is not run the downloaded data files are not needed. By removing the TestData target from ALL and making it a requirement of the test-stressproof target instead, the files are only downloaded if they are needed. Disabling the stressProof test now also disables the download of the data files. This is important when building in an environment without network access.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/402
https://github.com/root-project/root/pull/402:172,Testability,test,test,172,"The TestData target is currently declared ALL, which means it is always executed during the build.; However, the data it downloads is only used for running the stressProof test, so if this test is not run the downloaded data files are not needed. By removing the TestData target from ALL and making it a requirement of the test-stressproof target instead, the files are only downloaded if they are needed. Disabling the stressProof test now also disables the download of the data files. This is important when building in an environment without network access.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/402
https://github.com/root-project/root/pull/402:189,Testability,test,test,189,"The TestData target is currently declared ALL, which means it is always executed during the build.; However, the data it downloads is only used for running the stressProof test, so if this test is not run the downloaded data files are not needed. By removing the TestData target from ALL and making it a requirement of the test-stressproof target instead, the files are only downloaded if they are needed. Disabling the stressProof test now also disables the download of the data files. This is important when building in an environment without network access.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/402
https://github.com/root-project/root/pull/402:263,Testability,Test,TestData,263,"The TestData target is currently declared ALL, which means it is always executed during the build.; However, the data it downloads is only used for running the stressProof test, so if this test is not run the downloaded data files are not needed. By removing the TestData target from ALL and making it a requirement of the test-stressproof target instead, the files are only downloaded if they are needed. Disabling the stressProof test now also disables the download of the data files. This is important when building in an environment without network access.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/402
https://github.com/root-project/root/pull/402:323,Testability,test,test-stressproof,323,"The TestData target is currently declared ALL, which means it is always executed during the build.; However, the data it downloads is only used for running the stressProof test, so if this test is not run the downloaded data files are not needed. By removing the TestData target from ALL and making it a requirement of the test-stressproof target instead, the files are only downloaded if they are needed. Disabling the stressProof test now also disables the download of the data files. This is important when building in an environment without network access.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/402
https://github.com/root-project/root/pull/402:432,Testability,test,test,432,"The TestData target is currently declared ALL, which means it is always executed during the build.; However, the data it downloads is only used for running the stressProof test, so if this test is not run the downloaded data files are not needed. By removing the TestData target from ALL and making it a requirement of the test-stressproof target instead, the files are only downloaded if they are needed. Disabling the stressProof test now also disables the download of the data files. This is important when building in an environment without network access.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/402
https://github.com/root-project/root/pull/403:16,Availability,avail,available,16,These files are available in the source tree. By trying these local copies before trying the remote copies it is possible to run the tests without network access.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/403
https://github.com/root-project/root/pull/403:155,Security,access,access,155,These files are available in the source tree. By trying these local copies before trying the remote copies it is possible to run the tests without network access.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/403
https://github.com/root-project/root/pull/403:133,Testability,test,tests,133,These files are available in the source tree. By trying these local copies before trying the remote copies it is possible to run the tests without network access.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/403
https://github.com/root-project/root/pull/404:39,Availability,down,downloaded,39,"This makes it possible to create a pre-downloaded cache before running the tests, so that it is possible to run the tests in an environment without network access.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/404
https://github.com/root-project/root/pull/404:50,Performance,cache,cache,50,"This makes it possible to create a pre-downloaded cache before running the tests, so that it is possible to run the tests in an environment without network access.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/404
https://github.com/root-project/root/pull/404:156,Security,access,access,156,"This makes it possible to create a pre-downloaded cache before running the tests, so that it is possible to run the tests in an environment without network access.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/404
https://github.com/root-project/root/pull/404:75,Testability,test,tests,75,"This makes it possible to create a pre-downloaded cache before running the tests, so that it is possible to run the tests in an environment without network access.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/404
https://github.com/root-project/root/pull/404:116,Testability,test,tests,116,"This makes it possible to create a pre-downloaded cache before running the tests, so that it is possible to run the tests in an environment without network access.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/404
https://github.com/root-project/root/pull/406:34,Modifiability,config,config,34,The s390x arch was lost from root-config. This restores the functionality.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/406
https://github.com/root-project/root/pull/407:319,Availability,echo,echo,319,"when removing old paths make sure that $path:, :$path and $path are only matched; at the beginning, at the end, or match the whole string.; This fixes a problem with removing parts of a path. For example. ```; export ROOTSYS=/my/path; export LD_LIBRARY_PATH=/other/path:/my/path/lib:/my/path/lib/subdir; . thisroot.sh; echo $LD_LIBRARY_PATH; ```. would output the path to the root libraries followed by `:/other/path/subdir/`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/407
https://github.com/root-project/root/pull/408:0,Testability,Test,Tests,0,"Tests are labeled `longtest` if they run longer than 1 minute, based on this build: http://cdash.cern.ch/viewTest.php?onlypassed&buildid=329399; This is to be able to skip tests that runs for longer time, when for example during building of PRs when extensive testing may not be needed. Will make another PR in https://github.com/root-project/roottest as well that has the other tests labeled.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/408
https://github.com/root-project/root/pull/408:172,Testability,test,tests,172,"Tests are labeled `longtest` if they run longer than 1 minute, based on this build: http://cdash.cern.ch/viewTest.php?onlypassed&buildid=329399; This is to be able to skip tests that runs for longer time, when for example during building of PRs when extensive testing may not be needed. Will make another PR in https://github.com/root-project/roottest as well that has the other tests labeled.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/408
https://github.com/root-project/root/pull/408:260,Testability,test,testing,260,"Tests are labeled `longtest` if they run longer than 1 minute, based on this build: http://cdash.cern.ch/viewTest.php?onlypassed&buildid=329399; This is to be able to skip tests that runs for longer time, when for example during building of PRs when extensive testing may not be needed. Will make another PR in https://github.com/root-project/roottest as well that has the other tests labeled.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/408
https://github.com/root-project/root/pull/408:379,Testability,test,tests,379,"Tests are labeled `longtest` if they run longer than 1 minute, based on this build: http://cdash.cern.ch/viewTest.php?onlypassed&buildid=329399; This is to be able to skip tests that runs for longer time, when for example during building of PRs when extensive testing may not be needed. Will make another PR in https://github.com/root-project/roottest as well that has the other tests labeled.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/408
https://github.com/root-project/root/pull/413:167,Availability,echo,echo,167,"The default `SIGPIPE` handler installed by `TUnixSystem` does not do anything except print a message and possibly causing an endless loop of `SIGPIPE` handling:. ```; echo 'std::cout << ""foo"" << std::endl;' | root -l |& true; python -c 'import ROOT; print ""foo""' |& true; ```. This fixes ROOT-4568 and ROOT-7659. The alternative would be to remove all pending sigpipe signals which might have occurred while handling the signal itself. This would keep the current behavior and still fix the endless loop. . However think that not handling SIGPIPE by default would be a wiser choice as I don't see a real use case for printing that a SIGPIPE was received and then continuing normally.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/413
https://github.com/root-project/root/pull/413:30,Deployability,install,installed,30,"The default `SIGPIPE` handler installed by `TUnixSystem` does not do anything except print a message and possibly causing an endless loop of `SIGPIPE` handling:. ```; echo 'std::cout << ""foo"" << std::endl;' | root -l |& true; python -c 'import ROOT; print ""foo""' |& true; ```. This fixes ROOT-4568 and ROOT-7659. The alternative would be to remove all pending sigpipe signals which might have occurred while handling the signal itself. This would keep the current behavior and still fix the endless loop. . However think that not handling SIGPIPE by default would be a wiser choice as I don't see a real use case for printing that a SIGPIPE was received and then continuing normally.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/413
https://github.com/root-project/root/pull/413:93,Integrability,message,message,93,"The default `SIGPIPE` handler installed by `TUnixSystem` does not do anything except print a message and possibly causing an endless loop of `SIGPIPE` handling:. ```; echo 'std::cout << ""foo"" << std::endl;' | root -l |& true; python -c 'import ROOT; print ""foo""' |& true; ```. This fixes ROOT-4568 and ROOT-7659. The alternative would be to remove all pending sigpipe signals which might have occurred while handling the signal itself. This would keep the current behavior and still fix the endless loop. . However think that not handling SIGPIPE by default would be a wiser choice as I don't see a real use case for printing that a SIGPIPE was received and then continuing normally.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/413
https://github.com/root-project/root/pull/420:21,Performance,race condition,race condition,21,"This PR should fix a race condition with some of the TMVA tutorials on ARM, as they all use the same files in the `dataset` folder: http://cdash.cern.ch/testDetails.php?test=22693533&build=331203",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/420
https://github.com/root-project/root/pull/420:153,Testability,test,testDetails,153,"This PR should fix a race condition with some of the TMVA tutorials on ARM, as they all use the same files in the `dataset` folder: http://cdash.cern.ch/testDetails.php?test=22693533&build=331203",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/420
https://github.com/root-project/root/pull/420:169,Testability,test,test,169,"This PR should fix a race condition with some of the TMVA tutorials on ARM, as they all use the same files in the `dataset` folder: http://cdash.cern.ch/testDetails.php?test=22693533&build=331203",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/420
https://github.com/root-project/root/pull/423:1013,Energy Efficiency,green,green-lit,1013,"This PR is a work-in-progress. Submitting mainly to get feedback and test on all platforms (it compiles and tests run on my machines). `TDataFrame.hxx` neared the 2000 lines, so I decided to bite the bullet and disentangle it in logically separated parts. `TDataFrame`'s functionality is now divided as follows:. - `TDataFrame.{hxx,cxx}`: class `TDataFrame`; - `TDataFrameInterface.{hxx,cxx}`: class `TDataFrameInterface`; - `TDFNodes.{hxx,cxx}`: class `TDataFrameImpl`, `TDataFrameAction{,Base}`, `TDataFrameBranch{,Base}`, `TDataFrameFilter{,Base}`; - `TActionResultProxy.hxx`: class `TActionResultProxy`; - `TDFOperations.{hxx,cxx}`: all `*Operation` classes; - `TDFTraitsUtils.hxx` -> `TDFUtils.{hxx,cxx}`: all helper functions and meta-helpers. I also ran `clang-format` and `include-what-you-use` on these files to improve coding style and useless/misplaced includes. I plan to squash all commits into just two/three (one for splitting, one for formatting, one for the includes) if/when the changes will be green-lit. **Open issues**; - [x] `TActionResultProxy::TriggerRun` is still in `TDataFrame.hxx` because it depends on TDataFrameImpl. Moving it into `TActionResultProxy.hxx` would cause a circular include dependency; - [x] `ColumnName2ColumnTypeName` is in `TDataFrameInterface.{hxx,cxx}`, but being an helper function it should actually be in `TDFUtils.hxx`. This would cause a circular include dependency with `TDFNodes.hxx` due to `TDataFrameImpl`; - [x] same for `CallCreateAction`, but the circular dependency is with `TActionResultProxy`. This function is much less general than the former though, so maybe it could stay in `TDataFrameInterface.{hxx,cxx}`; - [x] `TSlotStack` is now declared and defined at namespace scope in `TDFNodes.cxx`. Declaration and definitions should be split, the class itself should probably be nested inside `TDataFrameImpl`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/423
https://github.com/root-project/root/pull/423:1120,Integrability,depend,depends,1120,"This PR is a work-in-progress. Submitting mainly to get feedback and test on all platforms (it compiles and tests run on my machines). `TDataFrame.hxx` neared the 2000 lines, so I decided to bite the bullet and disentangle it in logically separated parts. `TDataFrame`'s functionality is now divided as follows:. - `TDataFrame.{hxx,cxx}`: class `TDataFrame`; - `TDataFrameInterface.{hxx,cxx}`: class `TDataFrameInterface`; - `TDFNodes.{hxx,cxx}`: class `TDataFrameImpl`, `TDataFrameAction{,Base}`, `TDataFrameBranch{,Base}`, `TDataFrameFilter{,Base}`; - `TActionResultProxy.hxx`: class `TActionResultProxy`; - `TDFOperations.{hxx,cxx}`: all `*Operation` classes; - `TDFTraitsUtils.hxx` -> `TDFUtils.{hxx,cxx}`: all helper functions and meta-helpers. I also ran `clang-format` and `include-what-you-use` on these files to improve coding style and useless/misplaced includes. I plan to squash all commits into just two/three (one for splitting, one for formatting, one for the includes) if/when the changes will be green-lit. **Open issues**; - [x] `TActionResultProxy::TriggerRun` is still in `TDataFrame.hxx` because it depends on TDataFrameImpl. Moving it into `TActionResultProxy.hxx` would cause a circular include dependency; - [x] `ColumnName2ColumnTypeName` is in `TDataFrameInterface.{hxx,cxx}`, but being an helper function it should actually be in `TDFUtils.hxx`. This would cause a circular include dependency with `TDFNodes.hxx` due to `TDataFrameImpl`; - [x] same for `CallCreateAction`, but the circular dependency is with `TActionResultProxy`. This function is much less general than the former though, so maybe it could stay in `TDataFrameInterface.{hxx,cxx}`; - [x] `TSlotStack` is now declared and defined at namespace scope in `TDFNodes.cxx`. Declaration and definitions should be split, the class itself should probably be nested inside `TDataFrameImpl`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/423
https://github.com/root-project/root/pull/423:1218,Integrability,depend,dependency,1218,"This PR is a work-in-progress. Submitting mainly to get feedback and test on all platforms (it compiles and tests run on my machines). `TDataFrame.hxx` neared the 2000 lines, so I decided to bite the bullet and disentangle it in logically separated parts. `TDataFrame`'s functionality is now divided as follows:. - `TDataFrame.{hxx,cxx}`: class `TDataFrame`; - `TDataFrameInterface.{hxx,cxx}`: class `TDataFrameInterface`; - `TDFNodes.{hxx,cxx}`: class `TDataFrameImpl`, `TDataFrameAction{,Base}`, `TDataFrameBranch{,Base}`, `TDataFrameFilter{,Base}`; - `TActionResultProxy.hxx`: class `TActionResultProxy`; - `TDFOperations.{hxx,cxx}`: all `*Operation` classes; - `TDFTraitsUtils.hxx` -> `TDFUtils.{hxx,cxx}`: all helper functions and meta-helpers. I also ran `clang-format` and `include-what-you-use` on these files to improve coding style and useless/misplaced includes. I plan to squash all commits into just two/three (one for splitting, one for formatting, one for the includes) if/when the changes will be green-lit. **Open issues**; - [x] `TActionResultProxy::TriggerRun` is still in `TDataFrame.hxx` because it depends on TDataFrameImpl. Moving it into `TActionResultProxy.hxx` would cause a circular include dependency; - [x] `ColumnName2ColumnTypeName` is in `TDataFrameInterface.{hxx,cxx}`, but being an helper function it should actually be in `TDFUtils.hxx`. This would cause a circular include dependency with `TDFNodes.hxx` due to `TDataFrameImpl`; - [x] same for `CallCreateAction`, but the circular dependency is with `TActionResultProxy`. This function is much less general than the former though, so maybe it could stay in `TDataFrameInterface.{hxx,cxx}`; - [x] `TSlotStack` is now declared and defined at namespace scope in `TDFNodes.cxx`. Declaration and definitions should be split, the class itself should probably be nested inside `TDataFrameImpl`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/423
https://github.com/root-project/root/pull/423:1409,Integrability,depend,dependency,1409,"This PR is a work-in-progress. Submitting mainly to get feedback and test on all platforms (it compiles and tests run on my machines). `TDataFrame.hxx` neared the 2000 lines, so I decided to bite the bullet and disentangle it in logically separated parts. `TDataFrame`'s functionality is now divided as follows:. - `TDataFrame.{hxx,cxx}`: class `TDataFrame`; - `TDataFrameInterface.{hxx,cxx}`: class `TDataFrameInterface`; - `TDFNodes.{hxx,cxx}`: class `TDataFrameImpl`, `TDataFrameAction{,Base}`, `TDataFrameBranch{,Base}`, `TDataFrameFilter{,Base}`; - `TActionResultProxy.hxx`: class `TActionResultProxy`; - `TDFOperations.{hxx,cxx}`: all `*Operation` classes; - `TDFTraitsUtils.hxx` -> `TDFUtils.{hxx,cxx}`: all helper functions and meta-helpers. I also ran `clang-format` and `include-what-you-use` on these files to improve coding style and useless/misplaced includes. I plan to squash all commits into just two/three (one for splitting, one for formatting, one for the includes) if/when the changes will be green-lit. **Open issues**; - [x] `TActionResultProxy::TriggerRun` is still in `TDataFrame.hxx` because it depends on TDataFrameImpl. Moving it into `TActionResultProxy.hxx` would cause a circular include dependency; - [x] `ColumnName2ColumnTypeName` is in `TDataFrameInterface.{hxx,cxx}`, but being an helper function it should actually be in `TDFUtils.hxx`. This would cause a circular include dependency with `TDFNodes.hxx` due to `TDataFrameImpl`; - [x] same for `CallCreateAction`, but the circular dependency is with `TActionResultProxy`. This function is much less general than the former though, so maybe it could stay in `TDataFrameInterface.{hxx,cxx}`; - [x] `TSlotStack` is now declared and defined at namespace scope in `TDFNodes.cxx`. Declaration and definitions should be split, the class itself should probably be nested inside `TDataFrameImpl`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/423
https://github.com/root-project/root/pull/423:1517,Integrability,depend,dependency,1517,"This PR is a work-in-progress. Submitting mainly to get feedback and test on all platforms (it compiles and tests run on my machines). `TDataFrame.hxx` neared the 2000 lines, so I decided to bite the bullet and disentangle it in logically separated parts. `TDataFrame`'s functionality is now divided as follows:. - `TDataFrame.{hxx,cxx}`: class `TDataFrame`; - `TDataFrameInterface.{hxx,cxx}`: class `TDataFrameInterface`; - `TDFNodes.{hxx,cxx}`: class `TDataFrameImpl`, `TDataFrameAction{,Base}`, `TDataFrameBranch{,Base}`, `TDataFrameFilter{,Base}`; - `TActionResultProxy.hxx`: class `TActionResultProxy`; - `TDFOperations.{hxx,cxx}`: all `*Operation` classes; - `TDFTraitsUtils.hxx` -> `TDFUtils.{hxx,cxx}`: all helper functions and meta-helpers. I also ran `clang-format` and `include-what-you-use` on these files to improve coding style and useless/misplaced includes. I plan to squash all commits into just two/three (one for splitting, one for formatting, one for the includes) if/when the changes will be green-lit. **Open issues**; - [x] `TActionResultProxy::TriggerRun` is still in `TDataFrame.hxx` because it depends on TDataFrameImpl. Moving it into `TActionResultProxy.hxx` would cause a circular include dependency; - [x] `ColumnName2ColumnTypeName` is in `TDataFrameInterface.{hxx,cxx}`, but being an helper function it should actually be in `TDFUtils.hxx`. This would cause a circular include dependency with `TDFNodes.hxx` due to `TDataFrameImpl`; - [x] same for `CallCreateAction`, but the circular dependency is with `TActionResultProxy`. This function is much less general than the former though, so maybe it could stay in `TDataFrameInterface.{hxx,cxx}`; - [x] `TSlotStack` is now declared and defined at namespace scope in `TDFNodes.cxx`. Declaration and definitions should be split, the class itself should probably be nested inside `TDataFrameImpl`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/423
https://github.com/root-project/root/pull/423:69,Testability,test,test,69,"This PR is a work-in-progress. Submitting mainly to get feedback and test on all platforms (it compiles and tests run on my machines). `TDataFrame.hxx` neared the 2000 lines, so I decided to bite the bullet and disentangle it in logically separated parts. `TDataFrame`'s functionality is now divided as follows:. - `TDataFrame.{hxx,cxx}`: class `TDataFrame`; - `TDataFrameInterface.{hxx,cxx}`: class `TDataFrameInterface`; - `TDFNodes.{hxx,cxx}`: class `TDataFrameImpl`, `TDataFrameAction{,Base}`, `TDataFrameBranch{,Base}`, `TDataFrameFilter{,Base}`; - `TActionResultProxy.hxx`: class `TActionResultProxy`; - `TDFOperations.{hxx,cxx}`: all `*Operation` classes; - `TDFTraitsUtils.hxx` -> `TDFUtils.{hxx,cxx}`: all helper functions and meta-helpers. I also ran `clang-format` and `include-what-you-use` on these files to improve coding style and useless/misplaced includes. I plan to squash all commits into just two/three (one for splitting, one for formatting, one for the includes) if/when the changes will be green-lit. **Open issues**; - [x] `TActionResultProxy::TriggerRun` is still in `TDataFrame.hxx` because it depends on TDataFrameImpl. Moving it into `TActionResultProxy.hxx` would cause a circular include dependency; - [x] `ColumnName2ColumnTypeName` is in `TDataFrameInterface.{hxx,cxx}`, but being an helper function it should actually be in `TDFUtils.hxx`. This would cause a circular include dependency with `TDFNodes.hxx` due to `TDataFrameImpl`; - [x] same for `CallCreateAction`, but the circular dependency is with `TActionResultProxy`. This function is much less general than the former though, so maybe it could stay in `TDataFrameInterface.{hxx,cxx}`; - [x] `TSlotStack` is now declared and defined at namespace scope in `TDFNodes.cxx`. Declaration and definitions should be split, the class itself should probably be nested inside `TDataFrameImpl`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/423
https://github.com/root-project/root/pull/423:108,Testability,test,tests,108,"This PR is a work-in-progress. Submitting mainly to get feedback and test on all platforms (it compiles and tests run on my machines). `TDataFrame.hxx` neared the 2000 lines, so I decided to bite the bullet and disentangle it in logically separated parts. `TDataFrame`'s functionality is now divided as follows:. - `TDataFrame.{hxx,cxx}`: class `TDataFrame`; - `TDataFrameInterface.{hxx,cxx}`: class `TDataFrameInterface`; - `TDFNodes.{hxx,cxx}`: class `TDataFrameImpl`, `TDataFrameAction{,Base}`, `TDataFrameBranch{,Base}`, `TDataFrameFilter{,Base}`; - `TActionResultProxy.hxx`: class `TActionResultProxy`; - `TDFOperations.{hxx,cxx}`: all `*Operation` classes; - `TDFTraitsUtils.hxx` -> `TDFUtils.{hxx,cxx}`: all helper functions and meta-helpers. I also ran `clang-format` and `include-what-you-use` on these files to improve coding style and useless/misplaced includes. I plan to squash all commits into just two/three (one for splitting, one for formatting, one for the includes) if/when the changes will be green-lit. **Open issues**; - [x] `TActionResultProxy::TriggerRun` is still in `TDataFrame.hxx` because it depends on TDataFrameImpl. Moving it into `TActionResultProxy.hxx` would cause a circular include dependency; - [x] `ColumnName2ColumnTypeName` is in `TDataFrameInterface.{hxx,cxx}`, but being an helper function it should actually be in `TDFUtils.hxx`. This would cause a circular include dependency with `TDFNodes.hxx` due to `TDataFrameImpl`; - [x] same for `CallCreateAction`, but the circular dependency is with `TActionResultProxy`. This function is much less general than the former though, so maybe it could stay in `TDataFrameInterface.{hxx,cxx}`; - [x] `TSlotStack` is now declared and defined at namespace scope in `TDFNodes.cxx`. Declaration and definitions should be split, the class itself should probably be nested inside `TDataFrameImpl`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/423
https://github.com/root-project/root/pull/423:229,Testability,log,logically,229,"This PR is a work-in-progress. Submitting mainly to get feedback and test on all platforms (it compiles and tests run on my machines). `TDataFrame.hxx` neared the 2000 lines, so I decided to bite the bullet and disentangle it in logically separated parts. `TDataFrame`'s functionality is now divided as follows:. - `TDataFrame.{hxx,cxx}`: class `TDataFrame`; - `TDataFrameInterface.{hxx,cxx}`: class `TDataFrameInterface`; - `TDFNodes.{hxx,cxx}`: class `TDataFrameImpl`, `TDataFrameAction{,Base}`, `TDataFrameBranch{,Base}`, `TDataFrameFilter{,Base}`; - `TActionResultProxy.hxx`: class `TActionResultProxy`; - `TDFOperations.{hxx,cxx}`: all `*Operation` classes; - `TDFTraitsUtils.hxx` -> `TDFUtils.{hxx,cxx}`: all helper functions and meta-helpers. I also ran `clang-format` and `include-what-you-use` on these files to improve coding style and useless/misplaced includes. I plan to squash all commits into just two/three (one for splitting, one for formatting, one for the includes) if/when the changes will be green-lit. **Open issues**; - [x] `TActionResultProxy::TriggerRun` is still in `TDataFrame.hxx` because it depends on TDataFrameImpl. Moving it into `TActionResultProxy.hxx` would cause a circular include dependency; - [x] `ColumnName2ColumnTypeName` is in `TDataFrameInterface.{hxx,cxx}`, but being an helper function it should actually be in `TDFUtils.hxx`. This would cause a circular include dependency with `TDFNodes.hxx` due to `TDataFrameImpl`; - [x] same for `CallCreateAction`, but the circular dependency is with `TActionResultProxy`. This function is much less general than the former though, so maybe it could stay in `TDataFrameInterface.{hxx,cxx}`; - [x] `TSlotStack` is now declared and defined at namespace scope in `TDFNodes.cxx`. Declaration and definitions should be split, the class itself should probably be nested inside `TDataFrameImpl`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/423
https://github.com/root-project/root/pull/423:56,Usability,feedback,feedback,56,"This PR is a work-in-progress. Submitting mainly to get feedback and test on all platforms (it compiles and tests run on my machines). `TDataFrame.hxx` neared the 2000 lines, so I decided to bite the bullet and disentangle it in logically separated parts. `TDataFrame`'s functionality is now divided as follows:. - `TDataFrame.{hxx,cxx}`: class `TDataFrame`; - `TDataFrameInterface.{hxx,cxx}`: class `TDataFrameInterface`; - `TDFNodes.{hxx,cxx}`: class `TDataFrameImpl`, `TDataFrameAction{,Base}`, `TDataFrameBranch{,Base}`, `TDataFrameFilter{,Base}`; - `TActionResultProxy.hxx`: class `TActionResultProxy`; - `TDFOperations.{hxx,cxx}`: all `*Operation` classes; - `TDFTraitsUtils.hxx` -> `TDFUtils.{hxx,cxx}`: all helper functions and meta-helpers. I also ran `clang-format` and `include-what-you-use` on these files to improve coding style and useless/misplaced includes. I plan to squash all commits into just two/three (one for splitting, one for formatting, one for the includes) if/when the changes will be green-lit. **Open issues**; - [x] `TActionResultProxy::TriggerRun` is still in `TDataFrame.hxx` because it depends on TDataFrameImpl. Moving it into `TActionResultProxy.hxx` would cause a circular include dependency; - [x] `ColumnName2ColumnTypeName` is in `TDataFrameInterface.{hxx,cxx}`, but being an helper function it should actually be in `TDFUtils.hxx`. This would cause a circular include dependency with `TDFNodes.hxx` due to `TDataFrameImpl`; - [x] same for `CallCreateAction`, but the circular dependency is with `TActionResultProxy`. This function is much less general than the former though, so maybe it could stay in `TDataFrameInterface.{hxx,cxx}`; - [x] `TSlotStack` is now declared and defined at namespace scope in `TDFNodes.cxx`. Declaration and definitions should be split, the class itself should probably be nested inside `TDataFrameImpl`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/423
https://github.com/root-project/root/pull/425:91,Deployability,configurat,configuration,91,The current builds fail because without a valid modulemap the setresuid test failed during configuration time.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/425
https://github.com/root-project/root/pull/425:91,Modifiability,config,configuration,91,The current builds fail because without a valid modulemap the setresuid test failed during configuration time.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/425
https://github.com/root-project/root/pull/425:72,Testability,test,test,72,The current builds fail because without a valid modulemap the setresuid test failed during configuration time.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/425
https://github.com/root-project/root/pull/426:108,Integrability,depend,depend,108,"Some of the TMVA tutorials run in parallel and rely on the same generated file. Typically, one tutorial may depend on another one that generates the file. The top level ones did not depend on each other, thus running in parallel and causing a race condition. This PR should solve this issue by making them depend on each other.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/426
https://github.com/root-project/root/pull/426:182,Integrability,depend,depend,182,"Some of the TMVA tutorials run in parallel and rely on the same generated file. Typically, one tutorial may depend on another one that generates the file. The top level ones did not depend on each other, thus running in parallel and causing a race condition. This PR should solve this issue by making them depend on each other.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/426
https://github.com/root-project/root/pull/426:306,Integrability,depend,depend,306,"Some of the TMVA tutorials run in parallel and rely on the same generated file. Typically, one tutorial may depend on another one that generates the file. The top level ones did not depend on each other, thus running in parallel and causing a race condition. This PR should solve this issue by making them depend on each other.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/426
https://github.com/root-project/root/pull/426:243,Performance,race condition,race condition,243,"Some of the TMVA tutorials run in parallel and rely on the same generated file. Typically, one tutorial may depend on another one that generates the file. The top level ones did not depend on each other, thus running in parallel and causing a race condition. This PR should solve this issue by making them depend on each other.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/426
https://github.com/root-project/root/pull/427:50,Testability,test,test,50,"Changes the enable_if pattern in the Vc Genvector test application, to match the changes made in #394 during review.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/427
https://github.com/root-project/root/pull/428:239,Testability,Test,Tested,239,"Previously, CMake would ignore the path on Mac nodes since Mac enables the flag macos_native which ignores paths under `/sw`, `/opt/local`, and `/usr/local` when calling `find_program`. Providing the path as a hint makes it find ccache. ; Tested on macitois13.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/428
https://github.com/root-project/root/pull/429:32,Modifiability,config,config,32,Ccache has an issue reading the config file on some Linux distros when using an invalid kerberos ticket. For some reason it will attempt to access a ccache config file in the home directory which it does does not have permission to do causing ccache to exit. Approach suggested by @dpiparo,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/429
https://github.com/root-project/root/pull/429:156,Modifiability,config,config,156,Ccache has an issue reading the config file on some Linux distros when using an invalid kerberos ticket. For some reason it will attempt to access a ccache config file in the home directory which it does does not have permission to do causing ccache to exit. Approach suggested by @dpiparo,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/429
https://github.com/root-project/root/pull/429:140,Security,access,access,140,Ccache has an issue reading the config file on some Linux distros when using an invalid kerberos ticket. For some reason it will attempt to access a ccache config file in the home directory which it does does not have permission to do causing ccache to exit. Approach suggested by @dpiparo,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/429
https://github.com/root-project/root/pull/430:89,Deployability,patch,patch,89,This fixes https://sft.its.cern.ch/jira/browse/ROOT-8702. The fix is taken from Fedora's patch to their LLVM package:. http://pkgs.fedoraproject.org/cgit/rpms/llvm.git/tree/0001-Fix-R_AARCH64_MOVW_UABS_G3-relocation.patch. This is in turn based on the changes from the upstream change:. https://reviews.llvm.org/D27609,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/430
https://github.com/root-project/root/pull/430:216,Deployability,patch,patch,216,This fixes https://sft.its.cern.ch/jira/browse/ROOT-8702. The fix is taken from Fedora's patch to their LLVM package:. http://pkgs.fedoraproject.org/cgit/rpms/llvm.git/tree/0001-Fix-R_AARCH64_MOVW_UABS_G3-relocation.patch. This is in turn based on the changes from the upstream change:. https://reviews.llvm.org/D27609,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/430
https://github.com/root-project/root/pull/433:79,Integrability,depend,depends,79,This PR undoes part of #426 for simplification and ignores some tutorials that depends on tutorials which are already ignored on ARM.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/433
https://github.com/root-project/root/pull/433:8,Usability,undo,undoes,8,This PR undoes part of #426 for simplification and ignores some tutorials that depends on tutorials which are already ignored on ARM.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/433
https://github.com/root-project/root/pull/433:32,Usability,simpl,simplification,32,This PR undoes part of #426 for simplification and ignores some tutorials that depends on tutorials which are already ignored on ARM.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/433
https://github.com/root-project/root/pull/435:0,Energy Efficiency,Reduce,Reduces,0,"Reduces the amount of resources (population size, cycles, steps, etc.) required for TMVA tutorials.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/435
https://github.com/root-project/root/pull/438:213,Deployability,patch,patch,213,"A bug or lack of optimization is causing the tutorial `tutorial-tmva-TMVAMulticlass` to take forever to process. @ashlaban is working on optimizing this particular issue, so the ignore should be disabled once his patch is upstream.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/438
https://github.com/root-project/root/pull/438:17,Performance,optimiz,optimization,17,"A bug or lack of optimization is causing the tutorial `tutorial-tmva-TMVAMulticlass` to take forever to process. @ashlaban is working on optimizing this particular issue, so the ignore should be disabled once his patch is upstream.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/438
https://github.com/root-project/root/pull/438:137,Performance,optimiz,optimizing,137,"A bug or lack of optimization is causing the tutorial `tutorial-tmva-TMVAMulticlass` to take forever to process. @ashlaban is working on optimizing this particular issue, so the ignore should be disabled once his patch is upstream.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/438
https://github.com/root-project/root/pull/439:30,Testability,test,test,30,This PR resolves this failing test on ARM: http://cdash.cern.ch/testDetails.php?test=23147537&build=332879,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/439
https://github.com/root-project/root/pull/439:64,Testability,test,testDetails,64,This PR resolves this failing test on ARM: http://cdash.cern.ch/testDetails.php?test=23147537&build=332879,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/439
https://github.com/root-project/root/pull/439:80,Testability,test,test,80,This PR resolves this failing test on ARM: http://cdash.cern.ch/testDetails.php?test=23147537&build=332879,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/439
https://github.com/root-project/root/pull/442:545,Integrability,interface,interface,545,"In particular, all creations and deletions of `shared_ptr`s have been removed from the event loop. This is a long due optimization that required several changes in the internal behaviour of TDataFrame{Impl,Action,Branch,Filter}. Unfortunately all changes are entangled, so the third commit is quite fat. The main change to the internal logic is that `TDataFrame{Action,Branch,Filter}` now store a tuple of `TDataFrameValue`s rather than (possibly null) shared pointers to `TTreeReaderValueBase`.; `TDataFrameValue` offers a transparent, unified interface to the different kinds of values that the nodes must handle: temporary columns, to be evaluated on-the-fly, `TTreeReaderArray`s that must be converted to `array_view`s and `TTreeReaderValue`s.; `TDataFrameValue` also incorporates validity checks on the value types, e.g. that arrays read via `TTreeReaderArray` are actually contiguous in memory and that the type of a temporary column is the same as the type expected by the node that makes use of it.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/442
https://github.com/root-project/root/pull/442:118,Performance,optimiz,optimization,118,"In particular, all creations and deletions of `shared_ptr`s have been removed from the event loop. This is a long due optimization that required several changes in the internal behaviour of TDataFrame{Impl,Action,Branch,Filter}. Unfortunately all changes are entangled, so the third commit is quite fat. The main change to the internal logic is that `TDataFrame{Action,Branch,Filter}` now store a tuple of `TDataFrameValue`s rather than (possibly null) shared pointers to `TTreeReaderValueBase`.; `TDataFrameValue` offers a transparent, unified interface to the different kinds of values that the nodes must handle: temporary columns, to be evaluated on-the-fly, `TTreeReaderArray`s that must be converted to `array_view`s and `TTreeReaderValue`s.; `TDataFrameValue` also incorporates validity checks on the value types, e.g. that arrays read via `TTreeReaderArray` are actually contiguous in memory and that the type of a temporary column is the same as the type expected by the node that makes use of it.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/442
https://github.com/root-project/root/pull/442:336,Testability,log,logic,336,"In particular, all creations and deletions of `shared_ptr`s have been removed from the event loop. This is a long due optimization that required several changes in the internal behaviour of TDataFrame{Impl,Action,Branch,Filter}. Unfortunately all changes are entangled, so the third commit is quite fat. The main change to the internal logic is that `TDataFrame{Action,Branch,Filter}` now store a tuple of `TDataFrameValue`s rather than (possibly null) shared pointers to `TTreeReaderValueBase`.; `TDataFrameValue` offers a transparent, unified interface to the different kinds of values that the nodes must handle: temporary columns, to be evaluated on-the-fly, `TTreeReaderArray`s that must be converted to `array_view`s and `TTreeReaderValue`s.; `TDataFrameValue` also incorporates validity checks on the value types, e.g. that arrays read via `TTreeReaderArray` are actually contiguous in memory and that the type of a temporary column is the same as the type expected by the node that makes use of it.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/442
https://github.com/root-project/root/pull/443:183,Deployability,release,released,183,"Caches and precomputes data for this calculation, resulting in a; much more cache friendly access pattern. Leads to increased memory; usage during optimisation, which is subsequently released.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/443
https://github.com/root-project/root/pull/443:0,Performance,Cache,Caches,0,"Caches and precomputes data for this calculation, resulting in a; much more cache friendly access pattern. Leads to increased memory; usage during optimisation, which is subsequently released.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/443
https://github.com/root-project/root/pull/443:76,Performance,cache,cache,76,"Caches and precomputes data for this calculation, resulting in a; much more cache friendly access pattern. Leads to increased memory; usage during optimisation, which is subsequently released.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/443
https://github.com/root-project/root/pull/443:91,Security,access,access,91,"Caches and precomputes data for this calculation, resulting in a; much more cache friendly access pattern. Leads to increased memory; usage during optimisation, which is subsequently released.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/443
https://github.com/root-project/root/pull/445:536,Availability,error,error,536,"This allows the header files to spell the std math functions unqualified and; this way to allow template instantiations with vector types to swap them with; vector functions. Consider:; ```cpp. namespace N {; void call(double);; }. inline namespace __1 {; using N::call; // Enables ADL in a nicer and more transparent way; template <class T>; struct S {; int f() {; using namespace N; // enables ADL but it looks ugly...; call(T()); // call is an unqualified id, thus ADL will kick in. If we had `N::call(T())` we would have a compiler error.; return 42;; }; };; }. namespace N {; struct V{};; void call(V);; }. int res = S<N::V>().f(); // The compiler will add lookup candidates from namespace N. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/445
https://github.com/root-project/root/pull/446:40,Integrability,interface,interface,40,"Hi Guys,. * Added support to check if R interface is running in the thread of event loop, to avoid segfault in scientific linux running tests.; * Fixed some datatypes according to coding conventions. Cheers,; Omar.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/446
https://github.com/root-project/root/pull/446:93,Safety,avoid,avoid,93,"Hi Guys,. * Added support to check if R interface is running in the thread of event loop, to avoid segfault in scientific linux running tests.; * Fixed some datatypes according to coding conventions. Cheers,; Omar.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/446
https://github.com/root-project/root/pull/446:136,Testability,test,tests,136,"Hi Guys,. * Added support to check if R interface is running in the thread of event loop, to avoid segfault in scientific linux running tests.; * Fixed some datatypes according to coding conventions. Cheers,; Omar.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/446
https://github.com/root-project/root/pull/448:36,Availability,echo,echo,36,"Sorry @vgvassilev, I forgot to let `echo` escape the tabs :)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/448
https://github.com/root-project/root/pull/450:297,Security,access,access,297,"There was an infinite loop on the arm platform when running TMVAMulticlass.root. When compiling with the -ffast-math flag, sometimes a nan would be generated in the GA part of the cut optimisation. @dpiparo @martinmine Hopefully this resolves your issue. Tried it on the build machine I was given access to and it works there now. We in the TMVA team still need to revisit this part at some point, but for now I think this should be ok.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/450
https://github.com/root-project/root/pull/451:9,Testability,test,tests,9,Add unit tests for TQObject as an example for further reference.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/451
https://github.com/root-project/root/pull/452:131,Testability,log,logging,131,"fixed crash from the issue tracker ROOT-8563; ""TMVA Multiclass example crash when running with argument ""DNN""""; The problem during logging the output from the last layer, due to the difference of sizes of testPattern and Output. Now the code takes into account the fact that there may be multiple outputs from the last layer of the Neural Net.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/452
https://github.com/root-project/root/pull/452:205,Testability,test,testPattern,205,"fixed crash from the issue tracker ROOT-8563; ""TMVA Multiclass example crash when running with argument ""DNN""""; The problem during logging the output from the last layer, due to the difference of sizes of testPattern and Output. Now the code takes into account the fact that there may be multiple outputs from the last layer of the Neural Net.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/452
https://github.com/root-project/root/pull/453:410,Availability,error,error,410,"This PR fixes a regression introduced in a recent update to extend the templation in GenVector (PR #394). It turns out that this update broke the multiplication of a Transform3D by a Plane3D. This regression was spotted in the LHCb nightly build which tests against the master of ROOT. e.g. https://lhcb-nightlies.cern.ch/logs/build/nightly/lhcb-lcg-dev3/105/x86_64-centos7-gcc62-opt/LHCb/#show_error1538. The error is. ```; /build/jenkins-build-new/workspace/nightly-builds/build/build/LHCB/LHCB_HEAD/Det/RichDet/src/Lib/DeRichHPDPanel.cpp:673:52: error: no match for 'operator*' (operand types are 'const Transform3D {aka const ROOT::Math::Impl::Transform3D<double>}' and 'Gaudi::Plane3D {aka ROOT::Math::Impl::Plane3D<double>}'); 	 m_localPlane = geometry()->toLocalMatrix() * m_detectionPlane;. /build/jenkins-build-new/workspace/nightly-builds/build/build/LHCB/LHCB_HEAD/Det/RichDet/src/Lib/DeRichPMTPanel.cpp:407:46: error: no match for 'operator*' (operand types are 'const Transform3D {aka const ROOT::Math::Impl::Transform3D<double>}' and 'Gaudi::Plane3D {aka ROOT::Math::Impl::Plane3D<double>}'); 	 m_localPlane = geometry()->toLocalMatrix() * m_detectionPlane;; ```. This PR fixes this by adding an explicit operator for this. I have also extended the GenVector Vc test to explicitly cover this operation, as it was clearly one not covered in the ROOT tests so far.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/453
https://github.com/root-project/root/pull/453:549,Availability,error,error,549,"This PR fixes a regression introduced in a recent update to extend the templation in GenVector (PR #394). It turns out that this update broke the multiplication of a Transform3D by a Plane3D. This regression was spotted in the LHCb nightly build which tests against the master of ROOT. e.g. https://lhcb-nightlies.cern.ch/logs/build/nightly/lhcb-lcg-dev3/105/x86_64-centos7-gcc62-opt/LHCb/#show_error1538. The error is. ```; /build/jenkins-build-new/workspace/nightly-builds/build/build/LHCB/LHCB_HEAD/Det/RichDet/src/Lib/DeRichHPDPanel.cpp:673:52: error: no match for 'operator*' (operand types are 'const Transform3D {aka const ROOT::Math::Impl::Transform3D<double>}' and 'Gaudi::Plane3D {aka ROOT::Math::Impl::Plane3D<double>}'); 	 m_localPlane = geometry()->toLocalMatrix() * m_detectionPlane;. /build/jenkins-build-new/workspace/nightly-builds/build/build/LHCB/LHCB_HEAD/Det/RichDet/src/Lib/DeRichPMTPanel.cpp:407:46: error: no match for 'operator*' (operand types are 'const Transform3D {aka const ROOT::Math::Impl::Transform3D<double>}' and 'Gaudi::Plane3D {aka ROOT::Math::Impl::Plane3D<double>}'); 	 m_localPlane = geometry()->toLocalMatrix() * m_detectionPlane;; ```. This PR fixes this by adding an explicit operator for this. I have also extended the GenVector Vc test to explicitly cover this operation, as it was clearly one not covered in the ROOT tests so far.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/453
https://github.com/root-project/root/pull/453:923,Availability,error,error,923,"This PR fixes a regression introduced in a recent update to extend the templation in GenVector (PR #394). It turns out that this update broke the multiplication of a Transform3D by a Plane3D. This regression was spotted in the LHCb nightly build which tests against the master of ROOT. e.g. https://lhcb-nightlies.cern.ch/logs/build/nightly/lhcb-lcg-dev3/105/x86_64-centos7-gcc62-opt/LHCb/#show_error1538. The error is. ```; /build/jenkins-build-new/workspace/nightly-builds/build/build/LHCB/LHCB_HEAD/Det/RichDet/src/Lib/DeRichHPDPanel.cpp:673:52: error: no match for 'operator*' (operand types are 'const Transform3D {aka const ROOT::Math::Impl::Transform3D<double>}' and 'Gaudi::Plane3D {aka ROOT::Math::Impl::Plane3D<double>}'); 	 m_localPlane = geometry()->toLocalMatrix() * m_detectionPlane;. /build/jenkins-build-new/workspace/nightly-builds/build/build/LHCB/LHCB_HEAD/Det/RichDet/src/Lib/DeRichPMTPanel.cpp:407:46: error: no match for 'operator*' (operand types are 'const Transform3D {aka const ROOT::Math::Impl::Transform3D<double>}' and 'Gaudi::Plane3D {aka ROOT::Math::Impl::Plane3D<double>}'); 	 m_localPlane = geometry()->toLocalMatrix() * m_detectionPlane;; ```. This PR fixes this by adding an explicit operator for this. I have also extended the GenVector Vc test to explicitly cover this operation, as it was clearly one not covered in the ROOT tests so far.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/453
https://github.com/root-project/root/pull/453:50,Deployability,update,update,50,"This PR fixes a regression introduced in a recent update to extend the templation in GenVector (PR #394). It turns out that this update broke the multiplication of a Transform3D by a Plane3D. This regression was spotted in the LHCb nightly build which tests against the master of ROOT. e.g. https://lhcb-nightlies.cern.ch/logs/build/nightly/lhcb-lcg-dev3/105/x86_64-centos7-gcc62-opt/LHCb/#show_error1538. The error is. ```; /build/jenkins-build-new/workspace/nightly-builds/build/build/LHCB/LHCB_HEAD/Det/RichDet/src/Lib/DeRichHPDPanel.cpp:673:52: error: no match for 'operator*' (operand types are 'const Transform3D {aka const ROOT::Math::Impl::Transform3D<double>}' and 'Gaudi::Plane3D {aka ROOT::Math::Impl::Plane3D<double>}'); 	 m_localPlane = geometry()->toLocalMatrix() * m_detectionPlane;. /build/jenkins-build-new/workspace/nightly-builds/build/build/LHCB/LHCB_HEAD/Det/RichDet/src/Lib/DeRichPMTPanel.cpp:407:46: error: no match for 'operator*' (operand types are 'const Transform3D {aka const ROOT::Math::Impl::Transform3D<double>}' and 'Gaudi::Plane3D {aka ROOT::Math::Impl::Plane3D<double>}'); 	 m_localPlane = geometry()->toLocalMatrix() * m_detectionPlane;; ```. This PR fixes this by adding an explicit operator for this. I have also extended the GenVector Vc test to explicitly cover this operation, as it was clearly one not covered in the ROOT tests so far.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/453
https://github.com/root-project/root/pull/453:129,Deployability,update,update,129,"This PR fixes a regression introduced in a recent update to extend the templation in GenVector (PR #394). It turns out that this update broke the multiplication of a Transform3D by a Plane3D. This regression was spotted in the LHCb nightly build which tests against the master of ROOT. e.g. https://lhcb-nightlies.cern.ch/logs/build/nightly/lhcb-lcg-dev3/105/x86_64-centos7-gcc62-opt/LHCb/#show_error1538. The error is. ```; /build/jenkins-build-new/workspace/nightly-builds/build/build/LHCB/LHCB_HEAD/Det/RichDet/src/Lib/DeRichHPDPanel.cpp:673:52: error: no match for 'operator*' (operand types are 'const Transform3D {aka const ROOT::Math::Impl::Transform3D<double>}' and 'Gaudi::Plane3D {aka ROOT::Math::Impl::Plane3D<double>}'); 	 m_localPlane = geometry()->toLocalMatrix() * m_detectionPlane;. /build/jenkins-build-new/workspace/nightly-builds/build/build/LHCB/LHCB_HEAD/Det/RichDet/src/Lib/DeRichPMTPanel.cpp:407:46: error: no match for 'operator*' (operand types are 'const Transform3D {aka const ROOT::Math::Impl::Transform3D<double>}' and 'Gaudi::Plane3D {aka ROOT::Math::Impl::Plane3D<double>}'); 	 m_localPlane = geometry()->toLocalMatrix() * m_detectionPlane;; ```. This PR fixes this by adding an explicit operator for this. I have also extended the GenVector Vc test to explicitly cover this operation, as it was clearly one not covered in the ROOT tests so far.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/453
https://github.com/root-project/root/pull/453:60,Modifiability,extend,extend,60,"This PR fixes a regression introduced in a recent update to extend the templation in GenVector (PR #394). It turns out that this update broke the multiplication of a Transform3D by a Plane3D. This regression was spotted in the LHCb nightly build which tests against the master of ROOT. e.g. https://lhcb-nightlies.cern.ch/logs/build/nightly/lhcb-lcg-dev3/105/x86_64-centos7-gcc62-opt/LHCb/#show_error1538. The error is. ```; /build/jenkins-build-new/workspace/nightly-builds/build/build/LHCB/LHCB_HEAD/Det/RichDet/src/Lib/DeRichHPDPanel.cpp:673:52: error: no match for 'operator*' (operand types are 'const Transform3D {aka const ROOT::Math::Impl::Transform3D<double>}' and 'Gaudi::Plane3D {aka ROOT::Math::Impl::Plane3D<double>}'); 	 m_localPlane = geometry()->toLocalMatrix() * m_detectionPlane;. /build/jenkins-build-new/workspace/nightly-builds/build/build/LHCB/LHCB_HEAD/Det/RichDet/src/Lib/DeRichPMTPanel.cpp:407:46: error: no match for 'operator*' (operand types are 'const Transform3D {aka const ROOT::Math::Impl::Transform3D<double>}' and 'Gaudi::Plane3D {aka ROOT::Math::Impl::Plane3D<double>}'); 	 m_localPlane = geometry()->toLocalMatrix() * m_detectionPlane;; ```. This PR fixes this by adding an explicit operator for this. I have also extended the GenVector Vc test to explicitly cover this operation, as it was clearly one not covered in the ROOT tests so far.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/453
https://github.com/root-project/root/pull/453:1250,Modifiability,extend,extended,1250,"This PR fixes a regression introduced in a recent update to extend the templation in GenVector (PR #394). It turns out that this update broke the multiplication of a Transform3D by a Plane3D. This regression was spotted in the LHCb nightly build which tests against the master of ROOT. e.g. https://lhcb-nightlies.cern.ch/logs/build/nightly/lhcb-lcg-dev3/105/x86_64-centos7-gcc62-opt/LHCb/#show_error1538. The error is. ```; /build/jenkins-build-new/workspace/nightly-builds/build/build/LHCB/LHCB_HEAD/Det/RichDet/src/Lib/DeRichHPDPanel.cpp:673:52: error: no match for 'operator*' (operand types are 'const Transform3D {aka const ROOT::Math::Impl::Transform3D<double>}' and 'Gaudi::Plane3D {aka ROOT::Math::Impl::Plane3D<double>}'); 	 m_localPlane = geometry()->toLocalMatrix() * m_detectionPlane;. /build/jenkins-build-new/workspace/nightly-builds/build/build/LHCB/LHCB_HEAD/Det/RichDet/src/Lib/DeRichPMTPanel.cpp:407:46: error: no match for 'operator*' (operand types are 'const Transform3D {aka const ROOT::Math::Impl::Transform3D<double>}' and 'Gaudi::Plane3D {aka ROOT::Math::Impl::Plane3D<double>}'); 	 m_localPlane = geometry()->toLocalMatrix() * m_detectionPlane;; ```. This PR fixes this by adding an explicit operator for this. I have also extended the GenVector Vc test to explicitly cover this operation, as it was clearly one not covered in the ROOT tests so far.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/453
https://github.com/root-project/root/pull/453:252,Testability,test,tests,252,"This PR fixes a regression introduced in a recent update to extend the templation in GenVector (PR #394). It turns out that this update broke the multiplication of a Transform3D by a Plane3D. This regression was spotted in the LHCb nightly build which tests against the master of ROOT. e.g. https://lhcb-nightlies.cern.ch/logs/build/nightly/lhcb-lcg-dev3/105/x86_64-centos7-gcc62-opt/LHCb/#show_error1538. The error is. ```; /build/jenkins-build-new/workspace/nightly-builds/build/build/LHCB/LHCB_HEAD/Det/RichDet/src/Lib/DeRichHPDPanel.cpp:673:52: error: no match for 'operator*' (operand types are 'const Transform3D {aka const ROOT::Math::Impl::Transform3D<double>}' and 'Gaudi::Plane3D {aka ROOT::Math::Impl::Plane3D<double>}'); 	 m_localPlane = geometry()->toLocalMatrix() * m_detectionPlane;. /build/jenkins-build-new/workspace/nightly-builds/build/build/LHCB/LHCB_HEAD/Det/RichDet/src/Lib/DeRichPMTPanel.cpp:407:46: error: no match for 'operator*' (operand types are 'const Transform3D {aka const ROOT::Math::Impl::Transform3D<double>}' and 'Gaudi::Plane3D {aka ROOT::Math::Impl::Plane3D<double>}'); 	 m_localPlane = geometry()->toLocalMatrix() * m_detectionPlane;; ```. This PR fixes this by adding an explicit operator for this. I have also extended the GenVector Vc test to explicitly cover this operation, as it was clearly one not covered in the ROOT tests so far.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/453
https://github.com/root-project/root/pull/453:322,Testability,log,logs,322,"This PR fixes a regression introduced in a recent update to extend the templation in GenVector (PR #394). It turns out that this update broke the multiplication of a Transform3D by a Plane3D. This regression was spotted in the LHCb nightly build which tests against the master of ROOT. e.g. https://lhcb-nightlies.cern.ch/logs/build/nightly/lhcb-lcg-dev3/105/x86_64-centos7-gcc62-opt/LHCb/#show_error1538. The error is. ```; /build/jenkins-build-new/workspace/nightly-builds/build/build/LHCB/LHCB_HEAD/Det/RichDet/src/Lib/DeRichHPDPanel.cpp:673:52: error: no match for 'operator*' (operand types are 'const Transform3D {aka const ROOT::Math::Impl::Transform3D<double>}' and 'Gaudi::Plane3D {aka ROOT::Math::Impl::Plane3D<double>}'); 	 m_localPlane = geometry()->toLocalMatrix() * m_detectionPlane;. /build/jenkins-build-new/workspace/nightly-builds/build/build/LHCB/LHCB_HEAD/Det/RichDet/src/Lib/DeRichPMTPanel.cpp:407:46: error: no match for 'operator*' (operand types are 'const Transform3D {aka const ROOT::Math::Impl::Transform3D<double>}' and 'Gaudi::Plane3D {aka ROOT::Math::Impl::Plane3D<double>}'); 	 m_localPlane = geometry()->toLocalMatrix() * m_detectionPlane;; ```. This PR fixes this by adding an explicit operator for this. I have also extended the GenVector Vc test to explicitly cover this operation, as it was clearly one not covered in the ROOT tests so far.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/453
https://github.com/root-project/root/pull/453:1276,Testability,test,test,1276,"This PR fixes a regression introduced in a recent update to extend the templation in GenVector (PR #394). It turns out that this update broke the multiplication of a Transform3D by a Plane3D. This regression was spotted in the LHCb nightly build which tests against the master of ROOT. e.g. https://lhcb-nightlies.cern.ch/logs/build/nightly/lhcb-lcg-dev3/105/x86_64-centos7-gcc62-opt/LHCb/#show_error1538. The error is. ```; /build/jenkins-build-new/workspace/nightly-builds/build/build/LHCB/LHCB_HEAD/Det/RichDet/src/Lib/DeRichHPDPanel.cpp:673:52: error: no match for 'operator*' (operand types are 'const Transform3D {aka const ROOT::Math::Impl::Transform3D<double>}' and 'Gaudi::Plane3D {aka ROOT::Math::Impl::Plane3D<double>}'); 	 m_localPlane = geometry()->toLocalMatrix() * m_detectionPlane;. /build/jenkins-build-new/workspace/nightly-builds/build/build/LHCB/LHCB_HEAD/Det/RichDet/src/Lib/DeRichPMTPanel.cpp:407:46: error: no match for 'operator*' (operand types are 'const Transform3D {aka const ROOT::Math::Impl::Transform3D<double>}' and 'Gaudi::Plane3D {aka ROOT::Math::Impl::Plane3D<double>}'); 	 m_localPlane = geometry()->toLocalMatrix() * m_detectionPlane;; ```. This PR fixes this by adding an explicit operator for this. I have also extended the GenVector Vc test to explicitly cover this operation, as it was clearly one not covered in the ROOT tests so far.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/453
https://github.com/root-project/root/pull/453:1363,Testability,test,tests,1363,"This PR fixes a regression introduced in a recent update to extend the templation in GenVector (PR #394). It turns out that this update broke the multiplication of a Transform3D by a Plane3D. This regression was spotted in the LHCb nightly build which tests against the master of ROOT. e.g. https://lhcb-nightlies.cern.ch/logs/build/nightly/lhcb-lcg-dev3/105/x86_64-centos7-gcc62-opt/LHCb/#show_error1538. The error is. ```; /build/jenkins-build-new/workspace/nightly-builds/build/build/LHCB/LHCB_HEAD/Det/RichDet/src/Lib/DeRichHPDPanel.cpp:673:52: error: no match for 'operator*' (operand types are 'const Transform3D {aka const ROOT::Math::Impl::Transform3D<double>}' and 'Gaudi::Plane3D {aka ROOT::Math::Impl::Plane3D<double>}'); 	 m_localPlane = geometry()->toLocalMatrix() * m_detectionPlane;. /build/jenkins-build-new/workspace/nightly-builds/build/build/LHCB/LHCB_HEAD/Det/RichDet/src/Lib/DeRichPMTPanel.cpp:407:46: error: no match for 'operator*' (operand types are 'const Transform3D {aka const ROOT::Math::Impl::Transform3D<double>}' and 'Gaudi::Plane3D {aka ROOT::Math::Impl::Plane3D<double>}'); 	 m_localPlane = geometry()->toLocalMatrix() * m_detectionPlane;; ```. This PR fixes this by adding an explicit operator for this. I have also extended the GenVector Vc test to explicitly cover this operation, as it was clearly one not covered in the ROOT tests so far.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/453
https://github.com/root-project/root/pull/453:1327,Usability,clear,clearly,1327,"This PR fixes a regression introduced in a recent update to extend the templation in GenVector (PR #394). It turns out that this update broke the multiplication of a Transform3D by a Plane3D. This regression was spotted in the LHCb nightly build which tests against the master of ROOT. e.g. https://lhcb-nightlies.cern.ch/logs/build/nightly/lhcb-lcg-dev3/105/x86_64-centos7-gcc62-opt/LHCb/#show_error1538. The error is. ```; /build/jenkins-build-new/workspace/nightly-builds/build/build/LHCB/LHCB_HEAD/Det/RichDet/src/Lib/DeRichHPDPanel.cpp:673:52: error: no match for 'operator*' (operand types are 'const Transform3D {aka const ROOT::Math::Impl::Transform3D<double>}' and 'Gaudi::Plane3D {aka ROOT::Math::Impl::Plane3D<double>}'); 	 m_localPlane = geometry()->toLocalMatrix() * m_detectionPlane;. /build/jenkins-build-new/workspace/nightly-builds/build/build/LHCB/LHCB_HEAD/Det/RichDet/src/Lib/DeRichPMTPanel.cpp:407:46: error: no match for 'operator*' (operand types are 'const Transform3D {aka const ROOT::Math::Impl::Transform3D<double>}' and 'Gaudi::Plane3D {aka ROOT::Math::Impl::Plane3D<double>}'); 	 m_localPlane = geometry()->toLocalMatrix() * m_detectionPlane;; ```. This PR fixes this by adding an explicit operator for this. I have also extended the GenVector Vc test to explicitly cover this operation, as it was clearly one not covered in the ROOT tests so far.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/453
https://github.com/root-project/root/pull/454:97,Modifiability,Refactor,Refactored,97,"ROOT/ROOT-8517; Regression: TMVA ROCCurve crash. Fixed possible reason for a crash in the issue. Refactored the code, removing repetitions. ROCCurve and ROCIntegral used to only be computed correctly in cases when the number of background samples is exactly equal to the number of signal samples.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/454
https://github.com/root-project/root/pull/455:166,Modifiability,variab,variable,166,Minuit2Minimizer's GetVariableSettings method doesn't correctly report parameter limits.; This PR corrects its logic to report them correctly. In the old code then a variable with lower+upper limits only has the lower limit reported.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/455
https://github.com/root-project/root/pull/455:111,Testability,log,logic,111,Minuit2Minimizer's GetVariableSettings method doesn't correctly report parameter limits.; This PR corrects its logic to report them correctly. In the old code then a variable with lower+upper limits only has the lower limit reported.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/455
https://github.com/root-project/root/pull/460:5,Deployability,patch,patch,5,This patch improves the previous check whether the current compiler; is using an incompatible libstdc++ version or not.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/460
https://github.com/root-project/root/pull/462:87,Modifiability,variab,variable,87,"TMVA::TMVAGlob::GetInputVariableNames wants to find the substring ""__""; as part of the variable discovery process. However, it used; TString::First(char * character_set) which takes a char set as argument; and finds the first occurence of any character in that set. This is now replaced by TString::Index which _can_ find a substring.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/462
https://github.com/root-project/root/pull/463:3954,Deployability,update,updated,3954,"elp), I think it doesn't require anything except standardised list of type_info-derived types [8]; > 3) Take a closer look at noop1() and noop2() virtual methods above [6]. I suspect they were added to make libcxxabi type_info's vtable compatible with one of type_info from libsupc++, because libsupc++'s type_info also has a couple of virtual methods before the method which does catching check (see above [3]). The only difference is that __do_catch() has additional third argument whilst libcxxabi's can_catch() has only two. I think it won't cause problems if one calls two-argument method with three arguments, but doing the opposite might be troublesome. So, finally, if I'm right, we may try to call the method using vtable offset directly.; > ; > [1] https://itanium-cxx-abi.github.io/cxx-abi/abi.html#dynamic_cast-algorithm; > [2] https://itanium-cxx-abi.github.io/cxx-abi/abi.html#exception-matching-algorithm; > [3] https://github.com/gcc-mirror/gcc/blob/8805daa6d1a973e4e85698d7cf65a46c8cc85aac/libstdc%2B%2B-v3/libsupc%2B%2B/typeinfo#L163; > [4] https://github.com/llvm-mirror/libcxx/blob/68fdad67e334de18451c749550908274a5fd2542/include/typeinfo; > [5] https://github.com/llvm-mirror/libcxxabi/blob/1f4353379227ba3d8b44a8694fc54e0ca6de39cd/src/private_typeinfo.h#L20; > [6] https://github.com/llvm-mirror/libcxxabi/blob/1f4353379227ba3d8b44a8694fc54e0ca6de39cd/src/private_typeinfo.h#L26; > [7] https://github.com/llvm-mirror/libcxxabi/blob/1f4353379227ba3d8b44a8694fc54e0ca6de39cd/src/private_typeinfo.cpp#L147; > [8] https://itanium-cxx-abi.github.io/cxx-abi/abi.html#rtti-layout. On 26/03/17 16:54, Berserker Troll wrote:; > I've implemented cast based on direct vtable access [9]. It should work for both libstdc++/libsupc++ and libcxx(abi).; > Also I've updated my TDirectory test so they have the same output format [a]; >; > [9] https://gist.github.com/BerserkerTroll/01debd56c2987ab89b0a94b783373e35; > [a] https://gist.github.com/BerserkerTroll/b94c2d3e3a5848be7c7dd53e323e1cdb",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/463
https://github.com/root-project/root/pull/463:1251,Integrability,rout,routines,1251,"). I think this method requires more explanation. It all started from my proposal to rely on Itanium C++ ABI to implement cast. I won't post that mail here because it is written in such a broken English. On 24/03/17 22:32, Axel Naumann wrote:; > Hi Berserker,; >; > I'm more and more convinced that this is the way to go... I'm talking; > specifically about; > <https://github.com/gcc-mirror/gcc/blob/master/libstdc%2B%2B-v3/libsupc%2B%2B/cxxabi.h#L591>; > here.; >; > Do you think you could give it a shot in the form of a PR? . On 25/03/17 19:06, Berserker Troll wrote:; > Hi Axel,; > ; > __dynamic_cast is standardized, but works only for polymorphic classes, while TClass::DynamicCast and exception-based cast also work for non-polymorphic ones.; > If you want TDirectory to work for all kinds of classes you should consider not dynamic_cast algorithm [1], but exception handler matching one [2].; > Unfortunately, [2] says:; >> Since the RTTI related exception handling routines are ""personality specific"", no interfaces need to be specified in this document (beyond the layout of the RTTI data).; > ; > In libstdc++/libsupc++, handler matching algorithm is easily accessible directly through std::type_info from standard <typeinfo> header, using __do_catch() member function [3].; > The situation with libcxxabi is a bit more complicated. std::type_info in libcxx <typeinfo> header [4] doesn't have any non-standard member functions, instead it has additional hidden __shim_type_info class [5] between std::type_info and other Itanium C++ ABI type_info derived types. And this __shim_type_info class, in turn, provides access to the handler matching algorithm [6].; > ; > So, if we want this exception hander matching algorithm, there are a couple of options:; > 1) Stick to libsupc++ with its ""public"" __do_catch() member function; > 2) Implement independent handler matching algorithm ([7] might help), I think it doesn't require anything except standardised list of type_info-derived types [8",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/463
https://github.com/root-project/root/pull/463:1291,Integrability,interface,interfaces,1291,"). I think this method requires more explanation. It all started from my proposal to rely on Itanium C++ ABI to implement cast. I won't post that mail here because it is written in such a broken English. On 24/03/17 22:32, Axel Naumann wrote:; > Hi Berserker,; >; > I'm more and more convinced that this is the way to go... I'm talking; > specifically about; > <https://github.com/gcc-mirror/gcc/blob/master/libstdc%2B%2B-v3/libsupc%2B%2B/cxxabi.h#L591>; > here.; >; > Do you think you could give it a shot in the form of a PR? . On 25/03/17 19:06, Berserker Troll wrote:; > Hi Axel,; > ; > __dynamic_cast is standardized, but works only for polymorphic classes, while TClass::DynamicCast and exception-based cast also work for non-polymorphic ones.; > If you want TDirectory to work for all kinds of classes you should consider not dynamic_cast algorithm [1], but exception handler matching one [2].; > Unfortunately, [2] says:; >> Since the RTTI related exception handling routines are ""personality specific"", no interfaces need to be specified in this document (beyond the layout of the RTTI data).; > ; > In libstdc++/libsupc++, handler matching algorithm is easily accessible directly through std::type_info from standard <typeinfo> header, using __do_catch() member function [3].; > The situation with libcxxabi is a bit more complicated. std::type_info in libcxx <typeinfo> header [4] doesn't have any non-standard member functions, instead it has additional hidden __shim_type_info class [5] between std::type_info and other Itanium C++ ABI type_info derived types. And this __shim_type_info class, in turn, provides access to the handler matching algorithm [6].; > ; > So, if we want this exception hander matching algorithm, there are a couple of options:; > 1) Stick to libsupc++ with its ""public"" __do_catch() member function; > 2) Implement independent handler matching algorithm ([7] might help), I think it doesn't require anything except standardised list of type_info-derived types [8",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/463
https://github.com/root-project/root/pull/463:918,Modifiability,polymorphi,polymorphic,918,"This method is based on GNU libstc++/libsupc++ and LLVM libc++(abi) implementations of exception handler matching algorithm. And on the fact that in AMD64 SysV ABI class methods could be called just like ordinary functions with additional first argument (a.k.a. `this` pointer). I think this method requires more explanation. It all started from my proposal to rely on Itanium C++ ABI to implement cast. I won't post that mail here because it is written in such a broken English. On 24/03/17 22:32, Axel Naumann wrote:; > Hi Berserker,; >; > I'm more and more convinced that this is the way to go... I'm talking; > specifically about; > <https://github.com/gcc-mirror/gcc/blob/master/libstdc%2B%2B-v3/libsupc%2B%2B/cxxabi.h#L591>; > here.; >; > Do you think you could give it a shot in the form of a PR? . On 25/03/17 19:06, Berserker Troll wrote:; > Hi Axel,; > ; > __dynamic_cast is standardized, but works only for polymorphic classes, while TClass::DynamicCast and exception-based cast also work for non-polymorphic ones.; > If you want TDirectory to work for all kinds of classes you should consider not dynamic_cast algorithm [1], but exception handler matching one [2].; > Unfortunately, [2] says:; >> Since the RTTI related exception handling routines are ""personality specific"", no interfaces need to be specified in this document (beyond the layout of the RTTI data).; > ; > In libstdc++/libsupc++, handler matching algorithm is easily accessible directly through std::type_info from standard <typeinfo> header, using __do_catch() member function [3].; > The situation with libcxxabi is a bit more complicated. std::type_info in libcxx <typeinfo> header [4] doesn't have any non-standard member functions, instead it has additional hidden __shim_type_info class [5] between std::type_info and other Itanium C++ ABI type_info derived types. And this __shim_type_info class, in turn, provides access to the handler matching algorithm [6].; > ; > So, if we want this exception hander matching a",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/463
https://github.com/root-project/root/pull/463:1008,Modifiability,polymorphi,polymorphic,1008,"This method is based on GNU libstc++/libsupc++ and LLVM libc++(abi) implementations of exception handler matching algorithm. And on the fact that in AMD64 SysV ABI class methods could be called just like ordinary functions with additional first argument (a.k.a. `this` pointer). I think this method requires more explanation. It all started from my proposal to rely on Itanium C++ ABI to implement cast. I won't post that mail here because it is written in such a broken English. On 24/03/17 22:32, Axel Naumann wrote:; > Hi Berserker,; >; > I'm more and more convinced that this is the way to go... I'm talking; > specifically about; > <https://github.com/gcc-mirror/gcc/blob/master/libstdc%2B%2B-v3/libsupc%2B%2B/cxxabi.h#L591>; > here.; >; > Do you think you could give it a shot in the form of a PR? . On 25/03/17 19:06, Berserker Troll wrote:; > Hi Axel,; > ; > __dynamic_cast is standardized, but works only for polymorphic classes, while TClass::DynamicCast and exception-based cast also work for non-polymorphic ones.; > If you want TDirectory to work for all kinds of classes you should consider not dynamic_cast algorithm [1], but exception handler matching one [2].; > Unfortunately, [2] says:; >> Since the RTTI related exception handling routines are ""personality specific"", no interfaces need to be specified in this document (beyond the layout of the RTTI data).; > ; > In libstdc++/libsupc++, handler matching algorithm is easily accessible directly through std::type_info from standard <typeinfo> header, using __do_catch() member function [3].; > The situation with libcxxabi is a bit more complicated. std::type_info in libcxx <typeinfo> header [4] doesn't have any non-standard member functions, instead it has additional hidden __shim_type_info class [5] between std::type_info and other Itanium C++ ABI type_info derived types. And this __shim_type_info class, in turn, provides access to the handler matching algorithm [6].; > ; > So, if we want this exception hander matching a",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/463
https://github.com/root-project/root/pull/463:1446,Security,access,accessible,1446,"n English. On 24/03/17 22:32, Axel Naumann wrote:; > Hi Berserker,; >; > I'm more and more convinced that this is the way to go... I'm talking; > specifically about; > <https://github.com/gcc-mirror/gcc/blob/master/libstdc%2B%2B-v3/libsupc%2B%2B/cxxabi.h#L591>; > here.; >; > Do you think you could give it a shot in the form of a PR? . On 25/03/17 19:06, Berserker Troll wrote:; > Hi Axel,; > ; > __dynamic_cast is standardized, but works only for polymorphic classes, while TClass::DynamicCast and exception-based cast also work for non-polymorphic ones.; > If you want TDirectory to work for all kinds of classes you should consider not dynamic_cast algorithm [1], but exception handler matching one [2].; > Unfortunately, [2] says:; >> Since the RTTI related exception handling routines are ""personality specific"", no interfaces need to be specified in this document (beyond the layout of the RTTI data).; > ; > In libstdc++/libsupc++, handler matching algorithm is easily accessible directly through std::type_info from standard <typeinfo> header, using __do_catch() member function [3].; > The situation with libcxxabi is a bit more complicated. std::type_info in libcxx <typeinfo> header [4] doesn't have any non-standard member functions, instead it has additional hidden __shim_type_info class [5] between std::type_info and other Itanium C++ ABI type_info derived types. And this __shim_type_info class, in turn, provides access to the handler matching algorithm [6].; > ; > So, if we want this exception hander matching algorithm, there are a couple of options:; > 1) Stick to libsupc++ with its ""public"" __do_catch() member function; > 2) Implement independent handler matching algorithm ([7] might help), I think it doesn't require anything except standardised list of type_info-derived types [8]; > 3) Take a closer look at noop1() and noop2() virtual methods above [6]. I suspect they were added to make libcxxabi type_info's vtable compatible with one of type_info from libsupc++, bec",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/463
https://github.com/root-project/root/pull/463:1901,Security,access,access,1901,", but works only for polymorphic classes, while TClass::DynamicCast and exception-based cast also work for non-polymorphic ones.; > If you want TDirectory to work for all kinds of classes you should consider not dynamic_cast algorithm [1], but exception handler matching one [2].; > Unfortunately, [2] says:; >> Since the RTTI related exception handling routines are ""personality specific"", no interfaces need to be specified in this document (beyond the layout of the RTTI data).; > ; > In libstdc++/libsupc++, handler matching algorithm is easily accessible directly through std::type_info from standard <typeinfo> header, using __do_catch() member function [3].; > The situation with libcxxabi is a bit more complicated. std::type_info in libcxx <typeinfo> header [4] doesn't have any non-standard member functions, instead it has additional hidden __shim_type_info class [5] between std::type_info and other Itanium C++ ABI type_info derived types. And this __shim_type_info class, in turn, provides access to the handler matching algorithm [6].; > ; > So, if we want this exception hander matching algorithm, there are a couple of options:; > 1) Stick to libsupc++ with its ""public"" __do_catch() member function; > 2) Implement independent handler matching algorithm ([7] might help), I think it doesn't require anything except standardised list of type_info-derived types [8]; > 3) Take a closer look at noop1() and noop2() virtual methods above [6]. I suspect they were added to make libcxxabi type_info's vtable compatible with one of type_info from libsupc++, because libsupc++'s type_info also has a couple of virtual methods before the method which does catching check (see above [3]). The only difference is that __do_catch() has additional third argument whilst libcxxabi's can_catch() has only two. I think it won't cause problems if one calls two-argument method with three arguments, but doing the opposite might be troublesome. So, finally, if I'm right, we may try to call the method",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/463
https://github.com/root-project/root/pull/463:3868,Security,access,access,3868,"elp), I think it doesn't require anything except standardised list of type_info-derived types [8]; > 3) Take a closer look at noop1() and noop2() virtual methods above [6]. I suspect they were added to make libcxxabi type_info's vtable compatible with one of type_info from libsupc++, because libsupc++'s type_info also has a couple of virtual methods before the method which does catching check (see above [3]). The only difference is that __do_catch() has additional third argument whilst libcxxabi's can_catch() has only two. I think it won't cause problems if one calls two-argument method with three arguments, but doing the opposite might be troublesome. So, finally, if I'm right, we may try to call the method using vtable offset directly.; > ; > [1] https://itanium-cxx-abi.github.io/cxx-abi/abi.html#dynamic_cast-algorithm; > [2] https://itanium-cxx-abi.github.io/cxx-abi/abi.html#exception-matching-algorithm; > [3] https://github.com/gcc-mirror/gcc/blob/8805daa6d1a973e4e85698d7cf65a46c8cc85aac/libstdc%2B%2B-v3/libsupc%2B%2B/typeinfo#L163; > [4] https://github.com/llvm-mirror/libcxx/blob/68fdad67e334de18451c749550908274a5fd2542/include/typeinfo; > [5] https://github.com/llvm-mirror/libcxxabi/blob/1f4353379227ba3d8b44a8694fc54e0ca6de39cd/src/private_typeinfo.h#L20; > [6] https://github.com/llvm-mirror/libcxxabi/blob/1f4353379227ba3d8b44a8694fc54e0ca6de39cd/src/private_typeinfo.h#L26; > [7] https://github.com/llvm-mirror/libcxxabi/blob/1f4353379227ba3d8b44a8694fc54e0ca6de39cd/src/private_typeinfo.cpp#L147; > [8] https://itanium-cxx-abi.github.io/cxx-abi/abi.html#rtti-layout. On 26/03/17 16:54, Berserker Troll wrote:; > I've implemented cast based on direct vtable access [9]. It should work for both libstdc++/libsupc++ and libcxx(abi).; > Also I've updated my TDirectory test so they have the same output format [a]; >; > [9] https://gist.github.com/BerserkerTroll/01debd56c2987ab89b0a94b783373e35; > [a] https://gist.github.com/BerserkerTroll/b94c2d3e3a5848be7c7dd53e323e1cdb",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/463
https://github.com/root-project/root/pull/463:3976,Testability,test,test,3976,"elp), I think it doesn't require anything except standardised list of type_info-derived types [8]; > 3) Take a closer look at noop1() and noop2() virtual methods above [6]. I suspect they were added to make libcxxabi type_info's vtable compatible with one of type_info from libsupc++, because libsupc++'s type_info also has a couple of virtual methods before the method which does catching check (see above [3]). The only difference is that __do_catch() has additional third argument whilst libcxxabi's can_catch() has only two. I think it won't cause problems if one calls two-argument method with three arguments, but doing the opposite might be troublesome. So, finally, if I'm right, we may try to call the method using vtable offset directly.; > ; > [1] https://itanium-cxx-abi.github.io/cxx-abi/abi.html#dynamic_cast-algorithm; > [2] https://itanium-cxx-abi.github.io/cxx-abi/abi.html#exception-matching-algorithm; > [3] https://github.com/gcc-mirror/gcc/blob/8805daa6d1a973e4e85698d7cf65a46c8cc85aac/libstdc%2B%2B-v3/libsupc%2B%2B/typeinfo#L163; > [4] https://github.com/llvm-mirror/libcxx/blob/68fdad67e334de18451c749550908274a5fd2542/include/typeinfo; > [5] https://github.com/llvm-mirror/libcxxabi/blob/1f4353379227ba3d8b44a8694fc54e0ca6de39cd/src/private_typeinfo.h#L20; > [6] https://github.com/llvm-mirror/libcxxabi/blob/1f4353379227ba3d8b44a8694fc54e0ca6de39cd/src/private_typeinfo.h#L26; > [7] https://github.com/llvm-mirror/libcxxabi/blob/1f4353379227ba3d8b44a8694fc54e0ca6de39cd/src/private_typeinfo.cpp#L147; > [8] https://itanium-cxx-abi.github.io/cxx-abi/abi.html#rtti-layout. On 26/03/17 16:54, Berserker Troll wrote:; > I've implemented cast based on direct vtable access [9]. It should work for both libstdc++/libsupc++ and libcxx(abi).; > Also I've updated my TDirectory test so they have the same output format [a]; >; > [9] https://gist.github.com/BerserkerTroll/01debd56c2987ab89b0a94b783373e35; > [a] https://gist.github.com/BerserkerTroll/b94c2d3e3a5848be7c7dd53e323e1cdb",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/463
https://github.com/root-project/root/pull/464:128,Safety,avoid,avoids,128,"* a direct ApplyInverse() function for Points and Vectors; * faster than using the Inverse() + operator() mechanism, because; - avoids intermediate calculation and memory of inverse; - we know the precise form of the inverse transformation a priori; (the inverse of an 3D rotation is is transpose, etc.)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/464
https://github.com/root-project/root/pull/466:27,Integrability,depend,dependencies,27,This way when we introduce dependencies in TMath that require linkage (f.e. Vc) it won't suppose a problem for libCore.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/466
https://github.com/root-project/root/pull/470:175,Deployability,patch,patch,175,This happened when we moved the cxxmodules code before the add_subdirectory; which where responsible for filling the variable that contains the generated; contents. With this patch we wait with writing the variable contents to the; file until the variable actually contains the whole modulemap.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/470
https://github.com/root-project/root/pull/470:117,Modifiability,variab,variable,117,This happened when we moved the cxxmodules code before the add_subdirectory; which where responsible for filling the variable that contains the generated; contents. With this patch we wait with writing the variable contents to the; file until the variable actually contains the whole modulemap.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/470
https://github.com/root-project/root/pull/470:206,Modifiability,variab,variable,206,This happened when we moved the cxxmodules code before the add_subdirectory; which where responsible for filling the variable that contains the generated; contents. With this patch we wait with writing the variable contents to the; file until the variable actually contains the whole modulemap.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/470
https://github.com/root-project/root/pull/470:247,Modifiability,variab,variable,247,This happened when we moved the cxxmodules code before the add_subdirectory; which where responsible for filling the variable that contains the generated; contents. With this patch we wait with writing the variable contents to the; file until the variable actually contains the whole modulemap.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/470
https://github.com/root-project/root/pull/472:211,Safety,avoid,avoid,211,"clang-tidy with `modernize-use-bool-literals` complains about the fact that 0 is used in place of false. Given I assume there is no particular reason for using `0` rather than `false`, I suggest to change it to avoid the false positives.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/472
https://github.com/root-project/root/pull/476:62,Integrability,interface,interface,62,"""if (gR) { ... }"" will not work as a check whether the global interface object is freed. gR - the pointer to the TRInterface object - is assigned by new. Only one instance of this class can be created. There is no explicit delete of this global object, but it is destroyed when the program exits. But this destruction of remaining object when the program ends does not reset the gR pointer to NULL, so using ""if (gR) { ... }"" as a test to check whether the object is destroyed or not will not work. I think this PR implements the intended behaviour.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/476
https://github.com/root-project/root/pull/476:431,Testability,test,test,431,"""if (gR) { ... }"" will not work as a check whether the global interface object is freed. gR - the pointer to the TRInterface object - is assigned by new. Only one instance of this class can be created. There is no explicit delete of this global object, but it is destroyed when the program exits. But this destruction of remaining object when the program ends does not reset the gR pointer to NULL, so using ""if (gR) { ... }"" as a test to check whether the object is destroyed or not will not work. I think this PR implements the intended behaviour.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/476
https://github.com/root-project/root/pull/477:200,Deployability,patch,patch,200,"The Linux builds with enabled modules were failing because stdio.h; wasn't provided by a module but textually included. This seemed to; cause merging issues which caused the compilation to fail. This patch adds a modulemap for a few libc modules that seem to work; without modification as modules inside ROOT. We had to remove a few 'extern ""C""' because importing a module; inside such a context isn't allowed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/477
https://github.com/root-project/root/pull/478:350,Deployability,patch,patch,350,"This is a backport from llvm revision 278983:; ""PR18417: Increase -ftemplate-depth to the value 1024 recommended; by the C++ standard's Annex B"". Motivation: the current template instantiation depth limit (256) makes; it impossible to move-construct std::tuple's of size equal or greater than 17. Thanks @vgvassilev for pointing me to the right llvm patch.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/478
https://github.com/root-project/root/pull/479:70,Usability,guid,guide,70,"`clang-format` will not be happy with the very long lines in the user guide, but on the other hand markdown only accepts table rows on a single line, so I think this case calls for an exception.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/479
https://github.com/root-project/root/pull/482:190,Modifiability,inherit,inherit,190,* This commit allows the compiler to potentially; inline/optimize construction of TObjects; * This is in particular important for data-objects; which are created billions of times and which inherit from; TObject,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/482
https://github.com/root-project/root/pull/482:57,Performance,optimiz,optimize,57,* This commit allows the compiler to potentially; inline/optimize construction of TObjects; * This is in particular important for data-objects; which are created billions of times and which inherit from; TObject,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/482
https://github.com/root-project/root/pull/492:4,Modifiability,variab,variable,4,"The variable fDropoutProbability in DNN/Layer is being initialized twice; in the constructor, ignoring the value passed in the initialization; list, which causes a bug that breaks TGradientDescent minimizer.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/492
https://github.com/root-project/root/pull/494:96,Integrability,message,messages,96,"This has a couple more fixes from the study of a previous bug, some typo fixes, etc. The commit messages have more details.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/494
https://github.com/root-project/root/pull/497:85,Testability,test,test,85,"This pull request addresses Pere's comments and adds some more changes like a simple test for VecCore functionality and better support for latest VecCore changes (from version 0.3.2 to 0.4.0). It should be ready for merging, but I'd like to see all tests pass first. I tested on my own machine with several combinations of `vc=ON/OFF`, `builtin_vc=ON/OFF` and `veccore=ON/OFF`, `builtin_veccore=ON/OFF`. It should all work properly. However, since external VecCore cannot find a builtin Vc, requesting `builtin_vc=ON` and `veccore=ON` will trigger `builtin_veccore=ON` automatically. Please feel free to to make more suggestions for extra changes if necessary.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/497
https://github.com/root-project/root/pull/497:249,Testability,test,tests,249,"This pull request addresses Pere's comments and adds some more changes like a simple test for VecCore functionality and better support for latest VecCore changes (from version 0.3.2 to 0.4.0). It should be ready for merging, but I'd like to see all tests pass first. I tested on my own machine with several combinations of `vc=ON/OFF`, `builtin_vc=ON/OFF` and `veccore=ON/OFF`, `builtin_veccore=ON/OFF`. It should all work properly. However, since external VecCore cannot find a builtin Vc, requesting `builtin_vc=ON` and `veccore=ON` will trigger `builtin_veccore=ON` automatically. Please feel free to to make more suggestions for extra changes if necessary.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/497
https://github.com/root-project/root/pull/497:269,Testability,test,tested,269,"This pull request addresses Pere's comments and adds some more changes like a simple test for VecCore functionality and better support for latest VecCore changes (from version 0.3.2 to 0.4.0). It should be ready for merging, but I'd like to see all tests pass first. I tested on my own machine with several combinations of `vc=ON/OFF`, `builtin_vc=ON/OFF` and `veccore=ON/OFF`, `builtin_veccore=ON/OFF`. It should all work properly. However, since external VecCore cannot find a builtin Vc, requesting `builtin_vc=ON` and `veccore=ON` will trigger `builtin_veccore=ON` automatically. Please feel free to to make more suggestions for extra changes if necessary.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/497
https://github.com/root-project/root/pull/497:78,Usability,simpl,simple,78,"This pull request addresses Pere's comments and adds some more changes like a simple test for VecCore functionality and better support for latest VecCore changes (from version 0.3.2 to 0.4.0). It should be ready for merging, but I'd like to see all tests pass first. I tested on my own machine with several combinations of `vc=ON/OFF`, `builtin_vc=ON/OFF` and `veccore=ON/OFF`, `builtin_veccore=ON/OFF`. It should all work properly. However, since external VecCore cannot find a builtin Vc, requesting `builtin_vc=ON` and `veccore=ON` will trigger `builtin_veccore=ON` automatically. Please feel free to to make more suggestions for extra changes if necessary.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/497
https://github.com/root-project/root/pull/498:50,Testability,test,testDetails,50,The exact comparison [fails](http://cdash.cern.ch/testDetails.php?test=23864693&build=342450) in some architectures where rounding may occur.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/498
https://github.com/root-project/root/pull/498:66,Testability,test,test,66,The exact comparison [fails](http://cdash.cern.ch/testDetails.php?test=23864693&build=342450) in some architectures where rounding may occur.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/498
https://github.com/root-project/root/pull/502:41,Testability,test,tests,41,These commits fix two GenVector failing [tests](http://cdash.cern.ch/viewTest.php?onlyfailed&buildid=342982).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/502
https://github.com/root-project/root/pull/503:13,Modifiability,config,configure,13,"One also can configure websocket timeout when creating THttpServer. Required for TWebCanvas prototype,; but also can be used in other applications",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/503
https://github.com/root-project/root/pull/503:33,Safety,timeout,timeout,33,"One also can configure websocket timeout when creating THttpServer. Required for TWebCanvas prototype,; but also can be used in other applications",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/503
https://github.com/root-project/root/pull/504:5,Deployability,patch,patch,5,This patch also untangles the generation code of PCMs and PCHs.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/504
https://github.com/root-project/root/pull/505:80,Availability,toler,tolerance,80,Replace direct floating point comparison with `AreEqualRel()` comparison with a tolerance.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/505
https://github.com/root-project/root/pull/507:959,Availability,error,errors,959,"This is an update to PR #40 that includes:; - a rebase with all CMA-ES commits at the tip of master (as of 04/17/2017); - a set of small fixes as requested by @vgvassilev . As a reminder, this PR fetches, builds and wraps https://github.com/beniz/libcmaes/ with ROOT. This PR builds ROOT with CMA-ES support and I've been able to run some of the tests, indicating that it is working fine. **Issues**; However, some caveats remain, on which help is required, at the moment. - [ ] `build/include/libcmaes/cmaes.h` and `build/include/Eigen` are not properly passed to the compiler at build time. I cannot find how to do it properly. At the moment I am using symlinks as a temporary hack (see how to build below). - [ ] To access the inner option of the CMA-ES Minimizer, I was using code similar to; ```C++; ROOT::Math::IOptions &opts = ROOT::Math::MinimizerOptions::Default(fitter);; opts.SetIntValue(""lambda"",lambda);; ```; Code above now appears to fail with errors such as:; ```; root [0] .L tutorials/fit/cmaesFitBench.C++g; Info in <TUnixSystem::ACLiC>: creating shared library /home/beniz/research/siminole/dev/tmp/root/build/./tutorials/fit/cmaesFitBench_C.so; In file included from input_line_11:9:; ././tutorials/fit/cmaesFitBench.C:58:16: error: no type named 'IOptions' in namespace 'ROOT::Math'; ROOT::Math::IOptions *opts = ROOT::Math::MinimizerOptions::Default(fitter);; ~~~~~~~~~~~~^; ././tutorials/fit/cmaesFitBench.C:58:45: error: no member named 'MinimizerOptions' in namespace 'ROOT::Math'; ROOT::Math::IOptions *opts = ROOT::Math::MinimizerOptions::Default(fitter);; ~~~~~~~~~~~~^; Error in <ACLiC>: Dictionary generation failed!; ```; Help is needed to fix the above. **How to build**; ```; cd build; cmake ../ -Dminuit2=on -Dtesting=on -Dlibcmaes=on; make; ```; The build will fail because of the header issue mentioned above, so do:; ```; cd include; ln -s eigen3/Eigen .; ln -s eigen3/unsupported .; cd ..; make; ```; You can then use the newly built ROOT and test that CMA-ES is",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/507
https://github.com/root-project/root/pull/507:1247,Availability,error,error,1247,"maes/ with ROOT. This PR builds ROOT with CMA-ES support and I've been able to run some of the tests, indicating that it is working fine. **Issues**; However, some caveats remain, on which help is required, at the moment. - [ ] `build/include/libcmaes/cmaes.h` and `build/include/Eigen` are not properly passed to the compiler at build time. I cannot find how to do it properly. At the moment I am using symlinks as a temporary hack (see how to build below). - [ ] To access the inner option of the CMA-ES Minimizer, I was using code similar to; ```C++; ROOT::Math::IOptions &opts = ROOT::Math::MinimizerOptions::Default(fitter);; opts.SetIntValue(""lambda"",lambda);; ```; Code above now appears to fail with errors such as:; ```; root [0] .L tutorials/fit/cmaesFitBench.C++g; Info in <TUnixSystem::ACLiC>: creating shared library /home/beniz/research/siminole/dev/tmp/root/build/./tutorials/fit/cmaesFitBench_C.so; In file included from input_line_11:9:; ././tutorials/fit/cmaesFitBench.C:58:16: error: no type named 'IOptions' in namespace 'ROOT::Math'; ROOT::Math::IOptions *opts = ROOT::Math::MinimizerOptions::Default(fitter);; ~~~~~~~~~~~~^; ././tutorials/fit/cmaesFitBench.C:58:45: error: no member named 'MinimizerOptions' in namespace 'ROOT::Math'; ROOT::Math::IOptions *opts = ROOT::Math::MinimizerOptions::Default(fitter);; ~~~~~~~~~~~~^; Error in <ACLiC>: Dictionary generation failed!; ```; Help is needed to fix the above. **How to build**; ```; cd build; cmake ../ -Dminuit2=on -Dtesting=on -Dlibcmaes=on; make; ```; The build will fail because of the header issue mentioned above, so do:; ```; cd include; ln -s eigen3/Eigen .; ln -s eigen3/unsupported .; cd ..; make; ```; You can then use the newly built ROOT and test that CMA-ES is working:; ```; .L tutorials/fit/cmaesGausFit.C++g; cmaesGausFit(); ```. Please see instructions and links from PR #40 for more tests, performance checks, etc... Once everything is fine, I'll be able to squash all commits into a single one if needed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/507
https://github.com/root-project/root/pull/507:1439,Availability,error,error,1439,"maes/ with ROOT. This PR builds ROOT with CMA-ES support and I've been able to run some of the tests, indicating that it is working fine. **Issues**; However, some caveats remain, on which help is required, at the moment. - [ ] `build/include/libcmaes/cmaes.h` and `build/include/Eigen` are not properly passed to the compiler at build time. I cannot find how to do it properly. At the moment I am using symlinks as a temporary hack (see how to build below). - [ ] To access the inner option of the CMA-ES Minimizer, I was using code similar to; ```C++; ROOT::Math::IOptions &opts = ROOT::Math::MinimizerOptions::Default(fitter);; opts.SetIntValue(""lambda"",lambda);; ```; Code above now appears to fail with errors such as:; ```; root [0] .L tutorials/fit/cmaesFitBench.C++g; Info in <TUnixSystem::ACLiC>: creating shared library /home/beniz/research/siminole/dev/tmp/root/build/./tutorials/fit/cmaesFitBench_C.so; In file included from input_line_11:9:; ././tutorials/fit/cmaesFitBench.C:58:16: error: no type named 'IOptions' in namespace 'ROOT::Math'; ROOT::Math::IOptions *opts = ROOT::Math::MinimizerOptions::Default(fitter);; ~~~~~~~~~~~~^; ././tutorials/fit/cmaesFitBench.C:58:45: error: no member named 'MinimizerOptions' in namespace 'ROOT::Math'; ROOT::Math::IOptions *opts = ROOT::Math::MinimizerOptions::Default(fitter);; ~~~~~~~~~~~~^; Error in <ACLiC>: Dictionary generation failed!; ```; Help is needed to fix the above. **How to build**; ```; cd build; cmake ../ -Dminuit2=on -Dtesting=on -Dlibcmaes=on; make; ```; The build will fail because of the header issue mentioned above, so do:; ```; cd include; ln -s eigen3/Eigen .; ln -s eigen3/unsupported .; cd ..; make; ```; You can then use the newly built ROOT and test that CMA-ES is working:; ```; .L tutorials/fit/cmaesGausFit.C++g; cmaesGausFit(); ```. Please see instructions and links from PR #40 for more tests, performance checks, etc... Once everything is fine, I'll be able to squash all commits into a single one if needed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/507
https://github.com/root-project/root/pull/507:1600,Availability,Error,Error,1600,"maes/ with ROOT. This PR builds ROOT with CMA-ES support and I've been able to run some of the tests, indicating that it is working fine. **Issues**; However, some caveats remain, on which help is required, at the moment. - [ ] `build/include/libcmaes/cmaes.h` and `build/include/Eigen` are not properly passed to the compiler at build time. I cannot find how to do it properly. At the moment I am using symlinks as a temporary hack (see how to build below). - [ ] To access the inner option of the CMA-ES Minimizer, I was using code similar to; ```C++; ROOT::Math::IOptions &opts = ROOT::Math::MinimizerOptions::Default(fitter);; opts.SetIntValue(""lambda"",lambda);; ```; Code above now appears to fail with errors such as:; ```; root [0] .L tutorials/fit/cmaesFitBench.C++g; Info in <TUnixSystem::ACLiC>: creating shared library /home/beniz/research/siminole/dev/tmp/root/build/./tutorials/fit/cmaesFitBench_C.so; In file included from input_line_11:9:; ././tutorials/fit/cmaesFitBench.C:58:16: error: no type named 'IOptions' in namespace 'ROOT::Math'; ROOT::Math::IOptions *opts = ROOT::Math::MinimizerOptions::Default(fitter);; ~~~~~~~~~~~~^; ././tutorials/fit/cmaesFitBench.C:58:45: error: no member named 'MinimizerOptions' in namespace 'ROOT::Math'; ROOT::Math::IOptions *opts = ROOT::Math::MinimizerOptions::Default(fitter);; ~~~~~~~~~~~~^; Error in <ACLiC>: Dictionary generation failed!; ```; Help is needed to fix the above. **How to build**; ```; cd build; cmake ../ -Dminuit2=on -Dtesting=on -Dlibcmaes=on; make; ```; The build will fail because of the header issue mentioned above, so do:; ```; cd include; ln -s eigen3/Eigen .; ln -s eigen3/unsupported .; cd ..; make; ```; You can then use the newly built ROOT and test that CMA-ES is working:; ```; .L tutorials/fit/cmaesGausFit.C++g; cmaesGausFit(); ```. Please see instructions and links from PR #40 for more tests, performance checks, etc... Once everything is fine, I'll be able to squash all commits into a single one if needed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/507
https://github.com/root-project/root/pull/507:11,Deployability,update,update,11,"This is an update to PR #40 that includes:; - a rebase with all CMA-ES commits at the tip of master (as of 04/17/2017); - a set of small fixes as requested by @vgvassilev . As a reminder, this PR fetches, builds and wraps https://github.com/beniz/libcmaes/ with ROOT. This PR builds ROOT with CMA-ES support and I've been able to run some of the tests, indicating that it is working fine. **Issues**; However, some caveats remain, on which help is required, at the moment. - [ ] `build/include/libcmaes/cmaes.h` and `build/include/Eigen` are not properly passed to the compiler at build time. I cannot find how to do it properly. At the moment I am using symlinks as a temporary hack (see how to build below). - [ ] To access the inner option of the CMA-ES Minimizer, I was using code similar to; ```C++; ROOT::Math::IOptions &opts = ROOT::Math::MinimizerOptions::Default(fitter);; opts.SetIntValue(""lambda"",lambda);; ```; Code above now appears to fail with errors such as:; ```; root [0] .L tutorials/fit/cmaesFitBench.C++g; Info in <TUnixSystem::ACLiC>: creating shared library /home/beniz/research/siminole/dev/tmp/root/build/./tutorials/fit/cmaesFitBench_C.so; In file included from input_line_11:9:; ././tutorials/fit/cmaesFitBench.C:58:16: error: no type named 'IOptions' in namespace 'ROOT::Math'; ROOT::Math::IOptions *opts = ROOT::Math::MinimizerOptions::Default(fitter);; ~~~~~~~~~~~~^; ././tutorials/fit/cmaesFitBench.C:58:45: error: no member named 'MinimizerOptions' in namespace 'ROOT::Math'; ROOT::Math::IOptions *opts = ROOT::Math::MinimizerOptions::Default(fitter);; ~~~~~~~~~~~~^; Error in <ACLiC>: Dictionary generation failed!; ```; Help is needed to fix the above. **How to build**; ```; cd build; cmake ../ -Dminuit2=on -Dtesting=on -Dlibcmaes=on; make; ```; The build will fail because of the header issue mentioned above, so do:; ```; cd include; ln -s eigen3/Eigen .; ln -s eigen3/unsupported .; cd ..; make; ```; You can then use the newly built ROOT and test that CMA-ES is",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/507
https://github.com/root-project/root/pull/507:216,Integrability,wrap,wraps,216,"This is an update to PR #40 that includes:; - a rebase with all CMA-ES commits at the tip of master (as of 04/17/2017); - a set of small fixes as requested by @vgvassilev . As a reminder, this PR fetches, builds and wraps https://github.com/beniz/libcmaes/ with ROOT. This PR builds ROOT with CMA-ES support and I've been able to run some of the tests, indicating that it is working fine. **Issues**; However, some caveats remain, on which help is required, at the moment. - [ ] `build/include/libcmaes/cmaes.h` and `build/include/Eigen` are not properly passed to the compiler at build time. I cannot find how to do it properly. At the moment I am using symlinks as a temporary hack (see how to build below). - [ ] To access the inner option of the CMA-ES Minimizer, I was using code similar to; ```C++; ROOT::Math::IOptions &opts = ROOT::Math::MinimizerOptions::Default(fitter);; opts.SetIntValue(""lambda"",lambda);; ```; Code above now appears to fail with errors such as:; ```; root [0] .L tutorials/fit/cmaesFitBench.C++g; Info in <TUnixSystem::ACLiC>: creating shared library /home/beniz/research/siminole/dev/tmp/root/build/./tutorials/fit/cmaesFitBench_C.so; In file included from input_line_11:9:; ././tutorials/fit/cmaesFitBench.C:58:16: error: no type named 'IOptions' in namespace 'ROOT::Math'; ROOT::Math::IOptions *opts = ROOT::Math::MinimizerOptions::Default(fitter);; ~~~~~~~~~~~~^; ././tutorials/fit/cmaesFitBench.C:58:45: error: no member named 'MinimizerOptions' in namespace 'ROOT::Math'; ROOT::Math::IOptions *opts = ROOT::Math::MinimizerOptions::Default(fitter);; ~~~~~~~~~~~~^; Error in <ACLiC>: Dictionary generation failed!; ```; Help is needed to fix the above. **How to build**; ```; cd build; cmake ../ -Dminuit2=on -Dtesting=on -Dlibcmaes=on; make; ```; The build will fail because of the header issue mentioned above, so do:; ```; cd include; ln -s eigen3/Eigen .; ln -s eigen3/unsupported .; cd ..; make; ```; You can then use the newly built ROOT and test that CMA-ES is",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/507
https://github.com/root-project/root/pull/507:2136,Performance,perform,performance,2136,"maes/ with ROOT. This PR builds ROOT with CMA-ES support and I've been able to run some of the tests, indicating that it is working fine. **Issues**; However, some caveats remain, on which help is required, at the moment. - [ ] `build/include/libcmaes/cmaes.h` and `build/include/Eigen` are not properly passed to the compiler at build time. I cannot find how to do it properly. At the moment I am using symlinks as a temporary hack (see how to build below). - [ ] To access the inner option of the CMA-ES Minimizer, I was using code similar to; ```C++; ROOT::Math::IOptions &opts = ROOT::Math::MinimizerOptions::Default(fitter);; opts.SetIntValue(""lambda"",lambda);; ```; Code above now appears to fail with errors such as:; ```; root [0] .L tutorials/fit/cmaesFitBench.C++g; Info in <TUnixSystem::ACLiC>: creating shared library /home/beniz/research/siminole/dev/tmp/root/build/./tutorials/fit/cmaesFitBench_C.so; In file included from input_line_11:9:; ././tutorials/fit/cmaesFitBench.C:58:16: error: no type named 'IOptions' in namespace 'ROOT::Math'; ROOT::Math::IOptions *opts = ROOT::Math::MinimizerOptions::Default(fitter);; ~~~~~~~~~~~~^; ././tutorials/fit/cmaesFitBench.C:58:45: error: no member named 'MinimizerOptions' in namespace 'ROOT::Math'; ROOT::Math::IOptions *opts = ROOT::Math::MinimizerOptions::Default(fitter);; ~~~~~~~~~~~~^; Error in <ACLiC>: Dictionary generation failed!; ```; Help is needed to fix the above. **How to build**; ```; cd build; cmake ../ -Dminuit2=on -Dtesting=on -Dlibcmaes=on; make; ```; The build will fail because of the header issue mentioned above, so do:; ```; cd include; ln -s eigen3/Eigen .; ln -s eigen3/unsupported .; cd ..; make; ```; You can then use the newly built ROOT and test that CMA-ES is working:; ```; .L tutorials/fit/cmaesGausFit.C++g; cmaesGausFit(); ```. Please see instructions and links from PR #40 for more tests, performance checks, etc... Once everything is fine, I'll be able to squash all commits into a single one if needed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/507
https://github.com/root-project/root/pull/507:719,Security,access,access,719,"This is an update to PR #40 that includes:; - a rebase with all CMA-ES commits at the tip of master (as of 04/17/2017); - a set of small fixes as requested by @vgvassilev . As a reminder, this PR fetches, builds and wraps https://github.com/beniz/libcmaes/ with ROOT. This PR builds ROOT with CMA-ES support and I've been able to run some of the tests, indicating that it is working fine. **Issues**; However, some caveats remain, on which help is required, at the moment. - [ ] `build/include/libcmaes/cmaes.h` and `build/include/Eigen` are not properly passed to the compiler at build time. I cannot find how to do it properly. At the moment I am using symlinks as a temporary hack (see how to build below). - [ ] To access the inner option of the CMA-ES Minimizer, I was using code similar to; ```C++; ROOT::Math::IOptions &opts = ROOT::Math::MinimizerOptions::Default(fitter);; opts.SetIntValue(""lambda"",lambda);; ```; Code above now appears to fail with errors such as:; ```; root [0] .L tutorials/fit/cmaesFitBench.C++g; Info in <TUnixSystem::ACLiC>: creating shared library /home/beniz/research/siminole/dev/tmp/root/build/./tutorials/fit/cmaesFitBench_C.so; In file included from input_line_11:9:; ././tutorials/fit/cmaesFitBench.C:58:16: error: no type named 'IOptions' in namespace 'ROOT::Math'; ROOT::Math::IOptions *opts = ROOT::Math::MinimizerOptions::Default(fitter);; ~~~~~~~~~~~~^; ././tutorials/fit/cmaesFitBench.C:58:45: error: no member named 'MinimizerOptions' in namespace 'ROOT::Math'; ROOT::Math::IOptions *opts = ROOT::Math::MinimizerOptions::Default(fitter);; ~~~~~~~~~~~~^; Error in <ACLiC>: Dictionary generation failed!; ```; Help is needed to fix the above. **How to build**; ```; cd build; cmake ../ -Dminuit2=on -Dtesting=on -Dlibcmaes=on; make; ```; The build will fail because of the header issue mentioned above, so do:; ```; cd include; ln -s eigen3/Eigen .; ln -s eigen3/unsupported .; cd ..; make; ```; You can then use the newly built ROOT and test that CMA-ES is",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/507
https://github.com/root-project/root/pull/507:346,Testability,test,tests,346,"This is an update to PR #40 that includes:; - a rebase with all CMA-ES commits at the tip of master (as of 04/17/2017); - a set of small fixes as requested by @vgvassilev . As a reminder, this PR fetches, builds and wraps https://github.com/beniz/libcmaes/ with ROOT. This PR builds ROOT with CMA-ES support and I've been able to run some of the tests, indicating that it is working fine. **Issues**; However, some caveats remain, on which help is required, at the moment. - [ ] `build/include/libcmaes/cmaes.h` and `build/include/Eigen` are not properly passed to the compiler at build time. I cannot find how to do it properly. At the moment I am using symlinks as a temporary hack (see how to build below). - [ ] To access the inner option of the CMA-ES Minimizer, I was using code similar to; ```C++; ROOT::Math::IOptions &opts = ROOT::Math::MinimizerOptions::Default(fitter);; opts.SetIntValue(""lambda"",lambda);; ```; Code above now appears to fail with errors such as:; ```; root [0] .L tutorials/fit/cmaesFitBench.C++g; Info in <TUnixSystem::ACLiC>: creating shared library /home/beniz/research/siminole/dev/tmp/root/build/./tutorials/fit/cmaesFitBench_C.so; In file included from input_line_11:9:; ././tutorials/fit/cmaesFitBench.C:58:16: error: no type named 'IOptions' in namespace 'ROOT::Math'; ROOT::Math::IOptions *opts = ROOT::Math::MinimizerOptions::Default(fitter);; ~~~~~~~~~~~~^; ././tutorials/fit/cmaesFitBench.C:58:45: error: no member named 'MinimizerOptions' in namespace 'ROOT::Math'; ROOT::Math::IOptions *opts = ROOT::Math::MinimizerOptions::Default(fitter);; ~~~~~~~~~~~~^; Error in <ACLiC>: Dictionary generation failed!; ```; Help is needed to fix the above. **How to build**; ```; cd build; cmake ../ -Dminuit2=on -Dtesting=on -Dlibcmaes=on; make; ```; The build will fail because of the header issue mentioned above, so do:; ```; cd include; ln -s eigen3/Eigen .; ln -s eigen3/unsupported .; cd ..; make; ```; You can then use the newly built ROOT and test that CMA-ES is",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/507
https://github.com/root-project/root/pull/507:1982,Testability,test,test,1982,"maes/ with ROOT. This PR builds ROOT with CMA-ES support and I've been able to run some of the tests, indicating that it is working fine. **Issues**; However, some caveats remain, on which help is required, at the moment. - [ ] `build/include/libcmaes/cmaes.h` and `build/include/Eigen` are not properly passed to the compiler at build time. I cannot find how to do it properly. At the moment I am using symlinks as a temporary hack (see how to build below). - [ ] To access the inner option of the CMA-ES Minimizer, I was using code similar to; ```C++; ROOT::Math::IOptions &opts = ROOT::Math::MinimizerOptions::Default(fitter);; opts.SetIntValue(""lambda"",lambda);; ```; Code above now appears to fail with errors such as:; ```; root [0] .L tutorials/fit/cmaesFitBench.C++g; Info in <TUnixSystem::ACLiC>: creating shared library /home/beniz/research/siminole/dev/tmp/root/build/./tutorials/fit/cmaesFitBench_C.so; In file included from input_line_11:9:; ././tutorials/fit/cmaesFitBench.C:58:16: error: no type named 'IOptions' in namespace 'ROOT::Math'; ROOT::Math::IOptions *opts = ROOT::Math::MinimizerOptions::Default(fitter);; ~~~~~~~~~~~~^; ././tutorials/fit/cmaesFitBench.C:58:45: error: no member named 'MinimizerOptions' in namespace 'ROOT::Math'; ROOT::Math::IOptions *opts = ROOT::Math::MinimizerOptions::Default(fitter);; ~~~~~~~~~~~~^; Error in <ACLiC>: Dictionary generation failed!; ```; Help is needed to fix the above. **How to build**; ```; cd build; cmake ../ -Dminuit2=on -Dtesting=on -Dlibcmaes=on; make; ```; The build will fail because of the header issue mentioned above, so do:; ```; cd include; ln -s eigen3/Eigen .; ln -s eigen3/unsupported .; cd ..; make; ```; You can then use the newly built ROOT and test that CMA-ES is working:; ```; .L tutorials/fit/cmaesGausFit.C++g; cmaesGausFit(); ```. Please see instructions and links from PR #40 for more tests, performance checks, etc... Once everything is fine, I'll be able to squash all commits into a single one if needed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/507
https://github.com/root-project/root/pull/507:2129,Testability,test,tests,2129,"maes/ with ROOT. This PR builds ROOT with CMA-ES support and I've been able to run some of the tests, indicating that it is working fine. **Issues**; However, some caveats remain, on which help is required, at the moment. - [ ] `build/include/libcmaes/cmaes.h` and `build/include/Eigen` are not properly passed to the compiler at build time. I cannot find how to do it properly. At the moment I am using symlinks as a temporary hack (see how to build below). - [ ] To access the inner option of the CMA-ES Minimizer, I was using code similar to; ```C++; ROOT::Math::IOptions &opts = ROOT::Math::MinimizerOptions::Default(fitter);; opts.SetIntValue(""lambda"",lambda);; ```; Code above now appears to fail with errors such as:; ```; root [0] .L tutorials/fit/cmaesFitBench.C++g; Info in <TUnixSystem::ACLiC>: creating shared library /home/beniz/research/siminole/dev/tmp/root/build/./tutorials/fit/cmaesFitBench_C.so; In file included from input_line_11:9:; ././tutorials/fit/cmaesFitBench.C:58:16: error: no type named 'IOptions' in namespace 'ROOT::Math'; ROOT::Math::IOptions *opts = ROOT::Math::MinimizerOptions::Default(fitter);; ~~~~~~~~~~~~^; ././tutorials/fit/cmaesFitBench.C:58:45: error: no member named 'MinimizerOptions' in namespace 'ROOT::Math'; ROOT::Math::IOptions *opts = ROOT::Math::MinimizerOptions::Default(fitter);; ~~~~~~~~~~~~^; Error in <ACLiC>: Dictionary generation failed!; ```; Help is needed to fix the above. **How to build**; ```; cd build; cmake ../ -Dminuit2=on -Dtesting=on -Dlibcmaes=on; make; ```; The build will fail because of the header issue mentioned above, so do:; ```; cd include; ln -s eigen3/Eigen .; ln -s eigen3/unsupported .; cd ..; make; ```; You can then use the newly built ROOT and test that CMA-ES is working:; ```; .L tutorials/fit/cmaesGausFit.C++g; cmaesGausFit(); ```. Please see instructions and links from PR #40 for more tests, performance checks, etc... Once everything is fine, I'll be able to squash all commits into a single one if needed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/507
https://github.com/root-project/root/pull/511:0,Testability,Test,Test,0,Test file: `math/smatrix/test/testSMatrix.cxx`. Failing test on CDash:; http://cdash.cern.ch/testDetails.php?test=24128678&build=345047,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/511
https://github.com/root-project/root/pull/511:25,Testability,test,test,25,Test file: `math/smatrix/test/testSMatrix.cxx`. Failing test on CDash:; http://cdash.cern.ch/testDetails.php?test=24128678&build=345047,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/511
https://github.com/root-project/root/pull/511:30,Testability,test,testSMatrix,30,Test file: `math/smatrix/test/testSMatrix.cxx`. Failing test on CDash:; http://cdash.cern.ch/testDetails.php?test=24128678&build=345047,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/511
https://github.com/root-project/root/pull/511:56,Testability,test,test,56,Test file: `math/smatrix/test/testSMatrix.cxx`. Failing test on CDash:; http://cdash.cern.ch/testDetails.php?test=24128678&build=345047,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/511
https://github.com/root-project/root/pull/511:93,Testability,test,testDetails,93,Test file: `math/smatrix/test/testSMatrix.cxx`. Failing test on CDash:; http://cdash.cern.ch/testDetails.php?test=24128678&build=345047,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/511
https://github.com/root-project/root/pull/511:109,Testability,test,test,109,Test file: `math/smatrix/test/testSMatrix.cxx`. Failing test on CDash:; http://cdash.cern.ch/testDetails.php?test=24128678&build=345047,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/511
https://github.com/root-project/root/pull/512:18,Integrability,message,messages,18,Please see commit messages for full explanation of the changes. Failing test: http://cdash.cern.ch/testDetails.php?test=24129853&build=345069,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/512
https://github.com/root-project/root/pull/512:72,Testability,test,test,72,Please see commit messages for full explanation of the changes. Failing test: http://cdash.cern.ch/testDetails.php?test=24129853&build=345069,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/512
https://github.com/root-project/root/pull/512:99,Testability,test,testDetails,99,Please see commit messages for full explanation of the changes. Failing test: http://cdash.cern.ch/testDetails.php?test=24129853&build=345069,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/512
https://github.com/root-project/root/pull/512:115,Testability,test,test,115,Please see commit messages for full explanation of the changes. Failing test: http://cdash.cern.ch/testDetails.php?test=24129853&build=345069,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/512
https://github.com/root-project/root/pull/513:10,Security,secur,security,10,Addressed security threat reported by S. Luders.; Using the same technology used in TSystem::ExpandFileName .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/513
https://github.com/root-project/root/pull/513:19,Security,threat,threat,19,Addressed security threat reported by S. Luders.; Using the same technology used in TSystem::ExpandFileName .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/513
https://github.com/root-project/root/pull/515:0,Modifiability,Extend,Extending,0,Extending TH2Poly such as to make it behave like TProfile2D with the addition of being able to deal with polygonal bins. TH2; |; |; +-------+------+------+-----+-----+-------------+; | | | | | |; TH2C TH2S TH2I TH2F TH2D TH2Poly; | |; | |; TProfile2D TProfile2Poly. The main goal of TProfile2Poly: Showing averages / standard deviation of measured values per polygonal bins. **[EDIT]**; Proposed tutorial:; https://gist.github.com/imKuehlschrank/1efbbd4426d9bdfa9ceb27e09ae7e958; Similar style as https://root.cern/doc/master/th2polyEurope_8C.html,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/515
https://github.com/root-project/root/pull/516:0,Modifiability,Rewrite,Rewrite,0,"Rewrite of TChain::ParseTreeFilename and mods in TApplication::GetOptions.; Adds also full support for wildcards, at least for the backends supporting it,; and for generic paths on the command line, e.g. for. $ root root://host.my.dom//my/dir/file.root?option#anchor",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/516
https://github.com/root-project/root/pull/518:65,Availability,error,errors,65,"Casting the matrices from double to float create small rounding; errors of the order of 1e-06 in the reference matrices themselves,; so when they are multiplied the sum over long rows/columns accumulates; many rounding errors and make the test fail. Using TMatrixT of float; as the reference to begin with eliminates this problem. **Note:** _This is a backport of the same fix to master, but with 3 commits combined into a single one._. Reference: http://cdash.cern.ch/testSummary.php?project=1&name=TMVA-DNN-Arithmetic-Cpu&date=2017-04-21",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/518
https://github.com/root-project/root/pull/518:219,Availability,error,errors,219,"Casting the matrices from double to float create small rounding; errors of the order of 1e-06 in the reference matrices themselves,; so when they are multiplied the sum over long rows/columns accumulates; many rounding errors and make the test fail. Using TMatrixT of float; as the reference to begin with eliminates this problem. **Note:** _This is a backport of the same fix to master, but with 3 commits combined into a single one._. Reference: http://cdash.cern.ch/testSummary.php?project=1&name=TMVA-DNN-Arithmetic-Cpu&date=2017-04-21",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/518
https://github.com/root-project/root/pull/518:239,Testability,test,test,239,"Casting the matrices from double to float create small rounding; errors of the order of 1e-06 in the reference matrices themselves,; so when they are multiplied the sum over long rows/columns accumulates; many rounding errors and make the test fail. Using TMatrixT of float; as the reference to begin with eliminates this problem. **Note:** _This is a backport of the same fix to master, but with 3 commits combined into a single one._. Reference: http://cdash.cern.ch/testSummary.php?project=1&name=TMVA-DNN-Arithmetic-Cpu&date=2017-04-21",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/518
https://github.com/root-project/root/pull/518:469,Testability,test,testSummary,469,"Casting the matrices from double to float create small rounding; errors of the order of 1e-06 in the reference matrices themselves,; so when they are multiplied the sum over long rows/columns accumulates; many rounding errors and make the test fail. Using TMatrixT of float; as the reference to begin with eliminates this problem. **Note:** _This is a backport of the same fix to master, but with 3 commits combined into a single one._. Reference: http://cdash.cern.ch/testSummary.php?project=1&name=TMVA-DNN-Arithmetic-Cpu&date=2017-04-21",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/518
https://github.com/root-project/root/pull/519:82,Testability,assert,assertion,82,The sysroot flag should not be set when writing a module otherwise we; trigger an assertion in ASTWriter.cpp:1245.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/519
https://github.com/root-project/root/pull/521:164,Availability,toler,tolerance,164,"- Improve diagnostic output of compare() function; - Test inverted matrix times original against identity using; element by element comparison, and use less strict tolerance; to account for innacuracies due to matrix inversion. *Note: I am still running this test many times to make sure it doesn't fail anymore. Please wait to merge until after the runs are finished.*",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/521
https://github.com/root-project/root/pull/521:53,Testability,Test,Test,53,"- Improve diagnostic output of compare() function; - Test inverted matrix times original against identity using; element by element comparison, and use less strict tolerance; to account for innacuracies due to matrix inversion. *Note: I am still running this test many times to make sure it doesn't fail anymore. Please wait to merge until after the runs are finished.*",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/521
https://github.com/root-project/root/pull/521:259,Testability,test,test,259,"- Improve diagnostic output of compare() function; - Test inverted matrix times original against identity using; element by element comparison, and use less strict tolerance; to account for innacuracies due to matrix inversion. *Note: I am still running this test many times to make sure it doesn't fail anymore. Please wait to merge until after the runs are finished.*",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/521
https://github.com/root-project/root/pull/522:480,Availability,error,errors,480,"This patch set enabled C++17 (C++1z) support in ROOT. This will require at least GCC 7.1.0 (soon to be released, probably in a month). GCC 7 fully implements C++17 language features. CMSSW builds using GCC 6.2.0, GCC 6.3.0 and GCC 7.0.1 are all compiled with C++17. Note that biggest issues came from `TString` and `std::string` interaction due to `std::string_view` conversion operator in `TString`. This makes mixing `TString` and `std::string` painful. Thus to avoid ambiguity errors `std::string_view` operator is now marked as explicit. Otherwise in a lot of places I had to use `static_cast<>` to pick one of conversion operators (which makes the patch bigger).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/522
https://github.com/root-project/root/pull/522:5,Deployability,patch,patch,5,"This patch set enabled C++17 (C++1z) support in ROOT. This will require at least GCC 7.1.0 (soon to be released, probably in a month). GCC 7 fully implements C++17 language features. CMSSW builds using GCC 6.2.0, GCC 6.3.0 and GCC 7.0.1 are all compiled with C++17. Note that biggest issues came from `TString` and `std::string` interaction due to `std::string_view` conversion operator in `TString`. This makes mixing `TString` and `std::string` painful. Thus to avoid ambiguity errors `std::string_view` operator is now marked as explicit. Otherwise in a lot of places I had to use `static_cast<>` to pick one of conversion operators (which makes the patch bigger).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/522
https://github.com/root-project/root/pull/522:103,Deployability,release,released,103,"This patch set enabled C++17 (C++1z) support in ROOT. This will require at least GCC 7.1.0 (soon to be released, probably in a month). GCC 7 fully implements C++17 language features. CMSSW builds using GCC 6.2.0, GCC 6.3.0 and GCC 7.0.1 are all compiled with C++17. Note that biggest issues came from `TString` and `std::string` interaction due to `std::string_view` conversion operator in `TString`. This makes mixing `TString` and `std::string` painful. Thus to avoid ambiguity errors `std::string_view` operator is now marked as explicit. Otherwise in a lot of places I had to use `static_cast<>` to pick one of conversion operators (which makes the patch bigger).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/522
https://github.com/root-project/root/pull/522:653,Deployability,patch,patch,653,"This patch set enabled C++17 (C++1z) support in ROOT. This will require at least GCC 7.1.0 (soon to be released, probably in a month). GCC 7 fully implements C++17 language features. CMSSW builds using GCC 6.2.0, GCC 6.3.0 and GCC 7.0.1 are all compiled with C++17. Note that biggest issues came from `TString` and `std::string` interaction due to `std::string_view` conversion operator in `TString`. This makes mixing `TString` and `std::string` painful. Thus to avoid ambiguity errors `std::string_view` operator is now marked as explicit. Otherwise in a lot of places I had to use `static_cast<>` to pick one of conversion operators (which makes the patch bigger).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/522
https://github.com/root-project/root/pull/522:464,Safety,avoid,avoid,464,"This patch set enabled C++17 (C++1z) support in ROOT. This will require at least GCC 7.1.0 (soon to be released, probably in a month). GCC 7 fully implements C++17 language features. CMSSW builds using GCC 6.2.0, GCC 6.3.0 and GCC 7.0.1 are all compiled with C++17. Note that biggest issues came from `TString` and `std::string` interaction due to `std::string_view` conversion operator in `TString`. This makes mixing `TString` and `std::string` painful. Thus to avoid ambiguity errors `std::string_view` operator is now marked as explicit. Otherwise in a lot of places I had to use `static_cast<>` to pick one of conversion operators (which makes the patch bigger).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/522
https://github.com/root-project/root/pull/523:343,Availability,avail,available,343,"These 3 small patches I am using for ROOT + Intel QuickAssist Technology (QAT). QAT provides HW-accelerated (de)compression and crypto (incl. hashing). For easy integration Intel provides zlib-shim and openssl-shim, support the most common interfaces (but not everything). Note, that QAT also has software fallback mechanism. More details are available in the commit messages.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/523
https://github.com/root-project/root/pull/523:14,Deployability,patch,patches,14,"These 3 small patches I am using for ROOT + Intel QuickAssist Technology (QAT). QAT provides HW-accelerated (de)compression and crypto (incl. hashing). For easy integration Intel provides zlib-shim and openssl-shim, support the most common interfaces (but not everything). Note, that QAT also has software fallback mechanism. More details are available in the commit messages.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/523
https://github.com/root-project/root/pull/523:161,Deployability,integrat,integration,161,"These 3 small patches I am using for ROOT + Intel QuickAssist Technology (QAT). QAT provides HW-accelerated (de)compression and crypto (incl. hashing). For easy integration Intel provides zlib-shim and openssl-shim, support the most common interfaces (but not everything). Note, that QAT also has software fallback mechanism. More details are available in the commit messages.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/523
https://github.com/root-project/root/pull/523:161,Integrability,integrat,integration,161,"These 3 small patches I am using for ROOT + Intel QuickAssist Technology (QAT). QAT provides HW-accelerated (de)compression and crypto (incl. hashing). For easy integration Intel provides zlib-shim and openssl-shim, support the most common interfaces (but not everything). Note, that QAT also has software fallback mechanism. More details are available in the commit messages.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/523
https://github.com/root-project/root/pull/523:240,Integrability,interface,interfaces,240,"These 3 small patches I am using for ROOT + Intel QuickAssist Technology (QAT). QAT provides HW-accelerated (de)compression and crypto (incl. hashing). For easy integration Intel provides zlib-shim and openssl-shim, support the most common interfaces (but not everything). Note, that QAT also has software fallback mechanism. More details are available in the commit messages.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/523
https://github.com/root-project/root/pull/523:367,Integrability,message,messages,367,"These 3 small patches I am using for ROOT + Intel QuickAssist Technology (QAT). QAT provides HW-accelerated (de)compression and crypto (incl. hashing). For easy integration Intel provides zlib-shim and openssl-shim, support the most common interfaces (but not everything). Note, that QAT also has software fallback mechanism. More details are available in the commit messages.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/523
https://github.com/root-project/root/pull/523:142,Security,hash,hashing,142,"These 3 small patches I am using for ROOT + Intel QuickAssist Technology (QAT). QAT provides HW-accelerated (de)compression and crypto (incl. hashing). For easy integration Intel provides zlib-shim and openssl-shim, support the most common interfaces (but not everything). Note, that QAT also has software fallback mechanism. More details are available in the commit messages.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/523
https://github.com/root-project/root/pull/524:17,Availability,error,error,17,fixed copy/paste error in stressLinear; fixed resource leak in ruleVisHists,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/524
https://github.com/root-project/root/pull/527:155,Availability,error,error,155,So far we only trigger an assertion in LLVM when we can't find the; modulemap file which is not very user-friendly. With this patch; we actually prints an error message in this situation.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/527
https://github.com/root-project/root/pull/527:126,Deployability,patch,patch,126,So far we only trigger an assertion in LLVM when we can't find the; modulemap file which is not very user-friendly. With this patch; we actually prints an error message in this situation.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/527
https://github.com/root-project/root/pull/527:161,Integrability,message,message,161,So far we only trigger an assertion in LLVM when we can't find the; modulemap file which is not very user-friendly. With this patch; we actually prints an error message in this situation.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/527
https://github.com/root-project/root/pull/527:26,Testability,assert,assertion,26,So far we only trigger an assertion in LLVM when we can't find the; modulemap file which is not very user-friendly. With this patch; we actually prints an error message in this situation.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/527
https://github.com/root-project/root/pull/527:101,Usability,user-friendly,user-friendly,101,So far we only trigger an assertion in LLVM when we can't find the; modulemap file which is not very user-friendly. With this patch; we actually prints an error message in this situation.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/527
https://github.com/root-project/root/pull/528:104,Deployability,install,installed,104,Editors like VIM creates temporary files (.*.swp) that were added into the list of files to be moved or installed.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/528
https://github.com/root-project/root/pull/532:186,Deployability,update,updated,186,"This PR adds branch type inference to Histo1D with weights, as well as Histo2D, Histo3D, Profile1D and Profile2D both with and without weights.; Code has been simplified. Docs have been updated. A related PR in roottest introduces testing for the new functionality.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/532
https://github.com/root-project/root/pull/532:231,Testability,test,testing,231,"This PR adds branch type inference to Histo1D with weights, as well as Histo2D, Histo3D, Profile1D and Profile2D both with and without weights.; Code has been simplified. Docs have been updated. A related PR in roottest introduces testing for the new functionality.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/532
https://github.com/root-project/root/pull/532:159,Usability,simpl,simplified,159,"This PR adds branch type inference to Histo1D with weights, as well as Histo2D, Histo3D, Profile1D and Profile2D both with and without weights.; Code has been simplified. Docs have been updated. A related PR in roottest introduces testing for the new functionality.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/532
https://github.com/root-project/root/pull/533:371,Integrability,interface,interfaces,371,"This PR is a work in progress for a parallel version of the snapshot action introduced recently to TDataFrame. This version compiles and passes the `test_snaphot.C` test from roottest.git, but still needs quite a bit of work. I imported the files we use with attributed authorship for each part, but we now need to move them to the right place if needed and refactor the interfaces according to feedback from various sources. Please feel free to make comments directly on the code, and I will try to address everything by the deadline for branching out 6.10.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/533
https://github.com/root-project/root/pull/533:358,Modifiability,refactor,refactor,358,"This PR is a work in progress for a parallel version of the snapshot action introduced recently to TDataFrame. This version compiles and passes the `test_snaphot.C` test from roottest.git, but still needs quite a bit of work. I imported the files we use with attributed authorship for each part, but we now need to move them to the right place if needed and refactor the interfaces according to feedback from various sources. Please feel free to make comments directly on the code, and I will try to address everything by the deadline for branching out 6.10.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/533
https://github.com/root-project/root/pull/533:165,Testability,test,test,165,"This PR is a work in progress for a parallel version of the snapshot action introduced recently to TDataFrame. This version compiles and passes the `test_snaphot.C` test from roottest.git, but still needs quite a bit of work. I imported the files we use with attributed authorship for each part, but we now need to move them to the right place if needed and refactor the interfaces according to feedback from various sources. Please feel free to make comments directly on the code, and I will try to address everything by the deadline for branching out 6.10.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/533
https://github.com/root-project/root/pull/533:395,Usability,feedback,feedback,395,"This PR is a work in progress for a parallel version of the snapshot action introduced recently to TDataFrame. This version compiles and passes the `test_snaphot.C` test from roottest.git, but still needs quite a bit of work. I imported the files we use with attributed authorship for each part, but we now need to move them to the right place if needed and refactor the interfaces according to feedback from various sources. Please feel free to make comments directly on the code, and I will try to address everything by the deadline for branching out 6.10.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/533
https://github.com/root-project/root/pull/534:239,Availability,toler,tolerance,239,"The problem with this test is that it is comparing an analytical; solution of the derivative against the center difference formula; f'(x) = (f(x+dx) - f(x-dx))/(2*dx), and this formula is not exact.; The choice of dx was too large for the tolerance accepted for the; maximum relative error. Using a smaller dx for the center difference; calculation fixes this issue by reducing the error in the numerical; derivative calculation.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/534
https://github.com/root-project/root/pull/534:284,Availability,error,error,284,"The problem with this test is that it is comparing an analytical; solution of the derivative against the center difference formula; f'(x) = (f(x+dx) - f(x-dx))/(2*dx), and this formula is not exact.; The choice of dx was too large for the tolerance accepted for the; maximum relative error. Using a smaller dx for the center difference; calculation fixes this issue by reducing the error in the numerical; derivative calculation.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/534
https://github.com/root-project/root/pull/534:382,Availability,error,error,382,"The problem with this test is that it is comparing an analytical; solution of the derivative against the center difference formula; f'(x) = (f(x+dx) - f(x-dx))/(2*dx), and this formula is not exact.; The choice of dx was too large for the tolerance accepted for the; maximum relative error. Using a smaller dx for the center difference; calculation fixes this issue by reducing the error in the numerical; derivative calculation.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/534
https://github.com/root-project/root/pull/534:22,Testability,test,test,22,"The problem with this test is that it is comparing an analytical; solution of the derivative against the center difference formula; f'(x) = (f(x+dx) - f(x-dx))/(2*dx), and this formula is not exact.; The choice of dx was too large for the tolerance accepted for the; maximum relative error. Using a smaller dx for the center difference; calculation fixes this issue by reducing the error in the numerical; derivative calculation.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/534
https://github.com/root-project/root/pull/535:29,Testability,Test,Tests,29,This PR concludes ROOT-8766. Tests for this functionality are added by a separate PR to roottest.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/535
https://github.com/root-project/root/pull/536:87,Safety,avoid,avoid,87,"Seems like ignore-non-existent-contents is quite new,; so we just remove it for now to avoid crashing on; parsing this file with the old clang version inside; ROOT.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/536
https://github.com/root-project/root/pull/537:21,Integrability,depend,depend,21,"It's AST supposed to depend on NDEBUG, so having this as a module is; wrong.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/537
https://github.com/root-project/root/pull/539:13,Testability,assert,assert,13,The previous assert was not only ugly but also did the inverse; check (failed when it could open the file correctly).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/539
https://github.com/root-project/root/pull/541:31,Integrability,depend,dependency,31,Previously we had some strange dependency net with multiple commands; that sometimes lead to only having half a modulemap in the build dir.; Now there is only one target that depends on the generated modulemap; and exactly one custom command that generates the whole modulemap.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/541
https://github.com/root-project/root/pull/541:175,Integrability,depend,depends,175,Previously we had some strange dependency net with multiple commands; that sometimes lead to only having half a modulemap in the build dir.; Now there is only one target that depends on the generated modulemap; and exactly one custom command that generates the whole modulemap.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/541
https://github.com/root-project/root/pull/542:31,Integrability,depend,dependency,31,Previously we had some strange dependency net with multiple commands; that sometimes lead to only having half a modulemap in the build dir.; Now there is only one target that depends on the generated modulemap; and exactly one custom command that generates the whole modulemap.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/542
https://github.com/root-project/root/pull/542:175,Integrability,depend,depends,175,Previously we had some strange dependency net with multiple commands; that sometimes lead to only having half a modulemap in the build dir.; Now there is only one target that depends on the generated modulemap; and exactly one custom command that generates the whole modulemap.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/542
https://github.com/root-project/root/pull/543:87,Testability,test,tests,87,Disable both features when running modules to prevent that those mess with our modules tests.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/543
https://github.com/root-project/root/pull/549:128,Availability,avail,available,128,"GCC 4.9 only defines '__cplusplus' to the value 201300L and not to; 201402L as expected for C++14. This makes the check for the available; C++ standards in the interpreter fail to enable C++14 (which in turn; means that ROOT cannot be compiled with GCC 4.9 if C++14 was enabled in; Cmake). Similarly, for C++17 apart from the proper value 201703L other; values seems to be floating around (e.g. 201406L as defined by the; version of LLVM included with ROOT). The requirement for '__cplusplus_'; to enable certain C++ standards in the interpreter is made less strict; and just needs to be larger than the previous final value. This basically reinstates commit; 0a62e34aa86b812651cfcf9526ba03b975adaa5c which was undone by commit; 702298d9ad83866d0be62f0422c03ac8ea6687f1.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/549
https://github.com/root-project/root/pull/549:711,Usability,undo,undone,711,"GCC 4.9 only defines '__cplusplus' to the value 201300L and not to; 201402L as expected for C++14. This makes the check for the available; C++ standards in the interpreter fail to enable C++14 (which in turn; means that ROOT cannot be compiled with GCC 4.9 if C++14 was enabled in; Cmake). Similarly, for C++17 apart from the proper value 201703L other; values seems to be floating around (e.g. 201406L as defined by the; version of LLVM included with ROOT). The requirement for '__cplusplus_'; to enable certain C++ standards in the interpreter is made less strict; and just needs to be larger than the previous final value. This basically reinstates commit; 0a62e34aa86b812651cfcf9526ba03b975adaa5c which was undone by commit; 702298d9ad83866d0be62f0422c03ac8ea6687f1.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/549
https://github.com/root-project/root/pull/554:9,Modifiability,variab,variable,9,The make variable BONJOURCPPFLAGS and all uses of it was removed in commit cd86add. This one occurrence was reintroduced in commit dc627fb. Remove it again.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/554
https://github.com/root-project/root/pull/557:63,Deployability,release,release,63,"Added my contributions and changed wordings w.r.t. latest 6.09 release. Naturally, feel free to modify anything.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/557
https://github.com/root-project/root/pull/558:59,Deployability,update,updated,59,The old code didn't query the modules if the identifier is updated. This caused some checks to fail such as CheckABICompatibility().,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/558
https://github.com/root-project/root/pull/559:407,Testability,test,tested,407,"These commits fix the tab completion for JupyROOT notebooks. This fixes [ROOT-8346](https://sft.its.cern.ch/jira/browse/ROOT-8346) and [ROOT-8347](https://sft.its.cern.ch/jira/browse/ROOT-8347). There still seem to be issues though, for example; ```; TString a (SHIFT+ENTER); a.D(TAB)a(TAB); ```; completes to; ```; a.Data()ta(); ```; But to me this seems to be caused outside of ROOT. The completions were tested using this [test](https://gist.github.com/suhlatwork/ef20df8ffeef8cf9212d6535ef2e8137#file-testtcjupyroot-py).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/559
https://github.com/root-project/root/pull/559:426,Testability,test,test,426,"These commits fix the tab completion for JupyROOT notebooks. This fixes [ROOT-8346](https://sft.its.cern.ch/jira/browse/ROOT-8346) and [ROOT-8347](https://sft.its.cern.ch/jira/browse/ROOT-8347). There still seem to be issues though, for example; ```; TString a (SHIFT+ENTER); a.D(TAB)a(TAB); ```; completes to; ```; a.Data()ta(); ```; But to me this seems to be caused outside of ROOT. The completions were tested using this [test](https://gist.github.com/suhlatwork/ef20df8ffeef8cf9212d6535ef2e8137#file-testtcjupyroot-py).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/559
https://github.com/root-project/root/pull/559:505,Testability,test,testtcjupyroot-py,505,"These commits fix the tab completion for JupyROOT notebooks. This fixes [ROOT-8346](https://sft.its.cern.ch/jira/browse/ROOT-8346) and [ROOT-8347](https://sft.its.cern.ch/jira/browse/ROOT-8347). There still seem to be issues though, for example; ```; TString a (SHIFT+ENTER); a.D(TAB)a(TAB); ```; completes to; ```; a.Data()ta(); ```; But to me this seems to be caused outside of ROOT. The completions were tested using this [test](https://gist.github.com/suhlatwork/ef20df8ffeef8cf9212d6535ef2e8137#file-testtcjupyroot-py).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/559
https://github.com/root-project/root/pull/562:227,Testability,test,test,227,"Passes `test_snapshot.C` on my computer. However, I believe there are problems elsewhere when more than one cluster exists in the generated trees (i.e. when ForeachSlot actually has more than one slot). We need to make sure to test TDataFrame with trees with multiple slots in the future.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/562
https://github.com/root-project/root/pull/563:105,Availability,error,errors,105,"libOracle.so is compiled with stdc++ and on OS X we're always; compiling with libc++. To prevent linking errors between libOracle.so; and the generated ROOT code in the STL symbols, we just disable; Oracle on this platform.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/563
https://github.com/root-project/root/pull/566:78,Deployability,update,updates,78,Also sanitize setting of TEveArrow parameters and propagation of bounding-box updates to GL viewer.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/566
https://github.com/root-project/root/pull/566:5,Security,sanitiz,sanitize,5,Also sanitize setting of TEveArrow parameters and propagation of bounding-box updates to GL viewer.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/566
https://github.com/root-project/root/pull/567:17,Integrability,interface,interfaces,17,Extended fitting interfaces.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/567
https://github.com/root-project/root/pull/567:0,Modifiability,Extend,Extended,0,Extended fitting interfaces.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/567
https://github.com/root-project/root/pull/569:78,Deployability,install,installed,78,"This helps when python modules are not in the default library path, e.g. when installed in the default system location for python modules like /usr/lib64/pythonX.X/site-packages.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/569
https://github.com/root-project/root/pull/570:681,Deployability,continuous,continuous,681,"C++ didn't have wording for class members until C++11. C++ draft, 9.2 [class.mem]; 17) ""Non-static data members of a (non-union) class with the same access control; (Clause 11) are allocated so that later members have higher addresses within a; class object. The order of allocation of non-static data members with different; access control is unspecified (Clause 11). Implementation alignment requirements; might cause two adjacent members not to be allocated immediately after each; other; so might requirements for space for managing virtual functions (10.3) and; virtual base classes (10.1)."". This means fX, fY and fZ indeed get higher addresses but are not guaranteed to be; continuous in memory. This should fix this issue.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/570
https://github.com/root-project/root/pull/570:181,Energy Efficiency,allocate,allocated,181,"C++ didn't have wording for class members until C++11. C++ draft, 9.2 [class.mem]; 17) ""Non-static data members of a (non-union) class with the same access control; (Clause 11) are allocated so that later members have higher addresses within a; class object. The order of allocation of non-static data members with different; access control is unspecified (Clause 11). Implementation alignment requirements; might cause two adjacent members not to be allocated immediately after each; other; so might requirements for space for managing virtual functions (10.3) and; virtual base classes (10.1)."". This means fX, fY and fZ indeed get higher addresses but are not guaranteed to be; continuous in memory. This should fix this issue.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/570
https://github.com/root-project/root/pull/570:451,Energy Efficiency,allocate,allocated,451,"C++ didn't have wording for class members until C++11. C++ draft, 9.2 [class.mem]; 17) ""Non-static data members of a (non-union) class with the same access control; (Clause 11) are allocated so that later members have higher addresses within a; class object. The order of allocation of non-static data members with different; access control is unspecified (Clause 11). Implementation alignment requirements; might cause two adjacent members not to be allocated immediately after each; other; so might requirements for space for managing virtual functions (10.3) and; virtual base classes (10.1)."". This means fX, fY and fZ indeed get higher addresses but are not guaranteed to be; continuous in memory. This should fix this issue.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/570
https://github.com/root-project/root/pull/570:149,Security,access,access,149,"C++ didn't have wording for class members until C++11. C++ draft, 9.2 [class.mem]; 17) ""Non-static data members of a (non-union) class with the same access control; (Clause 11) are allocated so that later members have higher addresses within a; class object. The order of allocation of non-static data members with different; access control is unspecified (Clause 11). Implementation alignment requirements; might cause two adjacent members not to be allocated immediately after each; other; so might requirements for space for managing virtual functions (10.3) and; virtual base classes (10.1)."". This means fX, fY and fZ indeed get higher addresses but are not guaranteed to be; continuous in memory. This should fix this issue.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/570
https://github.com/root-project/root/pull/570:326,Security,access,access,326,"C++ didn't have wording for class members until C++11. C++ draft, 9.2 [class.mem]; 17) ""Non-static data members of a (non-union) class with the same access control; (Clause 11) are allocated so that later members have higher addresses within a; class object. The order of allocation of non-static data members with different; access control is unspecified (Clause 11). Implementation alignment requirements; might cause two adjacent members not to be allocated immediately after each; other; so might requirements for space for managing virtual functions (10.3) and; virtual base classes (10.1)."". This means fX, fY and fZ indeed get higher addresses but are not guaranteed to be; continuous in memory. This should fix this issue.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/570
https://github.com/root-project/root/pull/572:314,Energy Efficiency,allocate,allocated,314,"as it turnes out the `...class.C` files generated by the TMVA MLP are not thread safe (`fWeights` is a constant array of contant pointers to beginnings of double arrays, and the contents therein vary at runtime inside the GetMvaValue__ method). So the quick hack here is to replace the class member of dynamically allocated arrays by fixed sized arrays in the function scope. # QUASICODE OLD. ```; class mlp {; private:; double *fweights[3]; mlp() {; fweights[0] = new double[5];; fweights[1] = new double[10];; fweights[2] = new double[1];; }; ~mlp() {; delete fweights[0];; delete fweights[1];; delete fweights[2];; }; getmvavalue( std::vector<double> input) const {; fweights[0] = input;; fweights[1] = some_function(fweights[0]);; fweights[2] = some_other_function(fweights[1]);; return fweights[2][0];; }; ```. # QUASICODE NEW. ```; class mlp {; private:; mlp() {; }; ~mlp() {; }; getmvavalue( std::vector<double> input) const {. double fweights0[5];; double fweights1[10];; double fweights2[1];; fweights0 = input;; fweights1 = some_function(fweights0);; fweights2 = some_other_function(fweights1);; return fweights2[0];; }; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/572
https://github.com/root-project/root/pull/572:81,Safety,safe,safe,81,"as it turnes out the `...class.C` files generated by the TMVA MLP are not thread safe (`fWeights` is a constant array of contant pointers to beginnings of double arrays, and the contents therein vary at runtime inside the GetMvaValue__ method). So the quick hack here is to replace the class member of dynamically allocated arrays by fixed sized arrays in the function scope. # QUASICODE OLD. ```; class mlp {; private:; double *fweights[3]; mlp() {; fweights[0] = new double[5];; fweights[1] = new double[10];; fweights[2] = new double[1];; }; ~mlp() {; delete fweights[0];; delete fweights[1];; delete fweights[2];; }; getmvavalue( std::vector<double> input) const {; fweights[0] = input;; fweights[1] = some_function(fweights[0]);; fweights[2] = some_other_function(fweights[1]);; return fweights[2][0];; }; ```. # QUASICODE NEW. ```; class mlp {; private:; mlp() {; }; ~mlp() {; }; getmvavalue( std::vector<double> input) const {. double fweights0[5];; double fweights1[10];; double fweights2[1];; fweights0 = input;; fweights1 = some_function(fweights0);; fweights2 = some_other_function(fweights1);; return fweights2[0];; }; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/572
https://github.com/root-project/root/pull/573:185,Testability,test,test,185,This PR adds in TreeProcessorMP support for processing TTree datasets filtering via a TEntryList.; A new set of Process methods taking a TEntryList * as 3rd argument has been added.; A test for the new functionality is ready to be pushed in roottest once this is pushed.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/573
https://github.com/root-project/root/pull/574:137,Performance,perform,performance,137,Introduces a new (for multiclass anyway) button in the gui that; when clicked displays one ROC curve per class. Each curve contains; the performance of all methods for that class. Uses the new ROCCurve class to calculate the curves.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/574
https://github.com/root-project/root/pull/577:50,Performance,race condition,race conditions,50,"This does not completely resolve the issue of the race conditions, but simplifies the implementation of TBufferMerger a lot by doing away with the ThreadFileMerger imported from GeantV and using TFileMerger directly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/577
https://github.com/root-project/root/pull/577:71,Usability,simpl,simplifies,71,"This does not completely resolve the issue of the race conditions, but simplifies the implementation of TBufferMerger a lot by doing away with the ThreadFileMerger imported from GeantV and using TFileMerger directly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/577
https://github.com/root-project/root/pull/578:1132,Deployability,patch,patch,1132,"Idea to create separate actions list, which will be used only for text-based streaming.; Most actions functions can be reused from normal I/O, ; only several cases should be implemented slightly different. On the long run one could create complimentary actions list for reading data with TBufferXML or TBufferSQL2 and fully isolate text-based and binary I/O. That is in PR:; - creating separate list **fWriteText,** now used only with JSON; - provide new method TStreamerInfo::AddWriteTextAction() to fill actions list; - actions build from the full list of class members (avoid compressed members); - provide specialized actions for kTNamed, kTObject, kSTLp and kStreamLoop; - make actions for kSTLp and kStreamLoop with template parameter isText, potentially can be reused in binary I/O. PR solves several existing problem with JSON:; - TNamed and TObject as direct data members; - correct store of kSTLp members with arrays; - kStreamLoop member with fCounter==0; - kStreamLoop member with fCounter==1; - rudimentary support for TRef; - store dummy TObject instance. With provided code all my test classes working. I can provide patch for roottest. P.S. Most probably, Travis-CI check will be unhappy about source-code formatting.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/578
https://github.com/root-project/root/pull/578:573,Safety,avoid,avoid,573,"Idea to create separate actions list, which will be used only for text-based streaming.; Most actions functions can be reused from normal I/O, ; only several cases should be implemented slightly different. On the long run one could create complimentary actions list for reading data with TBufferXML or TBufferSQL2 and fully isolate text-based and binary I/O. That is in PR:; - creating separate list **fWriteText,** now used only with JSON; - provide new method TStreamerInfo::AddWriteTextAction() to fill actions list; - actions build from the full list of class members (avoid compressed members); - provide specialized actions for kTNamed, kTObject, kSTLp and kStreamLoop; - make actions for kSTLp and kStreamLoop with template parameter isText, potentially can be reused in binary I/O. PR solves several existing problem with JSON:; - TNamed and TObject as direct data members; - correct store of kSTLp members with arrays; - kStreamLoop member with fCounter==0; - kStreamLoop member with fCounter==1; - rudimentary support for TRef; - store dummy TObject instance. With provided code all my test classes working. I can provide patch for roottest. P.S. Most probably, Travis-CI check will be unhappy about source-code formatting.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/578
https://github.com/root-project/root/pull/578:1096,Testability,test,test,1096,"Idea to create separate actions list, which will be used only for text-based streaming.; Most actions functions can be reused from normal I/O, ; only several cases should be implemented slightly different. On the long run one could create complimentary actions list for reading data with TBufferXML or TBufferSQL2 and fully isolate text-based and binary I/O. That is in PR:; - creating separate list **fWriteText,** now used only with JSON; - provide new method TStreamerInfo::AddWriteTextAction() to fill actions list; - actions build from the full list of class members (avoid compressed members); - provide specialized actions for kTNamed, kTObject, kSTLp and kStreamLoop; - make actions for kSTLp and kStreamLoop with template parameter isText, potentially can be reused in binary I/O. PR solves several existing problem with JSON:; - TNamed and TObject as direct data members; - correct store of kSTLp members with arrays; - kStreamLoop member with fCounter==0; - kStreamLoop member with fCounter==1; - rudimentary support for TRef; - store dummy TObject instance. With provided code all my test classes working. I can provide patch for roottest. P.S. Most probably, Travis-CI check will be unhappy about source-code formatting.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/578
https://github.com/root-project/root/pull/580:1135,Deployability,patch,patch,1135,"Improved variant of PR #578 . Idea to create separate actions list, which will be used only for text-based streaming.; Most actions functions can be reused from normal I/O,; only several cases should be implemented slightly different. On the long run one could create complimentary actions list for reading data with TBufferXML or TBufferSQL2 and fully isolate text-based and binary I/O. That is in PR:. creating separate list fWriteText, now used only with JSON; provide new method TStreamerInfo::AddWriteTextAction() to fill actions list; actions build from the full list of class members (avoid compressed members); provide specialized actions for kTNamed, kTObject, kSTLp and kStreamLoop; make actions for kSTLp and kStreamLoop with template parameter isText, potentially can be reused in binary I/O. PR solves several existing problem with JSON:. TNamed and TObject as direct data members; correct store of kSTLp members with arrays; kStreamLoop member with fCounter==0; kStreamLoop member with fCounter==1; rudimentary support for TRef; store dummy TObject instance. With provided code all my test classes working. I can provide patch for roottest. P.S. Most probably, Travis-CI check will be unhappy about source-code formatting.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/580
https://github.com/root-project/root/pull/580:592,Safety,avoid,avoid,592,"Improved variant of PR #578 . Idea to create separate actions list, which will be used only for text-based streaming.; Most actions functions can be reused from normal I/O,; only several cases should be implemented slightly different. On the long run one could create complimentary actions list for reading data with TBufferXML or TBufferSQL2 and fully isolate text-based and binary I/O. That is in PR:. creating separate list fWriteText, now used only with JSON; provide new method TStreamerInfo::AddWriteTextAction() to fill actions list; actions build from the full list of class members (avoid compressed members); provide specialized actions for kTNamed, kTObject, kSTLp and kStreamLoop; make actions for kSTLp and kStreamLoop with template parameter isText, potentially can be reused in binary I/O. PR solves several existing problem with JSON:. TNamed and TObject as direct data members; correct store of kSTLp members with arrays; kStreamLoop member with fCounter==0; kStreamLoop member with fCounter==1; rudimentary support for TRef; store dummy TObject instance. With provided code all my test classes working. I can provide patch for roottest. P.S. Most probably, Travis-CI check will be unhappy about source-code formatting.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/580
https://github.com/root-project/root/pull/580:1099,Testability,test,test,1099,"Improved variant of PR #578 . Idea to create separate actions list, which will be used only for text-based streaming.; Most actions functions can be reused from normal I/O,; only several cases should be implemented slightly different. On the long run one could create complimentary actions list for reading data with TBufferXML or TBufferSQL2 and fully isolate text-based and binary I/O. That is in PR:. creating separate list fWriteText, now used only with JSON; provide new method TStreamerInfo::AddWriteTextAction() to fill actions list; actions build from the full list of class members (avoid compressed members); provide specialized actions for kTNamed, kTObject, kSTLp and kStreamLoop; make actions for kSTLp and kStreamLoop with template parameter isText, potentially can be reused in binary I/O. PR solves several existing problem with JSON:. TNamed and TObject as direct data members; correct store of kSTLp members with arrays; kStreamLoop member with fCounter==0; kStreamLoop member with fCounter==1; rudimentary support for TRef; store dummy TObject instance. With provided code all my test classes working. I can provide patch for roottest. P.S. Most probably, Travis-CI check will be unhappy about source-code formatting.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/580
https://github.com/root-project/root/pull/584:82,Availability,redundant,redundant,82,"Primary changes proposed; - avoiding char to TString to char conversions; - avoid redundant call to xmlEngine().hasattr(node,att) checking instead for null ptr from getattr.; - Add specialization of void TMVA::Tools::ReadAttr( void* node, const char* attrname, T& value ) for float,int, short. [which seem to be the ones we use aside from bool, which now is the biggest contributor to ReadAttr* timing.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/584
https://github.com/root-project/root/pull/584:28,Safety,avoid,avoiding,28,"Primary changes proposed; - avoiding char to TString to char conversions; - avoid redundant call to xmlEngine().hasattr(node,att) checking instead for null ptr from getattr.; - Add specialization of void TMVA::Tools::ReadAttr( void* node, const char* attrname, T& value ) for float,int, short. [which seem to be the ones we use aside from bool, which now is the biggest contributor to ReadAttr* timing.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/584
https://github.com/root-project/root/pull/584:76,Safety,avoid,avoid,76,"Primary changes proposed; - avoiding char to TString to char conversions; - avoid redundant call to xmlEngine().hasattr(node,att) checking instead for null ptr from getattr.; - Add specialization of void TMVA::Tools::ReadAttr( void* node, const char* attrname, T& value ) for float,int, short. [which seem to be the ones we use aside from bool, which now is the biggest contributor to ReadAttr* timing.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/584
https://github.com/root-project/root/pull/584:82,Safety,redund,redundant,82,"Primary changes proposed; - avoiding char to TString to char conversions; - avoid redundant call to xmlEngine().hasattr(node,att) checking instead for null ptr from getattr.; - Add specialization of void TMVA::Tools::ReadAttr( void* node, const char* attrname, T& value ) for float,int, short. [which seem to be the ones we use aside from bool, which now is the biggest contributor to ReadAttr* timing.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/584
https://github.com/root-project/root/pull/586:168,Availability,Ping,Ping,168,"This is a general refactoring of the class test/stressMathMore.cxx.; It involves using Google test for assertions, test fixtures, and general; refactoring of the code. Ping @lmoneta",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/586
https://github.com/root-project/root/pull/586:18,Modifiability,refactor,refactoring,18,"This is a general refactoring of the class test/stressMathMore.cxx.; It involves using Google test for assertions, test fixtures, and general; refactoring of the code. Ping @lmoneta",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/586
https://github.com/root-project/root/pull/586:143,Modifiability,refactor,refactoring,143,"This is a general refactoring of the class test/stressMathMore.cxx.; It involves using Google test for assertions, test fixtures, and general; refactoring of the code. Ping @lmoneta",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/586
https://github.com/root-project/root/pull/586:43,Testability,test,test,43,"This is a general refactoring of the class test/stressMathMore.cxx.; It involves using Google test for assertions, test fixtures, and general; refactoring of the code. Ping @lmoneta",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/586
https://github.com/root-project/root/pull/586:94,Testability,test,test,94,"This is a general refactoring of the class test/stressMathMore.cxx.; It involves using Google test for assertions, test fixtures, and general; refactoring of the code. Ping @lmoneta",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/586
https://github.com/root-project/root/pull/586:103,Testability,assert,assertions,103,"This is a general refactoring of the class test/stressMathMore.cxx.; It involves using Google test for assertions, test fixtures, and general; refactoring of the code. Ping @lmoneta",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/586
https://github.com/root-project/root/pull/586:115,Testability,test,test,115,"This is a general refactoring of the class test/stressMathMore.cxx.; It involves using Google test for assertions, test fixtures, and general; refactoring of the code. Ping @lmoneta",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/586
https://github.com/root-project/root/pull/587:75,Testability,test,tests,75,"The default setting has been determined to be near the optimal; value from tests runs on a 4 core machine (up to 8 threads), by; creating up to 1GB of data with lightweight calculations both to; tmpfs, and to ext4 filesystem on an SSD drive.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/587
https://github.com/root-project/root/pull/590:102,Testability,test,testing,102,"This PR adds support for the LZ4 compression algorithm (branch has been significantly cleaned up). In testing with the sample `Event` object found in the `test` subdirectory, we found that the resulting files were about 13% larger than the default compression settings. Deserialization speed was 95% of the uncompressed speed. As discussed with @pcanal",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/590
https://github.com/root-project/root/pull/590:155,Testability,test,test,155,"This PR adds support for the LZ4 compression algorithm (branch has been significantly cleaned up). In testing with the sample `Event` object found in the `test` subdirectory, we found that the resulting files were about 13% larger than the default compression settings. Deserialization speed was 95% of the uncompressed speed. As discussed with @pcanal",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/590
https://github.com/root-project/root/pull/591:66,Deployability,patch,patches,66,I have moved CMSSW to the latest GCC 7.1.1 and to the tip of 6.10 patches branch. These are the fixes I have applied on top of that branch for CMS.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/591
https://github.com/root-project/root/pull/593:46,Modifiability,config,configure,46,"This PR adds support for LZ4 in the ""classic"" configure/Makefile build, adding near-parity to the `cmake`-based build. The exception is `win32` -- `core/lz4/Module.mk` will need to be heavily tackled by someone with a Windows background (I do not have access to a Windows-based host). @pcanal - note that this reverts the commit disabling LZ4 for the `cmake`-based build.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/593
https://github.com/root-project/root/pull/593:252,Security,access,access,252,"This PR adds support for LZ4 in the ""classic"" configure/Makefile build, adding near-parity to the `cmake`-based build. The exception is `win32` -- `core/lz4/Module.mk` will need to be heavily tackled by someone with a Windows background (I do not have access to a Windows-based host). @pcanal - note that this reverts the commit disabling LZ4 for the `cmake`-based build.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/593
https://github.com/root-project/root/pull/594:252,Availability,Ping,Ping,252,"Basic refactoring of test/stressMathCore.cxx to be smaller, more manageable files, and to use Google Test. The functionality is the same, but is now using Google Test for assertions instead of doing logical operations on an integer as the test result. Ping @lmoneta",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/594
https://github.com/root-project/root/pull/594:6,Modifiability,refactor,refactoring,6,"Basic refactoring of test/stressMathCore.cxx to be smaller, more manageable files, and to use Google Test. The functionality is the same, but is now using Google Test for assertions instead of doing logical operations on an integer as the test result. Ping @lmoneta",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/594
https://github.com/root-project/root/pull/594:21,Testability,test,test,21,"Basic refactoring of test/stressMathCore.cxx to be smaller, more manageable files, and to use Google Test. The functionality is the same, but is now using Google Test for assertions instead of doing logical operations on an integer as the test result. Ping @lmoneta",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/594
https://github.com/root-project/root/pull/594:101,Testability,Test,Test,101,"Basic refactoring of test/stressMathCore.cxx to be smaller, more manageable files, and to use Google Test. The functionality is the same, but is now using Google Test for assertions instead of doing logical operations on an integer as the test result. Ping @lmoneta",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/594
https://github.com/root-project/root/pull/594:162,Testability,Test,Test,162,"Basic refactoring of test/stressMathCore.cxx to be smaller, more manageable files, and to use Google Test. The functionality is the same, but is now using Google Test for assertions instead of doing logical operations on an integer as the test result. Ping @lmoneta",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/594
https://github.com/root-project/root/pull/594:171,Testability,assert,assertions,171,"Basic refactoring of test/stressMathCore.cxx to be smaller, more manageable files, and to use Google Test. The functionality is the same, but is now using Google Test for assertions instead of doing logical operations on an integer as the test result. Ping @lmoneta",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/594
https://github.com/root-project/root/pull/594:199,Testability,log,logical,199,"Basic refactoring of test/stressMathCore.cxx to be smaller, more manageable files, and to use Google Test. The functionality is the same, but is now using Google Test for assertions instead of doing logical operations on an integer as the test result. Ping @lmoneta",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/594
https://github.com/root-project/root/pull/594:239,Testability,test,test,239,"Basic refactoring of test/stressMathCore.cxx to be smaller, more manageable files, and to use Google Test. The functionality is the same, but is now using Google Test for assertions instead of doing logical operations on an integer as the test result. Ping @lmoneta",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/594
https://github.com/root-project/root/pull/595:33,Testability,test,tests,33,"Please take a look. Although the tests pass, this is not supposed to be merged yet, as I have yet to understand why it's so slow when we pass a positive auto-flush value to snapshot the tree.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/595
https://github.com/root-project/root/pull/596:45,Performance,perform,performant,45,One pending question (beside whether this is performant enough) is whether to keep the old TRWSpinLock and the new TRWSpinLock (Reentrant) or to have them (as in this MR) the same.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/596
https://github.com/root-project/root/pull/597:7,Usability,simpl,simple,7,Adds a simple comparison technique for multiclass classifiers.; 1-vs-rest will do a binary comparison between given class; considered signal and all others collectively considered; background. 1-vs-1 will do pair-wise binary comparisons. Output is in TMVA::Factory::EvaluateAllMethods,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/597
https://github.com/root-project/root/pull/598:91,Availability,down,downloads,91,"I realized this was broken when updating the VecCore version to 0.4.1. The new version now downloads Vc and UME::SIMD from LCG packages repository, and uses http instead of https, in order to avoid problems in systems in which curl has no support for https. I also took the oportunity to fix a few warnings due to wrong indentation of the code.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/598
https://github.com/root-project/root/pull/598:192,Safety,avoid,avoid,192,"I realized this was broken when updating the VecCore version to 0.4.1. The new version now downloads Vc and UME::SIMD from LCG packages repository, and uses http instead of https, in order to avoid problems in systems in which curl has no support for https. I also took the oportunity to fix a few warnings due to wrong indentation of the code.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/598
https://github.com/root-project/root/pull/599:438,Deployability,update,update,438,"The build system appears to assume that `roottest` is, by default, in a subdirectory of the source directory named `roottest`. I'd love to make it easier to include `roottest` in builds to encourage developers to utilize it: this seems like a great use of `git submodule`!. Here's how a user would clone the `root` and `roottest` repos:; ```; git clone https://github.com/root-project/root.git; cd root; git submodule init; git submodule update; ```. One would then do the normal build with `cmake`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/599
https://github.com/root-project/root/pull/605:42,Availability,failure,failure,42,"In response to @dpiparo pointing out this failure http://cdash.cern.ch/testDetails.php?test=25539356&build=359962. The DNN with architecture=Standard is to phased out. In this case it would make sense to disable the corresponding test, since the failure is not to be fixed. If this is acceptable, feel free to merge.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/605
https://github.com/root-project/root/pull/605:246,Availability,failure,failure,246,"In response to @dpiparo pointing out this failure http://cdash.cern.ch/testDetails.php?test=25539356&build=359962. The DNN with architecture=Standard is to phased out. In this case it would make sense to disable the corresponding test, since the failure is not to be fixed. If this is acceptable, feel free to merge.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/605
https://github.com/root-project/root/pull/605:71,Testability,test,testDetails,71,"In response to @dpiparo pointing out this failure http://cdash.cern.ch/testDetails.php?test=25539356&build=359962. The DNN with architecture=Standard is to phased out. In this case it would make sense to disable the corresponding test, since the failure is not to be fixed. If this is acceptable, feel free to merge.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/605
https://github.com/root-project/root/pull/605:87,Testability,test,test,87,"In response to @dpiparo pointing out this failure http://cdash.cern.ch/testDetails.php?test=25539356&build=359962. The DNN with architecture=Standard is to phased out. In this case it would make sense to disable the corresponding test, since the failure is not to be fixed. If this is acceptable, feel free to merge.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/605
https://github.com/root-project/root/pull/605:230,Testability,test,test,230,"In response to @dpiparo pointing out this failure http://cdash.cern.ch/testDetails.php?test=25539356&build=359962. The DNN with architecture=Standard is to phased out. In this case it would make sense to disable the corresponding test, since the failure is not to be fixed. If this is acceptable, feel free to merge.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/605
https://github.com/root-project/root/pull/611:355,Deployability,Patch,Patch,355,"If a class/struct has virtual method it should also contain a virtual; dtor. This is important if one uses allocator (tcmalloc, jemalloc) with; C++14 sized deallocation. It's needed to provide a proper object size; to deallocation function. We found that jemalloc (dev branch) tends to deadlock if wrong object; size is provided to deallocation function. Patch is just as precaution. Signed-off-by: David Abdurachmanov <david.abdurachmanov@gmail.com>",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/611
https://github.com/root-project/root/pull/614:216,Integrability,wrap,wrapper,216,"It turns out that just calling every function like this; ```; functionname[<template args>](args); ```; doesn't always result in correct code. In a concrete example, PyROOT is currently not able to generate a; valid wrapper for comparing libc++ std::vector<int>::iterator objects.; The wrapper becomes invalid by over-specifying the template arguments; and trying to call:; ```; std::__1::operator==<int *, int *>(a, b); ```. Now we first try to cast such functions to the correct type before; we start doing a lookup, e.g. above example would be:. ```; ((bool (&)(const std::__wrap_iter<int*>&,const std::__wrap_iter<int*>&))std::__1::operator==<int*, int*>)(i,i)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/614
https://github.com/root-project/root/pull/614:286,Integrability,wrap,wrapper,286,"It turns out that just calling every function like this; ```; functionname[<template args>](args); ```; doesn't always result in correct code. In a concrete example, PyROOT is currently not able to generate a; valid wrapper for comparing libc++ std::vector<int>::iterator objects.; The wrapper becomes invalid by over-specifying the template arguments; and trying to call:; ```; std::__1::operator==<int *, int *>(a, b); ```. Now we first try to cast such functions to the correct type before; we start doing a lookup, e.g. above example would be:. ```; ((bool (&)(const std::__wrap_iter<int*>&,const std::__wrap_iter<int*>&))std::__1::operator==<int*, int*>)(i,i)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/614
https://github.com/root-project/root/pull/615:141,Deployability,Patch,Patch,141,It solves problem I recognize for the first time with ROOT7 webgui.; It was wrong representation for container like: std::vector<UserClass>; Patch for roottest will follow very soon.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/615
https://github.com/root-project/root/pull/616:488,Deployability,update,updated,488,"`root macro.C -- arg1 arg2 arg3 ...` will behave as `root macro.C(arg1,arg2,arg3,...)`. Options won't be attached to:; - expressions — `root -e expression`;; - macros, passed with options (with `(` in them, to be precise) — `root macro.C(arg1, arg2)`;; - `.root` files;. If there are several macros without options, the arguments will be passed to the last one (with warning).; If there are no macros, the options after the `--` will be ignored (with warning). No options description was updated yet. Initially my idea was to allow to turn macro function parameters into named options, but @Axel-Naumann asked to leave them positional. But I'm still planning to introduce named arguments/options. Positional arguments as options is not a great improvement over the current way to pass arguments to macros.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/616
https://github.com/root-project/root/pull/618:98,Integrability,depend,dependencies,98,"Fix [this](http://cdash.cern.ch/viewBuildError.php?type=1&buildid=362417) warning:. ```; Scanning dependencies of target testRootFinder; [ 96%] Building CXX object math/mathcore/test/CMakeFiles/testRootFinder.dir/testRootFinder.cxx.o; /.../root/graf3d/gl/src/gl2ps.cxx: In function ‘void gl2psBuildBspTree(GL2PSbsptree*, GL2PSlist*)’:; /.../root/graf3d/gl/src/gl2ps.cxx:1540:19: warning: ‘prim’ may be used uninitialized in this function [-Wmaybe-uninitialized]; GL2PSprimitive *prim, *frontprim = NULL, *backprim = NULL;; ^~~~; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/618
https://github.com/root-project/root/pull/618:121,Testability,test,testRootFinder,121,"Fix [this](http://cdash.cern.ch/viewBuildError.php?type=1&buildid=362417) warning:. ```; Scanning dependencies of target testRootFinder; [ 96%] Building CXX object math/mathcore/test/CMakeFiles/testRootFinder.dir/testRootFinder.cxx.o; /.../root/graf3d/gl/src/gl2ps.cxx: In function ‘void gl2psBuildBspTree(GL2PSbsptree*, GL2PSlist*)’:; /.../root/graf3d/gl/src/gl2ps.cxx:1540:19: warning: ‘prim’ may be used uninitialized in this function [-Wmaybe-uninitialized]; GL2PSprimitive *prim, *frontprim = NULL, *backprim = NULL;; ^~~~; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/618
https://github.com/root-project/root/pull/618:178,Testability,test,test,178,"Fix [this](http://cdash.cern.ch/viewBuildError.php?type=1&buildid=362417) warning:. ```; Scanning dependencies of target testRootFinder; [ 96%] Building CXX object math/mathcore/test/CMakeFiles/testRootFinder.dir/testRootFinder.cxx.o; /.../root/graf3d/gl/src/gl2ps.cxx: In function ‘void gl2psBuildBspTree(GL2PSbsptree*, GL2PSlist*)’:; /.../root/graf3d/gl/src/gl2ps.cxx:1540:19: warning: ‘prim’ may be used uninitialized in this function [-Wmaybe-uninitialized]; GL2PSprimitive *prim, *frontprim = NULL, *backprim = NULL;; ^~~~; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/618
https://github.com/root-project/root/pull/618:194,Testability,test,testRootFinder,194,"Fix [this](http://cdash.cern.ch/viewBuildError.php?type=1&buildid=362417) warning:. ```; Scanning dependencies of target testRootFinder; [ 96%] Building CXX object math/mathcore/test/CMakeFiles/testRootFinder.dir/testRootFinder.cxx.o; /.../root/graf3d/gl/src/gl2ps.cxx: In function ‘void gl2psBuildBspTree(GL2PSbsptree*, GL2PSlist*)’:; /.../root/graf3d/gl/src/gl2ps.cxx:1540:19: warning: ‘prim’ may be used uninitialized in this function [-Wmaybe-uninitialized]; GL2PSprimitive *prim, *frontprim = NULL, *backprim = NULL;; ^~~~; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/618
https://github.com/root-project/root/pull/618:213,Testability,test,testRootFinder,213,"Fix [this](http://cdash.cern.ch/viewBuildError.php?type=1&buildid=362417) warning:. ```; Scanning dependencies of target testRootFinder; [ 96%] Building CXX object math/mathcore/test/CMakeFiles/testRootFinder.dir/testRootFinder.cxx.o; /.../root/graf3d/gl/src/gl2ps.cxx: In function ‘void gl2psBuildBspTree(GL2PSbsptree*, GL2PSlist*)’:; /.../root/graf3d/gl/src/gl2ps.cxx:1540:19: warning: ‘prim’ may be used uninitialized in this function [-Wmaybe-uninitialized]; GL2PSprimitive *prim, *frontprim = NULL, *backprim = NULL;; ^~~~; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/618
https://github.com/root-project/root/pull/620:9,Deployability,upgrade,upgrade,9,The llvm upgrade broke users builds because it double finds the llvm external; project cling. Remove the overspecification. Note that if there is still an issue with the incrementals one needs to delete; CMakeCache.txt file in the main directory.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/620
https://github.com/root-project/root/pull/622:76,Deployability,Update,Update,76,- let create TVirtualPadPainter via the TCanvasImp.; - handling of TCanvas::Update() can be perfromed in TCanvasImp,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/622
https://github.com/root-project/root/pull/623:196,Availability,error,errors,196,"This was lost while migrating to newer LLVM/Clang stack. Otherwise `-std=c++11` is added to compilation lines overriding `-std=c++1z`. Thus Cling/Interpreter ends up in C++11 mode and then we get errors about `std::string_view` only being available in C++17. Compiled on Fedora 26 with `-Dminimal=ON -Dcxx17=ON`. Note, it still fails to build near the end:. ```; FAILED: html/G__Html.cxx lib/libHtml_rdict.pcm lib/libHtml.rootmap; cd /build/build/html && /usr/bin/cmake -E env LD_LIBRARY_PATH=/build/build/lib: ROOTIGNOREPREFIX=1 /build/build/bin/rootcling -rootbuild -f G__Html.cxx -s /build/build/lib/libHtml.so -excludePath /build/root -excludePath /build/build -rml libHtml.so -rmf /build/build/lib/libHtml.rootmap -I/build/root -I/build/root/interpreter/cling/include -I/build/build/include TClassDocOutput.h TDocDirective.h TDocInfo.h TDocOutput.h TDocParser.h THtml.h /build/root/html/inc/LinkDef.h. *** Break *** segmentation violation; ```. Signed-off-by: David Abdurachmanov <davidlt@cern.ch>",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/623
https://github.com/root-project/root/pull/623:239,Availability,avail,available,239,"This was lost while migrating to newer LLVM/Clang stack. Otherwise `-std=c++11` is added to compilation lines overriding `-std=c++1z`. Thus Cling/Interpreter ends up in C++11 mode and then we get errors about `std::string_view` only being available in C++17. Compiled on Fedora 26 with `-Dminimal=ON -Dcxx17=ON`. Note, it still fails to build near the end:. ```; FAILED: html/G__Html.cxx lib/libHtml_rdict.pcm lib/libHtml.rootmap; cd /build/build/html && /usr/bin/cmake -E env LD_LIBRARY_PATH=/build/build/lib: ROOTIGNOREPREFIX=1 /build/build/bin/rootcling -rootbuild -f G__Html.cxx -s /build/build/lib/libHtml.so -excludePath /build/root -excludePath /build/build -rml libHtml.so -rmf /build/build/lib/libHtml.rootmap -I/build/root -I/build/root/interpreter/cling/include -I/build/build/include TClassDocOutput.h TDocDirective.h TDocInfo.h TDocOutput.h TDocParser.h THtml.h /build/root/html/inc/LinkDef.h. *** Break *** segmentation violation; ```. Signed-off-by: David Abdurachmanov <davidlt@cern.ch>",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/623
https://github.com/root-project/root/pull/624:0,Usability,Simpl,Simplifies,0,Simplifies usage for the use-case:. https://root-forum.cern.ch/t/thttpserver-without-items-from-groot-only-explicitly-registered/24640,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/624
https://github.com/root-project/root/pull/625:0,Deployability,Patch,Patches,0,Patches by @marsupial,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/625
https://github.com/root-project/root/pull/628:98,Testability,test,test,98,"Reverts root-project/root#627. Note: do not merge it until the failing 'projectroot.math.mathcore.test.mathcore_testLogLExecPolicy' on some platforms is resolved. @xvallspl, @lmoneta.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/628
https://github.com/root-project/root/pull/629:46,Deployability,upgrade,upgrade,46,Fixes a memory corruption seen after the llvm upgrade. This is still a terrible hack;; it will be replaced by a proper fix in clang::CodeGen (coming up).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/629
https://github.com/root-project/root/pull/633:68,Testability,test,test,68,This PR enables globbing on ROOT_ADD_GTEST. Instead of specifying a test in CMake as ; ```; ROOT_ADD_GTEST(myTest test1.cxx test2.cxx test3.cxx); ```; This PR enables specifying it as:; ```; ROOT_ADD_GTEST(myTest test*.cxx); ```,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/633
https://github.com/root-project/root/pull/633:213,Testability,test,test,213,This PR enables globbing on ROOT_ADD_GTEST. Instead of specifying a test in CMake as ; ```; ROOT_ADD_GTEST(myTest test1.cxx test2.cxx test3.cxx); ```; This PR enables specifying it as:; ```; ROOT_ADD_GTEST(myTest test*.cxx); ```,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/633
https://github.com/root-project/root/pull/634:617,Availability,error,error,617,"when macro function is invoked from command line or by `.x macro.C` metacommand; i.e. `root 'macro.C(#arg3 = 13, arg1 = {42, 43}, arg5 = ""string""#)'` (compiled macros are also supported) or from ROOT REPL: `.x macro.C(#arg3 = 13, arg1 = {42, 43}, arg5 = ""string""#)`.; **N.B.! No space between parentheses and `#`.**; Calling from REPL as `macro(#arg3 = 13, arg1 = {42, 43}, arg5 = ""string""#)` is not supported (yet?). Passing arguments as options (`root macro.C+ --# arg3=13 'arg1={42, 43}' 'arg5=""string""'`), like in #616 ~~will be implemented if this PR merged~~ is implemented. Some implementation decisions, e.g. error reporting, are suboptimal so discussion, suggestions, criticism are welcome.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/634
https://github.com/root-project/root/pull/636:25,Usability,feedback,feedback,25,Here it is...any kind of feedback welcome :),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/636
https://github.com/root-project/root/pull/641:91,Testability,test,tests,91,Add a dummy Travis-CI build file that does nothing but excludes this branch from Travis-CI tests. @vgvassilev,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/641
https://github.com/root-project/root/pull/642:28,Integrability,interface,interface,28,To stay consistent with the interface method.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/642
https://github.com/root-project/root/pull/644:52,Integrability,message,messages,52,"Currently if we compile this test we get ld warning messages like this:. ```; ld: direct access in function ... to global weak symbol. This was likely; caused by different translation units being compiled with different; visibility settings.; ```. This seems to be caused by the fact that visibility=hidden is spreading; from the parent directory to the test directory, even though it should; only land in the src/ directory. As CMAKE_CXX_FLAGS is working on a; per subdirectory basis, we just move the code for handling the source; code to the src/ folder, which should contain the visibility=hidden.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/644
https://github.com/root-project/root/pull/644:89,Security,access,access,89,"Currently if we compile this test we get ld warning messages like this:. ```; ld: direct access in function ... to global weak symbol. This was likely; caused by different translation units being compiled with different; visibility settings.; ```. This seems to be caused by the fact that visibility=hidden is spreading; from the parent directory to the test directory, even though it should; only land in the src/ directory. As CMAKE_CXX_FLAGS is working on a; per subdirectory basis, we just move the code for handling the source; code to the src/ folder, which should contain the visibility=hidden.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/644
https://github.com/root-project/root/pull/644:29,Testability,test,test,29,"Currently if we compile this test we get ld warning messages like this:. ```; ld: direct access in function ... to global weak symbol. This was likely; caused by different translation units being compiled with different; visibility settings.; ```. This seems to be caused by the fact that visibility=hidden is spreading; from the parent directory to the test directory, even though it should; only land in the src/ directory. As CMAKE_CXX_FLAGS is working on a; per subdirectory basis, we just move the code for handling the source; code to the src/ folder, which should contain the visibility=hidden.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/644
https://github.com/root-project/root/pull/644:354,Testability,test,test,354,"Currently if we compile this test we get ld warning messages like this:. ```; ld: direct access in function ... to global weak symbol. This was likely; caused by different translation units being compiled with different; visibility settings.; ```. This seems to be caused by the fact that visibility=hidden is spreading; from the parent directory to the test directory, even though it should; only land in the src/ directory. As CMAKE_CXX_FLAGS is working on a; per subdirectory basis, we just move the code for handling the source; code to the src/ folder, which should contain the visibility=hidden.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/644
https://github.com/root-project/root/pull/645:0,Deployability,Update,Updates,0,Updates DeclCollectorPPAdapter to new clang interface that reports an when every **#undef** encountered.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/645
https://github.com/root-project/root/pull/645:44,Integrability,interface,interface,44,Updates DeclCollectorPPAdapter to new clang interface that reports an when every **#undef** encountered.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/645
https://github.com/root-project/root/pull/652:13,Availability,toler,tolerance,13,"Increase the tolerance for testVector34, as done in 43cae6c9ab93723b880eba4a4c5a20403cd6659a",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/652
https://github.com/root-project/root/pull/655:322,Modifiability,Refactor,Refactor,322,"This PR adds vectorized implementations of several functions in TMath. It is a work in progress, just to receive early feedback. Currently, the following functions are vectorized and tested:. - TMath::Min; - TMath::Gaus; - TMath::BreitWigner; - TMath::CauchyDist; - TMath::LaplaceDist; - TMath::LaplaceDistI. TODO:; - [ ] Refactor the tests to avoid repeated code.; - [ ] Implement remaining functions.; - [ ] Discuss what to do with functions that, i.e., receive an Int_t and return a Double_t. When vectorizing this kind of patterns, one problem arises: the length of integers and double vectors cannot be assumed to be the same. Any comment is more than welcome.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/655
https://github.com/root-project/root/pull/655:344,Safety,avoid,avoid,344,"This PR adds vectorized implementations of several functions in TMath. It is a work in progress, just to receive early feedback. Currently, the following functions are vectorized and tested:. - TMath::Min; - TMath::Gaus; - TMath::BreitWigner; - TMath::CauchyDist; - TMath::LaplaceDist; - TMath::LaplaceDistI. TODO:; - [ ] Refactor the tests to avoid repeated code.; - [ ] Implement remaining functions.; - [ ] Discuss what to do with functions that, i.e., receive an Int_t and return a Double_t. When vectorizing this kind of patterns, one problem arises: the length of integers and double vectors cannot be assumed to be the same. Any comment is more than welcome.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/655
https://github.com/root-project/root/pull/655:183,Testability,test,tested,183,"This PR adds vectorized implementations of several functions in TMath. It is a work in progress, just to receive early feedback. Currently, the following functions are vectorized and tested:. - TMath::Min; - TMath::Gaus; - TMath::BreitWigner; - TMath::CauchyDist; - TMath::LaplaceDist; - TMath::LaplaceDistI. TODO:; - [ ] Refactor the tests to avoid repeated code.; - [ ] Implement remaining functions.; - [ ] Discuss what to do with functions that, i.e., receive an Int_t and return a Double_t. When vectorizing this kind of patterns, one problem arises: the length of integers and double vectors cannot be assumed to be the same. Any comment is more than welcome.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/655
https://github.com/root-project/root/pull/655:335,Testability,test,tests,335,"This PR adds vectorized implementations of several functions in TMath. It is a work in progress, just to receive early feedback. Currently, the following functions are vectorized and tested:. - TMath::Min; - TMath::Gaus; - TMath::BreitWigner; - TMath::CauchyDist; - TMath::LaplaceDist; - TMath::LaplaceDistI. TODO:; - [ ] Refactor the tests to avoid repeated code.; - [ ] Implement remaining functions.; - [ ] Discuss what to do with functions that, i.e., receive an Int_t and return a Double_t. When vectorizing this kind of patterns, one problem arises: the length of integers and double vectors cannot be assumed to be the same. Any comment is more than welcome.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/655
https://github.com/root-project/root/pull/655:119,Usability,feedback,feedback,119,"This PR adds vectorized implementations of several functions in TMath. It is a work in progress, just to receive early feedback. Currently, the following functions are vectorized and tested:. - TMath::Min; - TMath::Gaus; - TMath::BreitWigner; - TMath::CauchyDist; - TMath::LaplaceDist; - TMath::LaplaceDistI. TODO:; - [ ] Refactor the tests to avoid repeated code.; - [ ] Implement remaining functions.; - [ ] Discuss what to do with functions that, i.e., receive an Int_t and return a Double_t. When vectorizing this kind of patterns, one problem arises: the length of integers and double vectors cannot be assumed to be the same. Any comment is more than welcome.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/655
https://github.com/root-project/root/pull/657:286,Deployability,patch,patches,286,"This is an overhaul of the optimize baskets algorithm, primarily done by Ilija Vukotic and extended by David Smith. Goal of this algorithm is to minimize overall memory size when writing and number of baskets in a cluster. Since this work predates ROOT moving to GitHub, it appears the patches primarily are floating around in various people's inbox. This is my attempt to ""capture"" the knowledge and ideas, even if we don't decide to go this direction. @pcanal @smithdh",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/657
https://github.com/root-project/root/pull/657:91,Modifiability,extend,extended,91,"This is an overhaul of the optimize baskets algorithm, primarily done by Ilija Vukotic and extended by David Smith. Goal of this algorithm is to minimize overall memory size when writing and number of baskets in a cluster. Since this work predates ROOT moving to GitHub, it appears the patches primarily are floating around in various people's inbox. This is my attempt to ""capture"" the knowledge and ideas, even if we don't decide to go this direction. @pcanal @smithdh",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/657
https://github.com/root-project/root/pull/657:27,Performance,optimiz,optimize,27,"This is an overhaul of the optimize baskets algorithm, primarily done by Ilija Vukotic and extended by David Smith. Goal of this algorithm is to minimize overall memory size when writing and number of baskets in a cluster. Since this work predates ROOT moving to GitHub, it appears the patches primarily are floating around in various people's inbox. This is my attempt to ""capture"" the knowledge and ideas, even if we don't decide to go this direction. @pcanal @smithdh",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/657
https://github.com/root-project/root/pull/659:283,Availability,Error,Error,283,"Fix for stressGraphics.ref. On RHEL/EPEL 7:; ```; Test 10: TLatex 4 (Greek letters).................................. OK; PDF output................................................ OK; GIF output......................................... 10 FAILED; Result = 13517; Reference = 14622; Error = 1105 (was 1100); JPG output................................................ OK; PNG output................................................ OK; C file result............................................. OK; ```; On Fedora 24:; ```; Test 10: TLatex 4 (Greek letters).................................. OK; PDF output................................................ OK; GIF output......................................... 10 FAILED; Result = 13509; Reference = 14622; Error = 1113 (was 1100); JPG output................................................ OK; PNG output................................................ OK; C file result............................................. OK; ```; The results were off by just 5 and 13 bytes more, respectively, than the current allowed limit. For Fedora 25, 26 and 27 no error was triggered.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/659
https://github.com/root-project/root/pull/659:755,Availability,Error,Error,755,"Fix for stressGraphics.ref. On RHEL/EPEL 7:; ```; Test 10: TLatex 4 (Greek letters).................................. OK; PDF output................................................ OK; GIF output......................................... 10 FAILED; Result = 13517; Reference = 14622; Error = 1105 (was 1100); JPG output................................................ OK; PNG output................................................ OK; C file result............................................. OK; ```; On Fedora 24:; ```; Test 10: TLatex 4 (Greek letters).................................. OK; PDF output................................................ OK; GIF output......................................... 10 FAILED; Result = 13509; Reference = 14622; Error = 1113 (was 1100); JPG output................................................ OK; PNG output................................................ OK; C file result............................................. OK; ```; The results were off by just 5 and 13 bytes more, respectively, than the current allowed limit. For Fedora 25, 26 and 27 no error was triggered.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/659
https://github.com/root-project/root/pull/659:1098,Availability,error,error,1098,"Fix for stressGraphics.ref. On RHEL/EPEL 7:; ```; Test 10: TLatex 4 (Greek letters).................................. OK; PDF output................................................ OK; GIF output......................................... 10 FAILED; Result = 13517; Reference = 14622; Error = 1105 (was 1100); JPG output................................................ OK; PNG output................................................ OK; C file result............................................. OK; ```; On Fedora 24:; ```; Test 10: TLatex 4 (Greek letters).................................. OK; PDF output................................................ OK; GIF output......................................... 10 FAILED; Result = 13509; Reference = 14622; Error = 1113 (was 1100); JPG output................................................ OK; PNG output................................................ OK; C file result............................................. OK; ```; The results were off by just 5 and 13 bytes more, respectively, than the current allowed limit. For Fedora 25, 26 and 27 no error was triggered.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/659
https://github.com/root-project/root/pull/659:50,Testability,Test,Test,50,"Fix for stressGraphics.ref. On RHEL/EPEL 7:; ```; Test 10: TLatex 4 (Greek letters).................................. OK; PDF output................................................ OK; GIF output......................................... 10 FAILED; Result = 13517; Reference = 14622; Error = 1105 (was 1100); JPG output................................................ OK; PNG output................................................ OK; C file result............................................. OK; ```; On Fedora 24:; ```; Test 10: TLatex 4 (Greek letters).................................. OK; PDF output................................................ OK; GIF output......................................... 10 FAILED; Result = 13509; Reference = 14622; Error = 1113 (was 1100); JPG output................................................ OK; PNG output................................................ OK; C file result............................................. OK; ```; The results were off by just 5 and 13 bytes more, respectively, than the current allowed limit. For Fedora 25, 26 and 27 no error was triggered.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/659
https://github.com/root-project/root/pull/659:522,Testability,Test,Test,522,"Fix for stressGraphics.ref. On RHEL/EPEL 7:; ```; Test 10: TLatex 4 (Greek letters).................................. OK; PDF output................................................ OK; GIF output......................................... 10 FAILED; Result = 13517; Reference = 14622; Error = 1105 (was 1100); JPG output................................................ OK; PNG output................................................ OK; C file result............................................. OK; ```; On Fedora 24:; ```; Test 10: TLatex 4 (Greek letters).................................. OK; PDF output................................................ OK; GIF output......................................... 10 FAILED; Result = 13509; Reference = 14622; Error = 1113 (was 1100); JPG output................................................ OK; PNG output................................................ OK; C file result............................................. OK; ```; The results were off by just 5 and 13 bytes more, respectively, than the current allowed limit. For Fedora 25, 26 and 27 no error was triggered.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/659
https://github.com/root-project/root/pull/661:33,Performance,perform,performance,33,This enables to easily get build performance statistics and debug other build; bottlenecks.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/661
https://github.com/root-project/root/pull/661:79,Performance,bottleneck,bottlenecks,79,This enables to easily get build performance statistics and debug other build; bottlenecks.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/661
https://github.com/root-project/root/pull/662:29,Testability,test,test,29,The corresponding regression test is submitted in a PR to roottest.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/662
https://github.com/root-project/root/pull/663:0,Deployability,Update,Update,0,Update zlib to 1.2.8 released in Apr 2013. This is a battle tested; version which is used as a base for QAT and Cloudflare zlib forks. roottest passed with no additional issues. Signed-off-by: David Abdurachmanov <David.Abdurachmanov@cern.ch>,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/663
https://github.com/root-project/root/pull/663:21,Deployability,release,released,21,Update zlib to 1.2.8 released in Apr 2013. This is a battle tested; version which is used as a base for QAT and Cloudflare zlib forks. roottest passed with no additional issues. Signed-off-by: David Abdurachmanov <David.Abdurachmanov@cern.ch>,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/663
https://github.com/root-project/root/pull/663:60,Testability,test,tested,60,Update zlib to 1.2.8 released in Apr 2013. This is a battle tested; version which is used as a base for QAT and Cloudflare zlib forks. roottest passed with no additional issues. Signed-off-by: David Abdurachmanov <David.Abdurachmanov@cern.ch>,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/663
https://github.com/root-project/root/pull/664:140,Deployability,patch,patch,140,"Hello,. it is Vladimir working on the Convolutional Neural Networks in TMVA,; as a part of the Google Summer of Code 2017. This is my first patch for now,; where I have created the entire CNN structure and implemented and tested; the reference architecture. I had some problems with the backpropagation,; so I was not able to test that. For everything else there are tests. In the next patch which I plan to be before the first evaluation starts, I will include a CPU; architecture implementation, and a correct backporpagation.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/664
https://github.com/root-project/root/pull/664:386,Deployability,patch,patch,386,"Hello,. it is Vladimir working on the Convolutional Neural Networks in TMVA,; as a part of the Google Summer of Code 2017. This is my first patch for now,; where I have created the entire CNN structure and implemented and tested; the reference architecture. I had some problems with the backpropagation,; so I was not able to test that. For everything else there are tests. In the next patch which I plan to be before the first evaluation starts, I will include a CPU; architecture implementation, and a correct backporpagation.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/664
https://github.com/root-project/root/pull/664:222,Testability,test,tested,222,"Hello,. it is Vladimir working on the Convolutional Neural Networks in TMVA,; as a part of the Google Summer of Code 2017. This is my first patch for now,; where I have created the entire CNN structure and implemented and tested; the reference architecture. I had some problems with the backpropagation,; so I was not able to test that. For everything else there are tests. In the next patch which I plan to be before the first evaluation starts, I will include a CPU; architecture implementation, and a correct backporpagation.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/664
https://github.com/root-project/root/pull/664:326,Testability,test,test,326,"Hello,. it is Vladimir working on the Convolutional Neural Networks in TMVA,; as a part of the Google Summer of Code 2017. This is my first patch for now,; where I have created the entire CNN structure and implemented and tested; the reference architecture. I had some problems with the backpropagation,; so I was not able to test that. For everything else there are tests. In the next patch which I plan to be before the first evaluation starts, I will include a CPU; architecture implementation, and a correct backporpagation.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/664
https://github.com/root-project/root/pull/664:367,Testability,test,tests,367,"Hello,. it is Vladimir working on the Convolutional Neural Networks in TMVA,; as a part of the Google Summer of Code 2017. This is my first patch for now,; where I have created the entire CNN structure and implemented and tested; the reference architecture. I had some problems with the backpropagation,; so I was not able to test that. For everything else there are tests. In the next patch which I plan to be before the first evaluation starts, I will include a CPU; architecture implementation, and a correct backporpagation.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/664
https://github.com/root-project/root/pull/666:368,Energy Efficiency,green,green,368,"These changes are based on an analysis with VTune that showed that most waiting happened around `TClass::LoadClassInfo()`. Returning early without taking the lock when the information is already loaded yields very significant performance improvements. Images with each thread activity before and after the optimizations are attached. The x-axis represents time, light green means a thread is active, and dark green and brown mean running. Before changes:; ![before](https://user-images.githubusercontent.com/249404/27340439-be419240-55da-11e7-9cba-d881cfdd3104.png). After changes:; ![after](https://user-images.githubusercontent.com/249404/27340446-c57cf018-55da-11e7-9ef2-bbe30b30092f.png)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/666
https://github.com/root-project/root/pull/666:409,Energy Efficiency,green,green,409,"These changes are based on an analysis with VTune that showed that most waiting happened around `TClass::LoadClassInfo()`. Returning early without taking the lock when the information is already loaded yields very significant performance improvements. Images with each thread activity before and after the optimizations are attached. The x-axis represents time, light green means a thread is active, and dark green and brown mean running. Before changes:; ![before](https://user-images.githubusercontent.com/249404/27340439-be419240-55da-11e7-9cba-d881cfdd3104.png). After changes:; ![after](https://user-images.githubusercontent.com/249404/27340446-c57cf018-55da-11e7-9ef2-bbe30b30092f.png)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/666
https://github.com/root-project/root/pull/666:105,Performance,Load,LoadClassInfo,105,"These changes are based on an analysis with VTune that showed that most waiting happened around `TClass::LoadClassInfo()`. Returning early without taking the lock when the information is already loaded yields very significant performance improvements. Images with each thread activity before and after the optimizations are attached. The x-axis represents time, light green means a thread is active, and dark green and brown mean running. Before changes:; ![before](https://user-images.githubusercontent.com/249404/27340439-be419240-55da-11e7-9cba-d881cfdd3104.png). After changes:; ![after](https://user-images.githubusercontent.com/249404/27340446-c57cf018-55da-11e7-9ef2-bbe30b30092f.png)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/666
https://github.com/root-project/root/pull/666:195,Performance,load,loaded,195,"These changes are based on an analysis with VTune that showed that most waiting happened around `TClass::LoadClassInfo()`. Returning early without taking the lock when the information is already loaded yields very significant performance improvements. Images with each thread activity before and after the optimizations are attached. The x-axis represents time, light green means a thread is active, and dark green and brown mean running. Before changes:; ![before](https://user-images.githubusercontent.com/249404/27340439-be419240-55da-11e7-9cba-d881cfdd3104.png). After changes:; ![after](https://user-images.githubusercontent.com/249404/27340446-c57cf018-55da-11e7-9ef2-bbe30b30092f.png)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/666
https://github.com/root-project/root/pull/666:226,Performance,perform,performance,226,"These changes are based on an analysis with VTune that showed that most waiting happened around `TClass::LoadClassInfo()`. Returning early without taking the lock when the information is already loaded yields very significant performance improvements. Images with each thread activity before and after the optimizations are attached. The x-axis represents time, light green means a thread is active, and dark green and brown mean running. Before changes:; ![before](https://user-images.githubusercontent.com/249404/27340439-be419240-55da-11e7-9cba-d881cfdd3104.png). After changes:; ![after](https://user-images.githubusercontent.com/249404/27340446-c57cf018-55da-11e7-9ef2-bbe30b30092f.png)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/666
https://github.com/root-project/root/pull/666:306,Performance,optimiz,optimizations,306,"These changes are based on an analysis with VTune that showed that most waiting happened around `TClass::LoadClassInfo()`. Returning early without taking the lock when the information is already loaded yields very significant performance improvements. Images with each thread activity before and after the optimizations are attached. The x-axis represents time, light green means a thread is active, and dark green and brown mean running. Before changes:; ![before](https://user-images.githubusercontent.com/249404/27340439-be419240-55da-11e7-9cba-d881cfdd3104.png). After changes:; ![after](https://user-images.githubusercontent.com/249404/27340446-c57cf018-55da-11e7-9ef2-bbe30b30092f.png)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/666
https://github.com/root-project/root/pull/667:159,Deployability,patch,patch,159,"We accidentially check and annotate the return type of the function twice for; being a pointer/reference type when we do the ""else"" part of the; wrapper. This patch removes this wrong second check and extends; the tests to check that the cast in both branches of the if/else; is correct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/667
https://github.com/root-project/root/pull/667:145,Integrability,wrap,wrapper,145,"We accidentially check and annotate the return type of the function twice for; being a pointer/reference type when we do the ""else"" part of the; wrapper. This patch removes this wrong second check and extends; the tests to check that the cast in both branches of the if/else; is correct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/667
https://github.com/root-project/root/pull/667:201,Modifiability,extend,extends,201,"We accidentially check and annotate the return type of the function twice for; being a pointer/reference type when we do the ""else"" part of the; wrapper. This patch removes this wrong second check and extends; the tests to check that the cast in both branches of the if/else; is correct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/667
https://github.com/root-project/root/pull/667:214,Testability,test,tests,214,"We accidentially check and annotate the return type of the function twice for; being a pointer/reference type when we do the ""else"" part of the; wrapper. This patch removes this wrong second check and extends; the tests to check that the cast in both branches of the if/else; is correct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/667
https://github.com/root-project/root/pull/676:382,Deployability,Update,Update,382,"The new internal class is TReentrantRWLock access externally via the abstract interface TVirtualRWMutex. The next steps after this is to start using by:; 1) Replace gROOTMutex by a TRWMutexImp; 2) Add R__READLOCKGUARD; 3) Add a TListWithRWLock and THashListWithRWLock; 4) Use those in TROOT; 5) Remove current external locks for those ROOT lists (in particular the ListOfFiles); 6) Update all RecursiveRemove implementation (in particular TCling::RecursiveRemove, without update it destroys scalability) to make use of the Read/Write lock.; 7) Introduce scalability test on RecursiveRemove",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/676
https://github.com/root-project/root/pull/676:472,Deployability,update,update,472,"The new internal class is TReentrantRWLock access externally via the abstract interface TVirtualRWMutex. The next steps after this is to start using by:; 1) Replace gROOTMutex by a TRWMutexImp; 2) Add R__READLOCKGUARD; 3) Add a TListWithRWLock and THashListWithRWLock; 4) Use those in TROOT; 5) Remove current external locks for those ROOT lists (in particular the ListOfFiles); 6) Update all RecursiveRemove implementation (in particular TCling::RecursiveRemove, without update it destroys scalability) to make use of the Read/Write lock.; 7) Introduce scalability test on RecursiveRemove",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/676
https://github.com/root-project/root/pull/676:78,Integrability,interface,interface,78,"The new internal class is TReentrantRWLock access externally via the abstract interface TVirtualRWMutex. The next steps after this is to start using by:; 1) Replace gROOTMutex by a TRWMutexImp; 2) Add R__READLOCKGUARD; 3) Add a TListWithRWLock and THashListWithRWLock; 4) Use those in TROOT; 5) Remove current external locks for those ROOT lists (in particular the ListOfFiles); 6) Update all RecursiveRemove implementation (in particular TCling::RecursiveRemove, without update it destroys scalability) to make use of the Read/Write lock.; 7) Introduce scalability test on RecursiveRemove",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/676
https://github.com/root-project/root/pull/676:491,Performance,scalab,scalability,491,"The new internal class is TReentrantRWLock access externally via the abstract interface TVirtualRWMutex. The next steps after this is to start using by:; 1) Replace gROOTMutex by a TRWMutexImp; 2) Add R__READLOCKGUARD; 3) Add a TListWithRWLock and THashListWithRWLock; 4) Use those in TROOT; 5) Remove current external locks for those ROOT lists (in particular the ListOfFiles); 6) Update all RecursiveRemove implementation (in particular TCling::RecursiveRemove, without update it destroys scalability) to make use of the Read/Write lock.; 7) Introduce scalability test on RecursiveRemove",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/676
https://github.com/root-project/root/pull/676:554,Performance,scalab,scalability,554,"The new internal class is TReentrantRWLock access externally via the abstract interface TVirtualRWMutex. The next steps after this is to start using by:; 1) Replace gROOTMutex by a TRWMutexImp; 2) Add R__READLOCKGUARD; 3) Add a TListWithRWLock and THashListWithRWLock; 4) Use those in TROOT; 5) Remove current external locks for those ROOT lists (in particular the ListOfFiles); 6) Update all RecursiveRemove implementation (in particular TCling::RecursiveRemove, without update it destroys scalability) to make use of the Read/Write lock.; 7) Introduce scalability test on RecursiveRemove",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/676
https://github.com/root-project/root/pull/676:43,Security,access,access,43,"The new internal class is TReentrantRWLock access externally via the abstract interface TVirtualRWMutex. The next steps after this is to start using by:; 1) Replace gROOTMutex by a TRWMutexImp; 2) Add R__READLOCKGUARD; 3) Add a TListWithRWLock and THashListWithRWLock; 4) Use those in TROOT; 5) Remove current external locks for those ROOT lists (in particular the ListOfFiles); 6) Update all RecursiveRemove implementation (in particular TCling::RecursiveRemove, without update it destroys scalability) to make use of the Read/Write lock.; 7) Introduce scalability test on RecursiveRemove",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/676
https://github.com/root-project/root/pull/676:566,Testability,test,test,566,"The new internal class is TReentrantRWLock access externally via the abstract interface TVirtualRWMutex. The next steps after this is to start using by:; 1) Replace gROOTMutex by a TRWMutexImp; 2) Add R__READLOCKGUARD; 3) Add a TListWithRWLock and THashListWithRWLock; 4) Use those in TROOT; 5) Remove current external locks for those ROOT lists (in particular the ListOfFiles); 6) Update all RecursiveRemove implementation (in particular TCling::RecursiveRemove, without update it destroys scalability) to make use of the Read/Write lock.; 7) Introduce scalability test on RecursiveRemove",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/676
https://github.com/root-project/root/pull/677:95,Availability,redundant,redundant,95,"The macro should be already set via `${VecCore_DEFINITIONS}`, so setting it unconditionally is redundant and leads to many warnings. However, the build system is not quite ready for setting this only via; `${VecCore_DEFINITIONS}`, so we need to conditionally set it if dependencies are satisfied and it is not set.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/677
https://github.com/root-project/root/pull/677:269,Integrability,depend,dependencies,269,"The macro should be already set via `${VecCore_DEFINITIONS}`, so setting it unconditionally is redundant and leads to many warnings. However, the build system is not quite ready for setting this only via; `${VecCore_DEFINITIONS}`, so we need to conditionally set it if dependencies are satisfied and it is not set.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/677
https://github.com/root-project/root/pull/677:95,Safety,redund,redundant,95,"The macro should be already set via `${VecCore_DEFINITIONS}`, so setting it unconditionally is redundant and leads to many warnings. However, the build system is not quite ready for setting this only via; `${VecCore_DEFINITIONS}`, so we need to conditionally set it if dependencies are satisfied and it is not set.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/677
https://github.com/root-project/root/pull/679:76,Availability,error,errors,76,"Can we enable diagnostics for value printing, to be more helpful in case of errors?",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/679
https://github.com/root-project/root/pull/681:603,Availability,avail,available,603,"Hello, Everyone!. My name is Sergey and I am a GSOC student this year. The aim of my project is to implement Multi-Target Regression algorithms to TMVA and to extend the capability of existing ones to handle multiple targets. In this commit I have modified the DecisionTree, allowing it to solve regression problems for multiple targets. The idea was inspired by how it is done in Clus package. (The variance of each subset resulting from a split is simply summed up from variances for each target). I have also extended the capability of BDT method to handle multiple targets (The only boosting method available for it right now is Bagging, but I am planning to implement Multi-target gradient descent based on the paper Boosted multi-task learning (2010) by Olivier Chapelle; Pannagadatta Shivaswamy.; ·",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/681
https://github.com/root-project/root/pull/681:159,Modifiability,extend,extend,159,"Hello, Everyone!. My name is Sergey and I am a GSOC student this year. The aim of my project is to implement Multi-Target Regression algorithms to TMVA and to extend the capability of existing ones to handle multiple targets. In this commit I have modified the DecisionTree, allowing it to solve regression problems for multiple targets. The idea was inspired by how it is done in Clus package. (The variance of each subset resulting from a split is simply summed up from variances for each target). I have also extended the capability of BDT method to handle multiple targets (The only boosting method available for it right now is Bagging, but I am planning to implement Multi-target gradient descent based on the paper Boosted multi-task learning (2010) by Olivier Chapelle; Pannagadatta Shivaswamy.; ·",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/681
https://github.com/root-project/root/pull/681:512,Modifiability,extend,extended,512,"Hello, Everyone!. My name is Sergey and I am a GSOC student this year. The aim of my project is to implement Multi-Target Regression algorithms to TMVA and to extend the capability of existing ones to handle multiple targets. In this commit I have modified the DecisionTree, allowing it to solve regression problems for multiple targets. The idea was inspired by how it is done in Clus package. (The variance of each subset resulting from a split is simply summed up from variances for each target). I have also extended the capability of BDT method to handle multiple targets (The only boosting method available for it right now is Bagging, but I am planning to implement Multi-target gradient descent based on the paper Boosted multi-task learning (2010) by Olivier Chapelle; Pannagadatta Shivaswamy.; ·",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/681
https://github.com/root-project/root/pull/681:450,Usability,simpl,simply,450,"Hello, Everyone!. My name is Sergey and I am a GSOC student this year. The aim of my project is to implement Multi-Target Regression algorithms to TMVA and to extend the capability of existing ones to handle multiple targets. In this commit I have modified the DecisionTree, allowing it to solve regression problems for multiple targets. The idea was inspired by how it is done in Clus package. (The variance of each subset resulting from a split is simply summed up from variances for each target). I have also extended the capability of BDT method to handle multiple targets (The only boosting method available for it right now is Bagging, but I am planning to implement Multi-target gradient descent based on the paper Boosted multi-task learning (2010) by Olivier Chapelle; Pannagadatta Shivaswamy.; ·",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/681
https://github.com/root-project/root/pull/681:741,Usability,learn,learning,741,"Hello, Everyone!. My name is Sergey and I am a GSOC student this year. The aim of my project is to implement Multi-Target Regression algorithms to TMVA and to extend the capability of existing ones to handle multiple targets. In this commit I have modified the DecisionTree, allowing it to solve regression problems for multiple targets. The idea was inspired by how it is done in Clus package. (The variance of each subset resulting from a split is simply summed up from variances for each target). I have also extended the capability of BDT method to handle multiple targets (The only boosting method available for it right now is Bagging, but I am planning to implement Multi-target gradient descent based on the paper Boosted multi-task learning (2010) by Olivier Chapelle; Pannagadatta Shivaswamy.; ·",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/681
https://github.com/root-project/root/pull/683:25,Deployability,patch,patch,25,"…lized decls"". clang.git patch id: ffc388b",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/683
https://github.com/root-project/root/pull/684:72,Deployability,patch,patch,72,This reverts commit 5f7fd3aa6007c04e9d761816fea6d9b3146bd79a. clang.git patch id: 4412120,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/684
https://github.com/root-project/root/pull/685:190,Integrability,wrap,wrapper,190,"Hi everyone!. I am a GSoC student working on introducing Recurrent Neural Networks in TMVA. This is the first part of commits which introduces the `RNNLayer` class as well as `RecurrentNet` wrapper along with their respective methods (Forward, Backward etc). I will soon add tests for different functions.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/685
https://github.com/root-project/root/pull/685:275,Testability,test,tests,275,"Hi everyone!. I am a GSoC student working on introducing Recurrent Neural Networks in TMVA. This is the first part of commits which introduces the `RNNLayer` class as well as `RecurrentNet` wrapper along with their respective methods (Forward, Backward etc). I will soon add tests for different functions.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/685
https://github.com/root-project/root/pull/686:224,Deployability,patch,patch,224,"Hello everyone!; This is Akshay Vashistha, a GSOC student working on AutoEncoders. Currently I have implemented the Denoise Layer and working on stacking up the layers. After this, I will write some tests for same.; My next patch will have a properly implemented stacked layer architecture and some tests for verifying the correctness.; Thanks",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/686
https://github.com/root-project/root/pull/686:161,Modifiability,layers,layers,161,"Hello everyone!; This is Akshay Vashistha, a GSOC student working on AutoEncoders. Currently I have implemented the Denoise Layer and working on stacking up the layers. After this, I will write some tests for same.; My next patch will have a properly implemented stacked layer architecture and some tests for verifying the correctness.; Thanks",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/686
https://github.com/root-project/root/pull/686:199,Testability,test,tests,199,"Hello everyone!; This is Akshay Vashistha, a GSOC student working on AutoEncoders. Currently I have implemented the Denoise Layer and working on stacking up the layers. After this, I will write some tests for same.; My next patch will have a properly implemented stacked layer architecture and some tests for verifying the correctness.; Thanks",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/686
https://github.com/root-project/root/pull/686:299,Testability,test,tests,299,"Hello everyone!; This is Akshay Vashistha, a GSOC student working on AutoEncoders. Currently I have implemented the Denoise Layer and working on stacking up the layers. After this, I will write some tests for same.; My next patch will have a properly implemented stacked layer architecture and some tests for verifying the correctness.; Thanks",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/686
https://github.com/root-project/root/pull/688:170,Modifiability,config,configure,170,"This enables us to write performance benchmarks for specific ROOT functional points. Some of the advantages:; * We can split performance tests from unit tests;; * We can configure the benchmarks in a uniform way, specifying classes of benchmarks along with their running parameters (such as iterations);; * We can calculate asymptotic complexity (Big O) of the benchmarked items;; * Multithreading is a first class citizen;; * We can fine tune optimization levels (preventing some code to be optimized away);; * Rich reporting options;; * Possibility for calculating statistical performance deviations;; * More can be found [here](https://github.com/google/benchmark). This would enable finer grained benchmarking of vectorized code.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/688
https://github.com/root-project/root/pull/688:25,Performance,perform,performance,25,"This enables us to write performance benchmarks for specific ROOT functional points. Some of the advantages:; * We can split performance tests from unit tests;; * We can configure the benchmarks in a uniform way, specifying classes of benchmarks along with their running parameters (such as iterations);; * We can calculate asymptotic complexity (Big O) of the benchmarked items;; * Multithreading is a first class citizen;; * We can fine tune optimization levels (preventing some code to be optimized away);; * Rich reporting options;; * Possibility for calculating statistical performance deviations;; * More can be found [here](https://github.com/google/benchmark). This would enable finer grained benchmarking of vectorized code.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/688
https://github.com/root-project/root/pull/688:125,Performance,perform,performance,125,"This enables us to write performance benchmarks for specific ROOT functional points. Some of the advantages:; * We can split performance tests from unit tests;; * We can configure the benchmarks in a uniform way, specifying classes of benchmarks along with their running parameters (such as iterations);; * We can calculate asymptotic complexity (Big O) of the benchmarked items;; * Multithreading is a first class citizen;; * We can fine tune optimization levels (preventing some code to be optimized away);; * Rich reporting options;; * Possibility for calculating statistical performance deviations;; * More can be found [here](https://github.com/google/benchmark). This would enable finer grained benchmarking of vectorized code.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/688
https://github.com/root-project/root/pull/688:439,Performance,tune,tune,439,"This enables us to write performance benchmarks for specific ROOT functional points. Some of the advantages:; * We can split performance tests from unit tests;; * We can configure the benchmarks in a uniform way, specifying classes of benchmarks along with their running parameters (such as iterations);; * We can calculate asymptotic complexity (Big O) of the benchmarked items;; * Multithreading is a first class citizen;; * We can fine tune optimization levels (preventing some code to be optimized away);; * Rich reporting options;; * Possibility for calculating statistical performance deviations;; * More can be found [here](https://github.com/google/benchmark). This would enable finer grained benchmarking of vectorized code.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/688
https://github.com/root-project/root/pull/688:444,Performance,optimiz,optimization,444,"This enables us to write performance benchmarks for specific ROOT functional points. Some of the advantages:; * We can split performance tests from unit tests;; * We can configure the benchmarks in a uniform way, specifying classes of benchmarks along with their running parameters (such as iterations);; * We can calculate asymptotic complexity (Big O) of the benchmarked items;; * Multithreading is a first class citizen;; * We can fine tune optimization levels (preventing some code to be optimized away);; * Rich reporting options;; * Possibility for calculating statistical performance deviations;; * More can be found [here](https://github.com/google/benchmark). This would enable finer grained benchmarking of vectorized code.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/688
https://github.com/root-project/root/pull/688:492,Performance,optimiz,optimized,492,"This enables us to write performance benchmarks for specific ROOT functional points. Some of the advantages:; * We can split performance tests from unit tests;; * We can configure the benchmarks in a uniform way, specifying classes of benchmarks along with their running parameters (such as iterations);; * We can calculate asymptotic complexity (Big O) of the benchmarked items;; * Multithreading is a first class citizen;; * We can fine tune optimization levels (preventing some code to be optimized away);; * Rich reporting options;; * Possibility for calculating statistical performance deviations;; * More can be found [here](https://github.com/google/benchmark). This would enable finer grained benchmarking of vectorized code.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/688
https://github.com/root-project/root/pull/688:579,Performance,perform,performance,579,"This enables us to write performance benchmarks for specific ROOT functional points. Some of the advantages:; * We can split performance tests from unit tests;; * We can configure the benchmarks in a uniform way, specifying classes of benchmarks along with their running parameters (such as iterations);; * We can calculate asymptotic complexity (Big O) of the benchmarked items;; * Multithreading is a first class citizen;; * We can fine tune optimization levels (preventing some code to be optimized away);; * Rich reporting options;; * Possibility for calculating statistical performance deviations;; * More can be found [here](https://github.com/google/benchmark). This would enable finer grained benchmarking of vectorized code.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/688
https://github.com/root-project/root/pull/688:37,Testability,benchmark,benchmarks,37,"This enables us to write performance benchmarks for specific ROOT functional points. Some of the advantages:; * We can split performance tests from unit tests;; * We can configure the benchmarks in a uniform way, specifying classes of benchmarks along with their running parameters (such as iterations);; * We can calculate asymptotic complexity (Big O) of the benchmarked items;; * Multithreading is a first class citizen;; * We can fine tune optimization levels (preventing some code to be optimized away);; * Rich reporting options;; * Possibility for calculating statistical performance deviations;; * More can be found [here](https://github.com/google/benchmark). This would enable finer grained benchmarking of vectorized code.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/688
https://github.com/root-project/root/pull/688:137,Testability,test,tests,137,"This enables us to write performance benchmarks for specific ROOT functional points. Some of the advantages:; * We can split performance tests from unit tests;; * We can configure the benchmarks in a uniform way, specifying classes of benchmarks along with their running parameters (such as iterations);; * We can calculate asymptotic complexity (Big O) of the benchmarked items;; * Multithreading is a first class citizen;; * We can fine tune optimization levels (preventing some code to be optimized away);; * Rich reporting options;; * Possibility for calculating statistical performance deviations;; * More can be found [here](https://github.com/google/benchmark). This would enable finer grained benchmarking of vectorized code.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/688
https://github.com/root-project/root/pull/688:153,Testability,test,tests,153,"This enables us to write performance benchmarks for specific ROOT functional points. Some of the advantages:; * We can split performance tests from unit tests;; * We can configure the benchmarks in a uniform way, specifying classes of benchmarks along with their running parameters (such as iterations);; * We can calculate asymptotic complexity (Big O) of the benchmarked items;; * Multithreading is a first class citizen;; * We can fine tune optimization levels (preventing some code to be optimized away);; * Rich reporting options;; * Possibility for calculating statistical performance deviations;; * More can be found [here](https://github.com/google/benchmark). This would enable finer grained benchmarking of vectorized code.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/688
https://github.com/root-project/root/pull/688:184,Testability,benchmark,benchmarks,184,"This enables us to write performance benchmarks for specific ROOT functional points. Some of the advantages:; * We can split performance tests from unit tests;; * We can configure the benchmarks in a uniform way, specifying classes of benchmarks along with their running parameters (such as iterations);; * We can calculate asymptotic complexity (Big O) of the benchmarked items;; * Multithreading is a first class citizen;; * We can fine tune optimization levels (preventing some code to be optimized away);; * Rich reporting options;; * Possibility for calculating statistical performance deviations;; * More can be found [here](https://github.com/google/benchmark). This would enable finer grained benchmarking of vectorized code.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/688
https://github.com/root-project/root/pull/688:235,Testability,benchmark,benchmarks,235,"This enables us to write performance benchmarks for specific ROOT functional points. Some of the advantages:; * We can split performance tests from unit tests;; * We can configure the benchmarks in a uniform way, specifying classes of benchmarks along with their running parameters (such as iterations);; * We can calculate asymptotic complexity (Big O) of the benchmarked items;; * Multithreading is a first class citizen;; * We can fine tune optimization levels (preventing some code to be optimized away);; * Rich reporting options;; * Possibility for calculating statistical performance deviations;; * More can be found [here](https://github.com/google/benchmark). This would enable finer grained benchmarking of vectorized code.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/688
https://github.com/root-project/root/pull/688:361,Testability,benchmark,benchmarked,361,"This enables us to write performance benchmarks for specific ROOT functional points. Some of the advantages:; * We can split performance tests from unit tests;; * We can configure the benchmarks in a uniform way, specifying classes of benchmarks along with their running parameters (such as iterations);; * We can calculate asymptotic complexity (Big O) of the benchmarked items;; * Multithreading is a first class citizen;; * We can fine tune optimization levels (preventing some code to be optimized away);; * Rich reporting options;; * Possibility for calculating statistical performance deviations;; * More can be found [here](https://github.com/google/benchmark). This would enable finer grained benchmarking of vectorized code.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/688
https://github.com/root-project/root/pull/688:657,Testability,benchmark,benchmark,657,"This enables us to write performance benchmarks for specific ROOT functional points. Some of the advantages:; * We can split performance tests from unit tests;; * We can configure the benchmarks in a uniform way, specifying classes of benchmarks along with their running parameters (such as iterations);; * We can calculate asymptotic complexity (Big O) of the benchmarked items;; * Multithreading is a first class citizen;; * We can fine tune optimization levels (preventing some code to be optimized away);; * Rich reporting options;; * Possibility for calculating statistical performance deviations;; * More can be found [here](https://github.com/google/benchmark). This would enable finer grained benchmarking of vectorized code.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/688
https://github.com/root-project/root/pull/688:701,Testability,benchmark,benchmarking,701,"This enables us to write performance benchmarks for specific ROOT functional points. Some of the advantages:; * We can split performance tests from unit tests;; * We can configure the benchmarks in a uniform way, specifying classes of benchmarks along with their running parameters (such as iterations);; * We can calculate asymptotic complexity (Big O) of the benchmarked items;; * Multithreading is a first class citizen;; * We can fine tune optimization levels (preventing some code to be optimized away);; * Rich reporting options;; * Possibility for calculating statistical performance deviations;; * More can be found [here](https://github.com/google/benchmark). This would enable finer grained benchmarking of vectorized code.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/688
https://github.com/root-project/root/pull/691:35,Testability,log,logic,35,Various clean-ups to the even loop logic of TDF,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/691
https://github.com/root-project/root/pull/692:37,Modifiability,refactor,refactored,37,"The logic of `SnapshotImpl` has been refactored to move the single-thread initialization and execution inside the `SnapshotHelper` class, and the multi-thread in `SnapshotHelperMT`. This code simplification also puts `Snapshot` in line with other actions, moving most of the logic inside `TDFActionHelpers.hxx`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/692
https://github.com/root-project/root/pull/692:146,Performance,multi-thread,multi-thread,146,"The logic of `SnapshotImpl` has been refactored to move the single-thread initialization and execution inside the `SnapshotHelper` class, and the multi-thread in `SnapshotHelperMT`. This code simplification also puts `Snapshot` in line with other actions, moving most of the logic inside `TDFActionHelpers.hxx`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/692
https://github.com/root-project/root/pull/692:4,Testability,log,logic,4,"The logic of `SnapshotImpl` has been refactored to move the single-thread initialization and execution inside the `SnapshotHelper` class, and the multi-thread in `SnapshotHelperMT`. This code simplification also puts `Snapshot` in line with other actions, moving most of the logic inside `TDFActionHelpers.hxx`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/692
https://github.com/root-project/root/pull/692:275,Testability,log,logic,275,"The logic of `SnapshotImpl` has been refactored to move the single-thread initialization and execution inside the `SnapshotHelper` class, and the multi-thread in `SnapshotHelperMT`. This code simplification also puts `Snapshot` in line with other actions, moving most of the logic inside `TDFActionHelpers.hxx`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/692
https://github.com/root-project/root/pull/692:192,Usability,simpl,simplification,192,"The logic of `SnapshotImpl` has been refactored to move the single-thread initialization and execution inside the `SnapshotHelper` class, and the multi-thread in `SnapshotHelperMT`. This code simplification also puts `Snapshot` in line with other actions, moving most of the logic inside `TDFActionHelpers.hxx`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/692
https://github.com/root-project/root/pull/693:190,Integrability,wrap,wrapper,190,"Hi everyone!. I am a GSoC student working on introducing Recurrent Neural Networks in TMVA. This is the first part of commits which introduces the `RNNLayer` class as well as `RecurrentNet` wrapper along with their respective methods (Forward, Backward etc). I will soon add tests for different functions.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/693
https://github.com/root-project/root/pull/693:275,Testability,test,tests,275,"Hi everyone!. I am a GSoC student working on introducing Recurrent Neural Networks in TMVA. This is the first part of commits which introduces the `RNNLayer` class as well as `RecurrentNet` wrapper along with their respective methods (Forward, Backward etc). I will soon add tests for different functions.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/693
https://github.com/root-project/root/pull/696:114,Deployability,patch,patch,114,"Hello everyone,; This is Akshay Vashistha, a GSOC student working on Autoencoder implementation. Here is my first patch. Currently it has a denoise layer and finetune layer for stacking.; In my next patch I will add verified tests.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/696
https://github.com/root-project/root/pull/696:199,Deployability,patch,patch,199,"Hello everyone,; This is Akshay Vashistha, a GSOC student working on Autoencoder implementation. Here is my first patch. Currently it has a denoise layer and finetune layer for stacking.; In my next patch I will add verified tests.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/696
https://github.com/root-project/root/pull/696:225,Testability,test,tests,225,"Hello everyone,; This is Akshay Vashistha, a GSOC student working on Autoencoder implementation. Here is my first patch. Currently it has a denoise layer and finetune layer for stacking.; In my next patch I will add verified tests.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/696
https://github.com/root-project/root/pull/697:99,Deployability,patch,patch,99,"ROOT version of https://github.com/root-project/cling/pull/158 (but NOTE different directory; this patch needs to be applied to cling, too)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/697
https://github.com/root-project/root/pull/700:71,Deployability,install,install,71,"To use C++ modules during runtime we need to generate a modulemap; and install it alongside the ROOT headers. However, right now; we need to turn on cxxmodules to generate a modulemap, which would; force experiments to fulfill all the depndencies that cxxmodules; brings with it (that is, a modern clang that can build ROOT with C++; modules). This patch untangles the modulemap generation from the cxxmodules; option, so that we always generate a modulemap even when cxxmodules; is turned off. We now also install the modulemap alongside; the ROOT headers. No functional change for normal ROOT expected here, as the modulemap; will just be ignored without having runtime C++ modules enabled.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/700
https://github.com/root-project/root/pull/700:349,Deployability,patch,patch,349,"To use C++ modules during runtime we need to generate a modulemap; and install it alongside the ROOT headers. However, right now; we need to turn on cxxmodules to generate a modulemap, which would; force experiments to fulfill all the depndencies that cxxmodules; brings with it (that is, a modern clang that can build ROOT with C++; modules). This patch untangles the modulemap generation from the cxxmodules; option, so that we always generate a modulemap even when cxxmodules; is turned off. We now also install the modulemap alongside; the ROOT headers. No functional change for normal ROOT expected here, as the modulemap; will just be ignored without having runtime C++ modules enabled.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/700
https://github.com/root-project/root/pull/700:507,Deployability,install,install,507,"To use C++ modules during runtime we need to generate a modulemap; and install it alongside the ROOT headers. However, right now; we need to turn on cxxmodules to generate a modulemap, which would; force experiments to fulfill all the depndencies that cxxmodules; brings with it (that is, a modern clang that can build ROOT with C++; modules). This patch untangles the modulemap generation from the cxxmodules; option, so that we always generate a modulemap even when cxxmodules; is turned off. We now also install the modulemap alongside; the ROOT headers. No functional change for normal ROOT expected here, as the modulemap; will just be ignored without having runtime C++ modules enabled.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/700
https://github.com/root-project/root/pull/703:89,Testability,test,tests,89,The PR changes TDF's source code as well as the tutorials. A related PR that changes the tests is open in roottest. I also added an extra commit with a minor fix to TDF's user guide.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/703
https://github.com/root-project/root/pull/703:176,Usability,guid,guide,176,The PR changes TDF's source code as well as the tutorials. A related PR that changes the tests is open in roottest. I also added an extra commit with a minor fix to TDF's user guide.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/703
https://github.com/root-project/root/pull/704:37,Availability,error,error,37,"Without this, I am getting a compile error because `std::function` is undefined.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/704
https://github.com/root-project/root/pull/705:437,Availability,error,error,437,"[EDIT]: 2017-07-20 dropped commit (6953483). See the commit messages for detailed descriptions of the changes. In essence, when comparing some data with the KolmogorovTest an infinite loop was triggered. (bba95dd) We want to get an approximate solution to the test despite there being some bins with neg. content; (06024c8) To prevent the infinite loop in other cases, calling FillRandom with a histogram with negative content is now an error.; (6953483) The caching inside GetRandom can violate an invariant of the function. (Always return NaN when there is a bin with neg. content in the source histogram). [EDIT] Removed after discussion with Lorenzo. The recomputation of the integral here was deemed too expensive as the function is intended to be called in tight loops. Since these changes might have far reaching effects I am up for discussion whether any commits should be dropped. A reproducer in can be found [here](https://gist.github.com/ashlaban/05552ab5f5a7aa05e9c9b73229b2dba4).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/705
https://github.com/root-project/root/pull/705:60,Integrability,message,messages,60,"[EDIT]: 2017-07-20 dropped commit (6953483). See the commit messages for detailed descriptions of the changes. In essence, when comparing some data with the KolmogorovTest an infinite loop was triggered. (bba95dd) We want to get an approximate solution to the test despite there being some bins with neg. content; (06024c8) To prevent the infinite loop in other cases, calling FillRandom with a histogram with negative content is now an error.; (6953483) The caching inside GetRandom can violate an invariant of the function. (Always return NaN when there is a bin with neg. content in the source histogram). [EDIT] Removed after discussion with Lorenzo. The recomputation of the integral here was deemed too expensive as the function is intended to be called in tight loops. Since these changes might have far reaching effects I am up for discussion whether any commits should be dropped. A reproducer in can be found [here](https://gist.github.com/ashlaban/05552ab5f5a7aa05e9c9b73229b2dba4).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/705
https://github.com/root-project/root/pull/705:260,Testability,test,test,260,"[EDIT]: 2017-07-20 dropped commit (6953483). See the commit messages for detailed descriptions of the changes. In essence, when comparing some data with the KolmogorovTest an infinite loop was triggered. (bba95dd) We want to get an approximate solution to the test despite there being some bins with neg. content; (06024c8) To prevent the infinite loop in other cases, calling FillRandom with a histogram with negative content is now an error.; (6953483) The caching inside GetRandom can violate an invariant of the function. (Always return NaN when there is a bin with neg. content in the source histogram). [EDIT] Removed after discussion with Lorenzo. The recomputation of the integral here was deemed too expensive as the function is intended to be called in tight loops. Since these changes might have far reaching effects I am up for discussion whether any commits should be dropped. A reproducer in can be found [here](https://gist.github.com/ashlaban/05552ab5f5a7aa05e9c9b73229b2dba4).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/705
https://github.com/root-project/root/pull/707:0,Deployability,Update,Updated,0,Updated EvaluateAllMethods to output confusion matrix and 1vsRest data for both test data and training data for easier overtraining check. The TMVAMultiClassGui now supports generating 1v1 roc curves. Fixes bug where generated multiclass roc curves were not save to disk when created. Adds correctness tests for the ROCCurve class.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/707
https://github.com/root-project/root/pull/707:80,Testability,test,test,80,Updated EvaluateAllMethods to output confusion matrix and 1vsRest data for both test data and training data for easier overtraining check. The TMVAMultiClassGui now supports generating 1v1 roc curves. Fixes bug where generated multiclass roc curves were not save to disk when created. Adds correctness tests for the ROCCurve class.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/707
https://github.com/root-project/root/pull/707:302,Testability,test,tests,302,Updated EvaluateAllMethods to output confusion matrix and 1vsRest data for both test data and training data for easier overtraining check. The TMVAMultiClassGui now supports generating 1v1 roc curves. Fixes bug where generated multiclass roc curves were not save to disk when created. Adds correctness tests for the ROCCurve class.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/707
https://github.com/root-project/root/pull/708:114,Deployability,patch,patch,114,"Hello everyone,; This is Akshay Vashistha, a GSOC student working on AutoEncoder implementation. Here is my first patch. It has a base class layer for autoencoders, a denoise layer and StackedNets. The denoise layer can corrupt, encode and reconstruct the input. The stacked layer has both Pretraining and finetuning steps. ; Currently working on writing tests to check the correctness of code. In my next patch I will add some verified tests with required changes. Thank You.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/708
https://github.com/root-project/root/pull/708:406,Deployability,patch,patch,406,"Hello everyone,; This is Akshay Vashistha, a GSOC student working on AutoEncoder implementation. Here is my first patch. It has a base class layer for autoencoders, a denoise layer and StackedNets. The denoise layer can corrupt, encode and reconstruct the input. The stacked layer has both Pretraining and finetuning steps. ; Currently working on writing tests to check the correctness of code. In my next patch I will add some verified tests with required changes. Thank You.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/708
https://github.com/root-project/root/pull/708:355,Testability,test,tests,355,"Hello everyone,; This is Akshay Vashistha, a GSOC student working on AutoEncoder implementation. Here is my first patch. It has a base class layer for autoencoders, a denoise layer and StackedNets. The denoise layer can corrupt, encode and reconstruct the input. The stacked layer has both Pretraining and finetuning steps. ; Currently working on writing tests to check the correctness of code. In my next patch I will add some verified tests with required changes. Thank You.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/708
https://github.com/root-project/root/pull/708:437,Testability,test,tests,437,"Hello everyone,; This is Akshay Vashistha, a GSOC student working on AutoEncoder implementation. Here is my first patch. It has a base class layer for autoencoders, a denoise layer and StackedNets. The denoise layer can corrupt, encode and reconstruct the input. The stacked layer has both Pretraining and finetuning steps. ; Currently working on writing tests to check the correctness of code. In my next patch I will add some verified tests with required changes. Thank You.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/708
https://github.com/root-project/root/pull/709:359,Availability,avail,available,359,This branch contains modifications to address some performance issues identifies in JIRA issue [ROOT-8871](https://sft.its.cern.ch/jira/browse/ROOT-8871). The main changes are:; * Make `TClass::LoadClassInfo()` private and avoid locking the interpreter unnecessarily; * Avoid interpreter lock in `TClass::GetListOfBases()` and return existing list if already available; * Reduce scope of interpreter locks in several places where the lock is taken before necessary; * Add locks where unprotected use of `gInterpreter` is made; * Improve code clarity and performance of `TTree::Fill()`; * Some typo and formatting fixes to improve conformance to coding conventions,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/709
https://github.com/root-project/root/pull/709:372,Energy Efficiency,Reduce,Reduce,372,This branch contains modifications to address some performance issues identifies in JIRA issue [ROOT-8871](https://sft.its.cern.ch/jira/browse/ROOT-8871). The main changes are:; * Make `TClass::LoadClassInfo()` private and avoid locking the interpreter unnecessarily; * Avoid interpreter lock in `TClass::GetListOfBases()` and return existing list if already available; * Reduce scope of interpreter locks in several places where the lock is taken before necessary; * Add locks where unprotected use of `gInterpreter` is made; * Improve code clarity and performance of `TTree::Fill()`; * Some typo and formatting fixes to improve conformance to coding conventions,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/709
https://github.com/root-project/root/pull/709:51,Performance,perform,performance,51,This branch contains modifications to address some performance issues identifies in JIRA issue [ROOT-8871](https://sft.its.cern.ch/jira/browse/ROOT-8871). The main changes are:; * Make `TClass::LoadClassInfo()` private and avoid locking the interpreter unnecessarily; * Avoid interpreter lock in `TClass::GetListOfBases()` and return existing list if already available; * Reduce scope of interpreter locks in several places where the lock is taken before necessary; * Add locks where unprotected use of `gInterpreter` is made; * Improve code clarity and performance of `TTree::Fill()`; * Some typo and formatting fixes to improve conformance to coding conventions,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/709
https://github.com/root-project/root/pull/709:194,Performance,Load,LoadClassInfo,194,This branch contains modifications to address some performance issues identifies in JIRA issue [ROOT-8871](https://sft.its.cern.ch/jira/browse/ROOT-8871). The main changes are:; * Make `TClass::LoadClassInfo()` private and avoid locking the interpreter unnecessarily; * Avoid interpreter lock in `TClass::GetListOfBases()` and return existing list if already available; * Reduce scope of interpreter locks in several places where the lock is taken before necessary; * Add locks where unprotected use of `gInterpreter` is made; * Improve code clarity and performance of `TTree::Fill()`; * Some typo and formatting fixes to improve conformance to coding conventions,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/709
https://github.com/root-project/root/pull/709:554,Performance,perform,performance,554,This branch contains modifications to address some performance issues identifies in JIRA issue [ROOT-8871](https://sft.its.cern.ch/jira/browse/ROOT-8871). The main changes are:; * Make `TClass::LoadClassInfo()` private and avoid locking the interpreter unnecessarily; * Avoid interpreter lock in `TClass::GetListOfBases()` and return existing list if already available; * Reduce scope of interpreter locks in several places where the lock is taken before necessary; * Add locks where unprotected use of `gInterpreter` is made; * Improve code clarity and performance of `TTree::Fill()`; * Some typo and formatting fixes to improve conformance to coding conventions,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/709
https://github.com/root-project/root/pull/709:223,Safety,avoid,avoid,223,This branch contains modifications to address some performance issues identifies in JIRA issue [ROOT-8871](https://sft.its.cern.ch/jira/browse/ROOT-8871). The main changes are:; * Make `TClass::LoadClassInfo()` private and avoid locking the interpreter unnecessarily; * Avoid interpreter lock in `TClass::GetListOfBases()` and return existing list if already available; * Reduce scope of interpreter locks in several places where the lock is taken before necessary; * Add locks where unprotected use of `gInterpreter` is made; * Improve code clarity and performance of `TTree::Fill()`; * Some typo and formatting fixes to improve conformance to coding conventions,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/709
https://github.com/root-project/root/pull/709:270,Safety,Avoid,Avoid,270,This branch contains modifications to address some performance issues identifies in JIRA issue [ROOT-8871](https://sft.its.cern.ch/jira/browse/ROOT-8871). The main changes are:; * Make `TClass::LoadClassInfo()` private and avoid locking the interpreter unnecessarily; * Avoid interpreter lock in `TClass::GetListOfBases()` and return existing list if already available; * Reduce scope of interpreter locks in several places where the lock is taken before necessary; * Add locks where unprotected use of `gInterpreter` is made; * Improve code clarity and performance of `TTree::Fill()`; * Some typo and formatting fixes to improve conformance to coding conventions,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/709
https://github.com/root-project/root/pull/712:75,Deployability,patch,patches,75,https://github.com/root-project/cling/pull/158. NOTE: must apply textinput patches directly to cling.git.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/712
https://github.com/root-project/root/pull/713:226,Testability,log,logic,226,"Formerly the children count of each node was not reset after the first event loop,; with the consequence that the event loop would never be quit early, even if all ranges had been exhausted. Some changes to the children count logic were necessary to correctly handle all cases.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/713
https://github.com/root-project/root/pull/714:539,Deployability,patch,patch,539,"So far we create our DeclCollector in the CIFactory and then tried to; get this variable back in the IncrementalParser by casting the; ASTConsumer of our compiler instance to a DeclCollector. This strategy; fails as soon as we want to have multiple collectors and start using; the clang multiplexer as this call will now fail (e.g. in this case to; have another ASTConsumer that looks in the C++ modules case for what; libraries we need to link - and the best way to add this is via; the multiplexed ASTConsumer that clang provides). This patch moves the responsibility for the DeclCollector to the; caller that relies on getting a DeclCollector back, which is in this; case the constructor of IncrementalParser.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/714
https://github.com/root-project/root/pull/714:80,Modifiability,variab,variable,80,"So far we create our DeclCollector in the CIFactory and then tried to; get this variable back in the IncrementalParser by casting the; ASTConsumer of our compiler instance to a DeclCollector. This strategy; fails as soon as we want to have multiple collectors and start using; the clang multiplexer as this call will now fail (e.g. in this case to; have another ASTConsumer that looks in the C++ modules case for what; libraries we need to link - and the best way to add this is via; the multiplexed ASTConsumer that clang provides). This patch moves the responsibility for the DeclCollector to the; caller that relies on getting a DeclCollector back, which is in this; case the constructor of IncrementalParser.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/714
https://github.com/root-project/root/pull/716:28,Deployability,patch,patch,28,"…/cling version"". clang.git patch id: c46d940",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/716
https://github.com/root-project/root/pull/719:576,Performance,optimiz,optimized,576,"When multiple threads are touching the list of cleanups, another thread can delete the object retrieved via TObjLink::GetObject(), and then when it is dereferenced in ob->TestBit(...) it causes a crash in ROOT. Stack trace (simplified):; ```; in TObject::TestBit (this=0x0, f=33554432) at TObject.h:159; ^^^; in TList::RecursiveRemove (this=0xb3c3e0, obj=0x7ff3547da6b0); at root/core/cont/src/TList.cxx:717; ^^^; in THashList::RecursiveRemove (this=0xb504b0, obj=0x7ff3547da6b0); at root/core/cont/src/THashList.cxx:286; in TObject::~TObject (this=0x7ff3547da6b0, __in_chrg=<optimized out>); at root/core/base/src/TObject.cxx:88; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/719
https://github.com/root-project/root/pull/719:171,Testability,Test,TestBit,171,"When multiple threads are touching the list of cleanups, another thread can delete the object retrieved via TObjLink::GetObject(), and then when it is dereferenced in ob->TestBit(...) it causes a crash in ROOT. Stack trace (simplified):; ```; in TObject::TestBit (this=0x0, f=33554432) at TObject.h:159; ^^^; in TList::RecursiveRemove (this=0xb3c3e0, obj=0x7ff3547da6b0); at root/core/cont/src/TList.cxx:717; ^^^; in THashList::RecursiveRemove (this=0xb504b0, obj=0x7ff3547da6b0); at root/core/cont/src/THashList.cxx:286; in TObject::~TObject (this=0x7ff3547da6b0, __in_chrg=<optimized out>); at root/core/base/src/TObject.cxx:88; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/719
https://github.com/root-project/root/pull/719:255,Testability,Test,TestBit,255,"When multiple threads are touching the list of cleanups, another thread can delete the object retrieved via TObjLink::GetObject(), and then when it is dereferenced in ob->TestBit(...) it causes a crash in ROOT. Stack trace (simplified):; ```; in TObject::TestBit (this=0x0, f=33554432) at TObject.h:159; ^^^; in TList::RecursiveRemove (this=0xb3c3e0, obj=0x7ff3547da6b0); at root/core/cont/src/TList.cxx:717; ^^^; in THashList::RecursiveRemove (this=0xb504b0, obj=0x7ff3547da6b0); at root/core/cont/src/THashList.cxx:286; in TObject::~TObject (this=0x7ff3547da6b0, __in_chrg=<optimized out>); at root/core/base/src/TObject.cxx:88; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/719
https://github.com/root-project/root/pull/719:224,Usability,simpl,simplified,224,"When multiple threads are touching the list of cleanups, another thread can delete the object retrieved via TObjLink::GetObject(), and then when it is dereferenced in ob->TestBit(...) it causes a crash in ROOT. Stack trace (simplified):; ```; in TObject::TestBit (this=0x0, f=33554432) at TObject.h:159; ^^^; in TList::RecursiveRemove (this=0xb3c3e0, obj=0x7ff3547da6b0); at root/core/cont/src/TList.cxx:717; ^^^; in THashList::RecursiveRemove (this=0xb504b0, obj=0x7ff3547da6b0); at root/core/cont/src/THashList.cxx:286; in TObject::~TObject (this=0x7ff3547da6b0, __in_chrg=<optimized out>); at root/core/base/src/TObject.cxx:88; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/719
https://github.com/root-project/root/pull/720:1100,Deployability,integrat,integrate,1100,"`gInterpreter::ProcessLine` has an important run-time cost.; Instead of calling it everytime the jitting of an action is required, we now store all the strings that are to jit in TLoopManager and do a single call to `gInterpreter::ProcessLine` before running the event-loop. A couple of life-time issues had to be resolved for this to work properly: in order to let result proxies and action helpers share ownership of the result object, I introduced (simple) manual lifetime management of a shared_ptr (weird, I know). In order to deal with deferred jitting of an action that hangs from a node whose `TInterface` has already been destroyed (can happen due to the deferral of jitting) all `BuildAndBook` functions have been made independent of `TInterface`. In the long term it might be possible to refactor the jitting mechanism so that the `TAction` (and the `TTreeReaderValue/Array`s that it contains) is jitted but the action helpers are not, lifting the requirement of manual lifetime management of a shared_ptr. Although this should be possible in principle, I currently don't see how we could integrate it with the existing logic, so I decided for this much less invasive solution. Before/after runtimes for two extreme scenarios:. `test_inference.cxx` (which performs a lot of jitting).; compile time: ~8s -> ~9s; run time: ~40s -> ~7s. 50 jitted Histo1D calls in a loop (thanks to Attila for the use-case):; run time: ~35s -> <2s. This PR conflicts with #713 . Depending on which one gets merged first I will rebase the other.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/720
https://github.com/root-project/root/pull/720:1100,Integrability,integrat,integrate,1100,"`gInterpreter::ProcessLine` has an important run-time cost.; Instead of calling it everytime the jitting of an action is required, we now store all the strings that are to jit in TLoopManager and do a single call to `gInterpreter::ProcessLine` before running the event-loop. A couple of life-time issues had to be resolved for this to work properly: in order to let result proxies and action helpers share ownership of the result object, I introduced (simple) manual lifetime management of a shared_ptr (weird, I know). In order to deal with deferred jitting of an action that hangs from a node whose `TInterface` has already been destroyed (can happen due to the deferral of jitting) all `BuildAndBook` functions have been made independent of `TInterface`. In the long term it might be possible to refactor the jitting mechanism so that the `TAction` (and the `TTreeReaderValue/Array`s that it contains) is jitted but the action helpers are not, lifting the requirement of manual lifetime management of a shared_ptr. Although this should be possible in principle, I currently don't see how we could integrate it with the existing logic, so I decided for this much less invasive solution. Before/after runtimes for two extreme scenarios:. `test_inference.cxx` (which performs a lot of jitting).; compile time: ~8s -> ~9s; run time: ~40s -> ~7s. 50 jitted Histo1D calls in a loop (thanks to Attila for the use-case):; run time: ~35s -> <2s. This PR conflicts with #713 . Depending on which one gets merged first I will rebase the other.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/720
https://github.com/root-project/root/pull/720:1470,Integrability,Depend,Depending,1470,"`gInterpreter::ProcessLine` has an important run-time cost.; Instead of calling it everytime the jitting of an action is required, we now store all the strings that are to jit in TLoopManager and do a single call to `gInterpreter::ProcessLine` before running the event-loop. A couple of life-time issues had to be resolved for this to work properly: in order to let result proxies and action helpers share ownership of the result object, I introduced (simple) manual lifetime management of a shared_ptr (weird, I know). In order to deal with deferred jitting of an action that hangs from a node whose `TInterface` has already been destroyed (can happen due to the deferral of jitting) all `BuildAndBook` functions have been made independent of `TInterface`. In the long term it might be possible to refactor the jitting mechanism so that the `TAction` (and the `TTreeReaderValue/Array`s that it contains) is jitted but the action helpers are not, lifting the requirement of manual lifetime management of a shared_ptr. Although this should be possible in principle, I currently don't see how we could integrate it with the existing logic, so I decided for this much less invasive solution. Before/after runtimes for two extreme scenarios:. `test_inference.cxx` (which performs a lot of jitting).; compile time: ~8s -> ~9s; run time: ~40s -> ~7s. 50 jitted Histo1D calls in a loop (thanks to Attila for the use-case):; run time: ~35s -> <2s. This PR conflicts with #713 . Depending on which one gets merged first I will rebase the other.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/720
https://github.com/root-project/root/pull/720:799,Modifiability,refactor,refactor,799,"`gInterpreter::ProcessLine` has an important run-time cost.; Instead of calling it everytime the jitting of an action is required, we now store all the strings that are to jit in TLoopManager and do a single call to `gInterpreter::ProcessLine` before running the event-loop. A couple of life-time issues had to be resolved for this to work properly: in order to let result proxies and action helpers share ownership of the result object, I introduced (simple) manual lifetime management of a shared_ptr (weird, I know). In order to deal with deferred jitting of an action that hangs from a node whose `TInterface` has already been destroyed (can happen due to the deferral of jitting) all `BuildAndBook` functions have been made independent of `TInterface`. In the long term it might be possible to refactor the jitting mechanism so that the `TAction` (and the `TTreeReaderValue/Array`s that it contains) is jitted but the action helpers are not, lifting the requirement of manual lifetime management of a shared_ptr. Although this should be possible in principle, I currently don't see how we could integrate it with the existing logic, so I decided for this much less invasive solution. Before/after runtimes for two extreme scenarios:. `test_inference.cxx` (which performs a lot of jitting).; compile time: ~8s -> ~9s; run time: ~40s -> ~7s. 50 jitted Histo1D calls in a loop (thanks to Attila for the use-case):; run time: ~35s -> <2s. This PR conflicts with #713 . Depending on which one gets merged first I will rebase the other.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/720
https://github.com/root-project/root/pull/720:1267,Performance,perform,performs,1267,"`gInterpreter::ProcessLine` has an important run-time cost.; Instead of calling it everytime the jitting of an action is required, we now store all the strings that are to jit in TLoopManager and do a single call to `gInterpreter::ProcessLine` before running the event-loop. A couple of life-time issues had to be resolved for this to work properly: in order to let result proxies and action helpers share ownership of the result object, I introduced (simple) manual lifetime management of a shared_ptr (weird, I know). In order to deal with deferred jitting of an action that hangs from a node whose `TInterface` has already been destroyed (can happen due to the deferral of jitting) all `BuildAndBook` functions have been made independent of `TInterface`. In the long term it might be possible to refactor the jitting mechanism so that the `TAction` (and the `TTreeReaderValue/Array`s that it contains) is jitted but the action helpers are not, lifting the requirement of manual lifetime management of a shared_ptr. Although this should be possible in principle, I currently don't see how we could integrate it with the existing logic, so I decided for this much less invasive solution. Before/after runtimes for two extreme scenarios:. `test_inference.cxx` (which performs a lot of jitting).; compile time: ~8s -> ~9s; run time: ~40s -> ~7s. 50 jitted Histo1D calls in a loop (thanks to Attila for the use-case):; run time: ~35s -> <2s. This PR conflicts with #713 . Depending on which one gets merged first I will rebase the other.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/720
https://github.com/root-project/root/pull/720:1131,Testability,log,logic,1131,"`gInterpreter::ProcessLine` has an important run-time cost.; Instead of calling it everytime the jitting of an action is required, we now store all the strings that are to jit in TLoopManager and do a single call to `gInterpreter::ProcessLine` before running the event-loop. A couple of life-time issues had to be resolved for this to work properly: in order to let result proxies and action helpers share ownership of the result object, I introduced (simple) manual lifetime management of a shared_ptr (weird, I know). In order to deal with deferred jitting of an action that hangs from a node whose `TInterface` has already been destroyed (can happen due to the deferral of jitting) all `BuildAndBook` functions have been made independent of `TInterface`. In the long term it might be possible to refactor the jitting mechanism so that the `TAction` (and the `TTreeReaderValue/Array`s that it contains) is jitted but the action helpers are not, lifting the requirement of manual lifetime management of a shared_ptr. Although this should be possible in principle, I currently don't see how we could integrate it with the existing logic, so I decided for this much less invasive solution. Before/after runtimes for two extreme scenarios:. `test_inference.cxx` (which performs a lot of jitting).; compile time: ~8s -> ~9s; run time: ~40s -> ~7s. 50 jitted Histo1D calls in a loop (thanks to Attila for the use-case):; run time: ~35s -> <2s. This PR conflicts with #713 . Depending on which one gets merged first I will rebase the other.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/720
https://github.com/root-project/root/pull/720:452,Usability,simpl,simple,452,"`gInterpreter::ProcessLine` has an important run-time cost.; Instead of calling it everytime the jitting of an action is required, we now store all the strings that are to jit in TLoopManager and do a single call to `gInterpreter::ProcessLine` before running the event-loop. A couple of life-time issues had to be resolved for this to work properly: in order to let result proxies and action helpers share ownership of the result object, I introduced (simple) manual lifetime management of a shared_ptr (weird, I know). In order to deal with deferred jitting of an action that hangs from a node whose `TInterface` has already been destroyed (can happen due to the deferral of jitting) all `BuildAndBook` functions have been made independent of `TInterface`. In the long term it might be possible to refactor the jitting mechanism so that the `TAction` (and the `TTreeReaderValue/Array`s that it contains) is jitted but the action helpers are not, lifting the requirement of manual lifetime management of a shared_ptr. Although this should be possible in principle, I currently don't see how we could integrate it with the existing logic, so I decided for this much less invasive solution. Before/after runtimes for two extreme scenarios:. `test_inference.cxx` (which performs a lot of jitting).; compile time: ~8s -> ~9s; run time: ~40s -> ~7s. 50 jitted Histo1D calls in a loop (thanks to Attila for the use-case):; run time: ~35s -> <2s. This PR conflicts with #713 . Depending on which one gets merged first I will rebase the other.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/720
https://github.com/root-project/root/pull/721:726,Availability,error,error,726,"How to compile code see Readme in gui/canvaspainter. Code is not yet used - I will provide another patch after this PR and #717 are merged. CEF-related makefile should be improved. ; One can use **cefsimple** cmake files as an example. https://bitbucket.org/chromiumembedded/cef/src/8e69e3dcea8b/tests/cefsimple/?at=master. **cefsimple** has some specialization for linux, mac and windows. ; I used only linux till now. One could try mac - for that one should include simple_handler_mac.mm into compilation instead of simple_handler_linux.cxx. Same is for cef_main.cxx. Formally one need to create separate versions for mac, linux and windows.; You can see example also in **cefsimple**. These are different platform-specific error handlers. Building of Qt5 part is not called from makefile. I hope, one can add it into makefile when qt5-webengine is discovered. Also rootqt5 executable should be moved into $ROOTSYS/bin directory",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/721
https://github.com/root-project/root/pull/721:99,Deployability,patch,patch,99,"How to compile code see Readme in gui/canvaspainter. Code is not yet used - I will provide another patch after this PR and #717 are merged. CEF-related makefile should be improved. ; One can use **cefsimple** cmake files as an example. https://bitbucket.org/chromiumembedded/cef/src/8e69e3dcea8b/tests/cefsimple/?at=master. **cefsimple** has some specialization for linux, mac and windows. ; I used only linux till now. One could try mac - for that one should include simple_handler_mac.mm into compilation instead of simple_handler_linux.cxx. Same is for cef_main.cxx. Formally one need to create separate versions for mac, linux and windows.; You can see example also in **cefsimple**. These are different platform-specific error handlers. Building of Qt5 part is not called from makefile. I hope, one can add it into makefile when qt5-webengine is discovered. Also rootqt5 executable should be moved into $ROOTSYS/bin directory",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/721
https://github.com/root-project/root/pull/721:296,Testability,test,tests,296,"How to compile code see Readme in gui/canvaspainter. Code is not yet used - I will provide another patch after this PR and #717 are merged. CEF-related makefile should be improved. ; One can use **cefsimple** cmake files as an example. https://bitbucket.org/chromiumembedded/cef/src/8e69e3dcea8b/tests/cefsimple/?at=master. **cefsimple** has some specialization for linux, mac and windows. ; I used only linux till now. One could try mac - for that one should include simple_handler_mac.mm into compilation instead of simple_handler_linux.cxx. Same is for cef_main.cxx. Formally one need to create separate versions for mac, linux and windows.; You can see example also in **cefsimple**. These are different platform-specific error handlers. Building of Qt5 part is not called from makefile. I hope, one can add it into makefile when qt5-webengine is discovered. Also rootqt5 executable should be moved into $ROOTSYS/bin directory",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/721
https://github.com/root-project/root/pull/725:54,Testability,log,logic,54,* fix issue in interaction of named filters and range logic (fixes test_report on noimt builds); * throw instead of crashing when wrong branch names are used for jitted actions; * only call `ProcessLine` if there is something to jit; * use `ULong64_t` instead of `Long64_t` for number of events to generate with TDF,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/725
https://github.com/root-project/root/pull/731:295,Availability,error,errors,295,The changes to fix the build process with GCC6 mentioned in [ROOT-8180](https://sft.its.cern.ch/jira/browse/ROOT-8180) only apply to GCC6. The same problem occurs again using GCC7 because of the equality check to major version 6. . The commit is tested on Arch Linux 64Bit and fixes the compile errors.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/731
https://github.com/root-project/root/pull/731:246,Testability,test,tested,246,The changes to fix the build process with GCC6 mentioned in [ROOT-8180](https://sft.its.cern.ch/jira/browse/ROOT-8180) only apply to GCC6. The same problem occurs again using GCC7 because of the equality check to major version 6. . The commit is tested on Arch Linux 64Bit and fixes the compile errors.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/731
https://github.com/root-project/root/pull/738:139,Energy Efficiency,Adapt,Adapted,139,"Extension of the DNN implementation with weighting of training samples according to event weights for all backends (Reference, CPU, Cuda). Adapted and extended tests to cover new functionality. . Also removes one previously unused file.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/738
https://github.com/root-project/root/pull/738:139,Modifiability,Adapt,Adapted,139,"Extension of the DNN implementation with weighting of training samples according to event weights for all backends (Reference, CPU, Cuda). Adapted and extended tests to cover new functionality. . Also removes one previously unused file.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/738
https://github.com/root-project/root/pull/738:151,Modifiability,extend,extended,151,"Extension of the DNN implementation with weighting of training samples according to event weights for all backends (Reference, CPU, Cuda). Adapted and extended tests to cover new functionality. . Also removes one previously unused file.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/738
https://github.com/root-project/root/pull/738:160,Testability,test,tests,160,"Extension of the DNN implementation with weighting of training samples according to event weights for all backends (Reference, CPU, Cuda). Adapted and extended tests to cover new functionality. . Also removes one previously unused file.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/738
https://github.com/root-project/root/pull/740:43,Availability,error,error,43,"The `max template recursion depth reached` error is due to the; implementation of std::tuple's move constructor in some STL; implementations (notably, gcc). The logic has been modified to avoid copying large tuples:; - the number of slots is now fixed for each node at construction time; - all the logic that was implemented by the `CreateSlot` methods has; been moved to the corresponding nodes' constructors.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/740
https://github.com/root-project/root/pull/740:188,Safety,avoid,avoid,188,"The `max template recursion depth reached` error is due to the; implementation of std::tuple's move constructor in some STL; implementations (notably, gcc). The logic has been modified to avoid copying large tuples:; - the number of slots is now fixed for each node at construction time; - all the logic that was implemented by the `CreateSlot` methods has; been moved to the corresponding nodes' constructors.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/740
https://github.com/root-project/root/pull/740:161,Testability,log,logic,161,"The `max template recursion depth reached` error is due to the; implementation of std::tuple's move constructor in some STL; implementations (notably, gcc). The logic has been modified to avoid copying large tuples:; - the number of slots is now fixed for each node at construction time; - all the logic that was implemented by the `CreateSlot` methods has; been moved to the corresponding nodes' constructors.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/740
https://github.com/root-project/root/pull/740:298,Testability,log,logic,298,"The `max template recursion depth reached` error is due to the; implementation of std::tuple's move constructor in some STL; implementations (notably, gcc). The logic has been modified to avoid copying large tuples:; - the number of slots is now fixed for each node at construction time; - all the logic that was implemented by the `CreateSlot` methods has; been moved to the corresponding nodes' constructors.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/740
https://github.com/root-project/root/pull/741:280,Performance,perform,performance,280,"If IMT is disabled, TTree::Fill() is constructing and destructing the; imtHelper object at every call and never using it. By moving its; declaration into the #ifdef, we avoid this penalty. This commit also; avoids the penalty of checking for fIMTEnabled if IMT is disabled. VTune performance analysis (comparison of two basic hotspots analyses):. ![screenshot](https://user-images.githubusercontent.com/249404/27871466-078e31c0-61a6-11e7-99f7-295d7282bc5c.png). Note the time difference in `TTree::Fill()`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/741
https://github.com/root-project/root/pull/741:169,Safety,avoid,avoid,169,"If IMT is disabled, TTree::Fill() is constructing and destructing the; imtHelper object at every call and never using it. By moving its; declaration into the #ifdef, we avoid this penalty. This commit also; avoids the penalty of checking for fIMTEnabled if IMT is disabled. VTune performance analysis (comparison of two basic hotspots analyses):. ![screenshot](https://user-images.githubusercontent.com/249404/27871466-078e31c0-61a6-11e7-99f7-295d7282bc5c.png). Note the time difference in `TTree::Fill()`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/741
https://github.com/root-project/root/pull/741:207,Safety,avoid,avoids,207,"If IMT is disabled, TTree::Fill() is constructing and destructing the; imtHelper object at every call and never using it. By moving its; declaration into the #ifdef, we avoid this penalty. This commit also; avoids the penalty of checking for fIMTEnabled if IMT is disabled. VTune performance analysis (comparison of two basic hotspots analyses):. ![screenshot](https://user-images.githubusercontent.com/249404/27871466-078e31c0-61a6-11e7-99f7-295d7282bc5c.png). Note the time difference in `TTree::Fill()`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/741
https://github.com/root-project/root/pull/743:43,Availability,error,error,43,"The `max template recursion depth reached` error is due to the; implementation of std::tuple's move constructor in some STL; implementations (notably, gcc). The logic has been modified to avoid copying large tuples:; - the number of slots is now fixed for each node at construction time; - all the logic that was implemented by the `CreateSlot` methods has; been moved to the corresponding nodes' constructors. Cherry-pick conflicts:; 	tree/treeplayer/inc/ROOT/TDFNodes.hxx; 	tree/treeplayer/src/TDFNodes.cxx",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/743
https://github.com/root-project/root/pull/743:188,Safety,avoid,avoid,188,"The `max template recursion depth reached` error is due to the; implementation of std::tuple's move constructor in some STL; implementations (notably, gcc). The logic has been modified to avoid copying large tuples:; - the number of slots is now fixed for each node at construction time; - all the logic that was implemented by the `CreateSlot` methods has; been moved to the corresponding nodes' constructors. Cherry-pick conflicts:; 	tree/treeplayer/inc/ROOT/TDFNodes.hxx; 	tree/treeplayer/src/TDFNodes.cxx",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/743
https://github.com/root-project/root/pull/743:161,Testability,log,logic,161,"The `max template recursion depth reached` error is due to the; implementation of std::tuple's move constructor in some STL; implementations (notably, gcc). The logic has been modified to avoid copying large tuples:; - the number of slots is now fixed for each node at construction time; - all the logic that was implemented by the `CreateSlot` methods has; been moved to the corresponding nodes' constructors. Cherry-pick conflicts:; 	tree/treeplayer/inc/ROOT/TDFNodes.hxx; 	tree/treeplayer/src/TDFNodes.cxx",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/743
https://github.com/root-project/root/pull/743:298,Testability,log,logic,298,"The `max template recursion depth reached` error is due to the; implementation of std::tuple's move constructor in some STL; implementations (notably, gcc). The logic has been modified to avoid copying large tuples:; - the number of slots is now fixed for each node at construction time; - all the logic that was implemented by the `CreateSlot` methods has; been moved to the corresponding nodes' constructors. Cherry-pick conflicts:; 	tree/treeplayer/inc/ROOT/TDFNodes.hxx; 	tree/treeplayer/src/TDFNodes.cxx",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/743
https://github.com/root-project/root/pull/744:179,Deployability,patch,patch,179,"This is to test a potential fix to a recent regression in llvm wrt exposing symbols to the JIT from dlopened with RTLD_LOCAL libraries. This regression forced ROOT to revert this patch, adding one more patch to the list of llvm patches. We want to check if D33529 fixes our issue and make sure it goes in the next llvm release (coming soon). @marsupial, I failed to apply D33657 on top and D33658. They are marked as dependencies but it looks like they do not apply cleanly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/744
https://github.com/root-project/root/pull/744:202,Deployability,patch,patch,202,"This is to test a potential fix to a recent regression in llvm wrt exposing symbols to the JIT from dlopened with RTLD_LOCAL libraries. This regression forced ROOT to revert this patch, adding one more patch to the list of llvm patches. We want to check if D33529 fixes our issue and make sure it goes in the next llvm release (coming soon). @marsupial, I failed to apply D33657 on top and D33658. They are marked as dependencies but it looks like they do not apply cleanly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/744
https://github.com/root-project/root/pull/744:228,Deployability,patch,patches,228,"This is to test a potential fix to a recent regression in llvm wrt exposing symbols to the JIT from dlopened with RTLD_LOCAL libraries. This regression forced ROOT to revert this patch, adding one more patch to the list of llvm patches. We want to check if D33529 fixes our issue and make sure it goes in the next llvm release (coming soon). @marsupial, I failed to apply D33657 on top and D33658. They are marked as dependencies but it looks like they do not apply cleanly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/744
https://github.com/root-project/root/pull/744:319,Deployability,release,release,319,"This is to test a potential fix to a recent regression in llvm wrt exposing symbols to the JIT from dlopened with RTLD_LOCAL libraries. This regression forced ROOT to revert this patch, adding one more patch to the list of llvm patches. We want to check if D33529 fixes our issue and make sure it goes in the next llvm release (coming soon). @marsupial, I failed to apply D33657 on top and D33658. They are marked as dependencies but it looks like they do not apply cleanly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/744
https://github.com/root-project/root/pull/744:417,Integrability,depend,dependencies,417,"This is to test a potential fix to a recent regression in llvm wrt exposing symbols to the JIT from dlopened with RTLD_LOCAL libraries. This regression forced ROOT to revert this patch, adding one more patch to the list of llvm patches. We want to check if D33529 fixes our issue and make sure it goes in the next llvm release (coming soon). @marsupial, I failed to apply D33657 on top and D33658. They are marked as dependencies but it looks like they do not apply cleanly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/744
https://github.com/root-project/root/pull/744:11,Testability,test,test,11,"This is to test a potential fix to a recent regression in llvm wrt exposing symbols to the JIT from dlopened with RTLD_LOCAL libraries. This regression forced ROOT to revert this patch, adding one more patch to the list of llvm patches. We want to check if D33529 fixes our issue and make sure it goes in the next llvm release (coming soon). @marsupial, I failed to apply D33657 on top and D33658. They are marked as dependencies but it looks like they do not apply cleanly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/744
https://github.com/root-project/root/pull/747:242,Energy Efficiency,reduce,reduced,242,"This is a refactored version of part of PR #709. The figure attached below shows an example of the difference in wait time, as measured by VTune for parallel filling of a TTree with random numbers. The number of waits on `LoadClassInfo()` is reduced from 451 to just 8 (one wait per thread). ![screenshot](https://user-images.githubusercontent.com/249404/27913555-cbd6b592-6260-11e7-87af-7a11f376b71a.png)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/747
https://github.com/root-project/root/pull/747:10,Modifiability,refactor,refactored,10,"This is a refactored version of part of PR #709. The figure attached below shows an example of the difference in wait time, as measured by VTune for parallel filling of a TTree with random numbers. The number of waits on `LoadClassInfo()` is reduced from 451 to just 8 (one wait per thread). ![screenshot](https://user-images.githubusercontent.com/249404/27913555-cbd6b592-6260-11e7-87af-7a11f376b71a.png)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/747
https://github.com/root-project/root/pull/747:222,Performance,Load,LoadClassInfo,222,"This is a refactored version of part of PR #709. The figure attached below shows an example of the difference in wait time, as measured by VTune for parallel filling of a TTree with random numbers. The number of waits on `LoadClassInfo()` is reduced from 451 to just 8 (one wait per thread). ![screenshot](https://user-images.githubusercontent.com/249404/27913555-cbd6b592-6260-11e7-87af-7a11f376b71a.png)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/747
https://github.com/root-project/root/pull/748:50,Modifiability,variab,variables,50,"There is no support for thread_local on macOS, so variables with; thread local storage must use the ROOT macros for this purpose.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/748
https://github.com/root-project/root/pull/751:401,Deployability,install,installed,401,"There is no equivalent 'gsl' option, so since mathcore is the main; consumer of GSL, it makes sense to enable the builtin version when; the user requests to build mathmore rather than disabling mathmore.; The behavior is still to fail when mathmore is ON and builtin_gsl is OFF,; however. The previous behavior was to turn OFF mathmore instead. We also have a problem in some build nodes where GSL is installed,; but is not found.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/751
https://github.com/root-project/root/pull/752:10,Deployability,patch,patch,10,With this patch we can finally do `make -j200`! (And I no longer have to explain to the summer students why they have to type `make Cling; make` to compile root :) ). We also get the module dependencies for rootcling right. See the specific commits for the individual fixes.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/752
https://github.com/root-project/root/pull/752:190,Integrability,depend,dependencies,190,With this patch we can finally do `make -j200`! (And I no longer have to explain to the summer students why they have to type `make Cling; make` to compile root :) ). We also get the module dependencies for rootcling right. See the specific commits for the individual fixes.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/752
https://github.com/root-project/root/pull/754:60,Availability,avail,available,60,"Introduce a new helper returning the number of logical CPUs available to the current process. In case of having an affinity mask, it will return in accordance to it (IMT & tbb required for this). Function naming can be improved. I wanted to keep tbb away from ImplicitMT and that's why the core function is defined in TPoolManager.hxx. Should it be a member of the class?. Also delete useless return.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/754
https://github.com/root-project/root/pull/754:124,Availability,mask,mask,124,"Introduce a new helper returning the number of logical CPUs available to the current process. In case of having an affinity mask, it will return in accordance to it (IMT & tbb required for this). Function naming can be improved. I wanted to keep tbb away from ImplicitMT and that's why the core function is defined in TPoolManager.hxx. Should it be a member of the class?. Also delete useless return.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/754
https://github.com/root-project/root/pull/754:47,Testability,log,logical,47,"Introduce a new helper returning the number of logical CPUs available to the current process. In case of having an affinity mask, it will return in accordance to it (IMT & tbb required for this). Function naming can be improved. I wanted to keep tbb away from ImplicitMT and that's why the core function is defined in TPoolManager.hxx. Should it be a member of the class?. Also delete useless return.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/754
https://github.com/root-project/root/pull/755:176,Availability,error,errors,176,"This PR brings compile options of the classic build closer to what the CMake system has.; There is also a fix for stressEntryList, which was failing on ICC because of rounding errors.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/755
https://github.com/root-project/root/pull/756:321,Energy Efficiency,allocate,allocated,321,"Fix a memory leak (only present in master, not in 6.10) that was hitting non-jitted actions. The shared_ptr-on-the-heap trick is only needed for jitted actions,; but we were using it for all of them -- forgetting to delete the; shared_ptr in the non-jitted case. Now only the code path with jitting makes use of the heap-allocated; shared_ptr, removing the leak.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/756
https://github.com/root-project/root/pull/757:0,Energy Efficiency,Reduce,Reduce,0,"Reduce(Op, 0) is nicer than Reduce(Op, """", 0).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/757
https://github.com/root-project/root/pull/757:28,Energy Efficiency,Reduce,Reduce,28,"Reduce(Op, 0) is nicer than Reduce(Op, """", 0).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/757
https://github.com/root-project/root/pull/759:82,Deployability,patch,patch,82,"We should enable rootcling warnings and just fix the issues; they point out. This patch enables those warnings and; fixes the warnings that have accumulated over the past years. The specific actions to fix each warnings were:. * We remove TSchemaWarning as this class was removed in commit; 3803a99. * We remove TMPInterruptHandler as this class was removed in commit; 780e16a. * We rename the ROOT::TPoolManager selection rule to the correct; ROOT::Internal::TPoolManager. * We added the VarTransformHandler.h to the headers passed to rootcling; in TMVA. * We remove the selection rule for TMVA::DataSetFactory::EventStats; because the class is private/protected. * Fixed missing ""_t"" in the TrackMathCoreLinkDef.h.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/759
https://github.com/root-project/root/pull/760:31,Availability,redundant,redundant,31,This patch affords trimming of redundant Jupyter notebook information contained within TCanvas .JSON objects. Specifically this includes the removing the list of TColors which reduces the size of a benchmark notebook (a compiled test notebook of Root Primer graphics) by up to 80% upon preliminary tests.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/760
https://github.com/root-project/root/pull/760:5,Deployability,patch,patch,5,This patch affords trimming of redundant Jupyter notebook information contained within TCanvas .JSON objects. Specifically this includes the removing the list of TColors which reduces the size of a benchmark notebook (a compiled test notebook of Root Primer graphics) by up to 80% upon preliminary tests.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/760
https://github.com/root-project/root/pull/760:176,Energy Efficiency,reduce,reduces,176,This patch affords trimming of redundant Jupyter notebook information contained within TCanvas .JSON objects. Specifically this includes the removing the list of TColors which reduces the size of a benchmark notebook (a compiled test notebook of Root Primer graphics) by up to 80% upon preliminary tests.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/760
https://github.com/root-project/root/pull/760:31,Safety,redund,redundant,31,This patch affords trimming of redundant Jupyter notebook information contained within TCanvas .JSON objects. Specifically this includes the removing the list of TColors which reduces the size of a benchmark notebook (a compiled test notebook of Root Primer graphics) by up to 80% upon preliminary tests.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/760
https://github.com/root-project/root/pull/760:198,Testability,benchmark,benchmark,198,This patch affords trimming of redundant Jupyter notebook information contained within TCanvas .JSON objects. Specifically this includes the removing the list of TColors which reduces the size of a benchmark notebook (a compiled test notebook of Root Primer graphics) by up to 80% upon preliminary tests.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/760
https://github.com/root-project/root/pull/760:229,Testability,test,test,229,This patch affords trimming of redundant Jupyter notebook information contained within TCanvas .JSON objects. Specifically this includes the removing the list of TColors which reduces the size of a benchmark notebook (a compiled test notebook of Root Primer graphics) by up to 80% upon preliminary tests.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/760
https://github.com/root-project/root/pull/760:298,Testability,test,tests,298,This patch affords trimming of redundant Jupyter notebook information contained within TCanvas .JSON objects. Specifically this includes the removing the list of TColors which reduces the size of a benchmark notebook (a compiled test notebook of Root Primer graphics) by up to 80% upon preliminary tests.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/760
https://github.com/root-project/root/pull/764:377,Usability,feedback,feedback,377,"* added a paragraph on ""creating a TDataFrame"", including a TDF from scratch; * added examples and short explanations for string expressions for `Define` and `Filter`; * added a minimal example of creation of a TDF from scratch, including snapshotting to a new data-set; * switched ""branch"" with ""column"" where we are not specifically talking of a TTree. I am also waiting for feedback from @hshe824 who is kindly taking a look at it.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/764
https://github.com/root-project/root/pull/767:8,Testability,test,test,8,Just to test in jenkins,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/767
https://github.com/root-project/root/pull/768:244,Availability,error,error,244,"All actions and transformations now use the same method to decide what columns to act no: `ROOT::Internal::TDF::SelectColumnNames`. The method picks the necessary number of default columns if the user-provided list is absent. Throws in case of error. The two separate old mechanisms to achieve the same (`PickBranchNames` and `GetBranchNames`+`GetDefaultBranchNames`) have been completely removed. This PR does not introduce conflicts with #764, also related to TDF.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/768
https://github.com/root-project/root/pull/769:138,Deployability,patch,patch,138,"If the G__X filenames don't match with a module called X, then; CMake can't find the right dependencies and we get race conditions.; This patch fixes all a few more typos that caused those problems. Found by our debug code in RootNewMacros (which is now nearly silent).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/769
https://github.com/root-project/root/pull/769:91,Integrability,depend,dependencies,91,"If the G__X filenames don't match with a module called X, then; CMake can't find the right dependencies and we get race conditions.; This patch fixes all a few more typos that caused those problems. Found by our debug code in RootNewMacros (which is now nearly silent).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/769
https://github.com/root-project/root/pull/769:115,Performance,race condition,race conditions,115,"If the G__X filenames don't match with a module called X, then; CMake can't find the right dependencies and we get race conditions.; This patch fixes all a few more typos that caused those problems. Found by our debug code in RootNewMacros (which is now nearly silent).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/769
https://github.com/root-project/root/pull/771:52,Modifiability,variab,variables,52,sourcing thisroot.sh in a shell script will lead to variables ```p``` and ```drop``` set globally. The proposed change fixes that.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/771
https://github.com/root-project/root/pull/774:681,Deployability,patch,patchset,681,"By setting a new bit in the TTree object, `kFlushAtCluster`, one can enter the ""one basket per event cluster"" mode. This forces baskets to line up with event clusters, at the cost of extra memory use. This new mode simplifies the basket layout within the file, reducing the amount of time handling special cases for the bulk IO mode. Because the baskets *must* grow to the size of an event cluster, we do not invoke `OptimizeBaskets` when one-basket-per-cluster mode is enabled. As this mode is expected to cause increased memory usage (the memory utilized by the `TTree` is more strongly tied to the variations in event size), we combine this with a technique borrowed from a CMS patchset to more aggressively shrink basket sizes after very large objects. The new basket shrinking algorithm will trigger whenever the basket is flushed. If the actual object size in the last clusters is significantly below the buffer size, then the basket will be shrunk. Given this tradeoff, I do not currently see this being enabled by default. The ideal ratio of `(basket buffer size)/(occupied buffer size)` is controlled by a new tunable in the `TTree`, defaulting to 1.1. A lower setting reduces overall memory usage at the cost of extra allocations; a higher setting increases aggregate memory usage. In writing out a 10k event CMS file (total CPU time is 32 minutes):. - Base case (without this patch):; - 888MB RSS; - 30 reallocations (shrinking of baskets due to low occupancy).; - 0.173ms taken for reallocation.; - New shrinking algorithm (this patch with defaults):; - 866MB RSS; - 4434 reallocations; - 97.0ms; - One basket per cluster mode with new shrinking algorithm:; - 902MB RSS; - 2882 reallocations; - 93.6ms. The CPU-time cost of the reallocation is 0.005% of total runtime (considering the file has to be read also, maybe 0.01% of output time?). This patch purposely leaves in the code that measures reallocation time in order to allow others to experiment; the intent is to disable / remove th",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/774
https://github.com/root-project/root/pull/774:1387,Deployability,patch,patch,1387,"ee object, `kFlushAtCluster`, one can enter the ""one basket per event cluster"" mode. This forces baskets to line up with event clusters, at the cost of extra memory use. This new mode simplifies the basket layout within the file, reducing the amount of time handling special cases for the bulk IO mode. Because the baskets *must* grow to the size of an event cluster, we do not invoke `OptimizeBaskets` when one-basket-per-cluster mode is enabled. As this mode is expected to cause increased memory usage (the memory utilized by the `TTree` is more strongly tied to the variations in event size), we combine this with a technique borrowed from a CMS patchset to more aggressively shrink basket sizes after very large objects. The new basket shrinking algorithm will trigger whenever the basket is flushed. If the actual object size in the last clusters is significantly below the buffer size, then the basket will be shrunk. Given this tradeoff, I do not currently see this being enabled by default. The ideal ratio of `(basket buffer size)/(occupied buffer size)` is controlled by a new tunable in the `TTree`, defaulting to 1.1. A lower setting reduces overall memory usage at the cost of extra allocations; a higher setting increases aggregate memory usage. In writing out a 10k event CMS file (total CPU time is 32 minutes):. - Base case (without this patch):; - 888MB RSS; - 30 reallocations (shrinking of baskets due to low occupancy).; - 0.173ms taken for reallocation.; - New shrinking algorithm (this patch with defaults):; - 866MB RSS; - 4434 reallocations; - 97.0ms; - One basket per cluster mode with new shrinking algorithm:; - 902MB RSS; - 2882 reallocations; - 93.6ms. The CPU-time cost of the reallocation is 0.005% of total runtime (considering the file has to be read also, maybe 0.01% of output time?). This patch purposely leaves in the code that measures reallocation time in order to allow others to experiment; the intent is to disable / remove the code before a final release.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/774
https://github.com/root-project/root/pull/774:1541,Deployability,patch,patch,1541,"ee object, `kFlushAtCluster`, one can enter the ""one basket per event cluster"" mode. This forces baskets to line up with event clusters, at the cost of extra memory use. This new mode simplifies the basket layout within the file, reducing the amount of time handling special cases for the bulk IO mode. Because the baskets *must* grow to the size of an event cluster, we do not invoke `OptimizeBaskets` when one-basket-per-cluster mode is enabled. As this mode is expected to cause increased memory usage (the memory utilized by the `TTree` is more strongly tied to the variations in event size), we combine this with a technique borrowed from a CMS patchset to more aggressively shrink basket sizes after very large objects. The new basket shrinking algorithm will trigger whenever the basket is flushed. If the actual object size in the last clusters is significantly below the buffer size, then the basket will be shrunk. Given this tradeoff, I do not currently see this being enabled by default. The ideal ratio of `(basket buffer size)/(occupied buffer size)` is controlled by a new tunable in the `TTree`, defaulting to 1.1. A lower setting reduces overall memory usage at the cost of extra allocations; a higher setting increases aggregate memory usage. In writing out a 10k event CMS file (total CPU time is 32 minutes):. - Base case (without this patch):; - 888MB RSS; - 30 reallocations (shrinking of baskets due to low occupancy).; - 0.173ms taken for reallocation.; - New shrinking algorithm (this patch with defaults):; - 866MB RSS; - 4434 reallocations; - 97.0ms; - One basket per cluster mode with new shrinking algorithm:; - 902MB RSS; - 2882 reallocations; - 93.6ms. The CPU-time cost of the reallocation is 0.005% of total runtime (considering the file has to be read also, maybe 0.01% of output time?). This patch purposely leaves in the code that measures reallocation time in order to allow others to experiment; the intent is to disable / remove the code before a final release.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/774
https://github.com/root-project/root/pull/774:1858,Deployability,patch,patch,1858,"ee object, `kFlushAtCluster`, one can enter the ""one basket per event cluster"" mode. This forces baskets to line up with event clusters, at the cost of extra memory use. This new mode simplifies the basket layout within the file, reducing the amount of time handling special cases for the bulk IO mode. Because the baskets *must* grow to the size of an event cluster, we do not invoke `OptimizeBaskets` when one-basket-per-cluster mode is enabled. As this mode is expected to cause increased memory usage (the memory utilized by the `TTree` is more strongly tied to the variations in event size), we combine this with a technique borrowed from a CMS patchset to more aggressively shrink basket sizes after very large objects. The new basket shrinking algorithm will trigger whenever the basket is flushed. If the actual object size in the last clusters is significantly below the buffer size, then the basket will be shrunk. Given this tradeoff, I do not currently see this being enabled by default. The ideal ratio of `(basket buffer size)/(occupied buffer size)` is controlled by a new tunable in the `TTree`, defaulting to 1.1. A lower setting reduces overall memory usage at the cost of extra allocations; a higher setting increases aggregate memory usage. In writing out a 10k event CMS file (total CPU time is 32 minutes):. - Base case (without this patch):; - 888MB RSS; - 30 reallocations (shrinking of baskets due to low occupancy).; - 0.173ms taken for reallocation.; - New shrinking algorithm (this patch with defaults):; - 866MB RSS; - 4434 reallocations; - 97.0ms; - One basket per cluster mode with new shrinking algorithm:; - 902MB RSS; - 2882 reallocations; - 93.6ms. The CPU-time cost of the reallocation is 0.005% of total runtime (considering the file has to be read also, maybe 0.01% of output time?). This patch purposely leaves in the code that measures reallocation time in order to allow others to experiment; the intent is to disable / remove the code before a final release.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/774
https://github.com/root-project/root/pull/774:2023,Deployability,release,release,2023,"ee object, `kFlushAtCluster`, one can enter the ""one basket per event cluster"" mode. This forces baskets to line up with event clusters, at the cost of extra memory use. This new mode simplifies the basket layout within the file, reducing the amount of time handling special cases for the bulk IO mode. Because the baskets *must* grow to the size of an event cluster, we do not invoke `OptimizeBaskets` when one-basket-per-cluster mode is enabled. As this mode is expected to cause increased memory usage (the memory utilized by the `TTree` is more strongly tied to the variations in event size), we combine this with a technique borrowed from a CMS patchset to more aggressively shrink basket sizes after very large objects. The new basket shrinking algorithm will trigger whenever the basket is flushed. If the actual object size in the last clusters is significantly below the buffer size, then the basket will be shrunk. Given this tradeoff, I do not currently see this being enabled by default. The ideal ratio of `(basket buffer size)/(occupied buffer size)` is controlled by a new tunable in the `TTree`, defaulting to 1.1. A lower setting reduces overall memory usage at the cost of extra allocations; a higher setting increases aggregate memory usage. In writing out a 10k event CMS file (total CPU time is 32 minutes):. - Base case (without this patch):; - 888MB RSS; - 30 reallocations (shrinking of baskets due to low occupancy).; - 0.173ms taken for reallocation.; - New shrinking algorithm (this patch with defaults):; - 866MB RSS; - 4434 reallocations; - 97.0ms; - One basket per cluster mode with new shrinking algorithm:; - 902MB RSS; - 2882 reallocations; - 93.6ms. The CPU-time cost of the reallocation is 0.005% of total runtime (considering the file has to be read also, maybe 0.01% of output time?). This patch purposely leaves in the code that measures reallocation time in order to allow others to experiment; the intent is to disable / remove the code before a final release.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/774
https://github.com/root-project/root/pull/774:1178,Energy Efficiency,reduce,reduces,1178,"ee object, `kFlushAtCluster`, one can enter the ""one basket per event cluster"" mode. This forces baskets to line up with event clusters, at the cost of extra memory use. This new mode simplifies the basket layout within the file, reducing the amount of time handling special cases for the bulk IO mode. Because the baskets *must* grow to the size of an event cluster, we do not invoke `OptimizeBaskets` when one-basket-per-cluster mode is enabled. As this mode is expected to cause increased memory usage (the memory utilized by the `TTree` is more strongly tied to the variations in event size), we combine this with a technique borrowed from a CMS patchset to more aggressively shrink basket sizes after very large objects. The new basket shrinking algorithm will trigger whenever the basket is flushed. If the actual object size in the last clusters is significantly below the buffer size, then the basket will be shrunk. Given this tradeoff, I do not currently see this being enabled by default. The ideal ratio of `(basket buffer size)/(occupied buffer size)` is controlled by a new tunable in the `TTree`, defaulting to 1.1. A lower setting reduces overall memory usage at the cost of extra allocations; a higher setting increases aggregate memory usage. In writing out a 10k event CMS file (total CPU time is 32 minutes):. - Base case (without this patch):; - 888MB RSS; - 30 reallocations (shrinking of baskets due to low occupancy).; - 0.173ms taken for reallocation.; - New shrinking algorithm (this patch with defaults):; - 866MB RSS; - 4434 reallocations; - 97.0ms; - One basket per cluster mode with new shrinking algorithm:; - 902MB RSS; - 2882 reallocations; - 93.6ms. The CPU-time cost of the reallocation is 0.005% of total runtime (considering the file has to be read also, maybe 0.01% of output time?). This patch purposely leaves in the code that measures reallocation time in order to allow others to experiment; the intent is to disable / remove the code before a final release.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/774
https://github.com/root-project/root/pull/774:417,Performance,Optimiz,OptimizeBaskets,417,"By setting a new bit in the TTree object, `kFlushAtCluster`, one can enter the ""one basket per event cluster"" mode. This forces baskets to line up with event clusters, at the cost of extra memory use. This new mode simplifies the basket layout within the file, reducing the amount of time handling special cases for the bulk IO mode. Because the baskets *must* grow to the size of an event cluster, we do not invoke `OptimizeBaskets` when one-basket-per-cluster mode is enabled. As this mode is expected to cause increased memory usage (the memory utilized by the `TTree` is more strongly tied to the variations in event size), we combine this with a technique borrowed from a CMS patchset to more aggressively shrink basket sizes after very large objects. The new basket shrinking algorithm will trigger whenever the basket is flushed. If the actual object size in the last clusters is significantly below the buffer size, then the basket will be shrunk. Given this tradeoff, I do not currently see this being enabled by default. The ideal ratio of `(basket buffer size)/(occupied buffer size)` is controlled by a new tunable in the `TTree`, defaulting to 1.1. A lower setting reduces overall memory usage at the cost of extra allocations; a higher setting increases aggregate memory usage. In writing out a 10k event CMS file (total CPU time is 32 minutes):. - Base case (without this patch):; - 888MB RSS; - 30 reallocations (shrinking of baskets due to low occupancy).; - 0.173ms taken for reallocation.; - New shrinking algorithm (this patch with defaults):; - 866MB RSS; - 4434 reallocations; - 97.0ms; - One basket per cluster mode with new shrinking algorithm:; - 902MB RSS; - 2882 reallocations; - 93.6ms. The CPU-time cost of the reallocation is 0.005% of total runtime (considering the file has to be read also, maybe 0.01% of output time?). This patch purposely leaves in the code that measures reallocation time in order to allow others to experiment; the intent is to disable / remove th",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/774
https://github.com/root-project/root/pull/774:215,Usability,simpl,simplifies,215,"By setting a new bit in the TTree object, `kFlushAtCluster`, one can enter the ""one basket per event cluster"" mode. This forces baskets to line up with event clusters, at the cost of extra memory use. This new mode simplifies the basket layout within the file, reducing the amount of time handling special cases for the bulk IO mode. Because the baskets *must* grow to the size of an event cluster, we do not invoke `OptimizeBaskets` when one-basket-per-cluster mode is enabled. As this mode is expected to cause increased memory usage (the memory utilized by the `TTree` is more strongly tied to the variations in event size), we combine this with a technique borrowed from a CMS patchset to more aggressively shrink basket sizes after very large objects. The new basket shrinking algorithm will trigger whenever the basket is flushed. If the actual object size in the last clusters is significantly below the buffer size, then the basket will be shrunk. Given this tradeoff, I do not currently see this being enabled by default. The ideal ratio of `(basket buffer size)/(occupied buffer size)` is controlled by a new tunable in the `TTree`, defaulting to 1.1. A lower setting reduces overall memory usage at the cost of extra allocations; a higher setting increases aggregate memory usage. In writing out a 10k event CMS file (total CPU time is 32 minutes):. - Base case (without this patch):; - 888MB RSS; - 30 reallocations (shrinking of baskets due to low occupancy).; - 0.173ms taken for reallocation.; - New shrinking algorithm (this patch with defaults):; - 866MB RSS; - 4434 reallocations; - 97.0ms; - One basket per cluster mode with new shrinking algorithm:; - 902MB RSS; - 2882 reallocations; - 93.6ms. The CPU-time cost of the reallocation is 0.005% of total runtime (considering the file has to be read also, maybe 0.01% of output time?). This patch purposely leaves in the code that measures reallocation time in order to allow others to experiment; the intent is to disable / remove th",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/774
https://github.com/root-project/root/pull/775:357,Deployability,update,update,357,"This PR solves ROOT-8873 ""Reinforce the mechanism to detect non existing branches"". All transformations and actions now throw an exception right when called if at least one of the columns they will work on is not present in the data nor is a custom column (created via `Define`). `test_missingBranches` is expected to start failing -- a PR in roottest will update the reference file.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/775
https://github.com/root-project/root/pull/775:53,Safety,detect,detect,53,"This PR solves ROOT-8873 ""Reinforce the mechanism to detect non existing branches"". All transformations and actions now throw an exception right when called if at least one of the columns they will work on is not present in the data nor is a custom column (created via `Define`). `test_missingBranches` is expected to start failing -- a PR in roottest will update the reference file.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/775
https://github.com/root-project/root/pull/776:270,Testability,test,tests,270,Wouter Verkerke has added some fixes to RooFit for usage in the Higgs Combination working group in ATLAS. These fixes include additions of new classes as well as genuine bugfixes. This is a minimal collection of these fixes that successfully compiles and passes all the tests on an SLC6 machine. @egpbos,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/776
https://github.com/root-project/root/pull/777:29,Availability,error,error,29,This patch instead prints an error with some useful debugging; information that should help identify the cause of this issue.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/777
https://github.com/root-project/root/pull/777:5,Deployability,patch,patch,5,This patch instead prints an error with some useful debugging; information that should help identify the cause of this issue.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/777
https://github.com/root-project/root/pull/778:190,Testability,test,tests,190,"I am a GSoC student working on introducing Recurrent Neural Networks in TMVA. This is the rectified commits using suggestions from #693 . It introduces basic `RNNLayer`, `RecurrentNet` with tests for forward pass. It does not require immediate merge and I'll keep adding commits to it according to feedbacks.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/778
https://github.com/root-project/root/pull/778:298,Usability,feedback,feedbacks,298,"I am a GSoC student working on introducing Recurrent Neural Networks in TMVA. This is the rectified commits using suggestions from #693 . It introduces basic `RNNLayer`, `RecurrentNet` with tests for forward pass. It does not require immediate merge and I'll keep adding commits to it according to feedbacks.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/778
https://github.com/root-project/root/pull/779:10,Integrability,depend,dependence,10,Fixes the dependence of the correct handling of the signal and background classes; on the order in which in which data sets are filled. This was described here:; https://root-forum.cern.ch/t/tmva-signal-background-target-responses-inverted,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/779
https://github.com/root-project/root/pull/780:156,Availability,error,errors,156,We often parse the output of commands to get certain system; information. This however fails as soon as the system locale changes; which results in cryptic errors where certain variables have the; wrong content on an otherwise perfectly fine working system. This patch sets LANG=C from CMake to force all subprocesses that; we run to use the stable C locale that should prevent all those; errors in the future.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/780
https://github.com/root-project/root/pull/780:389,Availability,error,errors,389,We often parse the output of commands to get certain system; information. This however fails as soon as the system locale changes; which results in cryptic errors where certain variables have the; wrong content on an otherwise perfectly fine working system. This patch sets LANG=C from CMake to force all subprocesses that; we run to use the stable C locale that should prevent all those; errors in the future.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/780
https://github.com/root-project/root/pull/780:263,Deployability,patch,patch,263,We often parse the output of commands to get certain system; information. This however fails as soon as the system locale changes; which results in cryptic errors where certain variables have the; wrong content on an otherwise perfectly fine working system. This patch sets LANG=C from CMake to force all subprocesses that; we run to use the stable C locale that should prevent all those; errors in the future.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/780
https://github.com/root-project/root/pull/780:177,Modifiability,variab,variables,177,We often parse the output of commands to get certain system; information. This however fails as soon as the system locale changes; which results in cryptic errors where certain variables have the; wrong content on an otherwise perfectly fine working system. This patch sets LANG=C from CMake to force all subprocesses that; we run to use the stable C locale that should prevent all those; errors in the future.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/780
https://github.com/root-project/root/pull/783:4,Performance,race condition,race condition,4,Fix race condition in SnapshotHelper.; After this fix I am not able to reproduce crashes on this test in master anymore.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/783
https://github.com/root-project/root/pull/783:97,Testability,test,test,97,Fix race condition in SnapshotHelper.; After this fix I am not able to reproduce crashes on this test in master anymore.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/783
https://github.com/root-project/root/pull/786:272,Deployability,toggle,toggled,272,"It is container for the all menu items, collected for the TDrawable; Now is temporary object, later all items can be preserved until TDrawable::Execute() is called. Create hierarchy of menu items class:; - base TMenuItem class; - TCheckedMenuItem for items which could be toggled; - TArgsMenuItem for item with several arguments, which should be provided for function call",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/786
https://github.com/root-project/root/pull/789:420,Deployability,install,installation,420,"If ROOT compiled with CEF3 support, new canvas will be created not in the web browser, ; but with CEF methods. ; Also when rootqt5 is compiled, one can run macro and open canvas with Qt windows; See gui/canvaspainter/README for more details. @peremato ; Build procedure should be changed; CEF should be detected/configured when top ROOT cmake is called; Also some resources should be copied or linked from CEF into ROOT installation; ; rootqt5 executable should be compiled when qt5 with required plugins (qt5-webengine) is exists",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/789
https://github.com/root-project/root/pull/789:312,Modifiability,config,configured,312,"If ROOT compiled with CEF3 support, new canvas will be created not in the web browser, ; but with CEF methods. ; Also when rootqt5 is compiled, one can run macro and open canvas with Qt windows; See gui/canvaspainter/README for more details. @peremato ; Build procedure should be changed; CEF should be detected/configured when top ROOT cmake is called; Also some resources should be copied or linked from CEF into ROOT installation; ; rootqt5 executable should be compiled when qt5 with required plugins (qt5-webengine) is exists",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/789
https://github.com/root-project/root/pull/789:497,Modifiability,plugin,plugins,497,"If ROOT compiled with CEF3 support, new canvas will be created not in the web browser, ; but with CEF methods. ; Also when rootqt5 is compiled, one can run macro and open canvas with Qt windows; See gui/canvaspainter/README for more details. @peremato ; Build procedure should be changed; CEF should be detected/configured when top ROOT cmake is called; Also some resources should be copied or linked from CEF into ROOT installation; ; rootqt5 executable should be compiled when qt5 with required plugins (qt5-webengine) is exists",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/789
https://github.com/root-project/root/pull/789:303,Safety,detect,detected,303,"If ROOT compiled with CEF3 support, new canvas will be created not in the web browser, ; but with CEF methods. ; Also when rootqt5 is compiled, one can run macro and open canvas with Qt windows; See gui/canvaspainter/README for more details. @peremato ; Build procedure should be changed; CEF should be detected/configured when top ROOT cmake is called; Also some resources should be copied or linked from CEF into ROOT installation; ; rootqt5 executable should be compiled when qt5 with required plugins (qt5-webengine) is exists",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/789
https://github.com/root-project/root/pull/791:49,Integrability,depend,depend,49,"The object files of the ROOT libraries currently depend on the; dictionary generation because CMake inherits the add_library; dependencies just for good measure. To speed up (re-)compilation,; we remove this dependency by compiling everything first into; a CMake OBJECT library and then link against those object files,; prevent CMake from adding those extra dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/791
https://github.com/root-project/root/pull/791:126,Integrability,depend,dependencies,126,"The object files of the ROOT libraries currently depend on the; dictionary generation because CMake inherits the add_library; dependencies just for good measure. To speed up (re-)compilation,; we remove this dependency by compiling everything first into; a CMake OBJECT library and then link against those object files,; prevent CMake from adding those extra dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/791
https://github.com/root-project/root/pull/791:208,Integrability,depend,dependency,208,"The object files of the ROOT libraries currently depend on the; dictionary generation because CMake inherits the add_library; dependencies just for good measure. To speed up (re-)compilation,; we remove this dependency by compiling everything first into; a CMake OBJECT library and then link against those object files,; prevent CMake from adding those extra dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/791
https://github.com/root-project/root/pull/791:359,Integrability,depend,dependencies,359,"The object files of the ROOT libraries currently depend on the; dictionary generation because CMake inherits the add_library; dependencies just for good measure. To speed up (re-)compilation,; we remove this dependency by compiling everything first into; a CMake OBJECT library and then link against those object files,; prevent CMake from adding those extra dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/791
https://github.com/root-project/root/pull/791:100,Modifiability,inherit,inherits,100,"The object files of the ROOT libraries currently depend on the; dictionary generation because CMake inherits the add_library; dependencies just for good measure. To speed up (re-)compilation,; we remove this dependency by compiling everything first into; a CMake OBJECT library and then link against those object files,; prevent CMake from adding those extra dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/791
https://github.com/root-project/root/pull/792:270,Testability,test,tests,270,Wouter Verkerke has added some fixes to RooFit for usage in the Higgs Combination working group in ATLAS. These fixes include additions of new classes as well as genuine bugfixes. This is a minimal collection of these fixes that successfully compiles and passes all the tests on an SLC6 machine. @egpbos. [rebased version of this pull request: [https://github.com/root-project/root/pull/776](url)],MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/792
https://github.com/root-project/root/pull/793:46,Integrability,interface,interfaces,46,"Work in progress to fully generalize gradient interfaces, in order to allow vectorization and parallelization of the fitting methods that make use of them. The implementation of Chi2 gradient has been parallelized and vectorized: these new implementations are unit tested and benchmarked against the simple scalar serial case. To do: test the general use case, where the user simply calls the fitting method specifying that the gradient should be used. Early reviews are more than welcome!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/793
https://github.com/root-project/root/pull/793:265,Testability,test,tested,265,"Work in progress to fully generalize gradient interfaces, in order to allow vectorization and parallelization of the fitting methods that make use of them. The implementation of Chi2 gradient has been parallelized and vectorized: these new implementations are unit tested and benchmarked against the simple scalar serial case. To do: test the general use case, where the user simply calls the fitting method specifying that the gradient should be used. Early reviews are more than welcome!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/793
https://github.com/root-project/root/pull/793:276,Testability,benchmark,benchmarked,276,"Work in progress to fully generalize gradient interfaces, in order to allow vectorization and parallelization of the fitting methods that make use of them. The implementation of Chi2 gradient has been parallelized and vectorized: these new implementations are unit tested and benchmarked against the simple scalar serial case. To do: test the general use case, where the user simply calls the fitting method specifying that the gradient should be used. Early reviews are more than welcome!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/793
https://github.com/root-project/root/pull/793:334,Testability,test,test,334,"Work in progress to fully generalize gradient interfaces, in order to allow vectorization and parallelization of the fitting methods that make use of them. The implementation of Chi2 gradient has been parallelized and vectorized: these new implementations are unit tested and benchmarked against the simple scalar serial case. To do: test the general use case, where the user simply calls the fitting method specifying that the gradient should be used. Early reviews are more than welcome!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/793
https://github.com/root-project/root/pull/793:300,Usability,simpl,simple,300,"Work in progress to fully generalize gradient interfaces, in order to allow vectorization and parallelization of the fitting methods that make use of them. The implementation of Chi2 gradient has been parallelized and vectorized: these new implementations are unit tested and benchmarked against the simple scalar serial case. To do: test the general use case, where the user simply calls the fitting method specifying that the gradient should be used. Early reviews are more than welcome!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/793
https://github.com/root-project/root/pull/793:376,Usability,simpl,simply,376,"Work in progress to fully generalize gradient interfaces, in order to allow vectorization and parallelization of the fitting methods that make use of them. The implementation of Chi2 gradient has been parallelized and vectorized: these new implementations are unit tested and benchmarked against the simple scalar serial case. To do: test the general use case, where the user simply calls the fitting method specifying that the gradient should be used. Early reviews are more than welcome!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/793
https://github.com/root-project/root/pull/794:150,Deployability,patch,patch,150,Previously these build options where hidden behind a define and the; only way to test them is to manually add this to the CXX/CC flags; by hand. This patch turns this into a proper (but experimental) build setting; to better document the effort to have proper memory deallocation in; ROOT. It also fixes some of the broken code that was hidden behind; this define.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/794
https://github.com/root-project/root/pull/794:81,Testability,test,test,81,Previously these build options where hidden behind a define and the; only way to test them is to manually add this to the CXX/CC flags; by hand. This patch turns this into a proper (but experimental) build setting; to better document the effort to have proper memory deallocation in; ROOT. It also fixes some of the broken code that was hidden behind; this define.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/794
https://github.com/root-project/root/pull/796:1041,Energy Efficiency,efficient,efficient,1041,"This pull request is the result of work done by David Clark as a summer intern at Argonne:; To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence.; ; By setting the `MaxVirtualSize` of the tree to a negative value, entire clusters will be loaded into memory and previous clusters will be retained - the absolute value of `MaxVirtualSize` indicates how many additional clusters will be kept in memory.; ; If `TTree MaxVirtualSize` is set to a negative value, `GetEntry()` will load the entire cluster into memory, not just the first basket. `GetBasket()` is modified to call a new function `GetFreshCluster()` if `MaxVirtualSize` is negative. This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, `GetFreshCluster()` reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here).; ; To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. - Without the change enables there were 1.5 GB read in 31102 read calls. ; - With MaxVirtualSize set to -1, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/796
https://github.com/root-project/root/pull/796:107,Performance,multi-thread,multi-threaded,107,"This pull request is the result of work done by David Clark as a summer intern at Argonne:; To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence.; ; By setting the `MaxVirtualSize` of the tree to a negative value, entire clusters will be loaded into memory and previous clusters will be retained - the absolute value of `MaxVirtualSize` indicates how many additional clusters will be kept in memory.; ; If `TTree MaxVirtualSize` is set to a negative value, `GetEntry()` will load the entire cluster into memory, not just the first basket. `GetBasket()` is modified to call a new function `GetFreshCluster()` if `MaxVirtualSize` is negative. This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, `GetFreshCluster()` reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here).; ; To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. - Without the change enables there were 1.5 GB read in 31102 read calls. ; - With MaxVirtualSize set to -1, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/796
https://github.com/root-project/root/pull/796:378,Performance,load,loaded,378,"This pull request is the result of work done by David Clark as a summer intern at Argonne:; To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence.; ; By setting the `MaxVirtualSize` of the tree to a negative value, entire clusters will be loaded into memory and previous clusters will be retained - the absolute value of `MaxVirtualSize` indicates how many additional clusters will be kept in memory.; ; If `TTree MaxVirtualSize` is set to a negative value, `GetEntry()` will load the entire cluster into memory, not just the first basket. `GetBasket()` is modified to call a new function `GetFreshCluster()` if `MaxVirtualSize` is negative. This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, `GetFreshCluster()` reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here).; ; To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. - Without the change enables there were 1.5 GB read in 31102 read calls. ; - With MaxVirtualSize set to -1, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/796
https://github.com/root-project/root/pull/796:615,Performance,load,load,615,"This pull request is the result of work done by David Clark as a summer intern at Argonne:; To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence.; ; By setting the `MaxVirtualSize` of the tree to a negative value, entire clusters will be loaded into memory and previous clusters will be retained - the absolute value of `MaxVirtualSize` indicates how many additional clusters will be kept in memory.; ; If `TTree MaxVirtualSize` is set to a negative value, `GetEntry()` will load the entire cluster into memory, not just the first basket. `GetBasket()` is modified to call a new function `GetFreshCluster()` if `MaxVirtualSize` is negative. This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, `GetFreshCluster()` reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here).; ; To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. - Without the change enables there were 1.5 GB read in 31102 read calls. ; - With MaxVirtualSize set to -1, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/796
https://github.com/root-project/root/pull/796:1225,Performance,perform,performance,1225,"This pull request is the result of work done by David Clark as a summer intern at Argonne:; To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence.; ; By setting the `MaxVirtualSize` of the tree to a negative value, entire clusters will be loaded into memory and previous clusters will be retained - the absolute value of `MaxVirtualSize` indicates how many additional clusters will be kept in memory.; ; If `TTree MaxVirtualSize` is set to a negative value, `GetEntry()` will load the entire cluster into memory, not just the first basket. `GetBasket()` is modified to call a new function `GetFreshCluster()` if `MaxVirtualSize` is negative. This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, `GetFreshCluster()` reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here).; ; To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. - Without the change enables there were 1.5 GB read in 31102 read calls. ; - With MaxVirtualSize set to -1, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/796
https://github.com/root-project/root/pull/796:1216,Testability,test,test,1216,"This pull request is the result of work done by David Clark as a summer intern at Argonne:; To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence.; ; By setting the `MaxVirtualSize` of the tree to a negative value, entire clusters will be loaded into memory and previous clusters will be retained - the absolute value of `MaxVirtualSize` indicates how many additional clusters will be kept in memory.; ; If `TTree MaxVirtualSize` is set to a negative value, `GetEntry()` will load the entire cluster into memory, not just the first basket. `GetBasket()` is modified to call a new function `GetFreshCluster()` if `MaxVirtualSize` is negative. This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, `GetFreshCluster()` reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here).; ; To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. - Without the change enables there were 1.5 GB read in 31102 read calls. ; - With MaxVirtualSize set to -1, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/796
https://github.com/root-project/root/pull/796:841,Usability,clear,clearing,841,"This pull request is the result of work done by David Clark as a summer intern at Argonne:; To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence.; ; By setting the `MaxVirtualSize` of the tree to a negative value, entire clusters will be loaded into memory and previous clusters will be retained - the absolute value of `MaxVirtualSize` indicates how many additional clusters will be kept in memory.; ; If `TTree MaxVirtualSize` is set to a negative value, `GetEntry()` will load the entire cluster into memory, not just the first basket. `GetBasket()` is modified to call a new function `GetFreshCluster()` if `MaxVirtualSize` is negative. This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, `GetFreshCluster()` reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here).; ; To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. - Without the change enables there were 1.5 GB read in 31102 read calls. ; - With MaxVirtualSize set to -1, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/796
https://github.com/root-project/root/pull/796:978,Usability,clear,clear,978,"This pull request is the result of work done by David Clark as a summer intern at Argonne:; To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence.; ; By setting the `MaxVirtualSize` of the tree to a negative value, entire clusters will be loaded into memory and previous clusters will be retained - the absolute value of `MaxVirtualSize` indicates how many additional clusters will be kept in memory.; ; If `TTree MaxVirtualSize` is set to a negative value, `GetEntry()` will load the entire cluster into memory, not just the first basket. `GetBasket()` is modified to call a new function `GetFreshCluster()` if `MaxVirtualSize` is negative. This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, `GetFreshCluster()` reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here).; ; To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. - Without the change enables there were 1.5 GB read in 31102 read calls. ; - With MaxVirtualSize set to -1, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/796
https://github.com/root-project/root/pull/797:423,Performance,perform,performed,423,"1. With the CEF instead of http/https local scheme handler is used. Means, THttpServer used without opening real HTTP port. ; 2. Use provided CEF messaging for direct communication between ROOT application and JS code. This channel if bidirectional and replaces websocket, used with normal browser. Longpoll remains as fallback solution.; 3. Enable batch mode with the CEF. When root started with ""root -b"" flag, rendering performed in memory - no any window is created. Not really clear which graphical libraries required - seems to be Xorg is still need to be linked. ; 4. First draft for Canvas::SaveAs() method for image creation. Both SVG and PNG are supported, several others (BMP/JPEG) can be provided. Worked in the same way for batch and gui mode. ; 5. draw_v6.cxx macro from tutorial works both in gui and batch mode and show usage of new Canvas::SaveAs() method",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/797
https://github.com/root-project/root/pull/797:482,Usability,clear,clear,482,"1. With the CEF instead of http/https local scheme handler is used. Means, THttpServer used without opening real HTTP port. ; 2. Use provided CEF messaging for direct communication between ROOT application and JS code. This channel if bidirectional and replaces websocket, used with normal browser. Longpoll remains as fallback solution.; 3. Enable batch mode with the CEF. When root started with ""root -b"" flag, rendering performed in memory - no any window is created. Not really clear which graphical libraries required - seems to be Xorg is still need to be linked. ; 4. First draft for Canvas::SaveAs() method for image creation. Both SVG and PNG are supported, several others (BMP/JPEG) can be provided. Worked in the same way for batch and gui mode. ; 5. draw_v6.cxx macro from tutorial works both in gui and batch mode and show usage of new Canvas::SaveAs() method",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/797
https://github.com/root-project/root/pull/798:333,Availability,error,errors,333,"The two specializations for the relative_error functions were removed this [commit](https://github.com/root-project/root/commit/43aac3fb4bc5f215ac3cb7755791372f05a5da72) by @amadio. However, the; general function template does not protect against the division by values that are numerically close; to zero and lead to large relative errors.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/798
https://github.com/root-project/root/pull/799:722,Usability,simpl,simplest,722,"This adds functionality to directly parse and create normalized sums as `TF1` objects (as opposed to creating `TF1NormSum` objects and then `TF1` functions from those), when our formula is of the form `NSUM(f1, f2, ...)`. This constructor is also more convenient than that of `TF1NormSum` because we allow the user to use a formula directly as function (such as `x^2`). Examples:; * `TF1 *f = new TF1(""f"", ""NSUM([sg] * gaus, [bg] * expo)"")`; * `TF1 *f = new TF1(""f"", ""NSUM(.5 * expo, .5 * (x + 1)^2)"")`. Note that this code uses the constructor for `TF1NormSum` which parses a formula. The constructor using the vectors of formulas may have been a better choice, but I could not get that constructor to work, even for the simplest inputs (I suspect it might be buggy).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/799
https://github.com/root-project/root/pull/804:4,Integrability,interface,interfaces,4,"The interfaces of ROOT's `string_view` and `std::string_view` are; different (e.g., no `to_string()` member function in `std::string_view`). Reference: http://en.cppreference.com/w/cpp/header/string_view",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/804
https://github.com/root-project/root/pull/807:430,Safety,avoid,avoid,430,"We can't use the interpreter when generating a PCM as this would; generate AST nodes which then would end up in the module, which; is causing a long chain of modules (such as redefinitons as we; suddenly have the same cling warpper function multiple times). In this code path we seem to always have a number that we want; to convert to a string. So let's just use atol instead here if; the argument is just a number, which should avoid the issue with; the generated code. As we also now check if the input is a number, I added an assert; that verifies we only call atol when the string is actually a; number.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/807
https://github.com/root-project/root/pull/807:530,Testability,assert,assert,530,"We can't use the interpreter when generating a PCM as this would; generate AST nodes which then would end up in the module, which; is causing a long chain of modules (such as redefinitons as we; suddenly have the same cling warpper function multiple times). In this code path we seem to always have a number that we want; to convert to a string. So let's just use atol instead here if; the argument is just a number, which should avoid the issue with; the generated code. As we also now check if the input is a number, I added an assert; that verifies we only call atol when the string is actually a; number.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/807
https://github.com/root-project/root/pull/810:20,Performance,perform,perform,20,"Like with chromium, perform drawing without creation of real window.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/810
https://github.com/root-project/root/pull/811:202,Security,Access,Accessing,202,"When chunking and fitting the right amount of elements per chunk you; may end up with empty chunks at the end. This chunks will still consist; of N elements per chunk, but they will not be initialized. Accessing; them was a problem. Solved by reducing the number of chunks (not; allowing empty chunks)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/811
https://github.com/root-project/root/pull/812:88,Testability,test,test,88,- Fix TensorFlow backend for PyKeras (breaks with non-empty sys.argv in Python); - Make test cases compatible with Keras v1.x and v2.x API. This is a fix for [ROOT-8928](https://sft.its.cern.ch/jira/browse/ROOT-8928).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/812
https://github.com/root-project/root/pull/813:1090,Deployability,upgrade,upgrade,1090,This fixes that we often rebuild parts of ROOT by just doing simple git things. Before this change; we had this dependency on the header VCSRevision.h which is used by different parts of LLVM:; ```; interpreter/llvm/src/include/llvm/Support/VCSRevision.h:; input: CUSTOM_COMMAND; /home/teemperor/root/root-trunk2/.git/logs/HEAD <- Timestamp of this changes a lot!; /home/teemperor/root/root-trunk2/interpreter/llvm/src/cmake/modules/GenerateVersionFromCVS.cmake; outputs:; interpreter/llvm/src/include/llvm/Support/llvm_vcsrevision_h; interpreter/llvm/src/include/llvm/Support/CMakeFiles/llvm_vcsrevision_h; ```. After this change we no longer have the git head in here:. ```; teemperor@ftlserver ~/r/trunk-build2> ninja -t query interpreter/llvm/src/include/llvm/Support/VCSRevision.h; interpreter/llvm/src/include/llvm/Support/VCSRevision.h:; outputs:; interpreter/llvm/src/include/llvm/Support/CMakeFiles/llvm_vcsrevision_h; ```. I added two commits: One that fixes the current builds in a hacky way and one that is doing it properly but only goes into effect once we have the next LLVM upgrade (as the flag for configuring this is just added recently).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/813
https://github.com/root-project/root/pull/813:112,Integrability,depend,dependency,112,This fixes that we often rebuild parts of ROOT by just doing simple git things. Before this change; we had this dependency on the header VCSRevision.h which is used by different parts of LLVM:; ```; interpreter/llvm/src/include/llvm/Support/VCSRevision.h:; input: CUSTOM_COMMAND; /home/teemperor/root/root-trunk2/.git/logs/HEAD <- Timestamp of this changes a lot!; /home/teemperor/root/root-trunk2/interpreter/llvm/src/cmake/modules/GenerateVersionFromCVS.cmake; outputs:; interpreter/llvm/src/include/llvm/Support/llvm_vcsrevision_h; interpreter/llvm/src/include/llvm/Support/CMakeFiles/llvm_vcsrevision_h; ```. After this change we no longer have the git head in here:. ```; teemperor@ftlserver ~/r/trunk-build2> ninja -t query interpreter/llvm/src/include/llvm/Support/VCSRevision.h; interpreter/llvm/src/include/llvm/Support/VCSRevision.h:; outputs:; interpreter/llvm/src/include/llvm/Support/CMakeFiles/llvm_vcsrevision_h; ```. I added two commits: One that fixes the current builds in a hacky way and one that is doing it properly but only goes into effect once we have the next LLVM upgrade (as the flag for configuring this is just added recently).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/813
https://github.com/root-project/root/pull/813:1115,Modifiability,config,configuring,1115,This fixes that we often rebuild parts of ROOT by just doing simple git things. Before this change; we had this dependency on the header VCSRevision.h which is used by different parts of LLVM:; ```; interpreter/llvm/src/include/llvm/Support/VCSRevision.h:; input: CUSTOM_COMMAND; /home/teemperor/root/root-trunk2/.git/logs/HEAD <- Timestamp of this changes a lot!; /home/teemperor/root/root-trunk2/interpreter/llvm/src/cmake/modules/GenerateVersionFromCVS.cmake; outputs:; interpreter/llvm/src/include/llvm/Support/llvm_vcsrevision_h; interpreter/llvm/src/include/llvm/Support/CMakeFiles/llvm_vcsrevision_h; ```. After this change we no longer have the git head in here:. ```; teemperor@ftlserver ~/r/trunk-build2> ninja -t query interpreter/llvm/src/include/llvm/Support/VCSRevision.h; interpreter/llvm/src/include/llvm/Support/VCSRevision.h:; outputs:; interpreter/llvm/src/include/llvm/Support/CMakeFiles/llvm_vcsrevision_h; ```. I added two commits: One that fixes the current builds in a hacky way and one that is doing it properly but only goes into effect once we have the next LLVM upgrade (as the flag for configuring this is just added recently).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/813
https://github.com/root-project/root/pull/813:318,Testability,log,logs,318,This fixes that we often rebuild parts of ROOT by just doing simple git things. Before this change; we had this dependency on the header VCSRevision.h which is used by different parts of LLVM:; ```; interpreter/llvm/src/include/llvm/Support/VCSRevision.h:; input: CUSTOM_COMMAND; /home/teemperor/root/root-trunk2/.git/logs/HEAD <- Timestamp of this changes a lot!; /home/teemperor/root/root-trunk2/interpreter/llvm/src/cmake/modules/GenerateVersionFromCVS.cmake; outputs:; interpreter/llvm/src/include/llvm/Support/llvm_vcsrevision_h; interpreter/llvm/src/include/llvm/Support/CMakeFiles/llvm_vcsrevision_h; ```. After this change we no longer have the git head in here:. ```; teemperor@ftlserver ~/r/trunk-build2> ninja -t query interpreter/llvm/src/include/llvm/Support/VCSRevision.h; interpreter/llvm/src/include/llvm/Support/VCSRevision.h:; outputs:; interpreter/llvm/src/include/llvm/Support/CMakeFiles/llvm_vcsrevision_h; ```. I added two commits: One that fixes the current builds in a hacky way and one that is doing it properly but only goes into effect once we have the next LLVM upgrade (as the flag for configuring this is just added recently).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/813
https://github.com/root-project/root/pull/813:61,Usability,simpl,simple,61,This fixes that we often rebuild parts of ROOT by just doing simple git things. Before this change; we had this dependency on the header VCSRevision.h which is used by different parts of LLVM:; ```; interpreter/llvm/src/include/llvm/Support/VCSRevision.h:; input: CUSTOM_COMMAND; /home/teemperor/root/root-trunk2/.git/logs/HEAD <- Timestamp of this changes a lot!; /home/teemperor/root/root-trunk2/interpreter/llvm/src/cmake/modules/GenerateVersionFromCVS.cmake; outputs:; interpreter/llvm/src/include/llvm/Support/llvm_vcsrevision_h; interpreter/llvm/src/include/llvm/Support/CMakeFiles/llvm_vcsrevision_h; ```. After this change we no longer have the git head in here:. ```; teemperor@ftlserver ~/r/trunk-build2> ninja -t query interpreter/llvm/src/include/llvm/Support/VCSRevision.h; interpreter/llvm/src/include/llvm/Support/VCSRevision.h:; outputs:; interpreter/llvm/src/include/llvm/Support/CMakeFiles/llvm_vcsrevision_h; ```. I added two commits: One that fixes the current builds in a hacky way and one that is doing it properly but only goes into effect once we have the next LLVM upgrade (as the flag for configuring this is just added recently).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/813
https://github.com/root-project/root/pull/814:240,Deployability,update,updates,240,"TDataFrame's user guide uses the term ""column"" interchangeably with ""branch"". At the same time, ""column"" is preferred as it is more general and will still be appropriate when TDataFrame will read data formats other than ROOT's. This commit updates the user-facing method signatures and the method documentations to use preferably use ""column"". This commit also adds some minor improvements to method descriptions.; It introduces no functional changes.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/814
https://github.com/root-project/root/pull/814:18,Usability,guid,guide,18,"TDataFrame's user guide uses the term ""column"" interchangeably with ""branch"". At the same time, ""column"" is preferred as it is more general and will still be appropriate when TDataFrame will read data formats other than ROOT's. This commit updates the user-facing method signatures and the method documentations to use preferably use ""column"". This commit also adds some minor improvements to method descriptions.; It introduces no functional changes.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/814
https://github.com/root-project/root/pull/816:291,Testability,test,test,291,"The casting of the function to improve lookup didn't took; variadic functions into aspect, causing ABI issues when generating; the code for calling this function. This correctly appends the; annotation for a variadic function to the function type. This fixes the roottest-python-cling-cling test when compiling; with icc.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/816
https://github.com/root-project/root/pull/817:0,Deployability,Integrat,Integration,0,Integration of all different layers in one Deep Learning module.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/817
https://github.com/root-project/root/pull/817:0,Integrability,Integrat,Integration,0,Integration of all different layers in one Deep Learning module.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/817
https://github.com/root-project/root/pull/817:29,Modifiability,layers,layers,29,Integration of all different layers in one Deep Learning module.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/817
https://github.com/root-project/root/pull/817:48,Usability,Learn,Learning,48,Integration of all different layers in one Deep Learning module.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/817
https://github.com/root-project/root/pull/818:12,Deployability,Update,Update,12,"Now Canvas::Update() and Canvas::SaveAs() can be synchronous and asynchronous.; Sync mean method will block calling thread until completed. ; Async returns immediately and let continue script execution. . In both methods one can provide callback functions which invoked once method is completed. ; Makes only sense in async mode. Canvas::Modified() increments version counter, which used to control version delivered to each JS client. ; Canvas::IsModified() return false only if all clients have actual version of the canvas. Canvas::Show() now can be provided with ""where"" parameter, which identifies how canvas should be shown. Parameter can be browser program name or some predefined values: ""cef"", ""qt5"", ""browser"". First steps are done to correctly cleanup connection to closed/crashed clients.; Probably, watchdog timer should be installed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/818
https://github.com/root-project/root/pull/818:837,Deployability,install,installed,837,"Now Canvas::Update() and Canvas::SaveAs() can be synchronous and asynchronous.; Sync mean method will block calling thread until completed. ; Async returns immediately and let continue script execution. . In both methods one can provide callback functions which invoked once method is completed. ; Makes only sense in async mode. Canvas::Modified() increments version counter, which used to control version delivered to each JS client. ; Canvas::IsModified() return false only if all clients have actual version of the canvas. Canvas::Show() now can be provided with ""where"" parameter, which identifies how canvas should be shown. Parameter can be browser program name or some predefined values: ""cef"", ""qt5"", ""browser"". First steps are done to correctly cleanup connection to closed/crashed clients.; Probably, watchdog timer should be installed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/818
https://github.com/root-project/root/pull/821:123,Modifiability,refactor,refactoring,123,"The code before the refatoring parssed the ${sources} to the; dictionary linking, but we forgot to handle this during the; refactoring.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/821
https://github.com/root-project/root/pull/822:56,Testability,test,tests,56,Commit ac0de75b8 introduced this typo which breaks some tests.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/822
https://github.com/root-project/root/pull/825:370,Availability,alive,alive,370,"`from ROOT import *` leads to a segmentation violation when used with Python 3.6. One could try fixing it instead of disabling it but the code which is used to install the lookup handler in the module `RootModule::SetRootLazyLookup` depends on internal CPython implementation details of the dict class which are not part of the public API. As a consequence keeping this alive will lead to very; fragile code, require continuous effort to adapt to internal changes and cause a lot of #ifdef handling. (as a matter of fact, Python 3.7 would probably already require new changes to this code already). . Also there's a statement in the bug report that `from ROOT import *` is broken in Python 3 so I don't understand why it's not disabled as it will only confuse users: https://sft.its.cern.ch/jira/browse/ROOT-8931. As such I would propose to instead have a clear error message that `from ROOT import *` does not work. This pr adds an `ImportError` which is easy to handle but cannot be just ignored by the user.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/825
https://github.com/root-project/root/pull/825:862,Availability,error,error,862,"`from ROOT import *` leads to a segmentation violation when used with Python 3.6. One could try fixing it instead of disabling it but the code which is used to install the lookup handler in the module `RootModule::SetRootLazyLookup` depends on internal CPython implementation details of the dict class which are not part of the public API. As a consequence keeping this alive will lead to very; fragile code, require continuous effort to adapt to internal changes and cause a lot of #ifdef handling. (as a matter of fact, Python 3.7 would probably already require new changes to this code already). . Also there's a statement in the bug report that `from ROOT import *` is broken in Python 3 so I don't understand why it's not disabled as it will only confuse users: https://sft.its.cern.ch/jira/browse/ROOT-8931. As such I would propose to instead have a clear error message that `from ROOT import *` does not work. This pr adds an `ImportError` which is easy to handle but cannot be just ignored by the user.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/825
https://github.com/root-project/root/pull/825:160,Deployability,install,install,160,"`from ROOT import *` leads to a segmentation violation when used with Python 3.6. One could try fixing it instead of disabling it but the code which is used to install the lookup handler in the module `RootModule::SetRootLazyLookup` depends on internal CPython implementation details of the dict class which are not part of the public API. As a consequence keeping this alive will lead to very; fragile code, require continuous effort to adapt to internal changes and cause a lot of #ifdef handling. (as a matter of fact, Python 3.7 would probably already require new changes to this code already). . Also there's a statement in the bug report that `from ROOT import *` is broken in Python 3 so I don't understand why it's not disabled as it will only confuse users: https://sft.its.cern.ch/jira/browse/ROOT-8931. As such I would propose to instead have a clear error message that `from ROOT import *` does not work. This pr adds an `ImportError` which is easy to handle but cannot be just ignored by the user.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/825
https://github.com/root-project/root/pull/825:417,Deployability,continuous,continuous,417,"`from ROOT import *` leads to a segmentation violation when used with Python 3.6. One could try fixing it instead of disabling it but the code which is used to install the lookup handler in the module `RootModule::SetRootLazyLookup` depends on internal CPython implementation details of the dict class which are not part of the public API. As a consequence keeping this alive will lead to very; fragile code, require continuous effort to adapt to internal changes and cause a lot of #ifdef handling. (as a matter of fact, Python 3.7 would probably already require new changes to this code already). . Also there's a statement in the bug report that `from ROOT import *` is broken in Python 3 so I don't understand why it's not disabled as it will only confuse users: https://sft.its.cern.ch/jira/browse/ROOT-8931. As such I would propose to instead have a clear error message that `from ROOT import *` does not work. This pr adds an `ImportError` which is easy to handle but cannot be just ignored by the user.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/825
https://github.com/root-project/root/pull/825:438,Energy Efficiency,adapt,adapt,438,"`from ROOT import *` leads to a segmentation violation when used with Python 3.6. One could try fixing it instead of disabling it but the code which is used to install the lookup handler in the module `RootModule::SetRootLazyLookup` depends on internal CPython implementation details of the dict class which are not part of the public API. As a consequence keeping this alive will lead to very; fragile code, require continuous effort to adapt to internal changes and cause a lot of #ifdef handling. (as a matter of fact, Python 3.7 would probably already require new changes to this code already). . Also there's a statement in the bug report that `from ROOT import *` is broken in Python 3 so I don't understand why it's not disabled as it will only confuse users: https://sft.its.cern.ch/jira/browse/ROOT-8931. As such I would propose to instead have a clear error message that `from ROOT import *` does not work. This pr adds an `ImportError` which is easy to handle but cannot be just ignored by the user.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/825
https://github.com/root-project/root/pull/825:233,Integrability,depend,depends,233,"`from ROOT import *` leads to a segmentation violation when used with Python 3.6. One could try fixing it instead of disabling it but the code which is used to install the lookup handler in the module `RootModule::SetRootLazyLookup` depends on internal CPython implementation details of the dict class which are not part of the public API. As a consequence keeping this alive will lead to very; fragile code, require continuous effort to adapt to internal changes and cause a lot of #ifdef handling. (as a matter of fact, Python 3.7 would probably already require new changes to this code already). . Also there's a statement in the bug report that `from ROOT import *` is broken in Python 3 so I don't understand why it's not disabled as it will only confuse users: https://sft.its.cern.ch/jira/browse/ROOT-8931. As such I would propose to instead have a clear error message that `from ROOT import *` does not work. This pr adds an `ImportError` which is easy to handle but cannot be just ignored by the user.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/825
https://github.com/root-project/root/pull/825:868,Integrability,message,message,868,"`from ROOT import *` leads to a segmentation violation when used with Python 3.6. One could try fixing it instead of disabling it but the code which is used to install the lookup handler in the module `RootModule::SetRootLazyLookup` depends on internal CPython implementation details of the dict class which are not part of the public API. As a consequence keeping this alive will lead to very; fragile code, require continuous effort to adapt to internal changes and cause a lot of #ifdef handling. (as a matter of fact, Python 3.7 would probably already require new changes to this code already). . Also there's a statement in the bug report that `from ROOT import *` is broken in Python 3 so I don't understand why it's not disabled as it will only confuse users: https://sft.its.cern.ch/jira/browse/ROOT-8931. As such I would propose to instead have a clear error message that `from ROOT import *` does not work. This pr adds an `ImportError` which is easy to handle but cannot be just ignored by the user.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/825
https://github.com/root-project/root/pull/825:438,Modifiability,adapt,adapt,438,"`from ROOT import *` leads to a segmentation violation when used with Python 3.6. One could try fixing it instead of disabling it but the code which is used to install the lookup handler in the module `RootModule::SetRootLazyLookup` depends on internal CPython implementation details of the dict class which are not part of the public API. As a consequence keeping this alive will lead to very; fragile code, require continuous effort to adapt to internal changes and cause a lot of #ifdef handling. (as a matter of fact, Python 3.7 would probably already require new changes to this code already). . Also there's a statement in the bug report that `from ROOT import *` is broken in Python 3 so I don't understand why it's not disabled as it will only confuse users: https://sft.its.cern.ch/jira/browse/ROOT-8931. As such I would propose to instead have a clear error message that `from ROOT import *` does not work. This pr adds an `ImportError` which is easy to handle but cannot be just ignored by the user.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/825
https://github.com/root-project/root/pull/825:856,Usability,clear,clear,856,"`from ROOT import *` leads to a segmentation violation when used with Python 3.6. One could try fixing it instead of disabling it but the code which is used to install the lookup handler in the module `RootModule::SetRootLazyLookup` depends on internal CPython implementation details of the dict class which are not part of the public API. As a consequence keeping this alive will lead to very; fragile code, require continuous effort to adapt to internal changes and cause a lot of #ifdef handling. (as a matter of fact, Python 3.7 would probably already require new changes to this code already). . Also there's a statement in the bug report that `from ROOT import *` is broken in Python 3 so I don't understand why it's not disabled as it will only confuse users: https://sft.its.cern.ch/jira/browse/ROOT-8931. As such I would propose to instead have a clear error message that `from ROOT import *` does not work. This pr adds an `ImportError` which is easy to handle but cannot be just ignored by the user.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/825
https://github.com/root-project/root/pull/827:5,Deployability,patch,patch,5,This patch allows to tell vectorized from scalar evaluations and will fix the multidimensional scalar evaluation of a vectorized TF1 on non-SIMD data.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/827
https://github.com/root-project/root/pull/828:292,Usability,resume,resumed,292,"When processing a TTree with TTreeProcessorMT, each thread creates and uses its own TTreeView (by using a TThreadedObject<TTreeView>). . Until now, in the case of interleaved execution of tasks, the second task could overwrite the first's TFile and TTree, causing crashes when the first task resumed execution. This PR modifies TTreeView so that it supports several tasks opening and using different TFiles at the same time, solving the issue described above.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/828
https://github.com/root-project/root/pull/830:25,Deployability,integrat,integration,25,"This PR improves VecCore integration into ROOT. Before we copied all VecCore and Vc headers into the build directory, since rootcling did not get the right includes when Vc or VecCore were builtin. Now the right includes are propagates by calling `set_property()` with the necessary include directories. Ideally, in the future we should take the includes not from the `DIRECTORY` property, but from the target dependencies for each subcomponent.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/830
https://github.com/root-project/root/pull/830:25,Integrability,integrat,integration,25,"This PR improves VecCore integration into ROOT. Before we copied all VecCore and Vc headers into the build directory, since rootcling did not get the right includes when Vc or VecCore were builtin. Now the right includes are propagates by calling `set_property()` with the necessary include directories. Ideally, in the future we should take the includes not from the `DIRECTORY` property, but from the target dependencies for each subcomponent.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/830
https://github.com/root-project/root/pull/830:410,Integrability,depend,dependencies,410,"This PR improves VecCore integration into ROOT. Before we copied all VecCore and Vc headers into the build directory, since rootcling did not get the right includes when Vc or VecCore were builtin. Now the right includes are propagates by calling `set_property()` with the necessary include directories. Ideally, in the future we should take the includes not from the `DIRECTORY` property, but from the target dependencies for each subcomponent.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/830
https://github.com/root-project/root/pull/831:207,Availability,fault,faulty,207,"Since we enabled warnings by default in rootcling, which pointed; out a bunch of warnings in the code base, we also set rootcling; into a mode in which it is unable to ever fail. The reason for this is this faulty if statement. If we enable warnings,; we set the errorIgnoreLevel to kWarning. But this if statement only records; any errors if the errorIgnoreLevel is NOT kWarning (which is between; kThrowOnWarning and kError). The new if statements only checks if the the printed message is an error; or higher (which would include any kind of fatal error). If the errorIgnoreLevel; is set higher, we already correctly filter this at the start of the method; where we return on filtered messages.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/831
https://github.com/root-project/root/pull/831:263,Availability,error,errorIgnoreLevel,263,"Since we enabled warnings by default in rootcling, which pointed; out a bunch of warnings in the code base, we also set rootcling; into a mode in which it is unable to ever fail. The reason for this is this faulty if statement. If we enable warnings,; we set the errorIgnoreLevel to kWarning. But this if statement only records; any errors if the errorIgnoreLevel is NOT kWarning (which is between; kThrowOnWarning and kError). The new if statements only checks if the the printed message is an error; or higher (which would include any kind of fatal error). If the errorIgnoreLevel; is set higher, we already correctly filter this at the start of the method; where we return on filtered messages.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/831
https://github.com/root-project/root/pull/831:333,Availability,error,errors,333,"Since we enabled warnings by default in rootcling, which pointed; out a bunch of warnings in the code base, we also set rootcling; into a mode in which it is unable to ever fail. The reason for this is this faulty if statement. If we enable warnings,; we set the errorIgnoreLevel to kWarning. But this if statement only records; any errors if the errorIgnoreLevel is NOT kWarning (which is between; kThrowOnWarning and kError). The new if statements only checks if the the printed message is an error; or higher (which would include any kind of fatal error). If the errorIgnoreLevel; is set higher, we already correctly filter this at the start of the method; where we return on filtered messages.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/831
https://github.com/root-project/root/pull/831:347,Availability,error,errorIgnoreLevel,347,"Since we enabled warnings by default in rootcling, which pointed; out a bunch of warnings in the code base, we also set rootcling; into a mode in which it is unable to ever fail. The reason for this is this faulty if statement. If we enable warnings,; we set the errorIgnoreLevel to kWarning. But this if statement only records; any errors if the errorIgnoreLevel is NOT kWarning (which is between; kThrowOnWarning and kError). The new if statements only checks if the the printed message is an error; or higher (which would include any kind of fatal error). If the errorIgnoreLevel; is set higher, we already correctly filter this at the start of the method; where we return on filtered messages.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/831
https://github.com/root-project/root/pull/831:495,Availability,error,error,495,"Since we enabled warnings by default in rootcling, which pointed; out a bunch of warnings in the code base, we also set rootcling; into a mode in which it is unable to ever fail. The reason for this is this faulty if statement. If we enable warnings,; we set the errorIgnoreLevel to kWarning. But this if statement only records; any errors if the errorIgnoreLevel is NOT kWarning (which is between; kThrowOnWarning and kError). The new if statements only checks if the the printed message is an error; or higher (which would include any kind of fatal error). If the errorIgnoreLevel; is set higher, we already correctly filter this at the start of the method; where we return on filtered messages.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/831
https://github.com/root-project/root/pull/831:551,Availability,error,error,551,"Since we enabled warnings by default in rootcling, which pointed; out a bunch of warnings in the code base, we also set rootcling; into a mode in which it is unable to ever fail. The reason for this is this faulty if statement. If we enable warnings,; we set the errorIgnoreLevel to kWarning. But this if statement only records; any errors if the errorIgnoreLevel is NOT kWarning (which is between; kThrowOnWarning and kError). The new if statements only checks if the the printed message is an error; or higher (which would include any kind of fatal error). If the errorIgnoreLevel; is set higher, we already correctly filter this at the start of the method; where we return on filtered messages.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/831
https://github.com/root-project/root/pull/831:566,Availability,error,errorIgnoreLevel,566,"Since we enabled warnings by default in rootcling, which pointed; out a bunch of warnings in the code base, we also set rootcling; into a mode in which it is unable to ever fail. The reason for this is this faulty if statement. If we enable warnings,; we set the errorIgnoreLevel to kWarning. But this if statement only records; any errors if the errorIgnoreLevel is NOT kWarning (which is between; kThrowOnWarning and kError). The new if statements only checks if the the printed message is an error; or higher (which would include any kind of fatal error). If the errorIgnoreLevel; is set higher, we already correctly filter this at the start of the method; where we return on filtered messages.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/831
https://github.com/root-project/root/pull/831:481,Integrability,message,message,481,"Since we enabled warnings by default in rootcling, which pointed; out a bunch of warnings in the code base, we also set rootcling; into a mode in which it is unable to ever fail. The reason for this is this faulty if statement. If we enable warnings,; we set the errorIgnoreLevel to kWarning. But this if statement only records; any errors if the errorIgnoreLevel is NOT kWarning (which is between; kThrowOnWarning and kError). The new if statements only checks if the the printed message is an error; or higher (which would include any kind of fatal error). If the errorIgnoreLevel; is set higher, we already correctly filter this at the start of the method; where we return on filtered messages.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/831
https://github.com/root-project/root/pull/831:688,Integrability,message,messages,688,"Since we enabled warnings by default in rootcling, which pointed; out a bunch of warnings in the code base, we also set rootcling; into a mode in which it is unable to ever fail. The reason for this is this faulty if statement. If we enable warnings,; we set the errorIgnoreLevel to kWarning. But this if statement only records; any errors if the errorIgnoreLevel is NOT kWarning (which is between; kThrowOnWarning and kError). The new if statements only checks if the the printed message is an error; or higher (which would include any kind of fatal error). If the errorIgnoreLevel; is set higher, we already correctly filter this at the start of the method; where we return on filtered messages.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/831
https://github.com/root-project/root/pull/833:16,Performance,race condition,race condition,16,"This PR fixes a race condition in which a TTreeReader and its; TTreeReaderValues could be deleted concurrently, possibly leading to use-after-deletes:; Thread #1) a task ends and pushes back processing slot; Thread #2) a task starts and overwrites thread-local TTreeReaderValues; Thread #1) first task deletes TTreeReader",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/833
https://github.com/root-project/root/pull/833:98,Performance,concurren,concurrently,98,"This PR fixes a race condition in which a TTreeReader and its; TTreeReaderValues could be deleted concurrently, possibly leading to use-after-deletes:; Thread #1) a task ends and pushes back processing slot; Thread #2) a task starts and overwrites thread-local TTreeReaderValues; Thread #1) first task deletes TTreeReader",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/833
https://github.com/root-project/root/pull/835:137,Deployability,patch,patch,137,"This PR includes the commits of; * PR #833 ; * a fix (dependent on #833) for task-unsafety in TDataFrame's TColumnValue; * PR #828 ; * a patch for task-unsafety in TDataFrame's thread-slot distribution by @dpiparo (commit 2787af2). If we want to push these commits little by little, PR #833 and PR #828 should be merged first, then I can open a third PR with the second (and fourth?) fix.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/835
https://github.com/root-project/root/pull/835:54,Integrability,depend,dependent,54,"This PR includes the commits of; * PR #833 ; * a fix (dependent on #833) for task-unsafety in TDataFrame's TColumnValue; * PR #828 ; * a patch for task-unsafety in TDataFrame's thread-slot distribution by @dpiparo (commit 2787af2). If we want to push these commits little by little, PR #833 and PR #828 should be merged first, then I can open a third PR with the second (and fourth?) fix.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/835
https://github.com/root-project/root/pull/835:82,Safety,unsafe,unsafety,82,"This PR includes the commits of; * PR #833 ; * a fix (dependent on #833) for task-unsafety in TDataFrame's TColumnValue; * PR #828 ; * a patch for task-unsafety in TDataFrame's thread-slot distribution by @dpiparo (commit 2787af2). If we want to push these commits little by little, PR #833 and PR #828 should be merged first, then I can open a third PR with the second (and fourth?) fix.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/835
https://github.com/root-project/root/pull/835:152,Safety,unsafe,unsafety,152,"This PR includes the commits of; * PR #833 ; * a fix (dependent on #833) for task-unsafety in TDataFrame's TColumnValue; * PR #828 ; * a patch for task-unsafety in TDataFrame's thread-slot distribution by @dpiparo (commit 2787af2). If we want to push these commits little by little, PR #833 and PR #828 should be merged first, then I can open a third PR with the second (and fourth?) fix.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/835
https://github.com/root-project/root/pull/836:90,Testability,test,test,90,"Due to a previous change in the gradient boosted DT the parameters used in the stressTMVA test case resulted in a ROC score (0.87) that was just below threshold (0.88). This change modifies the shrinkage to be 0.1 instead of 0.3. Both choices are reasoable ""black-box"" parameters meaning it's a very limited tuning.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/836
https://github.com/root-project/root/pull/837:358,Deployability,update,update,358,"This fixes a race condition in which a TTreeReader and its; TTreeReaderValues could be deleted concurrently:; Thread #1) a task ends and pushes back processing slot; Thread #2) a task starts and overwrites thread-local TTreeReaderValues; Thread #1) first task deletes TTreeReader. I have not run a stress-test on this PR yet, to check for rare crashes. Will update as soon as I do.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/837
https://github.com/root-project/root/pull/837:13,Performance,race condition,race condition,13,"This fixes a race condition in which a TTreeReader and its; TTreeReaderValues could be deleted concurrently:; Thread #1) a task ends and pushes back processing slot; Thread #2) a task starts and overwrites thread-local TTreeReaderValues; Thread #1) first task deletes TTreeReader. I have not run a stress-test on this PR yet, to check for rare crashes. Will update as soon as I do.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/837
https://github.com/root-project/root/pull/837:95,Performance,concurren,concurrently,95,"This fixes a race condition in which a TTreeReader and its; TTreeReaderValues could be deleted concurrently:; Thread #1) a task ends and pushes back processing slot; Thread #2) a task starts and overwrites thread-local TTreeReaderValues; Thread #1) first task deletes TTreeReader. I have not run a stress-test on this PR yet, to check for rare crashes. Will update as soon as I do.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/837
https://github.com/root-project/root/pull/837:305,Testability,test,test,305,"This fixes a race condition in which a TTreeReader and its; TTreeReaderValues could be deleted concurrently:; Thread #1) a task ends and pushes back processing slot; Thread #2) a task starts and overwrites thread-local TTreeReaderValues; Thread #1) first task deletes TTreeReader. I have not run a stress-test on this PR yet, to check for rare crashes. Will update as soon as I do.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/837
https://github.com/root-project/root/pull/839:176,Usability,simpl,simple,176,"Mostly, this is a set of links to other, existing documentation. However, the GitHub web UI will recommend developers review this file before submitting a pull-request. It's a simple nudge to ""do the right thing"".",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/839
https://github.com/root-project/root/pull/842:254,Deployability,patch,patch,254,"Currently we rebuilt LTO everytime you rerun cmake, as CMake; touches the vcsrevision file that LTO depends on. Make isn't; smart enough to realise it's still just an empty file, so it; retriggers the LTO compilations whenever you run CMake. Again, this patch will be obsolete on the next LLVM upgrade; as this CMake code is refactored upstream.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/842
https://github.com/root-project/root/pull/842:294,Deployability,upgrade,upgrade,294,"Currently we rebuilt LTO everytime you rerun cmake, as CMake; touches the vcsrevision file that LTO depends on. Make isn't; smart enough to realise it's still just an empty file, so it; retriggers the LTO compilations whenever you run CMake. Again, this patch will be obsolete on the next LLVM upgrade; as this CMake code is refactored upstream.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/842
https://github.com/root-project/root/pull/842:100,Integrability,depend,depends,100,"Currently we rebuilt LTO everytime you rerun cmake, as CMake; touches the vcsrevision file that LTO depends on. Make isn't; smart enough to realise it's still just an empty file, so it; retriggers the LTO compilations whenever you run CMake. Again, this patch will be obsolete on the next LLVM upgrade; as this CMake code is refactored upstream.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/842
https://github.com/root-project/root/pull/842:325,Modifiability,refactor,refactored,325,"Currently we rebuilt LTO everytime you rerun cmake, as CMake; touches the vcsrevision file that LTO depends on. Make isn't; smart enough to realise it's still just an empty file, so it; retriggers the LTO compilations whenever you run CMake. Again, this patch will be obsolete on the next LLVM upgrade; as this CMake code is refactored upstream.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/842
https://github.com/root-project/root/pull/843:117,Modifiability,maintainab,maintainable,117,"This splits up the file test/stressHistogram.cxx into smaller, more independent files using Google Test that is more maintainable than the existing code.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/843
https://github.com/root-project/root/pull/843:24,Testability,test,test,24,"This splits up the file test/stressHistogram.cxx into smaller, more independent files using Google Test that is more maintainable than the existing code.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/843
https://github.com/root-project/root/pull/843:99,Testability,Test,Test,99,"This splits up the file test/stressHistogram.cxx into smaller, more independent files using Google Test that is more maintainable than the existing code.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/843
https://github.com/root-project/root/pull/844:78,Modifiability,variab,variables,78,"Right now OS X is recognized standard UNIX and OS X, so we actually; pass two variables to the dictgen script, which isn't the idea of this; variable. We only pass OS X now here and on other UNIX systems we pass; only UNIX.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/844
https://github.com/root-project/root/pull/844:141,Modifiability,variab,variable,141,"Right now OS X is recognized standard UNIX and OS X, so we actually; pass two variables to the dictgen script, which isn't the idea of this; variable. We only pass OS X now here and on other UNIX systems we pass; only UNIX.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/844
https://github.com/root-project/root/pull/845:65,Security,access,access,65,"This fixes the OS X warnings like this one:. ld: warning: direct access in function 'XXX' from file; 'libLLVMScalarOpts.a(NewGVN.cpp.o)' to global weak; symbol 'llvm::ReverseIterate<bool>::value' from file; 'interpreter/llvm/src/lib/libclingUtils.a(AST.cpp.o)'; means the weak symbol cannot be overridden; at runtime. This was likely caused by different translation; units being compiled with different visibility settings. I assume it's a compiler bug and it maybe fixes itself in LLVM 6.0; as this is quite recently introduced code, so let's go with the; most conservative fix and just disable this validation layer in LLVM; (that we don't use from what I can see).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/845
https://github.com/root-project/root/pull/845:601,Security,validat,validation,601,"This fixes the OS X warnings like this one:. ld: warning: direct access in function 'XXX' from file; 'libLLVMScalarOpts.a(NewGVN.cpp.o)' to global weak; symbol 'llvm::ReverseIterate<bool>::value' from file; 'interpreter/llvm/src/lib/libclingUtils.a(AST.cpp.o)'; means the weak symbol cannot be overridden; at runtime. This was likely caused by different translation; units being compiled with different visibility settings. I assume it's a compiler bug and it maybe fixes itself in LLVM 6.0; as this is quite recently introduced code, so let's go with the; most conservative fix and just disable this validation layer in LLVM; (that we don't use from what I can see).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/845
https://github.com/root-project/root/pull/846:18,Deployability,integrat,integrates,18,"This pull request integrates the `TF1Convolution` object into `TF1` so that one can directly create a `TF1` with a convolution in it. The syntax to construct such a convolution is:; `new TF1(""f"", ""CONV(f1, f2)"")`; Note that convolutions can be nested with each other and `NSUM`s. Also, if you are helping me merge, please note that this pull request contains within it the `TF1NormSum` code from PR #799. . **Edit:** Due to problems with the rebase, this PR has been closed. Please see PR #853 instead.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/846
https://github.com/root-project/root/pull/846:18,Integrability,integrat,integrates,18,"This pull request integrates the `TF1Convolution` object into `TF1` so that one can directly create a `TF1` with a convolution in it. The syntax to construct such a convolution is:; `new TF1(""f"", ""CONV(f1, f2)"")`; Note that convolutions can be nested with each other and `NSUM`s. Also, if you are helping me merge, please note that this pull request contains within it the `TF1NormSum` code from PR #799. . **Edit:** Due to problems with the rebase, this PR has been closed. Please see PR #853 instead.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/846
https://github.com/root-project/root/pull/851:93,Deployability,integrat,integration,93,"Creating a new pull request since I force-pushed to the old branch. This PR improves VecCore integration into ROOT. Before we copied all VecCore and Vc headers into the build directory, since rootcling did not get the right includes when Vc or VecCore were builtin. Now the right includes are propagates by calling set_property() with the necessary include directories. Ideally, in the future we should take the includes not from the DIRECTORY property, but from the target dependencies for each subcomponent.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/851
https://github.com/root-project/root/pull/851:93,Integrability,integrat,integration,93,"Creating a new pull request since I force-pushed to the old branch. This PR improves VecCore integration into ROOT. Before we copied all VecCore and Vc headers into the build directory, since rootcling did not get the right includes when Vc or VecCore were builtin. Now the right includes are propagates by calling set_property() with the necessary include directories. Ideally, in the future we should take the includes not from the DIRECTORY property, but from the target dependencies for each subcomponent.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/851
https://github.com/root-project/root/pull/851:474,Integrability,depend,dependencies,474,"Creating a new pull request since I force-pushed to the old branch. This PR improves VecCore integration into ROOT. Before we copied all VecCore and Vc headers into the build directory, since rootcling did not get the right includes when Vc or VecCore were builtin. Now the right includes are propagates by calling set_property() with the necessary include directories. Ideally, in the future we should take the includes not from the DIRECTORY property, but from the target dependencies for each subcomponent.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/851
https://github.com/root-project/root/pull/853:18,Deployability,integrat,integrates,18,"This pull request integrates the `TF1Convolution` object into `TF1` so that one can directly create a `TF1` with a convolution in it. The syntax to construct such a convolution is:; `new TF1(""f"", ""CONV(f1, f2)"")`; Convolutions can also be nested with each other and `NSUM`s. Note: this is the corrected version of PR #846.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/853
https://github.com/root-project/root/pull/853:18,Integrability,integrat,integrates,18,"This pull request integrates the `TF1Convolution` object into `TF1` so that one can directly create a `TF1` with a convolution in it. The syntax to construct such a convolution is:; `new TF1(""f"", ""CONV(f1, f2)"")`; Convolutions can also be nested with each other and `NSUM`s. Note: this is the corrected version of PR #846.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/853
https://github.com/root-project/root/pull/855:25,Testability,test,testing,25,This PR is a part of LZ4 testing,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/855
https://github.com/root-project/root/pull/856:0,Testability,Test,Test,0,"Test PR, do not merge.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/856
https://github.com/root-project/root/pull/857:56,Usability,intuit,intuitive,56,"This pull request makes the ordering of parameters more intuitive. In particular, parameters whose names begin with a 'p' will only be considered numeric if followed by a number, and otherwise will be sorted in regular alphabetical order (so now [phi] will come after [alpha]). It is especially important to have an intuitive ordering of parameters, since we will be introducing syntax to specify parameters positionally.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/857
https://github.com/root-project/root/pull/857:316,Usability,intuit,intuitive,316,"This pull request makes the ordering of parameters more intuitive. In particular, parameters whose names begin with a 'p' will only be considered numeric if followed by a number, and otherwise will be sorted in regular alphabetical order (so now [phi] will come after [alpha]). It is especially important to have an intuitive ordering of parameters, since we will be introducing syntax to specify parameters positionally.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/857
https://github.com/root-project/root/pull/858:71,Modifiability,Variab,Variable,71,"Mulltiprocessing of Hyper Parameter Optimisation, Cross Validation and Variable Importance",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/858
https://github.com/root-project/root/pull/858:56,Security,Validat,Validation,56,"Mulltiprocessing of Hyper Parameter Optimisation, Cross Validation and Variable Importance",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/858
https://github.com/root-project/root/pull/859:46,Availability,fault,faulty,46,Technically this is not revert because of the faulty merge commit.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/859
https://github.com/root-project/root/pull/860:96,Modifiability,variab,variables,96,"This pull request allows one to use user-defined (and some predefined) functions with different variables and/or parameters from what was given in the original definition. For example, a function originally defined on variable `x` with parameter `[0]` can now easily be applied to variable `y` with parameter `[alpha]` as part of another function definition. The syntax for the `TFormula` is as follows:; * `f(var0, var1, var2, ..., param0, param1, param2, ...)`. Furthermore, this PR introduces a few shortcuts:; * The syntax `[n..m]` for ranges of numbered parameters (for example, `[1..3]` expands to `[1],[2],[3]`); * To simply replace/rename parameters, the variables may be omitted; * Otherwise, if redefining variables, the parameters may be omitted (except, of course, if substituting them all for parameters if the numbers of parameters and variables are equal). This PR supports the nesting of functions (but still not recursive definitions!).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/860
https://github.com/root-project/root/pull/860:218,Modifiability,variab,variable,218,"This pull request allows one to use user-defined (and some predefined) functions with different variables and/or parameters from what was given in the original definition. For example, a function originally defined on variable `x` with parameter `[0]` can now easily be applied to variable `y` with parameter `[alpha]` as part of another function definition. The syntax for the `TFormula` is as follows:; * `f(var0, var1, var2, ..., param0, param1, param2, ...)`. Furthermore, this PR introduces a few shortcuts:; * The syntax `[n..m]` for ranges of numbered parameters (for example, `[1..3]` expands to `[1],[2],[3]`); * To simply replace/rename parameters, the variables may be omitted; * Otherwise, if redefining variables, the parameters may be omitted (except, of course, if substituting them all for parameters if the numbers of parameters and variables are equal). This PR supports the nesting of functions (but still not recursive definitions!).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/860
https://github.com/root-project/root/pull/860:281,Modifiability,variab,variable,281,"This pull request allows one to use user-defined (and some predefined) functions with different variables and/or parameters from what was given in the original definition. For example, a function originally defined on variable `x` with parameter `[0]` can now easily be applied to variable `y` with parameter `[alpha]` as part of another function definition. The syntax for the `TFormula` is as follows:; * `f(var0, var1, var2, ..., param0, param1, param2, ...)`. Furthermore, this PR introduces a few shortcuts:; * The syntax `[n..m]` for ranges of numbered parameters (for example, `[1..3]` expands to `[1],[2],[3]`); * To simply replace/rename parameters, the variables may be omitted; * Otherwise, if redefining variables, the parameters may be omitted (except, of course, if substituting them all for parameters if the numbers of parameters and variables are equal). This PR supports the nesting of functions (but still not recursive definitions!).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/860
https://github.com/root-project/root/pull/860:663,Modifiability,variab,variables,663,"This pull request allows one to use user-defined (and some predefined) functions with different variables and/or parameters from what was given in the original definition. For example, a function originally defined on variable `x` with parameter `[0]` can now easily be applied to variable `y` with parameter `[alpha]` as part of another function definition. The syntax for the `TFormula` is as follows:; * `f(var0, var1, var2, ..., param0, param1, param2, ...)`. Furthermore, this PR introduces a few shortcuts:; * The syntax `[n..m]` for ranges of numbered parameters (for example, `[1..3]` expands to `[1],[2],[3]`); * To simply replace/rename parameters, the variables may be omitted; * Otherwise, if redefining variables, the parameters may be omitted (except, of course, if substituting them all for parameters if the numbers of parameters and variables are equal). This PR supports the nesting of functions (but still not recursive definitions!).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/860
https://github.com/root-project/root/pull/860:716,Modifiability,variab,variables,716,"This pull request allows one to use user-defined (and some predefined) functions with different variables and/or parameters from what was given in the original definition. For example, a function originally defined on variable `x` with parameter `[0]` can now easily be applied to variable `y` with parameter `[alpha]` as part of another function definition. The syntax for the `TFormula` is as follows:; * `f(var0, var1, var2, ..., param0, param1, param2, ...)`. Furthermore, this PR introduces a few shortcuts:; * The syntax `[n..m]` for ranges of numbered parameters (for example, `[1..3]` expands to `[1],[2],[3]`); * To simply replace/rename parameters, the variables may be omitted; * Otherwise, if redefining variables, the parameters may be omitted (except, of course, if substituting them all for parameters if the numbers of parameters and variables are equal). This PR supports the nesting of functions (but still not recursive definitions!).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/860
https://github.com/root-project/root/pull/860:850,Modifiability,variab,variables,850,"This pull request allows one to use user-defined (and some predefined) functions with different variables and/or parameters from what was given in the original definition. For example, a function originally defined on variable `x` with parameter `[0]` can now easily be applied to variable `y` with parameter `[alpha]` as part of another function definition. The syntax for the `TFormula` is as follows:; * `f(var0, var1, var2, ..., param0, param1, param2, ...)`. Furthermore, this PR introduces a few shortcuts:; * The syntax `[n..m]` for ranges of numbered parameters (for example, `[1..3]` expands to `[1],[2],[3]`); * To simply replace/rename parameters, the variables may be omitted; * Otherwise, if redefining variables, the parameters may be omitted (except, of course, if substituting them all for parameters if the numbers of parameters and variables are equal). This PR supports the nesting of functions (but still not recursive definitions!).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/860
https://github.com/root-project/root/pull/860:625,Usability,simpl,simply,625,"This pull request allows one to use user-defined (and some predefined) functions with different variables and/or parameters from what was given in the original definition. For example, a function originally defined on variable `x` with parameter `[0]` can now easily be applied to variable `y` with parameter `[alpha]` as part of another function definition. The syntax for the `TFormula` is as follows:; * `f(var0, var1, var2, ..., param0, param1, param2, ...)`. Furthermore, this PR introduces a few shortcuts:; * The syntax `[n..m]` for ranges of numbered parameters (for example, `[1..3]` expands to `[1],[2],[3]`); * To simply replace/rename parameters, the variables may be omitted; * Otherwise, if redefining variables, the parameters may be omitted (except, of course, if substituting them all for parameters if the numbers of parameters and variables are equal). This PR supports the nesting of functions (but still not recursive definitions!).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/860
https://github.com/root-project/root/pull/862:135,Testability,test,test,135,"Very preliminary prototype for graphical editor elements. Now only TAttLine and TAttFill are handled (again, very primitive) . Idea to test main functionality, see relationship between components. Also testing of OpenUI5 components. Layout and concrete implementation should be improved a lot. I set @Axel-Naumann as reviewers while @bellenot is in vacations.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/862
https://github.com/root-project/root/pull/862:202,Testability,test,testing,202,"Very preliminary prototype for graphical editor elements. Now only TAttLine and TAttFill are handled (again, very primitive) . Idea to test main functionality, see relationship between components. Also testing of OpenUI5 components. Layout and concrete implementation should be improved a lot. I set @Axel-Naumann as reviewers while @bellenot is in vacations.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/862
https://github.com/root-project/root/pull/865:150,Deployability,install,installed,150,"This is a workaround until we decide how to handle builtin externals; that have headers used by ROOT at runtime from the build directory.; If ROOT is installed, or if Vc/VecCore are external, no workaround is; needed, as ROOT finds the headers at runtime without problems.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/865
https://github.com/root-project/root/pull/868:22,Testability,log,logic,22,"Added resetting state logic in the TColor class that uses a flag to check for changes in the palette such that the Jupyter notebook cells will cause the list of TColors to be streamed independently of other cells, only if they are needed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/868
https://github.com/root-project/root/pull/869:19,Integrability,interface,interface,19,"This is a breaking interface change: Filter now returns templated; TInterface<TFilter<F,P>> objects instead of TInterface<TFilterBase>; as before (and anagolously for Define and Range).; Jitted transformations still return TInterfaces wrapping the base; classes (e.g. TFilterBase). Filter, Define and Range returned TInterfaces wrapping pointers to the; base classes representing the corresponding nodes. This choice was made; to limit compile time and ease the introduction of jitted transformations.; As a consequence, nodes of the functional graph communicated with each; other through virtual calls. This commit lets nodes call into each other through the derived (template); types instead. Given that all nodes' virtual methods are marked `final`,; this should allow compilers to de-virtualize such calls. Because of the interface change this commit is expected to break `test_templateRecursionLimit`. A PR to `root-project/roottest` will deal with this issue ([here](https://github.com/root-project/roottest/pull/67)).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/869
https://github.com/root-project/root/pull/869:235,Integrability,wrap,wrapping,235,"This is a breaking interface change: Filter now returns templated; TInterface<TFilter<F,P>> objects instead of TInterface<TFilterBase>; as before (and anagolously for Define and Range).; Jitted transformations still return TInterfaces wrapping the base; classes (e.g. TFilterBase). Filter, Define and Range returned TInterfaces wrapping pointers to the; base classes representing the corresponding nodes. This choice was made; to limit compile time and ease the introduction of jitted transformations.; As a consequence, nodes of the functional graph communicated with each; other through virtual calls. This commit lets nodes call into each other through the derived (template); types instead. Given that all nodes' virtual methods are marked `final`,; this should allow compilers to de-virtualize such calls. Because of the interface change this commit is expected to break `test_templateRecursionLimit`. A PR to `root-project/roottest` will deal with this issue ([here](https://github.com/root-project/roottest/pull/67)).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/869
https://github.com/root-project/root/pull/869:328,Integrability,wrap,wrapping,328,"This is a breaking interface change: Filter now returns templated; TInterface<TFilter<F,P>> objects instead of TInterface<TFilterBase>; as before (and anagolously for Define and Range).; Jitted transformations still return TInterfaces wrapping the base; classes (e.g. TFilterBase). Filter, Define and Range returned TInterfaces wrapping pointers to the; base classes representing the corresponding nodes. This choice was made; to limit compile time and ease the introduction of jitted transformations.; As a consequence, nodes of the functional graph communicated with each; other through virtual calls. This commit lets nodes call into each other through the derived (template); types instead. Given that all nodes' virtual methods are marked `final`,; this should allow compilers to de-virtualize such calls. Because of the interface change this commit is expected to break `test_templateRecursionLimit`. A PR to `root-project/roottest` will deal with this issue ([here](https://github.com/root-project/roottest/pull/67)).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/869
https://github.com/root-project/root/pull/869:826,Integrability,interface,interface,826,"This is a breaking interface change: Filter now returns templated; TInterface<TFilter<F,P>> objects instead of TInterface<TFilterBase>; as before (and anagolously for Define and Range).; Jitted transformations still return TInterfaces wrapping the base; classes (e.g. TFilterBase). Filter, Define and Range returned TInterfaces wrapping pointers to the; base classes representing the corresponding nodes. This choice was made; to limit compile time and ease the introduction of jitted transformations.; As a consequence, nodes of the functional graph communicated with each; other through virtual calls. This commit lets nodes call into each other through the derived (template); types instead. Given that all nodes' virtual methods are marked `final`,; this should allow compilers to de-virtualize such calls. Because of the interface change this commit is expected to break `test_templateRecursionLimit`. A PR to `root-project/roottest` will deal with this issue ([here](https://github.com/root-project/roottest/pull/67)).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/869
https://github.com/root-project/root/pull/871:182,Availability,error,errors,182,"If IMT is disabled, force the execution policy to be `ROOT::Fit::ExecutionPolicy::kSerial`, warning the user that a change in the execution policy has been made. This should fix the errors in the tests built without IMT. When the support for `kMultitProcess` is finished, maybe we should change this and force the execution policy to be `kMultitProcess`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/871
https://github.com/root-project/root/pull/871:196,Testability,test,tests,196,"If IMT is disabled, force the execution policy to be `ROOT::Fit::ExecutionPolicy::kSerial`, warning the user that a change in the execution policy has been made. This should fix the errors in the tests built without IMT. When the support for `kMultitProcess` is finished, maybe we should change this and force the execution policy to be `kMultitProcess`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/871
https://github.com/root-project/root/pull/872:133,Deployability,patch,patch,133,"When TMVA is reading an input tree it is possible for the user to have forgotten; to remove pointers to out-of-scope variables. This patch prevents TMVA from; messing up the stack in that case. The user should *always* call ResetBranchAddresses on their trees; when they are done with them, but in case they forgot this can save; some debugging time at no cost.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/872
https://github.com/root-project/root/pull/872:117,Modifiability,variab,variables,117,"When TMVA is reading an input tree it is possible for the user to have forgotten; to remove pointers to out-of-scope variables. This patch prevents TMVA from; messing up the stack in that case. The user should *always* call ResetBranchAddresses on their trees; when they are done with them, but in case they forgot this can save; some debugging time at no cost.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/872
https://github.com/root-project/root/pull/876:26,Availability,error,errors,26,"We currently have two ODR errors when using modules. One is when; using setjmp, the other is coming from TException. This patch; makes TException non-textual and moves it to the config module; to prevent cyclic dependencies. We also add setjmp to the; modulemap to fix the ODR errors on the setjmp struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/876
https://github.com/root-project/root/pull/876:277,Availability,error,errors,277,"We currently have two ODR errors when using modules. One is when; using setjmp, the other is coming from TException. This patch; makes TException non-textual and moves it to the config module; to prevent cyclic dependencies. We also add setjmp to the; modulemap to fix the ODR errors on the setjmp struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/876
https://github.com/root-project/root/pull/876:122,Deployability,patch,patch,122,"We currently have two ODR errors when using modules. One is when; using setjmp, the other is coming from TException. This patch; makes TException non-textual and moves it to the config module; to prevent cyclic dependencies. We also add setjmp to the; modulemap to fix the ODR errors on the setjmp struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/876
https://github.com/root-project/root/pull/876:211,Integrability,depend,dependencies,211,"We currently have two ODR errors when using modules. One is when; using setjmp, the other is coming from TException. This patch; makes TException non-textual and moves it to the config module; to prevent cyclic dependencies. We also add setjmp to the; modulemap to fix the ODR errors on the setjmp struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/876
https://github.com/root-project/root/pull/876:178,Modifiability,config,config,178,"We currently have two ODR errors when using modules. One is when; using setjmp, the other is coming from TException. This patch; makes TException non-textual and moves it to the config module; to prevent cyclic dependencies. We also add setjmp to the; modulemap to fix the ODR errors on the setjmp struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/876
https://github.com/root-project/root/pull/877:201,Deployability,patch,patch,201,"As stated in the team meeting a month ago, we need dependencies between rootcling invocations when running with C++ modules because each built module needs to reference any depending C++ modules. This patch also adds a build option for C++ modules that needs to be set for this setting to get active. This build option should replace the environment variable that we had before in areas where it is more practical to have a fixed CMake setting such as running PRs on Jenkins or when having CMake specific code for C++ modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/877
https://github.com/root-project/root/pull/877:51,Integrability,depend,dependencies,51,"As stated in the team meeting a month ago, we need dependencies between rootcling invocations when running with C++ modules because each built module needs to reference any depending C++ modules. This patch also adds a build option for C++ modules that needs to be set for this setting to get active. This build option should replace the environment variable that we had before in areas where it is more practical to have a fixed CMake setting such as running PRs on Jenkins or when having CMake specific code for C++ modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/877
https://github.com/root-project/root/pull/877:173,Integrability,depend,depending,173,"As stated in the team meeting a month ago, we need dependencies between rootcling invocations when running with C++ modules because each built module needs to reference any depending C++ modules. This patch also adds a build option for C++ modules that needs to be set for this setting to get active. This build option should replace the environment variable that we had before in areas where it is more practical to have a fixed CMake setting such as running PRs on Jenkins or when having CMake specific code for C++ modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/877
https://github.com/root-project/root/pull/877:350,Modifiability,variab,variable,350,"As stated in the team meeting a month ago, we need dependencies between rootcling invocations when running with C++ modules because each built module needs to reference any depending C++ modules. This patch also adds a build option for C++ modules that needs to be set for this setting to get active. This build option should replace the environment variable that we had before in areas where it is more practical to have a fixed CMake setting such as running PRs on Jenkins or when having CMake specific code for C++ modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/877
https://github.com/root-project/root/pull/878:205,Availability,error,error,205,"The Core module is now just called `Core`, and no longer `libCore.so`,; which leads to the confusing PCM file name `libCore.so.pcm` which is 75%; just boilerplate prefixes and suffixes. This also make the error; messages from clang more readable now as they use the same module name.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/878
https://github.com/root-project/root/pull/878:212,Integrability,message,messages,212,"The Core module is now just called `Core`, and no longer `libCore.so`,; which leads to the confusing PCM file name `libCore.so.pcm` which is 75%; just boilerplate prefixes and suffixes. This also make the error; messages from clang more readable now as they use the same module name.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/878
https://github.com/root-project/root/pull/881:83,Modifiability,variab,variable,83,- Fix segfault if class name has underscore in name; - Fix segfault if no identity variable transformation is booked,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/881
https://github.com/root-project/root/pull/882:10,Testability,test,testing,10,for build testing,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/882
https://github.com/root-project/root/pull/887:15,Testability,test,tests,15,"Generalize the tests in `testGradient.cxx` to include the case of multidimensional functions. With these changes, there are 18 use cases covered, from all the possible combinations of. * Type of gradient: Chi2, LogL or PoissonLogL; * Number of dimensions: 1 or 2; * Data type: scalar or vectorial; * Execution policy: serial or multithread. excluding the scalar serial case, which is the base case whose solution is assumed to be correct. Also, a bug in the memory management of the data coordinates in the gradient evaluation has been fixed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/887
https://github.com/root-project/root/pull/887:25,Testability,test,testGradient,25,"Generalize the tests in `testGradient.cxx` to include the case of multidimensional functions. With these changes, there are 18 use cases covered, from all the possible combinations of. * Type of gradient: Chi2, LogL or PoissonLogL; * Number of dimensions: 1 or 2; * Data type: scalar or vectorial; * Execution policy: serial or multithread. excluding the scalar serial case, which is the base case whose solution is assumed to be correct. Also, a bug in the memory management of the data coordinates in the gradient evaluation has been fixed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/887
https://github.com/root-project/root/pull/887:211,Testability,Log,LogL,211,"Generalize the tests in `testGradient.cxx` to include the case of multidimensional functions. With these changes, there are 18 use cases covered, from all the possible combinations of. * Type of gradient: Chi2, LogL or PoissonLogL; * Number of dimensions: 1 or 2; * Data type: scalar or vectorial; * Execution policy: serial or multithread. excluding the scalar serial case, which is the base case whose solution is assumed to be correct. Also, a bug in the memory management of the data coordinates in the gradient evaluation has been fixed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/887
https://github.com/root-project/root/pull/890:151,Testability,test,test,151,"Fitter class can now receive vectorized gradient functions; i.e., `IParamMultiGradFunctionTempl<ROOT::Double_v>` objects. TODO:; - [ ] Fix the failing test.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/890
https://github.com/root-project/root/pull/891:1388,Deployability,install,installed,1388,"8510). The inital check for the compiler was. enable_language(Fortran OPTIONAL). This does not set the the CMAKE_Fortran_COMPILER variable (or sets it to; NOTFOUND) if a Fortran compiler is not found, but still marks the; Fortran language as being enabled for the current project. This broke; the settings for BLAS/LAPACK. The second attempt (bb40ede3941d0b4f2db4e23d5f9c32b221eb5fac) was to use. check_language(Fortran); if(CMAKE_Fortran_COMPILER); enable_language(Fortran); endif(). This does not find the Fortran compiler corresponding to the used C++; compiler. Cmake has some mechanism that if the C++ compiler is a GNU; compiler, it would also prefer GNU Fortran compilers. However, as the; check_language test is running in a separate process it would not know; about the C++ compiler. This is a problem in a set-up with executables; like:. /opt/newgcc/g++; /opt/newgcc/gfortran; /usr/bin/f95 (link to gfortran); /usr/bin/g++; /usr/bin/gfortran. Two versions of GCC are installed, one by the system, and one more; recent version in a separate directory. The directory to the newer; version is in the environment variable PATH before /usr/bin. In this; case the test from above (second attempt) would use /usr/bin/f95 as the; Fortran compiler, because Cmake usually prefers the executable f95 over; gfortran. This causes problems in case the two Fortran compilers are not; ABI compatible, i.e., gfortran 4.4 installed by the system vs. 4.9 as a; slightly more recent version. A simple enable_language (as in the; initial version) would correctly use /opt/newgcc/gfortran in this case.; This had to be worked around by setting the environment variable; FC=gfortran before running Cmake. To fix this, check_language is only used to determine whether a Fortran; compiler exists at all. If a compiler is found, then the; CMAKE_Fortran_COMPILER variable is reset, and enable_language again; performs a search of the compiler, this time prefering a compiler from; the same vendor as the C++ compiler.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/891
https://github.com/root-project/root/pull/891:1825,Deployability,install,installed,1825,"8510). The inital check for the compiler was. enable_language(Fortran OPTIONAL). This does not set the the CMAKE_Fortran_COMPILER variable (or sets it to; NOTFOUND) if a Fortran compiler is not found, but still marks the; Fortran language as being enabled for the current project. This broke; the settings for BLAS/LAPACK. The second attempt (bb40ede3941d0b4f2db4e23d5f9c32b221eb5fac) was to use. check_language(Fortran); if(CMAKE_Fortran_COMPILER); enable_language(Fortran); endif(). This does not find the Fortran compiler corresponding to the used C++; compiler. Cmake has some mechanism that if the C++ compiler is a GNU; compiler, it would also prefer GNU Fortran compilers. However, as the; check_language test is running in a separate process it would not know; about the C++ compiler. This is a problem in a set-up with executables; like:. /opt/newgcc/g++; /opt/newgcc/gfortran; /usr/bin/f95 (link to gfortran); /usr/bin/g++; /usr/bin/gfortran. Two versions of GCC are installed, one by the system, and one more; recent version in a separate directory. The directory to the newer; version is in the environment variable PATH before /usr/bin. In this; case the test from above (second attempt) would use /usr/bin/f95 as the; Fortran compiler, because Cmake usually prefers the executable f95 over; gfortran. This causes problems in case the two Fortran compilers are not; ABI compatible, i.e., gfortran 4.4 installed by the system vs. 4.9 as a; slightly more recent version. A simple enable_language (as in the; initial version) would correctly use /opt/newgcc/gfortran in this case.; This had to be worked around by setting the environment variable; FC=gfortran before running Cmake. To fix this, check_language is only used to determine whether a Fortran; compiler exists at all. If a compiler is found, then the; CMAKE_Fortran_COMPILER variable is reset, and enable_language again; performs a search of the compiler, this time prefering a compiler from; the same vendor as the C++ compiler.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/891
https://github.com/root-project/root/pull/891:152,Modifiability,variab,variable,152,"It turned out that my proposal to fix issue [ROOT-8510](https://sft.its.cern.ch/jira/browse/ROOT-8510) had the side-effect of requiring the environment variable FC to be set to find the correct Fortran compiler under some circumstances. This should now be fixed. Finding out whether a compiler is found in Cmake seems to be really; hard. In particular a non-found Fortran compiler caused issues on MacOS; (ROOT-8510). The inital check for the compiler was. enable_language(Fortran OPTIONAL). This does not set the the CMAKE_Fortran_COMPILER variable (or sets it to; NOTFOUND) if a Fortran compiler is not found, but still marks the; Fortran language as being enabled for the current project. This broke; the settings for BLAS/LAPACK. The second attempt (bb40ede3941d0b4f2db4e23d5f9c32b221eb5fac) was to use. check_language(Fortran); if(CMAKE_Fortran_COMPILER); enable_language(Fortran); endif(). This does not find the Fortran compiler corresponding to the used C++; compiler. Cmake has some mechanism that if the C++ compiler is a GNU; compiler, it would also prefer GNU Fortran compilers. However, as the; check_language test is running in a separate process it would not know; about the C++ compiler. This is a problem in a set-up with executables; like:. /opt/newgcc/g++; /opt/newgcc/gfortran; /usr/bin/f95 (link to gfortran); /usr/bin/g++; /usr/bin/gfortran. Two versions of GCC are installed, one by the system, and one more; recent version in a separate directory. The directory to the newer; version is in the environment variable PATH before /usr/bin. In this; case the test from above (second attempt) would use /usr/bin/f95 as the; Fortran compiler, because Cmake usually prefers the executable f95 over; gfortran. This causes problems in case the two Fortran compilers are not; ABI compatible, i.e., gfortran 4.4 installed by the system vs. 4.9 as a; slightly more recent version. A simple enable_language (as in the; initial version) would correctly use /opt/newgcc/gfortran in this case.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/891
https://github.com/root-project/root/pull/891:541,Modifiability,variab,variable,541,"It turned out that my proposal to fix issue [ROOT-8510](https://sft.its.cern.ch/jira/browse/ROOT-8510) had the side-effect of requiring the environment variable FC to be set to find the correct Fortran compiler under some circumstances. This should now be fixed. Finding out whether a compiler is found in Cmake seems to be really; hard. In particular a non-found Fortran compiler caused issues on MacOS; (ROOT-8510). The inital check for the compiler was. enable_language(Fortran OPTIONAL). This does not set the the CMAKE_Fortran_COMPILER variable (or sets it to; NOTFOUND) if a Fortran compiler is not found, but still marks the; Fortran language as being enabled for the current project. This broke; the settings for BLAS/LAPACK. The second attempt (bb40ede3941d0b4f2db4e23d5f9c32b221eb5fac) was to use. check_language(Fortran); if(CMAKE_Fortran_COMPILER); enable_language(Fortran); endif(). This does not find the Fortran compiler corresponding to the used C++; compiler. Cmake has some mechanism that if the C++ compiler is a GNU; compiler, it would also prefer GNU Fortran compilers. However, as the; check_language test is running in a separate process it would not know; about the C++ compiler. This is a problem in a set-up with executables; like:. /opt/newgcc/g++; /opt/newgcc/gfortran; /usr/bin/f95 (link to gfortran); /usr/bin/g++; /usr/bin/gfortran. Two versions of GCC are installed, one by the system, and one more; recent version in a separate directory. The directory to the newer; version is in the environment variable PATH before /usr/bin. In this; case the test from above (second attempt) would use /usr/bin/f95 as the; Fortran compiler, because Cmake usually prefers the executable f95 over; gfortran. This causes problems in case the two Fortran compilers are not; ABI compatible, i.e., gfortran 4.4 installed by the system vs. 4.9 as a; slightly more recent version. A simple enable_language (as in the; initial version) would correctly use /opt/newgcc/gfortran in this case.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/891
https://github.com/root-project/root/pull/891:1530,Modifiability,variab,variable,1530,"8510). The inital check for the compiler was. enable_language(Fortran OPTIONAL). This does not set the the CMAKE_Fortran_COMPILER variable (or sets it to; NOTFOUND) if a Fortran compiler is not found, but still marks the; Fortran language as being enabled for the current project. This broke; the settings for BLAS/LAPACK. The second attempt (bb40ede3941d0b4f2db4e23d5f9c32b221eb5fac) was to use. check_language(Fortran); if(CMAKE_Fortran_COMPILER); enable_language(Fortran); endif(). This does not find the Fortran compiler corresponding to the used C++; compiler. Cmake has some mechanism that if the C++ compiler is a GNU; compiler, it would also prefer GNU Fortran compilers. However, as the; check_language test is running in a separate process it would not know; about the C++ compiler. This is a problem in a set-up with executables; like:. /opt/newgcc/g++; /opt/newgcc/gfortran; /usr/bin/f95 (link to gfortran); /usr/bin/g++; /usr/bin/gfortran. Two versions of GCC are installed, one by the system, and one more; recent version in a separate directory. The directory to the newer; version is in the environment variable PATH before /usr/bin. In this; case the test from above (second attempt) would use /usr/bin/f95 as the; Fortran compiler, because Cmake usually prefers the executable f95 over; gfortran. This causes problems in case the two Fortran compilers are not; ABI compatible, i.e., gfortran 4.4 installed by the system vs. 4.9 as a; slightly more recent version. A simple enable_language (as in the; initial version) would correctly use /opt/newgcc/gfortran in this case.; This had to be worked around by setting the environment variable; FC=gfortran before running Cmake. To fix this, check_language is only used to determine whether a Fortran; compiler exists at all. If a compiler is found, then the; CMAKE_Fortran_COMPILER variable is reset, and enable_language again; performs a search of the compiler, this time prefering a compiler from; the same vendor as the C++ compiler.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/891
https://github.com/root-project/root/pull/891:2059,Modifiability,variab,variable,2059,"8510). The inital check for the compiler was. enable_language(Fortran OPTIONAL). This does not set the the CMAKE_Fortran_COMPILER variable (or sets it to; NOTFOUND) if a Fortran compiler is not found, but still marks the; Fortran language as being enabled for the current project. This broke; the settings for BLAS/LAPACK. The second attempt (bb40ede3941d0b4f2db4e23d5f9c32b221eb5fac) was to use. check_language(Fortran); if(CMAKE_Fortran_COMPILER); enable_language(Fortran); endif(). This does not find the Fortran compiler corresponding to the used C++; compiler. Cmake has some mechanism that if the C++ compiler is a GNU; compiler, it would also prefer GNU Fortran compilers. However, as the; check_language test is running in a separate process it would not know; about the C++ compiler. This is a problem in a set-up with executables; like:. /opt/newgcc/g++; /opt/newgcc/gfortran; /usr/bin/f95 (link to gfortran); /usr/bin/g++; /usr/bin/gfortran. Two versions of GCC are installed, one by the system, and one more; recent version in a separate directory. The directory to the newer; version is in the environment variable PATH before /usr/bin. In this; case the test from above (second attempt) would use /usr/bin/f95 as the; Fortran compiler, because Cmake usually prefers the executable f95 over; gfortran. This causes problems in case the two Fortran compilers are not; ABI compatible, i.e., gfortran 4.4 installed by the system vs. 4.9 as a; slightly more recent version. A simple enable_language (as in the; initial version) would correctly use /opt/newgcc/gfortran in this case.; This had to be worked around by setting the environment variable; FC=gfortran before running Cmake. To fix this, check_language is only used to determine whether a Fortran; compiler exists at all. If a compiler is found, then the; CMAKE_Fortran_COMPILER variable is reset, and enable_language again; performs a search of the compiler, this time prefering a compiler from; the same vendor as the C++ compiler.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/891
https://github.com/root-project/root/pull/891:2257,Modifiability,variab,variable,2257,"8510). The inital check for the compiler was. enable_language(Fortran OPTIONAL). This does not set the the CMAKE_Fortran_COMPILER variable (or sets it to; NOTFOUND) if a Fortran compiler is not found, but still marks the; Fortran language as being enabled for the current project. This broke; the settings for BLAS/LAPACK. The second attempt (bb40ede3941d0b4f2db4e23d5f9c32b221eb5fac) was to use. check_language(Fortran); if(CMAKE_Fortran_COMPILER); enable_language(Fortran); endif(). This does not find the Fortran compiler corresponding to the used C++; compiler. Cmake has some mechanism that if the C++ compiler is a GNU; compiler, it would also prefer GNU Fortran compilers. However, as the; check_language test is running in a separate process it would not know; about the C++ compiler. This is a problem in a set-up with executables; like:. /opt/newgcc/g++; /opt/newgcc/gfortran; /usr/bin/f95 (link to gfortran); /usr/bin/g++; /usr/bin/gfortran. Two versions of GCC are installed, one by the system, and one more; recent version in a separate directory. The directory to the newer; version is in the environment variable PATH before /usr/bin. In this; case the test from above (second attempt) would use /usr/bin/f95 as the; Fortran compiler, because Cmake usually prefers the executable f95 over; gfortran. This causes problems in case the two Fortran compilers are not; ABI compatible, i.e., gfortran 4.4 installed by the system vs. 4.9 as a; slightly more recent version. A simple enable_language (as in the; initial version) would correctly use /opt/newgcc/gfortran in this case.; This had to be worked around by setting the environment variable; FC=gfortran before running Cmake. To fix this, check_language is only used to determine whether a Fortran; compiler exists at all. If a compiler is found, then the; CMAKE_Fortran_COMPILER variable is reset, and enable_language again; performs a search of the compiler, this time prefering a compiler from; the same vendor as the C++ compiler.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/891
https://github.com/root-project/root/pull/891:2303,Performance,perform,performs,2303,"8510). The inital check for the compiler was. enable_language(Fortran OPTIONAL). This does not set the the CMAKE_Fortran_COMPILER variable (or sets it to; NOTFOUND) if a Fortran compiler is not found, but still marks the; Fortran language as being enabled for the current project. This broke; the settings for BLAS/LAPACK. The second attempt (bb40ede3941d0b4f2db4e23d5f9c32b221eb5fac) was to use. check_language(Fortran); if(CMAKE_Fortran_COMPILER); enable_language(Fortran); endif(). This does not find the Fortran compiler corresponding to the used C++; compiler. Cmake has some mechanism that if the C++ compiler is a GNU; compiler, it would also prefer GNU Fortran compilers. However, as the; check_language test is running in a separate process it would not know; about the C++ compiler. This is a problem in a set-up with executables; like:. /opt/newgcc/g++; /opt/newgcc/gfortran; /usr/bin/f95 (link to gfortran); /usr/bin/g++; /usr/bin/gfortran. Two versions of GCC are installed, one by the system, and one more; recent version in a separate directory. The directory to the newer; version is in the environment variable PATH before /usr/bin. In this; case the test from above (second attempt) would use /usr/bin/f95 as the; Fortran compiler, because Cmake usually prefers the executable f95 over; gfortran. This causes problems in case the two Fortran compilers are not; ABI compatible, i.e., gfortran 4.4 installed by the system vs. 4.9 as a; slightly more recent version. A simple enable_language (as in the; initial version) would correctly use /opt/newgcc/gfortran in this case.; This had to be worked around by setting the environment variable; FC=gfortran before running Cmake. To fix this, check_language is only used to determine whether a Fortran; compiler exists at all. If a compiler is found, then the; CMAKE_Fortran_COMPILER variable is reset, and enable_language again; performs a search of the compiler, this time prefering a compiler from; the same vendor as the C++ compiler.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/891
https://github.com/root-project/root/pull/891:1123,Testability,test,test,1123,"nment variable FC to be set to find the correct Fortran compiler under some circumstances. This should now be fixed. Finding out whether a compiler is found in Cmake seems to be really; hard. In particular a non-found Fortran compiler caused issues on MacOS; (ROOT-8510). The inital check for the compiler was. enable_language(Fortran OPTIONAL). This does not set the the CMAKE_Fortran_COMPILER variable (or sets it to; NOTFOUND) if a Fortran compiler is not found, but still marks the; Fortran language as being enabled for the current project. This broke; the settings for BLAS/LAPACK. The second attempt (bb40ede3941d0b4f2db4e23d5f9c32b221eb5fac) was to use. check_language(Fortran); if(CMAKE_Fortran_COMPILER); enable_language(Fortran); endif(). This does not find the Fortran compiler corresponding to the used C++; compiler. Cmake has some mechanism that if the C++ compiler is a GNU; compiler, it would also prefer GNU Fortran compilers. However, as the; check_language test is running in a separate process it would not know; about the C++ compiler. This is a problem in a set-up with executables; like:. /opt/newgcc/g++; /opt/newgcc/gfortran; /usr/bin/f95 (link to gfortran); /usr/bin/g++; /usr/bin/gfortran. Two versions of GCC are installed, one by the system, and one more; recent version in a separate directory. The directory to the newer; version is in the environment variable PATH before /usr/bin. In this; case the test from above (second attempt) would use /usr/bin/f95 as the; Fortran compiler, because Cmake usually prefers the executable f95 over; gfortran. This causes problems in case the two Fortran compilers are not; ABI compatible, i.e., gfortran 4.4 installed by the system vs. 4.9 as a; slightly more recent version. A simple enable_language (as in the; initial version) would correctly use /opt/newgcc/gfortran in this case.; This had to be worked around by setting the environment variable; FC=gfortran before running Cmake. To fix this, check_language is only used to ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/891
https://github.com/root-project/root/pull/891:1579,Testability,test,test,1579,"8510). The inital check for the compiler was. enable_language(Fortran OPTIONAL). This does not set the the CMAKE_Fortran_COMPILER variable (or sets it to; NOTFOUND) if a Fortran compiler is not found, but still marks the; Fortran language as being enabled for the current project. This broke; the settings for BLAS/LAPACK. The second attempt (bb40ede3941d0b4f2db4e23d5f9c32b221eb5fac) was to use. check_language(Fortran); if(CMAKE_Fortran_COMPILER); enable_language(Fortran); endif(). This does not find the Fortran compiler corresponding to the used C++; compiler. Cmake has some mechanism that if the C++ compiler is a GNU; compiler, it would also prefer GNU Fortran compilers. However, as the; check_language test is running in a separate process it would not know; about the C++ compiler. This is a problem in a set-up with executables; like:. /opt/newgcc/g++; /opt/newgcc/gfortran; /usr/bin/f95 (link to gfortran); /usr/bin/g++; /usr/bin/gfortran. Two versions of GCC are installed, one by the system, and one more; recent version in a separate directory. The directory to the newer; version is in the environment variable PATH before /usr/bin. In this; case the test from above (second attempt) would use /usr/bin/f95 as the; Fortran compiler, because Cmake usually prefers the executable f95 over; gfortran. This causes problems in case the two Fortran compilers are not; ABI compatible, i.e., gfortran 4.4 installed by the system vs. 4.9 as a; slightly more recent version. A simple enable_language (as in the; initial version) would correctly use /opt/newgcc/gfortran in this case.; This had to be worked around by setting the environment variable; FC=gfortran before running Cmake. To fix this, check_language is only used to determine whether a Fortran; compiler exists at all. If a compiler is found, then the; CMAKE_Fortran_COMPILER variable is reset, and enable_language again; performs a search of the compiler, this time prefering a compiler from; the same vendor as the C++ compiler.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/891
https://github.com/root-project/root/pull/891:1895,Usability,simpl,simple,1895,"8510). The inital check for the compiler was. enable_language(Fortran OPTIONAL). This does not set the the CMAKE_Fortran_COMPILER variable (or sets it to; NOTFOUND) if a Fortran compiler is not found, but still marks the; Fortran language as being enabled for the current project. This broke; the settings for BLAS/LAPACK. The second attempt (bb40ede3941d0b4f2db4e23d5f9c32b221eb5fac) was to use. check_language(Fortran); if(CMAKE_Fortran_COMPILER); enable_language(Fortran); endif(). This does not find the Fortran compiler corresponding to the used C++; compiler. Cmake has some mechanism that if the C++ compiler is a GNU; compiler, it would also prefer GNU Fortran compilers. However, as the; check_language test is running in a separate process it would not know; about the C++ compiler. This is a problem in a set-up with executables; like:. /opt/newgcc/g++; /opt/newgcc/gfortran; /usr/bin/f95 (link to gfortran); /usr/bin/g++; /usr/bin/gfortran. Two versions of GCC are installed, one by the system, and one more; recent version in a separate directory. The directory to the newer; version is in the environment variable PATH before /usr/bin. In this; case the test from above (second attempt) would use /usr/bin/f95 as the; Fortran compiler, because Cmake usually prefers the executable f95 over; gfortran. This causes problems in case the two Fortran compilers are not; ABI compatible, i.e., gfortran 4.4 installed by the system vs. 4.9 as a; slightly more recent version. A simple enable_language (as in the; initial version) would correctly use /opt/newgcc/gfortran in this case.; This had to be worked around by setting the environment variable; FC=gfortran before running Cmake. To fix this, check_language is only used to determine whether a Fortran; compiler exists at all. If a compiler is found, then the; CMAKE_Fortran_COMPILER variable is reset, and enable_language again; performs a search of the compiler, this time prefering a compiler from; the same vendor as the C++ compiler.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/891
https://github.com/root-project/root/pull/892:113,Testability,test,test,113,"Can one of the threading people cross-check that this does what it's supposed to do? I don't have a good, simple test case.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/892
https://github.com/root-project/root/pull/892:106,Usability,simpl,simple,106,"Can one of the threading people cross-check that this does what it's supposed to do? I don't have a good, simple test case.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/892
https://github.com/root-project/root/pull/893:33,Deployability,patch,patches,33,This should reduce the amount of patches we have in clang making the PCH; relocatable.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/893
https://github.com/root-project/root/pull/893:12,Energy Efficiency,reduce,reduce,12,This should reduce the amount of patches we have in clang making the PCH; relocatable.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/893
https://github.com/root-project/root/pull/896:134,Availability,error,errors,134,"Until now, in the case where `VecCore` is enabled, only `BinData::fData` was padded to protect vectorized loops against memory access errors. This commit adds the same padding in the case `VecCore` is enabled to all coordinate, data and error vectors of `FitData` family; in particular:; * `FitData::fCoords[i]` (for every `i`); * `BinData::fCoordErrors[i]` (for every `i`); * `BinData::fData`, `BinData::fDataError`; * `BinData::fDataErrorHigh`; * `BinData::fDataErrorLow`; * `BinData::fBinEdge[i]` (for every `i`)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/896
https://github.com/root-project/root/pull/896:237,Availability,error,error,237,"Until now, in the case where `VecCore` is enabled, only `BinData::fData` was padded to protect vectorized loops against memory access errors. This commit adds the same padding in the case `VecCore` is enabled to all coordinate, data and error vectors of `FitData` family; in particular:; * `FitData::fCoords[i]` (for every `i`); * `BinData::fCoordErrors[i]` (for every `i`); * `BinData::fData`, `BinData::fDataError`; * `BinData::fDataErrorHigh`; * `BinData::fDataErrorLow`; * `BinData::fBinEdge[i]` (for every `i`)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/896
https://github.com/root-project/root/pull/896:127,Security,access,access,127,"Until now, in the case where `VecCore` is enabled, only `BinData::fData` was padded to protect vectorized loops against memory access errors. This commit adds the same padding in the case `VecCore` is enabled to all coordinate, data and error vectors of `FitData` family; in particular:; * `FitData::fCoords[i]` (for every `i`); * `BinData::fCoordErrors[i]` (for every `i`); * `BinData::fData`, `BinData::fDataError`; * `BinData::fDataErrorHigh`; * `BinData::fDataErrorLow`; * `BinData::fBinEdge[i]` (for every `i`)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/896
https://github.com/root-project/root/pull/897:39,Modifiability,refactor,refactoring,39,Fixes 1vs1 roc curve drawing and minor refactoring.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/897
https://github.com/root-project/root/pull/902:830,Deployability,patch,patch,830,"When filling histograms without limits in parallel a problem to be addressed is how to make sure that the ranges are compatible for the final merging.; This PR proposes a technique based on a static reference list of TAxis, kept as a static in TH1, filled/used by the different threads. The first thread calculates the TAxis ranges and saves it into the list, the others use it. The list is protected by a RW lock .; The logic is implemented in TH1::BufferEmpty and holds for TH{1,2,3}, the specificity of each TH{1,2,3} being moved to a set of new member functions called by TH1::BufferEmpty. The change in TH1Merger is required to calculate the axis and dump the internal buffers when the internal buffersize has not yet been reached. This treatment can perhaps be improved to get the same result of the single thread case. The patch also implements the hook for a call back function to implement the same functionality in the case of multi-processing. A patch with adaptation to multiproc will follow. The tutorial mt301_fillHistAutoBin.C illustrates the usage with TThreadedObject . NB: many of the changes in TH1.h come from clang-format-{3.8, 3.9, 4.0}",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:957,Deployability,patch,patch,957,"When filling histograms without limits in parallel a problem to be addressed is how to make sure that the ranges are compatible for the final merging.; This PR proposes a technique based on a static reference list of TAxis, kept as a static in TH1, filled/used by the different threads. The first thread calculates the TAxis ranges and saves it into the list, the others use it. The list is protected by a RW lock .; The logic is implemented in TH1::BufferEmpty and holds for TH{1,2,3}, the specificity of each TH{1,2,3} being moved to a set of new member functions called by TH1::BufferEmpty. The change in TH1Merger is required to calculate the axis and dump the internal buffers when the internal buffersize has not yet been reached. This treatment can perhaps be improved to get the same result of the single thread case. The patch also implements the hook for a call back function to implement the same functionality in the case of multi-processing. A patch with adaptation to multiproc will follow. The tutorial mt301_fillHistAutoBin.C illustrates the usage with TThreadedObject . NB: many of the changes in TH1.h come from clang-format-{3.8, 3.9, 4.0}",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:968,Energy Efficiency,adapt,adaptation,968,"When filling histograms without limits in parallel a problem to be addressed is how to make sure that the ranges are compatible for the final merging.; This PR proposes a technique based on a static reference list of TAxis, kept as a static in TH1, filled/used by the different threads. The first thread calculates the TAxis ranges and saves it into the list, the others use it. The list is protected by a RW lock .; The logic is implemented in TH1::BufferEmpty and holds for TH{1,2,3}, the specificity of each TH{1,2,3} being moved to a set of new member functions called by TH1::BufferEmpty. The change in TH1Merger is required to calculate the axis and dump the internal buffers when the internal buffersize has not yet been reached. This treatment can perhaps be improved to get the same result of the single thread case. The patch also implements the hook for a call back function to implement the same functionality in the case of multi-processing. A patch with adaptation to multiproc will follow. The tutorial mt301_fillHistAutoBin.C illustrates the usage with TThreadedObject . NB: many of the changes in TH1.h come from clang-format-{3.8, 3.9, 4.0}",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:968,Modifiability,adapt,adaptation,968,"When filling histograms without limits in parallel a problem to be addressed is how to make sure that the ranges are compatible for the final merging.; This PR proposes a technique based on a static reference list of TAxis, kept as a static in TH1, filled/used by the different threads. The first thread calculates the TAxis ranges and saves it into the list, the others use it. The list is protected by a RW lock .; The logic is implemented in TH1::BufferEmpty and holds for TH{1,2,3}, the specificity of each TH{1,2,3} being moved to a set of new member functions called by TH1::BufferEmpty. The change in TH1Merger is required to calculate the axis and dump the internal buffers when the internal buffersize has not yet been reached. This treatment can perhaps be improved to get the same result of the single thread case. The patch also implements the hook for a call back function to implement the same functionality in the case of multi-processing. A patch with adaptation to multiproc will follow. The tutorial mt301_fillHistAutoBin.C illustrates the usage with TThreadedObject . NB: many of the changes in TH1.h come from clang-format-{3.8, 3.9, 4.0}",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:421,Testability,log,logic,421,"When filling histograms without limits in parallel a problem to be addressed is how to make sure that the ranges are compatible for the final merging.; This PR proposes a technique based on a static reference list of TAxis, kept as a static in TH1, filled/used by the different threads. The first thread calculates the TAxis ranges and saves it into the list, the others use it. The list is protected by a RW lock .; The logic is implemented in TH1::BufferEmpty and holds for TH{1,2,3}, the specificity of each TH{1,2,3} being moved to a set of new member functions called by TH1::BufferEmpty. The change in TH1Merger is required to calculate the axis and dump the internal buffers when the internal buffersize has not yet been reached. This treatment can perhaps be improved to get the same result of the single thread case. The patch also implements the hook for a call back function to implement the same functionality in the case of multi-processing. A patch with adaptation to multiproc will follow. The tutorial mt301_fillHistAutoBin.C illustrates the usage with TThreadedObject . NB: many of the changes in TH1.h come from clang-format-{3.8, 3.9, 4.0}",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/903:19,Performance,load,loading,19,"Removed explicitly loading pythia8 in pythia8 tutorials. On e.g. Docker, this test fails since the path to pythia8 is not under $PYTHIA8/lib/: http://cdash.cern.ch/testDetails.php?test=28516933&build=390221",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/903
https://github.com/root-project/root/pull/903:78,Testability,test,test,78,"Removed explicitly loading pythia8 in pythia8 tutorials. On e.g. Docker, this test fails since the path to pythia8 is not under $PYTHIA8/lib/: http://cdash.cern.ch/testDetails.php?test=28516933&build=390221",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/903
https://github.com/root-project/root/pull/903:164,Testability,test,testDetails,164,"Removed explicitly loading pythia8 in pythia8 tutorials. On e.g. Docker, this test fails since the path to pythia8 is not under $PYTHIA8/lib/: http://cdash.cern.ch/testDetails.php?test=28516933&build=390221",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/903
https://github.com/root-project/root/pull/903:180,Testability,test,test,180,"Removed explicitly loading pythia8 in pythia8 tutorials. On e.g. Docker, this test fails since the path to pythia8 is not under $PYTHIA8/lib/: http://cdash.cern.ch/testDetails.php?test=28516933&build=390221",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/903
https://github.com/root-project/root/pull/905:8,Modifiability,extend,extends,8,This PR extends the functionality of `TF1` functions based on `NSUM` or `CONV` (namely the classes `TF1NormSum` and `TF1Convolution` respectively). We are now able to:; * Set parameters and ranges directly from the `TF1`; * Copy these functions; * Stream these functions (for cloning and file I/O),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/905
https://github.com/root-project/root/pull/907:0,Usability,Simpl,Simply,0,Simply reuses the XXHASH implementation from the LZ4 library (also; used in the LZ4 frame format). @oshadura @jblomer - this should provide reasonable protection against bit-flips.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/907
https://github.com/root-project/root/pull/908:0,Testability,Test,Test,0,"Test PR, do not merge please.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/908
https://github.com/root-project/root/pull/914:83,Integrability,depend,dependencies,83,"Those dictionaries also generate a C++ module, but we don't specify; as of yet the dependencies on the referenced C++ modules from ROOT.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/914
https://github.com/root-project/root/pull/915:260,Availability,failure,failures,260,"RScanner iterates over all decls in our AST, but with modules we; have hidden decl from unimported submodules in our AST. As we; call Sema functions on these decls which use the normal clang; lookup that respects visibility, we suddenly get mysterious; lookup failures from inside Sema when running rootcling. This patch restricts RScanner to looking at visible decls, which; restores the original behavior where RScanner onlys sees visible decls; from included headers.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/915
https://github.com/root-project/root/pull/915:315,Deployability,patch,patch,315,"RScanner iterates over all decls in our AST, but with modules we; have hidden decl from unimported submodules in our AST. As we; call Sema functions on these decls which use the normal clang; lookup that respects visibility, we suddenly get mysterious; lookup failures from inside Sema when running rootcling. This patch restricts RScanner to looking at visible decls, which; restores the original behavior where RScanner onlys sees visible decls; from included headers.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/915
https://github.com/root-project/root/pull/916:23,Deployability,integrat,integrating,23,"Dear ROOT team,. while integrating some CMake functionality provided by ROOT through the `ROOT_USE_FILE` include into our project, some small issues came up. If we are mistaken and there are better solutions than the one I provided, your advice is very welcome. Our `FindROOT.cmake` implementation looks like this:; ```cmake; find_package(ROOT QUIET CONFIG; HINTS; ${ROOT_ROOT} # aliBuild; ${ROOTSYS} # upstream; $ENV{ROOTSYS} # upstream; ${SIMPATH} # FairSoft; ); include(FindPackageHandleStandardArgs); find_package_handle_standard_args(ROOT CONFIG_MODE); include(${ROOT_USE_FILE}); ```; which is called in a `CMakeLists.txt` like this; ```cmake; find_package(ROOT 6.10.04 REQUIRED); ```. Please see the commit messages for more details about the issues we had. Best regards,; Dennis",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/916
https://github.com/root-project/root/pull/916:23,Integrability,integrat,integrating,23,"Dear ROOT team,. while integrating some CMake functionality provided by ROOT through the `ROOT_USE_FILE` include into our project, some small issues came up. If we are mistaken and there are better solutions than the one I provided, your advice is very welcome. Our `FindROOT.cmake` implementation looks like this:; ```cmake; find_package(ROOT QUIET CONFIG; HINTS; ${ROOT_ROOT} # aliBuild; ${ROOTSYS} # upstream; $ENV{ROOTSYS} # upstream; ${SIMPATH} # FairSoft; ); include(FindPackageHandleStandardArgs); find_package_handle_standard_args(ROOT CONFIG_MODE); include(${ROOT_USE_FILE}); ```; which is called in a `CMakeLists.txt` like this; ```cmake; find_package(ROOT 6.10.04 REQUIRED); ```. Please see the commit messages for more details about the issues we had. Best regards,; Dennis",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/916
https://github.com/root-project/root/pull/916:713,Integrability,message,messages,713,"Dear ROOT team,. while integrating some CMake functionality provided by ROOT through the `ROOT_USE_FILE` include into our project, some small issues came up. If we are mistaken and there are better solutions than the one I provided, your advice is very welcome. Our `FindROOT.cmake` implementation looks like this:; ```cmake; find_package(ROOT QUIET CONFIG; HINTS; ${ROOT_ROOT} # aliBuild; ${ROOTSYS} # upstream; $ENV{ROOTSYS} # upstream; ${SIMPATH} # FairSoft; ); include(FindPackageHandleStandardArgs); find_package_handle_standard_args(ROOT CONFIG_MODE); include(${ROOT_USE_FILE}); ```; which is called in a `CMakeLists.txt` like this; ```cmake; find_package(ROOT 6.10.04 REQUIRED); ```. Please see the commit messages for more details about the issues we had. Best regards,; Dennis",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/916
https://github.com/root-project/root/pull/916:350,Modifiability,CONFIG,CONFIG,350,"Dear ROOT team,. while integrating some CMake functionality provided by ROOT through the `ROOT_USE_FILE` include into our project, some small issues came up. If we are mistaken and there are better solutions than the one I provided, your advice is very welcome. Our `FindROOT.cmake` implementation looks like this:; ```cmake; find_package(ROOT QUIET CONFIG; HINTS; ${ROOT_ROOT} # aliBuild; ${ROOTSYS} # upstream; $ENV{ROOTSYS} # upstream; ${SIMPATH} # FairSoft; ); include(FindPackageHandleStandardArgs); find_package_handle_standard_args(ROOT CONFIG_MODE); include(${ROOT_USE_FILE}); ```; which is called in a `CMakeLists.txt` like this; ```cmake; find_package(ROOT 6.10.04 REQUIRED); ```. Please see the commit messages for more details about the issues we had. Best regards,; Dennis",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/916
https://github.com/root-project/root/pull/917:287,Availability,error,errors,287,"This introduces TStatusBitsChecker which allows to check whether there is 'Status bits' overlap in a given class hierarchy. Expectedly, there are several overlaps .... This merge request also annotate (by properly naming the enum type as EStatusBits) as needed and resolves the reported errors in core, io/io, tree/tree and hist/hist. Some overlaps can not be resolve to preserve forward compatibility and after analysis of which bit is overlapping should be 'harmless' and thus are marked to be ignored by the checker tools (by adding a enum type named EStatusBitsDupExceptions). Usage example:; ```; return TStatusBitsChecker::CheckAlClasses();. // or without EStatusBitsDupExceptions in TStreamerElement.; TStatusBitsChecker::Check(""TStreamerElement"");. Error in <TStatusBitsChecker>: In TStreamerElement class hierarchy, there are duplicates bits:; Error in <TStatusBitsChecker>: Bit 6 used in TStreamerElement as kHasRange; Error in <TStatusBitsChecker>: Bit 6 used in TObject as kCannotPick; Error in <TStatusBitsChecker>: Bit 13 used in TStreamerElement as kDoNotDelete; Error in <TStatusBitsChecker>: Bit 13 used in TObject as kInvalidObject; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/917
https://github.com/root-project/root/pull/917:757,Availability,Error,Error,757,"This introduces TStatusBitsChecker which allows to check whether there is 'Status bits' overlap in a given class hierarchy. Expectedly, there are several overlaps .... This merge request also annotate (by properly naming the enum type as EStatusBits) as needed and resolves the reported errors in core, io/io, tree/tree and hist/hist. Some overlaps can not be resolve to preserve forward compatibility and after analysis of which bit is overlapping should be 'harmless' and thus are marked to be ignored by the checker tools (by adding a enum type named EStatusBitsDupExceptions). Usage example:; ```; return TStatusBitsChecker::CheckAlClasses();. // or without EStatusBitsDupExceptions in TStreamerElement.; TStatusBitsChecker::Check(""TStreamerElement"");. Error in <TStatusBitsChecker>: In TStreamerElement class hierarchy, there are duplicates bits:; Error in <TStatusBitsChecker>: Bit 6 used in TStreamerElement as kHasRange; Error in <TStatusBitsChecker>: Bit 6 used in TObject as kCannotPick; Error in <TStatusBitsChecker>: Bit 13 used in TStreamerElement as kDoNotDelete; Error in <TStatusBitsChecker>: Bit 13 used in TObject as kInvalidObject; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/917
https://github.com/root-project/root/pull/917:853,Availability,Error,Error,853,"This introduces TStatusBitsChecker which allows to check whether there is 'Status bits' overlap in a given class hierarchy. Expectedly, there are several overlaps .... This merge request also annotate (by properly naming the enum type as EStatusBits) as needed and resolves the reported errors in core, io/io, tree/tree and hist/hist. Some overlaps can not be resolve to preserve forward compatibility and after analysis of which bit is overlapping should be 'harmless' and thus are marked to be ignored by the checker tools (by adding a enum type named EStatusBitsDupExceptions). Usage example:; ```; return TStatusBitsChecker::CheckAlClasses();. // or without EStatusBitsDupExceptions in TStreamerElement.; TStatusBitsChecker::Check(""TStreamerElement"");. Error in <TStatusBitsChecker>: In TStreamerElement class hierarchy, there are duplicates bits:; Error in <TStatusBitsChecker>: Bit 6 used in TStreamerElement as kHasRange; Error in <TStatusBitsChecker>: Bit 6 used in TObject as kCannotPick; Error in <TStatusBitsChecker>: Bit 13 used in TStreamerElement as kDoNotDelete; Error in <TStatusBitsChecker>: Bit 13 used in TObject as kInvalidObject; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/917
https://github.com/root-project/root/pull/917:929,Availability,Error,Error,929,"This introduces TStatusBitsChecker which allows to check whether there is 'Status bits' overlap in a given class hierarchy. Expectedly, there are several overlaps .... This merge request also annotate (by properly naming the enum type as EStatusBits) as needed and resolves the reported errors in core, io/io, tree/tree and hist/hist. Some overlaps can not be resolve to preserve forward compatibility and after analysis of which bit is overlapping should be 'harmless' and thus are marked to be ignored by the checker tools (by adding a enum type named EStatusBitsDupExceptions). Usage example:; ```; return TStatusBitsChecker::CheckAlClasses();. // or without EStatusBitsDupExceptions in TStreamerElement.; TStatusBitsChecker::Check(""TStreamerElement"");. Error in <TStatusBitsChecker>: In TStreamerElement class hierarchy, there are duplicates bits:; Error in <TStatusBitsChecker>: Bit 6 used in TStreamerElement as kHasRange; Error in <TStatusBitsChecker>: Bit 6 used in TObject as kCannotPick; Error in <TStatusBitsChecker>: Bit 13 used in TStreamerElement as kDoNotDelete; Error in <TStatusBitsChecker>: Bit 13 used in TObject as kInvalidObject; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/917
https://github.com/root-project/root/pull/917:998,Availability,Error,Error,998,"This introduces TStatusBitsChecker which allows to check whether there is 'Status bits' overlap in a given class hierarchy. Expectedly, there are several overlaps .... This merge request also annotate (by properly naming the enum type as EStatusBits) as needed and resolves the reported errors in core, io/io, tree/tree and hist/hist. Some overlaps can not be resolve to preserve forward compatibility and after analysis of which bit is overlapping should be 'harmless' and thus are marked to be ignored by the checker tools (by adding a enum type named EStatusBitsDupExceptions). Usage example:; ```; return TStatusBitsChecker::CheckAlClasses();. // or without EStatusBitsDupExceptions in TStreamerElement.; TStatusBitsChecker::Check(""TStreamerElement"");. Error in <TStatusBitsChecker>: In TStreamerElement class hierarchy, there are duplicates bits:; Error in <TStatusBitsChecker>: Bit 6 used in TStreamerElement as kHasRange; Error in <TStatusBitsChecker>: Bit 6 used in TObject as kCannotPick; Error in <TStatusBitsChecker>: Bit 13 used in TStreamerElement as kDoNotDelete; Error in <TStatusBitsChecker>: Bit 13 used in TObject as kInvalidObject; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/917
https://github.com/root-project/root/pull/917:1078,Availability,Error,Error,1078,"This introduces TStatusBitsChecker which allows to check whether there is 'Status bits' overlap in a given class hierarchy. Expectedly, there are several overlaps .... This merge request also annotate (by properly naming the enum type as EStatusBits) as needed and resolves the reported errors in core, io/io, tree/tree and hist/hist. Some overlaps can not be resolve to preserve forward compatibility and after analysis of which bit is overlapping should be 'harmless' and thus are marked to be ignored by the checker tools (by adding a enum type named EStatusBitsDupExceptions). Usage example:; ```; return TStatusBitsChecker::CheckAlClasses();. // or without EStatusBitsDupExceptions in TStreamerElement.; TStatusBitsChecker::Check(""TStreamerElement"");. Error in <TStatusBitsChecker>: In TStreamerElement class hierarchy, there are duplicates bits:; Error in <TStatusBitsChecker>: Bit 6 used in TStreamerElement as kHasRange; Error in <TStatusBitsChecker>: Bit 6 used in TObject as kCannotPick; Error in <TStatusBitsChecker>: Bit 13 used in TStreamerElement as kDoNotDelete; Error in <TStatusBitsChecker>: Bit 13 used in TObject as kInvalidObject; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/917
https://github.com/root-project/root/pull/919:84,Testability,test,test,84,A [related PR](https://github.com/root-project/roottest/pull/74) in roottest adds a test for this case.; The fix will be backported to v6.10.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/919
https://github.com/root-project/root/pull/920:26,Testability,test,test,26,PR #75 in roottest adds a test for this case.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/920
https://github.com/root-project/root/pull/921:51,Availability,failure,failures,51,"We will probably see an increasing amount of these failures with; C++ modules as we now deserialize all declarations instead of just; the PCH ones. To safe us a lot of debugging time on where to push; the needed transaction, let's directly print the stack trace here; in the rare case that we crash here.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/921
https://github.com/root-project/root/pull/921:151,Safety,safe,safe,151,"We will probably see an increasing amount of these failures with; C++ modules as we now deserialize all declarations instead of just; the PCH ones. To safe us a lot of debugging time on where to push; the needed transaction, let's directly print the stack trace here; in the rare case that we crash here.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/921
https://github.com/root-project/root/pull/922:53,Deployability,configurat,configuration,53,This is a preparation because we want to ship module configuration; files in the future in the cling resource directory (Clang VFS overlay; files and modulemaps). This means that we will need to know this path; in a few other places (e.g. where we specify the -ivfsoverlayPATH; arguments and potential -fmodule-map-file=PATH args). It also makes this giant function a bit easier on the eyes.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/922
https://github.com/root-project/root/pull/922:53,Modifiability,config,configuration,53,This is a preparation because we want to ship module configuration; files in the future in the cling resource directory (Clang VFS overlay; files and modulemaps). This means that we will need to know this path; in a few other places (e.g. where we specify the -ivfsoverlayPATH; arguments and potential -fmodule-map-file=PATH args). It also makes this giant function a bit easier on the eyes.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/922
https://github.com/root-project/root/pull/923:114,Availability,error,error,114,This fixes that regex characters in the source directory path; cause the CMake configuration to fail with cryptic error messages. This happens because we interpret the source directory as a regex in a; few places in our CMake code.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/923
https://github.com/root-project/root/pull/923:79,Deployability,configurat,configuration,79,This fixes that regex characters in the source directory path; cause the CMake configuration to fail with cryptic error messages. This happens because we interpret the source directory as a regex in a; few places in our CMake code.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/923
https://github.com/root-project/root/pull/923:120,Integrability,message,messages,120,This fixes that regex characters in the source directory path; cause the CMake configuration to fail with cryptic error messages. This happens because we interpret the source directory as a regex in a; few places in our CMake code.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/923
https://github.com/root-project/root/pull/923:79,Modifiability,config,configuration,79,This fixes that regex characters in the source directory path; cause the CMake configuration to fail with cryptic error messages. This happens because we interpret the source directory as a regex in a; few places in our CMake code.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/923
https://github.com/root-project/root/pull/924:807,Integrability,depend,depends,807,"This PR moves the responsibility of knowing which custom columns have been defined at which point of the functional graph from `TCustomColumn` to `TInterface`. As an added improvement `TInterface` now checks that custom columns do not override each other (which was wrongly allowed before). As a consequence, `TCustomColumn` nodes are not required to be in the functional graph anymore (their function was to signal the point where a certain column name became valid), allowing simplifications of the graph traversing that TDF does during the event loop (e.g. to check all filters in a functional chain). `Define` now returns the same type as the node it was called on rather than `TInterface<TCustomColumn<Fun, PrevNode>>`. For this reason this PR is expected to break `test_templateRecursionLimit`, which depends on the exact type returned by `Define`. The test will be fixed by a separate PR to roottest.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/924
https://github.com/root-project/root/pull/924:859,Testability,test,test,859,"This PR moves the responsibility of knowing which custom columns have been defined at which point of the functional graph from `TCustomColumn` to `TInterface`. As an added improvement `TInterface` now checks that custom columns do not override each other (which was wrongly allowed before). As a consequence, `TCustomColumn` nodes are not required to be in the functional graph anymore (their function was to signal the point where a certain column name became valid), allowing simplifications of the graph traversing that TDF does during the event loop (e.g. to check all filters in a functional chain). `Define` now returns the same type as the node it was called on rather than `TInterface<TCustomColumn<Fun, PrevNode>>`. For this reason this PR is expected to break `test_templateRecursionLimit`, which depends on the exact type returned by `Define`. The test will be fixed by a separate PR to roottest.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/924
https://github.com/root-project/root/pull/924:478,Usability,simpl,simplifications,478,"This PR moves the responsibility of knowing which custom columns have been defined at which point of the functional graph from `TCustomColumn` to `TInterface`. As an added improvement `TInterface` now checks that custom columns do not override each other (which was wrongly allowed before). As a consequence, `TCustomColumn` nodes are not required to be in the functional graph anymore (their function was to signal the point where a certain column name became valid), allowing simplifications of the graph traversing that TDF does during the event loop (e.g. to check all filters in a functional chain). `Define` now returns the same type as the node it was called on rather than `TInterface<TCustomColumn<Fun, PrevNode>>`. For this reason this PR is expected to break `test_templateRecursionLimit`, which depends on the exact type returned by `Define`. The test will be fixed by a separate PR to roottest.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/924
https://github.com/root-project/root/pull/928:1220,Availability,error,errors,1220,"er generator via `gsl_rng_alloc()`. When the `GSLMCIntegrator` instance goes out of scope, its dtor is invoked which deletes the `GSLRngWrapper` pointer and thus invokes its dtor as well. However, `~GSLRngWrapper()` frees the allocated memory only if `fOwn` pointer is set to true, which is only set so in the assignment operator, but not in the `Allocate()` member function. Therefore, the `GSLMCIntegrator` class is leaking memory. This poses a problem, when doing a large number of integrations inside a for loop. The leak was discovered by running valgrind and inspecting the code. Minimal example:; ```cpp; #include <Math/GSLMCIntegrator.h> // ROOT::Math::GSLMCIntegrator. /* built with:. g++ -ggdb3 -Og `root-config --cflags` mcintegrator.cpp -o mcintegrator \; `root-config --libs` -lMathMore. */. int; main(); {; for(unsigned i = 0; i < 20000; ++i); {; ROOT::Math::GSLMCIntegrator vegas(""vegas"", 0., 1.e-1, 10);; }; return 0;; }; ```. Before fix:; ```; valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \; --undef-value-errors=no ./mcintegrator. ==12320== Memcheck, a memory error detector; ==12320== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al.; ==12320== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info; ==12320== Command: ./mcintegrator; ==12320==; ==12320==; ==12320== HEAP SUMMARY:; ==12320== in use at exit: 100,655,858 bytes in 44,260 blocks; ==12320== total heap usage: 67,782 allocs, 23,522 frees, 101,539,078 bytes allocated; ==12320==; ==12320== 99,089,984 (319,984 direct, 98,770,000 indirect) bytes in 19,999 blocks are definitely lost in loss record 3,515 of 3,515; ==12320== at 0x4C2BE7F: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so); ==12320== by 0xAD090F2: gsl_rng_alloc (in /usr/lib/libgsl.so.23.0.0); ==12320== by 0x8223765: Allocate (GSLRngWrapper.h:99); ==12320== by 0x8223765: ROOT::Math::GSLMCIntegrator::GSLMCIntegrator(char const*, double, double, unsigned int) (GSLMCIntegrator.cxx:117); ==",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:1275,Availability,error,error,1275,"LRngWrapper` pointer and thus invokes its dtor as well. However, `~GSLRngWrapper()` frees the allocated memory only if `fOwn` pointer is set to true, which is only set so in the assignment operator, but not in the `Allocate()` member function. Therefore, the `GSLMCIntegrator` class is leaking memory. This poses a problem, when doing a large number of integrations inside a for loop. The leak was discovered by running valgrind and inspecting the code. Minimal example:; ```cpp; #include <Math/GSLMCIntegrator.h> // ROOT::Math::GSLMCIntegrator. /* built with:. g++ -ggdb3 -Og `root-config --cflags` mcintegrator.cpp -o mcintegrator \; `root-config --libs` -lMathMore. */. int; main(); {; for(unsigned i = 0; i < 20000; ++i); {; ROOT::Math::GSLMCIntegrator vegas(""vegas"", 0., 1.e-1, 10);; }; return 0;; }; ```. Before fix:; ```; valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \; --undef-value-errors=no ./mcintegrator. ==12320== Memcheck, a memory error detector; ==12320== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al.; ==12320== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info; ==12320== Command: ./mcintegrator; ==12320==; ==12320==; ==12320== HEAP SUMMARY:; ==12320== in use at exit: 100,655,858 bytes in 44,260 blocks; ==12320== total heap usage: 67,782 allocs, 23,522 frees, 101,539,078 bytes allocated; ==12320==; ==12320== 99,089,984 (319,984 direct, 98,770,000 indirect) bytes in 19,999 blocks are definitely lost in loss record 3,515 of 3,515; ==12320== at 0x4C2BE7F: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so); ==12320== by 0xAD090F2: gsl_rng_alloc (in /usr/lib/libgsl.so.23.0.0); ==12320== by 0x8223765: Allocate (GSLRngWrapper.h:99); ==12320== by 0x8223765: ROOT::Math::GSLMCIntegrator::GSLMCIntegrator(char const*, double, double, unsigned int) (GSLMCIntegrator.cxx:117); ==12320== by 0x108BF5: main (mcintegrator.cpp:8); ==12320==; ==12320== LEAK SUMMARY:; ==12320== definitely lost: 319,984 bytes in 19,9",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:2750,Availability,error,errors,2750,"0 indirect) bytes in 19,999 blocks are definitely lost in loss record 3,515 of 3,515; ==12320== at 0x4C2BE7F: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so); ==12320== by 0xAD090F2: gsl_rng_alloc (in /usr/lib/libgsl.so.23.0.0); ==12320== by 0x8223765: Allocate (GSLRngWrapper.h:99); ==12320== by 0x8223765: ROOT::Math::GSLMCIntegrator::GSLMCIntegrator(char const*, double, double, unsigned int) (GSLMCIntegrator.cxx:117); ==12320== by 0x108BF5: main (mcintegrator.cpp:8); ==12320==; ==12320== LEAK SUMMARY:; ==12320== definitely lost: 319,984 bytes in 19,999 blocks; ==12320== indirectly lost: 98,770,000 bytes in 19,754 blocks; ==12320== possibly lost: 1,225,000 bytes in 245 blocks; ==12320== still reachable: 340,874 bytes in 4,262 blocks; ==12320== suppressed: 0 bytes in 0 blocks; ==12320== Reachable blocks (those to which a pointer was found) are not shown.; ==12320== To see them, rerun with: --leak-check=full --show-leak-kinds=all; ==12320==; ==12320== For counts of detected and suppressed errors, rerun with: -v; ==12320== ERROR SUMMARY: 2 errors from 2 contexts (suppressed: 0 from 0); ```. After fix:; ```; valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \; --undef-value-errors=no ./mcintegrator. ==14294== Memcheck, a memory error detector; ==14294== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al.; ==14294== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info; ==14294== Command: ./mcintegrator; ==14294==; ==14294==; ==14294== HEAP SUMMARY:; ==14294== in use at exit: 335,858 bytes in 4,260 blocks; ==14294== total heap usage: 67,782 allocs, 63,522 frees, 101,539,078 bytes allocated; ==14294==; ==14294== LEAK SUMMARY:; ==14294== definitely lost: 0 bytes in 0 blocks; ==14294== indirectly lost: 0 bytes in 0 blocks; ==14294== possibly lost: 0 bytes in 0 blocks; ==14294== still reachable: 335,858 bytes in 4,260 blocks; ==14294== suppressed: 0 bytes in 0 blocks; ==14294== Reachable blocks (those to which a poi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:2784,Availability,ERROR,ERROR,2784,"0 indirect) bytes in 19,999 blocks are definitely lost in loss record 3,515 of 3,515; ==12320== at 0x4C2BE7F: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so); ==12320== by 0xAD090F2: gsl_rng_alloc (in /usr/lib/libgsl.so.23.0.0); ==12320== by 0x8223765: Allocate (GSLRngWrapper.h:99); ==12320== by 0x8223765: ROOT::Math::GSLMCIntegrator::GSLMCIntegrator(char const*, double, double, unsigned int) (GSLMCIntegrator.cxx:117); ==12320== by 0x108BF5: main (mcintegrator.cpp:8); ==12320==; ==12320== LEAK SUMMARY:; ==12320== definitely lost: 319,984 bytes in 19,999 blocks; ==12320== indirectly lost: 98,770,000 bytes in 19,754 blocks; ==12320== possibly lost: 1,225,000 bytes in 245 blocks; ==12320== still reachable: 340,874 bytes in 4,262 blocks; ==12320== suppressed: 0 bytes in 0 blocks; ==12320== Reachable blocks (those to which a pointer was found) are not shown.; ==12320== To see them, rerun with: --leak-check=full --show-leak-kinds=all; ==12320==; ==12320== For counts of detected and suppressed errors, rerun with: -v; ==12320== ERROR SUMMARY: 2 errors from 2 contexts (suppressed: 0 from 0); ```. After fix:; ```; valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \; --undef-value-errors=no ./mcintegrator. ==14294== Memcheck, a memory error detector; ==14294== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al.; ==14294== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info; ==14294== Command: ./mcintegrator; ==14294==; ==14294==; ==14294== HEAP SUMMARY:; ==14294== in use at exit: 335,858 bytes in 4,260 blocks; ==14294== total heap usage: 67,782 allocs, 63,522 frees, 101,539,078 bytes allocated; ==14294==; ==14294== LEAK SUMMARY:; ==14294== definitely lost: 0 bytes in 0 blocks; ==14294== indirectly lost: 0 bytes in 0 blocks; ==14294== possibly lost: 0 bytes in 0 blocks; ==14294== still reachable: 335,858 bytes in 4,260 blocks; ==14294== suppressed: 0 bytes in 0 blocks; ==14294== Reachable blocks (those to which a poi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:2801,Availability,error,errors,2801,"0 indirect) bytes in 19,999 blocks are definitely lost in loss record 3,515 of 3,515; ==12320== at 0x4C2BE7F: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so); ==12320== by 0xAD090F2: gsl_rng_alloc (in /usr/lib/libgsl.so.23.0.0); ==12320== by 0x8223765: Allocate (GSLRngWrapper.h:99); ==12320== by 0x8223765: ROOT::Math::GSLMCIntegrator::GSLMCIntegrator(char const*, double, double, unsigned int) (GSLMCIntegrator.cxx:117); ==12320== by 0x108BF5: main (mcintegrator.cpp:8); ==12320==; ==12320== LEAK SUMMARY:; ==12320== definitely lost: 319,984 bytes in 19,999 blocks; ==12320== indirectly lost: 98,770,000 bytes in 19,754 blocks; ==12320== possibly lost: 1,225,000 bytes in 245 blocks; ==12320== still reachable: 340,874 bytes in 4,262 blocks; ==12320== suppressed: 0 bytes in 0 blocks; ==12320== Reachable blocks (those to which a pointer was found) are not shown.; ==12320== To see them, rerun with: --leak-check=full --show-leak-kinds=all; ==12320==; ==12320== For counts of detected and suppressed errors, rerun with: -v; ==12320== ERROR SUMMARY: 2 errors from 2 contexts (suppressed: 0 from 0); ```. After fix:; ```; valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \; --undef-value-errors=no ./mcintegrator. ==14294== Memcheck, a memory error detector; ==14294== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al.; ==14294== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info; ==14294== Command: ./mcintegrator; ==14294==; ==14294==; ==14294== HEAP SUMMARY:; ==14294== in use at exit: 335,858 bytes in 4,260 blocks; ==14294== total heap usage: 67,782 allocs, 63,522 frees, 101,539,078 bytes allocated; ==14294==; ==14294== LEAK SUMMARY:; ==14294== definitely lost: 0 bytes in 0 blocks; ==14294== indirectly lost: 0 bytes in 0 blocks; ==14294== possibly lost: 0 bytes in 0 blocks; ==14294== still reachable: 335,858 bytes in 4,260 blocks; ==14294== suppressed: 0 bytes in 0 blocks; ==14294== Reachable blocks (those to which a poi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:2957,Availability,error,errors,2957,"2320== by 0xAD090F2: gsl_rng_alloc (in /usr/lib/libgsl.so.23.0.0); ==12320== by 0x8223765: Allocate (GSLRngWrapper.h:99); ==12320== by 0x8223765: ROOT::Math::GSLMCIntegrator::GSLMCIntegrator(char const*, double, double, unsigned int) (GSLMCIntegrator.cxx:117); ==12320== by 0x108BF5: main (mcintegrator.cpp:8); ==12320==; ==12320== LEAK SUMMARY:; ==12320== definitely lost: 319,984 bytes in 19,999 blocks; ==12320== indirectly lost: 98,770,000 bytes in 19,754 blocks; ==12320== possibly lost: 1,225,000 bytes in 245 blocks; ==12320== still reachable: 340,874 bytes in 4,262 blocks; ==12320== suppressed: 0 bytes in 0 blocks; ==12320== Reachable blocks (those to which a pointer was found) are not shown.; ==12320== To see them, rerun with: --leak-check=full --show-leak-kinds=all; ==12320==; ==12320== For counts of detected and suppressed errors, rerun with: -v; ==12320== ERROR SUMMARY: 2 errors from 2 contexts (suppressed: 0 from 0); ```. After fix:; ```; valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \; --undef-value-errors=no ./mcintegrator. ==14294== Memcheck, a memory error detector; ==14294== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al.; ==14294== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info; ==14294== Command: ./mcintegrator; ==14294==; ==14294==; ==14294== HEAP SUMMARY:; ==14294== in use at exit: 335,858 bytes in 4,260 blocks; ==14294== total heap usage: 67,782 allocs, 63,522 frees, 101,539,078 bytes allocated; ==14294==; ==14294== LEAK SUMMARY:; ==14294== definitely lost: 0 bytes in 0 blocks; ==14294== indirectly lost: 0 bytes in 0 blocks; ==14294== possibly lost: 0 bytes in 0 blocks; ==14294== still reachable: 335,858 bytes in 4,260 blocks; ==14294== suppressed: 0 bytes in 0 blocks; ==14294== Reachable blocks (those to which a pointer was found) are not shown.; ==14294== To see them, rerun with: --leak-check=full --show-leak-kinds=all; ==14294==; ==14294== For counts of detected and suppressed errors, re",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:3012,Availability,error,error,3012,"Allocate (GSLRngWrapper.h:99); ==12320== by 0x8223765: ROOT::Math::GSLMCIntegrator::GSLMCIntegrator(char const*, double, double, unsigned int) (GSLMCIntegrator.cxx:117); ==12320== by 0x108BF5: main (mcintegrator.cpp:8); ==12320==; ==12320== LEAK SUMMARY:; ==12320== definitely lost: 319,984 bytes in 19,999 blocks; ==12320== indirectly lost: 98,770,000 bytes in 19,754 blocks; ==12320== possibly lost: 1,225,000 bytes in 245 blocks; ==12320== still reachable: 340,874 bytes in 4,262 blocks; ==12320== suppressed: 0 bytes in 0 blocks; ==12320== Reachable blocks (those to which a pointer was found) are not shown.; ==12320== To see them, rerun with: --leak-check=full --show-leak-kinds=all; ==12320==; ==12320== For counts of detected and suppressed errors, rerun with: -v; ==12320== ERROR SUMMARY: 2 errors from 2 contexts (suppressed: 0 from 0); ```. After fix:; ```; valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \; --undef-value-errors=no ./mcintegrator. ==14294== Memcheck, a memory error detector; ==14294== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al.; ==14294== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info; ==14294== Command: ./mcintegrator; ==14294==; ==14294==; ==14294== HEAP SUMMARY:; ==14294== in use at exit: 335,858 bytes in 4,260 blocks; ==14294== total heap usage: 67,782 allocs, 63,522 frees, 101,539,078 bytes allocated; ==14294==; ==14294== LEAK SUMMARY:; ==14294== definitely lost: 0 bytes in 0 blocks; ==14294== indirectly lost: 0 bytes in 0 blocks; ==14294== possibly lost: 0 bytes in 0 blocks; ==14294== still reachable: 335,858 bytes in 4,260 blocks; ==14294== suppressed: 0 bytes in 0 blocks; ==14294== Reachable blocks (those to which a pointer was found) are not shown.; ==14294== To see them, rerun with: --leak-check=full --show-leak-kinds=all; ==14294==; ==14294== For counts of detected and suppressed errors, rerun with: -v; ==14294== ERROR SUMMARY: 0 errors from 0 contexts (suppressed: 0 from 0); ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:3900,Availability,error,errors,3900,"Allocate (GSLRngWrapper.h:99); ==12320== by 0x8223765: ROOT::Math::GSLMCIntegrator::GSLMCIntegrator(char const*, double, double, unsigned int) (GSLMCIntegrator.cxx:117); ==12320== by 0x108BF5: main (mcintegrator.cpp:8); ==12320==; ==12320== LEAK SUMMARY:; ==12320== definitely lost: 319,984 bytes in 19,999 blocks; ==12320== indirectly lost: 98,770,000 bytes in 19,754 blocks; ==12320== possibly lost: 1,225,000 bytes in 245 blocks; ==12320== still reachable: 340,874 bytes in 4,262 blocks; ==12320== suppressed: 0 bytes in 0 blocks; ==12320== Reachable blocks (those to which a pointer was found) are not shown.; ==12320== To see them, rerun with: --leak-check=full --show-leak-kinds=all; ==12320==; ==12320== For counts of detected and suppressed errors, rerun with: -v; ==12320== ERROR SUMMARY: 2 errors from 2 contexts (suppressed: 0 from 0); ```. After fix:; ```; valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \; --undef-value-errors=no ./mcintegrator. ==14294== Memcheck, a memory error detector; ==14294== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al.; ==14294== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info; ==14294== Command: ./mcintegrator; ==14294==; ==14294==; ==14294== HEAP SUMMARY:; ==14294== in use at exit: 335,858 bytes in 4,260 blocks; ==14294== total heap usage: 67,782 allocs, 63,522 frees, 101,539,078 bytes allocated; ==14294==; ==14294== LEAK SUMMARY:; ==14294== definitely lost: 0 bytes in 0 blocks; ==14294== indirectly lost: 0 bytes in 0 blocks; ==14294== possibly lost: 0 bytes in 0 blocks; ==14294== still reachable: 335,858 bytes in 4,260 blocks; ==14294== suppressed: 0 bytes in 0 blocks; ==14294== Reachable blocks (those to which a pointer was found) are not shown.; ==14294== To see them, rerun with: --leak-check=full --show-leak-kinds=all; ==14294==; ==14294== For counts of detected and suppressed errors, rerun with: -v; ==14294== ERROR SUMMARY: 0 errors from 0 contexts (suppressed: 0 from 0); ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:3934,Availability,ERROR,ERROR,3934,"Allocate (GSLRngWrapper.h:99); ==12320== by 0x8223765: ROOT::Math::GSLMCIntegrator::GSLMCIntegrator(char const*, double, double, unsigned int) (GSLMCIntegrator.cxx:117); ==12320== by 0x108BF5: main (mcintegrator.cpp:8); ==12320==; ==12320== LEAK SUMMARY:; ==12320== definitely lost: 319,984 bytes in 19,999 blocks; ==12320== indirectly lost: 98,770,000 bytes in 19,754 blocks; ==12320== possibly lost: 1,225,000 bytes in 245 blocks; ==12320== still reachable: 340,874 bytes in 4,262 blocks; ==12320== suppressed: 0 bytes in 0 blocks; ==12320== Reachable blocks (those to which a pointer was found) are not shown.; ==12320== To see them, rerun with: --leak-check=full --show-leak-kinds=all; ==12320==; ==12320== For counts of detected and suppressed errors, rerun with: -v; ==12320== ERROR SUMMARY: 2 errors from 2 contexts (suppressed: 0 from 0); ```. After fix:; ```; valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \; --undef-value-errors=no ./mcintegrator. ==14294== Memcheck, a memory error detector; ==14294== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al.; ==14294== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info; ==14294== Command: ./mcintegrator; ==14294==; ==14294==; ==14294== HEAP SUMMARY:; ==14294== in use at exit: 335,858 bytes in 4,260 blocks; ==14294== total heap usage: 67,782 allocs, 63,522 frees, 101,539,078 bytes allocated; ==14294==; ==14294== LEAK SUMMARY:; ==14294== definitely lost: 0 bytes in 0 blocks; ==14294== indirectly lost: 0 bytes in 0 blocks; ==14294== possibly lost: 0 bytes in 0 blocks; ==14294== still reachable: 335,858 bytes in 4,260 blocks; ==14294== suppressed: 0 bytes in 0 blocks; ==14294== Reachable blocks (those to which a pointer was found) are not shown.; ==14294== To see them, rerun with: --leak-check=full --show-leak-kinds=all; ==14294==; ==14294== For counts of detected and suppressed errors, rerun with: -v; ==14294== ERROR SUMMARY: 0 errors from 0 contexts (suppressed: 0 from 0); ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:3951,Availability,error,errors,3951,"Allocate (GSLRngWrapper.h:99); ==12320== by 0x8223765: ROOT::Math::GSLMCIntegrator::GSLMCIntegrator(char const*, double, double, unsigned int) (GSLMCIntegrator.cxx:117); ==12320== by 0x108BF5: main (mcintegrator.cpp:8); ==12320==; ==12320== LEAK SUMMARY:; ==12320== definitely lost: 319,984 bytes in 19,999 blocks; ==12320== indirectly lost: 98,770,000 bytes in 19,754 blocks; ==12320== possibly lost: 1,225,000 bytes in 245 blocks; ==12320== still reachable: 340,874 bytes in 4,262 blocks; ==12320== suppressed: 0 bytes in 0 blocks; ==12320== Reachable blocks (those to which a pointer was found) are not shown.; ==12320== To see them, rerun with: --leak-check=full --show-leak-kinds=all; ==12320==; ==12320== For counts of detected and suppressed errors, rerun with: -v; ==12320== ERROR SUMMARY: 2 errors from 2 contexts (suppressed: 0 from 0); ```. After fix:; ```; valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \; --undef-value-errors=no ./mcintegrator. ==14294== Memcheck, a memory error detector; ==14294== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al.; ==14294== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info; ==14294== Command: ./mcintegrator; ==14294==; ==14294==; ==14294== HEAP SUMMARY:; ==14294== in use at exit: 335,858 bytes in 4,260 blocks; ==14294== total heap usage: 67,782 allocs, 63,522 frees, 101,539,078 bytes allocated; ==14294==; ==14294== LEAK SUMMARY:; ==14294== definitely lost: 0 bytes in 0 blocks; ==14294== indirectly lost: 0 bytes in 0 blocks; ==14294== possibly lost: 0 bytes in 0 blocks; ==14294== still reachable: 335,858 bytes in 4,260 blocks; ==14294== suppressed: 0 bytes in 0 blocks; ==14294== Reachable blocks (those to which a pointer was found) are not shown.; ==14294== To see them, rerun with: --leak-check=full --show-leak-kinds=all; ==14294==; ==14294== For counts of detected and suppressed errors, rerun with: -v; ==14294== ERROR SUMMARY: 0 errors from 0 contexts (suppressed: 0 from 0); ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:657,Deployability,integrat,integrations,657,"The ctor of `GSLMCIntegrator` creates a `GSLRngWrapper` instance on the heap and calls its `Allocate()` member function which in turn allocates memory for a GSL random number generator via `gsl_rng_alloc()`. When the `GSLMCIntegrator` instance goes out of scope, its dtor is invoked which deletes the `GSLRngWrapper` pointer and thus invokes its dtor as well. However, `~GSLRngWrapper()` frees the allocated memory only if `fOwn` pointer is set to true, which is only set so in the assignment operator, but not in the `Allocate()` member function. Therefore, the `GSLMCIntegrator` class is leaking memory. This poses a problem, when doing a large number of integrations inside a for loop. The leak was discovered by running valgrind and inspecting the code. Minimal example:; ```cpp; #include <Math/GSLMCIntegrator.h> // ROOT::Math::GSLMCIntegrator. /* built with:. g++ -ggdb3 -Og `root-config --cflags` mcintegrator.cpp -o mcintegrator \; `root-config --libs` -lMathMore. */. int; main(); {; for(unsigned i = 0; i < 20000; ++i); {; ROOT::Math::GSLMCIntegrator vegas(""vegas"", 0., 1.e-1, 10);; }; return 0;; }; ```. Before fix:; ```; valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \; --undef-value-errors=no ./mcintegrator. ==12320== Memcheck, a memory error detector; ==12320== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al.; ==12320== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info; ==12320== Command: ./mcintegrator; ==12320==; ==12320==; ==12320== HEAP SUMMARY:; ==12320== in use at exit: 100,655,858 bytes in 44,260 blocks; ==12320== total heap usage: 67,782 allocs, 23,522 frees, 101,539,078 bytes allocated; ==12320==; ==12320== 99,089,984 (319,984 direct, 98,770,000 indirect) bytes in 19,999 blocks are definitely lost in loss record 3,515 of 3,515; ==12320== at 0x4C2BE7F: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so); ==12320== by 0xAD090F2: gsl_rng_alloc (in /usr/lib/libgsl.so.23.0.0); ==12320== by 0x8223765: ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:92,Energy Efficiency,Allocate,Allocate,92,"The ctor of `GSLMCIntegrator` creates a `GSLRngWrapper` instance on the heap and calls its `Allocate()` member function which in turn allocates memory for a GSL random number generator via `gsl_rng_alloc()`. When the `GSLMCIntegrator` instance goes out of scope, its dtor is invoked which deletes the `GSLRngWrapper` pointer and thus invokes its dtor as well. However, `~GSLRngWrapper()` frees the allocated memory only if `fOwn` pointer is set to true, which is only set so in the assignment operator, but not in the `Allocate()` member function. Therefore, the `GSLMCIntegrator` class is leaking memory. This poses a problem, when doing a large number of integrations inside a for loop. The leak was discovered by running valgrind and inspecting the code. Minimal example:; ```cpp; #include <Math/GSLMCIntegrator.h> // ROOT::Math::GSLMCIntegrator. /* built with:. g++ -ggdb3 -Og `root-config --cflags` mcintegrator.cpp -o mcintegrator \; `root-config --libs` -lMathMore. */. int; main(); {; for(unsigned i = 0; i < 20000; ++i); {; ROOT::Math::GSLMCIntegrator vegas(""vegas"", 0., 1.e-1, 10);; }; return 0;; }; ```. Before fix:; ```; valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \; --undef-value-errors=no ./mcintegrator. ==12320== Memcheck, a memory error detector; ==12320== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al.; ==12320== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info; ==12320== Command: ./mcintegrator; ==12320==; ==12320==; ==12320== HEAP SUMMARY:; ==12320== in use at exit: 100,655,858 bytes in 44,260 blocks; ==12320== total heap usage: 67,782 allocs, 23,522 frees, 101,539,078 bytes allocated; ==12320==; ==12320== 99,089,984 (319,984 direct, 98,770,000 indirect) bytes in 19,999 blocks are definitely lost in loss record 3,515 of 3,515; ==12320== at 0x4C2BE7F: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so); ==12320== by 0xAD090F2: gsl_rng_alloc (in /usr/lib/libgsl.so.23.0.0); ==12320== by 0x8223765: ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:134,Energy Efficiency,allocate,allocates,134,"The ctor of `GSLMCIntegrator` creates a `GSLRngWrapper` instance on the heap and calls its `Allocate()` member function which in turn allocates memory for a GSL random number generator via `gsl_rng_alloc()`. When the `GSLMCIntegrator` instance goes out of scope, its dtor is invoked which deletes the `GSLRngWrapper` pointer and thus invokes its dtor as well. However, `~GSLRngWrapper()` frees the allocated memory only if `fOwn` pointer is set to true, which is only set so in the assignment operator, but not in the `Allocate()` member function. Therefore, the `GSLMCIntegrator` class is leaking memory. This poses a problem, when doing a large number of integrations inside a for loop. The leak was discovered by running valgrind and inspecting the code. Minimal example:; ```cpp; #include <Math/GSLMCIntegrator.h> // ROOT::Math::GSLMCIntegrator. /* built with:. g++ -ggdb3 -Og `root-config --cflags` mcintegrator.cpp -o mcintegrator \; `root-config --libs` -lMathMore. */. int; main(); {; for(unsigned i = 0; i < 20000; ++i); {; ROOT::Math::GSLMCIntegrator vegas(""vegas"", 0., 1.e-1, 10);; }; return 0;; }; ```. Before fix:; ```; valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \; --undef-value-errors=no ./mcintegrator. ==12320== Memcheck, a memory error detector; ==12320== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al.; ==12320== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info; ==12320== Command: ./mcintegrator; ==12320==; ==12320==; ==12320== HEAP SUMMARY:; ==12320== in use at exit: 100,655,858 bytes in 44,260 blocks; ==12320== total heap usage: 67,782 allocs, 23,522 frees, 101,539,078 bytes allocated; ==12320==; ==12320== 99,089,984 (319,984 direct, 98,770,000 indirect) bytes in 19,999 blocks are definitely lost in loss record 3,515 of 3,515; ==12320== at 0x4C2BE7F: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so); ==12320== by 0xAD090F2: gsl_rng_alloc (in /usr/lib/libgsl.so.23.0.0); ==12320== by 0x8223765: ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:398,Energy Efficiency,allocate,allocated,398,"The ctor of `GSLMCIntegrator` creates a `GSLRngWrapper` instance on the heap and calls its `Allocate()` member function which in turn allocates memory for a GSL random number generator via `gsl_rng_alloc()`. When the `GSLMCIntegrator` instance goes out of scope, its dtor is invoked which deletes the `GSLRngWrapper` pointer and thus invokes its dtor as well. However, `~GSLRngWrapper()` frees the allocated memory only if `fOwn` pointer is set to true, which is only set so in the assignment operator, but not in the `Allocate()` member function. Therefore, the `GSLMCIntegrator` class is leaking memory. This poses a problem, when doing a large number of integrations inside a for loop. The leak was discovered by running valgrind and inspecting the code. Minimal example:; ```cpp; #include <Math/GSLMCIntegrator.h> // ROOT::Math::GSLMCIntegrator. /* built with:. g++ -ggdb3 -Og `root-config --cflags` mcintegrator.cpp -o mcintegrator \; `root-config --libs` -lMathMore. */. int; main(); {; for(unsigned i = 0; i < 20000; ++i); {; ROOT::Math::GSLMCIntegrator vegas(""vegas"", 0., 1.e-1, 10);; }; return 0;; }; ```. Before fix:; ```; valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \; --undef-value-errors=no ./mcintegrator. ==12320== Memcheck, a memory error detector; ==12320== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al.; ==12320== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info; ==12320== Command: ./mcintegrator; ==12320==; ==12320==; ==12320== HEAP SUMMARY:; ==12320== in use at exit: 100,655,858 bytes in 44,260 blocks; ==12320== total heap usage: 67,782 allocs, 23,522 frees, 101,539,078 bytes allocated; ==12320==; ==12320== 99,089,984 (319,984 direct, 98,770,000 indirect) bytes in 19,999 blocks are definitely lost in loss record 3,515 of 3,515; ==12320== at 0x4C2BE7F: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so); ==12320== by 0xAD090F2: gsl_rng_alloc (in /usr/lib/libgsl.so.23.0.0); ==12320== by 0x8223765: ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:519,Energy Efficiency,Allocate,Allocate,519,"The ctor of `GSLMCIntegrator` creates a `GSLRngWrapper` instance on the heap and calls its `Allocate()` member function which in turn allocates memory for a GSL random number generator via `gsl_rng_alloc()`. When the `GSLMCIntegrator` instance goes out of scope, its dtor is invoked which deletes the `GSLRngWrapper` pointer and thus invokes its dtor as well. However, `~GSLRngWrapper()` frees the allocated memory only if `fOwn` pointer is set to true, which is only set so in the assignment operator, but not in the `Allocate()` member function. Therefore, the `GSLMCIntegrator` class is leaking memory. This poses a problem, when doing a large number of integrations inside a for loop. The leak was discovered by running valgrind and inspecting the code. Minimal example:; ```cpp; #include <Math/GSLMCIntegrator.h> // ROOT::Math::GSLMCIntegrator. /* built with:. g++ -ggdb3 -Og `root-config --cflags` mcintegrator.cpp -o mcintegrator \; `root-config --libs` -lMathMore. */. int; main(); {; for(unsigned i = 0; i < 20000; ++i); {; ROOT::Math::GSLMCIntegrator vegas(""vegas"", 0., 1.e-1, 10);; }; return 0;; }; ```. Before fix:; ```; valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \; --undef-value-errors=no ./mcintegrator. ==12320== Memcheck, a memory error detector; ==12320== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al.; ==12320== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info; ==12320== Command: ./mcintegrator; ==12320==; ==12320==; ==12320== HEAP SUMMARY:; ==12320== in use at exit: 100,655,858 bytes in 44,260 blocks; ==12320== total heap usage: 67,782 allocs, 23,522 frees, 101,539,078 bytes allocated; ==12320==; ==12320== 99,089,984 (319,984 direct, 98,770,000 indirect) bytes in 19,999 blocks are definitely lost in loss record 3,515 of 3,515; ==12320== at 0x4C2BE7F: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so); ==12320== by 0xAD090F2: gsl_rng_alloc (in /usr/lib/libgsl.so.23.0.0); ==12320== by 0x8223765: ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:1663,Energy Efficiency,allocate,allocated,1663,"loop. The leak was discovered by running valgrind and inspecting the code. Minimal example:; ```cpp; #include <Math/GSLMCIntegrator.h> // ROOT::Math::GSLMCIntegrator. /* built with:. g++ -ggdb3 -Og `root-config --cflags` mcintegrator.cpp -o mcintegrator \; `root-config --libs` -lMathMore. */. int; main(); {; for(unsigned i = 0; i < 20000; ++i); {; ROOT::Math::GSLMCIntegrator vegas(""vegas"", 0., 1.e-1, 10);; }; return 0;; }; ```. Before fix:; ```; valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \; --undef-value-errors=no ./mcintegrator. ==12320== Memcheck, a memory error detector; ==12320== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al.; ==12320== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info; ==12320== Command: ./mcintegrator; ==12320==; ==12320==; ==12320== HEAP SUMMARY:; ==12320== in use at exit: 100,655,858 bytes in 44,260 blocks; ==12320== total heap usage: 67,782 allocs, 23,522 frees, 101,539,078 bytes allocated; ==12320==; ==12320== 99,089,984 (319,984 direct, 98,770,000 indirect) bytes in 19,999 blocks are definitely lost in loss record 3,515 of 3,515; ==12320== at 0x4C2BE7F: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so); ==12320== by 0xAD090F2: gsl_rng_alloc (in /usr/lib/libgsl.so.23.0.0); ==12320== by 0x8223765: Allocate (GSLRngWrapper.h:99); ==12320== by 0x8223765: ROOT::Math::GSLMCIntegrator::GSLMCIntegrator(char const*, double, double, unsigned int) (GSLMCIntegrator.cxx:117); ==12320== by 0x108BF5: main (mcintegrator.cpp:8); ==12320==; ==12320== LEAK SUMMARY:; ==12320== definitely lost: 319,984 bytes in 19,999 blocks; ==12320== indirectly lost: 98,770,000 bytes in 19,754 blocks; ==12320== possibly lost: 1,225,000 bytes in 245 blocks; ==12320== still reachable: 340,874 bytes in 4,262 blocks; ==12320== suppressed: 0 bytes in 0 blocks; ==12320== Reachable blocks (those to which a pointer was found) are not shown.; ==12320== To see them, rerun with: --leak-check=full --show-leak-kin",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:2001,Energy Efficiency,Allocate,Allocate,2001,"signed i = 0; i < 20000; ++i); {; ROOT::Math::GSLMCIntegrator vegas(""vegas"", 0., 1.e-1, 10);; }; return 0;; }; ```. Before fix:; ```; valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \; --undef-value-errors=no ./mcintegrator. ==12320== Memcheck, a memory error detector; ==12320== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al.; ==12320== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info; ==12320== Command: ./mcintegrator; ==12320==; ==12320==; ==12320== HEAP SUMMARY:; ==12320== in use at exit: 100,655,858 bytes in 44,260 blocks; ==12320== total heap usage: 67,782 allocs, 23,522 frees, 101,539,078 bytes allocated; ==12320==; ==12320== 99,089,984 (319,984 direct, 98,770,000 indirect) bytes in 19,999 blocks are definitely lost in loss record 3,515 of 3,515; ==12320== at 0x4C2BE7F: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so); ==12320== by 0xAD090F2: gsl_rng_alloc (in /usr/lib/libgsl.so.23.0.0); ==12320== by 0x8223765: Allocate (GSLRngWrapper.h:99); ==12320== by 0x8223765: ROOT::Math::GSLMCIntegrator::GSLMCIntegrator(char const*, double, double, unsigned int) (GSLMCIntegrator.cxx:117); ==12320== by 0x108BF5: main (mcintegrator.cpp:8); ==12320==; ==12320== LEAK SUMMARY:; ==12320== definitely lost: 319,984 bytes in 19,999 blocks; ==12320== indirectly lost: 98,770,000 bytes in 19,754 blocks; ==12320== possibly lost: 1,225,000 bytes in 245 blocks; ==12320== still reachable: 340,874 bytes in 4,262 blocks; ==12320== suppressed: 0 bytes in 0 blocks; ==12320== Reachable blocks (those to which a pointer was found) are not shown.; ==12320== To see them, rerun with: --leak-check=full --show-leak-kinds=all; ==12320==; ==12320== For counts of detected and suppressed errors, rerun with: -v; ==12320== ERROR SUMMARY: 2 errors from 2 contexts (suppressed: 0 from 0); ```. After fix:; ```; valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \; --undef-value-errors=no ./mcintegrator. ==14294== Memche",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:3395,Energy Efficiency,allocate,allocated,3395,"Allocate (GSLRngWrapper.h:99); ==12320== by 0x8223765: ROOT::Math::GSLMCIntegrator::GSLMCIntegrator(char const*, double, double, unsigned int) (GSLMCIntegrator.cxx:117); ==12320== by 0x108BF5: main (mcintegrator.cpp:8); ==12320==; ==12320== LEAK SUMMARY:; ==12320== definitely lost: 319,984 bytes in 19,999 blocks; ==12320== indirectly lost: 98,770,000 bytes in 19,754 blocks; ==12320== possibly lost: 1,225,000 bytes in 245 blocks; ==12320== still reachable: 340,874 bytes in 4,262 blocks; ==12320== suppressed: 0 bytes in 0 blocks; ==12320== Reachable blocks (those to which a pointer was found) are not shown.; ==12320== To see them, rerun with: --leak-check=full --show-leak-kinds=all; ==12320==; ==12320== For counts of detected and suppressed errors, rerun with: -v; ==12320== ERROR SUMMARY: 2 errors from 2 contexts (suppressed: 0 from 0); ```. After fix:; ```; valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \; --undef-value-errors=no ./mcintegrator. ==14294== Memcheck, a memory error detector; ==14294== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al.; ==14294== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info; ==14294== Command: ./mcintegrator; ==14294==; ==14294==; ==14294== HEAP SUMMARY:; ==14294== in use at exit: 335,858 bytes in 4,260 blocks; ==14294== total heap usage: 67,782 allocs, 63,522 frees, 101,539,078 bytes allocated; ==14294==; ==14294== LEAK SUMMARY:; ==14294== definitely lost: 0 bytes in 0 blocks; ==14294== indirectly lost: 0 bytes in 0 blocks; ==14294== possibly lost: 0 bytes in 0 blocks; ==14294== still reachable: 335,858 bytes in 4,260 blocks; ==14294== suppressed: 0 bytes in 0 blocks; ==14294== Reachable blocks (those to which a pointer was found) are not shown.; ==14294== To see them, rerun with: --leak-check=full --show-leak-kinds=all; ==14294==; ==14294== For counts of detected and suppressed errors, rerun with: -v; ==14294== ERROR SUMMARY: 0 errors from 0 contexts (suppressed: 0 from 0); ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:657,Integrability,integrat,integrations,657,"The ctor of `GSLMCIntegrator` creates a `GSLRngWrapper` instance on the heap and calls its `Allocate()` member function which in turn allocates memory for a GSL random number generator via `gsl_rng_alloc()`. When the `GSLMCIntegrator` instance goes out of scope, its dtor is invoked which deletes the `GSLRngWrapper` pointer and thus invokes its dtor as well. However, `~GSLRngWrapper()` frees the allocated memory only if `fOwn` pointer is set to true, which is only set so in the assignment operator, but not in the `Allocate()` member function. Therefore, the `GSLMCIntegrator` class is leaking memory. This poses a problem, when doing a large number of integrations inside a for loop. The leak was discovered by running valgrind and inspecting the code. Minimal example:; ```cpp; #include <Math/GSLMCIntegrator.h> // ROOT::Math::GSLMCIntegrator. /* built with:. g++ -ggdb3 -Og `root-config --cflags` mcintegrator.cpp -o mcintegrator \; `root-config --libs` -lMathMore. */. int; main(); {; for(unsigned i = 0; i < 20000; ++i); {; ROOT::Math::GSLMCIntegrator vegas(""vegas"", 0., 1.e-1, 10);; }; return 0;; }; ```. Before fix:; ```; valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \; --undef-value-errors=no ./mcintegrator. ==12320== Memcheck, a memory error detector; ==12320== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al.; ==12320== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info; ==12320== Command: ./mcintegrator; ==12320==; ==12320==; ==12320== HEAP SUMMARY:; ==12320== in use at exit: 100,655,858 bytes in 44,260 blocks; ==12320== total heap usage: 67,782 allocs, 23,522 frees, 101,539,078 bytes allocated; ==12320==; ==12320== 99,089,984 (319,984 direct, 98,770,000 indirect) bytes in 19,999 blocks are definitely lost in loss record 3,515 of 3,515; ==12320== at 0x4C2BE7F: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so); ==12320== by 0xAD090F2: gsl_rng_alloc (in /usr/lib/libgsl.so.23.0.0); ==12320== by 0x8223765: ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:887,Modifiability,config,config,887,"The ctor of `GSLMCIntegrator` creates a `GSLRngWrapper` instance on the heap and calls its `Allocate()` member function which in turn allocates memory for a GSL random number generator via `gsl_rng_alloc()`. When the `GSLMCIntegrator` instance goes out of scope, its dtor is invoked which deletes the `GSLRngWrapper` pointer and thus invokes its dtor as well. However, `~GSLRngWrapper()` frees the allocated memory only if `fOwn` pointer is set to true, which is only set so in the assignment operator, but not in the `Allocate()` member function. Therefore, the `GSLMCIntegrator` class is leaking memory. This poses a problem, when doing a large number of integrations inside a for loop. The leak was discovered by running valgrind and inspecting the code. Minimal example:; ```cpp; #include <Math/GSLMCIntegrator.h> // ROOT::Math::GSLMCIntegrator. /* built with:. g++ -ggdb3 -Og `root-config --cflags` mcintegrator.cpp -o mcintegrator \; `root-config --libs` -lMathMore. */. int; main(); {; for(unsigned i = 0; i < 20000; ++i); {; ROOT::Math::GSLMCIntegrator vegas(""vegas"", 0., 1.e-1, 10);; }; return 0;; }; ```. Before fix:; ```; valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \; --undef-value-errors=no ./mcintegrator. ==12320== Memcheck, a memory error detector; ==12320== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al.; ==12320== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info; ==12320== Command: ./mcintegrator; ==12320==; ==12320==; ==12320== HEAP SUMMARY:; ==12320== in use at exit: 100,655,858 bytes in 44,260 blocks; ==12320== total heap usage: 67,782 allocs, 23,522 frees, 101,539,078 bytes allocated; ==12320==; ==12320== 99,089,984 (319,984 direct, 98,770,000 indirect) bytes in 19,999 blocks are definitely lost in loss record 3,515 of 3,515; ==12320== at 0x4C2BE7F: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so); ==12320== by 0xAD090F2: gsl_rng_alloc (in /usr/lib/libgsl.so.23.0.0); ==12320== by 0x8223765: ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:946,Modifiability,config,config,946,"The ctor of `GSLMCIntegrator` creates a `GSLRngWrapper` instance on the heap and calls its `Allocate()` member function which in turn allocates memory for a GSL random number generator via `gsl_rng_alloc()`. When the `GSLMCIntegrator` instance goes out of scope, its dtor is invoked which deletes the `GSLRngWrapper` pointer and thus invokes its dtor as well. However, `~GSLRngWrapper()` frees the allocated memory only if `fOwn` pointer is set to true, which is only set so in the assignment operator, but not in the `Allocate()` member function. Therefore, the `GSLMCIntegrator` class is leaking memory. This poses a problem, when doing a large number of integrations inside a for loop. The leak was discovered by running valgrind and inspecting the code. Minimal example:; ```cpp; #include <Math/GSLMCIntegrator.h> // ROOT::Math::GSLMCIntegrator. /* built with:. g++ -ggdb3 -Og `root-config --cflags` mcintegrator.cpp -o mcintegrator \; `root-config --libs` -lMathMore. */. int; main(); {; for(unsigned i = 0; i < 20000; ++i); {; ROOT::Math::GSLMCIntegrator vegas(""vegas"", 0., 1.e-1, 10);; }; return 0;; }; ```. Before fix:; ```; valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \; --undef-value-errors=no ./mcintegrator. ==12320== Memcheck, a memory error detector; ==12320== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al.; ==12320== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info; ==12320== Command: ./mcintegrator; ==12320==; ==12320==; ==12320== HEAP SUMMARY:; ==12320== in use at exit: 100,655,858 bytes in 44,260 blocks; ==12320== total heap usage: 67,782 allocs, 23,522 frees, 101,539,078 bytes allocated; ==12320==; ==12320== 99,089,984 (319,984 direct, 98,770,000 indirect) bytes in 19,999 blocks are definitely lost in loss record 3,515 of 3,515; ==12320== at 0x4C2BE7F: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so); ==12320== by 0xAD090F2: gsl_rng_alloc (in /usr/lib/libgsl.so.23.0.0); ==12320== by 0x8223765: ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:1281,Safety,detect,detector,1281,"LRngWrapper` pointer and thus invokes its dtor as well. However, `~GSLRngWrapper()` frees the allocated memory only if `fOwn` pointer is set to true, which is only set so in the assignment operator, but not in the `Allocate()` member function. Therefore, the `GSLMCIntegrator` class is leaking memory. This poses a problem, when doing a large number of integrations inside a for loop. The leak was discovered by running valgrind and inspecting the code. Minimal example:; ```cpp; #include <Math/GSLMCIntegrator.h> // ROOT::Math::GSLMCIntegrator. /* built with:. g++ -ggdb3 -Og `root-config --cflags` mcintegrator.cpp -o mcintegrator \; `root-config --libs` -lMathMore. */. int; main(); {; for(unsigned i = 0; i < 20000; ++i); {; ROOT::Math::GSLMCIntegrator vegas(""vegas"", 0., 1.e-1, 10);; }; return 0;; }; ```. Before fix:; ```; valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \; --undef-value-errors=no ./mcintegrator. ==12320== Memcheck, a memory error detector; ==12320== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al.; ==12320== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info; ==12320== Command: ./mcintegrator; ==12320==; ==12320==; ==12320== HEAP SUMMARY:; ==12320== in use at exit: 100,655,858 bytes in 44,260 blocks; ==12320== total heap usage: 67,782 allocs, 23,522 frees, 101,539,078 bytes allocated; ==12320==; ==12320== 99,089,984 (319,984 direct, 98,770,000 indirect) bytes in 19,999 blocks are definitely lost in loss record 3,515 of 3,515; ==12320== at 0x4C2BE7F: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so); ==12320== by 0xAD090F2: gsl_rng_alloc (in /usr/lib/libgsl.so.23.0.0); ==12320== by 0x8223765: Allocate (GSLRngWrapper.h:99); ==12320== by 0x8223765: ROOT::Math::GSLMCIntegrator::GSLMCIntegrator(char const*, double, double, unsigned int) (GSLMCIntegrator.cxx:117); ==12320== by 0x108BF5: main (mcintegrator.cpp:8); ==12320==; ==12320== LEAK SUMMARY:; ==12320== definitely lost: 319,984 bytes in 19,9",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:2726,Safety,detect,detected,2726,"0 indirect) bytes in 19,999 blocks are definitely lost in loss record 3,515 of 3,515; ==12320== at 0x4C2BE7F: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so); ==12320== by 0xAD090F2: gsl_rng_alloc (in /usr/lib/libgsl.so.23.0.0); ==12320== by 0x8223765: Allocate (GSLRngWrapper.h:99); ==12320== by 0x8223765: ROOT::Math::GSLMCIntegrator::GSLMCIntegrator(char const*, double, double, unsigned int) (GSLMCIntegrator.cxx:117); ==12320== by 0x108BF5: main (mcintegrator.cpp:8); ==12320==; ==12320== LEAK SUMMARY:; ==12320== definitely lost: 319,984 bytes in 19,999 blocks; ==12320== indirectly lost: 98,770,000 bytes in 19,754 blocks; ==12320== possibly lost: 1,225,000 bytes in 245 blocks; ==12320== still reachable: 340,874 bytes in 4,262 blocks; ==12320== suppressed: 0 bytes in 0 blocks; ==12320== Reachable blocks (those to which a pointer was found) are not shown.; ==12320== To see them, rerun with: --leak-check=full --show-leak-kinds=all; ==12320==; ==12320== For counts of detected and suppressed errors, rerun with: -v; ==12320== ERROR SUMMARY: 2 errors from 2 contexts (suppressed: 0 from 0); ```. After fix:; ```; valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \; --undef-value-errors=no ./mcintegrator. ==14294== Memcheck, a memory error detector; ==14294== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al.; ==14294== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info; ==14294== Command: ./mcintegrator; ==14294==; ==14294==; ==14294== HEAP SUMMARY:; ==14294== in use at exit: 335,858 bytes in 4,260 blocks; ==14294== total heap usage: 67,782 allocs, 63,522 frees, 101,539,078 bytes allocated; ==14294==; ==14294== LEAK SUMMARY:; ==14294== definitely lost: 0 bytes in 0 blocks; ==14294== indirectly lost: 0 bytes in 0 blocks; ==14294== possibly lost: 0 bytes in 0 blocks; ==14294== still reachable: 335,858 bytes in 4,260 blocks; ==14294== suppressed: 0 bytes in 0 blocks; ==14294== Reachable blocks (those to which a poi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:3018,Safety,detect,detector,3018,"Allocate (GSLRngWrapper.h:99); ==12320== by 0x8223765: ROOT::Math::GSLMCIntegrator::GSLMCIntegrator(char const*, double, double, unsigned int) (GSLMCIntegrator.cxx:117); ==12320== by 0x108BF5: main (mcintegrator.cpp:8); ==12320==; ==12320== LEAK SUMMARY:; ==12320== definitely lost: 319,984 bytes in 19,999 blocks; ==12320== indirectly lost: 98,770,000 bytes in 19,754 blocks; ==12320== possibly lost: 1,225,000 bytes in 245 blocks; ==12320== still reachable: 340,874 bytes in 4,262 blocks; ==12320== suppressed: 0 bytes in 0 blocks; ==12320== Reachable blocks (those to which a pointer was found) are not shown.; ==12320== To see them, rerun with: --leak-check=full --show-leak-kinds=all; ==12320==; ==12320== For counts of detected and suppressed errors, rerun with: -v; ==12320== ERROR SUMMARY: 2 errors from 2 contexts (suppressed: 0 from 0); ```. After fix:; ```; valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \; --undef-value-errors=no ./mcintegrator. ==14294== Memcheck, a memory error detector; ==14294== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al.; ==14294== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info; ==14294== Command: ./mcintegrator; ==14294==; ==14294==; ==14294== HEAP SUMMARY:; ==14294== in use at exit: 335,858 bytes in 4,260 blocks; ==14294== total heap usage: 67,782 allocs, 63,522 frees, 101,539,078 bytes allocated; ==14294==; ==14294== LEAK SUMMARY:; ==14294== definitely lost: 0 bytes in 0 blocks; ==14294== indirectly lost: 0 bytes in 0 blocks; ==14294== possibly lost: 0 bytes in 0 blocks; ==14294== still reachable: 335,858 bytes in 4,260 blocks; ==14294== suppressed: 0 bytes in 0 blocks; ==14294== Reachable blocks (those to which a pointer was found) are not shown.; ==14294== To see them, rerun with: --leak-check=full --show-leak-kinds=all; ==14294==; ==14294== For counts of detected and suppressed errors, rerun with: -v; ==14294== ERROR SUMMARY: 0 errors from 0 contexts (suppressed: 0 from 0); ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:3876,Safety,detect,detected,3876,"Allocate (GSLRngWrapper.h:99); ==12320== by 0x8223765: ROOT::Math::GSLMCIntegrator::GSLMCIntegrator(char const*, double, double, unsigned int) (GSLMCIntegrator.cxx:117); ==12320== by 0x108BF5: main (mcintegrator.cpp:8); ==12320==; ==12320== LEAK SUMMARY:; ==12320== definitely lost: 319,984 bytes in 19,999 blocks; ==12320== indirectly lost: 98,770,000 bytes in 19,754 blocks; ==12320== possibly lost: 1,225,000 bytes in 245 blocks; ==12320== still reachable: 340,874 bytes in 4,262 blocks; ==12320== suppressed: 0 bytes in 0 blocks; ==12320== Reachable blocks (those to which a pointer was found) are not shown.; ==12320== To see them, rerun with: --leak-check=full --show-leak-kinds=all; ==12320==; ==12320== For counts of detected and suppressed errors, rerun with: -v; ==12320== ERROR SUMMARY: 2 errors from 2 contexts (suppressed: 0 from 0); ```. After fix:; ```; valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \; --undef-value-errors=no ./mcintegrator. ==14294== Memcheck, a memory error detector; ==14294== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al.; ==14294== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info; ==14294== Command: ./mcintegrator; ==14294==; ==14294==; ==14294== HEAP SUMMARY:; ==14294== in use at exit: 335,858 bytes in 4,260 blocks; ==14294== total heap usage: 67,782 allocs, 63,522 frees, 101,539,078 bytes allocated; ==14294==; ==14294== LEAK SUMMARY:; ==14294== definitely lost: 0 bytes in 0 blocks; ==14294== indirectly lost: 0 bytes in 0 blocks; ==14294== possibly lost: 0 bytes in 0 blocks; ==14294== still reachable: 335,858 bytes in 4,260 blocks; ==14294== suppressed: 0 bytes in 0 blocks; ==14294== Reachable blocks (those to which a pointer was found) are not shown.; ==14294== To see them, rerun with: --leak-check=full --show-leak-kinds=all; ==14294==; ==14294== For counts of detected and suppressed errors, rerun with: -v; ==14294== ERROR SUMMARY: 0 errors from 0 contexts (suppressed: 0 from 0); ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/931:173,Deployability,patch,patch,173,"As seen in the posix_memalign workaround in clang, it seems that; marking modules as system actually has more semantic behavior; than just disabling warnings for them. This patch marks both; STL and libc as system to fix those issues. Also see: https://github.com/Teemperor/clang-modules-bugs/issues/3",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/931
https://github.com/root-project/root/pull/933:96,Testability,test,test,96,"Hi,; I noticed the TDataFrame entries for the code owners were a bit weird. I'm not sure how to test I did not screw up the syntax (the `**` pattern was explained [here](https://git-scm.com/docs/gitignore) and codeowners should allow the same pattern matching syntax).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/933
https://github.com/root-project/root/pull/934:88,Performance,perform,performance,88,"Compared to `GetAtSlotUnchecked`, `GetAtSlotRaw` trades some more; safety for some more performance: not only it avoids checking for; slot initialization (as `GetAtSlotUnchecked` does) but it also avoids; (copy-)construction of a `shared_ptr`. I can add a test, just tell me where :)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/934
https://github.com/root-project/root/pull/934:67,Safety,safe,safety,67,"Compared to `GetAtSlotUnchecked`, `GetAtSlotRaw` trades some more; safety for some more performance: not only it avoids checking for; slot initialization (as `GetAtSlotUnchecked` does) but it also avoids; (copy-)construction of a `shared_ptr`. I can add a test, just tell me where :)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/934
https://github.com/root-project/root/pull/934:113,Safety,avoid,avoids,113,"Compared to `GetAtSlotUnchecked`, `GetAtSlotRaw` trades some more; safety for some more performance: not only it avoids checking for; slot initialization (as `GetAtSlotUnchecked` does) but it also avoids; (copy-)construction of a `shared_ptr`. I can add a test, just tell me where :)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/934
https://github.com/root-project/root/pull/934:197,Safety,avoid,avoids,197,"Compared to `GetAtSlotUnchecked`, `GetAtSlotRaw` trades some more; safety for some more performance: not only it avoids checking for; slot initialization (as `GetAtSlotUnchecked` does) but it also avoids; (copy-)construction of a `shared_ptr`. I can add a test, just tell me where :)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/934
https://github.com/root-project/root/pull/934:256,Testability,test,test,256,"Compared to `GetAtSlotUnchecked`, `GetAtSlotRaw` trades some more; safety for some more performance: not only it avoids checking for; slot initialization (as `GetAtSlotUnchecked` does) but it also avoids; (copy-)construction of a `shared_ptr`. I can add a test, just tell me where :)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/934
https://github.com/root-project/root/pull/935:92,Modifiability,extend,extended,92,"With a new checksum functionality, it is required to have xxhash library: FindLZ4.cmake was extended to check if you have xxhash includes (for the case if you build your own standalone LZ4, where xxhash is a part of project) and find library in case if you are using system LZ4 that doesn't have xxhash (in this case you need to build standalone xxhash library), otherwise to fall back to builtin_lz4 option.; Builtin LZ4 version has xxhash library built inside by itself and provides different xxhash symbols for the LZ4 library extended with LZ4 namespace, while if it is used standalone LZ4 with standalone xxhash. To separate them, it was introduced LZ4_DEFINITIONS.; @amadio @bbockelm can you look please?",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/935
https://github.com/root-project/root/pull/935:530,Modifiability,extend,extended,530,"With a new checksum functionality, it is required to have xxhash library: FindLZ4.cmake was extended to check if you have xxhash includes (for the case if you build your own standalone LZ4, where xxhash is a part of project) and find library in case if you are using system LZ4 that doesn't have xxhash (in this case you need to build standalone xxhash library), otherwise to fall back to builtin_lz4 option.; Builtin LZ4 version has xxhash library built inside by itself and provides different xxhash symbols for the LZ4 library extended with LZ4 namespace, while if it is used standalone LZ4 with standalone xxhash. To separate them, it was introduced LZ4_DEFINITIONS.; @amadio @bbockelm can you look please?",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/935
https://github.com/root-project/root/pull/935:11,Security,checksum,checksum,11,"With a new checksum functionality, it is required to have xxhash library: FindLZ4.cmake was extended to check if you have xxhash includes (for the case if you build your own standalone LZ4, where xxhash is a part of project) and find library in case if you are using system LZ4 that doesn't have xxhash (in this case you need to build standalone xxhash library), otherwise to fall back to builtin_lz4 option.; Builtin LZ4 version has xxhash library built inside by itself and provides different xxhash symbols for the LZ4 library extended with LZ4 namespace, while if it is used standalone LZ4 with standalone xxhash. To separate them, it was introduced LZ4_DEFINITIONS.; @amadio @bbockelm can you look please?",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/935
https://github.com/root-project/root/pull/937:44,Safety,Avoid,Avoid,44,Prefer string_view in function signatures.; Avoid instantiating strings whenever possible.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/937
https://github.com/root-project/root/pull/942:155,Integrability,INTERFACE,INTERFACE,155,"CMake offers three visibility qualifiers for target include; directories, which are populated to target properties as shown in the; following table:. | | `INTERFACE` | `PUBLIC` | `PRIVATE` |; | --- | --- | --- | --- |; | `INCLUDE_DIRECTORIES` | | x | x |; | `INTERFACE_INCLUDE_DIRECTORIES` | X | x | |. For dictionary generation the `PUBLIC` and `INTERFACE` qualifiers and; hence the `INTERFACE_INCLUDE_DIRECTORIES` are to be preferred, because; header files meant to be consumed by the user are usually put into; `PUBLIC` and/or `INTERFACE` qualified directories. Furthermore, the CMake; imported targets always have `INTERFACE` visibility. This commit changes the current behaviour to read the; `INTERFACE_INCLUDE_DIRECTORIES` (as opposed to the `INCLUDE_DIRECTORIES`); target property which will catch more desired use cases, including; imported targets. In other words, this will now ignore `PRIVATE` include; directories, but include `INTERFACE` include directories - `PUBLIC` ones; stay unchanged. In addition, this commit adds a condition which ignores include; directories formulated as a CMake generator expression. Unfortunately,; there is currently no way to evaluate those seperately.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/942
https://github.com/root-project/root/pull/942:347,Integrability,INTERFACE,INTERFACE,347,"CMake offers three visibility qualifiers for target include; directories, which are populated to target properties as shown in the; following table:. | | `INTERFACE` | `PUBLIC` | `PRIVATE` |; | --- | --- | --- | --- |; | `INCLUDE_DIRECTORIES` | | x | x |; | `INTERFACE_INCLUDE_DIRECTORIES` | X | x | |. For dictionary generation the `PUBLIC` and `INTERFACE` qualifiers and; hence the `INTERFACE_INCLUDE_DIRECTORIES` are to be preferred, because; header files meant to be consumed by the user are usually put into; `PUBLIC` and/or `INTERFACE` qualified directories. Furthermore, the CMake; imported targets always have `INTERFACE` visibility. This commit changes the current behaviour to read the; `INTERFACE_INCLUDE_DIRECTORIES` (as opposed to the `INCLUDE_DIRECTORIES`); target property which will catch more desired use cases, including; imported targets. In other words, this will now ignore `PRIVATE` include; directories, but include `INTERFACE` include directories - `PUBLIC` ones; stay unchanged. In addition, this commit adds a condition which ignores include; directories formulated as a CMake generator expression. Unfortunately,; there is currently no way to evaluate those seperately.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/942
https://github.com/root-project/root/pull/942:531,Integrability,INTERFACE,INTERFACE,531,"CMake offers three visibility qualifiers for target include; directories, which are populated to target properties as shown in the; following table:. | | `INTERFACE` | `PUBLIC` | `PRIVATE` |; | --- | --- | --- | --- |; | `INCLUDE_DIRECTORIES` | | x | x |; | `INTERFACE_INCLUDE_DIRECTORIES` | X | x | |. For dictionary generation the `PUBLIC` and `INTERFACE` qualifiers and; hence the `INTERFACE_INCLUDE_DIRECTORIES` are to be preferred, because; header files meant to be consumed by the user are usually put into; `PUBLIC` and/or `INTERFACE` qualified directories. Furthermore, the CMake; imported targets always have `INTERFACE` visibility. This commit changes the current behaviour to read the; `INTERFACE_INCLUDE_DIRECTORIES` (as opposed to the `INCLUDE_DIRECTORIES`); target property which will catch more desired use cases, including; imported targets. In other words, this will now ignore `PRIVATE` include; directories, but include `INTERFACE` include directories - `PUBLIC` ones; stay unchanged. In addition, this commit adds a condition which ignores include; directories formulated as a CMake generator expression. Unfortunately,; there is currently no way to evaluate those seperately.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/942
https://github.com/root-project/root/pull/942:619,Integrability,INTERFACE,INTERFACE,619,"CMake offers three visibility qualifiers for target include; directories, which are populated to target properties as shown in the; following table:. | | `INTERFACE` | `PUBLIC` | `PRIVATE` |; | --- | --- | --- | --- |; | `INCLUDE_DIRECTORIES` | | x | x |; | `INTERFACE_INCLUDE_DIRECTORIES` | X | x | |. For dictionary generation the `PUBLIC` and `INTERFACE` qualifiers and; hence the `INTERFACE_INCLUDE_DIRECTORIES` are to be preferred, because; header files meant to be consumed by the user are usually put into; `PUBLIC` and/or `INTERFACE` qualified directories. Furthermore, the CMake; imported targets always have `INTERFACE` visibility. This commit changes the current behaviour to read the; `INTERFACE_INCLUDE_DIRECTORIES` (as opposed to the `INCLUDE_DIRECTORIES`); target property which will catch more desired use cases, including; imported targets. In other words, this will now ignore `PRIVATE` include; directories, but include `INTERFACE` include directories - `PUBLIC` ones; stay unchanged. In addition, this commit adds a condition which ignores include; directories formulated as a CMake generator expression. Unfortunately,; there is currently no way to evaluate those seperately.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/942
https://github.com/root-project/root/pull/942:940,Integrability,INTERFACE,INTERFACE,940,"CMake offers three visibility qualifiers for target include; directories, which are populated to target properties as shown in the; following table:. | | `INTERFACE` | `PUBLIC` | `PRIVATE` |; | --- | --- | --- | --- |; | `INCLUDE_DIRECTORIES` | | x | x |; | `INTERFACE_INCLUDE_DIRECTORIES` | X | x | |. For dictionary generation the `PUBLIC` and `INTERFACE` qualifiers and; hence the `INTERFACE_INCLUDE_DIRECTORIES` are to be preferred, because; header files meant to be consumed by the user are usually put into; `PUBLIC` and/or `INTERFACE` qualified directories. Furthermore, the CMake; imported targets always have `INTERFACE` visibility. This commit changes the current behaviour to read the; `INTERFACE_INCLUDE_DIRECTORIES` (as opposed to the `INCLUDE_DIRECTORIES`); target property which will catch more desired use cases, including; imported targets. In other words, this will now ignore `PRIVATE` include; directories, but include `INTERFACE` include directories - `PUBLIC` ones; stay unchanged. In addition, this commit adds a condition which ignores include; directories formulated as a CMake generator expression. Unfortunately,; there is currently no way to evaluate those seperately.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/942
https://github.com/root-project/root/pull/943:2045,Energy Efficiency,efficient,efficient,2045,"the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:; - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers.; - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two.; - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast.; - A Python-based `numpy` export interface. This exposes the (possibly serialized) memory directly as numpy arrays, allowing for efficient access to ROOT-serialized objects from the Python language.; - The `numpy` interface is low-level for Python; we intend to further explore the ideal high-level interface through projects such as https://github.com/diana-hep/plur. So indeed, lot's of experimental / internal interface work here - but we felt that (a) a sufficient amount depends on this and (b) we've demonstrated enough utility that it was time to start talking about merging. (With many thanks to @jpivarski for driving this work home with his work on a python interface!)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:1174,Integrability,interface,interfaces,1174,"ulk IO APIs aim to provide as fast access as possible in the case where the user is using relatively simple datatypes and the objects can be deserialized ""non-destructively"" (i.e., in-place in the existing memory buffers). For example - primitives and lists of primitives are supported; anything needing references are not. Despite the fact many of ROOT's very useful deserialization features are not supported, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:; - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers.; - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two.; - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast.; - A Python-based `numpy` export interface. This exposes the (possibly serialized) memory directly as numpy arrays, allowing for efficient access to ROOT-serialized objects from the Python language.; - The `numpy` interface is low-level for Python; we intend to furth",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:1206,Integrability,interface,interface,1206,"ulk IO APIs aim to provide as fast access as possible in the case where the user is using relatively simple datatypes and the objects can be deserialized ""non-destructively"" (i.e., in-place in the existing memory buffers). For example - primitives and lists of primitives are supported; anything needing references are not. Despite the fact many of ROOT's very useful deserialization features are not supported, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:; - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers.; - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two.; - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast.; - A Python-based `numpy` export interface. This exposes the (possibly serialized) memory directly as numpy arrays, allowing for efficient access to ROOT-serialized objects from the Python language.; - The `numpy` interface is low-level for Python; we intend to furth",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:1416,Integrability,interface,interface,1416,"- primitives and lists of primitives are supported; anything needing references are not. Despite the fact many of ROOT's very useful deserialization features are not supported, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:; - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers.; - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two.; - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast.; - A Python-based `numpy` export interface. This exposes the (possibly serialized) memory directly as numpy arrays, allowing for efficient access to ROOT-serialized objects from the Python language.; - The `numpy` interface is low-level for Python; we intend to further explore the ideal high-level interface through projects such as https://github.com/diana-hep/plur. So indeed, lot's of experimental / internal interface work here - but we felt that (a) a sufficient amount depends on this and (b) we",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:1507,Integrability,interface,interface,1507,"ry useful deserialization features are not supported, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:; - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers.; - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two.; - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast.; - A Python-based `numpy` export interface. This exposes the (possibly serialized) memory directly as numpy arrays, allowing for efficient access to ROOT-serialized objects from the Python language.; - The `numpy` interface is low-level for Python; we intend to further explore the ideal high-level interface through projects such as https://github.com/diana-hep/plur. So indeed, lot's of experimental / internal interface work here - but we felt that (a) a sufficient amount depends on this and (b) we've demonstrated enough utility that it was time to start talking about merging. (With many thanks to @jpivarski for driving",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:1797,Integrability,interface,interface,1797,"the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:; - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers.; - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two.; - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast.; - A Python-based `numpy` export interface. This exposes the (possibly serialized) memory directly as numpy arrays, allowing for efficient access to ROOT-serialized objects from the Python language.; - The `numpy` interface is low-level for Python; we intend to further explore the ideal high-level interface through projects such as https://github.com/diana-hep/plur. So indeed, lot's of experimental / internal interface work here - but we felt that (a) a sufficient amount depends on this and (b) we've demonstrated enough utility that it was time to start talking about merging. (With many thanks to @jpivarski for driving this work home with his work on a python interface!)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:1949,Integrability,interface,interface,1949,"the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:; - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers.; - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two.; - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast.; - A Python-based `numpy` export interface. This exposes the (possibly serialized) memory directly as numpy arrays, allowing for efficient access to ROOT-serialized objects from the Python language.; - The `numpy` interface is low-level for Python; we intend to further explore the ideal high-level interface through projects such as https://github.com/diana-hep/plur. So indeed, lot's of experimental / internal interface work here - but we felt that (a) a sufficient amount depends on this and (b) we've demonstrated enough utility that it was time to start talking about merging. (With many thanks to @jpivarski for driving this work home with his work on a python interface!)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:2130,Integrability,interface,interface,2130,"the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:; - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers.; - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two.; - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast.; - A Python-based `numpy` export interface. This exposes the (possibly serialized) memory directly as numpy arrays, allowing for efficient access to ROOT-serialized objects from the Python language.; - The `numpy` interface is low-level for Python; we intend to further explore the ideal high-level interface through projects such as https://github.com/diana-hep/plur. So indeed, lot's of experimental / internal interface work here - but we felt that (a) a sufficient amount depends on this and (b) we've demonstrated enough utility that it was time to start talking about merging. (With many thanks to @jpivarski for driving this work home with his work on a python interface!)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:2215,Integrability,interface,interface,2215,"the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:; - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers.; - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two.; - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast.; - A Python-based `numpy` export interface. This exposes the (possibly serialized) memory directly as numpy arrays, allowing for efficient access to ROOT-serialized objects from the Python language.; - The `numpy` interface is low-level for Python; we intend to further explore the ideal high-level interface through projects such as https://github.com/diana-hep/plur. So indeed, lot's of experimental / internal interface work here - but we felt that (a) a sufficient amount depends on this and (b) we've demonstrated enough utility that it was time to start talking about merging. (With many thanks to @jpivarski for driving this work home with his work on a python interface!)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:2329,Integrability,interface,interface,2329,"the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:; - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers.; - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two.; - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast.; - A Python-based `numpy` export interface. This exposes the (possibly serialized) memory directly as numpy arrays, allowing for efficient access to ROOT-serialized objects from the Python language.; - The `numpy` interface is low-level for Python; we intend to further explore the ideal high-level interface through projects such as https://github.com/diana-hep/plur. So indeed, lot's of experimental / internal interface work here - but we felt that (a) a sufficient amount depends on this and (b) we've demonstrated enough utility that it was time to start talking about merging. (With many thanks to @jpivarski for driving this work home with his work on a python interface!)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:2392,Integrability,depend,depends,2392,"the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:; - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers.; - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two.; - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast.; - A Python-based `numpy` export interface. This exposes the (possibly serialized) memory directly as numpy arrays, allowing for efficient access to ROOT-serialized objects from the Python language.; - The `numpy` interface is low-level for Python; we intend to further explore the ideal high-level interface through projects such as https://github.com/diana-hep/plur. So indeed, lot's of experimental / internal interface work here - but we felt that (a) a sufficient amount depends on this and (b) we've demonstrated enough utility that it was time to start talking about merging. (With many thanks to @jpivarski for driving this work home with his work on a python interface!)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:2584,Integrability,interface,interface,2584,"the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:; - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers.; - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two.; - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast.; - A Python-based `numpy` export interface. This exposes the (possibly serialized) memory directly as numpy arrays, allowing for efficient access to ROOT-serialized objects from the Python language.; - The `numpy` interface is low-level for Python; we intend to further explore the ideal high-level interface through projects such as https://github.com/diana-hep/plur. So indeed, lot's of experimental / internal interface work here - but we felt that (a) a sufficient amount depends on this and (b) we've demonstrated enough utility that it was time to start talking about merging. (With many thanks to @jpivarski for driving this work home with his work on a python interface!)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:1814,Modifiability,extend,extended,1814,"the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:; - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers.; - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two.; - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast.; - A Python-based `numpy` export interface. This exposes the (possibly serialized) memory directly as numpy arrays, allowing for efficient access to ROOT-serialized objects from the Python language.; - The `numpy` interface is low-level for Python; we intend to further explore the ideal high-level interface through projects such as https://github.com/diana-hep/plur. So indeed, lot's of experimental / internal interface work here - but we felt that (a) a sufficient amount depends on this and (b) we've demonstrated enough utility that it was time to start talking about merging. (With many thanks to @jpivarski for driving this work home with his work on a python interface!)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:218,Security,access,access,218,"This is the first attempt for merging the bulk IO APIs (hidden inside the `ROOT::Internal` namespace). The initial goal here is to start getting reviewer attention and feedback. The bulk IO APIs aim to provide as fast access as possible in the case where the user is using relatively simple datatypes and the objects can be deserialized ""non-destructively"" (i.e., in-place in the existing memory buffers). For example - primitives and lists of primitives are supported; anything needing references are not. Despite the fact many of ROOT's very useful deserialization features are not supported, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:; - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers.; - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two.; - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast.; - A Python-based `numpy` export interface. This exposes the (possibly serialized) me",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:1965,Security,expose,exposes,1965,"the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:; - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers.; - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two.; - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast.; - A Python-based `numpy` export interface. This exposes the (possibly serialized) memory directly as numpy arrays, allowing for efficient access to ROOT-serialized objects from the Python language.; - The `numpy` interface is low-level for Python; we intend to further explore the ideal high-level interface through projects such as https://github.com/diana-hep/plur. So indeed, lot's of experimental / internal interface work here - but we felt that (a) a sufficient amount depends on this and (b) we've demonstrated enough utility that it was time to start talking about merging. (With many thanks to @jpivarski for driving this work home with his work on a python interface!)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:2055,Security,access,access,2055,"the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:; - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers.; - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two.; - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast.; - A Python-based `numpy` export interface. This exposes the (possibly serialized) memory directly as numpy arrays, allowing for efficient access to ROOT-serialized objects from the Python language.; - The `numpy` interface is low-level for Python; we intend to further explore the ideal high-level interface through projects such as https://github.com/diana-hep/plur. So indeed, lot's of experimental / internal interface work here - but we felt that (a) a sufficient amount depends on this and (b) we've demonstrated enough utility that it was time to start talking about merging. (With many thanks to @jpivarski for driving this work home with his work on a python interface!)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:168,Usability,feedback,feedback,168,"This is the first attempt for merging the bulk IO APIs (hidden inside the `ROOT::Internal` namespace). The initial goal here is to start getting reviewer attention and feedback. The bulk IO APIs aim to provide as fast access as possible in the case where the user is using relatively simple datatypes and the objects can be deserialized ""non-destructively"" (i.e., in-place in the existing memory buffers). For example - primitives and lists of primitives are supported; anything needing references are not. Despite the fact many of ROOT's very useful deserialization features are not supported, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:; - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers.; - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two.; - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast.; - A Python-based `numpy` export interface. This exposes the (possibly serialized) me",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:284,Usability,simpl,simple,284,"This is the first attempt for merging the bulk IO APIs (hidden inside the `ROOT::Internal` namespace). The initial goal here is to start getting reviewer attention and feedback. The bulk IO APIs aim to provide as fast access as possible in the case where the user is using relatively simple datatypes and the objects can be deserialized ""non-destructively"" (i.e., in-place in the existing memory buffers). For example - primitives and lists of primitives are supported; anything needing references are not. Despite the fact many of ROOT's very useful deserialization features are not supported, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:; - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers.; - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two.; - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast.; - A Python-based `numpy` export interface. This exposes the (possibly serialized) me",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/944:96,Integrability,wrap,wrap,96,We need to set ROOT_MODULES to DEBUG when we want rootcling to; create C++ modules. For this we wrap all rootcling invocations; in cmake wrappers that set this environment variable.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/944
https://github.com/root-project/root/pull/944:137,Integrability,wrap,wrappers,137,We need to set ROOT_MODULES to DEBUG when we want rootcling to; create C++ modules. For this we wrap all rootcling invocations; in cmake wrappers that set this environment variable.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/944
https://github.com/root-project/root/pull/944:172,Modifiability,variab,variable,172,We need to set ROOT_MODULES to DEBUG when we want rootcling to; create C++ modules. For this we wrap all rootcling invocations; in cmake wrappers that set this environment variable.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/944
https://github.com/root-project/root/pull/946:71,Availability,error,error,71,"This code assumed that rootcling doesn't return zero when we; print an error, but this is not the case. Let's downgrade it to; a warning that we actually still return a zero exit code. Also the method now just returns true instead of writing 'true'; twice to the same result variable and then returning that.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/946
https://github.com/root-project/root/pull/946:110,Availability,down,downgrade,110,"This code assumed that rootcling doesn't return zero when we; print an error, but this is not the case. Let's downgrade it to; a warning that we actually still return a zero exit code. Also the method now just returns true instead of writing 'true'; twice to the same result variable and then returning that.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/946
https://github.com/root-project/root/pull/946:275,Modifiability,variab,variable,275,"This code assumed that rootcling doesn't return zero when we; print an error, but this is not the case. Let's downgrade it to; a warning that we actually still return a zero exit code. Also the method now just returns true instead of writing 'true'; twice to the same result variable and then returning that.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/946
https://github.com/root-project/root/pull/948:186,Deployability,install,install,186,"find_file without NO_DEFAULT_PATH searches pretty much the whole; file system for the given file. As we are looking for a root; header here that we then turn into a dictionary, copy and install; it we should probably limit us to just the ROOT directories here.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/948
https://github.com/root-project/root/pull/952:53,Availability,error,errors,53,When run C++17 kernel in Jupyter notebook cause some errors; due to currently clang-5.0 in https://root.cern.ch/download/cling/ is not; support c++17.; So add support to C++1z for Jupyter kernel and we can try some new; features in Jupyter notebook. for avoiding following error:. [I 05:46:38.253 NotebookApp] Kernel restarted:; d3413fa0-7046-4b63-912b-a286610eacc1; error: invalid value 'c++17' in '-std=c++17'; note: use 'c++98' or 'c++03' for 'ISO C++ 1998 with amendments' standard; note: use 'gnu++98' or 'gnu++03' for 'ISO C++ 1998 with amendments and; GNU extensions' standard; note: use 'c++11' for 'ISO C++ 2011 with amendments' standard; note: use 'gnu++11' for 'ISO C++ 2011 with amendments and GNU; extensions' standard; note: use 'c++14' for 'ISO C++ 2014 with amendments' standard; note: use 'gnu++14' for 'ISO C++ 2014 with amendments and GNU; extensions' standard; note: use 'c++1z' for 'Working draft for ISO C++ 2017' standard; note: use 'gnu++1z' for 'Working draft for ISO C++ 2017 with GNU; extensions' standard,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/952
https://github.com/root-project/root/pull/952:112,Availability,down,download,112,When run C++17 kernel in Jupyter notebook cause some errors; due to currently clang-5.0 in https://root.cern.ch/download/cling/ is not; support c++17.; So add support to C++1z for Jupyter kernel and we can try some new; features in Jupyter notebook. for avoiding following error:. [I 05:46:38.253 NotebookApp] Kernel restarted:; d3413fa0-7046-4b63-912b-a286610eacc1; error: invalid value 'c++17' in '-std=c++17'; note: use 'c++98' or 'c++03' for 'ISO C++ 1998 with amendments' standard; note: use 'gnu++98' or 'gnu++03' for 'ISO C++ 1998 with amendments and; GNU extensions' standard; note: use 'c++11' for 'ISO C++ 2011 with amendments' standard; note: use 'gnu++11' for 'ISO C++ 2011 with amendments and GNU; extensions' standard; note: use 'c++14' for 'ISO C++ 2014 with amendments' standard; note: use 'gnu++14' for 'ISO C++ 2014 with amendments and GNU; extensions' standard; note: use 'c++1z' for 'Working draft for ISO C++ 2017' standard; note: use 'gnu++1z' for 'Working draft for ISO C++ 2017 with GNU; extensions' standard,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/952
https://github.com/root-project/root/pull/952:273,Availability,error,error,273,When run C++17 kernel in Jupyter notebook cause some errors; due to currently clang-5.0 in https://root.cern.ch/download/cling/ is not; support c++17.; So add support to C++1z for Jupyter kernel and we can try some new; features in Jupyter notebook. for avoiding following error:. [I 05:46:38.253 NotebookApp] Kernel restarted:; d3413fa0-7046-4b63-912b-a286610eacc1; error: invalid value 'c++17' in '-std=c++17'; note: use 'c++98' or 'c++03' for 'ISO C++ 1998 with amendments' standard; note: use 'gnu++98' or 'gnu++03' for 'ISO C++ 1998 with amendments and; GNU extensions' standard; note: use 'c++11' for 'ISO C++ 2011 with amendments' standard; note: use 'gnu++11' for 'ISO C++ 2011 with amendments and GNU; extensions' standard; note: use 'c++14' for 'ISO C++ 2014 with amendments' standard; note: use 'gnu++14' for 'ISO C++ 2014 with amendments and GNU; extensions' standard; note: use 'c++1z' for 'Working draft for ISO C++ 2017' standard; note: use 'gnu++1z' for 'Working draft for ISO C++ 2017 with GNU; extensions' standard,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/952
https://github.com/root-project/root/pull/952:367,Availability,error,error,367,When run C++17 kernel in Jupyter notebook cause some errors; due to currently clang-5.0 in https://root.cern.ch/download/cling/ is not; support c++17.; So add support to C++1z for Jupyter kernel and we can try some new; features in Jupyter notebook. for avoiding following error:. [I 05:46:38.253 NotebookApp] Kernel restarted:; d3413fa0-7046-4b63-912b-a286610eacc1; error: invalid value 'c++17' in '-std=c++17'; note: use 'c++98' or 'c++03' for 'ISO C++ 1998 with amendments' standard; note: use 'gnu++98' or 'gnu++03' for 'ISO C++ 1998 with amendments and; GNU extensions' standard; note: use 'c++11' for 'ISO C++ 2011 with amendments' standard; note: use 'gnu++11' for 'ISO C++ 2011 with amendments and GNU; extensions' standard; note: use 'c++14' for 'ISO C++ 2014 with amendments' standard; note: use 'gnu++14' for 'ISO C++ 2014 with amendments and GNU; extensions' standard; note: use 'c++1z' for 'Working draft for ISO C++ 2017' standard; note: use 'gnu++1z' for 'Working draft for ISO C++ 2017 with GNU; extensions' standard,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/952
https://github.com/root-project/root/pull/952:254,Safety,avoid,avoiding,254,When run C++17 kernel in Jupyter notebook cause some errors; due to currently clang-5.0 in https://root.cern.ch/download/cling/ is not; support c++17.; So add support to C++1z for Jupyter kernel and we can try some new; features in Jupyter notebook. for avoiding following error:. [I 05:46:38.253 NotebookApp] Kernel restarted:; d3413fa0-7046-4b63-912b-a286610eacc1; error: invalid value 'c++17' in '-std=c++17'; note: use 'c++98' or 'c++03' for 'ISO C++ 1998 with amendments' standard; note: use 'gnu++98' or 'gnu++03' for 'ISO C++ 1998 with amendments and; GNU extensions' standard; note: use 'c++11' for 'ISO C++ 2011 with amendments' standard; note: use 'gnu++11' for 'ISO C++ 2011 with amendments and GNU; extensions' standard; note: use 'c++14' for 'ISO C++ 2014 with amendments' standard; note: use 'gnu++14' for 'ISO C++ 2014 with amendments and GNU; extensions' standard; note: use 'c++1z' for 'Working draft for ISO C++ 2017' standard; note: use 'gnu++1z' for 'Working draft for ISO C++ 2017 with GNU; extensions' standard,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/952
https://github.com/root-project/root/pull/953:50,Integrability,wrap,wrap,50,"Fix nullptr dereference bugs in TClass and TList, wrap TClass.cxx to 120 columns to follow coding conventions, and avoid StreamerInfo lookup when it is cached.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/953
https://github.com/root-project/root/pull/953:152,Performance,cache,cached,152,"Fix nullptr dereference bugs in TClass and TList, wrap TClass.cxx to 120 columns to follow coding conventions, and avoid StreamerInfo lookup when it is cached.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/953
https://github.com/root-project/root/pull/953:115,Safety,avoid,avoid,115,"Fix nullptr dereference bugs in TClass and TList, wrap TClass.cxx to 120 columns to follow coding conventions, and avoid StreamerInfo lookup when it is cached.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/953
https://github.com/root-project/root/pull/956:32,Performance,perform,performance,32,"Here you can find reports about performance of new zlib: https://indico.cern.ch/event/658075/; New zlib is showing ~3 ~4 times faster in case of ""write"" operations for 109 and 106 compression settings.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/956
https://github.com/root-project/root/pull/957:0,Safety,Avoid,Avoid,0,Avoid taking a lock if list of bases has already been computed.; Still need to reason about thread-safety prior to merging.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/957
https://github.com/root-project/root/pull/957:99,Safety,safe,safety,99,Avoid taking a lock if list of bases has already been computed.; Still need to reason about thread-safety prior to merging.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/957
https://github.com/root-project/root/pull/958:349,Testability,test,tested,349,"This is the [recommended way](https://cmake.org/cmake/help/latest/command/cmake_policy.html#setting-policies-by-cmake-version) to set CMake policy settings. This means that policies created in versions prior to 3.9 will use the NEW setting by default, and newer policies will generate warnings. Set to 3.9 since that's the highest version currently tested in Jenkins. The Mac builds are generating a [warning](http://cdash.cern.ch/buildSummary.php?buildid=393980) (shown below) about policy CMP0068, so I'd like to test this; and move to the new policy mechanism once any problems that show up are fixed. ```; CMake Warning (dev):; Policy CMP0068 is not set: RPATH settings on macOS do not affect; install_name. Run ""cmake --help-policy CMP0068"" for policy details. Use; the cmake_policy command to set the policy and suppress this warning. For compatibility with older versions of CMake, the install_name fields for; the following targets are still affected by RPATH settings:. LTO; libclang. This warning is for project developers. Use -Wno-dev to suppres-- Generating done; s it.; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/958
https://github.com/root-project/root/pull/958:515,Testability,test,test,515,"This is the [recommended way](https://cmake.org/cmake/help/latest/command/cmake_policy.html#setting-policies-by-cmake-version) to set CMake policy settings. This means that policies created in versions prior to 3.9 will use the NEW setting by default, and newer policies will generate warnings. Set to 3.9 since that's the highest version currently tested in Jenkins. The Mac builds are generating a [warning](http://cdash.cern.ch/buildSummary.php?buildid=393980) (shown below) about policy CMP0068, so I'd like to test this; and move to the new policy mechanism once any problems that show up are fixed. ```; CMake Warning (dev):; Policy CMP0068 is not set: RPATH settings on macOS do not affect; install_name. Run ""cmake --help-policy CMP0068"" for policy details. Use; the cmake_policy command to set the policy and suppress this warning. For compatibility with older versions of CMake, the install_name fields for; the following targets are still affected by RPATH settings:. LTO; libclang. This warning is for project developers. Use -Wno-dev to suppres-- Generating done; s it.; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/958
https://github.com/root-project/root/pull/959:432,Availability,error,error,432,"This PR introduces (with unit tests!) the concept of a forward-compatibility feature break flag for `TBasket`. This allows the `TBasket` class to identify if the object being deserialized was written by a newer version of ROOT using a feature that breaks forward-compatibility. Note that much care was taken so older versions of ROOT that *don't* recognize the new flag will believe the file is corrupt; they will give a misleading error message, but will not silently serve corrupted data. If this approach goes forward, I intend to backport the flags to older versions of ROOT -- they should be able to recognize files they aren't supposed to read. I do not plan to backport the new IO features themselves.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:438,Integrability,message,message,438,"This PR introduces (with unit tests!) the concept of a forward-compatibility feature break flag for `TBasket`. This allows the `TBasket` class to identify if the object being deserialized was written by a newer version of ROOT using a feature that breaks forward-compatibility. Note that much care was taken so older versions of ROOT that *don't* recognize the new flag will believe the file is corrupt; they will give a misleading error message, but will not silently serve corrupted data. If this approach goes forward, I intend to backport the flags to older versions of ROOT -- they should be able to recognize files they aren't supposed to read. I do not plan to backport the new IO features themselves.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:30,Testability,test,tests,30,"This PR introduces (with unit tests!) the concept of a forward-compatibility feature break flag for `TBasket`. This allows the `TBasket` class to identify if the object being deserialized was written by a newer version of ROOT using a feature that breaks forward-compatibility. Note that much care was taken so older versions of ROOT that *don't* recognize the new flag will believe the file is corrupt; they will give a misleading error message, but will not silently serve corrupted data. If this approach goes forward, I intend to backport the flags to older versions of ROOT -- they should be able to recognize files they aren't supposed to read. I do not plan to backport the new IO features themselves.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/960:125,Testability,log,log,125,Added some brief information about the function of GetUxmax etc. This helps clarify its return value when the axis is set to log. Some of this was mentioned on the [ROOT forum](https://root-forum.cern.ch/t/tpolyline3d-with-log-scale/26115/9) with @couet.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/960
https://github.com/root-project/root/pull/960:223,Testability,log,log-scale,223,Added some brief information about the function of GetUxmax etc. This helps clarify its return value when the axis is set to log. Some of this was mentioned on the [ROOT forum](https://root-forum.cern.ch/t/tpolyline3d-with-log-scale/26115/9) with @couet.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/960
https://github.com/root-project/root/pull/963:63,Integrability,depend,dependencies,63,"I introduced those targets because I thought we actually have; dependencies between the different rootcling invocations because; of the C++ modules. After some discussion with Axel, it turns out; we actually always have dependencies here, as the dictionaries; should regenerate the dictionary when one of the referenced; libraries/headers change (as the declarations in there change,; which might influence the current dictionary). We can just safely remove this, the actual dependency which is; ARG_DEPENDENCIES is still in the custom command dependencies; (currently the ROOTCLING_ targets where just a no-op that was; supposed to activated in a later commit when we remove the; ARG_DEPENDENCIES and replace it with the ROOTCLING_; dependencies if runtime_modules was set to ON).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/963
https://github.com/root-project/root/pull/963:220,Integrability,depend,dependencies,220,"I introduced those targets because I thought we actually have; dependencies between the different rootcling invocations because; of the C++ modules. After some discussion with Axel, it turns out; we actually always have dependencies here, as the dictionaries; should regenerate the dictionary when one of the referenced; libraries/headers change (as the declarations in there change,; which might influence the current dictionary). We can just safely remove this, the actual dependency which is; ARG_DEPENDENCIES is still in the custom command dependencies; (currently the ROOTCLING_ targets where just a no-op that was; supposed to activated in a later commit when we remove the; ARG_DEPENDENCIES and replace it with the ROOTCLING_; dependencies if runtime_modules was set to ON).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/963
https://github.com/root-project/root/pull/963:475,Integrability,depend,dependency,475,"I introduced those targets because I thought we actually have; dependencies between the different rootcling invocations because; of the C++ modules. After some discussion with Axel, it turns out; we actually always have dependencies here, as the dictionaries; should regenerate the dictionary when one of the referenced; libraries/headers change (as the declarations in there change,; which might influence the current dictionary). We can just safely remove this, the actual dependency which is; ARG_DEPENDENCIES is still in the custom command dependencies; (currently the ROOTCLING_ targets where just a no-op that was; supposed to activated in a later commit when we remove the; ARG_DEPENDENCIES and replace it with the ROOTCLING_; dependencies if runtime_modules was set to ON).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/963
https://github.com/root-project/root/pull/963:544,Integrability,depend,dependencies,544,"I introduced those targets because I thought we actually have; dependencies between the different rootcling invocations because; of the C++ modules. After some discussion with Axel, it turns out; we actually always have dependencies here, as the dictionaries; should regenerate the dictionary when one of the referenced; libraries/headers change (as the declarations in there change,; which might influence the current dictionary). We can just safely remove this, the actual dependency which is; ARG_DEPENDENCIES is still in the custom command dependencies; (currently the ROOTCLING_ targets where just a no-op that was; supposed to activated in a later commit when we remove the; ARG_DEPENDENCIES and replace it with the ROOTCLING_; dependencies if runtime_modules was set to ON).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/963
https://github.com/root-project/root/pull/963:734,Integrability,depend,dependencies,734,"I introduced those targets because I thought we actually have; dependencies between the different rootcling invocations because; of the C++ modules. After some discussion with Axel, it turns out; we actually always have dependencies here, as the dictionaries; should regenerate the dictionary when one of the referenced; libraries/headers change (as the declarations in there change,; which might influence the current dictionary). We can just safely remove this, the actual dependency which is; ARG_DEPENDENCIES is still in the custom command dependencies; (currently the ROOTCLING_ targets where just a no-op that was; supposed to activated in a later commit when we remove the; ARG_DEPENDENCIES and replace it with the ROOTCLING_; dependencies if runtime_modules was set to ON).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/963
https://github.com/root-project/root/pull/963:444,Safety,safe,safely,444,"I introduced those targets because I thought we actually have; dependencies between the different rootcling invocations because; of the C++ modules. After some discussion with Axel, it turns out; we actually always have dependencies here, as the dictionaries; should regenerate the dictionary when one of the referenced; libraries/headers change (as the declarations in there change,; which might influence the current dictionary). We can just safely remove this, the actual dependency which is; ARG_DEPENDENCIES is still in the custom command dependencies; (currently the ROOTCLING_ targets where just a no-op that was; supposed to activated in a later commit when we remove the; ARG_DEPENDENCIES and replace it with the ROOTCLING_; dependencies if runtime_modules was set to ON).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/963
https://github.com/root-project/root/pull/967:263,Deployability,patch,patch,263,"So far we just hard-coded the default definitions that LLVM uses to; the CLING_CXXFLAGS. This means that once LLVM actually changes; its compile defintions, code that uses the CLING_CXXFLAGS is no; longer in sync and starts reading invalid memory and so on. This patch extracts these flags from LLVM now and properly adds; them to the CLING_CXXFLAGS instead of hardcoding them. This fixes the failing roottest-root-aclic-misc-assertROOT7027 test. Thanks to Axel for debugging this!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/967
https://github.com/root-project/root/pull/967:441,Testability,test,test,441,"So far we just hard-coded the default definitions that LLVM uses to; the CLING_CXXFLAGS. This means that once LLVM actually changes; its compile defintions, code that uses the CLING_CXXFLAGS is no; longer in sync and starts reading invalid memory and so on. This patch extracts these flags from LLVM now and properly adds; them to the CLING_CXXFLAGS instead of hardcoding them. This fixes the failing roottest-root-aclic-misc-assertROOT7027 test. Thanks to Axel for debugging this!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/967
https://github.com/root-project/root/pull/968:36,Security,Validat,ValidationSize,36,"Introduces a new option to the DNN, ValidationSize, which can be used to split the training data into two parts, one for training and one for validation.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/968
https://github.com/root-project/root/pull/968:142,Security,validat,validation,142,"Introduces a new option to the DNN, ValidationSize, which can be used to split the training data into two parts, one for training and one for validation.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/968
https://github.com/root-project/root/pull/971:17,Performance,optimiz,optimization,17,"If -Ofast is the optimization level, then -ffast-math should be enabled for GCC builds (Linux) to be able to activate ```__FAST_MATH__``` macros (order of flags is important apparently too)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/975:84,Modifiability,variab,variable,84,This replace failed to actually make the paths relative because; of the typo in the variable name and the surrounding parentheses. This also fixes the nightly modules builds.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/975
https://github.com/root-project/root/pull/977:153,Modifiability,variab,variables,153,Remedies an inconsistency in how the operator `%` was treated in comparison to e.g. `&`. Also adds documentation on operators and the difference between variables and parameters.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/977
https://github.com/root-project/root/pull/978:54,Deployability,install,installed,54,Add the RooFit related libraries if RooFit feature is installed.; Tested and tested with a cmake build and a main that creates RooRealVar.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/978
https://github.com/root-project/root/pull/978:66,Testability,Test,Tested,66,Add the RooFit related libraries if RooFit feature is installed.; Tested and tested with a cmake build and a main that creates RooRealVar.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/978
https://github.com/root-project/root/pull/978:77,Testability,test,tested,77,Add the RooFit related libraries if RooFit feature is installed.; Tested and tested with a cmake build and a main that creates RooRealVar.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/978
https://github.com/root-project/root/pull/980:232,Performance,load,loading,232,"The ROOT macros use at the moment use a very expansive list; of paths when looking for headers. And right now clingutils rely on; the ROOT_GENERATE_DICTIONARY behaviour that a header that can't; be found will be deferred to runtime loading in cling, but this; strategy starts to fail once people have files named 'map',; 'vector' in any path that CMake's find_file searches by default. When those files are found by our CMake macros, they won't delay; the lookup of for example 'map' to the runtime but instead directly; include '/bin/map' (which is then causing Cling to fail as this; is usually an executable or something like that). As we can't seem to just fix the find_file behavior, we instead; fix this from clingutils' side by looking up the STL headers; manually via our cling search paths which means we no longer; rely on the 'if-not-found-load-at-runtime' branch in the; ROOT_GENERATE_DICTINARY macro.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/980
https://github.com/root-project/root/pull/980:851,Performance,load,load-at-runtime,851,"The ROOT macros use at the moment use a very expansive list; of paths when looking for headers. And right now clingutils rely on; the ROOT_GENERATE_DICTIONARY behaviour that a header that can't; be found will be deferred to runtime loading in cling, but this; strategy starts to fail once people have files named 'map',; 'vector' in any path that CMake's find_file searches by default. When those files are found by our CMake macros, they won't delay; the lookup of for example 'map' to the runtime but instead directly; include '/bin/map' (which is then causing Cling to fail as this; is usually an executable or something like that). As we can't seem to just fix the find_file behavior, we instead; fix this from clingutils' side by looking up the STL headers; manually via our cling search paths which means we no longer; rely on the 'if-not-found-load-at-runtime' branch in the; ROOT_GENERATE_DICTINARY macro.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/980
https://github.com/root-project/root/pull/982:305,Testability,test,tests,305,"Example usage:. ```c++; // generate random numbers and fill a histogram in parallel; constexpr auto nSlots = 4u;; ROOT::EnableImplicitMT(nSlots);; std::array<TRandom, nSlots> r;; TDataFrame d(1e8);; d.DefineSlot(""x"", [&r](unsigned int slot) { return r[slot].Gaus(); }, {}); .Histo1D(""x"");; ```. More unit tests are needed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/982
https://github.com/root-project/root/pull/983:0,Testability,Test,Test,0,Test PR to check build issues and incompatibilities with current test suite.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/983
https://github.com/root-project/root/pull/983:65,Testability,test,test,65,Test PR to check build issues and incompatibilities with current test suite.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/983
https://github.com/root-project/root/pull/994:523,Deployability,patch,patch,523,Necessary to make cling pickup the VFS from root which fixes all the merging; problems that we have in STL/libc. Original description:. Title: Use the VFS from the CompilerInvocation by default. The CompilerInstance should create its default VFS from its CompilerInvocation. Right now the; user has to manually create the VFS before creating the FileManager even though; `-ivfsoverlay file.yaml` was passed via the CompilerInvocation (which is exactly how we worked; around this issue in `FrontendAction.cpp` so far). This patch uses the invocation's VFS by default and also tests this behavior now from the; point of view of a program that uses the clang API.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/994
https://github.com/root-project/root/pull/994:575,Testability,test,tests,575,Necessary to make cling pickup the VFS from root which fixes all the merging; problems that we have in STL/libc. Original description:. Title: Use the VFS from the CompilerInvocation by default. The CompilerInstance should create its default VFS from its CompilerInvocation. Right now the; user has to manually create the VFS before creating the FileManager even though; `-ivfsoverlay file.yaml` was passed via the CompilerInvocation (which is exactly how we worked; around this issue in `FrontendAction.cpp` so far). This patch uses the invocation's VFS by default and also tests this behavior now from the; point of view of a program that uses the clang API.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/994
https://github.com/root-project/root/pull/995:263,Availability,error,errors,263,"With the module generation in rootcling Clang rlies on AST consumers; to do the module generation work for it. Right now this doesn't work; however with the interpreter, as we just overwrite the deserialization; listener that clang added which will cause strange errors during; the module generation (the most prompinent error is that the number; of recorded submodules will be incorrect, as this it the first thing; that Clang checks before writing a module and which is recorded by; an ASTDeserializationListener). This patch just adds a multiplexer here that allows us to keep the; old listener while also adding the one we have.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/995
https://github.com/root-project/root/pull/995:321,Availability,error,error,321,"With the module generation in rootcling Clang rlies on AST consumers; to do the module generation work for it. Right now this doesn't work; however with the interpreter, as we just overwrite the deserialization; listener that clang added which will cause strange errors during; the module generation (the most prompinent error is that the number; of recorded submodules will be incorrect, as this it the first thing; that Clang checks before writing a module and which is recorded by; an ASTDeserializationListener). This patch just adds a multiplexer here that allows us to keep the; old listener while also adding the one we have.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/995
https://github.com/root-project/root/pull/995:522,Deployability,patch,patch,522,"With the module generation in rootcling Clang rlies on AST consumers; to do the module generation work for it. Right now this doesn't work; however with the interpreter, as we just overwrite the deserialization; listener that clang added which will cause strange errors during; the module generation (the most prompinent error is that the number; of recorded submodules will be incorrect, as this it the first thing; that Clang checks before writing a module and which is recorded by; an ASTDeserializationListener). This patch just adds a multiplexer here that allows us to keep the; old listener while also adding the one we have.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/995
https://github.com/root-project/root/pull/1001:155,Performance,queue,queue,155,"Add methods TBufferMerger::GetQueueSize() and TBufferMerger::RegisterCallback() to alow user; to control the rate at which data is pushed into the merging queue. In our test, we use the callback; function to launch tasks asynchronously whenever a buffer is done processing.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1001
https://github.com/root-project/root/pull/1001:169,Testability,test,test,169,"Add methods TBufferMerger::GetQueueSize() and TBufferMerger::RegisterCallback() to alow user; to control the rate at which data is pushed into the merging queue. In our test, we use the callback; function to launch tasks asynchronously whenever a buffer is done processing.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1001
https://github.com/root-project/root/pull/1002:13,Deployability,install,install,13,"Test if root install has roofit, if yes add the roofit and other libraries to rootlibs",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1002
https://github.com/root-project/root/pull/1002:0,Testability,Test,Test,0,"Test if root install has roofit, if yes add the roofit and other libraries to rootlibs",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1002
https://github.com/root-project/root/pull/1004:58,Deployability,Update,Update,58,"...so we don't need to write ""MULTITHREAD"" as fit option. Update the test.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1004
https://github.com/root-project/root/pull/1004:69,Testability,test,test,69,"...so we don't need to write ""MULTITHREAD"" as fit option. Update the test.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1004
https://github.com/root-project/root/pull/1010:665,Energy Efficiency,schedul,scheduler,665,"@bbockelm @pcanal @dpiparo . Here is the new imt unzipping basket with TTaskGroup interface. Comparing to #785 , I noticed there are still 3%(in Real Time) ~ 5%(in CPU Time) performance drops in new implementation. The degradation is caused by tbb function:. tbb::internal::custom_scheduler<tbb::internal::IntelSchedulerTraits>::receive_or_steal_task(long&). I suspect the reason is because #785 in the following function:. https://github.com/zzxuanyuan/root/blob/15cceff19b48dfe4a4b0c69c1ec07ea75bd1ccb5/tree/tree/src/TTreeCacheUnzip.cxx#L708. CreateTasks() explicitly creates 2 tasks (empty_task and MappingTask; and set_ref_count(2) means 2 tasks in total). The scheduler might make a better decision here since it knows there will be only one task except empty_task running in future. On the other hand, TTaskGroup uses tbb::task_group which calls the following function:. https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L108. task_group_base() also first creates a empty_task. However, it only creates 1 task(itself) by setting reference count as 1 (set_ref_count(1)). When it invoke another task by calling . https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L103. allocate_additional_child() will create a new task as child and increment reference count by 1. I guess accumulating tasks on-the-fly might degrade the performance since the tbb scheduler could spend more time on finding tasks to work on. In a short, I think explicitly defining the total number of tasks and task graph should have better performance (more efficient for scheduler I guess) than adding more tasks to task_group as the program runs. There are two alternative approaches that might improve the performance. ; 1. Since we have already know we will only have one task (except empty_task) to add into the task_group, we could revise TTaskGroup interface and notify it what task is going to run in advance.; 2. We coul",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:1451,Energy Efficiency,schedul,scheduler,1451,"ementation. The degradation is caused by tbb function:. tbb::internal::custom_scheduler<tbb::internal::IntelSchedulerTraits>::receive_or_steal_task(long&). I suspect the reason is because #785 in the following function:. https://github.com/zzxuanyuan/root/blob/15cceff19b48dfe4a4b0c69c1ec07ea75bd1ccb5/tree/tree/src/TTreeCacheUnzip.cxx#L708. CreateTasks() explicitly creates 2 tasks (empty_task and MappingTask; and set_ref_count(2) means 2 tasks in total). The scheduler might make a better decision here since it knows there will be only one task except empty_task running in future. On the other hand, TTaskGroup uses tbb::task_group which calls the following function:. https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L108. task_group_base() also first creates a empty_task. However, it only creates 1 task(itself) by setting reference count as 1 (set_ref_count(1)). When it invoke another task by calling . https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L103. allocate_additional_child() will create a new task as child and increment reference count by 1. I guess accumulating tasks on-the-fly might degrade the performance since the tbb scheduler could spend more time on finding tasks to work on. In a short, I think explicitly defining the total number of tasks and task graph should have better performance (more efficient for scheduler I guess) than adding more tasks to task_group as the program runs. There are two alternative approaches that might improve the performance. ; 1. Since we have already know we will only have one task (except empty_task) to add into the task_group, we could revise TTaskGroup interface and notify it what task is going to run in advance.; 2. We could get rid of TTaskGroup in my current implemention and synchronously map baskets to different tasks. If we do not mind a little performance drops, the current implementation should be fine. Thanks,. Zhe",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:1630,Energy Efficiency,efficient,efficient,1630,"ementation. The degradation is caused by tbb function:. tbb::internal::custom_scheduler<tbb::internal::IntelSchedulerTraits>::receive_or_steal_task(long&). I suspect the reason is because #785 in the following function:. https://github.com/zzxuanyuan/root/blob/15cceff19b48dfe4a4b0c69c1ec07ea75bd1ccb5/tree/tree/src/TTreeCacheUnzip.cxx#L708. CreateTasks() explicitly creates 2 tasks (empty_task and MappingTask; and set_ref_count(2) means 2 tasks in total). The scheduler might make a better decision here since it knows there will be only one task except empty_task running in future. On the other hand, TTaskGroup uses tbb::task_group which calls the following function:. https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L108. task_group_base() also first creates a empty_task. However, it only creates 1 task(itself) by setting reference count as 1 (set_ref_count(1)). When it invoke another task by calling . https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L103. allocate_additional_child() will create a new task as child and increment reference count by 1. I guess accumulating tasks on-the-fly might degrade the performance since the tbb scheduler could spend more time on finding tasks to work on. In a short, I think explicitly defining the total number of tasks and task graph should have better performance (more efficient for scheduler I guess) than adding more tasks to task_group as the program runs. There are two alternative approaches that might improve the performance. ; 1. Since we have already know we will only have one task (except empty_task) to add into the task_group, we could revise TTaskGroup interface and notify it what task is going to run in advance.; 2. We could get rid of TTaskGroup in my current implemention and synchronously map baskets to different tasks. If we do not mind a little performance drops, the current implementation should be fine. Thanks,. Zhe",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:1644,Energy Efficiency,schedul,scheduler,1644,"ementation. The degradation is caused by tbb function:. tbb::internal::custom_scheduler<tbb::internal::IntelSchedulerTraits>::receive_or_steal_task(long&). I suspect the reason is because #785 in the following function:. https://github.com/zzxuanyuan/root/blob/15cceff19b48dfe4a4b0c69c1ec07ea75bd1ccb5/tree/tree/src/TTreeCacheUnzip.cxx#L708. CreateTasks() explicitly creates 2 tasks (empty_task and MappingTask; and set_ref_count(2) means 2 tasks in total). The scheduler might make a better decision here since it knows there will be only one task except empty_task running in future. On the other hand, TTaskGroup uses tbb::task_group which calls the following function:. https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L108. task_group_base() also first creates a empty_task. However, it only creates 1 task(itself) by setting reference count as 1 (set_ref_count(1)). When it invoke another task by calling . https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L103. allocate_additional_child() will create a new task as child and increment reference count by 1. I guess accumulating tasks on-the-fly might degrade the performance since the tbb scheduler could spend more time on finding tasks to work on. In a short, I think explicitly defining the total number of tasks and task graph should have better performance (more efficient for scheduler I guess) than adding more tasks to task_group as the program runs. There are two alternative approaches that might improve the performance. ; 1. Since we have already know we will only have one task (except empty_task) to add into the task_group, we could revise TTaskGroup interface and notify it what task is going to run in advance.; 2. We could get rid of TTaskGroup in my current implemention and synchronously map baskets to different tasks. If we do not mind a little performance drops, the current implementation should be fine. Thanks,. Zhe",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:82,Integrability,interface,interface,82,"@bbockelm @pcanal @dpiparo . Here is the new imt unzipping basket with TTaskGroup interface. Comparing to #785 , I noticed there are still 3%(in Real Time) ~ 5%(in CPU Time) performance drops in new implementation. The degradation is caused by tbb function:. tbb::internal::custom_scheduler<tbb::internal::IntelSchedulerTraits>::receive_or_steal_task(long&). I suspect the reason is because #785 in the following function:. https://github.com/zzxuanyuan/root/blob/15cceff19b48dfe4a4b0c69c1ec07ea75bd1ccb5/tree/tree/src/TTreeCacheUnzip.cxx#L708. CreateTasks() explicitly creates 2 tasks (empty_task and MappingTask; and set_ref_count(2) means 2 tasks in total). The scheduler might make a better decision here since it knows there will be only one task except empty_task running in future. On the other hand, TTaskGroup uses tbb::task_group which calls the following function:. https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L108. task_group_base() also first creates a empty_task. However, it only creates 1 task(itself) by setting reference count as 1 (set_ref_count(1)). When it invoke another task by calling . https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L103. allocate_additional_child() will create a new task as child and increment reference count by 1. I guess accumulating tasks on-the-fly might degrade the performance since the tbb scheduler could spend more time on finding tasks to work on. In a short, I think explicitly defining the total number of tasks and task graph should have better performance (more efficient for scheduler I guess) than adding more tasks to task_group as the program runs. There are two alternative approaches that might improve the performance. ; 1. Since we have already know we will only have one task (except empty_task) to add into the task_group, we could revise TTaskGroup interface and notify it what task is going to run in advance.; 2. We coul",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:1928,Integrability,interface,interface,1928,"ementation. The degradation is caused by tbb function:. tbb::internal::custom_scheduler<tbb::internal::IntelSchedulerTraits>::receive_or_steal_task(long&). I suspect the reason is because #785 in the following function:. https://github.com/zzxuanyuan/root/blob/15cceff19b48dfe4a4b0c69c1ec07ea75bd1ccb5/tree/tree/src/TTreeCacheUnzip.cxx#L708. CreateTasks() explicitly creates 2 tasks (empty_task and MappingTask; and set_ref_count(2) means 2 tasks in total). The scheduler might make a better decision here since it knows there will be only one task except empty_task running in future. On the other hand, TTaskGroup uses tbb::task_group which calls the following function:. https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L108. task_group_base() also first creates a empty_task. However, it only creates 1 task(itself) by setting reference count as 1 (set_ref_count(1)). When it invoke another task by calling . https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L103. allocate_additional_child() will create a new task as child and increment reference count by 1. I guess accumulating tasks on-the-fly might degrade the performance since the tbb scheduler could spend more time on finding tasks to work on. In a short, I think explicitly defining the total number of tasks and task graph should have better performance (more efficient for scheduler I guess) than adding more tasks to task_group as the program runs. There are two alternative approaches that might improve the performance. ; 1. Since we have already know we will only have one task (except empty_task) to add into the task_group, we could revise TTaskGroup interface and notify it what task is going to run in advance.; 2. We could get rid of TTaskGroup in my current implemention and synchronously map baskets to different tasks. If we do not mind a little performance drops, the current implementation should be fine. Thanks,. Zhe",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:174,Performance,perform,performance,174,"@bbockelm @pcanal @dpiparo . Here is the new imt unzipping basket with TTaskGroup interface. Comparing to #785 , I noticed there are still 3%(in Real Time) ~ 5%(in CPU Time) performance drops in new implementation. The degradation is caused by tbb function:. tbb::internal::custom_scheduler<tbb::internal::IntelSchedulerTraits>::receive_or_steal_task(long&). I suspect the reason is because #785 in the following function:. https://github.com/zzxuanyuan/root/blob/15cceff19b48dfe4a4b0c69c1ec07ea75bd1ccb5/tree/tree/src/TTreeCacheUnzip.cxx#L708. CreateTasks() explicitly creates 2 tasks (empty_task and MappingTask; and set_ref_count(2) means 2 tasks in total). The scheduler might make a better decision here since it knows there will be only one task except empty_task running in future. On the other hand, TTaskGroup uses tbb::task_group which calls the following function:. https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L108. task_group_base() also first creates a empty_task. However, it only creates 1 task(itself) by setting reference count as 1 (set_ref_count(1)). When it invoke another task by calling . https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L103. allocate_additional_child() will create a new task as child and increment reference count by 1. I guess accumulating tasks on-the-fly might degrade the performance since the tbb scheduler could spend more time on finding tasks to work on. In a short, I think explicitly defining the total number of tasks and task graph should have better performance (more efficient for scheduler I guess) than adding more tasks to task_group as the program runs. There are two alternative approaches that might improve the performance. ; 1. Since we have already know we will only have one task (except empty_task) to add into the task_group, we could revise TTaskGroup interface and notify it what task is going to run in advance.; 2. We coul",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:1425,Performance,perform,performance,1425,"ementation. The degradation is caused by tbb function:. tbb::internal::custom_scheduler<tbb::internal::IntelSchedulerTraits>::receive_or_steal_task(long&). I suspect the reason is because #785 in the following function:. https://github.com/zzxuanyuan/root/blob/15cceff19b48dfe4a4b0c69c1ec07ea75bd1ccb5/tree/tree/src/TTreeCacheUnzip.cxx#L708. CreateTasks() explicitly creates 2 tasks (empty_task and MappingTask; and set_ref_count(2) means 2 tasks in total). The scheduler might make a better decision here since it knows there will be only one task except empty_task running in future. On the other hand, TTaskGroup uses tbb::task_group which calls the following function:. https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L108. task_group_base() also first creates a empty_task. However, it only creates 1 task(itself) by setting reference count as 1 (set_ref_count(1)). When it invoke another task by calling . https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L103. allocate_additional_child() will create a new task as child and increment reference count by 1. I guess accumulating tasks on-the-fly might degrade the performance since the tbb scheduler could spend more time on finding tasks to work on. In a short, I think explicitly defining the total number of tasks and task graph should have better performance (more efficient for scheduler I guess) than adding more tasks to task_group as the program runs. There are two alternative approaches that might improve the performance. ; 1. Since we have already know we will only have one task (except empty_task) to add into the task_group, we could revise TTaskGroup interface and notify it what task is going to run in advance.; 2. We could get rid of TTaskGroup in my current implemention and synchronously map baskets to different tasks. If we do not mind a little performance drops, the current implementation should be fine. Thanks,. Zhe",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:1612,Performance,perform,performance,1612,"ementation. The degradation is caused by tbb function:. tbb::internal::custom_scheduler<tbb::internal::IntelSchedulerTraits>::receive_or_steal_task(long&). I suspect the reason is because #785 in the following function:. https://github.com/zzxuanyuan/root/blob/15cceff19b48dfe4a4b0c69c1ec07ea75bd1ccb5/tree/tree/src/TTreeCacheUnzip.cxx#L708. CreateTasks() explicitly creates 2 tasks (empty_task and MappingTask; and set_ref_count(2) means 2 tasks in total). The scheduler might make a better decision here since it knows there will be only one task except empty_task running in future. On the other hand, TTaskGroup uses tbb::task_group which calls the following function:. https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L108. task_group_base() also first creates a empty_task. However, it only creates 1 task(itself) by setting reference count as 1 (set_ref_count(1)). When it invoke another task by calling . https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L103. allocate_additional_child() will create a new task as child and increment reference count by 1. I guess accumulating tasks on-the-fly might degrade the performance since the tbb scheduler could spend more time on finding tasks to work on. In a short, I think explicitly defining the total number of tasks and task graph should have better performance (more efficient for scheduler I guess) than adding more tasks to task_group as the program runs. There are two alternative approaches that might improve the performance. ; 1. Since we have already know we will only have one task (except empty_task) to add into the task_group, we could revise TTaskGroup interface and notify it what task is going to run in advance.; 2. We could get rid of TTaskGroup in my current implemention and synchronously map baskets to different tasks. If we do not mind a little performance drops, the current implementation should be fine. Thanks,. Zhe",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:1781,Performance,perform,performance,1781,"ementation. The degradation is caused by tbb function:. tbb::internal::custom_scheduler<tbb::internal::IntelSchedulerTraits>::receive_or_steal_task(long&). I suspect the reason is because #785 in the following function:. https://github.com/zzxuanyuan/root/blob/15cceff19b48dfe4a4b0c69c1ec07ea75bd1ccb5/tree/tree/src/TTreeCacheUnzip.cxx#L708. CreateTasks() explicitly creates 2 tasks (empty_task and MappingTask; and set_ref_count(2) means 2 tasks in total). The scheduler might make a better decision here since it knows there will be only one task except empty_task running in future. On the other hand, TTaskGroup uses tbb::task_group which calls the following function:. https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L108. task_group_base() also first creates a empty_task. However, it only creates 1 task(itself) by setting reference count as 1 (set_ref_count(1)). When it invoke another task by calling . https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L103. allocate_additional_child() will create a new task as child and increment reference count by 1. I guess accumulating tasks on-the-fly might degrade the performance since the tbb scheduler could spend more time on finding tasks to work on. In a short, I think explicitly defining the total number of tasks and task graph should have better performance (more efficient for scheduler I guess) than adding more tasks to task_group as the program runs. There are two alternative approaches that might improve the performance. ; 1. Since we have already know we will only have one task (except empty_task) to add into the task_group, we could revise TTaskGroup interface and notify it what task is going to run in advance.; 2. We could get rid of TTaskGroup in my current implemention and synchronously map baskets to different tasks. If we do not mind a little performance drops, the current implementation should be fine. Thanks,. Zhe",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:2129,Performance,perform,performance,2129,"ementation. The degradation is caused by tbb function:. tbb::internal::custom_scheduler<tbb::internal::IntelSchedulerTraits>::receive_or_steal_task(long&). I suspect the reason is because #785 in the following function:. https://github.com/zzxuanyuan/root/blob/15cceff19b48dfe4a4b0c69c1ec07ea75bd1ccb5/tree/tree/src/TTreeCacheUnzip.cxx#L708. CreateTasks() explicitly creates 2 tasks (empty_task and MappingTask; and set_ref_count(2) means 2 tasks in total). The scheduler might make a better decision here since it knows there will be only one task except empty_task running in future. On the other hand, TTaskGroup uses tbb::task_group which calls the following function:. https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L108. task_group_base() also first creates a empty_task. However, it only creates 1 task(itself) by setting reference count as 1 (set_ref_count(1)). When it invoke another task by calling . https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L103. allocate_additional_child() will create a new task as child and increment reference count by 1. I guess accumulating tasks on-the-fly might degrade the performance since the tbb scheduler could spend more time on finding tasks to work on. In a short, I think explicitly defining the total number of tasks and task graph should have better performance (more efficient for scheduler I guess) than adding more tasks to task_group as the program runs. There are two alternative approaches that might improve the performance. ; 1. Since we have already know we will only have one task (except empty_task) to add into the task_group, we could revise TTaskGroup interface and notify it what task is going to run in advance.; 2. We could get rid of TTaskGroup in my current implemention and synchronously map baskets to different tasks. If we do not mind a little performance drops, the current implementation should be fine. Thanks,. Zhe",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1012:69,Deployability,Update,Updated,69,Fixing built of classic build for builtin lz4 and non-builtin case.; Updated version of PR#926 https://github.com/root-project/root/pull/926,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1012
https://github.com/root-project/root/pull/1014:121,Deployability,patch,patch,121,We need the VFS we generated during runtime to prevent merging; issues coming from libc/STL when running rootcling. This patch; adds the relevant flag to the normal compilation args (where; it does nothing as we don't have cxxmodules enabled by default); and then let them propagate to cling.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1014
https://github.com/root-project/root/pull/1016:208,Availability,error,error,208,"When running rootcling to produce C++ modules we currently run; into this issue that is an issue in this specific LLVM revision; we are using in ROOT. The issue was fixed by Richard upstream; in r303373. The error we fix with this patch is:; ```; While building module 'Core':; While building module 'stl' imported from input_line_1:1:; In file included from <module-includes>:5:; In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/ccomplex:39:; In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/complex:42:; /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:102:23: error: use of undeclared identifier '_Tp'; struct __are_same<_Tp, _Tp>; ^; /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:25: error: use of undeclared identifier '_Tp'; struct __is_pointer<_Tp*>; ^; /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:29: error: expected expression; struct __is_pointer<_Tp*>; ^; /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:329:37: error: declaration of '_Tp' must be imported from module 'stl.ccomplex' before it is required; : public __traitor<__is_integer<_Tp>, __is_floating<_Tp> >; ^; /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:327:21: note: previous declaration is here; template<typename _Tp>; ^; ```. Original patch description:. When we enter a module ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1016
https://github.com/root-project/root/pull/1016:873,Availability,error,error,873,"When running rootcling to produce C++ modules we currently run; into this issue that is an issue in this specific LLVM revision; we are using in ROOT. The issue was fixed by Richard upstream; in r303373. The error we fix with this patch is:; ```; While building module 'Core':; While building module 'stl' imported from input_line_1:1:; In file included from <module-includes>:5:; In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/ccomplex:39:; In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/complex:42:; /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:102:23: error: use of undeclared identifier '_Tp'; struct __are_same<_Tp, _Tp>; ^; /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:25: error: use of undeclared identifier '_Tp'; struct __is_pointer<_Tp*>; ^; /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:29: error: expected expression; struct __is_pointer<_Tp*>; ^; /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:329:37: error: declaration of '_Tp' must be imported from module 'stl.ccomplex' before it is required; : public __traitor<__is_integer<_Tp>, __is_floating<_Tp> >; ^; /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:327:21: note: previous declaration is here; template<typename _Tp>; ^; ```. Original patch description:. When we enter a module ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1016
https://github.com/root-project/root/pull/1016:1109,Availability,error,error,1109,"OOT. The issue was fixed by Richard upstream; in r303373. The error we fix with this patch is:; ```; While building module 'Core':; While building module 'stl' imported from input_line_1:1:; In file included from <module-includes>:5:; In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/ccomplex:39:; In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/complex:42:; /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:102:23: error: use of undeclared identifier '_Tp'; struct __are_same<_Tp, _Tp>; ^; /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:25: error: use of undeclared identifier '_Tp'; struct __is_pointer<_Tp*>; ^; /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:29: error: expected expression; struct __is_pointer<_Tp*>; ^; /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:329:37: error: declaration of '_Tp' must be imported from module 'stl.ccomplex' before it is required; : public __traitor<__is_integer<_Tp>, __is_floating<_Tp> >; ^; /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:327:21: note: previous declaration is here; template<typename _Tp>; ^; ```. Original patch description:. When we enter a module within a linkage specification, switch the linkage; specification and the TU to the new module. This is necessary to get the module ownership cor",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1016
https://github.com/root-project/root/pull/1016:1343,Availability,error,error,1343,"des>:5:; In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/ccomplex:39:; In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/complex:42:; /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:102:23: error: use of undeclared identifier '_Tp'; struct __are_same<_Tp, _Tp>; ^; /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:25: error: use of undeclared identifier '_Tp'; struct __is_pointer<_Tp*>; ^; /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:29: error: expected expression; struct __is_pointer<_Tp*>; ^; /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:329:37: error: declaration of '_Tp' must be imported from module 'stl.ccomplex' before it is required; : public __traitor<__is_integer<_Tp>, __is_floating<_Tp> >; ^; /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:327:21: note: previous declaration is here; template<typename _Tp>; ^; ```. Original patch description:. When we enter a module within a linkage specification, switch the linkage; specification and the TU to the new module. This is necessary to get the module ownership correct for entities that we; temporarily hang off the TranslationUnitDecl, such as template parameters and; function parameters. git-svn-id: https://llvm.org/svn/llvm-project/cfe/trunk@303373 91177308-0d34-0410-b5e6-96231b3b80d8",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1016
https://github.com/root-project/root/pull/1016:1562,Availability,error,error,1562,"des>:5:; In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/ccomplex:39:; In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/complex:42:; /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:102:23: error: use of undeclared identifier '_Tp'; struct __are_same<_Tp, _Tp>; ^; /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:25: error: use of undeclared identifier '_Tp'; struct __is_pointer<_Tp*>; ^; /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:29: error: expected expression; struct __is_pointer<_Tp*>; ^; /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:329:37: error: declaration of '_Tp' must be imported from module 'stl.ccomplex' before it is required; : public __traitor<__is_integer<_Tp>, __is_floating<_Tp> >; ^; /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:327:21: note: previous declaration is here; template<typename _Tp>; ^; ```. Original patch description:. When we enter a module within a linkage specification, switch the linkage; specification and the TU to the new module. This is necessary to get the module ownership correct for entities that we; temporarily hang off the TranslationUnitDecl, such as template parameters and; function parameters. git-svn-id: https://llvm.org/svn/llvm-project/cfe/trunk@303373 91177308-0d34-0410-b5e6-96231b3b80d8",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1016
https://github.com/root-project/root/pull/1016:231,Deployability,patch,patch,231,"When running rootcling to produce C++ modules we currently run; into this issue that is an issue in this specific LLVM revision; we are using in ROOT. The issue was fixed by Richard upstream; in r303373. The error we fix with this patch is:; ```; While building module 'Core':; While building module 'stl' imported from input_line_1:1:; In file included from <module-includes>:5:; In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/ccomplex:39:; In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/complex:42:; /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:102:23: error: use of undeclared identifier '_Tp'; struct __are_same<_Tp, _Tp>; ^; /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:25: error: use of undeclared identifier '_Tp'; struct __is_pointer<_Tp*>; ^; /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:29: error: expected expression; struct __is_pointer<_Tp*>; ^; /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:329:37: error: declaration of '_Tp' must be imported from module 'stl.ccomplex' before it is required; : public __traitor<__is_integer<_Tp>, __is_floating<_Tp> >; ^; /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:327:21: note: previous declaration is here; template<typename _Tp>; ^; ```. Original patch description:. When we enter a module ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1016
https://github.com/root-project/root/pull/1016:1958,Deployability,patch,patch,1958,"des>:5:; In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/ccomplex:39:; In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/complex:42:; /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:102:23: error: use of undeclared identifier '_Tp'; struct __are_same<_Tp, _Tp>; ^; /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:25: error: use of undeclared identifier '_Tp'; struct __is_pointer<_Tp*>; ^; /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:29: error: expected expression; struct __is_pointer<_Tp*>; ^; /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:329:37: error: declaration of '_Tp' must be imported from module 'stl.ccomplex' before it is required; : public __traitor<__is_integer<_Tp>, __is_floating<_Tp> >; ^; /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:327:21: note: previous declaration is here; template<typename _Tp>; ^; ```. Original patch description:. When we enter a module within a linkage specification, switch the linkage; specification and the TU to the new module. This is necessary to get the module ownership correct for entities that we; temporarily hang off the TranslationUnitDecl, such as template parameters and; function parameters. git-svn-id: https://llvm.org/svn/llvm-project/cfe/trunk@303373 91177308-0d34-0410-b5e6-96231b3b80d8",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1016
https://github.com/root-project/root/pull/1017:70,Testability,assert,assert,70,After some discussion with Axel we decided that there is no point to; assert here. This feature here is not related to C++ modules.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1017
https://github.com/root-project/root/pull/1018:3,Modifiability,refactor,refactoring,3,...refactoring the old way of obtaining it. Just for convenience.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1018
https://github.com/root-project/root/pull/1019:120,Deployability,update,updated,120,"If IMT is enabled, TThreadedObject should allocate as many slots as threads the pool has been set with. This PR will be updated with another default value for fgMaxSlots once PR https://github.com/root-project/root/pull/1018 has been agreed upon and merged.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1019
https://github.com/root-project/root/pull/1019:42,Energy Efficiency,allocate,allocate,42,"If IMT is enabled, TThreadedObject should allocate as many slots as threads the pool has been set with. This PR will be updated with another default value for fgMaxSlots once PR https://github.com/root-project/root/pull/1018 has been agreed upon and merged.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1019
https://github.com/root-project/root/pull/1020:68,Availability,error,error,68,"We currently fail to create a module for RootFit with the following error; message when merging a union in signal.h:; ```; In file included from input_line_12:67:; In file included from /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/RooErrorHandler.h:20:; In file included from /usr/include/signal.h:394:; /usr/include/bits/pthreadtypes.h:130:3: error: typedef redefinition with different types ('union pthread_cond_t' vs 'union pthread_cond_t'); } pthread_cond_t;; ^; /usr/include/sys/types.h:271:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'Hist.Foption.h'; ^; /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:820:10: note: Hist.Foption.h defined here; module ""Foption.h"" { header ""Foption.h"" export * }; ^; /usr/include/signal.h:394:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'RooFitCore.RooErrorHandler.h'; ^; /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:2449:10: note: RooFitCore.RooErrorHandler.h defined here; module ""RooErrorHandler.h"" { header ""RooErrorHandler.h"" export * }; ^; Error: /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/bin/rootcling: compilation failure (/build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/lib/libRooFitCorecbd7d3c40e_dictUmbrella.h); make[2]: *** [roofit/roofitcore/G__RooFitCore.cxx] Error 1; ```. This patch adds the header to the modulemap which prevents us from; trying to merge this struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1020
https://github.com/root-project/root/pull/1020:412,Availability,error,error,412,"We currently fail to create a module for RootFit with the following error; message when merging a union in signal.h:; ```; In file included from input_line_12:67:; In file included from /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/RooErrorHandler.h:20:; In file included from /usr/include/signal.h:394:; /usr/include/bits/pthreadtypes.h:130:3: error: typedef redefinition with different types ('union pthread_cond_t' vs 'union pthread_cond_t'); } pthread_cond_t;; ^; /usr/include/sys/types.h:271:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'Hist.Foption.h'; ^; /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:820:10: note: Hist.Foption.h defined here; module ""Foption.h"" { header ""Foption.h"" export * }; ^; /usr/include/signal.h:394:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'RooFitCore.RooErrorHandler.h'; ^; /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:2449:10: note: RooFitCore.RooErrorHandler.h defined here; module ""RooErrorHandler.h"" { header ""RooErrorHandler.h"" export * }; ^; Error: /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/bin/rootcling: compilation failure (/build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/lib/libRooFitCorecbd7d3c40e_dictUmbrella.h); make[2]: *** [roofit/roofitcore/G__RooFitCore.cxx] Error 1; ```. This patch adds the header to the modulemap which prevents us from; trying to merge this struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1020
https://github.com/root-project/root/pull/1020:1365,Availability,Error,Error,1365,"We currently fail to create a module for RootFit with the following error; message when merging a union in signal.h:; ```; In file included from input_line_12:67:; In file included from /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/RooErrorHandler.h:20:; In file included from /usr/include/signal.h:394:; /usr/include/bits/pthreadtypes.h:130:3: error: typedef redefinition with different types ('union pthread_cond_t' vs 'union pthread_cond_t'); } pthread_cond_t;; ^; /usr/include/sys/types.h:271:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'Hist.Foption.h'; ^; /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:820:10: note: Hist.Foption.h defined here; module ""Foption.h"" { header ""Foption.h"" export * }; ^; /usr/include/signal.h:394:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'RooFitCore.RooErrorHandler.h'; ^; /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:2449:10: note: RooFitCore.RooErrorHandler.h defined here; module ""RooErrorHandler.h"" { header ""RooErrorHandler.h"" export * }; ^; Error: /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/bin/rootcling: compilation failure (/build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/lib/libRooFitCorecbd7d3c40e_dictUmbrella.h); make[2]: *** [roofit/roofitcore/G__RooFitCore.cxx] Error 1; ```. This patch adds the header to the modulemap which prevents us from; trying to merge this struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1020
https://github.com/root-project/root/pull/1020:1504,Availability,failure,failure,1504,"We currently fail to create a module for RootFit with the following error; message when merging a union in signal.h:; ```; In file included from input_line_12:67:; In file included from /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/RooErrorHandler.h:20:; In file included from /usr/include/signal.h:394:; /usr/include/bits/pthreadtypes.h:130:3: error: typedef redefinition with different types ('union pthread_cond_t' vs 'union pthread_cond_t'); } pthread_cond_t;; ^; /usr/include/sys/types.h:271:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'Hist.Foption.h'; ^; /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:820:10: note: Hist.Foption.h defined here; module ""Foption.h"" { header ""Foption.h"" export * }; ^; /usr/include/signal.h:394:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'RooFitCore.RooErrorHandler.h'; ^; /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:2449:10: note: RooFitCore.RooErrorHandler.h defined here; module ""RooErrorHandler.h"" { header ""RooErrorHandler.h"" export * }; ^; Error: /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/bin/rootcling: compilation failure (/build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/lib/libRooFitCorecbd7d3c40e_dictUmbrella.h); make[2]: *** [roofit/roofitcore/G__RooFitCore.cxx] Error 1; ```. This patch adds the header to the modulemap which prevents us from; trying to merge this struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1020
https://github.com/root-project/root/pull/1020:1714,Availability,Error,Error,1714,"We currently fail to create a module for RootFit with the following error; message when merging a union in signal.h:; ```; In file included from input_line_12:67:; In file included from /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/RooErrorHandler.h:20:; In file included from /usr/include/signal.h:394:; /usr/include/bits/pthreadtypes.h:130:3: error: typedef redefinition with different types ('union pthread_cond_t' vs 'union pthread_cond_t'); } pthread_cond_t;; ^; /usr/include/sys/types.h:271:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'Hist.Foption.h'; ^; /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:820:10: note: Hist.Foption.h defined here; module ""Foption.h"" { header ""Foption.h"" export * }; ^; /usr/include/signal.h:394:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'RooFitCore.RooErrorHandler.h'; ^; /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:2449:10: note: RooFitCore.RooErrorHandler.h defined here; module ""RooErrorHandler.h"" { header ""RooErrorHandler.h"" export * }; ^; Error: /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/bin/rootcling: compilation failure (/build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/lib/libRooFitCorecbd7d3c40e_dictUmbrella.h); make[2]: *** [roofit/roofitcore/G__RooFitCore.cxx] Error 1; ```. This patch adds the header to the modulemap which prevents us from; trying to merge this struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1020
https://github.com/root-project/root/pull/1020:1733,Deployability,patch,patch,1733,"We currently fail to create a module for RootFit with the following error; message when merging a union in signal.h:; ```; In file included from input_line_12:67:; In file included from /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/RooErrorHandler.h:20:; In file included from /usr/include/signal.h:394:; /usr/include/bits/pthreadtypes.h:130:3: error: typedef redefinition with different types ('union pthread_cond_t' vs 'union pthread_cond_t'); } pthread_cond_t;; ^; /usr/include/sys/types.h:271:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'Hist.Foption.h'; ^; /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:820:10: note: Hist.Foption.h defined here; module ""Foption.h"" { header ""Foption.h"" export * }; ^; /usr/include/signal.h:394:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'RooFitCore.RooErrorHandler.h'; ^; /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:2449:10: note: RooFitCore.RooErrorHandler.h defined here; module ""RooErrorHandler.h"" { header ""RooErrorHandler.h"" export * }; ^; Error: /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/bin/rootcling: compilation failure (/build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/lib/libRooFitCorecbd7d3c40e_dictUmbrella.h); make[2]: *** [roofit/roofitcore/G__RooFitCore.cxx] Error 1; ```. This patch adds the header to the modulemap which prevents us from; trying to merge this struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1020
https://github.com/root-project/root/pull/1020:75,Integrability,message,message,75,"We currently fail to create a module for RootFit with the following error; message when merging a union in signal.h:; ```; In file included from input_line_12:67:; In file included from /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/RooErrorHandler.h:20:; In file included from /usr/include/signal.h:394:; /usr/include/bits/pthreadtypes.h:130:3: error: typedef redefinition with different types ('union pthread_cond_t' vs 'union pthread_cond_t'); } pthread_cond_t;; ^; /usr/include/sys/types.h:271:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'Hist.Foption.h'; ^; /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:820:10: note: Hist.Foption.h defined here; module ""Foption.h"" { header ""Foption.h"" export * }; ^; /usr/include/signal.h:394:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'RooFitCore.RooErrorHandler.h'; ^; /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:2449:10: note: RooFitCore.RooErrorHandler.h defined here; module ""RooErrorHandler.h"" { header ""RooErrorHandler.h"" export * }; ^; Error: /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/bin/rootcling: compilation failure (/build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/lib/libRooFitCorecbd7d3c40e_dictUmbrella.h); make[2]: *** [roofit/roofitcore/G__RooFitCore.cxx] Error 1; ```. This patch adds the header to the modulemap which prevents us from; trying to merge this struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1020
https://github.com/root-project/root/pull/1023:74,Testability,test,tests,74,* fix interaction of data-source columns and user-defined columns ; * add tests,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1023
https://github.com/root-project/root/pull/1028:124,Safety,avoid,avoid,124,"The warnings were raised by TThreadExecutor trying to be smart when chunking, overriding user specified number of chunks to avoid accessing uninitialized positions of the results vector. This is annoying f.e. when Fitting, with several calls to Map() with the same ""conflictive when chunking"" data.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1028
https://github.com/root-project/root/pull/1028:130,Security,access,accessing,130,"The warnings were raised by TThreadExecutor trying to be smart when chunking, overriding user specified number of chunks to avoid accessing uninitialized positions of the results vector. This is annoying f.e. when Fitting, with several calls to Map() with the same ""conflictive when chunking"" data.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1028
https://github.com/root-project/root/pull/1031:95,Integrability,message,message,95,This PR introduces a new way to express python unit tests with two CMake functions (see commit message) and leverages the new mechanism to re-formulate the PyROOT unit tests and to add new tests for the TDF pyROOT interface.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1031
https://github.com/root-project/root/pull/1031:214,Integrability,interface,interface,214,This PR introduces a new way to express python unit tests with two CMake functions (see commit message) and leverages the new mechanism to re-formulate the PyROOT unit tests and to add new tests for the TDF pyROOT interface.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1031
https://github.com/root-project/root/pull/1031:52,Testability,test,tests,52,This PR introduces a new way to express python unit tests with two CMake functions (see commit message) and leverages the new mechanism to re-formulate the PyROOT unit tests and to add new tests for the TDF pyROOT interface.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1031
https://github.com/root-project/root/pull/1031:168,Testability,test,tests,168,This PR introduces a new way to express python unit tests with two CMake functions (see commit message) and leverages the new mechanism to re-formulate the PyROOT unit tests and to add new tests for the TDF pyROOT interface.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1031
https://github.com/root-project/root/pull/1031:189,Testability,test,tests,189,This PR introduces a new way to express python unit tests with two CMake functions (see commit message) and leverages the new mechanism to re-formulate the PyROOT unit tests and to add new tests for the TDF pyROOT interface.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1031
https://github.com/root-project/root/pull/1034:251,Testability,test,test,251,This reverts commit 180cd90afe663f2e04017d03bc63111d124010c6.; It breaks lookup of functions with 'using ParentClass::Func'; in combination with modules which reuse the hidden flag for; module purposes. See https://reviews.llvm.org/D37180 for a clang test case that; tests for regressions like this in the future.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1034
https://github.com/root-project/root/pull/1034:267,Testability,test,tests,267,This reverts commit 180cd90afe663f2e04017d03bc63111d124010c6.; It breaks lookup of functions with 'using ParentClass::Func'; in combination with modules which reuse the hidden flag for; module purposes. See https://reviews.llvm.org/D37180 for a clang test case that; tests for regressions like this in the future.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1034
https://github.com/root-project/root/pull/1036:267,Availability,down,down,267,"When we add modules for system headers we are breaking this part; of the code that tries to track back via the include chain; the original header that includes this system header. In the; modules case we hit the ""module-includes:X"" include which; we then can't track down with the normal PP anymore. The reason for this code seems to be that we never know what header; is actually possible to be included and what is just some internal; (possibly non-standalone) header like ""bits/sys/types.h"". For normal rootcling informations we have to track down until; we leave the system includes or reach the top-level system; include to be sure that we can now actually include the; given path. For modules we already know when we are in the header that; is possible to be included by someone as this is the top; level module header, so we can just stop tracking once we hit the; top-level module header.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1036
https://github.com/root-project/root/pull/1036:546,Availability,down,down,546,"When we add modules for system headers we are breaking this part; of the code that tries to track back via the include chain; the original header that includes this system header. In the; modules case we hit the ""module-includes:X"" include which; we then can't track down with the normal PP anymore. The reason for this code seems to be that we never know what header; is actually possible to be included and what is just some internal; (possibly non-standalone) header like ""bits/sys/types.h"". For normal rootcling informations we have to track down until; we leave the system includes or reach the top-level system; include to be sure that we can now actually include the; given path. For modules we already know when we are in the header that; is possible to be included by someone as this is the top; level module header, so we can just stop tracking once we hit the; top-level module header.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1036
https://github.com/root-project/root/pull/1037:454,Deployability,update,update,454,"Users can now register one or more callbacks to TResultProxies (i.e.; the results of TDF actions). A callback is just a callable that takes; a reference to the result type as argument and is going to be invoked; by each worker thread once every N entries (users choose N). It is meant to be used to inspect partial results of the analysis; while the event loop is still running.; For example, in a single-thread event loop, one can draw a histogram; and update the canvas every 100 entries like this:; ; ```c++; auto h = tdf.Histo1D(""x"");; TCanvas c(""c"",""x hist"");; // update the canvas every 100 entries; h.RegisterCallback(100, [&c](TH1D &h_) { h_.Draw(); c.Update(); });; // trigger event loop, this `Draw` will be performed afterwards; h->Draw();; ```. Each worker thread invokes callbacks sequentially, but the same callback; might be invoked concurrently by different worker threads if implicit multi-threading; is enabled.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:569,Deployability,update,update,569,"Users can now register one or more callbacks to TResultProxies (i.e.; the results of TDF actions). A callback is just a callable that takes; a reference to the result type as argument and is going to be invoked; by each worker thread once every N entries (users choose N). It is meant to be used to inspect partial results of the analysis; while the event loop is still running.; For example, in a single-thread event loop, one can draw a histogram; and update the canvas every 100 entries like this:; ; ```c++; auto h = tdf.Histo1D(""x"");; TCanvas c(""c"",""x hist"");; // update the canvas every 100 entries; h.RegisterCallback(100, [&c](TH1D &h_) { h_.Draw(); c.Update(); });; // trigger event loop, this `Draw` will be performed afterwards; h->Draw();; ```. Each worker thread invokes callbacks sequentially, but the same callback; might be invoked concurrently by different worker threads if implicit multi-threading; is enabled.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:660,Deployability,Update,Update,660,"Users can now register one or more callbacks to TResultProxies (i.e.; the results of TDF actions). A callback is just a callable that takes; a reference to the result type as argument and is going to be invoked; by each worker thread once every N entries (users choose N). It is meant to be used to inspect partial results of the analysis; while the event loop is still running.; For example, in a single-thread event loop, one can draw a histogram; and update the canvas every 100 entries like this:; ; ```c++; auto h = tdf.Histo1D(""x"");; TCanvas c(""c"",""x hist"");; // update the canvas every 100 entries; h.RegisterCallback(100, [&c](TH1D &h_) { h_.Draw(); c.Update(); });; // trigger event loop, this `Draw` will be performed afterwards; h->Draw();; ```. Each worker thread invokes callbacks sequentially, but the same callback; might be invoked concurrently by different worker threads if implicit multi-threading; is enabled.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:718,Performance,perform,performed,718,"Users can now register one or more callbacks to TResultProxies (i.e.; the results of TDF actions). A callback is just a callable that takes; a reference to the result type as argument and is going to be invoked; by each worker thread once every N entries (users choose N). It is meant to be used to inspect partial results of the analysis; while the event loop is still running.; For example, in a single-thread event loop, one can draw a histogram; and update the canvas every 100 entries like this:; ; ```c++; auto h = tdf.Histo1D(""x"");; TCanvas c(""c"",""x hist"");; // update the canvas every 100 entries; h.RegisterCallback(100, [&c](TH1D &h_) { h_.Draw(); c.Update(); });; // trigger event loop, this `Draw` will be performed afterwards; h->Draw();; ```. Each worker thread invokes callbacks sequentially, but the same callback; might be invoked concurrently by different worker threads if implicit multi-threading; is enabled.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:848,Performance,concurren,concurrently,848,"Users can now register one or more callbacks to TResultProxies (i.e.; the results of TDF actions). A callback is just a callable that takes; a reference to the result type as argument and is going to be invoked; by each worker thread once every N entries (users choose N). It is meant to be used to inspect partial results of the analysis; while the event loop is still running.; For example, in a single-thread event loop, one can draw a histogram; and update the canvas every 100 entries like this:; ; ```c++; auto h = tdf.Histo1D(""x"");; TCanvas c(""c"",""x hist"");; // update the canvas every 100 entries; h.RegisterCallback(100, [&c](TH1D &h_) { h_.Draw(); c.Update(); });; // trigger event loop, this `Draw` will be performed afterwards; h->Draw();; ```. Each worker thread invokes callbacks sequentially, but the same callback; might be invoked concurrently by different worker threads if implicit multi-threading; is enabled.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:901,Performance,multi-thread,multi-threading,901,"Users can now register one or more callbacks to TResultProxies (i.e.; the results of TDF actions). A callback is just a callable that takes; a reference to the result type as argument and is going to be invoked; by each worker thread once every N entries (users choose N). It is meant to be used to inspect partial results of the analysis; while the event loop is still running.; For example, in a single-thread event loop, one can draw a histogram; and update the canvas every 100 entries like this:; ; ```c++; auto h = tdf.Histo1D(""x"");; TCanvas c(""c"",""x hist"");; // update the canvas every 100 entries; h.RegisterCallback(100, [&c](TH1D &h_) { h_.Draw(); c.Update(); });; // trigger event loop, this `Draw` will be performed afterwards; h->Draw();; ```. Each worker thread invokes callbacks sequentially, but the same callback; might be invoked concurrently by different worker threads if implicit multi-threading; is enabled.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1038:234,Deployability,patch,patch,234,"Previously the modules were only a environment variable, so we never; had any CMake code that added the correct dependencies here. Now we; do have runtime_cxxmodules, and we can actually properly add a; dependency here.; Without this patch a deleted C++ module file actually will never be regenerated.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1038
https://github.com/root-project/root/pull/1038:112,Integrability,depend,dependencies,112,"Previously the modules were only a environment variable, so we never; had any CMake code that added the correct dependencies here. Now we; do have runtime_cxxmodules, and we can actually properly add a; dependency here.; Without this patch a deleted C++ module file actually will never be regenerated.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1038
https://github.com/root-project/root/pull/1038:203,Integrability,depend,dependency,203,"Previously the modules were only a environment variable, so we never; had any CMake code that added the correct dependencies here. Now we; do have runtime_cxxmodules, and we can actually properly add a; dependency here.; Without this patch a deleted C++ module file actually will never be regenerated.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1038
https://github.com/root-project/root/pull/1038:47,Modifiability,variab,variable,47,"Previously the modules were only a environment variable, so we never; had any CMake code that added the correct dependencies here. Now we; do have runtime_cxxmodules, and we can actually properly add a; dependency here.; Without this patch a deleted C++ module file actually will never be regenerated.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1038
https://github.com/root-project/root/pull/1039:56,Deployability,Release,Release,56,"For LLVM we don't have Optimized build, but only Debug, Release, RelWithDebInfo, and MinSizeRel.; Thats why to have correctly interpreted __FAST_MATH__ in ROOT macroses we need to add -ffast-math flag for LLVM default Release build type.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1039
https://github.com/root-project/root/pull/1039:218,Deployability,Release,Release,218,"For LLVM we don't have Optimized build, but only Debug, Release, RelWithDebInfo, and MinSizeRel.; Thats why to have correctly interpreted __FAST_MATH__ in ROOT macroses we need to add -ffast-math flag for LLVM default Release build type.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1039
https://github.com/root-project/root/pull/1039:23,Performance,Optimiz,Optimized,23,"For LLVM we don't have Optimized build, but only Debug, Release, RelWithDebInfo, and MinSizeRel.; Thats why to have correctly interpreted __FAST_MATH__ in ROOT macroses we need to add -ffast-math flag for LLVM default Release build type.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1039
https://github.com/root-project/root/pull/1044:529,Testability,test,tests,529,"@lmoneta as discussed yesterday this is just the dump of our tanh approximation. I leave it up to you to decide how to do vectorisation. As seen between the ifndef statements, the vector unit is already used for a single evaluation of tanh (it is implemented as a fraction and numerator and denominator are calculated in parallel in the vector unit). I recon if one needs to do multiple tanh evaluations at the same time, one might want to swap between horizontal and vertical vectorisation. In the original, the if( x is large) tests were kept in UNLIKELY statements, I didn't follow up if this was because typical inputs in our use case are known, or because tanh is generally evaluated for small inputs …",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1044
https://github.com/root-project/root/pull/1046:110,Deployability,update,updates,110,"`Count` should return the same type that we use to enumerate entries, by definition. A related PR in roottest updates `test_misc` to comply with the interface change.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1046
https://github.com/root-project/root/pull/1046:149,Integrability,interface,interface,149,"`Count` should return the same type that we use to enumerate entries, by definition. A related PR in roottest updates `test_misc` to comply with the interface change.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1046
https://github.com/root-project/root/pull/1047:41,Deployability,upgrade,upgrade,41,This is in prepare for the upcoming llvm upgrade. The future orc jit compile; layer needs a std::shared_ptr<llvm::Module>. The current design passes a; llvm::Module* around and any conversions to a shared_ptr cause the; destruction of the llvm::Module which is a long-lived object in cling.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1047
https://github.com/root-project/root/pull/1048:102,Safety,detect,detection,102,"Highlights:; - Aliases to columns can be defined; - Aliases to column aliases can be defined; - Early detection of mistakes: non-existing column names, incoherent aliasing; - Support of aliased columns in actions and transformations, also jitted",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1048
https://github.com/root-project/root/pull/1049:24,Testability,assert,assert,24,"So, we just removed the assert that makes us aware that we need to; rethink this flag. I don't see a clear solution at the moment, but; this PR at least makes us aware that we need to solve this issue. For now I just removed it and we see what exactly Jenkins complains; about when it runs the tests.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1049
https://github.com/root-project/root/pull/1049:294,Testability,test,tests,294,"So, we just removed the assert that makes us aware that we need to; rethink this flag. I don't see a clear solution at the moment, but; this PR at least makes us aware that we need to solve this issue. For now I just removed it and we see what exactly Jenkins complains; about when it runs the tests.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1049
https://github.com/root-project/root/pull/1049:101,Usability,clear,clear,101,"So, we just removed the assert that makes us aware that we need to; rethink this flag. I don't see a clear solution at the moment, but; this PR at least makes us aware that we need to solve this issue. For now I just removed it and we see what exactly Jenkins complains; about when it runs the tests.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1049
https://github.com/root-project/root/pull/1050:286,Deployability,patch,patch,286,"This teaches again the IncrementalExecutor to emit only one module at a time. In the old MCJIT days, the API worked with module sets and cling assumed llvm's jit infrastructure is moving in this direction. LLVM 5.0 moves away from this concept and works with single llvm::Modules. This patch will make the upgrade to LLVM 5.0 smoother.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1050
https://github.com/root-project/root/pull/1050:306,Deployability,upgrade,upgrade,306,"This teaches again the IncrementalExecutor to emit only one module at a time. In the old MCJIT days, the API worked with module sets and cling assumed llvm's jit infrastructure is moving in this direction. LLVM 5.0 moves away from this concept and works with single llvm::Modules. This patch will make the upgrade to LLVM 5.0 smoother.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1050
https://github.com/root-project/root/pull/1051:43,Performance,Optimiz,Optimized,43,Adding -ffast-math flag to really activate Optimized builds for interpreter,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1051
https://github.com/root-project/root/pull/1052:296,Performance,queue,queue,296,"This introduces a `SetAutoSave()` function to `TBufferMerger` that lets users choose how often data is merged into the output file. This avoid excessive writing of TTree headers, which are compressed and causes the output thread to do too much work if merges happen at every buffer read from the queue.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1052
https://github.com/root-project/root/pull/1052:137,Safety,avoid,avoid,137,"This introduces a `SetAutoSave()` function to `TBufferMerger` that lets users choose how often data is merged into the output file. This avoid excessive writing of TTree headers, which are compressed and causes the output thread to do too much work if merges happen at every buffer read from the queue.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1052
https://github.com/root-project/root/pull/1053:11,Deployability,update,update,11,This is an update of https://github.com/root-project/root/pull/134 to work compile on MacOS and rename TSigHandling into TSignalManager. This is a work in progress as the new TSignalManager no longer calls TSystem::StackTrace but is also only implementing support for unix systems. @zzxuanyuan Could you update the code to support at least MacOS (and attempt to support Windows)?,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1053
https://github.com/root-project/root/pull/1053:304,Deployability,update,update,304,This is an update of https://github.com/root-project/root/pull/134 to work compile on MacOS and rename TSigHandling into TSignalManager. This is a work in progress as the new TSignalManager no longer calls TSystem::StackTrace but is also only implementing support for unix systems. @zzxuanyuan Could you update the code to support at least MacOS (and attempt to support Windows)?,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1053
https://github.com/root-project/root/pull/1054:130,Availability,error,error,130,"It should happen before we use the module the first time and not; afterwards, otherwise we just crash instead of printing a nice; error.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1054
https://github.com/root-project/root/pull/1056:58,Testability,test,testing,58,"First implementation of the caching mechanism and minimal testing. ; This is here to start the testing in the CI, the development is not finished yet.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1056
https://github.com/root-project/root/pull/1056:95,Testability,test,testing,95,"First implementation of the caching mechanism and minimal testing. ; This is here to start the testing in the CI, the development is not finished yet.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1056
https://github.com/root-project/root/pull/1058:280,Testability,test,tests,280,"The figure below gives an idea of possible improvement. For more information see [ROOT-8872](https://sft.its.cern.ch/jira/browse/ROOT-8872). ![ttree-fill-ge-timediff](https://user-images.githubusercontent.com/249404/30871641-cd327d8c-a2e7-11e7-8839-4c770ea32173.png). A couple of tests don't work after this change, so I will later break this up into several commits to make it easier to test and review.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1058
https://github.com/root-project/root/pull/1058:388,Testability,test,test,388,"The figure below gives an idea of possible improvement. For more information see [ROOT-8872](https://sft.its.cern.ch/jira/browse/ROOT-8872). ![ttree-fill-ge-timediff](https://user-images.githubusercontent.com/249404/30871641-cd327d8c-a2e7-11e7-8839-4c770ea32173.png). A couple of tests don't work after this change, so I will later break this up into several commits to make it easier to test and review.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1058
https://github.com/root-project/root/pull/1059:0,Modifiability,Extend,Extending,0,Extending FindLZ4.cmake with xxhash includes/library needed for LZ4 checksum functionality,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1059
https://github.com/root-project/root/pull/1059:68,Security,checksum,checksum,68,Extending FindLZ4.cmake with xxhash includes/library needed for LZ4 checksum functionality,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1059
https://github.com/root-project/root/pull/1061:178,Deployability,patch,patch,178,"Sometime happens that `zoombox == 0` and ROOT crashes.; It happens in our QtROOT interface, where event sequence could be slightly different as with normal X.; Would be nice, if patch also will go into 6.10 branch",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1061
https://github.com/root-project/root/pull/1061:81,Integrability,interface,interface,81,"Sometime happens that `zoombox == 0` and ROOT crashes.; It happens in our QtROOT interface, where event sequence could be slightly different as with normal X.; Would be nice, if patch also will go into 6.10 branch",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1061
https://github.com/root-project/root/pull/1062:5,Deployability,patch,patch,5,"This patch adds a few IO benchmarks. Some of them were hosted by @amadio in an external repository. The nature of some of the benchmarks is to create multiple times files on disk. Running repeatedly, this can wear out machines disk drives. For that reason we extend the `TFileMerger` to work with `TFile*` directly. Passing an externally created `TFile*` allows us to pass a `TMemFile`. Being able to benchmark based on in-memory files gives us another advantage: we can emulate very fast drives or certain delay patterns.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1062
https://github.com/root-project/root/pull/1062:259,Modifiability,extend,extend,259,"This patch adds a few IO benchmarks. Some of them were hosted by @amadio in an external repository. The nature of some of the benchmarks is to create multiple times files on disk. Running repeatedly, this can wear out machines disk drives. For that reason we extend the `TFileMerger` to work with `TFile*` directly. Passing an externally created `TFile*` allows us to pass a `TMemFile`. Being able to benchmark based on in-memory files gives us another advantage: we can emulate very fast drives or certain delay patterns.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1062
https://github.com/root-project/root/pull/1062:25,Testability,benchmark,benchmarks,25,"This patch adds a few IO benchmarks. Some of them were hosted by @amadio in an external repository. The nature of some of the benchmarks is to create multiple times files on disk. Running repeatedly, this can wear out machines disk drives. For that reason we extend the `TFileMerger` to work with `TFile*` directly. Passing an externally created `TFile*` allows us to pass a `TMemFile`. Being able to benchmark based on in-memory files gives us another advantage: we can emulate very fast drives or certain delay patterns.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1062
https://github.com/root-project/root/pull/1062:126,Testability,benchmark,benchmarks,126,"This patch adds a few IO benchmarks. Some of them were hosted by @amadio in an external repository. The nature of some of the benchmarks is to create multiple times files on disk. Running repeatedly, this can wear out machines disk drives. For that reason we extend the `TFileMerger` to work with `TFile*` directly. Passing an externally created `TFile*` allows us to pass a `TMemFile`. Being able to benchmark based on in-memory files gives us another advantage: we can emulate very fast drives or certain delay patterns.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1062
https://github.com/root-project/root/pull/1062:401,Testability,benchmark,benchmark,401,"This patch adds a few IO benchmarks. Some of them were hosted by @amadio in an external repository. The nature of some of the benchmarks is to create multiple times files on disk. Running repeatedly, this can wear out machines disk drives. For that reason we extend the `TFileMerger` to work with `TFile*` directly. Passing an externally created `TFile*` allows us to pass a `TMemFile`. Being able to benchmark based on in-memory files gives us another advantage: we can emulate very fast drives or certain delay patterns.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1062
https://github.com/root-project/root/pull/1065:1174,Energy Efficiency,efficient,efficient,1174,"After messing up my git repository, I closed pull request 796 and re-created this one with the same changes. This pull request is the result of work done by David Clark as a summer intern at Argonne:; To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence.; By setting TTree::SetClusterPrefetch(), an entire clusters will be loaded into memory, rather than single baskets.; By setting the MaxVirtualSize of the tree to a negative value, previous clusters will be retained - the absolute value of MaxVirtualSize indicates how many additional clusters will be kept in memory. If TTree CacheDoClusterPrefetch is set to true, GetEntry() will load the entire cluster into memory, not just the first basket. For this, GetBasket() is modified to call a new function GetFreshCluster(). This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, GetFreshCluster() reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry.; Without the change enables there were 1.5 GB read in 31102 read calls.; With MaxVirtualSize set to -1 and CacheDoClusterPrefetch true, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1065
https://github.com/root-project/root/pull/1065:216,Performance,multi-thread,multi-threaded,216,"After messing up my git repository, I closed pull request 796 and re-created this one with the same changes. This pull request is the result of work done by David Clark as a summer intern at Argonne:; To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence.; By setting TTree::SetClusterPrefetch(), an entire clusters will be loaded into memory, rather than single baskets.; By setting the MaxVirtualSize of the tree to a negative value, previous clusters will be retained - the absolute value of MaxVirtualSize indicates how many additional clusters will be kept in memory. If TTree CacheDoClusterPrefetch is set to true, GetEntry() will load the entire cluster into memory, not just the first basket. For this, GetBasket() is modified to call a new function GetFreshCluster(). This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, GetFreshCluster() reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry.; Without the change enables there were 1.5 GB read in 31102 read calls.; With MaxVirtualSize set to -1 and CacheDoClusterPrefetch true, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1065
https://github.com/root-project/root/pull/1065:463,Performance,load,loaded,463,"After messing up my git repository, I closed pull request 796 and re-created this one with the same changes. This pull request is the result of work done by David Clark as a summer intern at Argonne:; To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence.; By setting TTree::SetClusterPrefetch(), an entire clusters will be loaded into memory, rather than single baskets.; By setting the MaxVirtualSize of the tree to a negative value, previous clusters will be retained - the absolute value of MaxVirtualSize indicates how many additional clusters will be kept in memory. If TTree CacheDoClusterPrefetch is set to true, GetEntry() will load the entire cluster into memory, not just the first basket. For this, GetBasket() is modified to call a new function GetFreshCluster(). This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, GetFreshCluster() reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry.; Without the change enables there were 1.5 GB read in 31102 read calls.; With MaxVirtualSize set to -1 and CacheDoClusterPrefetch true, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1065
https://github.com/root-project/root/pull/1065:721,Performance,Cache,CacheDoClusterPrefetch,721,"After messing up my git repository, I closed pull request 796 and re-created this one with the same changes. This pull request is the result of work done by David Clark as a summer intern at Argonne:; To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence.; By setting TTree::SetClusterPrefetch(), an entire clusters will be loaded into memory, rather than single baskets.; By setting the MaxVirtualSize of the tree to a negative value, previous clusters will be retained - the absolute value of MaxVirtualSize indicates how many additional clusters will be kept in memory. If TTree CacheDoClusterPrefetch is set to true, GetEntry() will load the entire cluster into memory, not just the first basket. For this, GetBasket() is modified to call a new function GetFreshCluster(). This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, GetFreshCluster() reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry.; Without the change enables there were 1.5 GB read in 31102 read calls.; With MaxVirtualSize set to -1 and CacheDoClusterPrefetch true, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1065
https://github.com/root-project/root/pull/1065:776,Performance,load,load,776,"After messing up my git repository, I closed pull request 796 and re-created this one with the same changes. This pull request is the result of work done by David Clark as a summer intern at Argonne:; To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence.; By setting TTree::SetClusterPrefetch(), an entire clusters will be loaded into memory, rather than single baskets.; By setting the MaxVirtualSize of the tree to a negative value, previous clusters will be retained - the absolute value of MaxVirtualSize indicates how many additional clusters will be kept in memory. If TTree CacheDoClusterPrefetch is set to true, GetEntry() will load the entire cluster into memory, not just the first basket. For this, GetBasket() is modified to call a new function GetFreshCluster(). This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, GetFreshCluster() reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry.; Without the change enables there were 1.5 GB read in 31102 read calls.; With MaxVirtualSize set to -1 and CacheDoClusterPrefetch true, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1065
https://github.com/root-project/root/pull/1065:1355,Performance,perform,performance,1355,"After messing up my git repository, I closed pull request 796 and re-created this one with the same changes. This pull request is the result of work done by David Clark as a summer intern at Argonne:; To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence.; By setting TTree::SetClusterPrefetch(), an entire clusters will be loaded into memory, rather than single baskets.; By setting the MaxVirtualSize of the tree to a negative value, previous clusters will be retained - the absolute value of MaxVirtualSize indicates how many additional clusters will be kept in memory. If TTree CacheDoClusterPrefetch is set to true, GetEntry() will load the entire cluster into memory, not just the first basket. For this, GetBasket() is modified to call a new function GetFreshCluster(). This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, GetFreshCluster() reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry.; Without the change enables there were 1.5 GB read in 31102 read calls.; With MaxVirtualSize set to -1 and CacheDoClusterPrefetch true, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1065
https://github.com/root-project/root/pull/1065:1717,Performance,Cache,CacheDoClusterPrefetch,1717,"After messing up my git repository, I closed pull request 796 and re-created this one with the same changes. This pull request is the result of work done by David Clark as a summer intern at Argonne:; To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence.; By setting TTree::SetClusterPrefetch(), an entire clusters will be loaded into memory, rather than single baskets.; By setting the MaxVirtualSize of the tree to a negative value, previous clusters will be retained - the absolute value of MaxVirtualSize indicates how many additional clusters will be kept in memory. If TTree CacheDoClusterPrefetch is set to true, GetEntry() will load the entire cluster into memory, not just the first basket. For this, GetBasket() is modified to call a new function GetFreshCluster(). This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, GetFreshCluster() reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry.; Without the change enables there were 1.5 GB read in 31102 read calls.; With MaxVirtualSize set to -1 and CacheDoClusterPrefetch true, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1065
https://github.com/root-project/root/pull/1065:1346,Testability,test,test,1346,"After messing up my git repository, I closed pull request 796 and re-created this one with the same changes. This pull request is the result of work done by David Clark as a summer intern at Argonne:; To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence.; By setting TTree::SetClusterPrefetch(), an entire clusters will be loaded into memory, rather than single baskets.; By setting the MaxVirtualSize of the tree to a negative value, previous clusters will be retained - the absolute value of MaxVirtualSize indicates how many additional clusters will be kept in memory. If TTree CacheDoClusterPrefetch is set to true, GetEntry() will load the entire cluster into memory, not just the first basket. For this, GetBasket() is modified to call a new function GetFreshCluster(). This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, GetFreshCluster() reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry.; Without the change enables there were 1.5 GB read in 31102 read calls.; With MaxVirtualSize set to -1 and CacheDoClusterPrefetch true, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1065
https://github.com/root-project/root/pull/1065:976,Usability,clear,clearing,976,"After messing up my git repository, I closed pull request 796 and re-created this one with the same changes. This pull request is the result of work done by David Clark as a summer intern at Argonne:; To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence.; By setting TTree::SetClusterPrefetch(), an entire clusters will be loaded into memory, rather than single baskets.; By setting the MaxVirtualSize of the tree to a negative value, previous clusters will be retained - the absolute value of MaxVirtualSize indicates how many additional clusters will be kept in memory. If TTree CacheDoClusterPrefetch is set to true, GetEntry() will load the entire cluster into memory, not just the first basket. For this, GetBasket() is modified to call a new function GetFreshCluster(). This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, GetFreshCluster() reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry.; Without the change enables there were 1.5 GB read in 31102 read calls.; With MaxVirtualSize set to -1 and CacheDoClusterPrefetch true, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1065
https://github.com/root-project/root/pull/1065:1111,Usability,clear,clear,1111,"After messing up my git repository, I closed pull request 796 and re-created this one with the same changes. This pull request is the result of work done by David Clark as a summer intern at Argonne:; To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence.; By setting TTree::SetClusterPrefetch(), an entire clusters will be loaded into memory, rather than single baskets.; By setting the MaxVirtualSize of the tree to a negative value, previous clusters will be retained - the absolute value of MaxVirtualSize indicates how many additional clusters will be kept in memory. If TTree CacheDoClusterPrefetch is set to true, GetEntry() will load the entire cluster into memory, not just the first basket. For this, GetBasket() is modified to call a new function GetFreshCluster(). This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, GetFreshCluster() reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry.; Without the change enables there were 1.5 GB read in 31102 read calls.; With MaxVirtualSize set to -1 and CacheDoClusterPrefetch true, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1065
https://github.com/root-project/root/pull/1066:11,Deployability,patch,patch,11,Apply same patch for 6.10 branch,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1066
https://github.com/root-project/root/pull/1067:66,Modifiability,config,configure,66,"New version of mysql_config returns more than one -I option, make configure and cmake pick the right one. New version:; $ mysql_config --cflags; -I/usr/include -I/usr/include/mysql. Old version:; $ mysql_config --cflags; -I/usr/include/mysql",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1067
https://github.com/root-project/root/pull/1068:42,Modifiability,refactor,refactorization,42,"Add speedup printing, improve legibility, refactorization. Speedup printing can still be improved.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1068
https://github.com/root-project/root/pull/1073:5,Deployability,patch,patch,5,This patch allows TFileMerger to work with externally created TFile-s. Being; able to control the creation of the TFile objects give us a chance to use; in-memory files. This is very helpful in benchmarking when we want to simulate; fast disks or we just want to avoid disk wearout.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1073
https://github.com/root-project/root/pull/1073:263,Safety,avoid,avoid,263,This patch allows TFileMerger to work with externally created TFile-s. Being; able to control the creation of the TFile objects give us a chance to use; in-memory files. This is very helpful in benchmarking when we want to simulate; fast disks or we just want to avoid disk wearout.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1073
https://github.com/root-project/root/pull/1073:194,Testability,benchmark,benchmarking,194,This patch allows TFileMerger to work with externally created TFile-s. Being; able to control the creation of the TFile objects give us a chance to use; in-memory files. This is very helpful in benchmarking when we want to simulate; fast disks or we just want to avoid disk wearout.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1073
https://github.com/root-project/root/pull/1075:0,Deployability,Patch,Patch,0,Patch currently applied to the SHiP software stack. It would be nice if this could be merged upstream after review.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1075
https://github.com/root-project/root/pull/1078:125,Availability,error,error,125,1) Match only the custom columns of the node and not all when using regexpressions; 2) Prompt an understandable compile time error in case a cache of columns the type of which is non copyable is requested; 3) Test the ability of the data source to serve non copyable items,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1078
https://github.com/root-project/root/pull/1078:141,Performance,cache,cache,141,1) Match only the custom columns of the node and not all when using regexpressions; 2) Prompt an understandable compile time error in case a cache of columns the type of which is non copyable is requested; 3) Test the ability of the data source to serve non copyable items,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1078
https://github.com/root-project/root/pull/1078:209,Testability,Test,Test,209,1) Match only the custom columns of the node and not all when using regexpressions; 2) Prompt an understandable compile time error in case a cache of columns the type of which is non copyable is requested; 3) Test the ability of the data source to serve non copyable items,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1078
https://github.com/root-project/root/pull/1080:24,Testability,test,test,24,Asked the originator to test. See https://sft.its.cern.ch/jira/browse/ROOT-9032,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1080
https://github.com/root-project/root/pull/1082:56,Deployability,update,updated,56,"Better English, better Markdown formatting, less typos, updated references.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1082
https://github.com/root-project/root/pull/1085:122,Modifiability,variab,variables,122,This reverts commit 4e7e379f8e8afb8fed9ab602c606bfab00577d8c.; We need to create one TTree per slot per task as the input variables; (and their addresses) change each time.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1085
https://github.com/root-project/root/pull/1086:6,Testability,test,testing,6,Moved testing of `Snapshot` to its own gtest.; Added a test with many tasks per worker thread. This test is expected to fail until #1085 is merged.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1086
https://github.com/root-project/root/pull/1086:55,Testability,test,test,55,Moved testing of `Snapshot` to its own gtest.; Added a test with many tasks per worker thread. This test is expected to fail until #1085 is merged.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1086
https://github.com/root-project/root/pull/1086:100,Testability,test,test,100,Moved testing of `Snapshot` to its own gtest.; Added a test with many tasks per worker thread. This test is expected to fail until #1085 is merged.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1086
https://github.com/root-project/root/pull/1089:78,Availability,error,errors,78,- enclose min() and max() in parentheses to prevent the following compilation errors (min and max are defined as macros in Visual Studio):; error C2589: '(' : illegal token on right side of '::'; error C2059: syntax error : '::'; - implement the basic_string_view operator == (for const char *) (was somehow not resolved by Visual Studio). Thanks Axel for fixing it,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1089
https://github.com/root-project/root/pull/1089:140,Availability,error,error,140,- enclose min() and max() in parentheses to prevent the following compilation errors (min and max are defined as macros in Visual Studio):; error C2589: '(' : illegal token on right side of '::'; error C2059: syntax error : '::'; - implement the basic_string_view operator == (for const char *) (was somehow not resolved by Visual Studio). Thanks Axel for fixing it,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1089
https://github.com/root-project/root/pull/1089:196,Availability,error,error,196,- enclose min() and max() in parentheses to prevent the following compilation errors (min and max are defined as macros in Visual Studio):; error C2589: '(' : illegal token on right side of '::'; error C2059: syntax error : '::'; - implement the basic_string_view operator == (for const char *) (was somehow not resolved by Visual Studio). Thanks Axel for fixing it,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1089
https://github.com/root-project/root/pull/1089:216,Availability,error,error,216,- enclose min() and max() in parentheses to prevent the following compilation errors (min and max are defined as macros in Visual Studio):; error C2589: '(' : illegal token on right side of '::'; error C2059: syntax error : '::'; - implement the basic_string_view operator == (for const char *) (was somehow not resolved by Visual Studio). Thanks Axel for fixing it,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1089
https://github.com/root-project/root/pull/1091:511,Deployability,patch,patch,511,"Right now we only generate modulemaps for the ROOT libraries which; are exposed to the user. But we also have generate dictionary; calls for dictionaries that are not exposed to the user and should; only be private (such as TBench, TMathCoreUnitDict etc.). Right now we fail when compiling root on those dictionaries as we; don't have a modulemap for those dictionaries and we don't generate; one. This will also break tests that use the generate dictionary; call as those also don't have a modulemap now. This patch reuses the existing CMake code for generating modulemaps; and also uses it in those cases to provide a dictionary that; rootcling can use to generate a C++ module.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1091
https://github.com/root-project/root/pull/1091:72,Security,expose,exposed,72,"Right now we only generate modulemaps for the ROOT libraries which; are exposed to the user. But we also have generate dictionary; calls for dictionaries that are not exposed to the user and should; only be private (such as TBench, TMathCoreUnitDict etc.). Right now we fail when compiling root on those dictionaries as we; don't have a modulemap for those dictionaries and we don't generate; one. This will also break tests that use the generate dictionary; call as those also don't have a modulemap now. This patch reuses the existing CMake code for generating modulemaps; and also uses it in those cases to provide a dictionary that; rootcling can use to generate a C++ module.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1091
https://github.com/root-project/root/pull/1091:167,Security,expose,exposed,167,"Right now we only generate modulemaps for the ROOT libraries which; are exposed to the user. But we also have generate dictionary; calls for dictionaries that are not exposed to the user and should; only be private (such as TBench, TMathCoreUnitDict etc.). Right now we fail when compiling root on those dictionaries as we; don't have a modulemap for those dictionaries and we don't generate; one. This will also break tests that use the generate dictionary; call as those also don't have a modulemap now. This patch reuses the existing CMake code for generating modulemaps; and also uses it in those cases to provide a dictionary that; rootcling can use to generate a C++ module.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1091
https://github.com/root-project/root/pull/1091:419,Testability,test,tests,419,"Right now we only generate modulemaps for the ROOT libraries which; are exposed to the user. But we also have generate dictionary; calls for dictionaries that are not exposed to the user and should; only be private (such as TBench, TMathCoreUnitDict etc.). Right now we fail when compiling root on those dictionaries as we; don't have a modulemap for those dictionaries and we don't generate; one. This will also break tests that use the generate dictionary; call as those also don't have a modulemap now. This patch reuses the existing CMake code for generating modulemaps; and also uses it in those cases to provide a dictionary that; rootcling can use to generate a C++ module.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1091
https://github.com/root-project/root/pull/1092:6,Availability,error,error,6,"- Fix error C2057: expected constant expression in several array declarations; - Outline (move from header to source) the IsCandleScaled() and IsViolinScaled() to export them from DLL; - In fontembedps.cxx, replace unsupported memmem() function by std::search()",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1092
https://github.com/root-project/root/pull/1096:11,Testability,test,tests,11,...and add tests,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1096
https://github.com/root-project/root/pull/1098:20,Performance,load,load,20,Use the std::atomic load() method to access its content,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1098
https://github.com/root-project/root/pull/1098:37,Security,access,access,37,Use the std::atomic load() method to access its content,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1098
https://github.com/root-project/root/pull/1099:102,Availability,error,error,102,- Use TMath::Pi() instead of M_PI (undefined on Windows); - Replace 'uint' with 'unsigned int'; - Fix error C2057: expected constant expression with newX and newY arrays,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1099
https://github.com/root-project/root/pull/1101:93,Testability,test,tests,93,`EnableImplicitMT` and friends print warnings or do not exist in `noimt` builds. Disable IMT tests in this case. @amadio what is the correct syntax to start a noimt PR build? :),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1101
https://github.com/root-project/root/pull/1102:87,Availability,avail,available,87,"This PR makes the vectorised version of the mathematical functions provided by VecCore available to ROOT vey instantiating them in ROOT Mathcore. ; The symbols will be available automatically at the ROOT prompt and by bringing in the Vc symbols, functions like std::sin or std::cos with vector types (std::sin(ROOT::Double_v) will be available",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1102
https://github.com/root-project/root/pull/1102:168,Availability,avail,available,168,"This PR makes the vectorised version of the mathematical functions provided by VecCore available to ROOT vey instantiating them in ROOT Mathcore. ; The symbols will be available automatically at the ROOT prompt and by bringing in the Vc symbols, functions like std::sin or std::cos with vector types (std::sin(ROOT::Double_v) will be available",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1102
https://github.com/root-project/root/pull/1102:334,Availability,avail,available,334,"This PR makes the vectorised version of the mathematical functions provided by VecCore available to ROOT vey instantiating them in ROOT Mathcore. ; The symbols will be available automatically at the ROOT prompt and by bringing in the Vc symbols, functions like std::sin or std::cos with vector types (std::sin(ROOT::Double_v) will be available",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1102
https://github.com/root-project/root/pull/1103:61,Availability,robust,robust,61,"Still need to change the `find(""return "")` to something more robust, but this allows defines to be a bit more complex. For filters, we need to do a bit more work (i.e., ensure we get something convertible to boolean).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1103
https://github.com/root-project/root/pull/1104:24,Energy Efficiency,reduce,reduce,24,"This is a simple fix to reduce imbalance in multi-thread event-loops; with no data-source: previously we spawned one task per worker thread. Expected to break `test_emptysource`, which is fixed by [PR 96](https://github.com/root-project/roottest/pull/96) in roottest.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1104
https://github.com/root-project/root/pull/1104:44,Performance,multi-thread,multi-thread,44,"This is a simple fix to reduce imbalance in multi-thread event-loops; with no data-source: previously we spawned one task per worker thread. Expected to break `test_emptysource`, which is fixed by [PR 96](https://github.com/root-project/roottest/pull/96) in roottest.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1104
https://github.com/root-project/root/pull/1104:10,Usability,simpl,simple,10,"This is a simple fix to reduce imbalance in multi-thread event-loops; with no data-source: previously we spawned one task per worker thread. Expected to break `test_emptysource`, which is fixed by [PR 96](https://github.com/root-project/roottest/pull/96) in roottest.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1104
https://github.com/root-project/root/pull/1114:78,Availability,error,errors,78,"- remove ""future"" from the list of STL includes on Windows (it generates many errors); - replace backslashes by forward slashes in paths",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1114
https://github.com/root-project/root/pull/1121:0,Safety,Avoid,Avoid,0,Avoid to deal with unique_ptrs created by the compiler in jitted code.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1121
https://github.com/root-project/root/pull/1122:6,Integrability,depend,dependencied,6,- add dependencied on Core and IO (needed to resolve the symbols at link time on Windows); - add a few symbols to be exported; - use the ANSI version of system functions; - convert the backslashs to forward slashs in the rootmap file path,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1122
https://github.com/root-project/root/pull/1131:179,Performance,cache,cache,179,"This work on the C++ tutorial really shows that we need a fake column with the entry number. If we agree, this would be easy to achieve thanks to the recent developments done for cache :)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1131
https://github.com/root-project/root/pull/1132:404,Availability,error,error,404,- Force using Visual Studio 2017 or higher; - Undefine unsupported __attribute__ keyword; - Move the TObject constructors from the header to the source (prevent a couple of static members to be externally unresolved); - Use the AreAllSignalsBlocked() method instead of the static fgAllSignalsBlocked (prevent it to be externally unresolved); - Comment out inline TString operator==() to fix the compiler error C2593: 'operator ==' is ambiguous (!!!); - Implement a working dlsym function; - Remove some obsolete code,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1132
https://github.com/root-project/root/pull/1134:204,Availability,recover,recoverable,204,1) Do not put the non-copiable ds in a header. It's very cumbersome; at runtime to expose it to the interpreter. The code is now in a string. 2) Make the test a death test. The static assert causes a non-recoverable; failure which should be handled by this kind of test and not with a try/catch; block.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1134
https://github.com/root-project/root/pull/1134:217,Availability,failure,failure,217,1) Do not put the non-copiable ds in a header. It's very cumbersome; at runtime to expose it to the interpreter. The code is now in a string. 2) Make the test a death test. The static assert causes a non-recoverable; failure which should be handled by this kind of test and not with a try/catch; block.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1134
https://github.com/root-project/root/pull/1134:204,Safety,recover,recoverable,204,1) Do not put the non-copiable ds in a header. It's very cumbersome; at runtime to expose it to the interpreter. The code is now in a string. 2) Make the test a death test. The static assert causes a non-recoverable; failure which should be handled by this kind of test and not with a try/catch; block.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1134
https://github.com/root-project/root/pull/1134:83,Security,expose,expose,83,1) Do not put the non-copiable ds in a header. It's very cumbersome; at runtime to expose it to the interpreter. The code is now in a string. 2) Make the test a death test. The static assert causes a non-recoverable; failure which should be handled by this kind of test and not with a try/catch; block.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1134
https://github.com/root-project/root/pull/1134:154,Testability,test,test,154,1) Do not put the non-copiable ds in a header. It's very cumbersome; at runtime to expose it to the interpreter. The code is now in a string. 2) Make the test a death test. The static assert causes a non-recoverable; failure which should be handled by this kind of test and not with a try/catch; block.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1134
https://github.com/root-project/root/pull/1134:167,Testability,test,test,167,1) Do not put the non-copiable ds in a header. It's very cumbersome; at runtime to expose it to the interpreter. The code is now in a string. 2) Make the test a death test. The static assert causes a non-recoverable; failure which should be handled by this kind of test and not with a try/catch; block.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1134
https://github.com/root-project/root/pull/1134:184,Testability,assert,assert,184,1) Do not put the non-copiable ds in a header. It's very cumbersome; at runtime to expose it to the interpreter. The code is now in a string. 2) Make the test a death test. The static assert causes a non-recoverable; failure which should be handled by this kind of test and not with a try/catch; block.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1134
https://github.com/root-project/root/pull/1134:265,Testability,test,test,265,1) Do not put the non-copiable ds in a header. It's very cumbersome; at runtime to expose it to the interpreter. The code is now in a string. 2) Make the test a death test. The static assert causes a non-recoverable; failure which should be handled by this kind of test and not with a try/catch; block.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1134
https://github.com/root-project/root/pull/1140:216,Modifiability,variab,variable,216,"The Visual Studio 2017 path is very different than the previous versions, and even the registry entries are completely different, so for now let's try the trivial way first (using the %VCToolsInstallDir% environment variable); (to be reviewed)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1140
https://github.com/root-project/root/pull/1142:26,Deployability,integrat,integration,26,"I did the same ""style"" of integration as was done for roottest repository",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1142
https://github.com/root-project/root/pull/1142:26,Integrability,integrat,integration,26,"I did the same ""style"" of integration as was done for roottest repository",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1142
https://github.com/root-project/root/pull/1145:33,Modifiability,refactor,refactoring,33,Two more unit tests and a slight refactoring of the existing ones.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1145
https://github.com/root-project/root/pull/1145:14,Testability,test,tests,14,Two more unit tests and a slight refactoring of the existing ones.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1145
https://github.com/root-project/root/pull/1150:25,Availability,error,error,25,"This fixes the following error:; ```; error G34C21FBE: static_assert expression is not an integral constant expression; static_assert(offsetof(TEveVectorT, fZ) == offsetof(TEveVectorT, fX) + 2*sizeof(TT),; ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~; C:\Program Files (x86)\Windows Kits\10\Include\10.0.15063.0\ucrt\stddef.h:42:31: note: expanded from macro 'offsetof'; #define offsetof(s,m) ((size_t)&reinterpret_cast<char const volatile&>((((s*)0)->m))); ^; TEveProjections.h:174:71: note: in instantiation of member function 'TEveVectorT<float>::Arr' requested here; virtual Float_t* GetProjectedCenter() { return fProjectedCenter.Arr(); }; ^; TEveVector.h:55:21: note: cast that performs the conversions of a reinterpret_cast is not allowed in a constant expression; static_assert(offsetof(TEveVectorT, fZ) == offsetof(TEveVectorT, fX) + 2*sizeof(TT),; ^; C:\Program Files (x86)\Windows Kits\10\Include\10.0.15063.0\ucrt\stddef.h:42:32: note: expanded from macro 'offsetof'; #define offsetof(s,m) ((size_t)&reinterpret_cast<char const volatile&>((((s*)0)->m))); ^; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1150
https://github.com/root-project/root/pull/1150:38,Availability,error,error,38,"This fixes the following error:; ```; error G34C21FBE: static_assert expression is not an integral constant expression; static_assert(offsetof(TEveVectorT, fZ) == offsetof(TEveVectorT, fX) + 2*sizeof(TT),; ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~; C:\Program Files (x86)\Windows Kits\10\Include\10.0.15063.0\ucrt\stddef.h:42:31: note: expanded from macro 'offsetof'; #define offsetof(s,m) ((size_t)&reinterpret_cast<char const volatile&>((((s*)0)->m))); ^; TEveProjections.h:174:71: note: in instantiation of member function 'TEveVectorT<float>::Arr' requested here; virtual Float_t* GetProjectedCenter() { return fProjectedCenter.Arr(); }; ^; TEveVector.h:55:21: note: cast that performs the conversions of a reinterpret_cast is not allowed in a constant expression; static_assert(offsetof(TEveVectorT, fZ) == offsetof(TEveVectorT, fX) + 2*sizeof(TT),; ^; C:\Program Files (x86)\Windows Kits\10\Include\10.0.15063.0\ucrt\stddef.h:42:32: note: expanded from macro 'offsetof'; #define offsetof(s,m) ((size_t)&reinterpret_cast<char const volatile&>((((s*)0)->m))); ^; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1150
https://github.com/root-project/root/pull/1150:709,Performance,perform,performs,709,"This fixes the following error:; ```; error G34C21FBE: static_assert expression is not an integral constant expression; static_assert(offsetof(TEveVectorT, fZ) == offsetof(TEveVectorT, fX) + 2*sizeof(TT),; ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~; C:\Program Files (x86)\Windows Kits\10\Include\10.0.15063.0\ucrt\stddef.h:42:31: note: expanded from macro 'offsetof'; #define offsetof(s,m) ((size_t)&reinterpret_cast<char const volatile&>((((s*)0)->m))); ^; TEveProjections.h:174:71: note: in instantiation of member function 'TEveVectorT<float>::Arr' requested here; virtual Float_t* GetProjectedCenter() { return fProjectedCenter.Arr(); }; ^; TEveVector.h:55:21: note: cast that performs the conversions of a reinterpret_cast is not allowed in a constant expression; static_assert(offsetof(TEveVectorT, fZ) == offsetof(TEveVectorT, fX) + 2*sizeof(TT),; ^; C:\Program Files (x86)\Windows Kits\10\Include\10.0.15063.0\ucrt\stddef.h:42:32: note: expanded from macro 'offsetof'; #define offsetof(s,m) ((size_t)&reinterpret_cast<char const volatile&>((((s*)0)->m))); ^; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1150
https://github.com/root-project/root/pull/1151:25,Availability,error,errors,25,"This fixes the following errors:; ```; TRootDS.cxx(145): error C2668: 'std::make_unique': ambiguous call to overloaded function [TreePlayer.vcxproj]; C:\Users\bellenot\build\master-check\include\ROOT/RMakeUnique.hxx(26): note: could be 'std::unique_ptr<ROOT::Experimental::TDF::TRootDS,std::default_delete<_Ty>> std::make_unique<ROOT::Experimental::TDF::TRootDS,std::string_view&,std::string_view&>(std::string_view &,std::string_view &)'; with; [; _Ty=ROOT::Experimental::TDF::TRootDS; ]; C:\Program Files (x86)\Microsoft Visual Studio\2017\Community\VC\Tools\MSVC\14.11.25503\include\memory(2436): note:; or 'std::unique_ptr<ROOT::Experimental::TDF::TRootDS,std::default_delete<_Ty>> std::make_unique<ROOT::Experimental::TDF::TRootDS,std::string_view&,std::string_view&,void>(std::string_view &,std::string_view &)'; with; [; _Ty=ROOT::Experimental::TDF::TRootDS; ]; TRootDS.cxx(145): note: while trying to match the argument list '(std::string_view, std::string_view)'; TRootDS.cxx(145): error C2512: 'ROOT::Experimental::TDataFrame::TDataFrame': no appropriate default constructor available [TreePlayer.vcxproj]; TTrivialDS.cxx; TTrivialDS.cxx(82): error C2668: 'std::make_unique': ambiguous call to overloaded function [TreePlayer.vcxproj]; C:\Users\bellenot\build\master-check\include\ROOT/RMakeUnique.hxx(26): note: could be 'std::unique_ptr<ROOT::Experimental::TDF::TTrivialDS,std::default_delete<_Ty>> std::make_unique<ROOT::Experimental::TDF::TTrivialDS,ULong64_t&>(ULong64_t &)'; with; [; _Ty=ROOT::Experimental::TDF::TTrivialDS; ]; C:\Program Files (x86)\Microsoft Visual Studio\2017\Community\VC\Tools\MSVC\14.11.25503\include\memory(2436): note:; or 'std::unique_ptr<ROOT::Experimental::TDF::TTrivialDS,std::default_delete<_Ty>> std::make_unique<ROOT::Experimental::TDF::TTrivialDS,ULong64_t&,void>(ULong64_t &)'; with; [; _Ty=ROOT::Experimental::TDF::TTrivialDS; ]; TTrivialDS.cxx(82): note: while trying to match the argument list '(ULong64_t)'; TTrivialDS.cxx(82): error C2512: 'ROOT:",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1151
https://github.com/root-project/root/pull/1151:57,Availability,error,error,57,"This fixes the following errors:; ```; TRootDS.cxx(145): error C2668: 'std::make_unique': ambiguous call to overloaded function [TreePlayer.vcxproj]; C:\Users\bellenot\build\master-check\include\ROOT/RMakeUnique.hxx(26): note: could be 'std::unique_ptr<ROOT::Experimental::TDF::TRootDS,std::default_delete<_Ty>> std::make_unique<ROOT::Experimental::TDF::TRootDS,std::string_view&,std::string_view&>(std::string_view &,std::string_view &)'; with; [; _Ty=ROOT::Experimental::TDF::TRootDS; ]; C:\Program Files (x86)\Microsoft Visual Studio\2017\Community\VC\Tools\MSVC\14.11.25503\include\memory(2436): note:; or 'std::unique_ptr<ROOT::Experimental::TDF::TRootDS,std::default_delete<_Ty>> std::make_unique<ROOT::Experimental::TDF::TRootDS,std::string_view&,std::string_view&,void>(std::string_view &,std::string_view &)'; with; [; _Ty=ROOT::Experimental::TDF::TRootDS; ]; TRootDS.cxx(145): note: while trying to match the argument list '(std::string_view, std::string_view)'; TRootDS.cxx(145): error C2512: 'ROOT::Experimental::TDataFrame::TDataFrame': no appropriate default constructor available [TreePlayer.vcxproj]; TTrivialDS.cxx; TTrivialDS.cxx(82): error C2668: 'std::make_unique': ambiguous call to overloaded function [TreePlayer.vcxproj]; C:\Users\bellenot\build\master-check\include\ROOT/RMakeUnique.hxx(26): note: could be 'std::unique_ptr<ROOT::Experimental::TDF::TTrivialDS,std::default_delete<_Ty>> std::make_unique<ROOT::Experimental::TDF::TTrivialDS,ULong64_t&>(ULong64_t &)'; with; [; _Ty=ROOT::Experimental::TDF::TTrivialDS; ]; C:\Program Files (x86)\Microsoft Visual Studio\2017\Community\VC\Tools\MSVC\14.11.25503\include\memory(2436): note:; or 'std::unique_ptr<ROOT::Experimental::TDF::TTrivialDS,std::default_delete<_Ty>> std::make_unique<ROOT::Experimental::TDF::TTrivialDS,ULong64_t&,void>(ULong64_t &)'; with; [; _Ty=ROOT::Experimental::TDF::TTrivialDS; ]; TTrivialDS.cxx(82): note: while trying to match the argument list '(ULong64_t)'; TTrivialDS.cxx(82): error C2512: 'ROOT:",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1151
https://github.com/root-project/root/pull/1151:991,Availability,error,error,991,"DS.cxx(145): error C2668: 'std::make_unique': ambiguous call to overloaded function [TreePlayer.vcxproj]; C:\Users\bellenot\build\master-check\include\ROOT/RMakeUnique.hxx(26): note: could be 'std::unique_ptr<ROOT::Experimental::TDF::TRootDS,std::default_delete<_Ty>> std::make_unique<ROOT::Experimental::TDF::TRootDS,std::string_view&,std::string_view&>(std::string_view &,std::string_view &)'; with; [; _Ty=ROOT::Experimental::TDF::TRootDS; ]; C:\Program Files (x86)\Microsoft Visual Studio\2017\Community\VC\Tools\MSVC\14.11.25503\include\memory(2436): note:; or 'std::unique_ptr<ROOT::Experimental::TDF::TRootDS,std::default_delete<_Ty>> std::make_unique<ROOT::Experimental::TDF::TRootDS,std::string_view&,std::string_view&,void>(std::string_view &,std::string_view &)'; with; [; _Ty=ROOT::Experimental::TDF::TRootDS; ]; TRootDS.cxx(145): note: while trying to match the argument list '(std::string_view, std::string_view)'; TRootDS.cxx(145): error C2512: 'ROOT::Experimental::TDataFrame::TDataFrame': no appropriate default constructor available [TreePlayer.vcxproj]; TTrivialDS.cxx; TTrivialDS.cxx(82): error C2668: 'std::make_unique': ambiguous call to overloaded function [TreePlayer.vcxproj]; C:\Users\bellenot\build\master-check\include\ROOT/RMakeUnique.hxx(26): note: could be 'std::unique_ptr<ROOT::Experimental::TDF::TTrivialDS,std::default_delete<_Ty>> std::make_unique<ROOT::Experimental::TDF::TTrivialDS,ULong64_t&>(ULong64_t &)'; with; [; _Ty=ROOT::Experimental::TDF::TTrivialDS; ]; C:\Program Files (x86)\Microsoft Visual Studio\2017\Community\VC\Tools\MSVC\14.11.25503\include\memory(2436): note:; or 'std::unique_ptr<ROOT::Experimental::TDF::TTrivialDS,std::default_delete<_Ty>> std::make_unique<ROOT::Experimental::TDF::TTrivialDS,ULong64_t&,void>(ULong64_t &)'; with; [; _Ty=ROOT::Experimental::TDF::TTrivialDS; ]; TTrivialDS.cxx(82): note: while trying to match the argument list '(ULong64_t)'; TTrivialDS.cxx(82): error C2512: 'ROOT::Experimental::TDataFrame::TDataFrame': no ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1151
https://github.com/root-project/root/pull/1151:1085,Availability,avail,available,1085,"DS.cxx(145): error C2668: 'std::make_unique': ambiguous call to overloaded function [TreePlayer.vcxproj]; C:\Users\bellenot\build\master-check\include\ROOT/RMakeUnique.hxx(26): note: could be 'std::unique_ptr<ROOT::Experimental::TDF::TRootDS,std::default_delete<_Ty>> std::make_unique<ROOT::Experimental::TDF::TRootDS,std::string_view&,std::string_view&>(std::string_view &,std::string_view &)'; with; [; _Ty=ROOT::Experimental::TDF::TRootDS; ]; C:\Program Files (x86)\Microsoft Visual Studio\2017\Community\VC\Tools\MSVC\14.11.25503\include\memory(2436): note:; or 'std::unique_ptr<ROOT::Experimental::TDF::TRootDS,std::default_delete<_Ty>> std::make_unique<ROOT::Experimental::TDF::TRootDS,std::string_view&,std::string_view&,void>(std::string_view &,std::string_view &)'; with; [; _Ty=ROOT::Experimental::TDF::TRootDS; ]; TRootDS.cxx(145): note: while trying to match the argument list '(std::string_view, std::string_view)'; TRootDS.cxx(145): error C2512: 'ROOT::Experimental::TDataFrame::TDataFrame': no appropriate default constructor available [TreePlayer.vcxproj]; TTrivialDS.cxx; TTrivialDS.cxx(82): error C2668: 'std::make_unique': ambiguous call to overloaded function [TreePlayer.vcxproj]; C:\Users\bellenot\build\master-check\include\ROOT/RMakeUnique.hxx(26): note: could be 'std::unique_ptr<ROOT::Experimental::TDF::TTrivialDS,std::default_delete<_Ty>> std::make_unique<ROOT::Experimental::TDF::TTrivialDS,ULong64_t&>(ULong64_t &)'; with; [; _Ty=ROOT::Experimental::TDF::TTrivialDS; ]; C:\Program Files (x86)\Microsoft Visual Studio\2017\Community\VC\Tools\MSVC\14.11.25503\include\memory(2436): note:; or 'std::unique_ptr<ROOT::Experimental::TDF::TTrivialDS,std::default_delete<_Ty>> std::make_unique<ROOT::Experimental::TDF::TTrivialDS,ULong64_t&,void>(ULong64_t &)'; with; [; _Ty=ROOT::Experimental::TDF::TTrivialDS; ]; TTrivialDS.cxx(82): note: while trying to match the argument list '(ULong64_t)'; TTrivialDS.cxx(82): error C2512: 'ROOT::Experimental::TDataFrame::TDataFrame': no ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1151
https://github.com/root-project/root/pull/1151:1153,Availability,error,error,1153,"rloaded function [TreePlayer.vcxproj]; C:\Users\bellenot\build\master-check\include\ROOT/RMakeUnique.hxx(26): note: could be 'std::unique_ptr<ROOT::Experimental::TDF::TRootDS,std::default_delete<_Ty>> std::make_unique<ROOT::Experimental::TDF::TRootDS,std::string_view&,std::string_view&>(std::string_view &,std::string_view &)'; with; [; _Ty=ROOT::Experimental::TDF::TRootDS; ]; C:\Program Files (x86)\Microsoft Visual Studio\2017\Community\VC\Tools\MSVC\14.11.25503\include\memory(2436): note:; or 'std::unique_ptr<ROOT::Experimental::TDF::TRootDS,std::default_delete<_Ty>> std::make_unique<ROOT::Experimental::TDF::TRootDS,std::string_view&,std::string_view&,void>(std::string_view &,std::string_view &)'; with; [; _Ty=ROOT::Experimental::TDF::TRootDS; ]; TRootDS.cxx(145): note: while trying to match the argument list '(std::string_view, std::string_view)'; TRootDS.cxx(145): error C2512: 'ROOT::Experimental::TDataFrame::TDataFrame': no appropriate default constructor available [TreePlayer.vcxproj]; TTrivialDS.cxx; TTrivialDS.cxx(82): error C2668: 'std::make_unique': ambiguous call to overloaded function [TreePlayer.vcxproj]; C:\Users\bellenot\build\master-check\include\ROOT/RMakeUnique.hxx(26): note: could be 'std::unique_ptr<ROOT::Experimental::TDF::TTrivialDS,std::default_delete<_Ty>> std::make_unique<ROOT::Experimental::TDF::TTrivialDS,ULong64_t&>(ULong64_t &)'; with; [; _Ty=ROOT::Experimental::TDF::TTrivialDS; ]; C:\Program Files (x86)\Microsoft Visual Studio\2017\Community\VC\Tools\MSVC\14.11.25503\include\memory(2436): note:; or 'std::unique_ptr<ROOT::Experimental::TDF::TTrivialDS,std::default_delete<_Ty>> std::make_unique<ROOT::Experimental::TDF::TTrivialDS,ULong64_t&,void>(ULong64_t &)'; with; [; _Ty=ROOT::Experimental::TDF::TTrivialDS; ]; TTrivialDS.cxx(82): note: while trying to match the argument list '(ULong64_t)'; TTrivialDS.cxx(82): error C2512: 'ROOT::Experimental::TDataFrame::TDataFrame': no appropriate default constructor available [TreePlayer.vcxproj]. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1151
https://github.com/root-project/root/pull/1151:1982,Availability,error,error,1982,"rloaded function [TreePlayer.vcxproj]; C:\Users\bellenot\build\master-check\include\ROOT/RMakeUnique.hxx(26): note: could be 'std::unique_ptr<ROOT::Experimental::TDF::TRootDS,std::default_delete<_Ty>> std::make_unique<ROOT::Experimental::TDF::TRootDS,std::string_view&,std::string_view&>(std::string_view &,std::string_view &)'; with; [; _Ty=ROOT::Experimental::TDF::TRootDS; ]; C:\Program Files (x86)\Microsoft Visual Studio\2017\Community\VC\Tools\MSVC\14.11.25503\include\memory(2436): note:; or 'std::unique_ptr<ROOT::Experimental::TDF::TRootDS,std::default_delete<_Ty>> std::make_unique<ROOT::Experimental::TDF::TRootDS,std::string_view&,std::string_view&,void>(std::string_view &,std::string_view &)'; with; [; _Ty=ROOT::Experimental::TDF::TRootDS; ]; TRootDS.cxx(145): note: while trying to match the argument list '(std::string_view, std::string_view)'; TRootDS.cxx(145): error C2512: 'ROOT::Experimental::TDataFrame::TDataFrame': no appropriate default constructor available [TreePlayer.vcxproj]; TTrivialDS.cxx; TTrivialDS.cxx(82): error C2668: 'std::make_unique': ambiguous call to overloaded function [TreePlayer.vcxproj]; C:\Users\bellenot\build\master-check\include\ROOT/RMakeUnique.hxx(26): note: could be 'std::unique_ptr<ROOT::Experimental::TDF::TTrivialDS,std::default_delete<_Ty>> std::make_unique<ROOT::Experimental::TDF::TTrivialDS,ULong64_t&>(ULong64_t &)'; with; [; _Ty=ROOT::Experimental::TDF::TTrivialDS; ]; C:\Program Files (x86)\Microsoft Visual Studio\2017\Community\VC\Tools\MSVC\14.11.25503\include\memory(2436): note:; or 'std::unique_ptr<ROOT::Experimental::TDF::TTrivialDS,std::default_delete<_Ty>> std::make_unique<ROOT::Experimental::TDF::TTrivialDS,ULong64_t&,void>(ULong64_t &)'; with; [; _Ty=ROOT::Experimental::TDF::TTrivialDS; ]; TTrivialDS.cxx(82): note: while trying to match the argument list '(ULong64_t)'; TTrivialDS.cxx(82): error C2512: 'ROOT::Experimental::TDataFrame::TDataFrame': no appropriate default constructor available [TreePlayer.vcxproj]. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1151
https://github.com/root-project/root/pull/1151:2076,Availability,avail,available,2076,"rloaded function [TreePlayer.vcxproj]; C:\Users\bellenot\build\master-check\include\ROOT/RMakeUnique.hxx(26): note: could be 'std::unique_ptr<ROOT::Experimental::TDF::TRootDS,std::default_delete<_Ty>> std::make_unique<ROOT::Experimental::TDF::TRootDS,std::string_view&,std::string_view&>(std::string_view &,std::string_view &)'; with; [; _Ty=ROOT::Experimental::TDF::TRootDS; ]; C:\Program Files (x86)\Microsoft Visual Studio\2017\Community\VC\Tools\MSVC\14.11.25503\include\memory(2436): note:; or 'std::unique_ptr<ROOT::Experimental::TDF::TRootDS,std::default_delete<_Ty>> std::make_unique<ROOT::Experimental::TDF::TRootDS,std::string_view&,std::string_view&,void>(std::string_view &,std::string_view &)'; with; [; _Ty=ROOT::Experimental::TDF::TRootDS; ]; TRootDS.cxx(145): note: while trying to match the argument list '(std::string_view, std::string_view)'; TRootDS.cxx(145): error C2512: 'ROOT::Experimental::TDataFrame::TDataFrame': no appropriate default constructor available [TreePlayer.vcxproj]; TTrivialDS.cxx; TTrivialDS.cxx(82): error C2668: 'std::make_unique': ambiguous call to overloaded function [TreePlayer.vcxproj]; C:\Users\bellenot\build\master-check\include\ROOT/RMakeUnique.hxx(26): note: could be 'std::unique_ptr<ROOT::Experimental::TDF::TTrivialDS,std::default_delete<_Ty>> std::make_unique<ROOT::Experimental::TDF::TTrivialDS,ULong64_t&>(ULong64_t &)'; with; [; _Ty=ROOT::Experimental::TDF::TTrivialDS; ]; C:\Program Files (x86)\Microsoft Visual Studio\2017\Community\VC\Tools\MSVC\14.11.25503\include\memory(2436): note:; or 'std::unique_ptr<ROOT::Experimental::TDF::TTrivialDS,std::default_delete<_Ty>> std::make_unique<ROOT::Experimental::TDF::TTrivialDS,ULong64_t&,void>(ULong64_t &)'; with; [; _Ty=ROOT::Experimental::TDF::TTrivialDS; ]; TTrivialDS.cxx(82): note: while trying to match the argument list '(ULong64_t)'; TTrivialDS.cxx(82): error C2512: 'ROOT::Experimental::TDataFrame::TDataFrame': no appropriate default constructor available [TreePlayer.vcxproj]. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1151
https://github.com/root-project/root/pull/1157:287,Testability,test,tests,287,"We were not as general as we wanted to be:; ```c++; auto f = {""f1.root"", ""f2.root""};; TDataFrame(""tree"", f);; ```; could not compile. Move the responsibility to convert collections of; filenames to vector<string> to users. @dpiparo do you agree with this change? (note that it breaks no tests)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1157
https://github.com/root-project/root/pull/1158:103,Testability,log,logic,103,This issue was reported here: https://sft.its.cern.ch/jira/browse/ROOT-9046; PaintLine as now the same logic as PaintPolyMarker to decide if a point; is in the range or not.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1158
https://github.com/root-project/root/pull/1159:9,Testability,test,test,9,and unit test,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1159
https://github.com/root-project/root/pull/1160:223,Modifiability,Config,Configurable,223,"This commit provides the implementation of a new data source for TDataFrame that is able to read CSV files.; ; Some of its features include:; - File content stored in memory; - Type inference (int, double, bool, string); - Configurable delimiter; - Quoted fields & quote escaping support",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1160
https://github.com/root-project/root/pull/1161:127,Testability,test,test,127,This PR fixes -Dclingtest=On to add target cling and check-cling to ROOT. This in turn will build the cling binary and run its test suite.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1161
https://github.com/root-project/root/pull/1166:30,Modifiability,flexible,flexible,30,"ROOT is like before, but more flexible (391 compilation units less).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1166
https://github.com/root-project/root/pull/1172:51,Modifiability,variab,variables,51,Avoid searching in the standard system environment variables (i.e. PATH),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1172
https://github.com/root-project/root/pull/1172:0,Safety,Avoid,Avoid,0,Avoid searching in the standard system environment variables (i.e. PATH),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1172
https://github.com/root-project/root/pull/1174:0,Deployability,Update,Updated,0,Updated PR for https://github.com/root-project/root/pull/1149,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1174
https://github.com/root-project/root/pull/1177:187,Deployability,release,released,187,"From Timur:. When TGQuartz was developed, retina macs did not exist yet and Cocoa; did not provide any API to access scaling-related information.; After they have introduced this API and released retina MacBooks, our GUI; rendering was just fine and worked out of box, our 'pixmap-based' graphics; was fixed by multiplying pixmaps' geometry (by scaling factor) and also setting; the corresponding scaling CTM on the bitmap context. It appears, all these; years we did not know how expensive this scaling transformation is.; As was noticed recently, even a relatively simple poly-line consisting; of 25K segments takes _forever_ to draw - apparently Quartz is working; hard doing hell knows what under the hood (disabling anti-aliasing does not change; anything, for example). This patch is a possible fix, the proper solution would require a serious redesign; in many places (starting from TVirtualX and TCanvas) - for now we simply cancel; the scaling transformation when rendering potentially complex geometry and scale; coordinates manually instead. A macro reproducing this problem on retina display would be:. {; int n = 5000;; double xx[n];; double yy[n];; TRandom r;; for (int i=0; i<n; i++) {; xx[i] = r.Gaus(-1,0.5);; yy[i] = r.Gaus(1,1.5);; }; TGraph *g = new TGraph(n, xx,yy);; g->Draw(""al"");; }",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1177
https://github.com/root-project/root/pull/1177:781,Deployability,patch,patch,781,"From Timur:. When TGQuartz was developed, retina macs did not exist yet and Cocoa; did not provide any API to access scaling-related information.; After they have introduced this API and released retina MacBooks, our GUI; rendering was just fine and worked out of box, our 'pixmap-based' graphics; was fixed by multiplying pixmaps' geometry (by scaling factor) and also setting; the corresponding scaling CTM on the bitmap context. It appears, all these; years we did not know how expensive this scaling transformation is.; As was noticed recently, even a relatively simple poly-line consisting; of 25K segments takes _forever_ to draw - apparently Quartz is working; hard doing hell knows what under the hood (disabling anti-aliasing does not change; anything, for example). This patch is a possible fix, the proper solution would require a serious redesign; in many places (starting from TVirtualX and TCanvas) - for now we simply cancel; the scaling transformation when rendering potentially complex geometry and scale; coordinates manually instead. A macro reproducing this problem on retina display would be:. {; int n = 5000;; double xx[n];; double yy[n];; TRandom r;; for (int i=0; i<n; i++) {; xx[i] = r.Gaus(-1,0.5);; yy[i] = r.Gaus(1,1.5);; }; TGraph *g = new TGraph(n, xx,yy);; g->Draw(""al"");; }",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1177
https://github.com/root-project/root/pull/1177:110,Security,access,access,110,"From Timur:. When TGQuartz was developed, retina macs did not exist yet and Cocoa; did not provide any API to access scaling-related information.; After they have introduced this API and released retina MacBooks, our GUI; rendering was just fine and worked out of box, our 'pixmap-based' graphics; was fixed by multiplying pixmaps' geometry (by scaling factor) and also setting; the corresponding scaling CTM on the bitmap context. It appears, all these; years we did not know how expensive this scaling transformation is.; As was noticed recently, even a relatively simple poly-line consisting; of 25K segments takes _forever_ to draw - apparently Quartz is working; hard doing hell knows what under the hood (disabling anti-aliasing does not change; anything, for example). This patch is a possible fix, the proper solution would require a serious redesign; in many places (starting from TVirtualX and TCanvas) - for now we simply cancel; the scaling transformation when rendering potentially complex geometry and scale; coordinates manually instead. A macro reproducing this problem on retina display would be:. {; int n = 5000;; double xx[n];; double yy[n];; TRandom r;; for (int i=0; i<n; i++) {; xx[i] = r.Gaus(-1,0.5);; yy[i] = r.Gaus(1,1.5);; }; TGraph *g = new TGraph(n, xx,yy);; g->Draw(""al"");; }",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1177
https://github.com/root-project/root/pull/1177:567,Usability,simpl,simple,567,"From Timur:. When TGQuartz was developed, retina macs did not exist yet and Cocoa; did not provide any API to access scaling-related information.; After they have introduced this API and released retina MacBooks, our GUI; rendering was just fine and worked out of box, our 'pixmap-based' graphics; was fixed by multiplying pixmaps' geometry (by scaling factor) and also setting; the corresponding scaling CTM on the bitmap context. It appears, all these; years we did not know how expensive this scaling transformation is.; As was noticed recently, even a relatively simple poly-line consisting; of 25K segments takes _forever_ to draw - apparently Quartz is working; hard doing hell knows what under the hood (disabling anti-aliasing does not change; anything, for example). This patch is a possible fix, the proper solution would require a serious redesign; in many places (starting from TVirtualX and TCanvas) - for now we simply cancel; the scaling transformation when rendering potentially complex geometry and scale; coordinates manually instead. A macro reproducing this problem on retina display would be:. {; int n = 5000;; double xx[n];; double yy[n];; TRandom r;; for (int i=0; i<n; i++) {; xx[i] = r.Gaus(-1,0.5);; yy[i] = r.Gaus(1,1.5);; }; TGraph *g = new TGraph(n, xx,yy);; g->Draw(""al"");; }",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1177
https://github.com/root-project/root/pull/1177:926,Usability,simpl,simply,926,"From Timur:. When TGQuartz was developed, retina macs did not exist yet and Cocoa; did not provide any API to access scaling-related information.; After they have introduced this API and released retina MacBooks, our GUI; rendering was just fine and worked out of box, our 'pixmap-based' graphics; was fixed by multiplying pixmaps' geometry (by scaling factor) and also setting; the corresponding scaling CTM on the bitmap context. It appears, all these; years we did not know how expensive this scaling transformation is.; As was noticed recently, even a relatively simple poly-line consisting; of 25K segments takes _forever_ to draw - apparently Quartz is working; hard doing hell knows what under the hood (disabling anti-aliasing does not change; anything, for example). This patch is a possible fix, the proper solution would require a serious redesign; in many places (starting from TVirtualX and TCanvas) - for now we simply cancel; the scaling transformation when rendering potentially complex geometry and scale; coordinates manually instead. A macro reproducing this problem on retina display would be:. {; int n = 5000;; double xx[n];; double yy[n];; TRandom r;; for (int i=0; i<n; i++) {; xx[i] = r.Gaus(-1,0.5);; yy[i] = r.Gaus(1,1.5);; }; TGraph *g = new TGraph(n, xx,yy);; g->Draw(""al"");; }",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1177
https://github.com/root-project/root/pull/1180:46,Energy Efficiency,efficient,efficient,46,"This PR is related to #1010 . I could be more efficient to cancel the tasks immediately than wait for unnecessary tasks to be finished. Especially when cache is invalid, unzipping task has to continue running return function.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1180
https://github.com/root-project/root/pull/1180:152,Performance,cache,cache,152,"This PR is related to #1010 . I could be more efficient to cancel the tasks immediately than wait for unnecessary tasks to be finished. Especially when cache is invalid, unzipping task has to continue running return function.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1180
https://github.com/root-project/root/pull/1183:58,Testability,assert,assertions,58,… on histograms. In Debug and RelWithDebInfo builds (when assertions are active) the following; code caused an assertion to fire:. root [0] TEfficiency* eff = new TEfficiency;; root [1] eff->SetUseWeightedEvents();; Info in <TROOT::TEfficiency::SetUseWeightedEvents>: Histograms are filled with weights; root.exe: ../hist/hist/src/TEfficiency.cxx:3593: void TEfficiency::SetUseWeightedEvents(bool): Assertion `fTotalHistogram->GetSumw2N() > 0 && fPassedHistogram->GetSumw2N() > 0' failed. This fixes ROOT-9058.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1183
https://github.com/root-project/root/pull/1183:111,Testability,assert,assertion,111,… on histograms. In Debug and RelWithDebInfo builds (when assertions are active) the following; code caused an assertion to fire:. root [0] TEfficiency* eff = new TEfficiency;; root [1] eff->SetUseWeightedEvents();; Info in <TROOT::TEfficiency::SetUseWeightedEvents>: Histograms are filled with weights; root.exe: ../hist/hist/src/TEfficiency.cxx:3593: void TEfficiency::SetUseWeightedEvents(bool): Assertion `fTotalHistogram->GetSumw2N() > 0 && fPassedHistogram->GetSumw2N() > 0' failed. This fixes ROOT-9058.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1183
https://github.com/root-project/root/pull/1183:399,Testability,Assert,Assertion,399,… on histograms. In Debug and RelWithDebInfo builds (when assertions are active) the following; code caused an assertion to fire:. root [0] TEfficiency* eff = new TEfficiency;; root [1] eff->SetUseWeightedEvents();; Info in <TROOT::TEfficiency::SetUseWeightedEvents>: Histograms are filled with weights; root.exe: ../hist/hist/src/TEfficiency.cxx:3593: void TEfficiency::SetUseWeightedEvents(bool): Assertion `fTotalHistogram->GetSumw2N() > 0 && fPassedHistogram->GetSumw2N() > 0' failed. This fixes ROOT-9058.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1183
https://github.com/root-project/root/pull/1187:228,Testability,Log,Logical,228,[core/base/src/TStyle.cxx:1508]: (style) Array index 'i' is used before limits check; [geom/geom/src/TGeoNavigator.cxx:2219]: (style) Array index 'jst' is used before limits check. [geom/geocad/src/TGeoToOCC.cxx:527]: (warning) Logical disjunction always evaluates to true: EXPR > -1e-4 || EXPR < 1e-4; [geom/geocad/src/TGeoToOCC.cxx:528]: (warning) Logical disjunction always evaluates to true: EXPR > -1e-4 || EXPR < 1e-4; [geom/geocad/src/TGeoToOCC.cxx:529]: (warning) Logical disjunction always evaluates to true: EXPR > -1e-4 || EXPR < 1e-4; [geom/geocad/src/TGeoToOCC.cxx:530]: (warning) Logical disjunction always evaluates to true: EXPR > -1e-4 || EXPR < 1e-4; [graf2d/asimage/src/libAfterImage/char2uni.c:814]: (warning) Logical conjunction always evaluates to false: EXPR == 'S' && EXPR == 's'; [graf2d/asimage/src/libAfterImage/char2uni.c:815]: (warning) Logical conjunction always evaluates to false: EXPR == 'O' && EXPR == 'o'. [graf2d/asimage/src/libAfterImage/imencdec.c:376] -> [graf2d/asimage/src/libAfterImage/imencdec.c:376]: (style) Same expression on both sides of '&&'; [geom/geom/src/TGeoParaboloid.cxx:457] -> [geom/geom/src/TGeoParaboloid.cxx:457]: (style) Same expression on both sides of '||',MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1187
https://github.com/root-project/root/pull/1187:350,Testability,Log,Logical,350,[core/base/src/TStyle.cxx:1508]: (style) Array index 'i' is used before limits check; [geom/geom/src/TGeoNavigator.cxx:2219]: (style) Array index 'jst' is used before limits check. [geom/geocad/src/TGeoToOCC.cxx:527]: (warning) Logical disjunction always evaluates to true: EXPR > -1e-4 || EXPR < 1e-4; [geom/geocad/src/TGeoToOCC.cxx:528]: (warning) Logical disjunction always evaluates to true: EXPR > -1e-4 || EXPR < 1e-4; [geom/geocad/src/TGeoToOCC.cxx:529]: (warning) Logical disjunction always evaluates to true: EXPR > -1e-4 || EXPR < 1e-4; [geom/geocad/src/TGeoToOCC.cxx:530]: (warning) Logical disjunction always evaluates to true: EXPR > -1e-4 || EXPR < 1e-4; [graf2d/asimage/src/libAfterImage/char2uni.c:814]: (warning) Logical conjunction always evaluates to false: EXPR == 'S' && EXPR == 's'; [graf2d/asimage/src/libAfterImage/char2uni.c:815]: (warning) Logical conjunction always evaluates to false: EXPR == 'O' && EXPR == 'o'. [graf2d/asimage/src/libAfterImage/imencdec.c:376] -> [graf2d/asimage/src/libAfterImage/imencdec.c:376]: (style) Same expression on both sides of '&&'; [geom/geom/src/TGeoParaboloid.cxx:457] -> [geom/geom/src/TGeoParaboloid.cxx:457]: (style) Same expression on both sides of '||',MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1187
https://github.com/root-project/root/pull/1187:472,Testability,Log,Logical,472,[core/base/src/TStyle.cxx:1508]: (style) Array index 'i' is used before limits check; [geom/geom/src/TGeoNavigator.cxx:2219]: (style) Array index 'jst' is used before limits check. [geom/geocad/src/TGeoToOCC.cxx:527]: (warning) Logical disjunction always evaluates to true: EXPR > -1e-4 || EXPR < 1e-4; [geom/geocad/src/TGeoToOCC.cxx:528]: (warning) Logical disjunction always evaluates to true: EXPR > -1e-4 || EXPR < 1e-4; [geom/geocad/src/TGeoToOCC.cxx:529]: (warning) Logical disjunction always evaluates to true: EXPR > -1e-4 || EXPR < 1e-4; [geom/geocad/src/TGeoToOCC.cxx:530]: (warning) Logical disjunction always evaluates to true: EXPR > -1e-4 || EXPR < 1e-4; [graf2d/asimage/src/libAfterImage/char2uni.c:814]: (warning) Logical conjunction always evaluates to false: EXPR == 'S' && EXPR == 's'; [graf2d/asimage/src/libAfterImage/char2uni.c:815]: (warning) Logical conjunction always evaluates to false: EXPR == 'O' && EXPR == 'o'. [graf2d/asimage/src/libAfterImage/imencdec.c:376] -> [graf2d/asimage/src/libAfterImage/imencdec.c:376]: (style) Same expression on both sides of '&&'; [geom/geom/src/TGeoParaboloid.cxx:457] -> [geom/geom/src/TGeoParaboloid.cxx:457]: (style) Same expression on both sides of '||',MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1187
https://github.com/root-project/root/pull/1187:594,Testability,Log,Logical,594,[core/base/src/TStyle.cxx:1508]: (style) Array index 'i' is used before limits check; [geom/geom/src/TGeoNavigator.cxx:2219]: (style) Array index 'jst' is used before limits check. [geom/geocad/src/TGeoToOCC.cxx:527]: (warning) Logical disjunction always evaluates to true: EXPR > -1e-4 || EXPR < 1e-4; [geom/geocad/src/TGeoToOCC.cxx:528]: (warning) Logical disjunction always evaluates to true: EXPR > -1e-4 || EXPR < 1e-4; [geom/geocad/src/TGeoToOCC.cxx:529]: (warning) Logical disjunction always evaluates to true: EXPR > -1e-4 || EXPR < 1e-4; [geom/geocad/src/TGeoToOCC.cxx:530]: (warning) Logical disjunction always evaluates to true: EXPR > -1e-4 || EXPR < 1e-4; [graf2d/asimage/src/libAfterImage/char2uni.c:814]: (warning) Logical conjunction always evaluates to false: EXPR == 'S' && EXPR == 's'; [graf2d/asimage/src/libAfterImage/char2uni.c:815]: (warning) Logical conjunction always evaluates to false: EXPR == 'O' && EXPR == 'o'. [graf2d/asimage/src/libAfterImage/imencdec.c:376] -> [graf2d/asimage/src/libAfterImage/imencdec.c:376]: (style) Same expression on both sides of '&&'; [geom/geom/src/TGeoParaboloid.cxx:457] -> [geom/geom/src/TGeoParaboloid.cxx:457]: (style) Same expression on both sides of '||',MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1187
https://github.com/root-project/root/pull/1187:730,Testability,Log,Logical,730,[core/base/src/TStyle.cxx:1508]: (style) Array index 'i' is used before limits check; [geom/geom/src/TGeoNavigator.cxx:2219]: (style) Array index 'jst' is used before limits check. [geom/geocad/src/TGeoToOCC.cxx:527]: (warning) Logical disjunction always evaluates to true: EXPR > -1e-4 || EXPR < 1e-4; [geom/geocad/src/TGeoToOCC.cxx:528]: (warning) Logical disjunction always evaluates to true: EXPR > -1e-4 || EXPR < 1e-4; [geom/geocad/src/TGeoToOCC.cxx:529]: (warning) Logical disjunction always evaluates to true: EXPR > -1e-4 || EXPR < 1e-4; [geom/geocad/src/TGeoToOCC.cxx:530]: (warning) Logical disjunction always evaluates to true: EXPR > -1e-4 || EXPR < 1e-4; [graf2d/asimage/src/libAfterImage/char2uni.c:814]: (warning) Logical conjunction always evaluates to false: EXPR == 'S' && EXPR == 's'; [graf2d/asimage/src/libAfterImage/char2uni.c:815]: (warning) Logical conjunction always evaluates to false: EXPR == 'O' && EXPR == 'o'. [graf2d/asimage/src/libAfterImage/imencdec.c:376] -> [graf2d/asimage/src/libAfterImage/imencdec.c:376]: (style) Same expression on both sides of '&&'; [geom/geom/src/TGeoParaboloid.cxx:457] -> [geom/geom/src/TGeoParaboloid.cxx:457]: (style) Same expression on both sides of '||',MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1187
https://github.com/root-project/root/pull/1187:866,Testability,Log,Logical,866,[core/base/src/TStyle.cxx:1508]: (style) Array index 'i' is used before limits check; [geom/geom/src/TGeoNavigator.cxx:2219]: (style) Array index 'jst' is used before limits check. [geom/geocad/src/TGeoToOCC.cxx:527]: (warning) Logical disjunction always evaluates to true: EXPR > -1e-4 || EXPR < 1e-4; [geom/geocad/src/TGeoToOCC.cxx:528]: (warning) Logical disjunction always evaluates to true: EXPR > -1e-4 || EXPR < 1e-4; [geom/geocad/src/TGeoToOCC.cxx:529]: (warning) Logical disjunction always evaluates to true: EXPR > -1e-4 || EXPR < 1e-4; [geom/geocad/src/TGeoToOCC.cxx:530]: (warning) Logical disjunction always evaluates to true: EXPR > -1e-4 || EXPR < 1e-4; [graf2d/asimage/src/libAfterImage/char2uni.c:814]: (warning) Logical conjunction always evaluates to false: EXPR == 'S' && EXPR == 's'; [graf2d/asimage/src/libAfterImage/char2uni.c:815]: (warning) Logical conjunction always evaluates to false: EXPR == 'O' && EXPR == 'o'. [graf2d/asimage/src/libAfterImage/imencdec.c:376] -> [graf2d/asimage/src/libAfterImage/imencdec.c:376]: (style) Same expression on both sides of '&&'; [geom/geom/src/TGeoParaboloid.cxx:457] -> [geom/geom/src/TGeoParaboloid.cxx:457]: (style) Same expression on both sides of '||',MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1187
https://github.com/root-project/root/pull/1188:171,Deployability,patch,patch,171,"The generation of our PCH/PCM file requires only the header files to be in; place. There is no direct relationship between if the dictionaries will be; built or not. This patch fixes a build system bottleneck (esp visible when building in; -DLLVM_BUILD_TYPE=Debug), namely we use only one core to build the pch. Another; advantage is that now we can just say make Core or make Cling and fire up ROOT; without having to wait very long.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1188
https://github.com/root-project/root/pull/1188:198,Performance,bottleneck,bottleneck,198,"The generation of our PCH/PCM file requires only the header files to be in; place. There is no direct relationship between if the dictionaries will be; built or not. This patch fixes a build system bottleneck (esp visible when building in; -DLLVM_BUILD_TYPE=Debug), namely we use only one core to build the pch. Another; advantage is that now we can just say make Core or make Cling and fire up ROOT; without having to wait very long.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1188
https://github.com/root-project/root/pull/1189:73,Testability,test,test,73,Turns out that we forgot to link in ZLIB in libCore. @oshadura could you test? We should make sure the tests are running if we are in `-Dbuiltin_zlib=On/Off`,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1189
https://github.com/root-project/root/pull/1189:103,Testability,test,tests,103,Turns out that we forgot to link in ZLIB in libCore. @oshadura could you test? We should make sure the tests are running if we are in `-Dbuiltin_zlib=On/Off`,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1189
https://github.com/root-project/root/pull/1196:82,Performance,cache,cache,82,"Partially revert ""Mark the file entry invalid, until reread. Invalidate SLocEntry cache, readd it on reread.""; ; That change does not make any sense. Kudos to my old self.; ; Resolves ROOT-8956.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1196
https://github.com/root-project/root/pull/1198:35,Integrability,depend,dependency,35,With this only core/imt is missing dependency tracking (on MacOS).; See https://sft.its.cern.ch/jira/browse/ROOT-9066,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1198
https://github.com/root-project/root/pull/1201:114,Modifiability,variab,variable,114,"Fix mostly warning C4138: '*/' found outside of comment, but also:; warning C4101: 'hProcess': unreferenced local variable; warning C4005: 'open': macro redefinition; warning C4002: too many actual parameters for macro 'open'; warning C4091: 'static ': ignored on left of '' when no variable is declared",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1201
https://github.com/root-project/root/pull/1201:283,Modifiability,variab,variable,283,"Fix mostly warning C4138: '*/' found outside of comment, but also:; warning C4101: 'hProcess': unreferenced local variable; warning C4005: 'open': macro redefinition; warning C4002: too many actual parameters for macro 'open'; warning C4091: 'static ': ignored on left of '' when no variable is declared",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1201
https://github.com/root-project/root/pull/1202:134,Modifiability,variab,variable,134,"This initialization should be unnecessary, but avoids a warning on some compiler platforms about potentially uninitialized use of the variable. Most other compiler platforms should optimize away the assignment. Fixes an issue reported by @pcanal.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1202
https://github.com/root-project/root/pull/1202:181,Performance,optimiz,optimize,181,"This initialization should be unnecessary, but avoids a warning on some compiler platforms about potentially uninitialized use of the variable. Most other compiler platforms should optimize away the assignment. Fixes an issue reported by @pcanal.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1202
https://github.com/root-project/root/pull/1202:47,Safety,avoid,avoids,47,"This initialization should be unnecessary, but avoids a warning on some compiler platforms about potentially uninitialized use of the variable. Most other compiler platforms should optimize away the assignment. Fixes an issue reported by @pcanal.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1202
https://github.com/root-project/root/pull/1204:211,Safety,Avoid,Avoids,211,"- Do static initialization in the header where possible.; - Remove unnecessary pointers to `TList` in the `TFileMerger` when the `TList` is owned by the `TFileMerger`, always created, and has the same lifetime. Avoids unnecessary heap allocations.; - As the data members have changed, increase the `ClassDef` version.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1204
https://github.com/root-project/root/pull/1205:46,Testability,test,test,46,This assumption was causing rare breakages in test/datasource_root.cxx,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1205
https://github.com/root-project/root/pull/1207:188,Availability,error,error,188,"For example:. class Rho: public TObject; {; public:; Float_t Rho; // rho energy density; Float_t Edges[2]; // pseudorapidity range edges. ClassDef(Rho, 1); };. This leads to a compilation error when doing. THashConsistencyHolder<name>. and lead to. error: template argument for template type parameter must be a type. because in that context the data member hid the class name; So we now do. THashConsistencyHolder<decltype(*this)>",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1207
https://github.com/root-project/root/pull/1207:249,Availability,error,error,249,"For example:. class Rho: public TObject; {; public:; Float_t Rho; // rho energy density; Float_t Edges[2]; // pseudorapidity range edges. ClassDef(Rho, 1); };. This leads to a compilation error when doing. THashConsistencyHolder<name>. and lead to. error: template argument for template type parameter must be a type. because in that context the data member hid the class name; So we now do. THashConsistencyHolder<decltype(*this)>",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1207
https://github.com/root-project/root/pull/1207:73,Energy Efficiency,energy,energy,73,"For example:. class Rho: public TObject; {; public:; Float_t Rho; // rho energy density; Float_t Edges[2]; // pseudorapidity range edges. ClassDef(Rho, 1); };. This leads to a compilation error when doing. THashConsistencyHolder<name>. and lead to. error: template argument for template type parameter must be a type. because in that context the data member hid the class name; So we now do. THashConsistencyHolder<decltype(*this)>",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1207
https://github.com/root-project/root/pull/1208:184,Availability,down,downsides,184,"TLS is currently not suppored in the JIT. However, it's possible to; enable emulated TLS support in LLVM which means that we now support; TLS across all architectures. The performance downsides of this; should be neglectiable and can be easily worked around (by merging; TLS variables into a single one). Patch created with a lot of help from Lang Hames and Pavel Labath!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1208
https://github.com/root-project/root/pull/1208:305,Deployability,Patch,Patch,305,"TLS is currently not suppored in the JIT. However, it's possible to; enable emulated TLS support in LLVM which means that we now support; TLS across all architectures. The performance downsides of this; should be neglectiable and can be easily worked around (by merging; TLS variables into a single one). Patch created with a lot of help from Lang Hames and Pavel Labath!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1208
https://github.com/root-project/root/pull/1208:275,Modifiability,variab,variables,275,"TLS is currently not suppored in the JIT. However, it's possible to; enable emulated TLS support in LLVM which means that we now support; TLS across all architectures. The performance downsides of this; should be neglectiable and can be easily worked around (by merging; TLS variables into a single one). Patch created with a lot of help from Lang Hames and Pavel Labath!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1208
https://github.com/root-project/root/pull/1208:172,Performance,perform,performance,172,"TLS is currently not suppored in the JIT. However, it's possible to; enable emulated TLS support in LLVM which means that we now support; TLS across all architectures. The performance downsides of this; should be neglectiable and can be easily worked around (by merging; TLS variables into a single one). Patch created with a lot of help from Lang Hames and Pavel Labath!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1208
https://github.com/root-project/root/pull/1209:55,Usability,Simpl,Simplify,55,Fix some minor compiler warnings on various platforms. Simplify the `TIOFeatures::Set` implementation as suggested by @pcanal . I do not believe any of these indicate real bugs. Just some code cleanliness.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1209
https://github.com/root-project/root/pull/1211:47,Performance,optimiz,optimizes,47,We have a suboptimal behavior in the way cling optimizes code in O2 mode.; Disable it until the issue is understood and fixed.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1211
https://github.com/root-project/root/pull/1216:241,Availability,error,error,241,"The first commit introduces `DefineSlotEntry`, analogous to `DefineSlot` but also passes the entry number to the registered callable. The second commit is a simple refactoring of `Define` to separate user interface from internal details and error checking.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1216
https://github.com/root-project/root/pull/1216:205,Integrability,interface,interface,205,"The first commit introduces `DefineSlotEntry`, analogous to `DefineSlot` but also passes the entry number to the registered callable. The second commit is a simple refactoring of `Define` to separate user interface from internal details and error checking.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1216
https://github.com/root-project/root/pull/1216:164,Modifiability,refactor,refactoring,164,"The first commit introduces `DefineSlotEntry`, analogous to `DefineSlot` but also passes the entry number to the registered callable. The second commit is a simple refactoring of `Define` to separate user interface from internal details and error checking.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1216
https://github.com/root-project/root/pull/1216:157,Usability,simpl,simple,157,"The first commit introduces `DefineSlotEntry`, analogous to `DefineSlot` but also passes the entry number to the registered callable. The second commit is a simple refactoring of `Define` to separate user interface from internal details and error checking.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1216
https://github.com/root-project/root/pull/1217:87,Security,access,access,87,"This PR adds a support for passing along the IO feature flags in the merger and allows access from the command-line for `hadd`. Additionally, makes the `TIOFeatures` a serialized member of `TTree` and `TBranch`, allowing them to behave as expected when cloned.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1217
https://github.com/root-project/root/pull/1218:509,Availability,failure,failures,509,"This PR roots our llvm vendor drop to the LLVM's 5.0 release. Updating llvm will enable C++17 support in ROOT. There are many advantages of doing that such as relying on a release which is very thoroughly tested. After many years, this update removes practically all cling/ROOT-specific patches from llvm which means that technically we can link against vanilla llvm. Note that we still have (a reduced) set of patches in clang. Note this comes with a few issues (thus the do-not-merge label):; * We have two failures in cling's testsuite (visible when building with -Dclingtest=On) -- they seem to be coming from a stack-corruption when the JIT is supposed to throw an exception;; * A few roottest failures which I want to make sure it is the same set as on my own system.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1218
https://github.com/root-project/root/pull/1218:699,Availability,failure,failures,699,"This PR roots our llvm vendor drop to the LLVM's 5.0 release. Updating llvm will enable C++17 support in ROOT. There are many advantages of doing that such as relying on a release which is very thoroughly tested. After many years, this update removes practically all cling/ROOT-specific patches from llvm which means that technically we can link against vanilla llvm. Note that we still have (a reduced) set of patches in clang. Note this comes with a few issues (thus the do-not-merge label):; * We have two failures in cling's testsuite (visible when building with -Dclingtest=On) -- they seem to be coming from a stack-corruption when the JIT is supposed to throw an exception;; * A few roottest failures which I want to make sure it is the same set as on my own system.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1218
https://github.com/root-project/root/pull/1218:53,Deployability,release,release,53,"This PR roots our llvm vendor drop to the LLVM's 5.0 release. Updating llvm will enable C++17 support in ROOT. There are many advantages of doing that such as relying on a release which is very thoroughly tested. After many years, this update removes practically all cling/ROOT-specific patches from llvm which means that technically we can link against vanilla llvm. Note that we still have (a reduced) set of patches in clang. Note this comes with a few issues (thus the do-not-merge label):; * We have two failures in cling's testsuite (visible when building with -Dclingtest=On) -- they seem to be coming from a stack-corruption when the JIT is supposed to throw an exception;; * A few roottest failures which I want to make sure it is the same set as on my own system.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1218
https://github.com/root-project/root/pull/1218:172,Deployability,release,release,172,"This PR roots our llvm vendor drop to the LLVM's 5.0 release. Updating llvm will enable C++17 support in ROOT. There are many advantages of doing that such as relying on a release which is very thoroughly tested. After many years, this update removes practically all cling/ROOT-specific patches from llvm which means that technically we can link against vanilla llvm. Note that we still have (a reduced) set of patches in clang. Note this comes with a few issues (thus the do-not-merge label):; * We have two failures in cling's testsuite (visible when building with -Dclingtest=On) -- they seem to be coming from a stack-corruption when the JIT is supposed to throw an exception;; * A few roottest failures which I want to make sure it is the same set as on my own system.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1218
https://github.com/root-project/root/pull/1218:236,Deployability,update,update,236,"This PR roots our llvm vendor drop to the LLVM's 5.0 release. Updating llvm will enable C++17 support in ROOT. There are many advantages of doing that such as relying on a release which is very thoroughly tested. After many years, this update removes practically all cling/ROOT-specific patches from llvm which means that technically we can link against vanilla llvm. Note that we still have (a reduced) set of patches in clang. Note this comes with a few issues (thus the do-not-merge label):; * We have two failures in cling's testsuite (visible when building with -Dclingtest=On) -- they seem to be coming from a stack-corruption when the JIT is supposed to throw an exception;; * A few roottest failures which I want to make sure it is the same set as on my own system.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1218
https://github.com/root-project/root/pull/1218:287,Deployability,patch,patches,287,"This PR roots our llvm vendor drop to the LLVM's 5.0 release. Updating llvm will enable C++17 support in ROOT. There are many advantages of doing that such as relying on a release which is very thoroughly tested. After many years, this update removes practically all cling/ROOT-specific patches from llvm which means that technically we can link against vanilla llvm. Note that we still have (a reduced) set of patches in clang. Note this comes with a few issues (thus the do-not-merge label):; * We have two failures in cling's testsuite (visible when building with -Dclingtest=On) -- they seem to be coming from a stack-corruption when the JIT is supposed to throw an exception;; * A few roottest failures which I want to make sure it is the same set as on my own system.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1218
https://github.com/root-project/root/pull/1218:411,Deployability,patch,patches,411,"This PR roots our llvm vendor drop to the LLVM's 5.0 release. Updating llvm will enable C++17 support in ROOT. There are many advantages of doing that such as relying on a release which is very thoroughly tested. After many years, this update removes practically all cling/ROOT-specific patches from llvm which means that technically we can link against vanilla llvm. Note that we still have (a reduced) set of patches in clang. Note this comes with a few issues (thus the do-not-merge label):; * We have two failures in cling's testsuite (visible when building with -Dclingtest=On) -- they seem to be coming from a stack-corruption when the JIT is supposed to throw an exception;; * A few roottest failures which I want to make sure it is the same set as on my own system.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1218
https://github.com/root-project/root/pull/1218:395,Energy Efficiency,reduce,reduced,395,"This PR roots our llvm vendor drop to the LLVM's 5.0 release. Updating llvm will enable C++17 support in ROOT. There are many advantages of doing that such as relying on a release which is very thoroughly tested. After many years, this update removes practically all cling/ROOT-specific patches from llvm which means that technically we can link against vanilla llvm. Note that we still have (a reduced) set of patches in clang. Note this comes with a few issues (thus the do-not-merge label):; * We have two failures in cling's testsuite (visible when building with -Dclingtest=On) -- they seem to be coming from a stack-corruption when the JIT is supposed to throw an exception;; * A few roottest failures which I want to make sure it is the same set as on my own system.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1218
https://github.com/root-project/root/pull/1218:205,Testability,test,tested,205,"This PR roots our llvm vendor drop to the LLVM's 5.0 release. Updating llvm will enable C++17 support in ROOT. There are many advantages of doing that such as relying on a release which is very thoroughly tested. After many years, this update removes practically all cling/ROOT-specific patches from llvm which means that technically we can link against vanilla llvm. Note that we still have (a reduced) set of patches in clang. Note this comes with a few issues (thus the do-not-merge label):; * We have two failures in cling's testsuite (visible when building with -Dclingtest=On) -- they seem to be coming from a stack-corruption when the JIT is supposed to throw an exception;; * A few roottest failures which I want to make sure it is the same set as on my own system.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1218
https://github.com/root-project/root/pull/1218:529,Testability,test,testsuite,529,"This PR roots our llvm vendor drop to the LLVM's 5.0 release. Updating llvm will enable C++17 support in ROOT. There are many advantages of doing that such as relying on a release which is very thoroughly tested. After many years, this update removes practically all cling/ROOT-specific patches from llvm which means that technically we can link against vanilla llvm. Note that we still have (a reduced) set of patches in clang. Note this comes with a few issues (thus the do-not-merge label):; * We have two failures in cling's testsuite (visible when building with -Dclingtest=On) -- they seem to be coming from a stack-corruption when the JIT is supposed to throw an exception;; * A few roottest failures which I want to make sure it is the same set as on my own system.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1218
https://github.com/root-project/root/pull/1219:1224,Performance,perform,perform,1224,"It is sometimes not possible for a TDataSource to know the full range of entries upfront. To cope with these cases, we need TDataSource to somehow communicate to TDataFrame when it can finish looping -- dynamically, as we go, we are done when we are done. The solution proposed in this PR is that TDataFrame will call `TDataSource::GetEntryRanges` repeatedly instead of just once: after processing a batch of entry ranges, TDF will ask for another one, then another one, until the TDataSource replies with an empty vector, which signals the end of the event-loop. The current TDataSources required small modification to make sure that the second time `GetEntryRanges` is invoked it returns an empty vector. Furthermore, as TDataFrame might use the same TDataSource for multiple event-loops, the TDataSource must setup `fEntryRanges` at the beginning of each event-loop. This is the rationale for the introduction of the `TDataSource::Init` and `TDataSource::Finalise` methods, that can optionally be implemented by the concrete data-source classes to deal with per-event-loop initialization and clean-up operations.; I think the addition of `Init` might be a good thing overall because currently we high-jack `SetNSlots` to perform initialization operations -- `Init` seems like a more proper place. `Finalise` is introduced for symmetry.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1219
https://github.com/root-project/root/pull/1220:291,Deployability,install,installation,291,"Added some simple fixes to `ROOT::TFile`, to make it build with Xcode/Clang 9.0 on macOS High Sierra in C++14 mode. This is to fix the build problem described in https://sft.its.cern.ch/jira/browse/ROOT-9072. (I just thought that I might as well propose a fix, since I fixed it for my local installation anyway.). I imagine that cherry-picking the fix into the master branch would not be up to me anymore... (Should've read the contribution guidelines... 😛)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1220
https://github.com/root-project/root/pull/1220:11,Usability,simpl,simple,11,"Added some simple fixes to `ROOT::TFile`, to make it build with Xcode/Clang 9.0 on macOS High Sierra in C++14 mode. This is to fix the build problem described in https://sft.its.cern.ch/jira/browse/ROOT-9072. (I just thought that I might as well propose a fix, since I fixed it for my local installation anyway.). I imagine that cherry-picking the fix into the master branch would not be up to me anymore... (Should've read the contribution guidelines... 😛)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1220
https://github.com/root-project/root/pull/1220:441,Usability,guid,guidelines,441,"Added some simple fixes to `ROOT::TFile`, to make it build with Xcode/Clang 9.0 on macOS High Sierra in C++14 mode. This is to fix the build problem described in https://sft.its.cern.ch/jira/browse/ROOT-9072. (I just thought that I might as well propose a fix, since I fixed it for my local installation anyway.). I imagine that cherry-picking the fix into the master branch would not be up to me anymore... (Should've read the contribution guidelines... 😛)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1220
https://github.com/root-project/root/pull/1223:242,Deployability,continuous,continuous,242,"In 2003, in a possibly-misguided attempt to make compression faster, the entire contents of the built-in custom compression codec were converted from compilation targets to header files. This code, which is about 90% identical to `zlib`, had continuous additions throughout the years, including the code to invoke non-`zlib` based compression. With this patch, we have:. - `ZDeflate.c`/`ZInflate.c`/`ZTrees.c`/`Bits.c`/`ZIP.h`: Code related to the old compression functions.; - `Bits.h`: headers necessary to actually use the old compression functions.; - `RZip.{cxx,h}`: Modern headers that anything outside this package should use in order to invoke the C-style library functions.; - `Compression.h`: Enums defining the different compression levels. Additionally, we now force external callers to utilize the proper enum for the compression type (`ROOT::ECompressionAlgorithm`) instead of the type-erased `int`. Note that a lot of the resulting code does not follow coding conventions as I attempted to reduce the amount of code-churn related to this commit. `clang-format` checks are expected to fail.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1223
https://github.com/root-project/root/pull/1223:354,Deployability,patch,patch,354,"In 2003, in a possibly-misguided attempt to make compression faster, the entire contents of the built-in custom compression codec were converted from compilation targets to header files. This code, which is about 90% identical to `zlib`, had continuous additions throughout the years, including the code to invoke non-`zlib` based compression. With this patch, we have:. - `ZDeflate.c`/`ZInflate.c`/`ZTrees.c`/`Bits.c`/`ZIP.h`: Code related to the old compression functions.; - `Bits.h`: headers necessary to actually use the old compression functions.; - `RZip.{cxx,h}`: Modern headers that anything outside this package should use in order to invoke the C-style library functions.; - `Compression.h`: Enums defining the different compression levels. Additionally, we now force external callers to utilize the proper enum for the compression type (`ROOT::ECompressionAlgorithm`) instead of the type-erased `int`. Note that a lot of the resulting code does not follow coding conventions as I attempted to reduce the amount of code-churn related to this commit. `clang-format` checks are expected to fail.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1223
https://github.com/root-project/root/pull/1223:1005,Energy Efficiency,reduce,reduce,1005,"In 2003, in a possibly-misguided attempt to make compression faster, the entire contents of the built-in custom compression codec were converted from compilation targets to header files. This code, which is about 90% identical to `zlib`, had continuous additions throughout the years, including the code to invoke non-`zlib` based compression. With this patch, we have:. - `ZDeflate.c`/`ZInflate.c`/`ZTrees.c`/`Bits.c`/`ZIP.h`: Code related to the old compression functions.; - `Bits.h`: headers necessary to actually use the old compression functions.; - `RZip.{cxx,h}`: Modern headers that anything outside this package should use in order to invoke the C-style library functions.; - `Compression.h`: Enums defining the different compression levels. Additionally, we now force external callers to utilize the proper enum for the compression type (`ROOT::ECompressionAlgorithm`) instead of the type-erased `int`. Note that a lot of the resulting code does not follow coding conventions as I attempted to reduce the amount of code-churn related to this commit. `clang-format` checks are expected to fail.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1223
https://github.com/root-project/root/pull/1224:78,Availability,avail,available,78,Today I learned: returning a local variable calls the move-ctor by default if available.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1224
https://github.com/root-project/root/pull/1224:35,Modifiability,variab,variable,35,Today I learned: returning a local variable calls the move-ctor by default if available.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1224
https://github.com/root-project/root/pull/1224:8,Usability,learn,learned,8,Today I learned: returning a local variable calls the move-ctor by default if available.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1224
https://github.com/root-project/root/pull/1225:0,Usability,Simpl,Simplification,0,Simplification of building builtin LZ4 and fixing ROOT-9071,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1225
https://github.com/root-project/root/pull/1226:26,Availability,error,error,26,Use Class_Name leads to:. error: explicit specialization of 'Class_Name' after instantiation. when compiling with modules on,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1226
https://github.com/root-project/root/pull/1227:474,Deployability,patch,patch,474,"This implements a proof of concept of a new histogram auto binning mode designed to produced mergeable histograms when run in multi-threaded / multi-process mode. The algorithm chooses powers of 2 to chose the boundaries, ranges and number of bins. The idea is described in the following document: https://docs.google.com/document/d/1TEntRbVnRzZRLio8JhND51FTNqqTAvu0ngnhLGneahg/edit?usp=sharing. A method to adjust the final looking of the histogram is also included in the patch. Two multicore tutorials illustrate the usage: mt303_fillHistosAutobin.C and mt301_fillHistos.C .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1227
https://github.com/root-project/root/pull/1227:185,Energy Efficiency,power,powers,185,"This implements a proof of concept of a new histogram auto binning mode designed to produced mergeable histograms when run in multi-threaded / multi-process mode. The algorithm chooses powers of 2 to chose the boundaries, ranges and number of bins. The idea is described in the following document: https://docs.google.com/document/d/1TEntRbVnRzZRLio8JhND51FTNqqTAvu0ngnhLGneahg/edit?usp=sharing. A method to adjust the final looking of the histogram is also included in the patch. Two multicore tutorials illustrate the usage: mt303_fillHistosAutobin.C and mt301_fillHistos.C .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1227
https://github.com/root-project/root/pull/1227:126,Performance,multi-thread,multi-threaded,126,"This implements a proof of concept of a new histogram auto binning mode designed to produced mergeable histograms when run in multi-threaded / multi-process mode. The algorithm chooses powers of 2 to chose the boundaries, ranges and number of bins. The idea is described in the following document: https://docs.google.com/document/d/1TEntRbVnRzZRLio8JhND51FTNqqTAvu0ngnhLGneahg/edit?usp=sharing. A method to adjust the final looking of the histogram is also included in the patch. Two multicore tutorials illustrate the usage: mt303_fillHistosAutobin.C and mt301_fillHistos.C .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1227
https://github.com/root-project/root/pull/1229:216,Availability,error,errors,216,"When building ROOT in optimized mode, we enable fast math which then; disables errno on math functions. But this only happens in TCling,; so all modules built by rootcling_stage1 are suddenly out of sync; and we get errors like this:; ```; error: errno in math functions was enabled in PCH file but is currently disabled; ```. This patch just applies the same setting in _stage1. In theory we; should make a central place where we have these extra flags, but; that's out of scope for now.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1229
https://github.com/root-project/root/pull/1229:240,Availability,error,error,240,"When building ROOT in optimized mode, we enable fast math which then; disables errno on math functions. But this only happens in TCling,; so all modules built by rootcling_stage1 are suddenly out of sync; and we get errors like this:; ```; error: errno in math functions was enabled in PCH file but is currently disabled; ```. This patch just applies the same setting in _stage1. In theory we; should make a central place where we have these extra flags, but; that's out of scope for now.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1229
https://github.com/root-project/root/pull/1229:332,Deployability,patch,patch,332,"When building ROOT in optimized mode, we enable fast math which then; disables errno on math functions. But this only happens in TCling,; so all modules built by rootcling_stage1 are suddenly out of sync; and we get errors like this:; ```; error: errno in math functions was enabled in PCH file but is currently disabled; ```. This patch just applies the same setting in _stage1. In theory we; should make a central place where we have these extra flags, but; that's out of scope for now.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1229
https://github.com/root-project/root/pull/1229:22,Performance,optimiz,optimized,22,"When building ROOT in optimized mode, we enable fast math which then; disables errno on math functions. But this only happens in TCling,; so all modules built by rootcling_stage1 are suddenly out of sync; and we get errors like this:; ```; error: errno in math functions was enabled in PCH file but is currently disabled; ```. This patch just applies the same setting in _stage1. In theory we; should make a central place where we have these extra flags, but; that's out of scope for now.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1229
https://github.com/root-project/root/pull/1231:21,Availability,error,error,21,"We currently get the error below from stdlib.h as we have problems merging; these special declarations with GCC annotations. We can't add stdlib.h to; the normal libc module as this would cause a dependency cycle between the; builtin modules of clang and libc, but having this as a standalone module; seems to work for me. ```; In file included from input_line_12:18:; In file included from /home/teemperor/root/dbg-build/include/Minuit2/BasicFunctionGradient.h:13:; In file included from /home/teemperor/root/dbg-build/include/Minuit2/MnMatrix.h:31:; In file included from /home/teemperor/root/dbg-build/include/Minuit2/LASymMatrix.h:24:; In file included from /home/teemperor/root/dbg-build/include/Minuit2/StackAllocator.h:28:; In file included from /usr/bin/../lib64/gcc/x86_64-pc-linux-gnu/7.2.0/../../../../include/c++/7.2.0/cstdlib:75:; In file included from /home/teemperor/root/dbg-build/etc/cling/lib/clang/5.0.0/include/stdlib.h:8:; /usr/include/stdlib.h:742:8: error: reference to 'lldiv_t' is ambiguous; extern lldiv_t lldiv (long long int __numer,; ^; /usr/include/stdlib.h:81:5: note: candidate found by name lookup is 'lldiv_t'; } lldiv_t;; ^; /usr/include/stdlib.h:81:5: note: candidate found by name lookup is 'lldiv_t'; } lldiv_t;; ^; In file included from input_line_12:18:; In file included from /home/teemperor/root/dbg-build/include/Minuit2/BasicFunctionGradient.h:13:; In file included from /home/teemperor/root/dbg-build/include/Minuit2/MnMatrix.h:31:; In file included from /home/teemperor/root/dbg-build/include/Minuit2/LASymMatrix.h:24:; In file included from /home/teemperor/root/dbg-build/include/Minuit2/StackAllocator.h:28:; In file included from /usr/bin/../lib64/gcc/x86_64-pc-linux-gnu/7.2.0/../../../../include/c++/7.2.0/cstdlib:75:; In file included from /home/teemperor/root/dbg-build/etc/cling/lib/clang/5.0.0/include/stdlib.h:8:; /usr/include/stdlib.h:742:16: error: functions that differ only in their return type cannot be overloaded; extern lldiv_t lldiv (lo",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1231
https://github.com/root-project/root/pull/1231:973,Availability,error,error,973,"r below from stdlib.h as we have problems merging; these special declarations with GCC annotations. We can't add stdlib.h to; the normal libc module as this would cause a dependency cycle between the; builtin modules of clang and libc, but having this as a standalone module; seems to work for me. ```; In file included from input_line_12:18:; In file included from /home/teemperor/root/dbg-build/include/Minuit2/BasicFunctionGradient.h:13:; In file included from /home/teemperor/root/dbg-build/include/Minuit2/MnMatrix.h:31:; In file included from /home/teemperor/root/dbg-build/include/Minuit2/LASymMatrix.h:24:; In file included from /home/teemperor/root/dbg-build/include/Minuit2/StackAllocator.h:28:; In file included from /usr/bin/../lib64/gcc/x86_64-pc-linux-gnu/7.2.0/../../../../include/c++/7.2.0/cstdlib:75:; In file included from /home/teemperor/root/dbg-build/etc/cling/lib/clang/5.0.0/include/stdlib.h:8:; /usr/include/stdlib.h:742:8: error: reference to 'lldiv_t' is ambiguous; extern lldiv_t lldiv (long long int __numer,; ^; /usr/include/stdlib.h:81:5: note: candidate found by name lookup is 'lldiv_t'; } lldiv_t;; ^; /usr/include/stdlib.h:81:5: note: candidate found by name lookup is 'lldiv_t'; } lldiv_t;; ^; In file included from input_line_12:18:; In file included from /home/teemperor/root/dbg-build/include/Minuit2/BasicFunctionGradient.h:13:; In file included from /home/teemperor/root/dbg-build/include/Minuit2/MnMatrix.h:31:; In file included from /home/teemperor/root/dbg-build/include/Minuit2/LASymMatrix.h:24:; In file included from /home/teemperor/root/dbg-build/include/Minuit2/StackAllocator.h:28:; In file included from /usr/bin/../lib64/gcc/x86_64-pc-linux-gnu/7.2.0/../../../../include/c++/7.2.0/cstdlib:75:; In file included from /home/teemperor/root/dbg-build/etc/cling/lib/clang/5.0.0/include/stdlib.h:8:; /usr/include/stdlib.h:742:16: error: functions that differ only in their return type cannot be overloaded; extern lldiv_t lldiv (long long int __numer,; ~~",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1231
https://github.com/root-project/root/pull/1231:1900,Availability,error,error,1900,"b/clang/5.0.0/include/stdlib.h:8:; /usr/include/stdlib.h:742:8: error: reference to 'lldiv_t' is ambiguous; extern lldiv_t lldiv (long long int __numer,; ^; /usr/include/stdlib.h:81:5: note: candidate found by name lookup is 'lldiv_t'; } lldiv_t;; ^; /usr/include/stdlib.h:81:5: note: candidate found by name lookup is 'lldiv_t'; } lldiv_t;; ^; In file included from input_line_12:18:; In file included from /home/teemperor/root/dbg-build/include/Minuit2/BasicFunctionGradient.h:13:; In file included from /home/teemperor/root/dbg-build/include/Minuit2/MnMatrix.h:31:; In file included from /home/teemperor/root/dbg-build/include/Minuit2/LASymMatrix.h:24:; In file included from /home/teemperor/root/dbg-build/include/Minuit2/StackAllocator.h:28:; In file included from /usr/bin/../lib64/gcc/x86_64-pc-linux-gnu/7.2.0/../../../../include/c++/7.2.0/cstdlib:75:; In file included from /home/teemperor/root/dbg-build/etc/cling/lib/clang/5.0.0/include/stdlib.h:8:; /usr/include/stdlib.h:742:16: error: functions that differ only in their return type cannot be overloaded; extern lldiv_t lldiv (long long int __numer,; ~~~~~~~ ^; /usr/include/stdlib.h:742:16: note: previous declaration is here; extern lldiv_t lldiv (long long int __numer,; ~~~~~~~ ^; In file included from input_line_12:18:; In file included from /home/teemperor/root/dbg-build/include/Minuit2/BasicFunctionGradient.h:13:; In file included from /home/teemperor/root/dbg-build/include/Minuit2/MnMatrix.h:31:; In file included from /home/teemperor/root/dbg-build/include/Minuit2/LASymMatrix.h:24:; In file included from /home/teemperor/root/dbg-build/include/Minuit2/StackAllocator.h:28:; /usr/bin/../lib64/gcc/x86_64-pc-linux-gnu/7.2.0/../../../../include/c++/7.2.0/cstdlib:194:11: error: reference to 'lldiv_t' is ambiguous; using ::lldiv_t;; ^; /usr/include/stdlib.h:81:5: note: candidate found by name lookup is 'lldiv_t'; } lldiv_t;; ^; /usr/include/stdlib.h:81:5: note: candidate found by name lookup is 'lldiv_t'; } lldiv_t;; ^; ``",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1231
https://github.com/root-project/root/pull/1231:2654,Availability,error,error,2654,"b/clang/5.0.0/include/stdlib.h:8:; /usr/include/stdlib.h:742:8: error: reference to 'lldiv_t' is ambiguous; extern lldiv_t lldiv (long long int __numer,; ^; /usr/include/stdlib.h:81:5: note: candidate found by name lookup is 'lldiv_t'; } lldiv_t;; ^; /usr/include/stdlib.h:81:5: note: candidate found by name lookup is 'lldiv_t'; } lldiv_t;; ^; In file included from input_line_12:18:; In file included from /home/teemperor/root/dbg-build/include/Minuit2/BasicFunctionGradient.h:13:; In file included from /home/teemperor/root/dbg-build/include/Minuit2/MnMatrix.h:31:; In file included from /home/teemperor/root/dbg-build/include/Minuit2/LASymMatrix.h:24:; In file included from /home/teemperor/root/dbg-build/include/Minuit2/StackAllocator.h:28:; In file included from /usr/bin/../lib64/gcc/x86_64-pc-linux-gnu/7.2.0/../../../../include/c++/7.2.0/cstdlib:75:; In file included from /home/teemperor/root/dbg-build/etc/cling/lib/clang/5.0.0/include/stdlib.h:8:; /usr/include/stdlib.h:742:16: error: functions that differ only in their return type cannot be overloaded; extern lldiv_t lldiv (long long int __numer,; ~~~~~~~ ^; /usr/include/stdlib.h:742:16: note: previous declaration is here; extern lldiv_t lldiv (long long int __numer,; ~~~~~~~ ^; In file included from input_line_12:18:; In file included from /home/teemperor/root/dbg-build/include/Minuit2/BasicFunctionGradient.h:13:; In file included from /home/teemperor/root/dbg-build/include/Minuit2/MnMatrix.h:31:; In file included from /home/teemperor/root/dbg-build/include/Minuit2/LASymMatrix.h:24:; In file included from /home/teemperor/root/dbg-build/include/Minuit2/StackAllocator.h:28:; /usr/bin/../lib64/gcc/x86_64-pc-linux-gnu/7.2.0/../../../../include/c++/7.2.0/cstdlib:194:11: error: reference to 'lldiv_t' is ambiguous; using ::lldiv_t;; ^; /usr/include/stdlib.h:81:5: note: candidate found by name lookup is 'lldiv_t'; } lldiv_t;; ^; /usr/include/stdlib.h:81:5: note: candidate found by name lookup is 'lldiv_t'; } lldiv_t;; ^; ``",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1231
https://github.com/root-project/root/pull/1231:196,Integrability,depend,dependency,196,"We currently get the error below from stdlib.h as we have problems merging; these special declarations with GCC annotations. We can't add stdlib.h to; the normal libc module as this would cause a dependency cycle between the; builtin modules of clang and libc, but having this as a standalone module; seems to work for me. ```; In file included from input_line_12:18:; In file included from /home/teemperor/root/dbg-build/include/Minuit2/BasicFunctionGradient.h:13:; In file included from /home/teemperor/root/dbg-build/include/Minuit2/MnMatrix.h:31:; In file included from /home/teemperor/root/dbg-build/include/Minuit2/LASymMatrix.h:24:; In file included from /home/teemperor/root/dbg-build/include/Minuit2/StackAllocator.h:28:; In file included from /usr/bin/../lib64/gcc/x86_64-pc-linux-gnu/7.2.0/../../../../include/c++/7.2.0/cstdlib:75:; In file included from /home/teemperor/root/dbg-build/etc/cling/lib/clang/5.0.0/include/stdlib.h:8:; /usr/include/stdlib.h:742:8: error: reference to 'lldiv_t' is ambiguous; extern lldiv_t lldiv (long long int __numer,; ^; /usr/include/stdlib.h:81:5: note: candidate found by name lookup is 'lldiv_t'; } lldiv_t;; ^; /usr/include/stdlib.h:81:5: note: candidate found by name lookup is 'lldiv_t'; } lldiv_t;; ^; In file included from input_line_12:18:; In file included from /home/teemperor/root/dbg-build/include/Minuit2/BasicFunctionGradient.h:13:; In file included from /home/teemperor/root/dbg-build/include/Minuit2/MnMatrix.h:31:; In file included from /home/teemperor/root/dbg-build/include/Minuit2/LASymMatrix.h:24:; In file included from /home/teemperor/root/dbg-build/include/Minuit2/StackAllocator.h:28:; In file included from /usr/bin/../lib64/gcc/x86_64-pc-linux-gnu/7.2.0/../../../../include/c++/7.2.0/cstdlib:75:; In file included from /home/teemperor/root/dbg-build/etc/cling/lib/clang/5.0.0/include/stdlib.h:8:; /usr/include/stdlib.h:742:16: error: functions that differ only in their return type cannot be overloaded; extern lldiv_t lldiv (lo",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1231
https://github.com/root-project/root/pull/1233:99,Performance,perform,perform,99,- Code to support book multiple ml methods in the envelope class.; - A new class Classification to perform two class classification in the new architecture of TMVA.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1233
https://github.com/root-project/root/pull/1235:449,Deployability,Update,Update,449,"Put it into graf2d/gpad. For the moment it is not possible to add v7 TText into graf2d/graf due to cross-referencing between libGpad and libGraf in that case. Normally libGpad linked against libGraf, but if one adds v7 TText into libGraf, one need several v7 classes (including TCanvas) from libGpad. One gets circular dependency. Should be resolved after Axel redesigns draw attributes container. . Also include JSROOT code for FitPanel and TText. Update docu for THttpServer and JSROOT",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1235
https://github.com/root-project/root/pull/1235:319,Integrability,depend,dependency,319,"Put it into graf2d/gpad. For the moment it is not possible to add v7 TText into graf2d/graf due to cross-referencing between libGpad and libGraf in that case. Normally libGpad linked against libGraf, but if one adds v7 TText into libGraf, one need several v7 classes (including TCanvas) from libGpad. One gets circular dependency. Should be resolved after Axel redesigns draw attributes container. . Also include JSROOT code for FitPanel and TText. Update docu for THttpServer and JSROOT",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1235
https://github.com/root-project/root/pull/1236:2446,Deployability,patch,patch,2446," hidden Sizes; | `-EnumConstantDecl 0x55555643fe98 <line:1661:9, col:38> col:9 in GQt.TGQt.h hidden WordSize 'enum QSysInfo::Sizes'; | `-ImplicitCastExpr 0x55555643fee0 <col:20, col:38> 'unsigned int' <IntegralCast>; | `-ParenExpr 0x55555643fe70 <col:20, col:38> 'unsigned long'; | `-BinaryOperator 0x55555643fe48 <col:21, col:37> 'unsigned long' '<<'; | |-UnaryExprOrTypeTraitExpr 0x55555643fe08 <col:21, col:34> 'unsigned long' sizeof 'void *'; | `-IntegerLiteral 0x55555643fe28 <col:37> 'int' 3; `-EnumDecl 0x55555643ff00 <line:1672:5, line:1685:5> line:1672:10 in GQt.TGQt.h hidden Endian; |-EnumConstantDecl 0x55555643ffd8 <line:1673:9> col:9 in GQt.TGQt.h hidden referenced BigEndian 'enum QSysInfo::Endian'; |-EnumConstantDecl 0x555556440028 <line:1674:9> col:9 in GQt.TGQt.h hidden referenced LittleEndian 'enum QSysInfo::Endian'; `-EnumConstantDecl 0x5555564400a0 <line:1681:11, col:23> col:11 in GQt.TGQt.h hidden ByteOrder 'enum QSysInfo::Endian'; `-ImplicitCastExpr 0x5555564400e8 <col:23> 'unsigned int' <IntegralCast>; `-DeclRefExpr 0x555556440070 <col:23> 'int' EnumConstant 0x555556440028 'LittleEndian' 'enum QSysInfo::Endian'; ```. The reason for this is that we have QSysInfo both in the TQtClientWidget; and TGQt submodules and our current translation (which is supposed to; parse all header in the module) sees them both in one transaction. As we also don't recognize that this decl is from a module, the code; fires the assert even though duplictes are expected with modules. The reason why we don't recognize it as a declaration form an ASTFile; which disables the assert is that FromASTFile for the decls is; not set. This is because they haven't been loaded by the ASTFileReader; but are directly parsed as submodules in our special case where we; directly parse a module content from rootcling to generate it. We just workaround in this patch by checking that if the decl is from; the currently generated module, we are pretending it's as if it was; loaded from an AST file.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1236
https://github.com/root-project/root/pull/1236:2259,Performance,load,loaded,2259," hidden Sizes; | `-EnumConstantDecl 0x55555643fe98 <line:1661:9, col:38> col:9 in GQt.TGQt.h hidden WordSize 'enum QSysInfo::Sizes'; | `-ImplicitCastExpr 0x55555643fee0 <col:20, col:38> 'unsigned int' <IntegralCast>; | `-ParenExpr 0x55555643fe70 <col:20, col:38> 'unsigned long'; | `-BinaryOperator 0x55555643fe48 <col:21, col:37> 'unsigned long' '<<'; | |-UnaryExprOrTypeTraitExpr 0x55555643fe08 <col:21, col:34> 'unsigned long' sizeof 'void *'; | `-IntegerLiteral 0x55555643fe28 <col:37> 'int' 3; `-EnumDecl 0x55555643ff00 <line:1672:5, line:1685:5> line:1672:10 in GQt.TGQt.h hidden Endian; |-EnumConstantDecl 0x55555643ffd8 <line:1673:9> col:9 in GQt.TGQt.h hidden referenced BigEndian 'enum QSysInfo::Endian'; |-EnumConstantDecl 0x555556440028 <line:1674:9> col:9 in GQt.TGQt.h hidden referenced LittleEndian 'enum QSysInfo::Endian'; `-EnumConstantDecl 0x5555564400a0 <line:1681:11, col:23> col:11 in GQt.TGQt.h hidden ByteOrder 'enum QSysInfo::Endian'; `-ImplicitCastExpr 0x5555564400e8 <col:23> 'unsigned int' <IntegralCast>; `-DeclRefExpr 0x555556440070 <col:23> 'int' EnumConstant 0x555556440028 'LittleEndian' 'enum QSysInfo::Endian'; ```. The reason for this is that we have QSysInfo both in the TQtClientWidget; and TGQt submodules and our current translation (which is supposed to; parse all header in the module) sees them both in one transaction. As we also don't recognize that this decl is from a module, the code; fires the assert even though duplictes are expected with modules. The reason why we don't recognize it as a declaration form an ASTFile; which disables the assert is that FromASTFile for the decls is; not set. This is because they haven't been loaded by the ASTFileReader; but are directly parsed as submodules in our special case where we; directly parse a module content from rootcling to generate it. We just workaround in this patch by checking that if the decl is from; the currently generated module, we are pretending it's as if it was; loaded from an AST file.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1236
https://github.com/root-project/root/pull/1236:2559,Performance,load,loaded,2559," hidden Sizes; | `-EnumConstantDecl 0x55555643fe98 <line:1661:9, col:38> col:9 in GQt.TGQt.h hidden WordSize 'enum QSysInfo::Sizes'; | `-ImplicitCastExpr 0x55555643fee0 <col:20, col:38> 'unsigned int' <IntegralCast>; | `-ParenExpr 0x55555643fe70 <col:20, col:38> 'unsigned long'; | `-BinaryOperator 0x55555643fe48 <col:21, col:37> 'unsigned long' '<<'; | |-UnaryExprOrTypeTraitExpr 0x55555643fe08 <col:21, col:34> 'unsigned long' sizeof 'void *'; | `-IntegerLiteral 0x55555643fe28 <col:37> 'int' 3; `-EnumDecl 0x55555643ff00 <line:1672:5, line:1685:5> line:1672:10 in GQt.TGQt.h hidden Endian; |-EnumConstantDecl 0x55555643ffd8 <line:1673:9> col:9 in GQt.TGQt.h hidden referenced BigEndian 'enum QSysInfo::Endian'; |-EnumConstantDecl 0x555556440028 <line:1674:9> col:9 in GQt.TGQt.h hidden referenced LittleEndian 'enum QSysInfo::Endian'; `-EnumConstantDecl 0x5555564400a0 <line:1681:11, col:23> col:11 in GQt.TGQt.h hidden ByteOrder 'enum QSysInfo::Endian'; `-ImplicitCastExpr 0x5555564400e8 <col:23> 'unsigned int' <IntegralCast>; `-DeclRefExpr 0x555556440070 <col:23> 'int' EnumConstant 0x555556440028 'LittleEndian' 'enum QSysInfo::Endian'; ```. The reason for this is that we have QSysInfo both in the TQtClientWidget; and TGQt submodules and our current translation (which is supposed to; parse all header in the module) sees them both in one transaction. As we also don't recognize that this decl is from a module, the code; fires the assert even though duplictes are expected with modules. The reason why we don't recognize it as a declaration form an ASTFile; which disables the assert is that FromASTFile for the decls is; not set. This is because they haven't been loaded by the ASTFileReader; but are directly parsed as submodules in our special case where we; directly parse a module content from rootcling to generate it. We just workaround in this patch by checking that if the decl is from; the currently generated module, we are pretending it's as if it was; loaded from an AST file.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1236
https://github.com/root-project/root/pull/1236:425,Security,Access,AccessSpecDecl,425,"When generating the GQt module in rootcling, we hit the assertions; in forceAppend assertions about ""Duplicates?!"" with this declaration:. ```; CXXRecordDecl 0x55555643fae8 </usr/include/qt4/QtCore/qglobal.h:1658:1, line:1794:1> line:1658:21 in GQt.TGQt.h hidden class QSysInfo definition; |-also in GQt.TQtClientWidget.h; |-CXXRecordDecl 0x55555643fc30 <col:1, col:21> col:21 in GQt.TGQt.h hidden implicit class QSysInfo; |-AccessSpecDecl 0x55555643fce8 <line:1659:1, col:7> col:1 in GQt.TGQt.h public; |-EnumDecl 0x55555643fd18 <line:1660:5, line:1662:5> line:1660:10 in GQt.TGQt.h hidden Sizes; | `-EnumConstantDecl 0x55555643fe98 <line:1661:9, col:38> col:9 in GQt.TGQt.h hidden WordSize 'enum QSysInfo::Sizes'; | `-ImplicitCastExpr 0x55555643fee0 <col:20, col:38> 'unsigned int' <IntegralCast>; | `-ParenExpr 0x55555643fe70 <col:20, col:38> 'unsigned long'; | `-BinaryOperator 0x55555643fe48 <col:21, col:37> 'unsigned long' '<<'; | |-UnaryExprOrTypeTraitExpr 0x55555643fe08 <col:21, col:34> 'unsigned long' sizeof 'void *'; | `-IntegerLiteral 0x55555643fe28 <col:37> 'int' 3; `-EnumDecl 0x55555643ff00 <line:1672:5, line:1685:5> line:1672:10 in GQt.TGQt.h hidden Endian; |-EnumConstantDecl 0x55555643ffd8 <line:1673:9> col:9 in GQt.TGQt.h hidden referenced BigEndian 'enum QSysInfo::Endian'; |-EnumConstantDecl 0x555556440028 <line:1674:9> col:9 in GQt.TGQt.h hidden referenced LittleEndian 'enum QSysInfo::Endian'; `-EnumConstantDecl 0x5555564400a0 <line:1681:11, col:23> col:11 in GQt.TGQt.h hidden ByteOrder 'enum QSysInfo::Endian'; `-ImplicitCastExpr 0x5555564400e8 <col:23> 'unsigned int' <IntegralCast>; `-DeclRefExpr 0x555556440070 <col:23> 'int' EnumConstant 0x555556440028 'LittleEndian' 'enum QSysInfo::Endian'; ```. The reason for this is that we have QSysInfo both in the TQtClientWidget; and TGQt submodules and our current translation (which is supposed to; parse all header in the module) sees them both in one transaction. As we also don't recognize that this decl is from a modu",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1236
https://github.com/root-project/root/pull/1236:56,Testability,assert,assertions,56,"When generating the GQt module in rootcling, we hit the assertions; in forceAppend assertions about ""Duplicates?!"" with this declaration:. ```; CXXRecordDecl 0x55555643fae8 </usr/include/qt4/QtCore/qglobal.h:1658:1, line:1794:1> line:1658:21 in GQt.TGQt.h hidden class QSysInfo definition; |-also in GQt.TQtClientWidget.h; |-CXXRecordDecl 0x55555643fc30 <col:1, col:21> col:21 in GQt.TGQt.h hidden implicit class QSysInfo; |-AccessSpecDecl 0x55555643fce8 <line:1659:1, col:7> col:1 in GQt.TGQt.h public; |-EnumDecl 0x55555643fd18 <line:1660:5, line:1662:5> line:1660:10 in GQt.TGQt.h hidden Sizes; | `-EnumConstantDecl 0x55555643fe98 <line:1661:9, col:38> col:9 in GQt.TGQt.h hidden WordSize 'enum QSysInfo::Sizes'; | `-ImplicitCastExpr 0x55555643fee0 <col:20, col:38> 'unsigned int' <IntegralCast>; | `-ParenExpr 0x55555643fe70 <col:20, col:38> 'unsigned long'; | `-BinaryOperator 0x55555643fe48 <col:21, col:37> 'unsigned long' '<<'; | |-UnaryExprOrTypeTraitExpr 0x55555643fe08 <col:21, col:34> 'unsigned long' sizeof 'void *'; | `-IntegerLiteral 0x55555643fe28 <col:37> 'int' 3; `-EnumDecl 0x55555643ff00 <line:1672:5, line:1685:5> line:1672:10 in GQt.TGQt.h hidden Endian; |-EnumConstantDecl 0x55555643ffd8 <line:1673:9> col:9 in GQt.TGQt.h hidden referenced BigEndian 'enum QSysInfo::Endian'; |-EnumConstantDecl 0x555556440028 <line:1674:9> col:9 in GQt.TGQt.h hidden referenced LittleEndian 'enum QSysInfo::Endian'; `-EnumConstantDecl 0x5555564400a0 <line:1681:11, col:23> col:11 in GQt.TGQt.h hidden ByteOrder 'enum QSysInfo::Endian'; `-ImplicitCastExpr 0x5555564400e8 <col:23> 'unsigned int' <IntegralCast>; `-DeclRefExpr 0x555556440070 <col:23> 'int' EnumConstant 0x555556440028 'LittleEndian' 'enum QSysInfo::Endian'; ```. The reason for this is that we have QSysInfo both in the TQtClientWidget; and TGQt submodules and our current translation (which is supposed to; parse all header in the module) sees them both in one transaction. As we also don't recognize that this decl is from a modu",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1236
https://github.com/root-project/root/pull/1236:83,Testability,assert,assertions,83,"When generating the GQt module in rootcling, we hit the assertions; in forceAppend assertions about ""Duplicates?!"" with this declaration:. ```; CXXRecordDecl 0x55555643fae8 </usr/include/qt4/QtCore/qglobal.h:1658:1, line:1794:1> line:1658:21 in GQt.TGQt.h hidden class QSysInfo definition; |-also in GQt.TQtClientWidget.h; |-CXXRecordDecl 0x55555643fc30 <col:1, col:21> col:21 in GQt.TGQt.h hidden implicit class QSysInfo; |-AccessSpecDecl 0x55555643fce8 <line:1659:1, col:7> col:1 in GQt.TGQt.h public; |-EnumDecl 0x55555643fd18 <line:1660:5, line:1662:5> line:1660:10 in GQt.TGQt.h hidden Sizes; | `-EnumConstantDecl 0x55555643fe98 <line:1661:9, col:38> col:9 in GQt.TGQt.h hidden WordSize 'enum QSysInfo::Sizes'; | `-ImplicitCastExpr 0x55555643fee0 <col:20, col:38> 'unsigned int' <IntegralCast>; | `-ParenExpr 0x55555643fe70 <col:20, col:38> 'unsigned long'; | `-BinaryOperator 0x55555643fe48 <col:21, col:37> 'unsigned long' '<<'; | |-UnaryExprOrTypeTraitExpr 0x55555643fe08 <col:21, col:34> 'unsigned long' sizeof 'void *'; | `-IntegerLiteral 0x55555643fe28 <col:37> 'int' 3; `-EnumDecl 0x55555643ff00 <line:1672:5, line:1685:5> line:1672:10 in GQt.TGQt.h hidden Endian; |-EnumConstantDecl 0x55555643ffd8 <line:1673:9> col:9 in GQt.TGQt.h hidden referenced BigEndian 'enum QSysInfo::Endian'; |-EnumConstantDecl 0x555556440028 <line:1674:9> col:9 in GQt.TGQt.h hidden referenced LittleEndian 'enum QSysInfo::Endian'; `-EnumConstantDecl 0x5555564400a0 <line:1681:11, col:23> col:11 in GQt.TGQt.h hidden ByteOrder 'enum QSysInfo::Endian'; `-ImplicitCastExpr 0x5555564400e8 <col:23> 'unsigned int' <IntegralCast>; `-DeclRefExpr 0x555556440070 <col:23> 'int' EnumConstant 0x555556440028 'LittleEndian' 'enum QSysInfo::Endian'; ```. The reason for this is that we have QSysInfo both in the TQtClientWidget; and TGQt submodules and our current translation (which is supposed to; parse all header in the module) sees them both in one transaction. As we also don't recognize that this decl is from a modu",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1236
https://github.com/root-project/root/pull/1236:2025,Testability,assert,assert,2025," hidden Sizes; | `-EnumConstantDecl 0x55555643fe98 <line:1661:9, col:38> col:9 in GQt.TGQt.h hidden WordSize 'enum QSysInfo::Sizes'; | `-ImplicitCastExpr 0x55555643fee0 <col:20, col:38> 'unsigned int' <IntegralCast>; | `-ParenExpr 0x55555643fe70 <col:20, col:38> 'unsigned long'; | `-BinaryOperator 0x55555643fe48 <col:21, col:37> 'unsigned long' '<<'; | |-UnaryExprOrTypeTraitExpr 0x55555643fe08 <col:21, col:34> 'unsigned long' sizeof 'void *'; | `-IntegerLiteral 0x55555643fe28 <col:37> 'int' 3; `-EnumDecl 0x55555643ff00 <line:1672:5, line:1685:5> line:1672:10 in GQt.TGQt.h hidden Endian; |-EnumConstantDecl 0x55555643ffd8 <line:1673:9> col:9 in GQt.TGQt.h hidden referenced BigEndian 'enum QSysInfo::Endian'; |-EnumConstantDecl 0x555556440028 <line:1674:9> col:9 in GQt.TGQt.h hidden referenced LittleEndian 'enum QSysInfo::Endian'; `-EnumConstantDecl 0x5555564400a0 <line:1681:11, col:23> col:11 in GQt.TGQt.h hidden ByteOrder 'enum QSysInfo::Endian'; `-ImplicitCastExpr 0x5555564400e8 <col:23> 'unsigned int' <IntegralCast>; `-DeclRefExpr 0x555556440070 <col:23> 'int' EnumConstant 0x555556440028 'LittleEndian' 'enum QSysInfo::Endian'; ```. The reason for this is that we have QSysInfo both in the TQtClientWidget; and TGQt submodules and our current translation (which is supposed to; parse all header in the module) sees them both in one transaction. As we also don't recognize that this decl is from a module, the code; fires the assert even though duplictes are expected with modules. The reason why we don't recognize it as a declaration form an ASTFile; which disables the assert is that FromASTFile for the decls is; not set. This is because they haven't been loaded by the ASTFileReader; but are directly parsed as submodules in our special case where we; directly parse a module content from rootcling to generate it. We just workaround in this patch by checking that if the decl is from; the currently generated module, we are pretending it's as if it was; loaded from an AST file.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1236
https://github.com/root-project/root/pull/1236:2171,Testability,assert,assert,2171," hidden Sizes; | `-EnumConstantDecl 0x55555643fe98 <line:1661:9, col:38> col:9 in GQt.TGQt.h hidden WordSize 'enum QSysInfo::Sizes'; | `-ImplicitCastExpr 0x55555643fee0 <col:20, col:38> 'unsigned int' <IntegralCast>; | `-ParenExpr 0x55555643fe70 <col:20, col:38> 'unsigned long'; | `-BinaryOperator 0x55555643fe48 <col:21, col:37> 'unsigned long' '<<'; | |-UnaryExprOrTypeTraitExpr 0x55555643fe08 <col:21, col:34> 'unsigned long' sizeof 'void *'; | `-IntegerLiteral 0x55555643fe28 <col:37> 'int' 3; `-EnumDecl 0x55555643ff00 <line:1672:5, line:1685:5> line:1672:10 in GQt.TGQt.h hidden Endian; |-EnumConstantDecl 0x55555643ffd8 <line:1673:9> col:9 in GQt.TGQt.h hidden referenced BigEndian 'enum QSysInfo::Endian'; |-EnumConstantDecl 0x555556440028 <line:1674:9> col:9 in GQt.TGQt.h hidden referenced LittleEndian 'enum QSysInfo::Endian'; `-EnumConstantDecl 0x5555564400a0 <line:1681:11, col:23> col:11 in GQt.TGQt.h hidden ByteOrder 'enum QSysInfo::Endian'; `-ImplicitCastExpr 0x5555564400e8 <col:23> 'unsigned int' <IntegralCast>; `-DeclRefExpr 0x555556440070 <col:23> 'int' EnumConstant 0x555556440028 'LittleEndian' 'enum QSysInfo::Endian'; ```. The reason for this is that we have QSysInfo both in the TQtClientWidget; and TGQt submodules and our current translation (which is supposed to; parse all header in the module) sees them both in one transaction. As we also don't recognize that this decl is from a module, the code; fires the assert even though duplictes are expected with modules. The reason why we don't recognize it as a declaration form an ASTFile; which disables the assert is that FromASTFile for the decls is; not set. This is because they haven't been loaded by the ASTFileReader; but are directly parsed as submodules in our special case where we; directly parse a module content from rootcling to generate it. We just workaround in this patch by checking that if the decl is from; the currently generated module, we are pretending it's as if it was; loaded from an AST file.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1236
https://github.com/root-project/root/pull/1238:62,Deployability,update,updated,62,This fixes ROOT-9068 issue.; Tests in roottest have also been updated.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1238
https://github.com/root-project/root/pull/1238:29,Testability,Test,Tests,29,This fixes ROOT-9068 issue.; Tests in roottest have also been updated.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1238
https://github.com/root-project/root/pull/1239:166,Availability,error,error,166,"[graf2d/asimage/src/libAfterImage/afterbase.c:1282]: (style) Array index 'i' is used before limits check; [graf2d/asimage/src/libAfterImage/libungif/gifalloc.c:61]: (error) Memory leak: Object; [graf2d/win32gdk/src/TGWin32.cxx:4540]: (error) Memory leak: GIFarr; [graf3d/eve/src/TEveCalo2DGL.cxx:169]: (error) Memory leak: sliceVal; [graf3d/eve/src/TEveCalo2DGL.cxx:169]: (error) Memory leak: sliceValRef; [graf3d/eve/src/TEveCalo2DGL.cxx:369]: (error) Memory leak: sliceValsUp; [graf3d/eve/src/TEveCalo2DGL.cxx:369]: (error) Memory leak: sliceValsLow; [graf3d/eve/src/TEveCalo2DGL.cxx:369]: (error) Memory leak: sliceValsUpRef; [graf3d/eve/src/TEveCalo2DGL.cxx:369]: (error) Memory leak: sliceValsLowRef; [graf3d/eve/src/TEvePointSet.cxx:354]: (error) Memory leak: subarr. [graf3d/gl/src/gl2ps.cxx:1382] -> [graf3d/gl/src/gl2ps.cxx:1382]: (style) Same expression on both sides of '|'; see http://octave.org/doxygen/3.6/d3/d9c/gl2ps_8c_source.html#1343. [hist/hist/src/TFormula.cxx:1741]: (style) Array index 'i' is used before limits check.; [hist/hist/src/TFormula.cxx:1810]: (style) Array index 'i' is used before limits check.; [hist/hist/src/TGraphSmooth.cxx:173]: (style) Array index 'imin' is used before limits check; [hist/hist/src/TPrincipal.cxx:714]: (error) Memory leak: hX; [hist/hist/src/TPrincipal.cxx:714]: (error) Memory leak: hD; [hist/hist/src/TPrincipal.cxx:714]: (error) Memory leak: hP. [hist/histpainter/src/TGraph2DPainter.cxx:416]: (style) Array index 'js' is used before limits check.; [hist/histpainter/src/TGraph2DPainter.cxx:455]: (style) Array index 'js' is used before limits check.; [interpreter/llvm/src/tools/bugpoint/ToolRunner.cpp:386]: (error) When Pos==CommandLine.size(), CommandLine[Pos] is out of bounds. +Prefer prefix ++/-- operators for non-primitive types",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1239
https://github.com/root-project/root/pull/1239:235,Availability,error,error,235,"[graf2d/asimage/src/libAfterImage/afterbase.c:1282]: (style) Array index 'i' is used before limits check; [graf2d/asimage/src/libAfterImage/libungif/gifalloc.c:61]: (error) Memory leak: Object; [graf2d/win32gdk/src/TGWin32.cxx:4540]: (error) Memory leak: GIFarr; [graf3d/eve/src/TEveCalo2DGL.cxx:169]: (error) Memory leak: sliceVal; [graf3d/eve/src/TEveCalo2DGL.cxx:169]: (error) Memory leak: sliceValRef; [graf3d/eve/src/TEveCalo2DGL.cxx:369]: (error) Memory leak: sliceValsUp; [graf3d/eve/src/TEveCalo2DGL.cxx:369]: (error) Memory leak: sliceValsLow; [graf3d/eve/src/TEveCalo2DGL.cxx:369]: (error) Memory leak: sliceValsUpRef; [graf3d/eve/src/TEveCalo2DGL.cxx:369]: (error) Memory leak: sliceValsLowRef; [graf3d/eve/src/TEvePointSet.cxx:354]: (error) Memory leak: subarr. [graf3d/gl/src/gl2ps.cxx:1382] -> [graf3d/gl/src/gl2ps.cxx:1382]: (style) Same expression on both sides of '|'; see http://octave.org/doxygen/3.6/d3/d9c/gl2ps_8c_source.html#1343. [hist/hist/src/TFormula.cxx:1741]: (style) Array index 'i' is used before limits check.; [hist/hist/src/TFormula.cxx:1810]: (style) Array index 'i' is used before limits check.; [hist/hist/src/TGraphSmooth.cxx:173]: (style) Array index 'imin' is used before limits check; [hist/hist/src/TPrincipal.cxx:714]: (error) Memory leak: hX; [hist/hist/src/TPrincipal.cxx:714]: (error) Memory leak: hD; [hist/hist/src/TPrincipal.cxx:714]: (error) Memory leak: hP. [hist/histpainter/src/TGraph2DPainter.cxx:416]: (style) Array index 'js' is used before limits check.; [hist/histpainter/src/TGraph2DPainter.cxx:455]: (style) Array index 'js' is used before limits check.; [interpreter/llvm/src/tools/bugpoint/ToolRunner.cpp:386]: (error) When Pos==CommandLine.size(), CommandLine[Pos] is out of bounds. +Prefer prefix ++/-- operators for non-primitive types",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1239
https://github.com/root-project/root/pull/1239:303,Availability,error,error,303,"[graf2d/asimage/src/libAfterImage/afterbase.c:1282]: (style) Array index 'i' is used before limits check; [graf2d/asimage/src/libAfterImage/libungif/gifalloc.c:61]: (error) Memory leak: Object; [graf2d/win32gdk/src/TGWin32.cxx:4540]: (error) Memory leak: GIFarr; [graf3d/eve/src/TEveCalo2DGL.cxx:169]: (error) Memory leak: sliceVal; [graf3d/eve/src/TEveCalo2DGL.cxx:169]: (error) Memory leak: sliceValRef; [graf3d/eve/src/TEveCalo2DGL.cxx:369]: (error) Memory leak: sliceValsUp; [graf3d/eve/src/TEveCalo2DGL.cxx:369]: (error) Memory leak: sliceValsLow; [graf3d/eve/src/TEveCalo2DGL.cxx:369]: (error) Memory leak: sliceValsUpRef; [graf3d/eve/src/TEveCalo2DGL.cxx:369]: (error) Memory leak: sliceValsLowRef; [graf3d/eve/src/TEvePointSet.cxx:354]: (error) Memory leak: subarr. [graf3d/gl/src/gl2ps.cxx:1382] -> [graf3d/gl/src/gl2ps.cxx:1382]: (style) Same expression on both sides of '|'; see http://octave.org/doxygen/3.6/d3/d9c/gl2ps_8c_source.html#1343. [hist/hist/src/TFormula.cxx:1741]: (style) Array index 'i' is used before limits check.; [hist/hist/src/TFormula.cxx:1810]: (style) Array index 'i' is used before limits check.; [hist/hist/src/TGraphSmooth.cxx:173]: (style) Array index 'imin' is used before limits check; [hist/hist/src/TPrincipal.cxx:714]: (error) Memory leak: hX; [hist/hist/src/TPrincipal.cxx:714]: (error) Memory leak: hD; [hist/hist/src/TPrincipal.cxx:714]: (error) Memory leak: hP. [hist/histpainter/src/TGraph2DPainter.cxx:416]: (style) Array index 'js' is used before limits check.; [hist/histpainter/src/TGraph2DPainter.cxx:455]: (style) Array index 'js' is used before limits check.; [interpreter/llvm/src/tools/bugpoint/ToolRunner.cpp:386]: (error) When Pos==CommandLine.size(), CommandLine[Pos] is out of bounds. +Prefer prefix ++/-- operators for non-primitive types",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1239
https://github.com/root-project/root/pull/1239:373,Availability,error,error,373,"[graf2d/asimage/src/libAfterImage/afterbase.c:1282]: (style) Array index 'i' is used before limits check; [graf2d/asimage/src/libAfterImage/libungif/gifalloc.c:61]: (error) Memory leak: Object; [graf2d/win32gdk/src/TGWin32.cxx:4540]: (error) Memory leak: GIFarr; [graf3d/eve/src/TEveCalo2DGL.cxx:169]: (error) Memory leak: sliceVal; [graf3d/eve/src/TEveCalo2DGL.cxx:169]: (error) Memory leak: sliceValRef; [graf3d/eve/src/TEveCalo2DGL.cxx:369]: (error) Memory leak: sliceValsUp; [graf3d/eve/src/TEveCalo2DGL.cxx:369]: (error) Memory leak: sliceValsLow; [graf3d/eve/src/TEveCalo2DGL.cxx:369]: (error) Memory leak: sliceValsUpRef; [graf3d/eve/src/TEveCalo2DGL.cxx:369]: (error) Memory leak: sliceValsLowRef; [graf3d/eve/src/TEvePointSet.cxx:354]: (error) Memory leak: subarr. [graf3d/gl/src/gl2ps.cxx:1382] -> [graf3d/gl/src/gl2ps.cxx:1382]: (style) Same expression on both sides of '|'; see http://octave.org/doxygen/3.6/d3/d9c/gl2ps_8c_source.html#1343. [hist/hist/src/TFormula.cxx:1741]: (style) Array index 'i' is used before limits check.; [hist/hist/src/TFormula.cxx:1810]: (style) Array index 'i' is used before limits check.; [hist/hist/src/TGraphSmooth.cxx:173]: (style) Array index 'imin' is used before limits check; [hist/hist/src/TPrincipal.cxx:714]: (error) Memory leak: hX; [hist/hist/src/TPrincipal.cxx:714]: (error) Memory leak: hD; [hist/hist/src/TPrincipal.cxx:714]: (error) Memory leak: hP. [hist/histpainter/src/TGraph2DPainter.cxx:416]: (style) Array index 'js' is used before limits check.; [hist/histpainter/src/TGraph2DPainter.cxx:455]: (style) Array index 'js' is used before limits check.; [interpreter/llvm/src/tools/bugpoint/ToolRunner.cpp:386]: (error) When Pos==CommandLine.size(), CommandLine[Pos] is out of bounds. +Prefer prefix ++/-- operators for non-primitive types",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1239
https://github.com/root-project/root/pull/1239:446,Availability,error,error,446,"[graf2d/asimage/src/libAfterImage/afterbase.c:1282]: (style) Array index 'i' is used before limits check; [graf2d/asimage/src/libAfterImage/libungif/gifalloc.c:61]: (error) Memory leak: Object; [graf2d/win32gdk/src/TGWin32.cxx:4540]: (error) Memory leak: GIFarr; [graf3d/eve/src/TEveCalo2DGL.cxx:169]: (error) Memory leak: sliceVal; [graf3d/eve/src/TEveCalo2DGL.cxx:169]: (error) Memory leak: sliceValRef; [graf3d/eve/src/TEveCalo2DGL.cxx:369]: (error) Memory leak: sliceValsUp; [graf3d/eve/src/TEveCalo2DGL.cxx:369]: (error) Memory leak: sliceValsLow; [graf3d/eve/src/TEveCalo2DGL.cxx:369]: (error) Memory leak: sliceValsUpRef; [graf3d/eve/src/TEveCalo2DGL.cxx:369]: (error) Memory leak: sliceValsLowRef; [graf3d/eve/src/TEvePointSet.cxx:354]: (error) Memory leak: subarr. [graf3d/gl/src/gl2ps.cxx:1382] -> [graf3d/gl/src/gl2ps.cxx:1382]: (style) Same expression on both sides of '|'; see http://octave.org/doxygen/3.6/d3/d9c/gl2ps_8c_source.html#1343. [hist/hist/src/TFormula.cxx:1741]: (style) Array index 'i' is used before limits check.; [hist/hist/src/TFormula.cxx:1810]: (style) Array index 'i' is used before limits check.; [hist/hist/src/TGraphSmooth.cxx:173]: (style) Array index 'imin' is used before limits check; [hist/hist/src/TPrincipal.cxx:714]: (error) Memory leak: hX; [hist/hist/src/TPrincipal.cxx:714]: (error) Memory leak: hD; [hist/hist/src/TPrincipal.cxx:714]: (error) Memory leak: hP. [hist/histpainter/src/TGraph2DPainter.cxx:416]: (style) Array index 'js' is used before limits check.; [hist/histpainter/src/TGraph2DPainter.cxx:455]: (style) Array index 'js' is used before limits check.; [interpreter/llvm/src/tools/bugpoint/ToolRunner.cpp:386]: (error) When Pos==CommandLine.size(), CommandLine[Pos] is out of bounds. +Prefer prefix ++/-- operators for non-primitive types",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1239
https://github.com/root-project/root/pull/1239:519,Availability,error,error,519,"[graf2d/asimage/src/libAfterImage/afterbase.c:1282]: (style) Array index 'i' is used before limits check; [graf2d/asimage/src/libAfterImage/libungif/gifalloc.c:61]: (error) Memory leak: Object; [graf2d/win32gdk/src/TGWin32.cxx:4540]: (error) Memory leak: GIFarr; [graf3d/eve/src/TEveCalo2DGL.cxx:169]: (error) Memory leak: sliceVal; [graf3d/eve/src/TEveCalo2DGL.cxx:169]: (error) Memory leak: sliceValRef; [graf3d/eve/src/TEveCalo2DGL.cxx:369]: (error) Memory leak: sliceValsUp; [graf3d/eve/src/TEveCalo2DGL.cxx:369]: (error) Memory leak: sliceValsLow; [graf3d/eve/src/TEveCalo2DGL.cxx:369]: (error) Memory leak: sliceValsUpRef; [graf3d/eve/src/TEveCalo2DGL.cxx:369]: (error) Memory leak: sliceValsLowRef; [graf3d/eve/src/TEvePointSet.cxx:354]: (error) Memory leak: subarr. [graf3d/gl/src/gl2ps.cxx:1382] -> [graf3d/gl/src/gl2ps.cxx:1382]: (style) Same expression on both sides of '|'; see http://octave.org/doxygen/3.6/d3/d9c/gl2ps_8c_source.html#1343. [hist/hist/src/TFormula.cxx:1741]: (style) Array index 'i' is used before limits check.; [hist/hist/src/TFormula.cxx:1810]: (style) Array index 'i' is used before limits check.; [hist/hist/src/TGraphSmooth.cxx:173]: (style) Array index 'imin' is used before limits check; [hist/hist/src/TPrincipal.cxx:714]: (error) Memory leak: hX; [hist/hist/src/TPrincipal.cxx:714]: (error) Memory leak: hD; [hist/hist/src/TPrincipal.cxx:714]: (error) Memory leak: hP. [hist/histpainter/src/TGraph2DPainter.cxx:416]: (style) Array index 'js' is used before limits check.; [hist/histpainter/src/TGraph2DPainter.cxx:455]: (style) Array index 'js' is used before limits check.; [interpreter/llvm/src/tools/bugpoint/ToolRunner.cpp:386]: (error) When Pos==CommandLine.size(), CommandLine[Pos] is out of bounds. +Prefer prefix ++/-- operators for non-primitive types",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1239
https://github.com/root-project/root/pull/1239:593,Availability,error,error,593,"[graf2d/asimage/src/libAfterImage/afterbase.c:1282]: (style) Array index 'i' is used before limits check; [graf2d/asimage/src/libAfterImage/libungif/gifalloc.c:61]: (error) Memory leak: Object; [graf2d/win32gdk/src/TGWin32.cxx:4540]: (error) Memory leak: GIFarr; [graf3d/eve/src/TEveCalo2DGL.cxx:169]: (error) Memory leak: sliceVal; [graf3d/eve/src/TEveCalo2DGL.cxx:169]: (error) Memory leak: sliceValRef; [graf3d/eve/src/TEveCalo2DGL.cxx:369]: (error) Memory leak: sliceValsUp; [graf3d/eve/src/TEveCalo2DGL.cxx:369]: (error) Memory leak: sliceValsLow; [graf3d/eve/src/TEveCalo2DGL.cxx:369]: (error) Memory leak: sliceValsUpRef; [graf3d/eve/src/TEveCalo2DGL.cxx:369]: (error) Memory leak: sliceValsLowRef; [graf3d/eve/src/TEvePointSet.cxx:354]: (error) Memory leak: subarr. [graf3d/gl/src/gl2ps.cxx:1382] -> [graf3d/gl/src/gl2ps.cxx:1382]: (style) Same expression on both sides of '|'; see http://octave.org/doxygen/3.6/d3/d9c/gl2ps_8c_source.html#1343. [hist/hist/src/TFormula.cxx:1741]: (style) Array index 'i' is used before limits check.; [hist/hist/src/TFormula.cxx:1810]: (style) Array index 'i' is used before limits check.; [hist/hist/src/TGraphSmooth.cxx:173]: (style) Array index 'imin' is used before limits check; [hist/hist/src/TPrincipal.cxx:714]: (error) Memory leak: hX; [hist/hist/src/TPrincipal.cxx:714]: (error) Memory leak: hD; [hist/hist/src/TPrincipal.cxx:714]: (error) Memory leak: hP. [hist/histpainter/src/TGraph2DPainter.cxx:416]: (style) Array index 'js' is used before limits check.; [hist/histpainter/src/TGraph2DPainter.cxx:455]: (style) Array index 'js' is used before limits check.; [interpreter/llvm/src/tools/bugpoint/ToolRunner.cpp:386]: (error) When Pos==CommandLine.size(), CommandLine[Pos] is out of bounds. +Prefer prefix ++/-- operators for non-primitive types",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1239
https://github.com/root-project/root/pull/1239:669,Availability,error,error,669,"[graf2d/asimage/src/libAfterImage/afterbase.c:1282]: (style) Array index 'i' is used before limits check; [graf2d/asimage/src/libAfterImage/libungif/gifalloc.c:61]: (error) Memory leak: Object; [graf2d/win32gdk/src/TGWin32.cxx:4540]: (error) Memory leak: GIFarr; [graf3d/eve/src/TEveCalo2DGL.cxx:169]: (error) Memory leak: sliceVal; [graf3d/eve/src/TEveCalo2DGL.cxx:169]: (error) Memory leak: sliceValRef; [graf3d/eve/src/TEveCalo2DGL.cxx:369]: (error) Memory leak: sliceValsUp; [graf3d/eve/src/TEveCalo2DGL.cxx:369]: (error) Memory leak: sliceValsLow; [graf3d/eve/src/TEveCalo2DGL.cxx:369]: (error) Memory leak: sliceValsUpRef; [graf3d/eve/src/TEveCalo2DGL.cxx:369]: (error) Memory leak: sliceValsLowRef; [graf3d/eve/src/TEvePointSet.cxx:354]: (error) Memory leak: subarr. [graf3d/gl/src/gl2ps.cxx:1382] -> [graf3d/gl/src/gl2ps.cxx:1382]: (style) Same expression on both sides of '|'; see http://octave.org/doxygen/3.6/d3/d9c/gl2ps_8c_source.html#1343. [hist/hist/src/TFormula.cxx:1741]: (style) Array index 'i' is used before limits check.; [hist/hist/src/TFormula.cxx:1810]: (style) Array index 'i' is used before limits check.; [hist/hist/src/TGraphSmooth.cxx:173]: (style) Array index 'imin' is used before limits check; [hist/hist/src/TPrincipal.cxx:714]: (error) Memory leak: hX; [hist/hist/src/TPrincipal.cxx:714]: (error) Memory leak: hD; [hist/hist/src/TPrincipal.cxx:714]: (error) Memory leak: hP. [hist/histpainter/src/TGraph2DPainter.cxx:416]: (style) Array index 'js' is used before limits check.; [hist/histpainter/src/TGraph2DPainter.cxx:455]: (style) Array index 'js' is used before limits check.; [interpreter/llvm/src/tools/bugpoint/ToolRunner.cpp:386]: (error) When Pos==CommandLine.size(), CommandLine[Pos] is out of bounds. +Prefer prefix ++/-- operators for non-primitive types",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1239
https://github.com/root-project/root/pull/1239:746,Availability,error,error,746,"[graf2d/asimage/src/libAfterImage/afterbase.c:1282]: (style) Array index 'i' is used before limits check; [graf2d/asimage/src/libAfterImage/libungif/gifalloc.c:61]: (error) Memory leak: Object; [graf2d/win32gdk/src/TGWin32.cxx:4540]: (error) Memory leak: GIFarr; [graf3d/eve/src/TEveCalo2DGL.cxx:169]: (error) Memory leak: sliceVal; [graf3d/eve/src/TEveCalo2DGL.cxx:169]: (error) Memory leak: sliceValRef; [graf3d/eve/src/TEveCalo2DGL.cxx:369]: (error) Memory leak: sliceValsUp; [graf3d/eve/src/TEveCalo2DGL.cxx:369]: (error) Memory leak: sliceValsLow; [graf3d/eve/src/TEveCalo2DGL.cxx:369]: (error) Memory leak: sliceValsUpRef; [graf3d/eve/src/TEveCalo2DGL.cxx:369]: (error) Memory leak: sliceValsLowRef; [graf3d/eve/src/TEvePointSet.cxx:354]: (error) Memory leak: subarr. [graf3d/gl/src/gl2ps.cxx:1382] -> [graf3d/gl/src/gl2ps.cxx:1382]: (style) Same expression on both sides of '|'; see http://octave.org/doxygen/3.6/d3/d9c/gl2ps_8c_source.html#1343. [hist/hist/src/TFormula.cxx:1741]: (style) Array index 'i' is used before limits check.; [hist/hist/src/TFormula.cxx:1810]: (style) Array index 'i' is used before limits check.; [hist/hist/src/TGraphSmooth.cxx:173]: (style) Array index 'imin' is used before limits check; [hist/hist/src/TPrincipal.cxx:714]: (error) Memory leak: hX; [hist/hist/src/TPrincipal.cxx:714]: (error) Memory leak: hD; [hist/hist/src/TPrincipal.cxx:714]: (error) Memory leak: hP. [hist/histpainter/src/TGraph2DPainter.cxx:416]: (style) Array index 'js' is used before limits check.; [hist/histpainter/src/TGraph2DPainter.cxx:455]: (style) Array index 'js' is used before limits check.; [interpreter/llvm/src/tools/bugpoint/ToolRunner.cpp:386]: (error) When Pos==CommandLine.size(), CommandLine[Pos] is out of bounds. +Prefer prefix ++/-- operators for non-primitive types",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1239
https://github.com/root-project/root/pull/1239:1263,Availability,error,error,1263,"[graf2d/asimage/src/libAfterImage/afterbase.c:1282]: (style) Array index 'i' is used before limits check; [graf2d/asimage/src/libAfterImage/libungif/gifalloc.c:61]: (error) Memory leak: Object; [graf2d/win32gdk/src/TGWin32.cxx:4540]: (error) Memory leak: GIFarr; [graf3d/eve/src/TEveCalo2DGL.cxx:169]: (error) Memory leak: sliceVal; [graf3d/eve/src/TEveCalo2DGL.cxx:169]: (error) Memory leak: sliceValRef; [graf3d/eve/src/TEveCalo2DGL.cxx:369]: (error) Memory leak: sliceValsUp; [graf3d/eve/src/TEveCalo2DGL.cxx:369]: (error) Memory leak: sliceValsLow; [graf3d/eve/src/TEveCalo2DGL.cxx:369]: (error) Memory leak: sliceValsUpRef; [graf3d/eve/src/TEveCalo2DGL.cxx:369]: (error) Memory leak: sliceValsLowRef; [graf3d/eve/src/TEvePointSet.cxx:354]: (error) Memory leak: subarr. [graf3d/gl/src/gl2ps.cxx:1382] -> [graf3d/gl/src/gl2ps.cxx:1382]: (style) Same expression on both sides of '|'; see http://octave.org/doxygen/3.6/d3/d9c/gl2ps_8c_source.html#1343. [hist/hist/src/TFormula.cxx:1741]: (style) Array index 'i' is used before limits check.; [hist/hist/src/TFormula.cxx:1810]: (style) Array index 'i' is used before limits check.; [hist/hist/src/TGraphSmooth.cxx:173]: (style) Array index 'imin' is used before limits check; [hist/hist/src/TPrincipal.cxx:714]: (error) Memory leak: hX; [hist/hist/src/TPrincipal.cxx:714]: (error) Memory leak: hD; [hist/hist/src/TPrincipal.cxx:714]: (error) Memory leak: hP. [hist/histpainter/src/TGraph2DPainter.cxx:416]: (style) Array index 'js' is used before limits check.; [hist/histpainter/src/TGraph2DPainter.cxx:455]: (style) Array index 'js' is used before limits check.; [interpreter/llvm/src/tools/bugpoint/ToolRunner.cpp:386]: (error) When Pos==CommandLine.size(), CommandLine[Pos] is out of bounds. +Prefer prefix ++/-- operators for non-primitive types",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1239
https://github.com/root-project/root/pull/1239:1324,Availability,error,error,1324,"[graf2d/asimage/src/libAfterImage/afterbase.c:1282]: (style) Array index 'i' is used before limits check; [graf2d/asimage/src/libAfterImage/libungif/gifalloc.c:61]: (error) Memory leak: Object; [graf2d/win32gdk/src/TGWin32.cxx:4540]: (error) Memory leak: GIFarr; [graf3d/eve/src/TEveCalo2DGL.cxx:169]: (error) Memory leak: sliceVal; [graf3d/eve/src/TEveCalo2DGL.cxx:169]: (error) Memory leak: sliceValRef; [graf3d/eve/src/TEveCalo2DGL.cxx:369]: (error) Memory leak: sliceValsUp; [graf3d/eve/src/TEveCalo2DGL.cxx:369]: (error) Memory leak: sliceValsLow; [graf3d/eve/src/TEveCalo2DGL.cxx:369]: (error) Memory leak: sliceValsUpRef; [graf3d/eve/src/TEveCalo2DGL.cxx:369]: (error) Memory leak: sliceValsLowRef; [graf3d/eve/src/TEvePointSet.cxx:354]: (error) Memory leak: subarr. [graf3d/gl/src/gl2ps.cxx:1382] -> [graf3d/gl/src/gl2ps.cxx:1382]: (style) Same expression on both sides of '|'; see http://octave.org/doxygen/3.6/d3/d9c/gl2ps_8c_source.html#1343. [hist/hist/src/TFormula.cxx:1741]: (style) Array index 'i' is used before limits check.; [hist/hist/src/TFormula.cxx:1810]: (style) Array index 'i' is used before limits check.; [hist/hist/src/TGraphSmooth.cxx:173]: (style) Array index 'imin' is used before limits check; [hist/hist/src/TPrincipal.cxx:714]: (error) Memory leak: hX; [hist/hist/src/TPrincipal.cxx:714]: (error) Memory leak: hD; [hist/hist/src/TPrincipal.cxx:714]: (error) Memory leak: hP. [hist/histpainter/src/TGraph2DPainter.cxx:416]: (style) Array index 'js' is used before limits check.; [hist/histpainter/src/TGraph2DPainter.cxx:455]: (style) Array index 'js' is used before limits check.; [interpreter/llvm/src/tools/bugpoint/ToolRunner.cpp:386]: (error) When Pos==CommandLine.size(), CommandLine[Pos] is out of bounds. +Prefer prefix ++/-- operators for non-primitive types",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1239
https://github.com/root-project/root/pull/1239:1385,Availability,error,error,1385,"[graf2d/asimage/src/libAfterImage/afterbase.c:1282]: (style) Array index 'i' is used before limits check; [graf2d/asimage/src/libAfterImage/libungif/gifalloc.c:61]: (error) Memory leak: Object; [graf2d/win32gdk/src/TGWin32.cxx:4540]: (error) Memory leak: GIFarr; [graf3d/eve/src/TEveCalo2DGL.cxx:169]: (error) Memory leak: sliceVal; [graf3d/eve/src/TEveCalo2DGL.cxx:169]: (error) Memory leak: sliceValRef; [graf3d/eve/src/TEveCalo2DGL.cxx:369]: (error) Memory leak: sliceValsUp; [graf3d/eve/src/TEveCalo2DGL.cxx:369]: (error) Memory leak: sliceValsLow; [graf3d/eve/src/TEveCalo2DGL.cxx:369]: (error) Memory leak: sliceValsUpRef; [graf3d/eve/src/TEveCalo2DGL.cxx:369]: (error) Memory leak: sliceValsLowRef; [graf3d/eve/src/TEvePointSet.cxx:354]: (error) Memory leak: subarr. [graf3d/gl/src/gl2ps.cxx:1382] -> [graf3d/gl/src/gl2ps.cxx:1382]: (style) Same expression on both sides of '|'; see http://octave.org/doxygen/3.6/d3/d9c/gl2ps_8c_source.html#1343. [hist/hist/src/TFormula.cxx:1741]: (style) Array index 'i' is used before limits check.; [hist/hist/src/TFormula.cxx:1810]: (style) Array index 'i' is used before limits check.; [hist/hist/src/TGraphSmooth.cxx:173]: (style) Array index 'imin' is used before limits check; [hist/hist/src/TPrincipal.cxx:714]: (error) Memory leak: hX; [hist/hist/src/TPrincipal.cxx:714]: (error) Memory leak: hD; [hist/hist/src/TPrincipal.cxx:714]: (error) Memory leak: hP. [hist/histpainter/src/TGraph2DPainter.cxx:416]: (style) Array index 'js' is used before limits check.; [hist/histpainter/src/TGraph2DPainter.cxx:455]: (style) Array index 'js' is used before limits check.; [interpreter/llvm/src/tools/bugpoint/ToolRunner.cpp:386]: (error) When Pos==CommandLine.size(), CommandLine[Pos] is out of bounds. +Prefer prefix ++/-- operators for non-primitive types",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1239
https://github.com/root-project/root/pull/1239:1674,Availability,error,error,1674,"[graf2d/asimage/src/libAfterImage/afterbase.c:1282]: (style) Array index 'i' is used before limits check; [graf2d/asimage/src/libAfterImage/libungif/gifalloc.c:61]: (error) Memory leak: Object; [graf2d/win32gdk/src/TGWin32.cxx:4540]: (error) Memory leak: GIFarr; [graf3d/eve/src/TEveCalo2DGL.cxx:169]: (error) Memory leak: sliceVal; [graf3d/eve/src/TEveCalo2DGL.cxx:169]: (error) Memory leak: sliceValRef; [graf3d/eve/src/TEveCalo2DGL.cxx:369]: (error) Memory leak: sliceValsUp; [graf3d/eve/src/TEveCalo2DGL.cxx:369]: (error) Memory leak: sliceValsLow; [graf3d/eve/src/TEveCalo2DGL.cxx:369]: (error) Memory leak: sliceValsUpRef; [graf3d/eve/src/TEveCalo2DGL.cxx:369]: (error) Memory leak: sliceValsLowRef; [graf3d/eve/src/TEvePointSet.cxx:354]: (error) Memory leak: subarr. [graf3d/gl/src/gl2ps.cxx:1382] -> [graf3d/gl/src/gl2ps.cxx:1382]: (style) Same expression on both sides of '|'; see http://octave.org/doxygen/3.6/d3/d9c/gl2ps_8c_source.html#1343. [hist/hist/src/TFormula.cxx:1741]: (style) Array index 'i' is used before limits check.; [hist/hist/src/TFormula.cxx:1810]: (style) Array index 'i' is used before limits check.; [hist/hist/src/TGraphSmooth.cxx:173]: (style) Array index 'imin' is used before limits check; [hist/hist/src/TPrincipal.cxx:714]: (error) Memory leak: hX; [hist/hist/src/TPrincipal.cxx:714]: (error) Memory leak: hD; [hist/hist/src/TPrincipal.cxx:714]: (error) Memory leak: hP. [hist/histpainter/src/TGraph2DPainter.cxx:416]: (style) Array index 'js' is used before limits check.; [hist/histpainter/src/TGraph2DPainter.cxx:455]: (style) Array index 'js' is used before limits check.; [interpreter/llvm/src/tools/bugpoint/ToolRunner.cpp:386]: (error) When Pos==CommandLine.size(), CommandLine[Pos] is out of bounds. +Prefer prefix ++/-- operators for non-primitive types",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1239
https://github.com/root-project/root/pull/1242:121,Performance,perform,performance,121,"Clang has a quite new LTO mode that doesn't blow up linking; times as much as with vanilla LTO but still brings similar; performance improvements. It's quite easy for us to migrate; to this new mode, so it would make sense to just activate; it in Optimized builds where users are obviously looking; for performance. More information: https://clang.llvm.org/docs/ThinLTO.html",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1242
https://github.com/root-project/root/pull/1242:247,Performance,Optimiz,Optimized,247,"Clang has a quite new LTO mode that doesn't blow up linking; times as much as with vanilla LTO but still brings similar; performance improvements. It's quite easy for us to migrate; to this new mode, so it would make sense to just activate; it in Optimized builds where users are obviously looking; for performance. More information: https://clang.llvm.org/docs/ThinLTO.html",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1242
https://github.com/root-project/root/pull/1242:303,Performance,perform,performance,303,"Clang has a quite new LTO mode that doesn't blow up linking; times as much as with vanilla LTO but still brings similar; performance improvements. It's quite easy for us to migrate; to this new mode, so it would make sense to just activate; it in Optimized builds where users are obviously looking; for performance. More information: https://clang.llvm.org/docs/ThinLTO.html",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1242
https://github.com/root-project/root/pull/1243:220,Modifiability,variab,variable,220,In CEF and Qt5WebEngine set window size. Use for FitPanel 300x500 as initial size for demonstration. Also chrome browser allows to set window size and show HTML page without typical browser decoration; One can set shell variable WEBGUI_WHERE which allows to change default behavior,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1243
https://github.com/root-project/root/pull/1246:85,Energy Efficiency,reduce,reduce,85,"We don't use the PCH with modules, so we don't need to build it.; Should also really reduce building times with modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1246
https://github.com/root-project/root/pull/1247:171,Integrability,depend,dependency,171,"Currently there is a chance that rootcling includes and builds; the 'complex' dictionary before it is built, which will cause; the build to fail. To fix this we need this dependency here. The specific line that includes the complex header is; `core/dictgen/src/rootcling_impl.cxx:3045`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1247
https://github.com/root-project/root/pull/1248:0,Testability,Assert,Assert,0,Assert does not work on Linux?,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1248
https://github.com/root-project/root/pull/1253:20,Availability,down,downloaded,20,Also now verify all downloaded software before installing.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1253
https://github.com/root-project/root/pull/1253:47,Deployability,install,installing,47,Also now verify all downloaded software before installing.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1253
https://github.com/root-project/root/pull/1254:5,Deployability,patch,patch,5,"This patch series should finish up the cleanup of `core/zip` (well, for now...). Beyond fixing up some variable names and compiler warnings, this separates out the implementation of reading the ROOT framing format (the magic 9 byte headers) from the inflate implementation for the old compression algorithm..",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1254
https://github.com/root-project/root/pull/1254:103,Modifiability,variab,variable,103,"This patch series should finish up the cleanup of `core/zip` (well, for now...). Beyond fixing up some variable names and compiler warnings, this separates out the implementation of reading the ROOT framing format (the magic 9 byte headers) from the inflate implementation for the old compression algorithm..",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1254
https://github.com/root-project/root/pull/1256:112,Availability,error,error,112,"ldd has problems with linking tmva due to this function in the header. Outlining it fixes it. ```; /usr/bin/ld: error: can't create dynamic relocation R_X86_64_TLSLD against symbol: TMVA::BDTEventWrapper::GetVarIndex()::fVarIndex in readonly segment; recompile object files with -fPIC; >>> defined in CMakeFiles/TMVA.dir/src/DecisionTree.cxx.o; >>> referenced by BDTEventWrapper.h:64 (/home/axel/build/root/branches/v6-10/cmake/include/TMVA/BDTEventWrapper.h:64); >>> CMakeFiles/TMVA.dir/src/DecisionTree.cxx.o:(void std::__introsort_loop<__gnu_cxx::__normal_iterator<TMVA::BDTEventWrapper*, std::vector<TMVA::BDTEventWrapper, std::allocator<TMVA::BDTEventWrapper> > >, long, __gnu_cxx::__ops::_Iter_less_iter>(__gnu_cxx::__normal_iterator<TMVA::BDTEventWrapper*, std::vector<TMVA::BDTEventWrapper, std::allocator<TMVA::BDTEventWrapper> > >, __gnu_cxx::__normal_iterator<TMVA::BDTEventWrapper*, std::vector<TMVA::BDTEventWrapper, std::allocator<TMVA::BDTEventWrapper> > >, long, __gnu_cxx::__ops::_Iter_less_iter) (.isra.194)); ```. While it'd be great to submit a reproducer to lld (I didn't manage to create one within the few minutes I invested), this change might be a cheap workaround. Unless it's a hot function where outlining is a real cost?",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1256
https://github.com/root-project/root/pull/1257:70,Integrability,message,message,70,"See https://reviews.llvm.org/D39416 for more details. Original commit message:. The MultiplexExternalSemaSource doesn't correctly overload the getModule function,; causing the multiplexer to not forward this call as intended.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1257
https://github.com/root-project/root/pull/1263:20,Performance,load,load,20,"We still need it to load the library before we get the headers and; initializie some class infos, so we can't just remove it like that.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1263
https://github.com/root-project/root/pull/1267:62,Performance,load,loading,62,"We actually need those callbacks as they are responsible for; loading decls from unresolved identifiers, which then actually; triggers the loading of the specific header (or in our case; the specific C++ modules). For now we need this as long as the modules are based on the; rootmap mechanism.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1267
https://github.com/root-project/root/pull/1267:139,Performance,load,loading,139,"We actually need those callbacks as they are responsible for; loading decls from unresolved identifiers, which then actually; triggers the loading of the specific header (or in our case; the specific C++ modules). For now we need this as long as the modules are based on the; rootmap mechanism.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1267
https://github.com/root-project/root/pull/1268:5,Deployability,patch,patch,5,"This patch reimplements the broken patch in clang: ""Fix fwddecls of templates; with tmplt arg defauls coming from dictionaries (CMS / std::less). (#849)"". And partially reimplements:""Disable diags of dupe default args (func, templt); temporarily."". It also fixes the failing cling test Autoloading/AutoForwarding.C which; is visible when building root with -Dclingtest=On.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1268
https://github.com/root-project/root/pull/1268:35,Deployability,patch,patch,35,"This patch reimplements the broken patch in clang: ""Fix fwddecls of templates; with tmplt arg defauls coming from dictionaries (CMS / std::less). (#849)"". And partially reimplements:""Disable diags of dupe default args (func, templt); temporarily."". It also fixes the failing cling test Autoloading/AutoForwarding.C which; is visible when building root with -Dclingtest=On.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1268
https://github.com/root-project/root/pull/1268:281,Testability,test,test,281,"This patch reimplements the broken patch in clang: ""Fix fwddecls of templates; with tmplt arg defauls coming from dictionaries (CMS / std::less). (#849)"". And partially reimplements:""Disable diags of dupe default args (func, templt); temporarily."". It also fixes the failing cling test Autoloading/AutoForwarding.C which; is visible when building root with -Dclingtest=On.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1268
https://github.com/root-project/root/pull/1273:25,Deployability,patch,patch,25,"We already reverted this patch, but the LLVM upgrade to 5.0 seems; to have ignored this reversion.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1273
https://github.com/root-project/root/pull/1273:45,Deployability,upgrade,upgrade,45,"We already reverted this patch, but the LLVM upgrade to 5.0 seems; to have ignored this reversion.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1273
https://github.com/root-project/root/pull/1274:5,Deployability,patch,patch,5,"This patch hasn't landed in 5.0, so the LLVM upgrade overwrote this; patch without bringing in the upstreamed fixed version. Original commit message:. The default VFS for the FileManager should be created from the CompilerInvocation; instead of assuming there is none.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1274
https://github.com/root-project/root/pull/1274:45,Deployability,upgrade,upgrade,45,"This patch hasn't landed in 5.0, so the LLVM upgrade overwrote this; patch without bringing in the upstreamed fixed version. Original commit message:. The default VFS for the FileManager should be created from the CompilerInvocation; instead of assuming there is none.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1274
https://github.com/root-project/root/pull/1274:69,Deployability,patch,patch,69,"This patch hasn't landed in 5.0, so the LLVM upgrade overwrote this; patch without bringing in the upstreamed fixed version. Original commit message:. The default VFS for the FileManager should be created from the CompilerInvocation; instead of assuming there is none.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1274
https://github.com/root-project/root/pull/1274:141,Integrability,message,message,141,"This patch hasn't landed in 5.0, so the LLVM upgrade overwrote this; patch without bringing in the upstreamed fixed version. Original commit message:. The default VFS for the FileManager should be created from the CompilerInvocation; instead of assuming there is none.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1274
https://github.com/root-project/root/pull/1275:136,Availability,avail,available,136,"This PR enables the support to create Vectorized TFormula expression by adding a signature using ; ROOT::Double_v. The functionality is available if ROOT has been compiled with VecCore support, ; i.e. the macro R__HAS__VECCORE is defined",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1275
https://github.com/root-project/root/pull/1283:42,Modifiability,Config,Config,42,Moved the TThreadExecutor object to TMVA::Config. O.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1283
https://github.com/root-project/root/pull/1284:214,Deployability,patch,patch,214,We need to respect the existing ExternalASTSource when setting up the; interpreter. Otherwise the ASTReader (which is the existing source); doesn't receive the required callbacks to properly load C++ modules. This patch now creates a multiplexer that contains our new; ASTSource and the existing one if it's necessary. We also; no longer attach the existing sema source which seemingly; was only a workaround that only works for the special case; were the external sema source and the external AST source; are the same object.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1284
https://github.com/root-project/root/pull/1284:191,Performance,load,load,191,We need to respect the existing ExternalASTSource when setting up the; interpreter. Otherwise the ASTReader (which is the existing source); doesn't receive the required callbacks to properly load C++ modules. This patch now creates a multiplexer that contains our new; ASTSource and the existing one if it's necessary. We also; no longer attach the existing sema source which seemingly; was only a workaround that only works for the special case; were the external sema source and the external AST source; are the same object.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1284
https://github.com/root-project/root/pull/1285:18,Safety,avoid,avoid,18,This change is to avoid warnings from CMake 3.9.3 and newer on macOS.; See `cmake --help-policy CMP0068` for more information. Fixes [ROOT-9031](https://sft.its.cern.ch/jira/browse/ROOT-9031).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1285
https://github.com/root-project/root/pull/1287:864,Deployability,patch,patch,864,"Right now the ExternalASTSources in LLVM have an awkward way; of implementing their generation counters, which provide an; incrementing UID for versioning the AST when it is changed; lazily by the ExternalASTSource (for example when more decls; are). The current implementation is based on having an counter in; each ExternalASTSource, but each ExternalASTSource actually; only refers to the top most ExternalASTSource of the current; ASTContext, which means that the counter suddenly resets; when we add any kind of new ExternalASTSource (and we have; no way to work around this). Also, some ExternalASTSources; like the ASTReader make assumptions that they are the top; most ExternalASTSource which means that as soon as we; overwrite the ASTReader, we suddenly have two counters; running providing conflicting information to anyone; querying the counters. This patch merges all these counters into one counter; which is in the ASTContext. This should get rid of; any more counter desyncronization problems when we; attach our own external sources or when parts of the; code make invalid assumptions about which external; source is currently the top most one in the ASTContext. Patch is upstreamed via LLVM phabricator review D39714.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1287
https://github.com/root-project/root/pull/1287:1180,Deployability,Patch,Patch,1180,"Right now the ExternalASTSources in LLVM have an awkward way; of implementing their generation counters, which provide an; incrementing UID for versioning the AST when it is changed; lazily by the ExternalASTSource (for example when more decls; are). The current implementation is based on having an counter in; each ExternalASTSource, but each ExternalASTSource actually; only refers to the top most ExternalASTSource of the current; ASTContext, which means that the counter suddenly resets; when we add any kind of new ExternalASTSource (and we have; no way to work around this). Also, some ExternalASTSources; like the ASTReader make assumptions that they are the top; most ExternalASTSource which means that as soon as we; overwrite the ASTReader, we suddenly have two counters; running providing conflicting information to anyone; querying the counters. This patch merges all these counters into one counter; which is in the ASTContext. This should get rid of; any more counter desyncronization problems when we; attach our own external sources or when parts of the; code make invalid assumptions about which external; source is currently the top most one in the ASTContext. Patch is upstreamed via LLVM phabricator review D39714.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1287
https://github.com/root-project/root/pull/1291:636,Deployability,upgrade,upgrade,636,1. Use unique_ptr for owned objects. It is:; - THttpServer instance in TWebWindowManager; - TWebWindowWSHandler in TWebWindow; - move default constructors into source files; 2. Remove list of shared_ptr<TWebWindow> from window manager.; Window owned by the correspondent widget and automatically destroyed with the widget.; 3. Use object references in method arguments where object must exists.; 4. Provide documentation for all methods in TWebWindow and TWebWindowManager; 5. Small workaround for the case of broken websocket in civetweb. Appears when client does not regularly closes the socket. More investigation will be done after upgrade of civetweb code,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1291
https://github.com/root-project/root/pull/1295:58,Usability,feedback,feedback,58,Reported here: https://connect.microsoft.com/VisualStudio/feedback/details/3143729,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1295
https://github.com/root-project/root/pull/1297:16,Integrability,message,message,16,"Original commit message:; ""[tblgen] Remove uses of std::ptr_fun, it's removed in C++17."". @davidlt, does that fix ROOT-9085?",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1297
https://github.com/root-project/root/pull/1298:81,Testability,test,tests,81,When querying decls for information we can start a deserialization. This fixes 4 tests for runtime cxxmodules.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1298
https://github.com/root-project/root/pull/1299:875,Modifiability,extend,extended,875,"This implementation intends to pave the way for the support of tree/chain friends in TDataFrame MT. For that purpose, now TTreeProcessorMT stores the information about the friends of the processed tree/chain. In order to provide support for friends, this implementation proposes a new way of dealing with chains in TTreeProcessorMT. The old way consisted in operating file by file, obtaining a TTree from each file and then constructing a TTreeReader for the particular range a task was going to process in that TTree. The aforementioned implementation prevented the support for friend chains, since there was no chain to add the friends to, only trees. In this new implementation, TTreeProcessorMT always constructs a chain per TTreeView, from which TTreeReaders are created to operate on ranges of the chain. If necessary, friends could be added to that chain. I have also extended roottest-root-multicore-tp_process_imt to test the friends case.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1299
https://github.com/root-project/root/pull/1299:926,Testability,test,test,926,"This implementation intends to pave the way for the support of tree/chain friends in TDataFrame MT. For that purpose, now TTreeProcessorMT stores the information about the friends of the processed tree/chain. In order to provide support for friends, this implementation proposes a new way of dealing with chains in TTreeProcessorMT. The old way consisted in operating file by file, obtaining a TTree from each file and then constructing a TTreeReader for the particular range a task was going to process in that TTree. The aforementioned implementation prevented the support for friend chains, since there was no chain to add the friends to, only trees. In this new implementation, TTreeProcessorMT always constructs a chain per TTreeView, from which TTreeReaders are created to operate on ranges of the chain. If necessary, friends could be added to that chain. I have also extended roottest-root-multicore-tp_process_imt to test the friends case.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1299
https://github.com/root-project/root/pull/1300:374,Testability,test,test,374,"In some circumstance, the Translation Unit can devoid of any decl; useable by ClassInfo (i.e. it has only forward declaration and typedefs). This can happen at the beginning of the process when none of the; rootmap files declares a namespace. When this happens there is no ""valid"" iterator for TClingClassInfo; to use as the 'first' iterator and thus the existing invariant test,; 'first' iterator must not point to nullptr, is incorrect. To solve the problem use an explicit way of telling whether the; TClingClassInfo was setup for iteration (rather than deducing from; the value of the iterator pointee) and void memory growth by; using bit field for the bool data members.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1300
https://github.com/root-project/root/pull/1301:60,Modifiability,Config,Config,60,Small fix to support compilation without imt in class TMVA::Config. O.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1301
https://github.com/root-project/root/pull/1303:325,Integrability,interface,interface,325,Until now we let users use `array_view` columns to signal that they were reading c-style-array branches from a root file (and therefore we needed a `TTreeReaderArray` as a reader).; We now use our own `TArrayBranch` class for that purpose instead of embedding `array_view` with a meaning it does not have. This is a breaking interface change.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1303
https://github.com/root-project/root/pull/1304:115,Modifiability,config,configure-RelWithDebInfo,115,This should fix the warning below:; ```; CMake Warning (dev) at; googletest-prefix/src/googletest-stamp/googletest-configure-RelWithDebInfo.cmake:3:; Syntax Warning in cmake code at column 471. Argument not separated from preceding token by whitespace.; This warning is for project developers. Use -Wno-dev to suppress it.; ```. Warning introduced by f892e5e99c0e92326fd54eab059fc5a801762210.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1304
https://github.com/root-project/root/pull/1305:167,Availability,failure,failure,167,This is revised version of #1227.; Main change is the addition of an auto adjust mode that removes the need of a final adjust.; Still limited to the 1D case. The test failure in MemberComments is due to a missing update of MemberComments.ref .; A patch for roottest is available already. . Clang-format not applied this time.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1305
https://github.com/root-project/root/pull/1305:269,Availability,avail,available,269,This is revised version of #1227.; Main change is the addition of an auto adjust mode that removes the need of a final adjust.; Still limited to the 1D case. The test failure in MemberComments is due to a missing update of MemberComments.ref .; A patch for roottest is available already. . Clang-format not applied this time.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1305
https://github.com/root-project/root/pull/1305:213,Deployability,update,update,213,This is revised version of #1227.; Main change is the addition of an auto adjust mode that removes the need of a final adjust.; Still limited to the 1D case. The test failure in MemberComments is due to a missing update of MemberComments.ref .; A patch for roottest is available already. . Clang-format not applied this time.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1305
https://github.com/root-project/root/pull/1305:247,Deployability,patch,patch,247,This is revised version of #1227.; Main change is the addition of an auto adjust mode that removes the need of a final adjust.; Still limited to the 1D case. The test failure in MemberComments is due to a missing update of MemberComments.ref .; A patch for roottest is available already. . Clang-format not applied this time.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1305
https://github.com/root-project/root/pull/1305:162,Testability,test,test,162,This is revised version of #1227.; Main change is the addition of an auto adjust mode that removes the need of a final adjust.; Still limited to the 1D case. The test failure in MemberComments is due to a missing update of MemberComments.ref .; A patch for roottest is available already. . Clang-format not applied this time.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1305
https://github.com/root-project/root/pull/1308:4,Testability,test,tests,4,The tests for this pr are in PR1148 (test driven development!),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1308
https://github.com/root-project/root/pull/1308:37,Testability,test,test,37,The tests for this pr are in PR1148 (test driven development!),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1308
https://github.com/root-project/root/pull/1309:34,Availability,error,error,34,Thanks @etejedor for noticing the error messages I missed.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1309
https://github.com/root-project/root/pull/1309:40,Integrability,message,messages,40,Thanks @etejedor for noticing the error messages I missed.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1309
https://github.com/root-project/root/pull/1310:13,Testability,test,testing,13,Introduce MT testing for the TDataFrame with friends scenario.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1310
https://github.com/root-project/root/pull/1312:2720,Energy Efficiency,Adapt,Adapt,2720,"ery strict source compatibility requirements: ""we should only break source compatibility if the ROOT constructs were actively harmful in some way, the volume of affected ROOT code is relatively small, and we can provide source compatibility and migration"". As discussed with @pcanal, and with TExecutor introduced in ROOT 6.08, there's little possibilities any user has implemented a new derived class from TExecutor. If this happened, the user is most probably advanced enough to be able to change the implementation. In any case, the volume of affected ROOT code will be relatively small. . As suggested by @dpiparo, for the moment we will keep the new ```TExecutor``` in ```ROOT::Internals```, not exposing it to the user. The executor usage will look as following:. ```cpp ; ROOT::Internal::TExecutor pool(ROOT::Fit::ExecutionPolicy::kSerial);; auto mapFunction = [](unsigned i){return 1u;};; auto reductionFunction = [](const std::vector<unsigned> &v) {; return std::accumulate(v.begin(), v.end(), 0u);; };. pool.MapReduce(ROOT::Fit::ExecutionPolicy::kSerial, mapFunction, ROOT::TSeq<unsigned>(20), reductionFunction);; ```. **TLDR;** This PR changes the behaviour of existing executors and introduces; new ones:. * TExecutor: changes its functionality to be a general Executor, while; TExecutorBaseImpl takes the role of the previous TExecutor. TExecutor; now acts as a general interface to the executors. The executor it will; resolve to is specified by a execution policy parameter in its; constructor. * TExecutorBaseImpl: Plays the previous role of TExecutor. * TSequentialExecutor: provides a sequential implementation of the; executor model, defined by TExecutorBaseImpl. This PR is not finished, but I'm opening it for discussion. Things left:; - [x] Change kSerial to kSequential. - [x] Move Execution Policies to ROOT::Internal. - [x] Adapt Fitting functions to use the new TExecutor instead of if statements. A test can be found here: https://github.com/root-project/roottest/pull/106",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1312
https://github.com/root-project/root/pull/1312:257,Integrability,interface,interface,257,"Disclaimer: not everyone tagged in this comment agreed to the totality of my changes, and all dissenting comments have been considered. Anything included this PR is carved in stone and everything is open for discussion. I'm proposing a generalized executor interface that resolves to the specific ones (```TThreadExecutor```, ```TProcessExecutor```, a new ```SequentialExecutor```) with an execution policy received as a parameter. This is a use case that we found in places such as ```TMVA``` (@omazapa, @lmoneta) and the various fitting functions, where currently we rely on several if-else instructions where we check the execution policy (or even if ROOT has been compiled with IMT) to instantiate the right executor. My suggestion is to move ```TExecutor``` to ```ROOT::TExecutorBaseImpl``` (maybe in ```ROOT::Internals```?) and reuse the name. This breaks ROOT's very strict source compatibility requirements: ""we should only break source compatibility if the ROOT constructs were actively harmful in some way, the volume of affected ROOT code is relatively small, and we can provide source compatibility and migration"". As discussed with @pcanal, and with TExecutor introduced in ROOT 6.08, there's little possibilities any user has implemented a new derived class from TExecutor. If this happened, the user is most probably advanced enough to be able to change the implementation. In any case, the volume of affected ROOT code will be relatively small. . As suggested by @dpiparo, for the moment we will keep the new ```TExecutor``` in ```ROOT::Internals```, not exposing it to the user. The executor usage will look as following:. ```cpp ; ROOT::Internal::TExecutor pool(ROOT::Fit::ExecutionPolicy::kSerial);; auto mapFunction = [](unsigned i){return 1u;};; auto reductionFunction = [](const std::vector<unsigned> &v) {; return std::accumulate(v.begin(), v.end(), 0u);; };. pool.MapReduce(ROOT::Fit::ExecutionPolicy::kSerial, mapFunction, ROOT::TSeq<unsigned>(20), reductionFunction);; ```. *",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1312
https://github.com/root-project/root/pull/1312:2254,Integrability,interface,interface,2254,"ery strict source compatibility requirements: ""we should only break source compatibility if the ROOT constructs were actively harmful in some way, the volume of affected ROOT code is relatively small, and we can provide source compatibility and migration"". As discussed with @pcanal, and with TExecutor introduced in ROOT 6.08, there's little possibilities any user has implemented a new derived class from TExecutor. If this happened, the user is most probably advanced enough to be able to change the implementation. In any case, the volume of affected ROOT code will be relatively small. . As suggested by @dpiparo, for the moment we will keep the new ```TExecutor``` in ```ROOT::Internals```, not exposing it to the user. The executor usage will look as following:. ```cpp ; ROOT::Internal::TExecutor pool(ROOT::Fit::ExecutionPolicy::kSerial);; auto mapFunction = [](unsigned i){return 1u;};; auto reductionFunction = [](const std::vector<unsigned> &v) {; return std::accumulate(v.begin(), v.end(), 0u);; };. pool.MapReduce(ROOT::Fit::ExecutionPolicy::kSerial, mapFunction, ROOT::TSeq<unsigned>(20), reductionFunction);; ```. **TLDR;** This PR changes the behaviour of existing executors and introduces; new ones:. * TExecutor: changes its functionality to be a general Executor, while; TExecutorBaseImpl takes the role of the previous TExecutor. TExecutor; now acts as a general interface to the executors. The executor it will; resolve to is specified by a execution policy parameter in its; constructor. * TExecutorBaseImpl: Plays the previous role of TExecutor. * TSequentialExecutor: provides a sequential implementation of the; executor model, defined by TExecutorBaseImpl. This PR is not finished, but I'm opening it for discussion. Things left:; - [x] Change kSerial to kSequential. - [x] Move Execution Policies to ROOT::Internal. - [x] Adapt Fitting functions to use the new TExecutor instead of if statements. A test can be found here: https://github.com/root-project/roottest/pull/106",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1312
https://github.com/root-project/root/pull/1312:2720,Modifiability,Adapt,Adapt,2720,"ery strict source compatibility requirements: ""we should only break source compatibility if the ROOT constructs were actively harmful in some way, the volume of affected ROOT code is relatively small, and we can provide source compatibility and migration"". As discussed with @pcanal, and with TExecutor introduced in ROOT 6.08, there's little possibilities any user has implemented a new derived class from TExecutor. If this happened, the user is most probably advanced enough to be able to change the implementation. In any case, the volume of affected ROOT code will be relatively small. . As suggested by @dpiparo, for the moment we will keep the new ```TExecutor``` in ```ROOT::Internals```, not exposing it to the user. The executor usage will look as following:. ```cpp ; ROOT::Internal::TExecutor pool(ROOT::Fit::ExecutionPolicy::kSerial);; auto mapFunction = [](unsigned i){return 1u;};; auto reductionFunction = [](const std::vector<unsigned> &v) {; return std::accumulate(v.begin(), v.end(), 0u);; };. pool.MapReduce(ROOT::Fit::ExecutionPolicy::kSerial, mapFunction, ROOT::TSeq<unsigned>(20), reductionFunction);; ```. **TLDR;** This PR changes the behaviour of existing executors and introduces; new ones:. * TExecutor: changes its functionality to be a general Executor, while; TExecutorBaseImpl takes the role of the previous TExecutor. TExecutor; now acts as a general interface to the executors. The executor it will; resolve to is specified by a execution policy parameter in its; constructor. * TExecutorBaseImpl: Plays the previous role of TExecutor. * TSequentialExecutor: provides a sequential implementation of the; executor model, defined by TExecutorBaseImpl. This PR is not finished, but I'm opening it for discussion. Things left:; - [x] Change kSerial to kSequential. - [x] Move Execution Policies to ROOT::Internal. - [x] Adapt Fitting functions to use the new TExecutor instead of if statements. A test can be found here: https://github.com/root-project/roottest/pull/106",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1312
https://github.com/root-project/root/pull/1312:2797,Testability,test,test,2797,"ery strict source compatibility requirements: ""we should only break source compatibility if the ROOT constructs were actively harmful in some way, the volume of affected ROOT code is relatively small, and we can provide source compatibility and migration"". As discussed with @pcanal, and with TExecutor introduced in ROOT 6.08, there's little possibilities any user has implemented a new derived class from TExecutor. If this happened, the user is most probably advanced enough to be able to change the implementation. In any case, the volume of affected ROOT code will be relatively small. . As suggested by @dpiparo, for the moment we will keep the new ```TExecutor``` in ```ROOT::Internals```, not exposing it to the user. The executor usage will look as following:. ```cpp ; ROOT::Internal::TExecutor pool(ROOT::Fit::ExecutionPolicy::kSerial);; auto mapFunction = [](unsigned i){return 1u;};; auto reductionFunction = [](const std::vector<unsigned> &v) {; return std::accumulate(v.begin(), v.end(), 0u);; };. pool.MapReduce(ROOT::Fit::ExecutionPolicy::kSerial, mapFunction, ROOT::TSeq<unsigned>(20), reductionFunction);; ```. **TLDR;** This PR changes the behaviour of existing executors and introduces; new ones:. * TExecutor: changes its functionality to be a general Executor, while; TExecutorBaseImpl takes the role of the previous TExecutor. TExecutor; now acts as a general interface to the executors. The executor it will; resolve to is specified by a execution policy parameter in its; constructor. * TExecutorBaseImpl: Plays the previous role of TExecutor. * TSequentialExecutor: provides a sequential implementation of the; executor model, defined by TExecutorBaseImpl. This PR is not finished, but I'm opening it for discussion. Things left:; - [x] Change kSerial to kSequential. - [x] Move Execution Policies to ROOT::Internal. - [x] Adapt Fitting functions to use the new TExecutor instead of if statements. A test can be found here: https://github.com/root-project/roottest/pull/106",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1312
https://github.com/root-project/root/pull/1313:132,Energy Efficiency,consumption,consumption,132,"Just opening the PR to discuss the problem:; Jitting many `Define` (or `Filter`) calls currently incurs in major runtime and memory consumption penalties. This is because repeated calls to `Calc` or `ProcessLine` have a significant overhead w.r.t. a single call that jits the same code in a single go. Jitting all `Define` calls together (and together with all jitted actions) greatly reduces runtime and memory consumption. **Current issue:**; in code such as. ```c++; d.Define(""x"", ""42"").Min(""x""); ```. the `Min` action has no way to know the type of `x` because the lambda that produces `x` has not been jitted yet. Maybe we could defer even the creation of the strings to jit for the actions to _after_ we have jitted all the `Define`s, but this will require more thinking and more refactoring.; EDIT: the same goes for jitted `Snapshot`s, the formation of the string to jit must be deferred to after we have jitted and executed all `Define`s.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1313
https://github.com/root-project/root/pull/1313:385,Energy Efficiency,reduce,reduces,385,"Just opening the PR to discuss the problem:; Jitting many `Define` (or `Filter`) calls currently incurs in major runtime and memory consumption penalties. This is because repeated calls to `Calc` or `ProcessLine` have a significant overhead w.r.t. a single call that jits the same code in a single go. Jitting all `Define` calls together (and together with all jitted actions) greatly reduces runtime and memory consumption. **Current issue:**; in code such as. ```c++; d.Define(""x"", ""42"").Min(""x""); ```. the `Min` action has no way to know the type of `x` because the lambda that produces `x` has not been jitted yet. Maybe we could defer even the creation of the strings to jit for the actions to _after_ we have jitted all the `Define`s, but this will require more thinking and more refactoring.; EDIT: the same goes for jitted `Snapshot`s, the formation of the string to jit must be deferred to after we have jitted and executed all `Define`s.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1313
https://github.com/root-project/root/pull/1313:412,Energy Efficiency,consumption,consumption,412,"Just opening the PR to discuss the problem:; Jitting many `Define` (or `Filter`) calls currently incurs in major runtime and memory consumption penalties. This is because repeated calls to `Calc` or `ProcessLine` have a significant overhead w.r.t. a single call that jits the same code in a single go. Jitting all `Define` calls together (and together with all jitted actions) greatly reduces runtime and memory consumption. **Current issue:**; in code such as. ```c++; d.Define(""x"", ""42"").Min(""x""); ```. the `Min` action has no way to know the type of `x` because the lambda that produces `x` has not been jitted yet. Maybe we could defer even the creation of the strings to jit for the actions to _after_ we have jitted all the `Define`s, but this will require more thinking and more refactoring.; EDIT: the same goes for jitted `Snapshot`s, the formation of the string to jit must be deferred to after we have jitted and executed all `Define`s.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1313
https://github.com/root-project/root/pull/1313:786,Modifiability,refactor,refactoring,786,"Just opening the PR to discuss the problem:; Jitting many `Define` (or `Filter`) calls currently incurs in major runtime and memory consumption penalties. This is because repeated calls to `Calc` or `ProcessLine` have a significant overhead w.r.t. a single call that jits the same code in a single go. Jitting all `Define` calls together (and together with all jitted actions) greatly reduces runtime and memory consumption. **Current issue:**; in code such as. ```c++; d.Define(""x"", ""42"").Min(""x""); ```. the `Min` action has no way to know the type of `x` because the lambda that produces `x` has not been jitted yet. Maybe we could defer even the creation of the strings to jit for the actions to _after_ we have jitted all the `Define`s, but this will require more thinking and more refactoring.; EDIT: the same goes for jitted `Snapshot`s, the formation of the string to jit must be deferred to after we have jitted and executed all `Define`s.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1313
https://github.com/root-project/root/pull/1315:102,Performance,perform,perform,102,"TMVA new developments; * improvements for class TMVA::Envelope; * Added class TMVA::Classification to perform two class Classification; * Support to Train/Test multiple booked ml methods in parallel with MultiProc, calling the method Evaluate; * Documentation with Doxygen; * Test with Google Tests; * Example in Tutorials.; Cheers,; O.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1315
https://github.com/root-project/root/pull/1315:155,Testability,Test,Test,155,"TMVA new developments; * improvements for class TMVA::Envelope; * Added class TMVA::Classification to perform two class Classification; * Support to Train/Test multiple booked ml methods in parallel with MultiProc, calling the method Evaluate; * Documentation with Doxygen; * Test with Google Tests; * Example in Tutorials.; Cheers,; O.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1315
https://github.com/root-project/root/pull/1315:276,Testability,Test,Test,276,"TMVA new developments; * improvements for class TMVA::Envelope; * Added class TMVA::Classification to perform two class Classification; * Support to Train/Test multiple booked ml methods in parallel with MultiProc, calling the method Evaluate; * Documentation with Doxygen; * Test with Google Tests; * Example in Tutorials.; Cheers,; O.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1315
https://github.com/root-project/root/pull/1315:293,Testability,Test,Tests,293,"TMVA new developments; * improvements for class TMVA::Envelope; * Added class TMVA::Classification to perform two class Classification; * Support to Train/Test multiple booked ml methods in parallel with MultiProc, calling the method Evaluate; * Documentation with Doxygen; * Test with Google Tests; * Example in Tutorials.; Cheers,; O.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1315
https://github.com/root-project/root/pull/1316:102,Performance,perform,perform,102,"TMVA new developments. * improvements for class TMVA::Envelope; * Added class TMVA::Classification to perform two class Classification; * Support to Train/Test multiple booked ml methods in parallel with MultiProc, calling the method Evaluate; * Documentation with Doxygen; * Test with Google Tests; * Example in Tutorials. Cheers,; O.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1316
https://github.com/root-project/root/pull/1316:155,Testability,Test,Test,155,"TMVA new developments. * improvements for class TMVA::Envelope; * Added class TMVA::Classification to perform two class Classification; * Support to Train/Test multiple booked ml methods in parallel with MultiProc, calling the method Evaluate; * Documentation with Doxygen; * Test with Google Tests; * Example in Tutorials. Cheers,; O.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1316
https://github.com/root-project/root/pull/1316:276,Testability,Test,Test,276,"TMVA new developments. * improvements for class TMVA::Envelope; * Added class TMVA::Classification to perform two class Classification; * Support to Train/Test multiple booked ml methods in parallel with MultiProc, calling the method Evaluate; * Documentation with Doxygen; * Test with Google Tests; * Example in Tutorials. Cheers,; O.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1316
https://github.com/root-project/root/pull/1316:293,Testability,Test,Tests,293,"TMVA new developments. * improvements for class TMVA::Envelope; * Added class TMVA::Classification to perform two class Classification; * Support to Train/Test multiple booked ml methods in parallel with MultiProc, calling the method Evaluate; * Documentation with Doxygen; * Test with Google Tests; * Example in Tutorials. Cheers,; O.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1316
https://github.com/root-project/root/pull/1317:722,Performance,load,load,722,"Without modules, many STL and libc headers are automatically; provided by ROOT via the attached ROOT PCH. This means that; we don't need to have autloading or explicit includes for STL; or libc headers when running with the PCH attached. This leads; to making user code like this working in ROOT:. ```C++; // no includes here that provides assert; int foo() {; assert(false);; }; ```. However, as the modules don't come with this big PCH, we; are now suddenly in the situation where we can't resolve; things such as `assert`. We also can't rely on the; normal autoloading of ROOT as those declarations were; actually never autoloaded, but just provided by the PCH. To simulate this behavior with modules, we automatically load; those headers that we expect to have in the ROOT PCH; (which are probably the STL and libc headers).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1317
https://github.com/root-project/root/pull/1317:340,Testability,assert,assert,340,"Without modules, many STL and libc headers are automatically; provided by ROOT via the attached ROOT PCH. This means that; we don't need to have autloading or explicit includes for STL; or libc headers when running with the PCH attached. This leads; to making user code like this working in ROOT:. ```C++; // no includes here that provides assert; int foo() {; assert(false);; }; ```. However, as the modules don't come with this big PCH, we; are now suddenly in the situation where we can't resolve; things such as `assert`. We also can't rely on the; normal autoloading of ROOT as those declarations were; actually never autoloaded, but just provided by the PCH. To simulate this behavior with modules, we automatically load; those headers that we expect to have in the ROOT PCH; (which are probably the STL and libc headers).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1317
https://github.com/root-project/root/pull/1317:361,Testability,assert,assert,361,"Without modules, many STL and libc headers are automatically; provided by ROOT via the attached ROOT PCH. This means that; we don't need to have autloading or explicit includes for STL; or libc headers when running with the PCH attached. This leads; to making user code like this working in ROOT:. ```C++; // no includes here that provides assert; int foo() {; assert(false);; }; ```. However, as the modules don't come with this big PCH, we; are now suddenly in the situation where we can't resolve; things such as `assert`. We also can't rely on the; normal autoloading of ROOT as those declarations were; actually never autoloaded, but just provided by the PCH. To simulate this behavior with modules, we automatically load; those headers that we expect to have in the ROOT PCH; (which are probably the STL and libc headers).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1317
https://github.com/root-project/root/pull/1317:517,Testability,assert,assert,517,"Without modules, many STL and libc headers are automatically; provided by ROOT via the attached ROOT PCH. This means that; we don't need to have autloading or explicit includes for STL; or libc headers when running with the PCH attached. This leads; to making user code like this working in ROOT:. ```C++; // no includes here that provides assert; int foo() {; assert(false);; }; ```. However, as the modules don't come with this big PCH, we; are now suddenly in the situation where we can't resolve; things such as `assert`. We also can't rely on the; normal autoloading of ROOT as those declarations were; actually never autoloaded, but just provided by the PCH. To simulate this behavior with modules, we automatically load; those headers that we expect to have in the ROOT PCH; (which are probably the STL and libc headers).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1317
https://github.com/root-project/root/pull/1320:36,Availability,error,errors,36,This otherwise leads to compilation errors when we do `::fileno`; as OpenBSD implemented fileno as a macro (which seems to be allowed).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1320
https://github.com/root-project/root/pull/1327:234,Performance,perform,performed,234,I added the RooMCMC class into roofitcore. It is used as the RooMinuit class except that it is using a Monte Carlo Markov Chain as a minimizer. I also added a Tutorial to the roofit section where a basic comparison with Minuit can be performed. This is my first contribution to ROOT so I except that some thing will not be right.; But I compiled ROOT on my computer exactly with the changes I am committing here and everything went fine.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1327
https://github.com/root-project/root/pull/1328:0,Integrability,Depend,Depends,0,"Depends on: #1317, adds only one other commit:. It seems automatically loading TreePlayer when TDataFrame is used; without the appropriate include never worked. This was previously; fixed by just adding TreePlayer (which contains TDF) to the PCH.; ; As always, let's recreate this hack with modules to make restore; the old behavior with modules turned on.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1328
https://github.com/root-project/root/pull/1328:71,Performance,load,loading,71,"Depends on: #1317, adds only one other commit:. It seems automatically loading TreePlayer when TDataFrame is used; without the appropriate include never worked. This was previously; fixed by just adding TreePlayer (which contains TDF) to the PCH.; ; As always, let's recreate this hack with modules to make restore; the old behavior with modules turned on.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1328
https://github.com/root-project/root/pull/1335:59,Availability,error,errors,59,"Some tests are failing with modules such with redefinition errors; (for example `roottest-cling-parsing-scopeDict-build`). The reason for this is that we include all headers that form; the C++ module again to make sure the module is complete (some; rootcling invocations don't have all headers of the module as; arguments, most notably the Core module). The first inclusion; of these headers happens from the normal rootcling code. This patch changes this behavior that we only include the; *missing* headers that are necessary to make the C++ module; complete and not all headers.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1335
https://github.com/root-project/root/pull/1335:437,Deployability,patch,patch,437,"Some tests are failing with modules such with redefinition errors; (for example `roottest-cling-parsing-scopeDict-build`). The reason for this is that we include all headers that form; the C++ module again to make sure the module is complete (some; rootcling invocations don't have all headers of the module as; arguments, most notably the Core module). The first inclusion; of these headers happens from the normal rootcling code. This patch changes this behavior that we only include the; *missing* headers that are necessary to make the C++ module; complete and not all headers.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1335
https://github.com/root-project/root/pull/1335:5,Testability,test,tests,5,"Some tests are failing with modules such with redefinition errors; (for example `roottest-cling-parsing-scopeDict-build`). The reason for this is that we include all headers that form; the C++ module again to make sure the module is complete (some; rootcling invocations don't have all headers of the module as; arguments, most notably the Core module). The first inclusion; of these headers happens from the normal rootcling code. This patch changes this behavior that we only include the; *missing* headers that are necessary to make the C++ module; complete and not all headers.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1335
https://github.com/root-project/root/pull/1336:36,Availability,error,error,36,This will be replaced with a proper error message in the future; once we have a reliable way of implmenting such an error. For; now it's already an improvement if we always print a warning; when we build a module on demand.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1336
https://github.com/root-project/root/pull/1336:80,Availability,reliab,reliable,80,This will be replaced with a proper error message in the future; once we have a reliable way of implmenting such an error. For; now it's already an improvement if we always print a warning; when we build a module on demand.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1336
https://github.com/root-project/root/pull/1336:116,Availability,error,error,116,This will be replaced with a proper error message in the future; once we have a reliable way of implmenting such an error. For; now it's already an improvement if we always print a warning; when we build a module on demand.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1336
https://github.com/root-project/root/pull/1336:42,Integrability,message,message,42,This will be replaced with a proper error message in the future; once we have a reliable way of implmenting such an error. For; now it's already an improvement if we always print a warning; when we build a module on demand.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1336
https://github.com/root-project/root/pull/1337:415,Energy Efficiency,reduce,reduces,415,"When we want to autoload contents from namespaces we end up in; Sema::LookupQualifiedName; then we issue a callback to; FindExternallyVisibleName which forwards to LookupObject. Lookup object; takes a DeclContext as an argument. This argument is always the primary; lookup context (which for a NamespaceDecl is the original namespace. Regular autoloading does not consider this (or has chosen not to) because; this reduces the amount of autoloads. Such autoloads can happen when; resolving template specializations when computing a decl's linkage by; clang's CodeGen. This in turn loads unexpected libraries such as RooFit; when trying to resolve all template specializations of __to_raw_pointer; (located in &lt;memory&gt;), including the one taking a HistFactory::Data*.; The amount of deserializations might be reduced by applying [D29951](https://reviews.llvm.org/D29951). That way we end up needlessly loading RooFit and showing it's weird; banner, potentially breaking a lot of tests. This behavior can be considered as broken because we hide information; about possible redeclarations which can affect the linkage computation or; other checks in codegen. If we fix the bug we will probably explode; ROOT's memory footprint and make the gap between standard ROOT and ROOT; with modules even bigger. Since it is not clear how much work and issue resolving is required for; standard ROOT, we can probably only live with the workaround of the missing; concept: moving entities in namespaces whose autoloading requires declarations; to be in the PCH. For instance, ROOT::Experimental::TDataFrame.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1337
https://github.com/root-project/root/pull/1337:814,Energy Efficiency,reduce,reduced,814,"When we want to autoload contents from namespaces we end up in; Sema::LookupQualifiedName; then we issue a callback to; FindExternallyVisibleName which forwards to LookupObject. Lookup object; takes a DeclContext as an argument. This argument is always the primary; lookup context (which for a NamespaceDecl is the original namespace. Regular autoloading does not consider this (or has chosen not to) because; this reduces the amount of autoloads. Such autoloads can happen when; resolving template specializations when computing a decl's linkage by; clang's CodeGen. This in turn loads unexpected libraries such as RooFit; when trying to resolve all template specializations of __to_raw_pointer; (located in &lt;memory&gt;), including the one taking a HistFactory::Data*.; The amount of deserializations might be reduced by applying [D29951](https://reviews.llvm.org/D29951). That way we end up needlessly loading RooFit and showing it's weird; banner, potentially breaking a lot of tests. This behavior can be considered as broken because we hide information; about possible redeclarations which can affect the linkage computation or; other checks in codegen. If we fix the bug we will probably explode; ROOT's memory footprint and make the gap between standard ROOT and ROOT; with modules even bigger. Since it is not clear how much work and issue resolving is required for; standard ROOT, we can probably only live with the workaround of the missing; concept: moving entities in namespaces whose autoloading requires declarations; to be in the PCH. For instance, ROOT::Experimental::TDataFrame.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1337
https://github.com/root-project/root/pull/1337:581,Performance,load,loads,581,"When we want to autoload contents from namespaces we end up in; Sema::LookupQualifiedName; then we issue a callback to; FindExternallyVisibleName which forwards to LookupObject. Lookup object; takes a DeclContext as an argument. This argument is always the primary; lookup context (which for a NamespaceDecl is the original namespace. Regular autoloading does not consider this (or has chosen not to) because; this reduces the amount of autoloads. Such autoloads can happen when; resolving template specializations when computing a decl's linkage by; clang's CodeGen. This in turn loads unexpected libraries such as RooFit; when trying to resolve all template specializations of __to_raw_pointer; (located in &lt;memory&gt;), including the one taking a HistFactory::Data*.; The amount of deserializations might be reduced by applying [D29951](https://reviews.llvm.org/D29951). That way we end up needlessly loading RooFit and showing it's weird; banner, potentially breaking a lot of tests. This behavior can be considered as broken because we hide information; about possible redeclarations which can affect the linkage computation or; other checks in codegen. If we fix the bug we will probably explode; ROOT's memory footprint and make the gap between standard ROOT and ROOT; with modules even bigger. Since it is not clear how much work and issue resolving is required for; standard ROOT, we can probably only live with the workaround of the missing; concept: moving entities in namespaces whose autoloading requires declarations; to be in the PCH. For instance, ROOT::Experimental::TDataFrame.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1337
https://github.com/root-project/root/pull/1337:907,Performance,load,loading,907,"When we want to autoload contents from namespaces we end up in; Sema::LookupQualifiedName; then we issue a callback to; FindExternallyVisibleName which forwards to LookupObject. Lookup object; takes a DeclContext as an argument. This argument is always the primary; lookup context (which for a NamespaceDecl is the original namespace. Regular autoloading does not consider this (or has chosen not to) because; this reduces the amount of autoloads. Such autoloads can happen when; resolving template specializations when computing a decl's linkage by; clang's CodeGen. This in turn loads unexpected libraries such as RooFit; when trying to resolve all template specializations of __to_raw_pointer; (located in &lt;memory&gt;), including the one taking a HistFactory::Data*.; The amount of deserializations might be reduced by applying [D29951](https://reviews.llvm.org/D29951). That way we end up needlessly loading RooFit and showing it's weird; banner, potentially breaking a lot of tests. This behavior can be considered as broken because we hide information; about possible redeclarations which can affect the linkage computation or; other checks in codegen. If we fix the bug we will probably explode; ROOT's memory footprint and make the gap between standard ROOT and ROOT; with modules even bigger. Since it is not clear how much work and issue resolving is required for; standard ROOT, we can probably only live with the workaround of the missing; concept: moving entities in namespaces whose autoloading requires declarations; to be in the PCH. For instance, ROOT::Experimental::TDataFrame.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1337
https://github.com/root-project/root/pull/1337:984,Testability,test,tests,984,"When we want to autoload contents from namespaces we end up in; Sema::LookupQualifiedName; then we issue a callback to; FindExternallyVisibleName which forwards to LookupObject. Lookup object; takes a DeclContext as an argument. This argument is always the primary; lookup context (which for a NamespaceDecl is the original namespace. Regular autoloading does not consider this (or has chosen not to) because; this reduces the amount of autoloads. Such autoloads can happen when; resolving template specializations when computing a decl's linkage by; clang's CodeGen. This in turn loads unexpected libraries such as RooFit; when trying to resolve all template specializations of __to_raw_pointer; (located in &lt;memory&gt;), including the one taking a HistFactory::Data*.; The amount of deserializations might be reduced by applying [D29951](https://reviews.llvm.org/D29951). That way we end up needlessly loading RooFit and showing it's weird; banner, potentially breaking a lot of tests. This behavior can be considered as broken because we hide information; about possible redeclarations which can affect the linkage computation or; other checks in codegen. If we fix the bug we will probably explode; ROOT's memory footprint and make the gap between standard ROOT and ROOT; with modules even bigger. Since it is not clear how much work and issue resolving is required for; standard ROOT, we can probably only live with the workaround of the missing; concept: moving entities in namespaces whose autoloading requires declarations; to be in the PCH. For instance, ROOT::Experimental::TDataFrame.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1337
https://github.com/root-project/root/pull/1337:1321,Usability,clear,clear,1321,"When we want to autoload contents from namespaces we end up in; Sema::LookupQualifiedName; then we issue a callback to; FindExternallyVisibleName which forwards to LookupObject. Lookup object; takes a DeclContext as an argument. This argument is always the primary; lookup context (which for a NamespaceDecl is the original namespace. Regular autoloading does not consider this (or has chosen not to) because; this reduces the amount of autoloads. Such autoloads can happen when; resolving template specializations when computing a decl's linkage by; clang's CodeGen. This in turn loads unexpected libraries such as RooFit; when trying to resolve all template specializations of __to_raw_pointer; (located in &lt;memory&gt;), including the one taking a HistFactory::Data*.; The amount of deserializations might be reduced by applying [D29951](https://reviews.llvm.org/D29951). That way we end up needlessly loading RooFit and showing it's weird; banner, potentially breaking a lot of tests. This behavior can be considered as broken because we hide information; about possible redeclarations which can affect the linkage computation or; other checks in codegen. If we fix the bug we will probably explode; ROOT's memory footprint and make the gap between standard ROOT and ROOT; with modules even bigger. Since it is not clear how much work and issue resolving is required for; standard ROOT, we can probably only live with the workaround of the missing; concept: moving entities in namespaces whose autoloading requires declarations; to be in the PCH. For instance, ROOT::Experimental::TDataFrame.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1337
https://github.com/root-project/root/pull/1339:37,Availability,failure,failure,37,…ve use. This might fix intermittent failure in roottest_root_multicore_tp_process_imt; https://epsft-jenkins.cern.ch/job/root-pullrequests-build/11911/testReport/projectroot.roottest.root/multicore/roottest_root_multicore_tp_process_imt/; shows crash in:,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1339
https://github.com/root-project/root/pull/1339:152,Testability,test,testReport,152,…ve use. This might fix intermittent failure in roottest_root_multicore_tp_process_imt; https://epsft-jenkins.cern.ch/job/root-pullrequests-build/11911/testReport/projectroot.roottest.root/multicore/roottest_root_multicore_tp_process_imt/; shows crash in:,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1339
https://github.com/root-project/root/pull/1343:91,Availability,error,error,91,"[net/monalisa/src/TMonaLisaWriter.cxx:956] -> [net/monalisa/src/TMonaLisaWriter.cxx:957]: (error) Iterator 'iter' used after element has been erased.; [proof/proofd/src/XrdProofdProofServMgr.cxx:4648] -> [proof/proofd/src/XrdProofdProofServMgr.cxx:4646]: (error) Iterator 'iter' used after element has been erased. [math/minuit2/src/Minuit2Minimizer.cxx:669] -> [math/minuit2/src/Minuit2Minimizer.cxx:669]: (style) Same expression on both sides of '||'.; [math/minuit2/src/Minuit2Minimizer.cxx:736] -> [math/minuit2/src/Minuit2Minimizer.cxx:736]: (style) Same expression on both sides of '||'.; [math/minuit2/src/Minuit2Minimizer.cxx:753] -> [math/minuit2/src/Minuit2Minimizer.cxx:753]: (style) Same expression on both sides of '||'. [tree/tree/src/TBasket.cxx:852]: (style) Redundant condition: If 'flag >= 80', the comparison 'flag' is always true.; [misc/table/src/TFileIter.cxx:467] -> [misc/table/src/TFileIter.cxx:468]: (warning) Identical condition 'thisRunNumber<runNumber', second condition is always false. [math/mathcore/src/TMath.cxx:826]: (style) Array index 'ia' is used before limits check.; [math/mathcore/src/TMath.cxx:830]: (style) Array index 'ib' is used before limits check.; [math/mathcore/src/triangle.c:15434]: (style) Array index 'aspectindex' is used before limits check.; [roofit/roofit/src/RooIntegralMorph.cxx:375]: (style) Array index 'igapHigh' is used before limits check. [core/winnt/src/TWinNTSystem.cxx:5035]: (style) Statements following return, break, continue, goto or throw will never be executed.; [tree/treeplayer/src/TSelectorDraw.cxx:380]: (style) Statements following return, break, continue, goto or throw will never be executed. [net/auth/src/TAuthenticate.cxx:4205]: (error) Resource leak: fd; [roofit/roofitcore/src/BidirMMapPipe.cxx:1880]: (error) Memory leak: s; [tree/tree/src/TLeaf.cxx:222]: (error) Memory leak: countname; [tree/tree/src/TLeaf.cxx:226]: (error) Memory leak: countname; [tmva/tmva/src/MethodBase.cxx:2783]: (error) Memory leak: pdfS",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1343
https://github.com/root-project/root/pull/1343:256,Availability,error,error,256,"[net/monalisa/src/TMonaLisaWriter.cxx:956] -> [net/monalisa/src/TMonaLisaWriter.cxx:957]: (error) Iterator 'iter' used after element has been erased.; [proof/proofd/src/XrdProofdProofServMgr.cxx:4648] -> [proof/proofd/src/XrdProofdProofServMgr.cxx:4646]: (error) Iterator 'iter' used after element has been erased. [math/minuit2/src/Minuit2Minimizer.cxx:669] -> [math/minuit2/src/Minuit2Minimizer.cxx:669]: (style) Same expression on both sides of '||'.; [math/minuit2/src/Minuit2Minimizer.cxx:736] -> [math/minuit2/src/Minuit2Minimizer.cxx:736]: (style) Same expression on both sides of '||'.; [math/minuit2/src/Minuit2Minimizer.cxx:753] -> [math/minuit2/src/Minuit2Minimizer.cxx:753]: (style) Same expression on both sides of '||'. [tree/tree/src/TBasket.cxx:852]: (style) Redundant condition: If 'flag >= 80', the comparison 'flag' is always true.; [misc/table/src/TFileIter.cxx:467] -> [misc/table/src/TFileIter.cxx:468]: (warning) Identical condition 'thisRunNumber<runNumber', second condition is always false. [math/mathcore/src/TMath.cxx:826]: (style) Array index 'ia' is used before limits check.; [math/mathcore/src/TMath.cxx:830]: (style) Array index 'ib' is used before limits check.; [math/mathcore/src/triangle.c:15434]: (style) Array index 'aspectindex' is used before limits check.; [roofit/roofit/src/RooIntegralMorph.cxx:375]: (style) Array index 'igapHigh' is used before limits check. [core/winnt/src/TWinNTSystem.cxx:5035]: (style) Statements following return, break, continue, goto or throw will never be executed.; [tree/treeplayer/src/TSelectorDraw.cxx:380]: (style) Statements following return, break, continue, goto or throw will never be executed. [net/auth/src/TAuthenticate.cxx:4205]: (error) Resource leak: fd; [roofit/roofitcore/src/BidirMMapPipe.cxx:1880]: (error) Memory leak: s; [tree/tree/src/TLeaf.cxx:222]: (error) Memory leak: countname; [tree/tree/src/TLeaf.cxx:226]: (error) Memory leak: countname; [tmva/tmva/src/MethodBase.cxx:2783]: (error) Memory leak: pdfS",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1343
https://github.com/root-project/root/pull/1343:775,Availability,Redundant,Redundant,775,"[net/monalisa/src/TMonaLisaWriter.cxx:956] -> [net/monalisa/src/TMonaLisaWriter.cxx:957]: (error) Iterator 'iter' used after element has been erased.; [proof/proofd/src/XrdProofdProofServMgr.cxx:4648] -> [proof/proofd/src/XrdProofdProofServMgr.cxx:4646]: (error) Iterator 'iter' used after element has been erased. [math/minuit2/src/Minuit2Minimizer.cxx:669] -> [math/minuit2/src/Minuit2Minimizer.cxx:669]: (style) Same expression on both sides of '||'.; [math/minuit2/src/Minuit2Minimizer.cxx:736] -> [math/minuit2/src/Minuit2Minimizer.cxx:736]: (style) Same expression on both sides of '||'.; [math/minuit2/src/Minuit2Minimizer.cxx:753] -> [math/minuit2/src/Minuit2Minimizer.cxx:753]: (style) Same expression on both sides of '||'. [tree/tree/src/TBasket.cxx:852]: (style) Redundant condition: If 'flag >= 80', the comparison 'flag' is always true.; [misc/table/src/TFileIter.cxx:467] -> [misc/table/src/TFileIter.cxx:468]: (warning) Identical condition 'thisRunNumber<runNumber', second condition is always false. [math/mathcore/src/TMath.cxx:826]: (style) Array index 'ia' is used before limits check.; [math/mathcore/src/TMath.cxx:830]: (style) Array index 'ib' is used before limits check.; [math/mathcore/src/triangle.c:15434]: (style) Array index 'aspectindex' is used before limits check.; [roofit/roofit/src/RooIntegralMorph.cxx:375]: (style) Array index 'igapHigh' is used before limits check. [core/winnt/src/TWinNTSystem.cxx:5035]: (style) Statements following return, break, continue, goto or throw will never be executed.; [tree/treeplayer/src/TSelectorDraw.cxx:380]: (style) Statements following return, break, continue, goto or throw will never be executed. [net/auth/src/TAuthenticate.cxx:4205]: (error) Resource leak: fd; [roofit/roofitcore/src/BidirMMapPipe.cxx:1880]: (error) Memory leak: s; [tree/tree/src/TLeaf.cxx:222]: (error) Memory leak: countname; [tree/tree/src/TLeaf.cxx:226]: (error) Memory leak: countname; [tmva/tmva/src/MethodBase.cxx:2783]: (error) Memory leak: pdfS",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1343
https://github.com/root-project/root/pull/1343:1715,Availability,error,error,1715,"tree/src/TBasket.cxx:852]: (style) Redundant condition: If 'flag >= 80', the comparison 'flag' is always true.; [misc/table/src/TFileIter.cxx:467] -> [misc/table/src/TFileIter.cxx:468]: (warning) Identical condition 'thisRunNumber<runNumber', second condition is always false. [math/mathcore/src/TMath.cxx:826]: (style) Array index 'ia' is used before limits check.; [math/mathcore/src/TMath.cxx:830]: (style) Array index 'ib' is used before limits check.; [math/mathcore/src/triangle.c:15434]: (style) Array index 'aspectindex' is used before limits check.; [roofit/roofit/src/RooIntegralMorph.cxx:375]: (style) Array index 'igapHigh' is used before limits check. [core/winnt/src/TWinNTSystem.cxx:5035]: (style) Statements following return, break, continue, goto or throw will never be executed.; [tree/treeplayer/src/TSelectorDraw.cxx:380]: (style) Statements following return, break, continue, goto or throw will never be executed. [net/auth/src/TAuthenticate.cxx:4205]: (error) Resource leak: fd; [roofit/roofitcore/src/BidirMMapPipe.cxx:1880]: (error) Memory leak: s; [tree/tree/src/TLeaf.cxx:222]: (error) Memory leak: countname; [tree/tree/src/TLeaf.cxx:226]: (error) Memory leak: countname; [tmva/tmva/src/MethodBase.cxx:2783]: (error) Memory leak: pdfS; [tmva/tmva/src/MethodBase.cxx:2783]: (error) Memory leak: pdfB. [roofit/roofitcore/src/RooAbsArg.cxx:280]: (style) Redundant checking of STL container element existence before removing it. [core/dictgen/src/rootcling_impl.cxx:457]: (performance) Possible inefficient checking for 'fieldSelRules' emptiness.; [core/dictgen/src/rootcling_impl.cxx:4573]: (performance) Possible inefficient checking for 'filesIncludedByLinkdef' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:322]: (performance) Possible inefficient checking for 'fWebConn' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:374]: (performance) Possible inefficient checking for 'fCmds' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:419]: (performa",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1343
https://github.com/root-project/root/pull/1343:1790,Availability,error,error,1790,"= 80', the comparison 'flag' is always true.; [misc/table/src/TFileIter.cxx:467] -> [misc/table/src/TFileIter.cxx:468]: (warning) Identical condition 'thisRunNumber<runNumber', second condition is always false. [math/mathcore/src/TMath.cxx:826]: (style) Array index 'ia' is used before limits check.; [math/mathcore/src/TMath.cxx:830]: (style) Array index 'ib' is used before limits check.; [math/mathcore/src/triangle.c:15434]: (style) Array index 'aspectindex' is used before limits check.; [roofit/roofit/src/RooIntegralMorph.cxx:375]: (style) Array index 'igapHigh' is used before limits check. [core/winnt/src/TWinNTSystem.cxx:5035]: (style) Statements following return, break, continue, goto or throw will never be executed.; [tree/treeplayer/src/TSelectorDraw.cxx:380]: (style) Statements following return, break, continue, goto or throw will never be executed. [net/auth/src/TAuthenticate.cxx:4205]: (error) Resource leak: fd; [roofit/roofitcore/src/BidirMMapPipe.cxx:1880]: (error) Memory leak: s; [tree/tree/src/TLeaf.cxx:222]: (error) Memory leak: countname; [tree/tree/src/TLeaf.cxx:226]: (error) Memory leak: countname; [tmva/tmva/src/MethodBase.cxx:2783]: (error) Memory leak: pdfS; [tmva/tmva/src/MethodBase.cxx:2783]: (error) Memory leak: pdfB. [roofit/roofitcore/src/RooAbsArg.cxx:280]: (style) Redundant checking of STL container element existence before removing it. [core/dictgen/src/rootcling_impl.cxx:457]: (performance) Possible inefficient checking for 'fieldSelRules' emptiness.; [core/dictgen/src/rootcling_impl.cxx:4573]: (performance) Possible inefficient checking for 'filesIncludedByLinkdef' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:322]: (performance) Possible inefficient checking for 'fWebConn' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:374]: (performance) Possible inefficient checking for 'fCmds' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:419]: (performance) Possible inefficient checking for 'fWebConn' emptiness.; [gu",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1343
https://github.com/root-project/root/pull/1343:1845,Availability,error,error,1845,"rc/TFileIter.cxx:467] -> [misc/table/src/TFileIter.cxx:468]: (warning) Identical condition 'thisRunNumber<runNumber', second condition is always false. [math/mathcore/src/TMath.cxx:826]: (style) Array index 'ia' is used before limits check.; [math/mathcore/src/TMath.cxx:830]: (style) Array index 'ib' is used before limits check.; [math/mathcore/src/triangle.c:15434]: (style) Array index 'aspectindex' is used before limits check.; [roofit/roofit/src/RooIntegralMorph.cxx:375]: (style) Array index 'igapHigh' is used before limits check. [core/winnt/src/TWinNTSystem.cxx:5035]: (style) Statements following return, break, continue, goto or throw will never be executed.; [tree/treeplayer/src/TSelectorDraw.cxx:380]: (style) Statements following return, break, continue, goto or throw will never be executed. [net/auth/src/TAuthenticate.cxx:4205]: (error) Resource leak: fd; [roofit/roofitcore/src/BidirMMapPipe.cxx:1880]: (error) Memory leak: s; [tree/tree/src/TLeaf.cxx:222]: (error) Memory leak: countname; [tree/tree/src/TLeaf.cxx:226]: (error) Memory leak: countname; [tmva/tmva/src/MethodBase.cxx:2783]: (error) Memory leak: pdfS; [tmva/tmva/src/MethodBase.cxx:2783]: (error) Memory leak: pdfB. [roofit/roofitcore/src/RooAbsArg.cxx:280]: (style) Redundant checking of STL container element existence before removing it. [core/dictgen/src/rootcling_impl.cxx:457]: (performance) Possible inefficient checking for 'fieldSelRules' emptiness.; [core/dictgen/src/rootcling_impl.cxx:4573]: (performance) Possible inefficient checking for 'filesIncludedByLinkdef' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:322]: (performance) Possible inefficient checking for 'fWebConn' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:374]: (performance) Possible inefficient checking for 'fCmds' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:419]: (performance) Possible inefficient checking for 'fWebConn' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:475]: (performance",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1343
https://github.com/root-project/root/pull/1343:1908,Availability,error,error,1908,"ing) Identical condition 'thisRunNumber<runNumber', second condition is always false. [math/mathcore/src/TMath.cxx:826]: (style) Array index 'ia' is used before limits check.; [math/mathcore/src/TMath.cxx:830]: (style) Array index 'ib' is used before limits check.; [math/mathcore/src/triangle.c:15434]: (style) Array index 'aspectindex' is used before limits check.; [roofit/roofit/src/RooIntegralMorph.cxx:375]: (style) Array index 'igapHigh' is used before limits check. [core/winnt/src/TWinNTSystem.cxx:5035]: (style) Statements following return, break, continue, goto or throw will never be executed.; [tree/treeplayer/src/TSelectorDraw.cxx:380]: (style) Statements following return, break, continue, goto or throw will never be executed. [net/auth/src/TAuthenticate.cxx:4205]: (error) Resource leak: fd; [roofit/roofitcore/src/BidirMMapPipe.cxx:1880]: (error) Memory leak: s; [tree/tree/src/TLeaf.cxx:222]: (error) Memory leak: countname; [tree/tree/src/TLeaf.cxx:226]: (error) Memory leak: countname; [tmva/tmva/src/MethodBase.cxx:2783]: (error) Memory leak: pdfS; [tmva/tmva/src/MethodBase.cxx:2783]: (error) Memory leak: pdfB. [roofit/roofitcore/src/RooAbsArg.cxx:280]: (style) Redundant checking of STL container element existence before removing it. [core/dictgen/src/rootcling_impl.cxx:457]: (performance) Possible inefficient checking for 'fieldSelRules' emptiness.; [core/dictgen/src/rootcling_impl.cxx:4573]: (performance) Possible inefficient checking for 'filesIncludedByLinkdef' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:322]: (performance) Possible inefficient checking for 'fWebConn' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:374]: (performance) Possible inefficient checking for 'fCmds' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:419]: (performance) Possible inefficient checking for 'fWebConn' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:475]: (performance) Possible inefficient checking for 'fWebConn' emptiness.; [gui/c",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1343
https://github.com/root-project/root/pull/1343:1977,Availability,error,error,1977,"on is always false. [math/mathcore/src/TMath.cxx:826]: (style) Array index 'ia' is used before limits check.; [math/mathcore/src/TMath.cxx:830]: (style) Array index 'ib' is used before limits check.; [math/mathcore/src/triangle.c:15434]: (style) Array index 'aspectindex' is used before limits check.; [roofit/roofit/src/RooIntegralMorph.cxx:375]: (style) Array index 'igapHigh' is used before limits check. [core/winnt/src/TWinNTSystem.cxx:5035]: (style) Statements following return, break, continue, goto or throw will never be executed.; [tree/treeplayer/src/TSelectorDraw.cxx:380]: (style) Statements following return, break, continue, goto or throw will never be executed. [net/auth/src/TAuthenticate.cxx:4205]: (error) Resource leak: fd; [roofit/roofitcore/src/BidirMMapPipe.cxx:1880]: (error) Memory leak: s; [tree/tree/src/TLeaf.cxx:222]: (error) Memory leak: countname; [tree/tree/src/TLeaf.cxx:226]: (error) Memory leak: countname; [tmva/tmva/src/MethodBase.cxx:2783]: (error) Memory leak: pdfS; [tmva/tmva/src/MethodBase.cxx:2783]: (error) Memory leak: pdfB. [roofit/roofitcore/src/RooAbsArg.cxx:280]: (style) Redundant checking of STL container element existence before removing it. [core/dictgen/src/rootcling_impl.cxx:457]: (performance) Possible inefficient checking for 'fieldSelRules' emptiness.; [core/dictgen/src/rootcling_impl.cxx:4573]: (performance) Possible inefficient checking for 'filesIncludedByLinkdef' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:322]: (performance) Possible inefficient checking for 'fWebConn' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:374]: (performance) Possible inefficient checking for 'fCmds' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:419]: (performance) Possible inefficient checking for 'fWebConn' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:475]: (performance) Possible inefficient checking for 'fWebConn' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:587]: (performance) Possibl",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1343
https://github.com/root-project/root/pull/1343:2041,Availability,error,error,2041,"26]: (style) Array index 'ia' is used before limits check.; [math/mathcore/src/TMath.cxx:830]: (style) Array index 'ib' is used before limits check.; [math/mathcore/src/triangle.c:15434]: (style) Array index 'aspectindex' is used before limits check.; [roofit/roofit/src/RooIntegralMorph.cxx:375]: (style) Array index 'igapHigh' is used before limits check. [core/winnt/src/TWinNTSystem.cxx:5035]: (style) Statements following return, break, continue, goto or throw will never be executed.; [tree/treeplayer/src/TSelectorDraw.cxx:380]: (style) Statements following return, break, continue, goto or throw will never be executed. [net/auth/src/TAuthenticate.cxx:4205]: (error) Resource leak: fd; [roofit/roofitcore/src/BidirMMapPipe.cxx:1880]: (error) Memory leak: s; [tree/tree/src/TLeaf.cxx:222]: (error) Memory leak: countname; [tree/tree/src/TLeaf.cxx:226]: (error) Memory leak: countname; [tmva/tmva/src/MethodBase.cxx:2783]: (error) Memory leak: pdfS; [tmva/tmva/src/MethodBase.cxx:2783]: (error) Memory leak: pdfB. [roofit/roofitcore/src/RooAbsArg.cxx:280]: (style) Redundant checking of STL container element existence before removing it. [core/dictgen/src/rootcling_impl.cxx:457]: (performance) Possible inefficient checking for 'fieldSelRules' emptiness.; [core/dictgen/src/rootcling_impl.cxx:4573]: (performance) Possible inefficient checking for 'filesIncludedByLinkdef' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:322]: (performance) Possible inefficient checking for 'fWebConn' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:374]: (performance) Possible inefficient checking for 'fCmds' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:419]: (performance) Possible inefficient checking for 'fWebConn' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:475]: (performance) Possible inefficient checking for 'fWebConn' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:587]: (performance) Possible inefficient checking for 'fCmds' emptiness.; [gui",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1343
https://github.com/root-project/root/pull/1343:2118,Availability,Redundant,Redundant,2118,"yle) Array index 'ib' is used before limits check.; [math/mathcore/src/triangle.c:15434]: (style) Array index 'aspectindex' is used before limits check.; [roofit/roofit/src/RooIntegralMorph.cxx:375]: (style) Array index 'igapHigh' is used before limits check. [core/winnt/src/TWinNTSystem.cxx:5035]: (style) Statements following return, break, continue, goto or throw will never be executed.; [tree/treeplayer/src/TSelectorDraw.cxx:380]: (style) Statements following return, break, continue, goto or throw will never be executed. [net/auth/src/TAuthenticate.cxx:4205]: (error) Resource leak: fd; [roofit/roofitcore/src/BidirMMapPipe.cxx:1880]: (error) Memory leak: s; [tree/tree/src/TLeaf.cxx:222]: (error) Memory leak: countname; [tree/tree/src/TLeaf.cxx:226]: (error) Memory leak: countname; [tmva/tmva/src/MethodBase.cxx:2783]: (error) Memory leak: pdfS; [tmva/tmva/src/MethodBase.cxx:2783]: (error) Memory leak: pdfB. [roofit/roofitcore/src/RooAbsArg.cxx:280]: (style) Redundant checking of STL container element existence before removing it. [core/dictgen/src/rootcling_impl.cxx:457]: (performance) Possible inefficient checking for 'fieldSelRules' emptiness.; [core/dictgen/src/rootcling_impl.cxx:4573]: (performance) Possible inefficient checking for 'filesIncludedByLinkdef' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:322]: (performance) Possible inefficient checking for 'fWebConn' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:374]: (performance) Possible inefficient checking for 'fCmds' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:419]: (performance) Possible inefficient checking for 'fWebConn' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:475]: (performance) Possible inefficient checking for 'fWebConn' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:587]: (performance) Possible inefficient checking for 'fCmds' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:787]: (performance) Possible inefficient checking for 'fC",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1343
https://github.com/root-project/root/pull/1343:2236,Performance,perform,performance,2236,"' is used before limits check.; [roofit/roofit/src/RooIntegralMorph.cxx:375]: (style) Array index 'igapHigh' is used before limits check. [core/winnt/src/TWinNTSystem.cxx:5035]: (style) Statements following return, break, continue, goto or throw will never be executed.; [tree/treeplayer/src/TSelectorDraw.cxx:380]: (style) Statements following return, break, continue, goto or throw will never be executed. [net/auth/src/TAuthenticate.cxx:4205]: (error) Resource leak: fd; [roofit/roofitcore/src/BidirMMapPipe.cxx:1880]: (error) Memory leak: s; [tree/tree/src/TLeaf.cxx:222]: (error) Memory leak: countname; [tree/tree/src/TLeaf.cxx:226]: (error) Memory leak: countname; [tmva/tmva/src/MethodBase.cxx:2783]: (error) Memory leak: pdfS; [tmva/tmva/src/MethodBase.cxx:2783]: (error) Memory leak: pdfB. [roofit/roofitcore/src/RooAbsArg.cxx:280]: (style) Redundant checking of STL container element existence before removing it. [core/dictgen/src/rootcling_impl.cxx:457]: (performance) Possible inefficient checking for 'fieldSelRules' emptiness.; [core/dictgen/src/rootcling_impl.cxx:4573]: (performance) Possible inefficient checking for 'filesIncludedByLinkdef' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:322]: (performance) Possible inefficient checking for 'fWebConn' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:374]: (performance) Possible inefficient checking for 'fCmds' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:419]: (performance) Possible inefficient checking for 'fWebConn' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:475]: (performance) Possible inefficient checking for 'fWebConn' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:587]: (performance) Possible inefficient checking for 'fCmds' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:787]: (performance) Possible inefficient checking for 'fCmds' emptiness.; [html/src/TDocParser.cxx:684]: (performance) Possible inefficient checking for 'currentType' emptiness.;",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1343
https://github.com/root-project/root/pull/1343:2356,Performance,perform,performance,2356,"limits check. [core/winnt/src/TWinNTSystem.cxx:5035]: (style) Statements following return, break, continue, goto or throw will never be executed.; [tree/treeplayer/src/TSelectorDraw.cxx:380]: (style) Statements following return, break, continue, goto or throw will never be executed. [net/auth/src/TAuthenticate.cxx:4205]: (error) Resource leak: fd; [roofit/roofitcore/src/BidirMMapPipe.cxx:1880]: (error) Memory leak: s; [tree/tree/src/TLeaf.cxx:222]: (error) Memory leak: countname; [tree/tree/src/TLeaf.cxx:226]: (error) Memory leak: countname; [tmva/tmva/src/MethodBase.cxx:2783]: (error) Memory leak: pdfS; [tmva/tmva/src/MethodBase.cxx:2783]: (error) Memory leak: pdfB. [roofit/roofitcore/src/RooAbsArg.cxx:280]: (style) Redundant checking of STL container element existence before removing it. [core/dictgen/src/rootcling_impl.cxx:457]: (performance) Possible inefficient checking for 'fieldSelRules' emptiness.; [core/dictgen/src/rootcling_impl.cxx:4573]: (performance) Possible inefficient checking for 'filesIncludedByLinkdef' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:322]: (performance) Possible inefficient checking for 'fWebConn' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:374]: (performance) Possible inefficient checking for 'fCmds' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:419]: (performance) Possible inefficient checking for 'fWebConn' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:475]: (performance) Possible inefficient checking for 'fWebConn' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:587]: (performance) Possible inefficient checking for 'fCmds' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:787]: (performance) Possible inefficient checking for 'fCmds' emptiness.; [html/src/TDocParser.cxx:684]: (performance) Possible inefficient checking for 'currentType' emptiness.; [proof/proofd/src/XrdProofdManager.cxx:804]: (performance) Possible inefficient checking for 'uwrks' emptiness.; [proof/pro",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1343
https://github.com/root-project/root/pull/1343:2492,Performance,perform,performance,2492,"ver be executed.; [tree/treeplayer/src/TSelectorDraw.cxx:380]: (style) Statements following return, break, continue, goto or throw will never be executed. [net/auth/src/TAuthenticate.cxx:4205]: (error) Resource leak: fd; [roofit/roofitcore/src/BidirMMapPipe.cxx:1880]: (error) Memory leak: s; [tree/tree/src/TLeaf.cxx:222]: (error) Memory leak: countname; [tree/tree/src/TLeaf.cxx:226]: (error) Memory leak: countname; [tmva/tmva/src/MethodBase.cxx:2783]: (error) Memory leak: pdfS; [tmva/tmva/src/MethodBase.cxx:2783]: (error) Memory leak: pdfB. [roofit/roofitcore/src/RooAbsArg.cxx:280]: (style) Redundant checking of STL container element existence before removing it. [core/dictgen/src/rootcling_impl.cxx:457]: (performance) Possible inefficient checking for 'fieldSelRules' emptiness.; [core/dictgen/src/rootcling_impl.cxx:4573]: (performance) Possible inefficient checking for 'filesIncludedByLinkdef' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:322]: (performance) Possible inefficient checking for 'fWebConn' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:374]: (performance) Possible inefficient checking for 'fCmds' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:419]: (performance) Possible inefficient checking for 'fWebConn' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:475]: (performance) Possible inefficient checking for 'fWebConn' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:587]: (performance) Possible inefficient checking for 'fCmds' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:787]: (performance) Possible inefficient checking for 'fCmds' emptiness.; [html/src/TDocParser.cxx:684]: (performance) Possible inefficient checking for 'currentType' emptiness.; [proof/proofd/src/XrdProofdManager.cxx:804]: (performance) Possible inefficient checking for 'uwrks' emptiness.; [proof/proofd/src/XrdProofdSandbox.cxx:467]: (performance) Possible inefficient checking for 'staglst' emptiness.; [proof/proofd/src/XrdProo",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1343
https://github.com/root-project/root/pull/1343:2614,Performance,perform,performance,2614, or throw will never be executed. [net/auth/src/TAuthenticate.cxx:4205]: (error) Resource leak: fd; [roofit/roofitcore/src/BidirMMapPipe.cxx:1880]: (error) Memory leak: s; [tree/tree/src/TLeaf.cxx:222]: (error) Memory leak: countname; [tree/tree/src/TLeaf.cxx:226]: (error) Memory leak: countname; [tmva/tmva/src/MethodBase.cxx:2783]: (error) Memory leak: pdfS; [tmva/tmva/src/MethodBase.cxx:2783]: (error) Memory leak: pdfB. [roofit/roofitcore/src/RooAbsArg.cxx:280]: (style) Redundant checking of STL container element existence before removing it. [core/dictgen/src/rootcling_impl.cxx:457]: (performance) Possible inefficient checking for 'fieldSelRules' emptiness.; [core/dictgen/src/rootcling_impl.cxx:4573]: (performance) Possible inefficient checking for 'filesIncludedByLinkdef' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:322]: (performance) Possible inefficient checking for 'fWebConn' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:374]: (performance) Possible inefficient checking for 'fCmds' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:419]: (performance) Possible inefficient checking for 'fWebConn' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:475]: (performance) Possible inefficient checking for 'fWebConn' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:587]: (performance) Possible inefficient checking for 'fCmds' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:787]: (performance) Possible inefficient checking for 'fCmds' emptiness.; [html/src/TDocParser.cxx:684]: (performance) Possible inefficient checking for 'currentType' emptiness.; [proof/proofd/src/XrdProofdManager.cxx:804]: (performance) Possible inefficient checking for 'uwrks' emptiness.; [proof/proofd/src/XrdProofdSandbox.cxx:467]: (performance) Possible inefficient checking for 'staglst' emptiness.; [proof/proofd/src/XrdProofdSandbox.cxx:571]: (performance) Possible inefficient checking for 'actln' emptiness.; [roofit/roofitcore/src/RooSimWST,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1343
https://github.com/root-project/root/pull/1343:2733,Performance,perform,performance,2733,rc/BidirMMapPipe.cxx:1880]: (error) Memory leak: s; [tree/tree/src/TLeaf.cxx:222]: (error) Memory leak: countname; [tree/tree/src/TLeaf.cxx:226]: (error) Memory leak: countname; [tmva/tmva/src/MethodBase.cxx:2783]: (error) Memory leak: pdfS; [tmva/tmva/src/MethodBase.cxx:2783]: (error) Memory leak: pdfB. [roofit/roofitcore/src/RooAbsArg.cxx:280]: (style) Redundant checking of STL container element existence before removing it. [core/dictgen/src/rootcling_impl.cxx:457]: (performance) Possible inefficient checking for 'fieldSelRules' emptiness.; [core/dictgen/src/rootcling_impl.cxx:4573]: (performance) Possible inefficient checking for 'filesIncludedByLinkdef' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:322]: (performance) Possible inefficient checking for 'fWebConn' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:374]: (performance) Possible inefficient checking for 'fCmds' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:419]: (performance) Possible inefficient checking for 'fWebConn' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:475]: (performance) Possible inefficient checking for 'fWebConn' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:587]: (performance) Possible inefficient checking for 'fCmds' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:787]: (performance) Possible inefficient checking for 'fCmds' emptiness.; [html/src/TDocParser.cxx:684]: (performance) Possible inefficient checking for 'currentType' emptiness.; [proof/proofd/src/XrdProofdManager.cxx:804]: (performance) Possible inefficient checking for 'uwrks' emptiness.; [proof/proofd/src/XrdProofdSandbox.cxx:467]: (performance) Possible inefficient checking for 'staglst' emptiness.; [proof/proofd/src/XrdProofdSandbox.cxx:571]: (performance) Possible inefficient checking for 'actln' emptiness.; [roofit/roofitcore/src/RooSimWSTool.cxx:574]: (performance) Possible inefficient checking for 'slist' emptiness. all the reports Prefer prefix ++/-- oper,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1343
https://github.com/root-project/root/pull/1343:2855,Performance,perform,performance,2855,rror) Memory leak: s; [tree/tree/src/TLeaf.cxx:222]: (error) Memory leak: countname; [tree/tree/src/TLeaf.cxx:226]: (error) Memory leak: countname; [tmva/tmva/src/MethodBase.cxx:2783]: (error) Memory leak: pdfS; [tmva/tmva/src/MethodBase.cxx:2783]: (error) Memory leak: pdfB. [roofit/roofitcore/src/RooAbsArg.cxx:280]: (style) Redundant checking of STL container element existence before removing it. [core/dictgen/src/rootcling_impl.cxx:457]: (performance) Possible inefficient checking for 'fieldSelRules' emptiness.; [core/dictgen/src/rootcling_impl.cxx:4573]: (performance) Possible inefficient checking for 'filesIncludedByLinkdef' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:322]: (performance) Possible inefficient checking for 'fWebConn' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:374]: (performance) Possible inefficient checking for 'fCmds' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:419]: (performance) Possible inefficient checking for 'fWebConn' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:475]: (performance) Possible inefficient checking for 'fWebConn' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:587]: (performance) Possible inefficient checking for 'fCmds' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:787]: (performance) Possible inefficient checking for 'fCmds' emptiness.; [html/src/TDocParser.cxx:684]: (performance) Possible inefficient checking for 'currentType' emptiness.; [proof/proofd/src/XrdProofdManager.cxx:804]: (performance) Possible inefficient checking for 'uwrks' emptiness.; [proof/proofd/src/XrdProofdSandbox.cxx:467]: (performance) Possible inefficient checking for 'staglst' emptiness.; [proof/proofd/src/XrdProofdSandbox.cxx:571]: (performance) Possible inefficient checking for 'actln' emptiness.; [roofit/roofitcore/src/RooSimWSTool.cxx:574]: (performance) Possible inefficient checking for 'slist' emptiness. all the reports Prefer prefix ++/-- operators for non-primitive types,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1343
https://github.com/root-project/root/pull/1343:2977,Performance,perform,performance,2977,rror) Memory leak: s; [tree/tree/src/TLeaf.cxx:222]: (error) Memory leak: countname; [tree/tree/src/TLeaf.cxx:226]: (error) Memory leak: countname; [tmva/tmva/src/MethodBase.cxx:2783]: (error) Memory leak: pdfS; [tmva/tmva/src/MethodBase.cxx:2783]: (error) Memory leak: pdfB. [roofit/roofitcore/src/RooAbsArg.cxx:280]: (style) Redundant checking of STL container element existence before removing it. [core/dictgen/src/rootcling_impl.cxx:457]: (performance) Possible inefficient checking for 'fieldSelRules' emptiness.; [core/dictgen/src/rootcling_impl.cxx:4573]: (performance) Possible inefficient checking for 'filesIncludedByLinkdef' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:322]: (performance) Possible inefficient checking for 'fWebConn' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:374]: (performance) Possible inefficient checking for 'fCmds' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:419]: (performance) Possible inefficient checking for 'fWebConn' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:475]: (performance) Possible inefficient checking for 'fWebConn' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:587]: (performance) Possible inefficient checking for 'fCmds' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:787]: (performance) Possible inefficient checking for 'fCmds' emptiness.; [html/src/TDocParser.cxx:684]: (performance) Possible inefficient checking for 'currentType' emptiness.; [proof/proofd/src/XrdProofdManager.cxx:804]: (performance) Possible inefficient checking for 'uwrks' emptiness.; [proof/proofd/src/XrdProofdSandbox.cxx:467]: (performance) Possible inefficient checking for 'staglst' emptiness.; [proof/proofd/src/XrdProofdSandbox.cxx:571]: (performance) Possible inefficient checking for 'actln' emptiness.; [roofit/roofitcore/src/RooSimWSTool.cxx:574]: (performance) Possible inefficient checking for 'slist' emptiness. all the reports Prefer prefix ++/-- operators for non-primitive types,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1343
https://github.com/root-project/root/pull/1343:3096,Performance,perform,performance,3096,rror) Memory leak: s; [tree/tree/src/TLeaf.cxx:222]: (error) Memory leak: countname; [tree/tree/src/TLeaf.cxx:226]: (error) Memory leak: countname; [tmva/tmva/src/MethodBase.cxx:2783]: (error) Memory leak: pdfS; [tmva/tmva/src/MethodBase.cxx:2783]: (error) Memory leak: pdfB. [roofit/roofitcore/src/RooAbsArg.cxx:280]: (style) Redundant checking of STL container element existence before removing it. [core/dictgen/src/rootcling_impl.cxx:457]: (performance) Possible inefficient checking for 'fieldSelRules' emptiness.; [core/dictgen/src/rootcling_impl.cxx:4573]: (performance) Possible inefficient checking for 'filesIncludedByLinkdef' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:322]: (performance) Possible inefficient checking for 'fWebConn' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:374]: (performance) Possible inefficient checking for 'fCmds' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:419]: (performance) Possible inefficient checking for 'fWebConn' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:475]: (performance) Possible inefficient checking for 'fWebConn' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:587]: (performance) Possible inefficient checking for 'fCmds' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:787]: (performance) Possible inefficient checking for 'fCmds' emptiness.; [html/src/TDocParser.cxx:684]: (performance) Possible inefficient checking for 'currentType' emptiness.; [proof/proofd/src/XrdProofdManager.cxx:804]: (performance) Possible inefficient checking for 'uwrks' emptiness.; [proof/proofd/src/XrdProofdSandbox.cxx:467]: (performance) Possible inefficient checking for 'staglst' emptiness.; [proof/proofd/src/XrdProofdSandbox.cxx:571]: (performance) Possible inefficient checking for 'actln' emptiness.; [roofit/roofitcore/src/RooSimWSTool.cxx:574]: (performance) Possible inefficient checking for 'slist' emptiness. all the reports Prefer prefix ++/-- operators for non-primitive types,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1343
https://github.com/root-project/root/pull/1343:3195,Performance,perform,performance,3195,rror) Memory leak: s; [tree/tree/src/TLeaf.cxx:222]: (error) Memory leak: countname; [tree/tree/src/TLeaf.cxx:226]: (error) Memory leak: countname; [tmva/tmva/src/MethodBase.cxx:2783]: (error) Memory leak: pdfS; [tmva/tmva/src/MethodBase.cxx:2783]: (error) Memory leak: pdfB. [roofit/roofitcore/src/RooAbsArg.cxx:280]: (style) Redundant checking of STL container element existence before removing it. [core/dictgen/src/rootcling_impl.cxx:457]: (performance) Possible inefficient checking for 'fieldSelRules' emptiness.; [core/dictgen/src/rootcling_impl.cxx:4573]: (performance) Possible inefficient checking for 'filesIncludedByLinkdef' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:322]: (performance) Possible inefficient checking for 'fWebConn' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:374]: (performance) Possible inefficient checking for 'fCmds' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:419]: (performance) Possible inefficient checking for 'fWebConn' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:475]: (performance) Possible inefficient checking for 'fWebConn' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:587]: (performance) Possible inefficient checking for 'fCmds' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:787]: (performance) Possible inefficient checking for 'fCmds' emptiness.; [html/src/TDocParser.cxx:684]: (performance) Possible inefficient checking for 'currentType' emptiness.; [proof/proofd/src/XrdProofdManager.cxx:804]: (performance) Possible inefficient checking for 'uwrks' emptiness.; [proof/proofd/src/XrdProofdSandbox.cxx:467]: (performance) Possible inefficient checking for 'staglst' emptiness.; [proof/proofd/src/XrdProofdSandbox.cxx:571]: (performance) Possible inefficient checking for 'actln' emptiness.; [roofit/roofitcore/src/RooSimWSTool.cxx:574]: (performance) Possible inefficient checking for 'slist' emptiness. all the reports Prefer prefix ++/-- operators for non-primitive types,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1343
https://github.com/root-project/root/pull/1343:3314,Performance,perform,performance,3314,rror) Memory leak: s; [tree/tree/src/TLeaf.cxx:222]: (error) Memory leak: countname; [tree/tree/src/TLeaf.cxx:226]: (error) Memory leak: countname; [tmva/tmva/src/MethodBase.cxx:2783]: (error) Memory leak: pdfS; [tmva/tmva/src/MethodBase.cxx:2783]: (error) Memory leak: pdfB. [roofit/roofitcore/src/RooAbsArg.cxx:280]: (style) Redundant checking of STL container element existence before removing it. [core/dictgen/src/rootcling_impl.cxx:457]: (performance) Possible inefficient checking for 'fieldSelRules' emptiness.; [core/dictgen/src/rootcling_impl.cxx:4573]: (performance) Possible inefficient checking for 'filesIncludedByLinkdef' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:322]: (performance) Possible inefficient checking for 'fWebConn' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:374]: (performance) Possible inefficient checking for 'fCmds' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:419]: (performance) Possible inefficient checking for 'fWebConn' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:475]: (performance) Possible inefficient checking for 'fWebConn' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:587]: (performance) Possible inefficient checking for 'fCmds' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:787]: (performance) Possible inefficient checking for 'fCmds' emptiness.; [html/src/TDocParser.cxx:684]: (performance) Possible inefficient checking for 'currentType' emptiness.; [proof/proofd/src/XrdProofdManager.cxx:804]: (performance) Possible inefficient checking for 'uwrks' emptiness.; [proof/proofd/src/XrdProofdSandbox.cxx:467]: (performance) Possible inefficient checking for 'staglst' emptiness.; [proof/proofd/src/XrdProofdSandbox.cxx:571]: (performance) Possible inefficient checking for 'actln' emptiness.; [roofit/roofitcore/src/RooSimWSTool.cxx:574]: (performance) Possible inefficient checking for 'slist' emptiness. all the reports Prefer prefix ++/-- operators for non-primitive types,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1343
https://github.com/root-project/root/pull/1343:3427,Performance,perform,performance,3427,rror) Memory leak: s; [tree/tree/src/TLeaf.cxx:222]: (error) Memory leak: countname; [tree/tree/src/TLeaf.cxx:226]: (error) Memory leak: countname; [tmva/tmva/src/MethodBase.cxx:2783]: (error) Memory leak: pdfS; [tmva/tmva/src/MethodBase.cxx:2783]: (error) Memory leak: pdfB. [roofit/roofitcore/src/RooAbsArg.cxx:280]: (style) Redundant checking of STL container element existence before removing it. [core/dictgen/src/rootcling_impl.cxx:457]: (performance) Possible inefficient checking for 'fieldSelRules' emptiness.; [core/dictgen/src/rootcling_impl.cxx:4573]: (performance) Possible inefficient checking for 'filesIncludedByLinkdef' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:322]: (performance) Possible inefficient checking for 'fWebConn' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:374]: (performance) Possible inefficient checking for 'fCmds' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:419]: (performance) Possible inefficient checking for 'fWebConn' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:475]: (performance) Possible inefficient checking for 'fWebConn' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:587]: (performance) Possible inefficient checking for 'fCmds' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:787]: (performance) Possible inefficient checking for 'fCmds' emptiness.; [html/src/TDocParser.cxx:684]: (performance) Possible inefficient checking for 'currentType' emptiness.; [proof/proofd/src/XrdProofdManager.cxx:804]: (performance) Possible inefficient checking for 'uwrks' emptiness.; [proof/proofd/src/XrdProofdSandbox.cxx:467]: (performance) Possible inefficient checking for 'staglst' emptiness.; [proof/proofd/src/XrdProofdSandbox.cxx:571]: (performance) Possible inefficient checking for 'actln' emptiness.; [roofit/roofitcore/src/RooSimWSTool.cxx:574]: (performance) Possible inefficient checking for 'slist' emptiness. all the reports Prefer prefix ++/-- operators for non-primitive types,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1343
https://github.com/root-project/root/pull/1343:3542,Performance,perform,performance,3542,rror) Memory leak: s; [tree/tree/src/TLeaf.cxx:222]: (error) Memory leak: countname; [tree/tree/src/TLeaf.cxx:226]: (error) Memory leak: countname; [tmva/tmva/src/MethodBase.cxx:2783]: (error) Memory leak: pdfS; [tmva/tmva/src/MethodBase.cxx:2783]: (error) Memory leak: pdfB. [roofit/roofitcore/src/RooAbsArg.cxx:280]: (style) Redundant checking of STL container element existence before removing it. [core/dictgen/src/rootcling_impl.cxx:457]: (performance) Possible inefficient checking for 'fieldSelRules' emptiness.; [core/dictgen/src/rootcling_impl.cxx:4573]: (performance) Possible inefficient checking for 'filesIncludedByLinkdef' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:322]: (performance) Possible inefficient checking for 'fWebConn' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:374]: (performance) Possible inefficient checking for 'fCmds' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:419]: (performance) Possible inefficient checking for 'fWebConn' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:475]: (performance) Possible inefficient checking for 'fWebConn' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:587]: (performance) Possible inefficient checking for 'fCmds' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:787]: (performance) Possible inefficient checking for 'fCmds' emptiness.; [html/src/TDocParser.cxx:684]: (performance) Possible inefficient checking for 'currentType' emptiness.; [proof/proofd/src/XrdProofdManager.cxx:804]: (performance) Possible inefficient checking for 'uwrks' emptiness.; [proof/proofd/src/XrdProofdSandbox.cxx:467]: (performance) Possible inefficient checking for 'staglst' emptiness.; [proof/proofd/src/XrdProofdSandbox.cxx:571]: (performance) Possible inefficient checking for 'actln' emptiness.; [roofit/roofitcore/src/RooSimWSTool.cxx:574]: (performance) Possible inefficient checking for 'slist' emptiness. all the reports Prefer prefix ++/-- operators for non-primitive types,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1343
https://github.com/root-project/root/pull/1343:3656,Performance,perform,performance,3656,rror) Memory leak: s; [tree/tree/src/TLeaf.cxx:222]: (error) Memory leak: countname; [tree/tree/src/TLeaf.cxx:226]: (error) Memory leak: countname; [tmva/tmva/src/MethodBase.cxx:2783]: (error) Memory leak: pdfS; [tmva/tmva/src/MethodBase.cxx:2783]: (error) Memory leak: pdfB. [roofit/roofitcore/src/RooAbsArg.cxx:280]: (style) Redundant checking of STL container element existence before removing it. [core/dictgen/src/rootcling_impl.cxx:457]: (performance) Possible inefficient checking for 'fieldSelRules' emptiness.; [core/dictgen/src/rootcling_impl.cxx:4573]: (performance) Possible inefficient checking for 'filesIncludedByLinkdef' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:322]: (performance) Possible inefficient checking for 'fWebConn' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:374]: (performance) Possible inefficient checking for 'fCmds' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:419]: (performance) Possible inefficient checking for 'fWebConn' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:475]: (performance) Possible inefficient checking for 'fWebConn' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:587]: (performance) Possible inefficient checking for 'fCmds' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:787]: (performance) Possible inefficient checking for 'fCmds' emptiness.; [html/src/TDocParser.cxx:684]: (performance) Possible inefficient checking for 'currentType' emptiness.; [proof/proofd/src/XrdProofdManager.cxx:804]: (performance) Possible inefficient checking for 'uwrks' emptiness.; [proof/proofd/src/XrdProofdSandbox.cxx:467]: (performance) Possible inefficient checking for 'staglst' emptiness.; [proof/proofd/src/XrdProofdSandbox.cxx:571]: (performance) Possible inefficient checking for 'actln' emptiness.; [roofit/roofitcore/src/RooSimWSTool.cxx:574]: (performance) Possible inefficient checking for 'slist' emptiness. all the reports Prefer prefix ++/-- operators for non-primitive types,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1343
https://github.com/root-project/root/pull/1343:775,Safety,Redund,Redundant,775,"[net/monalisa/src/TMonaLisaWriter.cxx:956] -> [net/monalisa/src/TMonaLisaWriter.cxx:957]: (error) Iterator 'iter' used after element has been erased.; [proof/proofd/src/XrdProofdProofServMgr.cxx:4648] -> [proof/proofd/src/XrdProofdProofServMgr.cxx:4646]: (error) Iterator 'iter' used after element has been erased. [math/minuit2/src/Minuit2Minimizer.cxx:669] -> [math/minuit2/src/Minuit2Minimizer.cxx:669]: (style) Same expression on both sides of '||'.; [math/minuit2/src/Minuit2Minimizer.cxx:736] -> [math/minuit2/src/Minuit2Minimizer.cxx:736]: (style) Same expression on both sides of '||'.; [math/minuit2/src/Minuit2Minimizer.cxx:753] -> [math/minuit2/src/Minuit2Minimizer.cxx:753]: (style) Same expression on both sides of '||'. [tree/tree/src/TBasket.cxx:852]: (style) Redundant condition: If 'flag >= 80', the comparison 'flag' is always true.; [misc/table/src/TFileIter.cxx:467] -> [misc/table/src/TFileIter.cxx:468]: (warning) Identical condition 'thisRunNumber<runNumber', second condition is always false. [math/mathcore/src/TMath.cxx:826]: (style) Array index 'ia' is used before limits check.; [math/mathcore/src/TMath.cxx:830]: (style) Array index 'ib' is used before limits check.; [math/mathcore/src/triangle.c:15434]: (style) Array index 'aspectindex' is used before limits check.; [roofit/roofit/src/RooIntegralMorph.cxx:375]: (style) Array index 'igapHigh' is used before limits check. [core/winnt/src/TWinNTSystem.cxx:5035]: (style) Statements following return, break, continue, goto or throw will never be executed.; [tree/treeplayer/src/TSelectorDraw.cxx:380]: (style) Statements following return, break, continue, goto or throw will never be executed. [net/auth/src/TAuthenticate.cxx:4205]: (error) Resource leak: fd; [roofit/roofitcore/src/BidirMMapPipe.cxx:1880]: (error) Memory leak: s; [tree/tree/src/TLeaf.cxx:222]: (error) Memory leak: countname; [tree/tree/src/TLeaf.cxx:226]: (error) Memory leak: countname; [tmva/tmva/src/MethodBase.cxx:2783]: (error) Memory leak: pdfS",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1343
https://github.com/root-project/root/pull/1343:2118,Safety,Redund,Redundant,2118,"yle) Array index 'ib' is used before limits check.; [math/mathcore/src/triangle.c:15434]: (style) Array index 'aspectindex' is used before limits check.; [roofit/roofit/src/RooIntegralMorph.cxx:375]: (style) Array index 'igapHigh' is used before limits check. [core/winnt/src/TWinNTSystem.cxx:5035]: (style) Statements following return, break, continue, goto or throw will never be executed.; [tree/treeplayer/src/TSelectorDraw.cxx:380]: (style) Statements following return, break, continue, goto or throw will never be executed. [net/auth/src/TAuthenticate.cxx:4205]: (error) Resource leak: fd; [roofit/roofitcore/src/BidirMMapPipe.cxx:1880]: (error) Memory leak: s; [tree/tree/src/TLeaf.cxx:222]: (error) Memory leak: countname; [tree/tree/src/TLeaf.cxx:226]: (error) Memory leak: countname; [tmva/tmva/src/MethodBase.cxx:2783]: (error) Memory leak: pdfS; [tmva/tmva/src/MethodBase.cxx:2783]: (error) Memory leak: pdfB. [roofit/roofitcore/src/RooAbsArg.cxx:280]: (style) Redundant checking of STL container element existence before removing it. [core/dictgen/src/rootcling_impl.cxx:457]: (performance) Possible inefficient checking for 'fieldSelRules' emptiness.; [core/dictgen/src/rootcling_impl.cxx:4573]: (performance) Possible inefficient checking for 'filesIncludedByLinkdef' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:322]: (performance) Possible inefficient checking for 'fWebConn' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:374]: (performance) Possible inefficient checking for 'fCmds' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:419]: (performance) Possible inefficient checking for 'fWebConn' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:475]: (performance) Possible inefficient checking for 'fWebConn' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:587]: (performance) Possible inefficient checking for 'fCmds' emptiness.; [gui/canvaspainter/v7/src/TCanvasPainter.cxx:787]: (performance) Possible inefficient checking for 'fC",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1343
https://github.com/root-project/root/pull/1344:32,Performance,load,load,32,This will allow us to uniformly load all modules tagged as `[system]`. This way we avoid explicitly mentioning the module names (helpful for OSX).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1344
https://github.com/root-project/root/pull/1344:83,Safety,avoid,avoid,83,This will allow us to uniformly load all modules tagged as `[system]`. This way we avoid explicitly mentioning the module names (helpful for OSX).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1344
https://github.com/root-project/root/pull/1345:477,Deployability,patch,patch,477,"We need to disable the validation of PCM files because rootcling; serializes what it sees. For instance, we even serialize in the PCM; file some temporary lookup buffers and the contents of the module maps. We disable the PCH validation but that is not sufficient for PCM. The; TCling code `fInterpreter->getCI()->getPreprocessorOpts().DisablePCHValidation = true`; is not enough because we rely more on the clang driver to setup correctly; our modules-aware interpreter. This patch just uses the correct flag when setting up cling. A proper fix to this issue is thoroughly described in RE-0003 (rootcling; refactor proposal).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1345
https://github.com/root-project/root/pull/1345:607,Modifiability,refactor,refactor,607,"We need to disable the validation of PCM files because rootcling; serializes what it sees. For instance, we even serialize in the PCM; file some temporary lookup buffers and the contents of the module maps. We disable the PCH validation but that is not sufficient for PCM. The; TCling code `fInterpreter->getCI()->getPreprocessorOpts().DisablePCHValidation = true`; is not enough because we rely more on the clang driver to setup correctly; our modules-aware interpreter. This patch just uses the correct flag when setting up cling. A proper fix to this issue is thoroughly described in RE-0003 (rootcling; refactor proposal).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1345
https://github.com/root-project/root/pull/1345:23,Security,validat,validation,23,"We need to disable the validation of PCM files because rootcling; serializes what it sees. For instance, we even serialize in the PCM; file some temporary lookup buffers and the contents of the module maps. We disable the PCH validation but that is not sufficient for PCM. The; TCling code `fInterpreter->getCI()->getPreprocessorOpts().DisablePCHValidation = true`; is not enough because we rely more on the clang driver to setup correctly; our modules-aware interpreter. This patch just uses the correct flag when setting up cling. A proper fix to this issue is thoroughly described in RE-0003 (rootcling; refactor proposal).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1345
https://github.com/root-project/root/pull/1345:226,Security,validat,validation,226,"We need to disable the validation of PCM files because rootcling; serializes what it sees. For instance, we even serialize in the PCM; file some temporary lookup buffers and the contents of the module maps. We disable the PCH validation but that is not sufficient for PCM. The; TCling code `fInterpreter->getCI()->getPreprocessorOpts().DisablePCHValidation = true`; is not enough because we rely more on the clang driver to setup correctly; our modules-aware interpreter. This patch just uses the correct flag when setting up cling. A proper fix to this issue is thoroughly described in RE-0003 (rootcling; refactor proposal).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1345
https://github.com/root-project/root/pull/1350:41,Performance,perform,performance,41,This does not seem to affect the startup performance of ROOT.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1350
https://github.com/root-project/root/pull/1352:9,Deployability,patch,patch,9,"Original patch by Georgios Bitzes, manual rebase onto master. Compiles and works correctly against upstream/master on CC7. See here for more information: https://tmaier.web.cern.ch/tmaier/ROOTDavixRedirection/davix-root-fix.html. Please also backport this patch to 6-08 and 6-10. Thanks!; Mario",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1352
https://github.com/root-project/root/pull/1352:256,Deployability,patch,patch,256,"Original patch by Georgios Bitzes, manual rebase onto master. Compiles and works correctly against upstream/master on CC7. See here for more information: https://tmaier.web.cern.ch/tmaier/ROOTDavixRedirection/davix-root-fix.html. Please also backport this patch to 6-08 and 6-10. Thanks!; Mario",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1352
https://github.com/root-project/root/pull/1353:80,Availability,error,errors,80,"This PR adds a new callback to the PyKeras method.; I've build ROOT without any errors and run the ctests and all of them passed. . You can try out this new callback with:; `sudo pip install keras --upgrade`; `sudo pip install tensorflow --upgrade`. And then run: `python tutorials/tmva/keras/ClassificationKeras.py`. The callback will create a new directory called 'logs'.; Then you can call while or after training tensorboard: `tensorboard --logdir=./logs`; Now you can open the link from your terminal and visualize the network and training. ; The `ClassificationKeras.py` script, seems to be not compatible with the Keras 2.x API right now, therefore you can revert the changes of this PR in this specific script after testing. More information on TensorBoard: https://www.tensorflow.org/get_started/summaries_and_tensorboard. Also pointing to the author of the PyKeras implementation: @stwunsch. Thanks in advance for reviewing this PR!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1353
https://github.com/root-project/root/pull/1353:183,Deployability,install,install,183,"This PR adds a new callback to the PyKeras method.; I've build ROOT without any errors and run the ctests and all of them passed. . You can try out this new callback with:; `sudo pip install keras --upgrade`; `sudo pip install tensorflow --upgrade`. And then run: `python tutorials/tmva/keras/ClassificationKeras.py`. The callback will create a new directory called 'logs'.; Then you can call while or after training tensorboard: `tensorboard --logdir=./logs`; Now you can open the link from your terminal and visualize the network and training. ; The `ClassificationKeras.py` script, seems to be not compatible with the Keras 2.x API right now, therefore you can revert the changes of this PR in this specific script after testing. More information on TensorBoard: https://www.tensorflow.org/get_started/summaries_and_tensorboard. Also pointing to the author of the PyKeras implementation: @stwunsch. Thanks in advance for reviewing this PR!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1353
https://github.com/root-project/root/pull/1353:199,Deployability,upgrade,upgrade,199,"This PR adds a new callback to the PyKeras method.; I've build ROOT without any errors and run the ctests and all of them passed. . You can try out this new callback with:; `sudo pip install keras --upgrade`; `sudo pip install tensorflow --upgrade`. And then run: `python tutorials/tmva/keras/ClassificationKeras.py`. The callback will create a new directory called 'logs'.; Then you can call while or after training tensorboard: `tensorboard --logdir=./logs`; Now you can open the link from your terminal and visualize the network and training. ; The `ClassificationKeras.py` script, seems to be not compatible with the Keras 2.x API right now, therefore you can revert the changes of this PR in this specific script after testing. More information on TensorBoard: https://www.tensorflow.org/get_started/summaries_and_tensorboard. Also pointing to the author of the PyKeras implementation: @stwunsch. Thanks in advance for reviewing this PR!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1353
https://github.com/root-project/root/pull/1353:219,Deployability,install,install,219,"This PR adds a new callback to the PyKeras method.; I've build ROOT without any errors and run the ctests and all of them passed. . You can try out this new callback with:; `sudo pip install keras --upgrade`; `sudo pip install tensorflow --upgrade`. And then run: `python tutorials/tmva/keras/ClassificationKeras.py`. The callback will create a new directory called 'logs'.; Then you can call while or after training tensorboard: `tensorboard --logdir=./logs`; Now you can open the link from your terminal and visualize the network and training. ; The `ClassificationKeras.py` script, seems to be not compatible with the Keras 2.x API right now, therefore you can revert the changes of this PR in this specific script after testing. More information on TensorBoard: https://www.tensorflow.org/get_started/summaries_and_tensorboard. Also pointing to the author of the PyKeras implementation: @stwunsch. Thanks in advance for reviewing this PR!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1353
https://github.com/root-project/root/pull/1353:240,Deployability,upgrade,upgrade,240,"This PR adds a new callback to the PyKeras method.; I've build ROOT without any errors and run the ctests and all of them passed. . You can try out this new callback with:; `sudo pip install keras --upgrade`; `sudo pip install tensorflow --upgrade`. And then run: `python tutorials/tmva/keras/ClassificationKeras.py`. The callback will create a new directory called 'logs'.; Then you can call while or after training tensorboard: `tensorboard --logdir=./logs`; Now you can open the link from your terminal and visualize the network and training. ; The `ClassificationKeras.py` script, seems to be not compatible with the Keras 2.x API right now, therefore you can revert the changes of this PR in this specific script after testing. More information on TensorBoard: https://www.tensorflow.org/get_started/summaries_and_tensorboard. Also pointing to the author of the PyKeras implementation: @stwunsch. Thanks in advance for reviewing this PR!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1353
https://github.com/root-project/root/pull/1353:367,Testability,log,logs,367,"This PR adds a new callback to the PyKeras method.; I've build ROOT without any errors and run the ctests and all of them passed. . You can try out this new callback with:; `sudo pip install keras --upgrade`; `sudo pip install tensorflow --upgrade`. And then run: `python tutorials/tmva/keras/ClassificationKeras.py`. The callback will create a new directory called 'logs'.; Then you can call while or after training tensorboard: `tensorboard --logdir=./logs`; Now you can open the link from your terminal and visualize the network and training. ; The `ClassificationKeras.py` script, seems to be not compatible with the Keras 2.x API right now, therefore you can revert the changes of this PR in this specific script after testing. More information on TensorBoard: https://www.tensorflow.org/get_started/summaries_and_tensorboard. Also pointing to the author of the PyKeras implementation: @stwunsch. Thanks in advance for reviewing this PR!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1353
https://github.com/root-project/root/pull/1353:445,Testability,log,logdir,445,"This PR adds a new callback to the PyKeras method.; I've build ROOT without any errors and run the ctests and all of them passed. . You can try out this new callback with:; `sudo pip install keras --upgrade`; `sudo pip install tensorflow --upgrade`. And then run: `python tutorials/tmva/keras/ClassificationKeras.py`. The callback will create a new directory called 'logs'.; Then you can call while or after training tensorboard: `tensorboard --logdir=./logs`; Now you can open the link from your terminal and visualize the network and training. ; The `ClassificationKeras.py` script, seems to be not compatible with the Keras 2.x API right now, therefore you can revert the changes of this PR in this specific script after testing. More information on TensorBoard: https://www.tensorflow.org/get_started/summaries_and_tensorboard. Also pointing to the author of the PyKeras implementation: @stwunsch. Thanks in advance for reviewing this PR!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1353
https://github.com/root-project/root/pull/1353:454,Testability,log,logs,454,"This PR adds a new callback to the PyKeras method.; I've build ROOT without any errors and run the ctests and all of them passed. . You can try out this new callback with:; `sudo pip install keras --upgrade`; `sudo pip install tensorflow --upgrade`. And then run: `python tutorials/tmva/keras/ClassificationKeras.py`. The callback will create a new directory called 'logs'.; Then you can call while or after training tensorboard: `tensorboard --logdir=./logs`; Now you can open the link from your terminal and visualize the network and training. ; The `ClassificationKeras.py` script, seems to be not compatible with the Keras 2.x API right now, therefore you can revert the changes of this PR in this specific script after testing. More information on TensorBoard: https://www.tensorflow.org/get_started/summaries_and_tensorboard. Also pointing to the author of the PyKeras implementation: @stwunsch. Thanks in advance for reviewing this PR!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1353
https://github.com/root-project/root/pull/1353:724,Testability,test,testing,724,"This PR adds a new callback to the PyKeras method.; I've build ROOT without any errors and run the ctests and all of them passed. . You can try out this new callback with:; `sudo pip install keras --upgrade`; `sudo pip install tensorflow --upgrade`. And then run: `python tutorials/tmva/keras/ClassificationKeras.py`. The callback will create a new directory called 'logs'.; Then you can call while or after training tensorboard: `tensorboard --logdir=./logs`; Now you can open the link from your terminal and visualize the network and training. ; The `ClassificationKeras.py` script, seems to be not compatible with the Keras 2.x API right now, therefore you can revert the changes of this PR in this specific script after testing. More information on TensorBoard: https://www.tensorflow.org/get_started/summaries_and_tensorboard. Also pointing to the author of the PyKeras implementation: @stwunsch. Thanks in advance for reviewing this PR!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1353
https://github.com/root-project/root/pull/1355:161,Integrability,inject,injected,161,"ROOT can't autoparse classes inside namespaces with the rootmap; system (as the loading callbacks don't correctly land where; they are supposed to land with our injected namespaces). As this; turns out to be a feature of some kind, let's preload TMVA/TreePlayer; to fix all failing tests that are related to this feature/bug with; modules enabled.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1355
https://github.com/root-project/root/pull/1355:80,Performance,load,loading,80,"ROOT can't autoparse classes inside namespaces with the rootmap; system (as the loading callbacks don't correctly land where; they are supposed to land with our injected namespaces). As this; turns out to be a feature of some kind, let's preload TMVA/TreePlayer; to fix all failing tests that are related to this feature/bug with; modules enabled.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1355
https://github.com/root-project/root/pull/1355:161,Security,inject,injected,161,"ROOT can't autoparse classes inside namespaces with the rootmap; system (as the loading callbacks don't correctly land where; they are supposed to land with our injected namespaces). As this; turns out to be a feature of some kind, let's preload TMVA/TreePlayer; to fix all failing tests that are related to this feature/bug with; modules enabled.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1355
https://github.com/root-project/root/pull/1355:282,Testability,test,tests,282,"ROOT can't autoparse classes inside namespaces with the rootmap; system (as the loading callbacks don't correctly land where; they are supposed to land with our injected namespaces). As this; turns out to be a feature of some kind, let's preload TMVA/TreePlayer; to fix all failing tests that are related to this feature/bug with; modules enabled.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1355
https://github.com/root-project/root/pull/1356:325,Deployability,patch,patch,325,"…les. When we load a library, during its static intialization it calls; TCling::RegisterModule to make ROOT's runtime aware of that load. Regular; ROOT also will do some header parsing to add the minimal infrastructure; in place for cling to be able to call into that library. C++ modules define away the need to parse. This patch intends to skip all; parsing at this stage and fix recursive parsing issues for C++ modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1356
https://github.com/root-project/root/pull/1356:14,Performance,load,load,14,"…les. When we load a library, during its static intialization it calls; TCling::RegisterModule to make ROOT's runtime aware of that load. Regular; ROOT also will do some header parsing to add the minimal infrastructure; in place for cling to be able to call into that library. C++ modules define away the need to parse. This patch intends to skip all; parsing at this stage and fix recursive parsing issues for C++ modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1356
https://github.com/root-project/root/pull/1356:132,Performance,load,load,132,"…les. When we load a library, during its static intialization it calls; TCling::RegisterModule to make ROOT's runtime aware of that load. Regular; ROOT also will do some header parsing to add the minimal infrastructure; in place for cling to be able to call into that library. C++ modules define away the need to parse. This patch intends to skip all; parsing at this stage and fix recursive parsing issues for C++ modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1356
https://github.com/root-project/root/pull/1358:128,Deployability,patch,patch,128,"Requires that TEnv:: Getvalue, Lookup are const as well.; Also mark Defined const. Local compilation of ROOT succeeds after the patch.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1358
https://github.com/root-project/root/pull/1360:106,Modifiability,variab,variables,106,macOS has introduced feature named System Integrity Protection which prevents DYLD_* and LD_* environment variables to be propageted to a ROOT process.; We must disable the feature to use multiple versions of ROOT with AliBuild. There are two solution for this:. - Fix gSystem->Load() to allow dynamic loading using another environment variable; Pros: It just works (possibly) without out of tree modifications. Easy to relocate.; Cons: It's dirty. Unexpected load paths may be used even if they they have low priority. - Change all macros ever made so that they call gSystem->Load() with the full path or call AddDynamicPath in advance; Pros: It's neat. One can control load path precisely.; Cons: Too many macros to fix. We should fix the macros after relocation of libraries. This commit implements the former solution.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1360
https://github.com/root-project/root/pull/1360:336,Modifiability,variab,variable,336,macOS has introduced feature named System Integrity Protection which prevents DYLD_* and LD_* environment variables to be propageted to a ROOT process.; We must disable the feature to use multiple versions of ROOT with AliBuild. There are two solution for this:. - Fix gSystem->Load() to allow dynamic loading using another environment variable; Pros: It just works (possibly) without out of tree modifications. Easy to relocate.; Cons: It's dirty. Unexpected load paths may be used even if they they have low priority. - Change all macros ever made so that they call gSystem->Load() with the full path or call AddDynamicPath in advance; Pros: It's neat. One can control load path precisely.; Cons: Too many macros to fix. We should fix the macros after relocation of libraries. This commit implements the former solution.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1360
https://github.com/root-project/root/pull/1360:278,Performance,Load,Load,278,macOS has introduced feature named System Integrity Protection which prevents DYLD_* and LD_* environment variables to be propageted to a ROOT process.; We must disable the feature to use multiple versions of ROOT with AliBuild. There are two solution for this:. - Fix gSystem->Load() to allow dynamic loading using another environment variable; Pros: It just works (possibly) without out of tree modifications. Easy to relocate.; Cons: It's dirty. Unexpected load paths may be used even if they they have low priority. - Change all macros ever made so that they call gSystem->Load() with the full path or call AddDynamicPath in advance; Pros: It's neat. One can control load path precisely.; Cons: Too many macros to fix. We should fix the macros after relocation of libraries. This commit implements the former solution.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1360
https://github.com/root-project/root/pull/1360:302,Performance,load,loading,302,macOS has introduced feature named System Integrity Protection which prevents DYLD_* and LD_* environment variables to be propageted to a ROOT process.; We must disable the feature to use multiple versions of ROOT with AliBuild. There are two solution for this:. - Fix gSystem->Load() to allow dynamic loading using another environment variable; Pros: It just works (possibly) without out of tree modifications. Easy to relocate.; Cons: It's dirty. Unexpected load paths may be used even if they they have low priority. - Change all macros ever made so that they call gSystem->Load() with the full path or call AddDynamicPath in advance; Pros: It's neat. One can control load path precisely.; Cons: Too many macros to fix. We should fix the macros after relocation of libraries. This commit implements the former solution.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1360
https://github.com/root-project/root/pull/1360:460,Performance,load,load,460,macOS has introduced feature named System Integrity Protection which prevents DYLD_* and LD_* environment variables to be propageted to a ROOT process.; We must disable the feature to use multiple versions of ROOT with AliBuild. There are two solution for this:. - Fix gSystem->Load() to allow dynamic loading using another environment variable; Pros: It just works (possibly) without out of tree modifications. Easy to relocate.; Cons: It's dirty. Unexpected load paths may be used even if they they have low priority. - Change all macros ever made so that they call gSystem->Load() with the full path or call AddDynamicPath in advance; Pros: It's neat. One can control load path precisely.; Cons: Too many macros to fix. We should fix the macros after relocation of libraries. This commit implements the former solution.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1360
https://github.com/root-project/root/pull/1360:577,Performance,Load,Load,577,macOS has introduced feature named System Integrity Protection which prevents DYLD_* and LD_* environment variables to be propageted to a ROOT process.; We must disable the feature to use multiple versions of ROOT with AliBuild. There are two solution for this:. - Fix gSystem->Load() to allow dynamic loading using another environment variable; Pros: It just works (possibly) without out of tree modifications. Easy to relocate.; Cons: It's dirty. Unexpected load paths may be used even if they they have low priority. - Change all macros ever made so that they call gSystem->Load() with the full path or call AddDynamicPath in advance; Pros: It's neat. One can control load path precisely.; Cons: Too many macros to fix. We should fix the macros after relocation of libraries. This commit implements the former solution.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1360
https://github.com/root-project/root/pull/1360:671,Performance,load,load,671,macOS has introduced feature named System Integrity Protection which prevents DYLD_* and LD_* environment variables to be propageted to a ROOT process.; We must disable the feature to use multiple versions of ROOT with AliBuild. There are two solution for this:. - Fix gSystem->Load() to allow dynamic loading using another environment variable; Pros: It just works (possibly) without out of tree modifications. Easy to relocate.; Cons: It's dirty. Unexpected load paths may be used even if they they have low priority. - Change all macros ever made so that they call gSystem->Load() with the full path or call AddDynamicPath in advance; Pros: It's neat. One can control load path precisely.; Cons: Too many macros to fix. We should fix the macros after relocation of libraries. This commit implements the former solution.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1360
https://github.com/root-project/root/pull/1360:42,Security,Integrity,Integrity,42,macOS has introduced feature named System Integrity Protection which prevents DYLD_* and LD_* environment variables to be propageted to a ROOT process.; We must disable the feature to use multiple versions of ROOT with AliBuild. There are two solution for this:. - Fix gSystem->Load() to allow dynamic loading using another environment variable; Pros: It just works (possibly) without out of tree modifications. Easy to relocate.; Cons: It's dirty. Unexpected load paths may be used even if they they have low priority. - Change all macros ever made so that they call gSystem->Load() with the full path or call AddDynamicPath in advance; Pros: It's neat. One can control load path precisely.; Cons: Too many macros to fix. We should fix the macros after relocation of libraries. This commit implements the former solution.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1360
https://github.com/root-project/root/pull/1364:83,Modifiability,rewrite,rewrite,83,"I add a tutorial to Principal components using as base the existing one in Cint, I rewrite in PyROOT.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1364
https://github.com/root-project/root/pull/1371:143,Availability,reliab,reliability,143,Also provide improved solution for THttpServer shutdown - handling of websocket close done async and does not block civetweb threads. Improves reliability of cleanup process.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1371
https://github.com/root-project/root/pull/1372:144,Integrability,wrap,wrapping,144,"Intel Compiler cannot compile this piece of code:. static constexpr unsigned attrIdxToArrayIdx(unsigned Index) {; // MSVC warns about '~0U + 1' wrapping around when this is called on; // FunctionIndex, so cast to int first.; return static_cast<int>(Index) + 1;; }. int main(int, char**) {. static_assert(attrIdxToArrayIdx(~0U) == 0U, ""FOO"");; return 0;; }. The problem can be worked around by including the uncessary cast in an #ifdef; for MSVC, which is the only compiler that needs it.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1372
https://github.com/root-project/root/pull/1373:16,Integrability,message,message,16,"Original commit message:; ""Constify. NFC.""",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1373
https://github.com/root-project/root/pull/1374:13,Integrability,depend,dependency,13,"Without this dependency, a change to one of `LinkDef{1,2,3}.h` will; not trigger the regeneration of the `G__Core.cxx` dictionary, since; only the main `LinkDef.h` header was explicily listed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1374
https://github.com/root-project/root/pull/1377:248,Performance,perform,performed,248,"We now reset `fMustRunEventLoop` when a new named filter is added.; This fixes ROOT-9117: TDF now correctly re-runs the event-loop if; users ask for a cutflow report for a named filter that has been; added after a first event-loop has already been performed. In the future we might want to improve the inner logic so that; only the new named filters (and possibly new actions) are executed,; but the old filters are not re-run if not needed. [PR 109](https://github.com/root-project/roottest/pull/109) in roottest adds a test for this scenario.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1377
https://github.com/root-project/root/pull/1377:308,Testability,log,logic,308,"We now reset `fMustRunEventLoop` when a new named filter is added.; This fixes ROOT-9117: TDF now correctly re-runs the event-loop if; users ask for a cutflow report for a named filter that has been; added after a first event-loop has already been performed. In the future we might want to improve the inner logic so that; only the new named filters (and possibly new actions) are executed,; but the old filters are not re-run if not needed. [PR 109](https://github.com/root-project/roottest/pull/109) in roottest adds a test for this scenario.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1377
https://github.com/root-project/root/pull/1377:521,Testability,test,test,521,"We now reset `fMustRunEventLoop` when a new named filter is added.; This fixes ROOT-9117: TDF now correctly re-runs the event-loop if; users ask for a cutflow report for a named filter that has been; added after a first event-loop has already been performed. In the future we might want to improve the inner logic so that; only the new named filters (and possibly new actions) are executed,; but the old filters are not re-run if not needed. [PR 109](https://github.com/root-project/roottest/pull/109) in roottest adds a test for this scenario.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1377
https://github.com/root-project/root/pull/1381:61,Performance,load,loaded,61,This PR fixes the issue that we don't export macros from the loaded modules. See the specific commits for more.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1381
https://github.com/root-project/root/pull/1386:8,Deployability,continuous,continuous,8,"Through continuous changes in TFile/TDirectoryFile functionality,; sub-directory support in TXMLFile was lost. Now reintroduced again. Make similar changes for TSQLFile (only for historical reasons, seems to be nobody using it). Reformat source code with clang format",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1386
https://github.com/root-project/root/pull/1387:0,Testability,Assert,Assert,0,Assert isn't included from the STL/libc module as it's a textual; header which needs to be textually parsed. Let's add it to the; TCling `declare` call to cheaply get assert with modules into; the lookup.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1387
https://github.com/root-project/root/pull/1387:167,Testability,assert,assert,167,Assert isn't included from the STL/libc module as it's a textual; header which needs to be textually parsed. Let's add it to the; TCling `declare` call to cheaply get assert with modules into; the lookup.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1387
https://github.com/root-project/root/pull/1389:45,Testability,test,testing,45,"**Please do not merge this branch, it is for testing only!**",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1389
https://github.com/root-project/root/pull/1391:273,Modifiability,refactor,refactors,273,LoadCoreModules crashes when one of the core modules wasn't; found as we call `findModule` and then dereference that result; unconditionally. It also calls `findModule` and then passes; the found module name again to `findModule` in the `LoadModule`; function. This commit refactors this code and fixes those bugs.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1391
https://github.com/root-project/root/pull/1391:0,Performance,Load,LoadCoreModules,0,LoadCoreModules crashes when one of the core modules wasn't; found as we call `findModule` and then dereference that result; unconditionally. It also calls `findModule` and then passes; the found module name again to `findModule` in the `LoadModule`; function. This commit refactors this code and fixes those bugs.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1391
https://github.com/root-project/root/pull/1391:238,Performance,Load,LoadModule,238,LoadCoreModules crashes when one of the core modules wasn't; found as we call `findModule` and then dereference that result; unconditionally. It also calls `findModule` and then passes; the found module name again to `findModule` in the `LoadModule`; function. This commit refactors this code and fixes those bugs.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1391
https://github.com/root-project/root/pull/1393:60,Deployability,patch,patches,60,"Just testing for now, please do not merge as there are LLVM patches in the mix.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1393
https://github.com/root-project/root/pull/1393:5,Testability,test,testing,5,"Just testing for now, please do not merge as there are LLVM patches in the mix.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1393
https://github.com/root-project/root/pull/1394:0,Modifiability,Refactor,Refactored,0,Refactored LoadCoreModules that it now prints a warning if a module isn't found. Also fixes some nullptr-derefs from the old code where we accessed pointers before checking if they're null.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1394
https://github.com/root-project/root/pull/1394:11,Performance,Load,LoadCoreModules,11,Refactored LoadCoreModules that it now prints a warning if a module isn't found. Also fixes some nullptr-derefs from the old code where we accessed pointers before checking if they're null.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1394
https://github.com/root-project/root/pull/1394:139,Security,access,accessed,139,Refactored LoadCoreModules that it now prints a warning if a module isn't found. Also fixes some nullptr-derefs from the old code where we accessed pointers before checking if they're null.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1394
https://github.com/root-project/root/pull/1395:370,Availability,error,error,370,Rootcling's stage2 mode calls gDriverConfig->fTCling__GetInterpreter() to; get the TCling's instance of the cling interpreter. This in turn might; need to initialize TCling. Our modules setup preloads a modulemap but not the overlays preventing; system modules such as libc and stl to be loaded. This criples rootcling; and whenever it #includes a header file we get an error that we included; a module from ROOT which depends on modules stl but it is not accessible; through the module map.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1395
https://github.com/root-project/root/pull/1395:419,Integrability,depend,depends,419,Rootcling's stage2 mode calls gDriverConfig->fTCling__GetInterpreter() to; get the TCling's instance of the cling interpreter. This in turn might; need to initialize TCling. Our modules setup preloads a modulemap but not the overlays preventing; system modules such as libc and stl to be loaded. This criples rootcling; and whenever it #includes a header file we get an error that we included; a module from ROOT which depends on modules stl but it is not accessible; through the module map.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1395
https://github.com/root-project/root/pull/1395:288,Performance,load,loaded,288,Rootcling's stage2 mode calls gDriverConfig->fTCling__GetInterpreter() to; get the TCling's instance of the cling interpreter. This in turn might; need to initialize TCling. Our modules setup preloads a modulemap but not the overlays preventing; system modules such as libc and stl to be loaded. This criples rootcling; and whenever it #includes a header file we get an error that we included; a module from ROOT which depends on modules stl but it is not accessible; through the module map.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1395
https://github.com/root-project/root/pull/1395:456,Security,access,accessible,456,Rootcling's stage2 mode calls gDriverConfig->fTCling__GetInterpreter() to; get the TCling's instance of the cling interpreter. This in turn might; need to initialize TCling. Our modules setup preloads a modulemap but not the overlays preventing; system modules such as libc and stl to be loaded. This criples rootcling; and whenever it #includes a header file we get an error that we included; a module from ROOT which depends on modules stl but it is not accessible; through the module map.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1395
https://github.com/root-project/root/pull/1396:738,Availability,avail,available,738,"ROOT can't autoparse classes inside namespaces with the rootmap; system (as the loading callbacks don't correctly land where; they are supposed to land with our injected namespaces). As this; turns out to be a feature of some kind, let's preload; TMVA/TreePlayer/Graf to fix all failing tests that are related; to this feature/bug with modules enabled. This commit can be dropped if we solve on of those problems:. 1. figure out how to fix this bug in the rootmap-based loading; without regressin in performance. 2. replace the rootmap system with something else like attaching; all C++ modules on startup. Note that we already do something like this in normal ROOT by; including these packages into the PCH which also makes those; decls available in the normal clang lookup. This PR depends on #1394",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1396
https://github.com/root-project/root/pull/1396:161,Integrability,inject,injected,161,"ROOT can't autoparse classes inside namespaces with the rootmap; system (as the loading callbacks don't correctly land where; they are supposed to land with our injected namespaces). As this; turns out to be a feature of some kind, let's preload; TMVA/TreePlayer/Graf to fix all failing tests that are related; to this feature/bug with modules enabled. This commit can be dropped if we solve on of those problems:. 1. figure out how to fix this bug in the rootmap-based loading; without regressin in performance. 2. replace the rootmap system with something else like attaching; all C++ modules on startup. Note that we already do something like this in normal ROOT by; including these packages into the PCH which also makes those; decls available in the normal clang lookup. This PR depends on #1394",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1396
https://github.com/root-project/root/pull/1396:784,Integrability,depend,depends,784,"ROOT can't autoparse classes inside namespaces with the rootmap; system (as the loading callbacks don't correctly land where; they are supposed to land with our injected namespaces). As this; turns out to be a feature of some kind, let's preload; TMVA/TreePlayer/Graf to fix all failing tests that are related; to this feature/bug with modules enabled. This commit can be dropped if we solve on of those problems:. 1. figure out how to fix this bug in the rootmap-based loading; without regressin in performance. 2. replace the rootmap system with something else like attaching; all C++ modules on startup. Note that we already do something like this in normal ROOT by; including these packages into the PCH which also makes those; decls available in the normal clang lookup. This PR depends on #1394",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1396
https://github.com/root-project/root/pull/1396:80,Performance,load,loading,80,"ROOT can't autoparse classes inside namespaces with the rootmap; system (as the loading callbacks don't correctly land where; they are supposed to land with our injected namespaces). As this; turns out to be a feature of some kind, let's preload; TMVA/TreePlayer/Graf to fix all failing tests that are related; to this feature/bug with modules enabled. This commit can be dropped if we solve on of those problems:. 1. figure out how to fix this bug in the rootmap-based loading; without regressin in performance. 2. replace the rootmap system with something else like attaching; all C++ modules on startup. Note that we already do something like this in normal ROOT by; including these packages into the PCH which also makes those; decls available in the normal clang lookup. This PR depends on #1394",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1396
https://github.com/root-project/root/pull/1396:470,Performance,load,loading,470,"ROOT can't autoparse classes inside namespaces with the rootmap; system (as the loading callbacks don't correctly land where; they are supposed to land with our injected namespaces). As this; turns out to be a feature of some kind, let's preload; TMVA/TreePlayer/Graf to fix all failing tests that are related; to this feature/bug with modules enabled. This commit can be dropped if we solve on of those problems:. 1. figure out how to fix this bug in the rootmap-based loading; without regressin in performance. 2. replace the rootmap system with something else like attaching; all C++ modules on startup. Note that we already do something like this in normal ROOT by; including these packages into the PCH which also makes those; decls available in the normal clang lookup. This PR depends on #1394",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1396
https://github.com/root-project/root/pull/1396:500,Performance,perform,performance,500,"ROOT can't autoparse classes inside namespaces with the rootmap; system (as the loading callbacks don't correctly land where; they are supposed to land with our injected namespaces). As this; turns out to be a feature of some kind, let's preload; TMVA/TreePlayer/Graf to fix all failing tests that are related; to this feature/bug with modules enabled. This commit can be dropped if we solve on of those problems:. 1. figure out how to fix this bug in the rootmap-based loading; without regressin in performance. 2. replace the rootmap system with something else like attaching; all C++ modules on startup. Note that we already do something like this in normal ROOT by; including these packages into the PCH which also makes those; decls available in the normal clang lookup. This PR depends on #1394",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1396
https://github.com/root-project/root/pull/1396:161,Security,inject,injected,161,"ROOT can't autoparse classes inside namespaces with the rootmap; system (as the loading callbacks don't correctly land where; they are supposed to land with our injected namespaces). As this; turns out to be a feature of some kind, let's preload; TMVA/TreePlayer/Graf to fix all failing tests that are related; to this feature/bug with modules enabled. This commit can be dropped if we solve on of those problems:. 1. figure out how to fix this bug in the rootmap-based loading; without regressin in performance. 2. replace the rootmap system with something else like attaching; all C++ modules on startup. Note that we already do something like this in normal ROOT by; including these packages into the PCH which also makes those; decls available in the normal clang lookup. This PR depends on #1394",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1396
https://github.com/root-project/root/pull/1396:287,Testability,test,tests,287,"ROOT can't autoparse classes inside namespaces with the rootmap; system (as the loading callbacks don't correctly land where; they are supposed to land with our injected namespaces). As this; turns out to be a feature of some kind, let's preload; TMVA/TreePlayer/Graf to fix all failing tests that are related; to this feature/bug with modules enabled. This commit can be dropped if we solve on of those problems:. 1. figure out how to fix this bug in the rootmap-based loading; without regressin in performance. 2. replace the rootmap system with something else like attaching; all C++ modules on startup. Note that we already do something like this in normal ROOT by; including these packages into the PCH which also makes those; decls available in the normal clang lookup. This PR depends on #1394",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1396
https://github.com/root-project/root/pull/1400:153,Modifiability,variab,variables,153,- Switch object format from ELF (Linux) to COFF (Windows); - Fix mangled symbols lookup on Windows: remove leading '_' and use malloc to simulate __imp_ variables (that are indirection pointers),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1400
https://github.com/root-project/root/pull/1401:123,Testability,test,testReport,123,"This resolved https://epsft-jenkins.cern.ch/job/root-incremental-master/BUILDTYPE=Debug,COMPILER=native,LABEL=mac1012/5509/testReport/projectroot.tree.treeplayer/test/gtest_tree_treeplayer_test_dataframe_snapshot/",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1401
https://github.com/root-project/root/pull/1401:162,Testability,test,test,162,"This resolved https://epsft-jenkins.cern.ch/job/root-incremental-master/BUILDTYPE=Debug,COMPILER=native,LABEL=mac1012/5509/testReport/projectroot.tree.treeplayer/test/gtest_tree_treeplayer_test_dataframe_snapshot/",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1401
https://github.com/root-project/root/pull/1408:0,Safety,Avoid,Avoid,0,Avoid modification of StreamerInfo during their streaming and thus remove the need for lock acquisition there.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1408
https://github.com/root-project/root/pull/1411:37,Availability,failure,failure,37,…ve use. This might fix intermittent failure in roottest_root_multicore_tp_process_imt; https://epsft-jenkins.cern.ch/job/root-pullrequests-build/11911/testReport/projectroot.roottest.root/multicore/roottest_root_multicore_tp_process_imt/; shows crash in:,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1411
https://github.com/root-project/root/pull/1411:152,Testability,test,testReport,152,…ve use. This might fix intermittent failure in roottest_root_multicore_tp_process_imt; https://epsft-jenkins.cern.ch/job/root-pullrequests-build/11911/testReport/projectroot.roottest.root/multicore/roottest_root_multicore_tp_process_imt/; shows crash in:,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1411
https://github.com/root-project/root/pull/1419:18,Integrability,message,messages,18,Please see commit messages for more information. This probably also fixes [ROOT-9139](https://sft.its.cern.ch/jira/browse/ROOT-9139).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1419
https://github.com/root-project/root/pull/1422:11,Availability,error,errors,11,I hope all errors could be resolved.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1422
https://github.com/root-project/root/pull/1426:90,Safety,safe,safe,90,"The `IOTests` test has run on my machine for 10000 times without crashing, so this may be safe to remove now.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1426
https://github.com/root-project/root/pull/1426:14,Testability,test,test,14,"The `IOTests` test has run on my machine for 10000 times without crashing, so this may be safe to remove now.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1426
https://github.com/root-project/root/pull/1430:58,Performance,load,loading,58,"We move to cling, this should now work without explicitly loading; it. This also unblocks the modularization project which doesn't; include MathCore in the minimal base image.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1430
https://github.com/root-project/root/pull/1434:68,Deployability,patch,patch,68,"… separate files containing different volumes. (Markus Frank). This patch provides the method TGDMLWrite::WriteGDMLfile allowing to write the gdml corresponding to a volume hierarchy (like a detector). A geometry can be therefore exported in pieces, and the gdml parser was modified to avoid duplication of materials and other components upon reading.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1434
https://github.com/root-project/root/pull/1434:191,Safety,detect,detector,191,"… separate files containing different volumes. (Markus Frank). This patch provides the method TGDMLWrite::WriteGDMLfile allowing to write the gdml corresponding to a volume hierarchy (like a detector). A geometry can be therefore exported in pieces, and the gdml parser was modified to avoid duplication of materials and other components upon reading.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1434
https://github.com/root-project/root/pull/1434:286,Safety,avoid,avoid,286,"… separate files containing different volumes. (Markus Frank). This patch provides the method TGDMLWrite::WriteGDMLfile allowing to write the gdml corresponding to a volume hierarchy (like a detector). A geometry can be therefore exported in pieces, and the gdml parser was modified to avoid duplication of materials and other components upon reading.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1434
https://github.com/root-project/root/pull/1435:40,Availability,error,error,40,"[core/winnt/src/TWinNTSystem.cxx:996]: (error) Invalid number of character '(' when these macros are defined: 'ROOTPREFIX'.; [html/src/TDocDirective.cxx:316]: (error) Invalid number of character '{' when these macros are defined: 'R__BEPAEPSTLICHERALSDERPAPST'.; [math/mathcore/src/Delaunay2D.cxx:30]: (error) Invalid number of character '{' when these macros are defined: 'HAS_CGAL'. [graf2d/qt/src/TGQt.cxx:2817]: (error) Array 'shape[15]' accessed at index 15, which is out of bounds.; [graf2d/qt/src/TGQt.cxx:2818]: (error) Array 'shape[15]' accessed at index 16, which is out of bounds.; [graf2d/qt/src/TGQt.cxx:2841]: (error) Array 'shape[15]' accessed at index 15, which is out of bounds.; [net/http/civetweb/handle_form.inl:627]: (style) Array index 'd' is used before limits check. [roofit/roostats/src/MetropolisHastings.cxx:153]: (style) Condition 'i<1000' is always true. [graf2d/qt/src/TQtClientGuard.cxx:289]: (warning) Assert statement modifies 'thisPix'. [roofit/roofitcore/src/BidirMMapPipe.cxx:906]: (style) Throwing a copy of the caught exception instead of rethrowing the original exception.; [roofit/roofitcore/src/BidirMMapPipe.cxx:972]: (style) Throwing a copy of the caught exception instead of rethrowing the original exception.; [roofit/roofitcore/src/BidirMMapPipe.cxx:1394]: (style) Throwing a copy of the caught exception instead of rethrowing the original exception.; [roofit/roofitcore/src/BidirMMapPipe.cxx:1429]: (style) Throwing a copy of the caught exception instead of rethrowing the original exception. [graf3d/eve/src/TEveElement.cxx:1745]: (style) Exception should be caught by reference.; [roofit/histfactory/src/hist2workspace.cxx:76]: (style) Exception should be caught by reference.; [roofit/histfactory/src/hist2workspace.cxx:97]: (style) Exception should be caught by reference.; [roofit/roofitcore/src/RooClassFactory.cxx:786]: (style) Exception should be caught by reference.; [roofit/roofitcore/src/RooFactoryWSTool.cxx:413]: (style) Exception should be",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1435
https://github.com/root-project/root/pull/1435:160,Availability,error,error,160,"[core/winnt/src/TWinNTSystem.cxx:996]: (error) Invalid number of character '(' when these macros are defined: 'ROOTPREFIX'.; [html/src/TDocDirective.cxx:316]: (error) Invalid number of character '{' when these macros are defined: 'R__BEPAEPSTLICHERALSDERPAPST'.; [math/mathcore/src/Delaunay2D.cxx:30]: (error) Invalid number of character '{' when these macros are defined: 'HAS_CGAL'. [graf2d/qt/src/TGQt.cxx:2817]: (error) Array 'shape[15]' accessed at index 15, which is out of bounds.; [graf2d/qt/src/TGQt.cxx:2818]: (error) Array 'shape[15]' accessed at index 16, which is out of bounds.; [graf2d/qt/src/TGQt.cxx:2841]: (error) Array 'shape[15]' accessed at index 15, which is out of bounds.; [net/http/civetweb/handle_form.inl:627]: (style) Array index 'd' is used before limits check. [roofit/roostats/src/MetropolisHastings.cxx:153]: (style) Condition 'i<1000' is always true. [graf2d/qt/src/TQtClientGuard.cxx:289]: (warning) Assert statement modifies 'thisPix'. [roofit/roofitcore/src/BidirMMapPipe.cxx:906]: (style) Throwing a copy of the caught exception instead of rethrowing the original exception.; [roofit/roofitcore/src/BidirMMapPipe.cxx:972]: (style) Throwing a copy of the caught exception instead of rethrowing the original exception.; [roofit/roofitcore/src/BidirMMapPipe.cxx:1394]: (style) Throwing a copy of the caught exception instead of rethrowing the original exception.; [roofit/roofitcore/src/BidirMMapPipe.cxx:1429]: (style) Throwing a copy of the caught exception instead of rethrowing the original exception. [graf3d/eve/src/TEveElement.cxx:1745]: (style) Exception should be caught by reference.; [roofit/histfactory/src/hist2workspace.cxx:76]: (style) Exception should be caught by reference.; [roofit/histfactory/src/hist2workspace.cxx:97]: (style) Exception should be caught by reference.; [roofit/roofitcore/src/RooClassFactory.cxx:786]: (style) Exception should be caught by reference.; [roofit/roofitcore/src/RooFactoryWSTool.cxx:413]: (style) Exception should be",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1435
https://github.com/root-project/root/pull/1435:303,Availability,error,error,303,"[core/winnt/src/TWinNTSystem.cxx:996]: (error) Invalid number of character '(' when these macros are defined: 'ROOTPREFIX'.; [html/src/TDocDirective.cxx:316]: (error) Invalid number of character '{' when these macros are defined: 'R__BEPAEPSTLICHERALSDERPAPST'.; [math/mathcore/src/Delaunay2D.cxx:30]: (error) Invalid number of character '{' when these macros are defined: 'HAS_CGAL'. [graf2d/qt/src/TGQt.cxx:2817]: (error) Array 'shape[15]' accessed at index 15, which is out of bounds.; [graf2d/qt/src/TGQt.cxx:2818]: (error) Array 'shape[15]' accessed at index 16, which is out of bounds.; [graf2d/qt/src/TGQt.cxx:2841]: (error) Array 'shape[15]' accessed at index 15, which is out of bounds.; [net/http/civetweb/handle_form.inl:627]: (style) Array index 'd' is used before limits check. [roofit/roostats/src/MetropolisHastings.cxx:153]: (style) Condition 'i<1000' is always true. [graf2d/qt/src/TQtClientGuard.cxx:289]: (warning) Assert statement modifies 'thisPix'. [roofit/roofitcore/src/BidirMMapPipe.cxx:906]: (style) Throwing a copy of the caught exception instead of rethrowing the original exception.; [roofit/roofitcore/src/BidirMMapPipe.cxx:972]: (style) Throwing a copy of the caught exception instead of rethrowing the original exception.; [roofit/roofitcore/src/BidirMMapPipe.cxx:1394]: (style) Throwing a copy of the caught exception instead of rethrowing the original exception.; [roofit/roofitcore/src/BidirMMapPipe.cxx:1429]: (style) Throwing a copy of the caught exception instead of rethrowing the original exception. [graf3d/eve/src/TEveElement.cxx:1745]: (style) Exception should be caught by reference.; [roofit/histfactory/src/hist2workspace.cxx:76]: (style) Exception should be caught by reference.; [roofit/histfactory/src/hist2workspace.cxx:97]: (style) Exception should be caught by reference.; [roofit/roofitcore/src/RooClassFactory.cxx:786]: (style) Exception should be caught by reference.; [roofit/roofitcore/src/RooFactoryWSTool.cxx:413]: (style) Exception should be",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1435
https://github.com/root-project/root/pull/1435:417,Availability,error,error,417,"[core/winnt/src/TWinNTSystem.cxx:996]: (error) Invalid number of character '(' when these macros are defined: 'ROOTPREFIX'.; [html/src/TDocDirective.cxx:316]: (error) Invalid number of character '{' when these macros are defined: 'R__BEPAEPSTLICHERALSDERPAPST'.; [math/mathcore/src/Delaunay2D.cxx:30]: (error) Invalid number of character '{' when these macros are defined: 'HAS_CGAL'. [graf2d/qt/src/TGQt.cxx:2817]: (error) Array 'shape[15]' accessed at index 15, which is out of bounds.; [graf2d/qt/src/TGQt.cxx:2818]: (error) Array 'shape[15]' accessed at index 16, which is out of bounds.; [graf2d/qt/src/TGQt.cxx:2841]: (error) Array 'shape[15]' accessed at index 15, which is out of bounds.; [net/http/civetweb/handle_form.inl:627]: (style) Array index 'd' is used before limits check. [roofit/roostats/src/MetropolisHastings.cxx:153]: (style) Condition 'i<1000' is always true. [graf2d/qt/src/TQtClientGuard.cxx:289]: (warning) Assert statement modifies 'thisPix'. [roofit/roofitcore/src/BidirMMapPipe.cxx:906]: (style) Throwing a copy of the caught exception instead of rethrowing the original exception.; [roofit/roofitcore/src/BidirMMapPipe.cxx:972]: (style) Throwing a copy of the caught exception instead of rethrowing the original exception.; [roofit/roofitcore/src/BidirMMapPipe.cxx:1394]: (style) Throwing a copy of the caught exception instead of rethrowing the original exception.; [roofit/roofitcore/src/BidirMMapPipe.cxx:1429]: (style) Throwing a copy of the caught exception instead of rethrowing the original exception. [graf3d/eve/src/TEveElement.cxx:1745]: (style) Exception should be caught by reference.; [roofit/histfactory/src/hist2workspace.cxx:76]: (style) Exception should be caught by reference.; [roofit/histfactory/src/hist2workspace.cxx:97]: (style) Exception should be caught by reference.; [roofit/roofitcore/src/RooClassFactory.cxx:786]: (style) Exception should be caught by reference.; [roofit/roofitcore/src/RooFactoryWSTool.cxx:413]: (style) Exception should be",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1435
https://github.com/root-project/root/pull/1435:521,Availability,error,error,521,"[core/winnt/src/TWinNTSystem.cxx:996]: (error) Invalid number of character '(' when these macros are defined: 'ROOTPREFIX'.; [html/src/TDocDirective.cxx:316]: (error) Invalid number of character '{' when these macros are defined: 'R__BEPAEPSTLICHERALSDERPAPST'.; [math/mathcore/src/Delaunay2D.cxx:30]: (error) Invalid number of character '{' when these macros are defined: 'HAS_CGAL'. [graf2d/qt/src/TGQt.cxx:2817]: (error) Array 'shape[15]' accessed at index 15, which is out of bounds.; [graf2d/qt/src/TGQt.cxx:2818]: (error) Array 'shape[15]' accessed at index 16, which is out of bounds.; [graf2d/qt/src/TGQt.cxx:2841]: (error) Array 'shape[15]' accessed at index 15, which is out of bounds.; [net/http/civetweb/handle_form.inl:627]: (style) Array index 'd' is used before limits check. [roofit/roostats/src/MetropolisHastings.cxx:153]: (style) Condition 'i<1000' is always true. [graf2d/qt/src/TQtClientGuard.cxx:289]: (warning) Assert statement modifies 'thisPix'. [roofit/roofitcore/src/BidirMMapPipe.cxx:906]: (style) Throwing a copy of the caught exception instead of rethrowing the original exception.; [roofit/roofitcore/src/BidirMMapPipe.cxx:972]: (style) Throwing a copy of the caught exception instead of rethrowing the original exception.; [roofit/roofitcore/src/BidirMMapPipe.cxx:1394]: (style) Throwing a copy of the caught exception instead of rethrowing the original exception.; [roofit/roofitcore/src/BidirMMapPipe.cxx:1429]: (style) Throwing a copy of the caught exception instead of rethrowing the original exception. [graf3d/eve/src/TEveElement.cxx:1745]: (style) Exception should be caught by reference.; [roofit/histfactory/src/hist2workspace.cxx:76]: (style) Exception should be caught by reference.; [roofit/histfactory/src/hist2workspace.cxx:97]: (style) Exception should be caught by reference.; [roofit/roofitcore/src/RooClassFactory.cxx:786]: (style) Exception should be caught by reference.; [roofit/roofitcore/src/RooFactoryWSTool.cxx:413]: (style) Exception should be",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1435
https://github.com/root-project/root/pull/1435:625,Availability,error,error,625,"[core/winnt/src/TWinNTSystem.cxx:996]: (error) Invalid number of character '(' when these macros are defined: 'ROOTPREFIX'.; [html/src/TDocDirective.cxx:316]: (error) Invalid number of character '{' when these macros are defined: 'R__BEPAEPSTLICHERALSDERPAPST'.; [math/mathcore/src/Delaunay2D.cxx:30]: (error) Invalid number of character '{' when these macros are defined: 'HAS_CGAL'. [graf2d/qt/src/TGQt.cxx:2817]: (error) Array 'shape[15]' accessed at index 15, which is out of bounds.; [graf2d/qt/src/TGQt.cxx:2818]: (error) Array 'shape[15]' accessed at index 16, which is out of bounds.; [graf2d/qt/src/TGQt.cxx:2841]: (error) Array 'shape[15]' accessed at index 15, which is out of bounds.; [net/http/civetweb/handle_form.inl:627]: (style) Array index 'd' is used before limits check. [roofit/roostats/src/MetropolisHastings.cxx:153]: (style) Condition 'i<1000' is always true. [graf2d/qt/src/TQtClientGuard.cxx:289]: (warning) Assert statement modifies 'thisPix'. [roofit/roofitcore/src/BidirMMapPipe.cxx:906]: (style) Throwing a copy of the caught exception instead of rethrowing the original exception.; [roofit/roofitcore/src/BidirMMapPipe.cxx:972]: (style) Throwing a copy of the caught exception instead of rethrowing the original exception.; [roofit/roofitcore/src/BidirMMapPipe.cxx:1394]: (style) Throwing a copy of the caught exception instead of rethrowing the original exception.; [roofit/roofitcore/src/BidirMMapPipe.cxx:1429]: (style) Throwing a copy of the caught exception instead of rethrowing the original exception. [graf3d/eve/src/TEveElement.cxx:1745]: (style) Exception should be caught by reference.; [roofit/histfactory/src/hist2workspace.cxx:76]: (style) Exception should be caught by reference.; [roofit/histfactory/src/hist2workspace.cxx:97]: (style) Exception should be caught by reference.; [roofit/roofitcore/src/RooClassFactory.cxx:786]: (style) Exception should be caught by reference.; [roofit/roofitcore/src/RooFactoryWSTool.cxx:413]: (style) Exception should be",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1435
https://github.com/root-project/root/pull/1435:3284,Modifiability,Variab,VariableGaussTransform,3284,"g the original exception. [graf3d/eve/src/TEveElement.cxx:1745]: (style) Exception should be caught by reference.; [roofit/histfactory/src/hist2workspace.cxx:76]: (style) Exception should be caught by reference.; [roofit/histfactory/src/hist2workspace.cxx:97]: (style) Exception should be caught by reference.; [roofit/roofitcore/src/RooClassFactory.cxx:786]: (style) Exception should be caught by reference.; [roofit/roofitcore/src/RooFactoryWSTool.cxx:413]: (style) Exception should be caught by reference.; [roofit/roofitcore/src/RooFactoryWSTool.cxx:484]: (style) Exception should be caught by reference.; [roofit/roofitcore/src/RooFactoryWSTool.cxx:526]: (style) Exception should be caught by reference.; [roofit/roofitcore/src/RooFactoryWSTool.cxx:568]: (style) Exception should be caught by reference.; [roofit/roofitcore/src/RooFactoryWSTool.cxx:588]: (style) Exception should be caught by reference.; [roofit/roofitcore/src/RooFactoryWSTool.cxx:629]: (style) Exception should be caught by reference.; [roofit/roofitcore/src/RooFactoryWSTool.cxx:642]: (style) Exception should be caught by reference.; [roofit/roofitcore/src/RooFactoryWSTool.cxx:681]: (style) Exception should be caught by reference.; [roofit/roofitcore/src/RooFactoryWSTool.cxx:859]: (style) Exception should be caught by reference.; [tmva/tmva/src/CostComplexityPruneTool.cxx:131]: (style) Exception should be caught by reference.; [tmva/tmva/src/CostComplexityPruneTool.cxx:142]: (style) Exception should be caught by reference.; [tmva/tmva/src/DataSet.cxx:173]: (style) Exception should be caught by reference.; [tmva/tmva/src/Reader.cxx:636]: (style) Exception should be caught by reference.; [tmva/tmva/src/Reader.cxx:702]: (style) Exception should be caught by reference.; [tmva/tmva/src/VariableGaussTransform.cxx:751]: (style) Exception should be caught by reference. [io/sql/src/TSQLStructure.cxx:1931] -> [io/sql/src/TSQLStructure.cxx:1933]: (warning) Identical condition 'len==0', second condition is always false",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1435
https://github.com/root-project/root/pull/1435:442,Security,access,accessed,442,"[core/winnt/src/TWinNTSystem.cxx:996]: (error) Invalid number of character '(' when these macros are defined: 'ROOTPREFIX'.; [html/src/TDocDirective.cxx:316]: (error) Invalid number of character '{' when these macros are defined: 'R__BEPAEPSTLICHERALSDERPAPST'.; [math/mathcore/src/Delaunay2D.cxx:30]: (error) Invalid number of character '{' when these macros are defined: 'HAS_CGAL'. [graf2d/qt/src/TGQt.cxx:2817]: (error) Array 'shape[15]' accessed at index 15, which is out of bounds.; [graf2d/qt/src/TGQt.cxx:2818]: (error) Array 'shape[15]' accessed at index 16, which is out of bounds.; [graf2d/qt/src/TGQt.cxx:2841]: (error) Array 'shape[15]' accessed at index 15, which is out of bounds.; [net/http/civetweb/handle_form.inl:627]: (style) Array index 'd' is used before limits check. [roofit/roostats/src/MetropolisHastings.cxx:153]: (style) Condition 'i<1000' is always true. [graf2d/qt/src/TQtClientGuard.cxx:289]: (warning) Assert statement modifies 'thisPix'. [roofit/roofitcore/src/BidirMMapPipe.cxx:906]: (style) Throwing a copy of the caught exception instead of rethrowing the original exception.; [roofit/roofitcore/src/BidirMMapPipe.cxx:972]: (style) Throwing a copy of the caught exception instead of rethrowing the original exception.; [roofit/roofitcore/src/BidirMMapPipe.cxx:1394]: (style) Throwing a copy of the caught exception instead of rethrowing the original exception.; [roofit/roofitcore/src/BidirMMapPipe.cxx:1429]: (style) Throwing a copy of the caught exception instead of rethrowing the original exception. [graf3d/eve/src/TEveElement.cxx:1745]: (style) Exception should be caught by reference.; [roofit/histfactory/src/hist2workspace.cxx:76]: (style) Exception should be caught by reference.; [roofit/histfactory/src/hist2workspace.cxx:97]: (style) Exception should be caught by reference.; [roofit/roofitcore/src/RooClassFactory.cxx:786]: (style) Exception should be caught by reference.; [roofit/roofitcore/src/RooFactoryWSTool.cxx:413]: (style) Exception should be",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1435
https://github.com/root-project/root/pull/1435:546,Security,access,accessed,546,"[core/winnt/src/TWinNTSystem.cxx:996]: (error) Invalid number of character '(' when these macros are defined: 'ROOTPREFIX'.; [html/src/TDocDirective.cxx:316]: (error) Invalid number of character '{' when these macros are defined: 'R__BEPAEPSTLICHERALSDERPAPST'.; [math/mathcore/src/Delaunay2D.cxx:30]: (error) Invalid number of character '{' when these macros are defined: 'HAS_CGAL'. [graf2d/qt/src/TGQt.cxx:2817]: (error) Array 'shape[15]' accessed at index 15, which is out of bounds.; [graf2d/qt/src/TGQt.cxx:2818]: (error) Array 'shape[15]' accessed at index 16, which is out of bounds.; [graf2d/qt/src/TGQt.cxx:2841]: (error) Array 'shape[15]' accessed at index 15, which is out of bounds.; [net/http/civetweb/handle_form.inl:627]: (style) Array index 'd' is used before limits check. [roofit/roostats/src/MetropolisHastings.cxx:153]: (style) Condition 'i<1000' is always true. [graf2d/qt/src/TQtClientGuard.cxx:289]: (warning) Assert statement modifies 'thisPix'. [roofit/roofitcore/src/BidirMMapPipe.cxx:906]: (style) Throwing a copy of the caught exception instead of rethrowing the original exception.; [roofit/roofitcore/src/BidirMMapPipe.cxx:972]: (style) Throwing a copy of the caught exception instead of rethrowing the original exception.; [roofit/roofitcore/src/BidirMMapPipe.cxx:1394]: (style) Throwing a copy of the caught exception instead of rethrowing the original exception.; [roofit/roofitcore/src/BidirMMapPipe.cxx:1429]: (style) Throwing a copy of the caught exception instead of rethrowing the original exception. [graf3d/eve/src/TEveElement.cxx:1745]: (style) Exception should be caught by reference.; [roofit/histfactory/src/hist2workspace.cxx:76]: (style) Exception should be caught by reference.; [roofit/histfactory/src/hist2workspace.cxx:97]: (style) Exception should be caught by reference.; [roofit/roofitcore/src/RooClassFactory.cxx:786]: (style) Exception should be caught by reference.; [roofit/roofitcore/src/RooFactoryWSTool.cxx:413]: (style) Exception should be",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1435
https://github.com/root-project/root/pull/1435:650,Security,access,accessed,650,"[core/winnt/src/TWinNTSystem.cxx:996]: (error) Invalid number of character '(' when these macros are defined: 'ROOTPREFIX'.; [html/src/TDocDirective.cxx:316]: (error) Invalid number of character '{' when these macros are defined: 'R__BEPAEPSTLICHERALSDERPAPST'.; [math/mathcore/src/Delaunay2D.cxx:30]: (error) Invalid number of character '{' when these macros are defined: 'HAS_CGAL'. [graf2d/qt/src/TGQt.cxx:2817]: (error) Array 'shape[15]' accessed at index 15, which is out of bounds.; [graf2d/qt/src/TGQt.cxx:2818]: (error) Array 'shape[15]' accessed at index 16, which is out of bounds.; [graf2d/qt/src/TGQt.cxx:2841]: (error) Array 'shape[15]' accessed at index 15, which is out of bounds.; [net/http/civetweb/handle_form.inl:627]: (style) Array index 'd' is used before limits check. [roofit/roostats/src/MetropolisHastings.cxx:153]: (style) Condition 'i<1000' is always true. [graf2d/qt/src/TQtClientGuard.cxx:289]: (warning) Assert statement modifies 'thisPix'. [roofit/roofitcore/src/BidirMMapPipe.cxx:906]: (style) Throwing a copy of the caught exception instead of rethrowing the original exception.; [roofit/roofitcore/src/BidirMMapPipe.cxx:972]: (style) Throwing a copy of the caught exception instead of rethrowing the original exception.; [roofit/roofitcore/src/BidirMMapPipe.cxx:1394]: (style) Throwing a copy of the caught exception instead of rethrowing the original exception.; [roofit/roofitcore/src/BidirMMapPipe.cxx:1429]: (style) Throwing a copy of the caught exception instead of rethrowing the original exception. [graf3d/eve/src/TEveElement.cxx:1745]: (style) Exception should be caught by reference.; [roofit/histfactory/src/hist2workspace.cxx:76]: (style) Exception should be caught by reference.; [roofit/histfactory/src/hist2workspace.cxx:97]: (style) Exception should be caught by reference.; [roofit/roofitcore/src/RooClassFactory.cxx:786]: (style) Exception should be caught by reference.; [roofit/roofitcore/src/RooFactoryWSTool.cxx:413]: (style) Exception should be",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1435
https://github.com/root-project/root/pull/1435:934,Testability,Assert,Assert,934,"[core/winnt/src/TWinNTSystem.cxx:996]: (error) Invalid number of character '(' when these macros are defined: 'ROOTPREFIX'.; [html/src/TDocDirective.cxx:316]: (error) Invalid number of character '{' when these macros are defined: 'R__BEPAEPSTLICHERALSDERPAPST'.; [math/mathcore/src/Delaunay2D.cxx:30]: (error) Invalid number of character '{' when these macros are defined: 'HAS_CGAL'. [graf2d/qt/src/TGQt.cxx:2817]: (error) Array 'shape[15]' accessed at index 15, which is out of bounds.; [graf2d/qt/src/TGQt.cxx:2818]: (error) Array 'shape[15]' accessed at index 16, which is out of bounds.; [graf2d/qt/src/TGQt.cxx:2841]: (error) Array 'shape[15]' accessed at index 15, which is out of bounds.; [net/http/civetweb/handle_form.inl:627]: (style) Array index 'd' is used before limits check. [roofit/roostats/src/MetropolisHastings.cxx:153]: (style) Condition 'i<1000' is always true. [graf2d/qt/src/TQtClientGuard.cxx:289]: (warning) Assert statement modifies 'thisPix'. [roofit/roofitcore/src/BidirMMapPipe.cxx:906]: (style) Throwing a copy of the caught exception instead of rethrowing the original exception.; [roofit/roofitcore/src/BidirMMapPipe.cxx:972]: (style) Throwing a copy of the caught exception instead of rethrowing the original exception.; [roofit/roofitcore/src/BidirMMapPipe.cxx:1394]: (style) Throwing a copy of the caught exception instead of rethrowing the original exception.; [roofit/roofitcore/src/BidirMMapPipe.cxx:1429]: (style) Throwing a copy of the caught exception instead of rethrowing the original exception. [graf3d/eve/src/TEveElement.cxx:1745]: (style) Exception should be caught by reference.; [roofit/histfactory/src/hist2workspace.cxx:76]: (style) Exception should be caught by reference.; [roofit/histfactory/src/hist2workspace.cxx:97]: (style) Exception should be caught by reference.; [roofit/roofitcore/src/RooClassFactory.cxx:786]: (style) Exception should be caught by reference.; [roofit/roofitcore/src/RooFactoryWSTool.cxx:413]: (style) Exception should be",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1435
https://github.com/root-project/root/pull/1441:4,Performance,race condition,race condition,4,The race condition could lead to the TContext indirectly spinning the lock indefinitively,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1441
https://github.com/root-project/root/pull/1442:573,Availability,down,down,573,"Added new features to GeoCad library. - New features are used to export partial geometries to STEP files.; - Added 3 new member functions TGeoToStep::CreatePartialGeometry taking; different arguments.; - The first takes a file_name and a max_level, and defaults to the; previous (default arguments) behavior. The max_level sets the node depth; that will be exported in the STEP file.; - The second version, in addition to the previous version, has a part_name argument.; This is the name of a volume that is associated with a level 1 node.; Only this node and its children down to max_level will be exported.; - Similarly, a third version takes a map of part_name/max_level key/value pairs.; This allows the multiple level 1 nodes to be selected and exported to; different max_levels. 	modified: geom/geocad/inc/TGeoToStep.h; 	modified: geom/geocad/inc/TOCCToStep.h; 	modified: geom/geocad/src/TGeoToStep.cxx; 	modified: geom/geocad/src/TOCCToStep.cxx",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1442
https://github.com/root-project/root/pull/1443:4,Performance,race condition,race condition,4,The race condition could lead to the TContext indirectly spinning the lock indefinitively,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1443
https://github.com/root-project/root/pull/1445:5,Deployability,patch,patch,5,"This patch provides the method TGDMLWrite::WriteGDMLfile allowing to write the gdml corresponding to a volume hierarchy (like a detector). A geometry can be therefore exported in pieces, and the gdml parser was modified to avoid duplication of materials and other components upon reading.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1445
https://github.com/root-project/root/pull/1445:128,Safety,detect,detector,128,"This patch provides the method TGDMLWrite::WriteGDMLfile allowing to write the gdml corresponding to a volume hierarchy (like a detector). A geometry can be therefore exported in pieces, and the gdml parser was modified to avoid duplication of materials and other components upon reading.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1445
https://github.com/root-project/root/pull/1445:223,Safety,avoid,avoid,223,"This patch provides the method TGDMLWrite::WriteGDMLfile allowing to write the gdml corresponding to a volume hierarchy (like a detector). A geometry can be therefore exported in pieces, and the gdml parser was modified to avoid duplication of materials and other components upon reading.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1445
https://github.com/root-project/root/pull/1454:28,Energy Efficiency,Reduce,Reduce,28,"This is a generalization of Reduce that takes two lambdas:; - the accumulator lambda has signature `U(U,T)` or `void(U&,T)` where; U is the type of the accumulator, and T is the type of the column; to be accumulated into U; - the merge lambda has signature `U(U,U)` and ""puts together"" the; accumulators of each thread",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1454
https://github.com/root-project/root/pull/1455:145,Testability,Test,Testing,145,"This reverts commit e5299b1f790f1450c1545659f4cc869de7ebef70.; We still have to copy headers to the binary directory, so this is; not necessary. Testing before merging.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1455
https://github.com/root-project/root/pull/1456:597,Integrability,depend,depend,597,"this is a backport of; https://gitlab.cern.ch/lhcb/Rec/commit/6103563cc0fc537d8920a2918117b27a48823772#5c0090c3eee645cadb8dd97f9faf43e9664403ce_191_190. There are actually two changes:; - add an override in MethodBase generated code; - remove trailing whitespaces in the code of a MLP w/ normalise variable transformation. discussion points:; - one could also remove trailing whitespaces in other files (`grep -- ' "" << std::endl;'`); - the whitespaces are a bit on the boarder of history noise vs. useful; - the override will make the generated code for all code generated methods (not only MLP) depend on c++11 (which to my knowledge is the case for MLP already, but not for the other methods).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1456
https://github.com/root-project/root/pull/1456:298,Modifiability,variab,variable,298,"this is a backport of; https://gitlab.cern.ch/lhcb/Rec/commit/6103563cc0fc537d8920a2918117b27a48823772#5c0090c3eee645cadb8dd97f9faf43e9664403ce_191_190. There are actually two changes:; - add an override in MethodBase generated code; - remove trailing whitespaces in the code of a MLP w/ normalise variable transformation. discussion points:; - one could also remove trailing whitespaces in other files (`grep -- ' "" << std::endl;'`); - the whitespaces are a bit on the boarder of history noise vs. useful; - the override will make the generated code for all code generated methods (not only MLP) depend on c++11 (which to my knowledge is the case for MLP already, but not for the other methods).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1456
https://github.com/root-project/root/pull/1458:10,Performance,perform,performs,10,"rootcling performs an integrity check on the headers that are passed; via the command line and the ones we have in the modulemap. As this; check currently fails because we had to split up the Core and Thread,; we signal with a `use` directive that these other modules belong to; the current module. The `use` directive is usually only for signalling that we intend; to use this other module from our module, but as we anyway don't; use `-fmodules-decluse` in ROOT we can just reuse this for telling; rootcling that it should also check the split out submodules when; doing the integrity check for the headers. To give a concrete example: `ThreadLocalStorage` had to split; out of `Thread` to fix a cycle between `Core` and `Thread`.; However, rootcling now doesn't see the ThreadLocalStorage headers; in the `Thread` module but we pass them to the rootcling invocation; for `Thread`. This adds a `use ThreadLocalStorage` to Thread and; lets rootcling also iterate all `use`'d other modules when doing; this check, so we again have the full set of modules here.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1458
https://github.com/root-project/root/pull/1458:22,Security,integrity,integrity,22,"rootcling performs an integrity check on the headers that are passed; via the command line and the ones we have in the modulemap. As this; check currently fails because we had to split up the Core and Thread,; we signal with a `use` directive that these other modules belong to; the current module. The `use` directive is usually only for signalling that we intend; to use this other module from our module, but as we anyway don't; use `-fmodules-decluse` in ROOT we can just reuse this for telling; rootcling that it should also check the split out submodules when; doing the integrity check for the headers. To give a concrete example: `ThreadLocalStorage` had to split; out of `Thread` to fix a cycle between `Core` and `Thread`.; However, rootcling now doesn't see the ThreadLocalStorage headers; in the `Thread` module but we pass them to the rootcling invocation; for `Thread`. This adds a `use ThreadLocalStorage` to Thread and; lets rootcling also iterate all `use`'d other modules when doing; this check, so we again have the full set of modules here.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1458
https://github.com/root-project/root/pull/1458:577,Security,integrity,integrity,577,"rootcling performs an integrity check on the headers that are passed; via the command line and the ones we have in the modulemap. As this; check currently fails because we had to split up the Core and Thread,; we signal with a `use` directive that these other modules belong to; the current module. The `use` directive is usually only for signalling that we intend; to use this other module from our module, but as we anyway don't; use `-fmodules-decluse` in ROOT we can just reuse this for telling; rootcling that it should also check the split out submodules when; doing the integrity check for the headers. To give a concrete example: `ThreadLocalStorage` had to split; out of `Thread` to fix a cycle between `Core` and `Thread`.; However, rootcling now doesn't see the ThreadLocalStorage headers; in the `Thread` module but we pass them to the rootcling invocation; for `Thread`. This adds a `use ThreadLocalStorage` to Thread and; lets rootcling also iterate all `use`'d other modules when doing; this check, so we again have the full set of modules here.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1458
https://github.com/root-project/root/pull/1459:236,Availability,error,errors,236,"This header is directly included by TObject.h and directly including; it from some other header doesn't seem to be supported. As C++ modules; with submodule visibility simulate directl including each module header,; we seem to get some errors according to the comments in this header. This patch removes it from the argument list of the; ROOT_GENERATE_DICTIONARY call which prevents it from getting directly; included in the `Core` C++ module. We can also remove it from the header; blacklist after this change. The normal dictionary won't be affected by this. This header is anyway; not supposed to contain TVersionCheck.h but only TObject.h which will; still provide it in the right way.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1459
https://github.com/root-project/root/pull/1459:290,Deployability,patch,patch,290,"This header is directly included by TObject.h and directly including; it from some other header doesn't seem to be supported. As C++ modules; with submodule visibility simulate directl including each module header,; we seem to get some errors according to the comments in this header. This patch removes it from the argument list of the; ROOT_GENERATE_DICTIONARY call which prevents it from getting directly; included in the `Core` C++ module. We can also remove it from the header; blacklist after this change. The normal dictionary won't be affected by this. This header is anyway; not supposed to contain TVersionCheck.h but only TObject.h which will; still provide it in the right way.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1459
https://github.com/root-project/root/pull/1461:38,Deployability,update,updated,38,"This code is outdated and needs to be updated. But we anyway don't use or; test this code in any way, so let's send it to the git history were dead; code belongs.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1461
https://github.com/root-project/root/pull/1461:75,Testability,test,test,75,"This code is outdated and needs to be updated. But we anyway don't use or; test this code in any way, so let's send it to the git history were dead; code belongs.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1461
https://github.com/root-project/root/pull/1462:378,Testability,test,test,378,"All kinds of classes, supported for writing, now also can be read from JSON.; Also compressed arrays are supported. Use https://github.com/nlohmann/json parser for extract data from JSON.; For the moment it made private, later one can put it in ROOT include directories.; Does not work with gcc 4.8.x - replaced by dummy class. With the reading capability now is much easier to test JSON I/O. ; New testcases will be submitted to roottest soon.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1462
https://github.com/root-project/root/pull/1462:399,Testability,test,testcases,399,"All kinds of classes, supported for writing, now also can be read from JSON.; Also compressed arrays are supported. Use https://github.com/nlohmann/json parser for extract data from JSON.; For the moment it made private, later one can put it in ROOT include directories.; Does not work with gcc 4.8.x - replaced by dummy class. With the reading capability now is much easier to test JSON I/O. ; New testcases will be submitted to roottest soon.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1462
https://github.com/root-project/root/pull/1463:198,Deployability,patch,patch,198,"Beside the general aversion against using an environment variable; for this setting, it also turns out that we can't easily set an; environment variable for a rootcling invocation in roottest. This patch adds the -cxxmodule flag to rootcling to allow activating; this feature without the old environment variable. For backwards; compability, we keep the ROOT_MODULES support around (for now).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1463
https://github.com/root-project/root/pull/1463:57,Modifiability,variab,variable,57,"Beside the general aversion against using an environment variable; for this setting, it also turns out that we can't easily set an; environment variable for a rootcling invocation in roottest. This patch adds the -cxxmodule flag to rootcling to allow activating; this feature without the old environment variable. For backwards; compability, we keep the ROOT_MODULES support around (for now).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1463
https://github.com/root-project/root/pull/1463:144,Modifiability,variab,variable,144,"Beside the general aversion against using an environment variable; for this setting, it also turns out that we can't easily set an; environment variable for a rootcling invocation in roottest. This patch adds the -cxxmodule flag to rootcling to allow activating; this feature without the old environment variable. For backwards; compability, we keep the ROOT_MODULES support around (for now).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1463
https://github.com/root-project/root/pull/1463:304,Modifiability,variab,variable,304,"Beside the general aversion against using an environment variable; for this setting, it also turns out that we can't easily set an; environment variable for a rootcling invocation in roottest. This patch adds the -cxxmodule flag to rootcling to allow activating; this feature without the old environment variable. For backwards; compability, we keep the ROOT_MODULES support around (for now).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1463
https://github.com/root-project/root/pull/1466:100,Availability,down,downstream,100,"Hi,. This has been bugging me for a while now. 😛. ROOT has been exporting a CMake configuration for downstream projects (using ROOT) for a while now. But the exported/imported library targets at the moment can't be used with code like:. ```cmake; find_package( ROOT 6.10 REQUIRED ); add_executable( MyExecutable test.cxx ); target_link_libraries( MyExecutable ROOT::Core ); ```. In this case the build would complain that it can't find the ROOT headers that `test.cxx` may want to use. Even though the expectation against imported targets **is** that they would carry all information with them to compile any client code correctly. While the latter sentiment can take us quite far, as one could even argue that imported libraries should carry whatever compiler definitions/options the client may need with themselves, unfortunately this is not super easy to do with CMake at the moment. (For instance I don't know of a good way in which the imported library could impose the same C++ standard on the client project that ROOT was built with. While allowing the client project to use an even newer standard if needed.). So for now I'll just be satisfied making sure that at least the include directory needed by the ROOT libraries would be automatically propagated to clients wanting to link against them. This update takes care of that. Cheers,; Attila",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1466
https://github.com/root-project/root/pull/1466:82,Deployability,configurat,configuration,82,"Hi,. This has been bugging me for a while now. 😛. ROOT has been exporting a CMake configuration for downstream projects (using ROOT) for a while now. But the exported/imported library targets at the moment can't be used with code like:. ```cmake; find_package( ROOT 6.10 REQUIRED ); add_executable( MyExecutable test.cxx ); target_link_libraries( MyExecutable ROOT::Core ); ```. In this case the build would complain that it can't find the ROOT headers that `test.cxx` may want to use. Even though the expectation against imported targets **is** that they would carry all information with them to compile any client code correctly. While the latter sentiment can take us quite far, as one could even argue that imported libraries should carry whatever compiler definitions/options the client may need with themselves, unfortunately this is not super easy to do with CMake at the moment. (For instance I don't know of a good way in which the imported library could impose the same C++ standard on the client project that ROOT was built with. While allowing the client project to use an even newer standard if needed.). So for now I'll just be satisfied making sure that at least the include directory needed by the ROOT libraries would be automatically propagated to clients wanting to link against them. This update takes care of that. Cheers,; Attila",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1466
https://github.com/root-project/root/pull/1466:1309,Deployability,update,update,1309,"Hi,. This has been bugging me for a while now. 😛. ROOT has been exporting a CMake configuration for downstream projects (using ROOT) for a while now. But the exported/imported library targets at the moment can't be used with code like:. ```cmake; find_package( ROOT 6.10 REQUIRED ); add_executable( MyExecutable test.cxx ); target_link_libraries( MyExecutable ROOT::Core ); ```. In this case the build would complain that it can't find the ROOT headers that `test.cxx` may want to use. Even though the expectation against imported targets **is** that they would carry all information with them to compile any client code correctly. While the latter sentiment can take us quite far, as one could even argue that imported libraries should carry whatever compiler definitions/options the client may need with themselves, unfortunately this is not super easy to do with CMake at the moment. (For instance I don't know of a good way in which the imported library could impose the same C++ standard on the client project that ROOT was built with. While allowing the client project to use an even newer standard if needed.). So for now I'll just be satisfied making sure that at least the include directory needed by the ROOT libraries would be automatically propagated to clients wanting to link against them. This update takes care of that. Cheers,; Attila",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1466
https://github.com/root-project/root/pull/1466:82,Modifiability,config,configuration,82,"Hi,. This has been bugging me for a while now. 😛. ROOT has been exporting a CMake configuration for downstream projects (using ROOT) for a while now. But the exported/imported library targets at the moment can't be used with code like:. ```cmake; find_package( ROOT 6.10 REQUIRED ); add_executable( MyExecutable test.cxx ); target_link_libraries( MyExecutable ROOT::Core ); ```. In this case the build would complain that it can't find the ROOT headers that `test.cxx` may want to use. Even though the expectation against imported targets **is** that they would carry all information with them to compile any client code correctly. While the latter sentiment can take us quite far, as one could even argue that imported libraries should carry whatever compiler definitions/options the client may need with themselves, unfortunately this is not super easy to do with CMake at the moment. (For instance I don't know of a good way in which the imported library could impose the same C++ standard on the client project that ROOT was built with. While allowing the client project to use an even newer standard if needed.). So for now I'll just be satisfied making sure that at least the include directory needed by the ROOT libraries would be automatically propagated to clients wanting to link against them. This update takes care of that. Cheers,; Attila",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1466
https://github.com/root-project/root/pull/1466:312,Testability,test,test,312,"Hi,. This has been bugging me for a while now. 😛. ROOT has been exporting a CMake configuration for downstream projects (using ROOT) for a while now. But the exported/imported library targets at the moment can't be used with code like:. ```cmake; find_package( ROOT 6.10 REQUIRED ); add_executable( MyExecutable test.cxx ); target_link_libraries( MyExecutable ROOT::Core ); ```. In this case the build would complain that it can't find the ROOT headers that `test.cxx` may want to use. Even though the expectation against imported targets **is** that they would carry all information with them to compile any client code correctly. While the latter sentiment can take us quite far, as one could even argue that imported libraries should carry whatever compiler definitions/options the client may need with themselves, unfortunately this is not super easy to do with CMake at the moment. (For instance I don't know of a good way in which the imported library could impose the same C++ standard on the client project that ROOT was built with. While allowing the client project to use an even newer standard if needed.). So for now I'll just be satisfied making sure that at least the include directory needed by the ROOT libraries would be automatically propagated to clients wanting to link against them. This update takes care of that. Cheers,; Attila",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1466
https://github.com/root-project/root/pull/1466:459,Testability,test,test,459,"Hi,. This has been bugging me for a while now. 😛. ROOT has been exporting a CMake configuration for downstream projects (using ROOT) for a while now. But the exported/imported library targets at the moment can't be used with code like:. ```cmake; find_package( ROOT 6.10 REQUIRED ); add_executable( MyExecutable test.cxx ); target_link_libraries( MyExecutable ROOT::Core ); ```. In this case the build would complain that it can't find the ROOT headers that `test.cxx` may want to use. Even though the expectation against imported targets **is** that they would carry all information with them to compile any client code correctly. While the latter sentiment can take us quite far, as one could even argue that imported libraries should carry whatever compiler definitions/options the client may need with themselves, unfortunately this is not super easy to do with CMake at the moment. (For instance I don't know of a good way in which the imported library could impose the same C++ standard on the client project that ROOT was built with. While allowing the client project to use an even newer standard if needed.). So for now I'll just be satisfied making sure that at least the include directory needed by the ROOT libraries would be automatically propagated to clients wanting to link against them. This update takes care of that. Cheers,; Attila",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1466
https://github.com/root-project/root/pull/1467:8,Security,secur,security,8,Address security threat reported by S. Luders.; Using the same technology used in TSystem::ExpandFileName. This is a backport of commit 88ccff152604e0f1012653a596d802ff7ede3145. This is a fix for [CVE-2017-1000203](https://nvd.nist.gov/vuln/detail/CVE-2017-1000203).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1467
https://github.com/root-project/root/pull/1467:17,Security,threat,threat,17,Address security threat reported by S. Luders.; Using the same technology used in TSystem::ExpandFileName. This is a backport of commit 88ccff152604e0f1012653a596d802ff7ede3145. This is a fix for [CVE-2017-1000203](https://nvd.nist.gov/vuln/detail/CVE-2017-1000203).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1467
https://github.com/root-project/root/pull/1473:1,Energy Efficiency,Reduce,Reduce,1,"`Reduce(F f, const T &redIdentity)`; and; `Reduce(F f, std::string_view column)`; can clash. The first `Reduce` overload has been removed. A separate PR to roottest fixes `test_reduce` by adapting to this change.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1473
https://github.com/root-project/root/pull/1473:43,Energy Efficiency,Reduce,Reduce,43,"`Reduce(F f, const T &redIdentity)`; and; `Reduce(F f, std::string_view column)`; can clash. The first `Reduce` overload has been removed. A separate PR to roottest fixes `test_reduce` by adapting to this change.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1473
https://github.com/root-project/root/pull/1473:104,Energy Efficiency,Reduce,Reduce,104,"`Reduce(F f, const T &redIdentity)`; and; `Reduce(F f, std::string_view column)`; can clash. The first `Reduce` overload has been removed. A separate PR to roottest fixes `test_reduce` by adapting to this change.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1473
https://github.com/root-project/root/pull/1473:188,Energy Efficiency,adapt,adapting,188,"`Reduce(F f, const T &redIdentity)`; and; `Reduce(F f, std::string_view column)`; can clash. The first `Reduce` overload has been removed. A separate PR to roottest fixes `test_reduce` by adapting to this change.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1473
https://github.com/root-project/root/pull/1473:188,Modifiability,adapt,adapting,188,"`Reduce(F f, const T &redIdentity)`; and; `Reduce(F f, std::string_view column)`; can clash. The first `Reduce` overload has been removed. A separate PR to roottest fixes `test_reduce` by adapting to this change.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1473
https://github.com/root-project/root/pull/1474:120,Testability,test,tests,120,Substitute #defines and repeated #includes of the same code snippets; with fixtures and googletest's value parametrized tests.; No functional change is intended.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1474
https://github.com/root-project/root/pull/1475:0,Usability,Clear,Clear,0,Clear data row every time add a row to principal,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1475
https://github.com/root-project/root/pull/1477:30,Performance,multi-thread,multi-thread,30,"""TDF: bad interaction between multi-thread execution and separate output TFile"". See [jira ticket](https://sft.its.cern.ch/jira/browse/ROOT-9116?filter=-1) for more details.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1477
https://github.com/root-project/root/pull/1480:12,Deployability,patch,patch,12,Before this patch `ColumnName2ColumnTypeName` would silently return an empty string for the TTree branch type if it did not belong to one of the known listed categories (this what e.g. the cause of [ROOT-9130](ROOT-9130)).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1480
https://github.com/root-project/root/pull/1481:7,Integrability,depend,dependency,7,"Remove dependency from TBufferFile.; Now simply duplicate some code from TBufferFile in TBufferXML.; This is last version, which is fully compatible with previous XML I/O. Next steps - introduce TBufferText class, which will be base for JSON and XML classes.; Several methods will be shared between these two classes.; And both XML and JSON will use text actions for objects streaming, ; which may lead into incompatible changes in XML format.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1481
https://github.com/root-project/root/pull/1481:41,Usability,simpl,simply,41,"Remove dependency from TBufferFile.; Now simply duplicate some code from TBufferFile in TBufferXML.; This is last version, which is fully compatible with previous XML I/O. Next steps - introduce TBufferText class, which will be base for JSON and XML classes.; Several methods will be shared between these two classes.; And both XML and JSON will use text actions for objects streaming, ; which may lead into incompatible changes in XML format.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1481
https://github.com/root-project/root/pull/1484:235,Availability,error,error-when-running-interactively,235,Tutorial scripts uses 'rand' and 'random' keywords as a name for variables which causes many online notebooks to fail. Fixes ROOT-9030. Details:; * https://root-forum.cern.ch/t/declaration-of-trandom-object-as-rand-causes-redefinition-error-when-running-interactively/26363; * https://root.cern/doc/v610/group__tutorial__hist.html; * https://sft.its.cern.ch/jira/browse/ROOT-9030,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1484
https://github.com/root-project/root/pull/1484:65,Modifiability,variab,variables,65,Tutorial scripts uses 'rand' and 'random' keywords as a name for variables which causes many online notebooks to fail. Fixes ROOT-9030. Details:; * https://root-forum.cern.ch/t/declaration-of-trandom-object-as-rand-causes-redefinition-error-when-running-interactively/26363; * https://root.cern/doc/v610/group__tutorial__hist.html; * https://sft.its.cern.ch/jira/browse/ROOT-9030,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1484
https://github.com/root-project/root/pull/1487:271,Deployability,update,updated,271,"* replace ROOTSYS by $ROOTSYS; * import new options for `root` and `root-config` from the current help messages; * extended the explanation of `root` for macro compilation (`+`, `+O`, ...), combinations of macro and data files, combinations of macros with expressions; * updated a few URLs; * updated root-config explanation for Makefiles (adapting to built-in rules). Please check, especially the third point is based my on my regular usage of root and not on the official documentation.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1487
https://github.com/root-project/root/pull/1487:293,Deployability,update,updated,293,"* replace ROOTSYS by $ROOTSYS; * import new options for `root` and `root-config` from the current help messages; * extended the explanation of `root` for macro compilation (`+`, `+O`, ...), combinations of macro and data files, combinations of macros with expressions; * updated a few URLs; * updated root-config explanation for Makefiles (adapting to built-in rules). Please check, especially the third point is based my on my regular usage of root and not on the official documentation.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1487
https://github.com/root-project/root/pull/1487:340,Energy Efficiency,adapt,adapting,340,"* replace ROOTSYS by $ROOTSYS; * import new options for `root` and `root-config` from the current help messages; * extended the explanation of `root` for macro compilation (`+`, `+O`, ...), combinations of macro and data files, combinations of macros with expressions; * updated a few URLs; * updated root-config explanation for Makefiles (adapting to built-in rules). Please check, especially the third point is based my on my regular usage of root and not on the official documentation.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1487
https://github.com/root-project/root/pull/1487:103,Integrability,message,messages,103,"* replace ROOTSYS by $ROOTSYS; * import new options for `root` and `root-config` from the current help messages; * extended the explanation of `root` for macro compilation (`+`, `+O`, ...), combinations of macro and data files, combinations of macros with expressions; * updated a few URLs; * updated root-config explanation for Makefiles (adapting to built-in rules). Please check, especially the third point is based my on my regular usage of root and not on the official documentation.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1487
https://github.com/root-project/root/pull/1487:73,Modifiability,config,config,73,"* replace ROOTSYS by $ROOTSYS; * import new options for `root` and `root-config` from the current help messages; * extended the explanation of `root` for macro compilation (`+`, `+O`, ...), combinations of macro and data files, combinations of macros with expressions; * updated a few URLs; * updated root-config explanation for Makefiles (adapting to built-in rules). Please check, especially the third point is based my on my regular usage of root and not on the official documentation.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1487
https://github.com/root-project/root/pull/1487:115,Modifiability,extend,extended,115,"* replace ROOTSYS by $ROOTSYS; * import new options for `root` and `root-config` from the current help messages; * extended the explanation of `root` for macro compilation (`+`, `+O`, ...), combinations of macro and data files, combinations of macros with expressions; * updated a few URLs; * updated root-config explanation for Makefiles (adapting to built-in rules). Please check, especially the third point is based my on my regular usage of root and not on the official documentation.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1487
https://github.com/root-project/root/pull/1487:306,Modifiability,config,config,306,"* replace ROOTSYS by $ROOTSYS; * import new options for `root` and `root-config` from the current help messages; * extended the explanation of `root` for macro compilation (`+`, `+O`, ...), combinations of macro and data files, combinations of macros with expressions; * updated a few URLs; * updated root-config explanation for Makefiles (adapting to built-in rules). Please check, especially the third point is based my on my regular usage of root and not on the official documentation.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1487
https://github.com/root-project/root/pull/1487:340,Modifiability,adapt,adapting,340,"* replace ROOTSYS by $ROOTSYS; * import new options for `root` and `root-config` from the current help messages; * extended the explanation of `root` for macro compilation (`+`, `+O`, ...), combinations of macro and data files, combinations of macros with expressions; * updated a few URLs; * updated root-config explanation for Makefiles (adapting to built-in rules). Please check, especially the third point is based my on my regular usage of root and not on the official documentation.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1487
https://github.com/root-project/root/pull/1488:234,Testability,test,tests,234,"This is base class for all text-based streamers like TBufferJSON, TBufferXML and TBufferSQL2. For all these classes dedicated list of I/O actions used for object streaming.; All data formats are preserved till now - all correspondent tests from roottest are working. Main motivation - decouple basic functionality from TBufferFile. . For the moment no changes done in TBufferFile, but as next step one can introduce intermediate TBufferImpl class, which will be base class for TBufferFile and TBufferText. There are many methods, which are similar and can be shared.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1488
https://github.com/root-project/root/pull/1491:4,Availability,Error,Error,4,Fix Error Descriptor in `TTreeReaderValue::Get()` Function,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1491
https://github.com/root-project/root/pull/1493:788,Deployability,release,release,788,"1. Fix several problems with longpoll socket handler; * correctly reject connection; * re-use client request to send data back from server; * if no other applied, send dummy reply to client; 2. On JavaScript side correctly handle re-connect to TWebWindow; * correctly produce URL for ws:// or http://server/root.longpoll handle; * show minimal info when connection takes too long time; 3. Add TWebWindow::GetUrl() method, which create all necessary http handlers,; but does not show window in the browser. User now can copy and paste produced URL ; in any other browser - or use such URL to embed TWebWindow in any other frameowrk; 4. Provide minimal docu about TWebWindow class; 5. Provide latest JSROOT code - required for correct work of TWebWindow and longpoll,; close to final 5.4.0 release",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1493
https://github.com/root-project/root/pull/1496:4,Availability,Error,Error,4,Fix Error/Info/Warning Descriptors on TGraph/TH1/TMultiGraph,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1496
https://github.com/root-project/root/pull/1497:13,Energy Efficiency,adapt,adapt,13,"in addition, adapt tests accordingly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1497
https://github.com/root-project/root/pull/1497:13,Modifiability,adapt,adapt,13,"in addition, adapt tests accordingly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1497
https://github.com/root-project/root/pull/1497:19,Testability,test,tests,19,"in addition, adapt tests accordingly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1497
