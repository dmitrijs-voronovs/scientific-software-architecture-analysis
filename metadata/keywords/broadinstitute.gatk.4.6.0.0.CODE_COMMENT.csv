quality_attribute,keyword,matched_word,sentence,source,filename,author,repo,version,wiki,url
Availability,down,downloaded,"#!/usr/local/bin/python; # coding: UTF-8; # modified code downloaded from:; # http://devwiki.beloblotskiy.com/index.php5/Generic_HTML_Table_parser_(python); # mods by: Aquil H. Abdullah; # import pdb; # Print debug info; """"""; Error raised when TableParser finds a nested table.; """"""; # Generic HTML table parser; """"""; Class to handle extracting a table from an HTML Page.; NOTE: Does not handle Tables within ; """"""; # Can't use super HTMLParser is an old-style class; # super(TableParser, self).__init__(); # Added to generic class; # Added to generic class; # Added to generic class; # Added to generic class; # Added to generic class; """"""; Return the list of tables scraped from html page; """"""; # it's possible to check ""start tag - end tag"" pair here (see, tag and self._curr_tag); #if markup_debug_low: print u'[%s,%s] %s: ""%s""' % (self._tr_cnt, self._td_cnt, self._curr_tag, unicode(data, 'mbcs')); # Overridable ; # outside the table; # Overridable ; # pass; # Overridable ; # pass; # Overridable ; # pass; # Overridable ; # pass; # Overridable ; # pass",MatchSource.CODE_COMMENT,scripts/funcotator/data_sources/TableParser.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/scripts/funcotator/data_sources/TableParser.py
Availability,down,downloading,"#!/usr/bin/env python; """"""; By downloading the PROGRAM you agree to the following terms of use:. BROAD INSTITUTE SOFTWARE LICENSE AGREEMENT; FOR ACADEMIC NON-COMMERCIAL RESEARCH PURPOSES ONLY. This Agreement is made between the Broad Institute, Inc. with a principal address at 7 Cambridge Center, Cambridge, MA 02142 (""BROAD"") and the LICENSEE and is effective at the date the downloading is completed (""EFFECTIVE DATE""). WHEREAS, LICENSEE desires to license the PROGRAM, as defined hereinafter, and BROAD wishes to have this PROGRAM utilized in the public interest, subject only to the royalty-free, nonexclusive, nontransferable license rights of the United States Government pursuant to 48 CFR 52.227-14; and. WHEREAS, LICENSEE desires to license the PROGRAM and BROAD desires to grant a license on the following terms and conditions. NOW, THEREFORE, in consideration of the promises and covenants made herein, the parties hereto agree as follows:. 1. DEFINITIONS; 1.1 ""PROGRAM"" shall mean the object code and source code known as Oncotator 1.0 and related documentation, if any, as they exist on the EFFECTIVE DATE and can be downloaded from http://www.broadinstitute.org/cancer/cga/oncotator on the EFFECTIVE DATE. BROAD acknowledges that the PROGRAM employs one or more public domain code(s) that are freely available for public use. 2. LICENSE; 2.1 Grant. Subject to the terms of this Agreement, BROAD hereby grants to LICENSEE, solely for academic non-commercial research purposes, a non-exclusive, non-transferable license to: (a) download, execute and display the PROGRAM and (b) create bug fixes and modify the PROGRAM. LICENSEE hereby automatically grants to BROAD a non-exclusive, royalty-free, irrevocable license to any LICENSEE bug fixes or modifications to the PROGRAM with unlimited rights to sublicense and/or distribute. LICENSEE agrees to provide any such modifications and bug fixes to BROAD promptly upon their creation. The LICENSEE may apply the PROGRAM in a pipeline to data",MatchSource.CODE_COMMENT,scripts/funcotator/data_sources/cosmic/createCosmicFusionGeneTsv.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/scripts/funcotator/data_sources/cosmic/createCosmicFusionGeneTsv.py
Deployability,pipeline,pipeline," related documentation, if any, as they exist on the EFFECTIVE DATE and can be downloaded from http://www.broadinstitute.org/cancer/cga/oncotator on the EFFECTIVE DATE. BROAD acknowledges that the PROGRAM employs one or more public domain code(s) that are freely available for public use. 2. LICENSE; 2.1 Grant. Subject to the terms of this Agreement, BROAD hereby grants to LICENSEE, solely for academic non-commercial research purposes, a non-exclusive, non-transferable license to: (a) download, execute and display the PROGRAM and (b) create bug fixes and modify the PROGRAM. LICENSEE hereby automatically grants to BROAD a non-exclusive, royalty-free, irrevocable license to any LICENSEE bug fixes or modifications to the PROGRAM with unlimited rights to sublicense and/or distribute. LICENSEE agrees to provide any such modifications and bug fixes to BROAD promptly upon their creation. The LICENSEE may apply the PROGRAM in a pipeline to data owned by users other than the LICENSEE and provide these users the results of the PROGRAM provided LICENSEE does so for academic non-commercial purposes only. For clarification purposes, academic sponsored research is not a commercial use under the terms of this Agreement.; 2.2 No Sublicensing or Additional Rights. LICENSEE shall not sublicense or distribute the PROGRAM, in whole or in part, without prior written permission from BROAD. LICENSEE shall ensure that all of its users agree to the terms of this Agreement. LICENSEE further agrees that it shall not put the PROGRAM on a network, server, or other similar technology that may be accessed by anyone other than the LICENSEE and its employees and users who have agreed to the terms of this agreement.; 2.3 License Limitations. Nothing in this Agreement shall be construed to confer any rights upon LICENSEE by implication, estoppel, or otherwise to any computer software, trademark, intellectual property, or patent rights of BROAD, or of any other entity, except as expressly granted herei",MatchSource.CODE_COMMENT,scripts/funcotator/data_sources/cosmic/createCosmicFusionGeneTsv.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/scripts/funcotator/data_sources/cosmic/createCosmicFusionGeneTsv.py
Energy Efficiency,adapt,adapted,"nse or distribute the PROGRAM, in whole or in part, without prior written permission from BROAD. LICENSEE shall ensure that all of its users agree to the terms of this Agreement. LICENSEE further agrees that it shall not put the PROGRAM on a network, server, or other similar technology that may be accessed by anyone other than the LICENSEE and its employees and users who have agreed to the terms of this agreement.; 2.3 License Limitations. Nothing in this Agreement shall be construed to confer any rights upon LICENSEE by implication, estoppel, or otherwise to any computer software, trademark, intellectual property, or patent rights of BROAD, or of any other entity, except as expressly granted herein. LICENSEE agrees that the PROGRAM, in whole or part, shall not be used for any commercial purpose, including without limitation, as the basis of a commercial software or hardware product or to provide services. LICENSEE further agrees that the PROGRAM shall not be copied or otherwise adapted in order to circumvent the need for obtaining a license for use of the PROGRAM. 3. OWNERSHIP OF INTELLECTUAL PROPERTY; LICENSEE acknowledges that title to the PROGRAM shall remain with BROAD. The PROGRAM is marked with the following BROAD copyright notice and notice of attribution to contributors. LICENSEE shall retain such notice on all copies. LICENSEE agrees to include appropriate attribution if any results obtained from use of the PROGRAM are included in any publication. Copyright 2014 Broad Institute, Inc.; Notice of attribution: The Oncotator 1.0 program was made available through the generosity of the Broad Institute, Inc. LICENSEE shall not use any trademark or trade name of BROAD, or any variation, adaptation, or abbreviation, of such marks or trade names, or any names of officers, faculty, students, employees, or agents of BROAD except as states above for attribution purposes. 4. INDEMNIFICATION; LICENSEE shall indemnify, defend, and hold harmless BROAD, and their respectiv",MatchSource.CODE_COMMENT,scripts/funcotator/data_sources/cosmic/createCosmicFusionGeneTsv.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/scripts/funcotator/data_sources/cosmic/createCosmicFusionGeneTsv.py
Modifiability,adapt,adapted,"nse or distribute the PROGRAM, in whole or in part, without prior written permission from BROAD. LICENSEE shall ensure that all of its users agree to the terms of this Agreement. LICENSEE further agrees that it shall not put the PROGRAM on a network, server, or other similar technology that may be accessed by anyone other than the LICENSEE and its employees and users who have agreed to the terms of this agreement.; 2.3 License Limitations. Nothing in this Agreement shall be construed to confer any rights upon LICENSEE by implication, estoppel, or otherwise to any computer software, trademark, intellectual property, or patent rights of BROAD, or of any other entity, except as expressly granted herein. LICENSEE agrees that the PROGRAM, in whole or part, shall not be used for any commercial purpose, including without limitation, as the basis of a commercial software or hardware product or to provide services. LICENSEE further agrees that the PROGRAM shall not be copied or otherwise adapted in order to circumvent the need for obtaining a license for use of the PROGRAM. 3. OWNERSHIP OF INTELLECTUAL PROPERTY; LICENSEE acknowledges that title to the PROGRAM shall remain with BROAD. The PROGRAM is marked with the following BROAD copyright notice and notice of attribution to contributors. LICENSEE shall retain such notice on all copies. LICENSEE agrees to include appropriate attribution if any results obtained from use of the PROGRAM are included in any publication. Copyright 2014 Broad Institute, Inc.; Notice of attribution: The Oncotator 1.0 program was made available through the generosity of the Broad Institute, Inc. LICENSEE shall not use any trademark or trade name of BROAD, or any variation, adaptation, or abbreviation, of such marks or trade names, or any names of officers, faculty, students, employees, or agents of BROAD except as states above for attribution purposes. 4. INDEMNIFICATION; LICENSEE shall indemnify, defend, and hold harmless BROAD, and their respectiv",MatchSource.CODE_COMMENT,scripts/funcotator/data_sources/cosmic/createCosmicFusionGeneTsv.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/scripts/funcotator/data_sources/cosmic/createCosmicFusionGeneTsv.py
Performance,load,load,"llowing provisions shall survive the expiration or termination of this Agreement: Articles 1, 3, 4, 5 and Sections 2.2, 2.3, 7.3, and 7.4.; 7.4 Notice. Any notices under this Agreement shall be in writing, shall specifically refer to this Agreement, and shall be sent by hand, recognized national overnight courier, confirmed facsimile transmission, confirmed electronic mail, or registered or certified mail, postage prepaid, return receipt requested. All notices under this Agreement shall be deemed effective upon receipt.; 7.5 Amendment and Waiver; Entire Agreement. This Agreement may be amended, supplemented, or otherwise modified only by means of a written instrument signed by all parties. Any waiver of any rights or failure to act in a specific instance shall relate only to such instance and shall not be construed as an agreement to waive any rights or fail to act in any other instance, whether or not similar. This Agreement constitutes the entire agreement among the parties with respect to its subject matter and supersedes prior agreements or understandings between the parties relating to its subject matter.; 7.6 Binding Effect; Headings. This Agreement shall be binding upon and inure to the benefit of the parties and their respective permitted successors and assigns. All headings are for convenience only and shall not affect the meaning of any provision of this Agreement.; 7.7 Governing Law. This Agreement shall be construed, governed, interpreted and applied in accordance with the internal laws of the Commonwealth of Massachusetts, U.S.A., without regard to conflict of laws principles.; """"""; # Process arguments; ''' Create the COSMIC fusion gene Oncotator datasource.'''; ''' NOTE: This script will load large portions of the COSMIC input file into RAM. Updated for v76; '''; # Create a dictionary where key is the gene and value is another dict: {fusion_gene:count}; # blank; # geneListKeys = fusionGene.split('/'); # Look for the fusion; # Render the fusionGeneDict",MatchSource.CODE_COMMENT,scripts/funcotator/data_sources/cosmic/createCosmicFusionGeneTsv.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/scripts/funcotator/data_sources/cosmic/createCosmicFusionGeneTsv.py
Security,access,accessed,"ereby automatically grants to BROAD a non-exclusive, royalty-free, irrevocable license to any LICENSEE bug fixes or modifications to the PROGRAM with unlimited rights to sublicense and/or distribute. LICENSEE agrees to provide any such modifications and bug fixes to BROAD promptly upon their creation. The LICENSEE may apply the PROGRAM in a pipeline to data owned by users other than the LICENSEE and provide these users the results of the PROGRAM provided LICENSEE does so for academic non-commercial purposes only. For clarification purposes, academic sponsored research is not a commercial use under the terms of this Agreement.; 2.2 No Sublicensing or Additional Rights. LICENSEE shall not sublicense or distribute the PROGRAM, in whole or in part, without prior written permission from BROAD. LICENSEE shall ensure that all of its users agree to the terms of this Agreement. LICENSEE further agrees that it shall not put the PROGRAM on a network, server, or other similar technology that may be accessed by anyone other than the LICENSEE and its employees and users who have agreed to the terms of this agreement.; 2.3 License Limitations. Nothing in this Agreement shall be construed to confer any rights upon LICENSEE by implication, estoppel, or otherwise to any computer software, trademark, intellectual property, or patent rights of BROAD, or of any other entity, except as expressly granted herein. LICENSEE agrees that the PROGRAM, in whole or part, shall not be used for any commercial purpose, including without limitation, as the basis of a commercial software or hardware product or to provide services. LICENSEE further agrees that the PROGRAM shall not be copied or otherwise adapted in order to circumvent the need for obtaining a license for use of the PROGRAM. 3. OWNERSHIP OF INTELLECTUAL PROPERTY; LICENSEE acknowledges that title to the PROGRAM shall remain with BROAD. The PROGRAM is marked with the following BROAD copyright notice and notice of attribution to contributor",MatchSource.CODE_COMMENT,scripts/funcotator/data_sources/cosmic/createCosmicFusionGeneTsv.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/scripts/funcotator/data_sources/cosmic/createCosmicFusionGeneTsv.py
Integrability,wrap,wraps,"#!/usr/bin/env python; """"""; Created on Jul 5, 2012. @author: lichtens; """"""; """"""; Read a TSV file. ; ; This class wraps a DictReader, but handles comments, which are not handled gracefully in the python csv library. ; ; The next() method assumes user is interested in the content, not the comments. ; Get the comments using getComments or getCommentsAsList. The latter assumes each comment is a line of text. ; ; Notes:; IMPORTANT: At this time, this class does not support comments below the header line. ; This class will load all comment lines into RAM at one time. This could theoretically cause a bottleneck in some files.; ; TODO: Low priority: Possibly make this inherit from DictReader, since it is exactly the same plus some functionality; """"""; """"""; Constructor; """"""; # The comment lines must be loaded before the dict reader is initialized.; # Get rid of blank lines; # Go back one character to make sure that we have moved the file pointer to the; # beginning of the first non-comment line.; """""" Return each comment line as an entry in a list """"""",MatchSource.CODE_COMMENT,scripts/funcotator/data_sources/cosmic/GenericTsvReader.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/scripts/funcotator/data_sources/cosmic/GenericTsvReader.py
Modifiability,inherit,inherit,"#!/usr/bin/env python; """"""; Created on Jul 5, 2012. @author: lichtens; """"""; """"""; Read a TSV file. ; ; This class wraps a DictReader, but handles comments, which are not handled gracefully in the python csv library. ; ; The next() method assumes user is interested in the content, not the comments. ; Get the comments using getComments or getCommentsAsList. The latter assumes each comment is a line of text. ; ; Notes:; IMPORTANT: At this time, this class does not support comments below the header line. ; This class will load all comment lines into RAM at one time. This could theoretically cause a bottleneck in some files.; ; TODO: Low priority: Possibly make this inherit from DictReader, since it is exactly the same plus some functionality; """"""; """"""; Constructor; """"""; # The comment lines must be loaded before the dict reader is initialized.; # Get rid of blank lines; # Go back one character to make sure that we have moved the file pointer to the; # beginning of the first non-comment line.; """""" Return each comment line as an entry in a list """"""",MatchSource.CODE_COMMENT,scripts/funcotator/data_sources/cosmic/GenericTsvReader.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/scripts/funcotator/data_sources/cosmic/GenericTsvReader.py
Performance,load,load,"#!/usr/bin/env python; """"""; Created on Jul 5, 2012. @author: lichtens; """"""; """"""; Read a TSV file. ; ; This class wraps a DictReader, but handles comments, which are not handled gracefully in the python csv library. ; ; The next() method assumes user is interested in the content, not the comments. ; Get the comments using getComments or getCommentsAsList. The latter assumes each comment is a line of text. ; ; Notes:; IMPORTANT: At this time, this class does not support comments below the header line. ; This class will load all comment lines into RAM at one time. This could theoretically cause a bottleneck in some files.; ; TODO: Low priority: Possibly make this inherit from DictReader, since it is exactly the same plus some functionality; """"""; """"""; Constructor; """"""; # The comment lines must be loaded before the dict reader is initialized.; # Get rid of blank lines; # Go back one character to make sure that we have moved the file pointer to the; # beginning of the first non-comment line.; """""" Return each comment line as an entry in a list """"""",MatchSource.CODE_COMMENT,scripts/funcotator/data_sources/cosmic/GenericTsvReader.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/scripts/funcotator/data_sources/cosmic/GenericTsvReader.py
Performance,optimiz,optimization,"# Taken from http://stackoverflow.com/questions/845058/how-to-get-line-count-cheaply-in-python; """"""; returns integer of number of lines; :param filename: name of file.; :type filename: str; :return: number of lines in the file; """"""; # loop optimization",MatchSource.CODE_COMMENT,scripts/funcotator/data_sources/cosmic/shared_utils.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/scripts/funcotator/data_sources/cosmic/shared_utils.py
Performance,race condition,race conditions,"# Usage: python Reporter.py <log url>; #; # This script creates a comment on github using the API token provided through GITHUB_API_TOKEN; # It first checks if a comment already exists which was made with the given identity; # and which mentions the same github actions build ID as the current running one in the first line of the comment.; # If no comment is found it creates a new one with a header and the log url.; # If a matching comment is found this appends it's log information to the existing comment.; #; # There exist race conditions when running this in parallel which can result in shards being missed if this is called; # multiple times simultaneously.; # Update the comment or create a new one",MatchSource.CODE_COMMENT,scripts/github_actions/Reporter.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/scripts/github_actions/Reporter.py
Testability,log,log,"# Usage: python Reporter.py <log url>; #; # This script creates a comment on github using the API token provided through GITHUB_API_TOKEN; # It first checks if a comment already exists which was made with the given identity; # and which mentions the same github actions build ID as the current running one in the first line of the comment.; # If no comment is found it creates a new one with a header and the log url.; # If a matching comment is found this appends it's log information to the existing comment.; #; # There exist race conditions when running this in parallel which can result in shards being missed if this is called; # multiple times simultaneously.; # Update the comment or create a new one",MatchSource.CODE_COMMENT,scripts/github_actions/Reporter.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/scripts/github_actions/Reporter.py
Availability,error,error,"# DO NOT SEED; #random.seed(""3337""); # Process arguments; """"""WARNING: No error checking.; Assumes that the bam is coordinate sorted and paired-end.; java -jar picard.jar ReplaceSamHeader HEADER=tmp_header.sam I=<(cat <(head -n1 tmp_header.sam ) <(samtools view tumor_1_foo.bam)) O=yossi.bam CREATE_INDEX=true VALIDATION_STRINGENCY=SILENT. THIS SCRIPT CAN BE VERY SLOW ON LARGE BAMS. This script is mostly meant for generating test bams that validate (even in Picard). Example: python reheader_bam.py some.bam 20,21 some_20_21_only.bam""""""; # 1) BAM -> Filtered SAM w/ old header; # 2) SAM Filtered -> new header only SAM file; # samfile_out_filename is the output from previous step which is input now.; # Cosntruct the header-only sam file; # 3) SAM Filtered + new header only SAM file -> BAM; # Create a dictionary, so that we can lookup the SN and get the index.",MatchSource.CODE_COMMENT,scripts/unsupported/reheader_bam/reheader_bam.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/scripts/unsupported/reheader_bam/reheader_bam.py
Security,validat,validate,"# DO NOT SEED; #random.seed(""3337""); # Process arguments; """"""WARNING: No error checking.; Assumes that the bam is coordinate sorted and paired-end.; java -jar picard.jar ReplaceSamHeader HEADER=tmp_header.sam I=<(cat <(head -n1 tmp_header.sam ) <(samtools view tumor_1_foo.bam)) O=yossi.bam CREATE_INDEX=true VALIDATION_STRINGENCY=SILENT. THIS SCRIPT CAN BE VERY SLOW ON LARGE BAMS. This script is mostly meant for generating test bams that validate (even in Picard). Example: python reheader_bam.py some.bam 20,21 some_20_21_only.bam""""""; # 1) BAM -> Filtered SAM w/ old header; # 2) SAM Filtered -> new header only SAM file; # samfile_out_filename is the output from previous step which is input now.; # Cosntruct the header-only sam file; # 3) SAM Filtered + new header only SAM file -> BAM; # Create a dictionary, so that we can lookup the SN and get the index.",MatchSource.CODE_COMMENT,scripts/unsupported/reheader_bam/reheader_bam.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/scripts/unsupported/reheader_bam/reheader_bam.py
Testability,test,test,"# DO NOT SEED; #random.seed(""3337""); # Process arguments; """"""WARNING: No error checking.; Assumes that the bam is coordinate sorted and paired-end.; java -jar picard.jar ReplaceSamHeader HEADER=tmp_header.sam I=<(cat <(head -n1 tmp_header.sam ) <(samtools view tumor_1_foo.bam)) O=yossi.bam CREATE_INDEX=true VALIDATION_STRINGENCY=SILENT. THIS SCRIPT CAN BE VERY SLOW ON LARGE BAMS. This script is mostly meant for generating test bams that validate (even in Picard). Example: python reheader_bam.py some.bam 20,21 some_20_21_only.bam""""""; # 1) BAM -> Filtered SAM w/ old header; # 2) SAM Filtered -> new header only SAM file; # samfile_out_filename is the output from previous step which is input now.; # Cosntruct the header-only sam file; # 3) SAM Filtered + new header only SAM file -> BAM; # Create a dictionary, so that we can lookup the SN and get the index.",MatchSource.CODE_COMMENT,scripts/unsupported/reheader_bam/reheader_bam.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/scripts/unsupported/reheader_bam/reheader_bam.py
Deployability,install,install,"""""""; Functions and classes used to extend a GATK tool with Python. GATK uses two FIFOs to communicate wth Python. The ""ack"" FIFO is read by GATK; and written by Python code, and is used to signal that a Python command has; completed execution. The ""data"" FIFO is written by GATK and read by Python,; and is used to pass data to Python from Java. Most of the functions in this module are intended to be called by GATK via; the StreamingPythonScriptExecutor Java class, and are not called by Python; code directly. The one exception is the readDataFIFO function, which can be; used to read data that had been passed to Python by GATK Java code.; """"""; """"""; Open the GATK ack FIFO and install the exception handler hook. Called by GATK when the StreamingPythonScriptExecutor is initialized,; which is normally in onTraversalStart. Initializes the ack FIFO and; installs the exception hook. Since the exception hook uses the ack FIFO,; it can't be installed until after the FIFO is initialized.; """"""; """"""; GATK Handler for uncaught Python exceptions. The is installed by initializeGATK after the ack FIFO has been; initialized. When an unhandled exception is caught, the handler; sends a nack to GATK through the FIFO, which results in a; PythonScriptExecutorException being thrown in the tool.; """"""; """"""; Send a positive acknowledgment to GATK. This should generally only; be called by python code that is embedded in Java, since the executor; keeps track of whether an ack request is outstanding.; """"""; """"""; Send a negative acknowledgment to GATK. Generally only called by the; installed exception hook. This will result in a Java exception being; thrown that unless caught by Java code, will terminate the tool.; """"""; """"""; Send a negative acknowledgment to GATK, along with a message. Generally only; called by the installed exception hook. This will result in a Java exception being; thrown that unless caught by Java code, will terminate the tool.; """"""; """"""; Called by GATK when no more Python command",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gatktool/tool.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gatktool/tool.py
Integrability,message,message,"amingPythonScriptExecutor is initialized,; which is normally in onTraversalStart. Initializes the ack FIFO and; installs the exception hook. Since the exception hook uses the ack FIFO,; it can't be installed until after the FIFO is initialized.; """"""; """"""; GATK Handler for uncaught Python exceptions. The is installed by initializeGATK after the ack FIFO has been; initialized. When an unhandled exception is caught, the handler; sends a nack to GATK through the FIFO, which results in a; PythonScriptExecutorException being thrown in the tool.; """"""; """"""; Send a positive acknowledgment to GATK. This should generally only; be called by python code that is embedded in Java, since the executor; keeps track of whether an ack request is outstanding.; """"""; """"""; Send a negative acknowledgment to GATK. Generally only called by the; installed exception hook. This will result in a Java exception being; thrown that unless caught by Java code, will terminate the tool.; """"""; """"""; Send a negative acknowledgment to GATK, along with a message. Generally only; called by the installed exception hook. This will result in a Java exception being; thrown that unless caught by Java code, will terminate the tool.; """"""; """"""; Called by GATK when no more Python commands will be executed; """"""; """"""; Initialize the data FIFO for reading. Once this method has been called, the FIFO may be read using the; readDataFIFO function.; """"""; """"""""; Close the data FIFO. Afteer this method hass been called, the; data FIFO can no longer be read.; """"""; """"""; Read a line from the Data FIFO.; :return: string; """"""; """"""; Start Python CProfile profiling.; """"""; """"""; End Python CProfile profiling and write results to a file. The; startProfile function must have been previously called. The results; are ordered by cummulative time.; :param profileName: name of the file to which the profiling results should be written.; """"""; """"""; Manage the FIFO used to notify GATK (via an ack) that a command has; completed, or failed due to an ",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gatktool/tool.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gatktool/tool.py
Modifiability,extend,extend,"""""""; Functions and classes used to extend a GATK tool with Python. GATK uses two FIFOs to communicate wth Python. The ""ack"" FIFO is read by GATK; and written by Python code, and is used to signal that a Python command has; completed execution. The ""data"" FIFO is written by GATK and read by Python,; and is used to pass data to Python from Java. Most of the functions in this module are intended to be called by GATK via; the StreamingPythonScriptExecutor Java class, and are not called by Python; code directly. The one exception is the readDataFIFO function, which can be; used to read data that had been passed to Python by GATK Java code.; """"""; """"""; Open the GATK ack FIFO and install the exception handler hook. Called by GATK when the StreamingPythonScriptExecutor is initialized,; which is normally in onTraversalStart. Initializes the ack FIFO and; installs the exception hook. Since the exception hook uses the ack FIFO,; it can't be installed until after the FIFO is initialized.; """"""; """"""; GATK Handler for uncaught Python exceptions. The is installed by initializeGATK after the ack FIFO has been; initialized. When an unhandled exception is caught, the handler; sends a nack to GATK through the FIFO, which results in a; PythonScriptExecutorException being thrown in the tool.; """"""; """"""; Send a positive acknowledgment to GATK. This should generally only; be called by python code that is embedded in Java, since the executor; keeps track of whether an ack request is outstanding.; """"""; """"""; Send a negative acknowledgment to GATK. Generally only called by the; installed exception hook. This will result in a Java exception being; thrown that unless caught by Java code, will terminate the tool.; """"""; """"""; Send a negative acknowledgment to GATK, along with a message. Generally only; called by the installed exception hook. This will result in a Java exception being; thrown that unless caught by Java code, will terminate the tool.; """"""; """"""; Called by GATK when no more Python command",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gatktool/tool.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gatktool/tool.py
Integrability,message,messages,"""""""; Constants that must remain in sync with the companion StreamingProcessController Java; code in GATK. See StreamingToolConstants.java. """"""; """"""; Command acknowledgement messages used to signal positive acknowledgement ('ack',; negative acknowledgement ('nck'), and negative acknowledgement with an accompanying; message ('nkm').; """"""; """"""; The length of a message written with a negative ack (nkm) must be 4 bytes long when; serialized as a string, and cannot have a value > 9999.; """"""",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gatktool/toolconstants.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gatktool/toolconstants.py
Modifiability,extend,extending,"""""""gatktool package. Modules with functions and classes for extending GATK tools with Python. """"""",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gatktool/__init__.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gatktool/__init__.py
Modifiability,config,configs,"# model configs and workspaces; # post-processing; # pre-processing and io; # structs; # metadata; # inference tasks",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/__init__.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/__init__.py
Performance,perform,performing,"""""""Convergence stopping criterion based on the linear trend of the noisy ELBO observations.""""""; """"""Initializer. Args:; window: window size for performing linear regression; snr_stop_trigger_threshold: signal-to-noise (SNR) ratio threshold for triggering countdown to stop; stop_countdown_window: once the trigger is pulled, SNR must remain below the given threshold for at; least `stop_countdown_window` subsequent ELBO observations to raise StopIteration. the countdown; will be reset if at any point the snr goes about `snr_stop_trigger_threshold`.; """"""; # effective gain per iteration; # signal-to-noise ratio; # variance of elbo in the window; # absolute elbo change in the window; # average elbo in the window; """"""Add new iteration. Args:; approx: approximation (ignored); loss: current value of the loss function; i: current iteration number (ignored). Returns:; None; """"""; # reset countdown",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/inference/convergence_tracker.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/inference/convergence_tracker.py
Deployability,update,updated,"""""""Kullback-Leibler divergence operator with finite temperature.""""""; """"""Initializer. Args:; approx: an instance of PyMC approximation; temperature: a scalar shared pytensor tensor variable; """"""; """"""ADVI with deterministic annealing functionality. Note:; Temperature is not updated automatically by this class. This task is delegated to the ADVI step; function. This can be done by including a temperature update in `more_updates`; refer to; `pymc.opvi.ObjectiveFunction.step_function` for more information. """"""",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/inference/deterministic_annealing.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/inference/deterministic_annealing.py
Modifiability,variab,variable,"""""""Kullback-Leibler divergence operator with finite temperature.""""""; """"""Initializer. Args:; approx: an instance of PyMC approximation; temperature: a scalar shared pytensor tensor variable; """"""; """"""ADVI with deterministic annealing functionality. Note:; Temperature is not updated automatically by this class. This task is delegated to the ADVI step; function. This can be done by including a temperature update in `more_updates`; refer to; `pymc.opvi.ObjectiveFunction.step_function` for more information. """"""",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/inference/deterministic_annealing.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/inference/deterministic_annealing.py
Deployability,update,updates,"""""""The base class of stochastic optimizers equipped with the functionality of saving and loading the; optimizer state to and from disk (e.g. for stateful optimizers such as ADAM and ADAMAX), and the; possibility of utilizing the extra attributes of `GeneralizedContinuousModel` to perform structured; parameter updates, e.g. updating only sample-specific variables while keeping global variables intact; (see `FancyAdamax` for a concrete implementation).; """"""; """""". Args:; model: a generalized continuous PyMC model; approx: an instance of PyMC mean-field approximation. Returns:; A callable function that upon providing `loss_or_grads` and `params`, returns an; `OrderedDict` of shared pytensor tensor updates (for example, see `FancyAdamax.get_optimizer`).; """"""; """"""Adamax optimizer with saving/loading functionality and sample-specific-only update mode.""""""; """"""Initializer. Args:; learning_rate: learning rate; beta1: first moment forgetting factor; beta2: second moment forgetting factor; epsilon: a small float for avoiding division-by-zero; sample_specific_only: only update sample-specific variables (as specified in the generalized model); disable_bias_correction: disable moment estimation bias correction; """"""; # placeholder for first (m) and second (u) moments; # in mean-field type approximation, ``mu`` and ``rho`` each have their own tensors; # the list elements correspond to ``mu`` and ``rho`` moments, respectively; # placeholder for the state of moment estimation bias corrector; """"""Adamax stochastic optimizer with partial sample-specific-only update functionality. Args:; loss_or_grads: symbolic loss function or gradients; params: variational parameter bundle; model: an instance of generalized model; approx: an instance of variational approximation for the model; learning_rate: global learning rate; beta1: first moment estimation forgetting factor; beta2: second moment estimation forgetting factor; epsilon: a small float to avoid division-by-zero; sample_specific_only: only",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/inference/fancy_optimizers.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/inference/fancy_optimizers.py
Modifiability,variab,variables,"""""""The base class of stochastic optimizers equipped with the functionality of saving and loading the; optimizer state to and from disk (e.g. for stateful optimizers such as ADAM and ADAMAX), and the; possibility of utilizing the extra attributes of `GeneralizedContinuousModel` to perform structured; parameter updates, e.g. updating only sample-specific variables while keeping global variables intact; (see `FancyAdamax` for a concrete implementation).; """"""; """""". Args:; model: a generalized continuous PyMC model; approx: an instance of PyMC mean-field approximation. Returns:; A callable function that upon providing `loss_or_grads` and `params`, returns an; `OrderedDict` of shared pytensor tensor updates (for example, see `FancyAdamax.get_optimizer`).; """"""; """"""Adamax optimizer with saving/loading functionality and sample-specific-only update mode.""""""; """"""Initializer. Args:; learning_rate: learning rate; beta1: first moment forgetting factor; beta2: second moment forgetting factor; epsilon: a small float for avoiding division-by-zero; sample_specific_only: only update sample-specific variables (as specified in the generalized model); disable_bias_correction: disable moment estimation bias correction; """"""; # placeholder for first (m) and second (u) moments; # in mean-field type approximation, ``mu`` and ``rho`` each have their own tensors; # the list elements correspond to ``mu`` and ``rho`` moments, respectively; # placeholder for the state of moment estimation bias corrector; """"""Adamax stochastic optimizer with partial sample-specific-only update functionality. Args:; loss_or_grads: symbolic loss function or gradients; params: variational parameter bundle; model: an instance of generalized model; approx: an instance of variational approximation for the model; learning_rate: global learning rate; beta1: first moment estimation forgetting factor; beta2: second moment estimation forgetting factor; epsilon: a small float to avoid division-by-zero; sample_specific_only: only",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/inference/fancy_optimizers.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/inference/fancy_optimizers.py
Performance,optimiz,optimizers,"""""""The base class of stochastic optimizers equipped with the functionality of saving and loading the; optimizer state to and from disk (e.g. for stateful optimizers such as ADAM and ADAMAX), and the; possibility of utilizing the extra attributes of `GeneralizedContinuousModel` to perform structured; parameter updates, e.g. updating only sample-specific variables while keeping global variables intact; (see `FancyAdamax` for a concrete implementation).; """"""; """""". Args:; model: a generalized continuous PyMC model; approx: an instance of PyMC mean-field approximation. Returns:; A callable function that upon providing `loss_or_grads` and `params`, returns an; `OrderedDict` of shared pytensor tensor updates (for example, see `FancyAdamax.get_optimizer`).; """"""; """"""Adamax optimizer with saving/loading functionality and sample-specific-only update mode.""""""; """"""Initializer. Args:; learning_rate: learning rate; beta1: first moment forgetting factor; beta2: second moment forgetting factor; epsilon: a small float for avoiding division-by-zero; sample_specific_only: only update sample-specific variables (as specified in the generalized model); disable_bias_correction: disable moment estimation bias correction; """"""; # placeholder for first (m) and second (u) moments; # in mean-field type approximation, ``mu`` and ``rho`` each have their own tensors; # the list elements correspond to ``mu`` and ``rho`` moments, respectively; # placeholder for the state of moment estimation bias corrector; """"""Adamax stochastic optimizer with partial sample-specific-only update functionality. Args:; loss_or_grads: symbolic loss function or gradients; params: variational parameter bundle; model: an instance of generalized model; approx: an instance of variational approximation for the model; learning_rate: global learning rate; beta1: first moment estimation forgetting factor; beta2: second moment estimation forgetting factor; epsilon: a small float to avoid division-by-zero; sample_specific_only: only",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/inference/fancy_optimizers.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/inference/fancy_optimizers.py
Safety,avoid,avoiding,"xtra attributes of `GeneralizedContinuousModel` to perform structured; parameter updates, e.g. updating only sample-specific variables while keeping global variables intact; (see `FancyAdamax` for a concrete implementation).; """"""; """""". Args:; model: a generalized continuous PyMC model; approx: an instance of PyMC mean-field approximation. Returns:; A callable function that upon providing `loss_or_grads` and `params`, returns an; `OrderedDict` of shared pytensor tensor updates (for example, see `FancyAdamax.get_optimizer`).; """"""; """"""Adamax optimizer with saving/loading functionality and sample-specific-only update mode.""""""; """"""Initializer. Args:; learning_rate: learning rate; beta1: first moment forgetting factor; beta2: second moment forgetting factor; epsilon: a small float for avoiding division-by-zero; sample_specific_only: only update sample-specific variables (as specified in the generalized model); disable_bias_correction: disable moment estimation bias correction; """"""; # placeholder for first (m) and second (u) moments; # in mean-field type approximation, ``mu`` and ``rho`` each have their own tensors; # the list elements correspond to ``mu`` and ``rho`` moments, respectively; # placeholder for the state of moment estimation bias corrector; """"""Adamax stochastic optimizer with partial sample-specific-only update functionality. Args:; loss_or_grads: symbolic loss function or gradients; params: variational parameter bundle; model: an instance of generalized model; approx: an instance of variational approximation for the model; learning_rate: global learning rate; beta1: first moment estimation forgetting factor; beta2: second moment estimation forgetting factor; epsilon: a small float to avoid division-by-zero; sample_specific_only: only update parameters registered in the generalized model as sample-specific; disable_bias_correction: disable moment estimation bias correction; base_class: a reference to the base class to store a reference to the shared tensors (",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/inference/fancy_optimizers.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/inference/fancy_optimizers.py
Usability,learn,learning,"xtra attributes of `GeneralizedContinuousModel` to perform structured; parameter updates, e.g. updating only sample-specific variables while keeping global variables intact; (see `FancyAdamax` for a concrete implementation).; """"""; """""". Args:; model: a generalized continuous PyMC model; approx: an instance of PyMC mean-field approximation. Returns:; A callable function that upon providing `loss_or_grads` and `params`, returns an; `OrderedDict` of shared pytensor tensor updates (for example, see `FancyAdamax.get_optimizer`).; """"""; """"""Adamax optimizer with saving/loading functionality and sample-specific-only update mode.""""""; """"""Initializer. Args:; learning_rate: learning rate; beta1: first moment forgetting factor; beta2: second moment forgetting factor; epsilon: a small float for avoiding division-by-zero; sample_specific_only: only update sample-specific variables (as specified in the generalized model); disable_bias_correction: disable moment estimation bias correction; """"""; # placeholder for first (m) and second (u) moments; # in mean-field type approximation, ``mu`` and ``rho`` each have their own tensors; # the list elements correspond to ``mu`` and ``rho`` moments, respectively; # placeholder for the state of moment estimation bias corrector; """"""Adamax stochastic optimizer with partial sample-specific-only update functionality. Args:; loss_or_grads: symbolic loss function or gradients; params: variational parameter bundle; model: an instance of generalized model; approx: an instance of variational approximation for the model; learning_rate: global learning rate; beta1: first moment estimation forgetting factor; beta2: second moment estimation forgetting factor; epsilon: a small float to avoid division-by-zero; sample_specific_only: only update parameters registered in the generalized model as sample-specific; disable_bias_correction: disable moment estimation bias correction; base_class: a reference to the base class to store a reference to the shared tensors (",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/inference/fancy_optimizers.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/inference/fancy_optimizers.py
Modifiability,variab,variable,"""""""Configuration for `VariationalParameterTracker`.""""""; """"""Adds a new parameter to be tracked. Args:; var_name: name of the variable (must be a free variable name in the model); inv_trans: inverse transformation; inv_trans_var_name: name of the variable after inverse transformation. Returns:; None; """"""; """"""Keeps track of specified variational parameter.""""""",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/inference/param_tracker.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/inference/param_tracker.py
Performance,optimiz,optimizer,"""""""Writes the state of adamax optimizer to disk.""""""; """"""Import the state of adamax optimizer from disk.""""""",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/io/io_adamax.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/io/io_adamax.py
Availability,error,error,"; None; """"""; """"""Compose a SAM style comment string that encodes a key-value pair; Args:; key: key string; value: value string. Returns:; A SAM style comment representing the key-value pair. """"""; """"""Parse a SAM style comment. Args:; comment_line: a comment string. Returns:; Key-value pair represented by a SAM style comment; """"""; """"""Reads a vector or matrix ndarray from .tsv file. Args:; input_file: input .tsv file; comment: comment character; delimiter: delimiter character. Returns:; ndarray; """"""; """"""Extracts the variable-to-linear-array of a PyMC mean-field approximation. Args:; approx: an instance of PyMC mean-field approximation. Returns:; A list of VarMap; """"""; # Originally, with PyMC3 3.5, this simply returned a List[pymc3.blocking.VarMap]:; # return approx.bij.ordering.vmap; # However, changes were made to the API and the VarMap class was obviated by the use of Xarray, see:; # https://discourse.pymc.io/t/how-to-get-named-means-and-sds-from-advi-fit/11073; # Unfortunately, this new functionality appears to be somewhat brittle and yields an error in our use case.; # We instead bring the old VarMap class into this module and recreate the old functionality to; # preserve our preexisting interfaces.; """"""Extracts mean-field posterior parameters in the right shape and dtype from an instance; of PyMC mean-field approximation. Args:; approx: an instance of PyMC mean-field approximation. Returns:; A tuple (set of variable names,; map from variable names to their respective Gaussian means,; map from variable names to their respective Gaussian standard deviations); """"""; """"""Writes a dictionary to JSON file. Args:; output_file: output .json file; dict_to_write: dictionary to write to file; ignored_keys: a set of keys to ignore; """"""; # json.dump does not add newline to end of file; """"""Reads gcnvkernel version from a JSON file and issues a warning if it is created with a different; version of the module. Args:; gcnvkernel_version_json_file: input .json file containing gcnvkern",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/io/io_commons.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/io/io_commons.py
Deployability,update,updated,"ame_set: set of all variable names in the model; approx_mu_map: a map from variable names to their respective Gaussian means; approx_std_map: a map from variable names to their respective Gaussian standard deviations; model: the generalized model corresponding to the provided mean-field approximation; extra_comment_lines: (optional) additional comment lines to write to the header of each output file; """"""; """"""Writes global parameters contained in an instance of PyMC mean-field approximation to disk. Args:; output_path: output path (must be writable); approx: an instance of PyMC mean-field approximation; model: the generalized model corresponding to the provided mean-field approximation; """"""; # parse mean-field posterior parameters; """"""Reads global parameters of a given model from saved mean-field posteriors and injects them; into a provided mean-field instance. Args:; input_model_path: input model path; approx: an instance of PyMC mean-field approximation to be updated; model: the generalized model corresponding to the provided mean-field approximation and the saved; instance; """"""; # convert std to rho, see pymc.dist_math.sd2rho; """"""Reads sample-specific parameters of a given sample from saved mean-field posteriors and injects them; into a provided mean-field instance. Args:; input_sample_calls_path: path to saved sample-specific posteriors; sample_index: index of the sample in the current instance of model/approximation; sample_name: name of the sample in the current instance of model/approximation; (used to check whether `input_sample_calls_path` actually corresponds to the sample); approx: an instance of PyMC mean-field approximation corresponding to the provided model; model: the generalized model corresponding to the provided mean-field approximation. Returns:; None; """"""; """"""Updates the ndarray buffer of the shared parameter tensor according to a given sample-specific; parameter for a given sample index. Args:; _param: ndarray buffer of the shared parameter tenso",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/io/io_commons.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/io/io_commons.py
Integrability,interface,interfaces,"omment representing the key-value pair. """"""; """"""Parse a SAM style comment. Args:; comment_line: a comment string. Returns:; Key-value pair represented by a SAM style comment; """"""; """"""Reads a vector or matrix ndarray from .tsv file. Args:; input_file: input .tsv file; comment: comment character; delimiter: delimiter character. Returns:; ndarray; """"""; """"""Extracts the variable-to-linear-array of a PyMC mean-field approximation. Args:; approx: an instance of PyMC mean-field approximation. Returns:; A list of VarMap; """"""; # Originally, with PyMC3 3.5, this simply returned a List[pymc3.blocking.VarMap]:; # return approx.bij.ordering.vmap; # However, changes were made to the API and the VarMap class was obviated by the use of Xarray, see:; # https://discourse.pymc.io/t/how-to-get-named-means-and-sds-from-advi-fit/11073; # Unfortunately, this new functionality appears to be somewhat brittle and yields an error in our use case.; # We instead bring the old VarMap class into this module and recreate the old functionality to; # preserve our preexisting interfaces.; """"""Extracts mean-field posterior parameters in the right shape and dtype from an instance; of PyMC mean-field approximation. Args:; approx: an instance of PyMC mean-field approximation. Returns:; A tuple (set of variable names,; map from variable names to their respective Gaussian means,; map from variable names to their respective Gaussian standard deviations); """"""; """"""Writes a dictionary to JSON file. Args:; output_file: output .json file; dict_to_write: dictionary to write to file; ignored_keys: a set of keys to ignore; """"""; # json.dump does not add newline to end of file; """"""Reads gcnvkernel version from a JSON file and issues a warning if it is created with a different; version of the module. Args:; gcnvkernel_version_json_file: input .json file containing gcnvkernel version; """"""; """"""Reads gcnvkernel version from a path that contains `io_consts.default_gcnvkernel_version_json_filename`,; reads the gcnvkernel ver",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/io/io_commons.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/io/io_commons.py
Modifiability,variab,variable-to-linear-array,"array to .tsv file. Note:; Shape and dtype information are stored in the header. Args:; output_file: output .tsv file; array: array to write to .tsv; comment: comment character; delimiter: delimiter character; extra_comment_lines: (optional) list of extra comment lines to add to the header; column_name_str: header line (e.g. for representing the ndarray as a table with named columns); write_shape_info: if True, ndarray shape info will be written to the header. Returns:; None; """"""; """"""Compose a SAM style comment string that encodes a key-value pair; Args:; key: key string; value: value string. Returns:; A SAM style comment representing the key-value pair. """"""; """"""Parse a SAM style comment. Args:; comment_line: a comment string. Returns:; Key-value pair represented by a SAM style comment; """"""; """"""Reads a vector or matrix ndarray from .tsv file. Args:; input_file: input .tsv file; comment: comment character; delimiter: delimiter character. Returns:; ndarray; """"""; """"""Extracts the variable-to-linear-array of a PyMC mean-field approximation. Args:; approx: an instance of PyMC mean-field approximation. Returns:; A list of VarMap; """"""; # Originally, with PyMC3 3.5, this simply returned a List[pymc3.blocking.VarMap]:; # return approx.bij.ordering.vmap; # However, changes were made to the API and the VarMap class was obviated by the use of Xarray, see:; # https://discourse.pymc.io/t/how-to-get-named-means-and-sds-from-advi-fit/11073; # Unfortunately, this new functionality appears to be somewhat brittle and yields an error in our use case.; # We instead bring the old VarMap class into this module and recreate the old functionality to; # preserve our preexisting interfaces.; """"""Extracts mean-field posterior parameters in the right shape and dtype from an instance; of PyMC mean-field approximation. Args:; approx: an instance of PyMC mean-field approximation. Returns:; A tuple (set of variable names,; map from variable names to their respective Gaussian means,; map from variable ",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/io/io_commons.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/io/io_commons.py
Security,inject,injects,"ssues a warning if it is created with a different version of the module. Args:; input_path:; """"""; """"""Writes sample-specific parameters contained in an instance of PyMC mean-field approximation; to disk. Args:; sample_index: sample integer index; sample_posterior_path: output path (must be writable); approx_var_name_set: set of all variable names in the model; approx_mu_map: a map from variable names to their respective Gaussian means; approx_std_map: a map from variable names to their respective Gaussian standard deviations; model: the generalized model corresponding to the provided mean-field approximation; extra_comment_lines: (optional) additional comment lines to write to the header of each output file; """"""; """"""Writes global parameters contained in an instance of PyMC mean-field approximation to disk. Args:; output_path: output path (must be writable); approx: an instance of PyMC mean-field approximation; model: the generalized model corresponding to the provided mean-field approximation; """"""; # parse mean-field posterior parameters; """"""Reads global parameters of a given model from saved mean-field posteriors and injects them; into a provided mean-field instance. Args:; input_model_path: input model path; approx: an instance of PyMC mean-field approximation to be updated; model: the generalized model corresponding to the provided mean-field approximation and the saved; instance; """"""; # convert std to rho, see pymc.dist_math.sd2rho; """"""Reads sample-specific parameters of a given sample from saved mean-field posteriors and injects them; into a provided mean-field instance. Args:; input_sample_calls_path: path to saved sample-specific posteriors; sample_index: index of the sample in the current instance of model/approximation; sample_name: name of the sample in the current instance of model/approximation; (used to check whether `input_sample_calls_path` actually corresponds to the sample); approx: an instance of PyMC mean-field approximation corresponding to the pro",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/io/io_commons.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/io/io_commons.py
Usability,simpl,simply,"limiter character; extra_comment_lines: (optional) list of extra comment lines to add to the header; column_name_str: header line (e.g. for representing the ndarray as a table with named columns); write_shape_info: if True, ndarray shape info will be written to the header. Returns:; None; """"""; """"""Compose a SAM style comment string that encodes a key-value pair; Args:; key: key string; value: value string. Returns:; A SAM style comment representing the key-value pair. """"""; """"""Parse a SAM style comment. Args:; comment_line: a comment string. Returns:; Key-value pair represented by a SAM style comment; """"""; """"""Reads a vector or matrix ndarray from .tsv file. Args:; input_file: input .tsv file; comment: comment character; delimiter: delimiter character. Returns:; ndarray; """"""; """"""Extracts the variable-to-linear-array of a PyMC mean-field approximation. Args:; approx: an instance of PyMC mean-field approximation. Returns:; A list of VarMap; """"""; # Originally, with PyMC3 3.5, this simply returned a List[pymc3.blocking.VarMap]:; # return approx.bij.ordering.vmap; # However, changes were made to the API and the VarMap class was obviated by the use of Xarray, see:; # https://discourse.pymc.io/t/how-to-get-named-means-and-sds-from-advi-fit/11073; # Unfortunately, this new functionality appears to be somewhat brittle and yields an error in our use case.; # We instead bring the old VarMap class into this module and recreate the old functionality to; # preserve our preexisting interfaces.; """"""Extracts mean-field posterior parameters in the right shape and dtype from an instance; of PyMC mean-field approximation. Args:; approx: an instance of PyMC mean-field approximation. Returns:; A tuple (set of variable names,; map from variable names to their respective Gaussian means,; map from variable names to their respective Gaussian standard deviations); """"""; """"""Writes a dictionary to JSON file. Args:; output_file: output .json file; dict_to_write: dictionary to write to file; ignored_k",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/io/io_commons.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/io/io_commons.py
Deployability,configurat,configurations,"# interval list .tsv file column names; # prefix for saving posteriors for multiple samples; # log copy number posterior matrix column name prefix for each integer copy number state; # generic column prefix; # ploidy prior table header column names; # column names for ploidy and depth .tsv outputs; # column names for copy-number segments file; # column name for baseline copy-number file; # column name for denoised copy-number files; # regular expression for matching sample name from header comment line; # prefix for adding sample name as a header comment line; # SAM header comment tag; # regular expression for matching key value pair from SAM comment line; # SAM style comment characters; # key values for storing array type in shape information; # dtype dictionaries giving types of mandatory columns whose names are known ahead of time; # (some of these dictionaries are not currently used, but we define their formats for future reference); # default file names for loading and saving models, posteriors, and configurations; # default exit code that indicates that inference diverged; # note that it needs to be in sync with the corresponding constant in GermlineCNVCaller",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/io/io_consts.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/io/io_consts.py
Modifiability,config,configurations,"# interval list .tsv file column names; # prefix for saving posteriors for multiple samples; # log copy number posterior matrix column name prefix for each integer copy number state; # generic column prefix; # ploidy prior table header column names; # column names for ploidy and depth .tsv outputs; # column names for copy-number segments file; # column name for baseline copy-number file; # column name for denoised copy-number files; # regular expression for matching sample name from header comment line; # prefix for adding sample name as a header comment line; # SAM header comment tag; # regular expression for matching key value pair from SAM comment line; # SAM style comment characters; # key values for storing array type in shape information; # dtype dictionaries giving types of mandatory columns whose names are known ahead of time; # (some of these dictionaries are not currently used, but we define their formats for future reference); # default file names for loading and saving models, posteriors, and configurations; # default exit code that indicates that inference diverged; # note that it needs to be in sync with the corresponding constant in GermlineCNVCaller",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/io/io_consts.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/io/io_consts.py
Performance,load,loading,"# interval list .tsv file column names; # prefix for saving posteriors for multiple samples; # log copy number posterior matrix column name prefix for each integer copy number state; # generic column prefix; # ploidy prior table header column names; # column names for ploidy and depth .tsv outputs; # column names for copy-number segments file; # column name for baseline copy-number file; # column name for denoised copy-number files; # regular expression for matching sample name from header comment line; # prefix for adding sample name as a header comment line; # SAM header comment tag; # regular expression for matching key value pair from SAM comment line; # SAM style comment characters; # key values for storing array type in shape information; # dtype dictionaries giving types of mandatory columns whose names are known ahead of time; # (some of these dictionaries are not currently used, but we define their formats for future reference); # default file names for loading and saving models, posteriors, and configurations; # default exit code that indicates that inference diverged; # note that it needs to be in sync with the corresponding constant in GermlineCNVCaller",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/io/io_consts.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/io/io_consts.py
Testability,log,log,"# interval list .tsv file column names; # prefix for saving posteriors for multiple samples; # log copy number posterior matrix column name prefix for each integer copy number state; # generic column prefix; # ploidy prior table header column names; # column names for ploidy and depth .tsv outputs; # column names for copy-number segments file; # column name for baseline copy-number file; # column name for denoised copy-number files; # regular expression for matching sample name from header comment line; # prefix for adding sample name as a header comment line; # SAM header comment tag; # regular expression for matching key value pair from SAM comment line; # SAM style comment characters; # key values for storing array type in shape information; # dtype dictionaries giving types of mandatory columns whose names are known ahead of time; # (some of these dictionaries are not currently used, but we define their formats for future reference); # default file names for loading and saving models, posteriors, and configurations; # default exit code that indicates that inference diverged; # note that it needs to be in sync with the corresponding constant in GermlineCNVCaller",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/io/io_consts.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/io/io_consts.py
Deployability,update,update,"""""""Writes global denoising model parameters to disk.""""""; # write gcnvkernel version; # write denoising config; # write calling config; # write global variables in the workspace; # write global variables in the posterior; """"""Reads global denoising model parameters from disk.""""""; # check if the model is created with the same gcnvkernel version; # read global workspace variables; # read global posterior parameters; """"""Writes sample-specific model parameters and associated workspace variables to disk.""""""; # write gcnvkernel version; # write denoising config; # write calling config; # extract mean-field parameters; # compute approximate denoised copy ratios; # write sample-specific posteriors in the approximation; # write sample name; # write copy number log posterior; # write copy number log emission; # write baseline copy numbers; # write denoised copy ratio means; # write denoised copy ratio standard deviations; """"""Reads sample-specific model parameters and associated workspace variables from disk.""""""; """"""Reads a TSV-formatted dim-2 (intervals x copy-number) ndarray from a sample posterior path.""""""; # assert that the interval list is the same; # read sample-specific posteriors and update approximation; # read copy number posterior and emission and update workspace; # update auxiliary workspace variables",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/io/io_denoising_calling.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/io/io_denoising_calling.py
Modifiability,config,config,"""""""Writes global denoising model parameters to disk.""""""; # write gcnvkernel version; # write denoising config; # write calling config; # write global variables in the workspace; # write global variables in the posterior; """"""Reads global denoising model parameters from disk.""""""; # check if the model is created with the same gcnvkernel version; # read global workspace variables; # read global posterior parameters; """"""Writes sample-specific model parameters and associated workspace variables to disk.""""""; # write gcnvkernel version; # write denoising config; # write calling config; # extract mean-field parameters; # compute approximate denoised copy ratios; # write sample-specific posteriors in the approximation; # write sample name; # write copy number log posterior; # write copy number log emission; # write baseline copy numbers; # write denoised copy ratio means; # write denoised copy ratio standard deviations; """"""Reads sample-specific model parameters and associated workspace variables from disk.""""""; """"""Reads a TSV-formatted dim-2 (intervals x copy-number) ndarray from a sample posterior path.""""""; # assert that the interval list is the same; # read sample-specific posteriors and update approximation; # read copy number posterior and emission and update workspace; # update auxiliary workspace variables",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/io/io_denoising_calling.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/io/io_denoising_calling.py
Testability,log,log,"""""""Writes global denoising model parameters to disk.""""""; # write gcnvkernel version; # write denoising config; # write calling config; # write global variables in the workspace; # write global variables in the posterior; """"""Reads global denoising model parameters from disk.""""""; # check if the model is created with the same gcnvkernel version; # read global workspace variables; # read global posterior parameters; """"""Writes sample-specific model parameters and associated workspace variables to disk.""""""; # write gcnvkernel version; # write denoising config; # write calling config; # extract mean-field parameters; # compute approximate denoised copy ratios; # write sample-specific posteriors in the approximation; # write sample name; # write copy number log posterior; # write copy number log emission; # write baseline copy numbers; # write denoised copy ratio means; # write denoised copy ratio standard deviations; """"""Reads sample-specific model parameters and associated workspace variables from disk.""""""; """"""Reads a TSV-formatted dim-2 (intervals x copy-number) ndarray from a sample posterior path.""""""; # assert that the interval list is the same; # read sample-specific posteriors and update approximation; # read copy number posterior and emission and update workspace; # update auxiliary workspace variables",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/io/io_denoising_calling.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/io/io_denoising_calling.py
Integrability,message,messages,"ame, counts, (and optionally a list of intervals if `return_interval_list` == True); """"""; """"""Loads an interval list .tsv file.; Args:; interval_list_tsv_file: input interval list .tsv file; comment: comment character; delimiter: delimiter character. Returns:; interval list; """"""; """"""Extract SAM header from a file. Notes:; Only contiguous SAM header lines (starting with '@') are considered. The parsing of the input file; stops as soon as a line starting with any other character is reached. Returns:; a list of str; """"""; """"""Loads read counts for a given cohort corresponding to a provided list of intervals. Args:; read_count_file_list: list of read counts .tsv files; modeling_interval_list: requested list of intervals. Raises:; AssertionError: if some of the intervals in `modeling_interval_list` are absent in the; provided read counts .tsv file. Note:; it is assumed that all read counts have the SAME intervals.; this assumption is not asserted for speed. Returns:; list of sample names, 2-dim (sample x interval) ndarray of read counts; """"""; # load intervals from the first read counts table; # do not load intervals again for speed, assume it is the same as the first sample; # subset the counts in the order dictated by modeling_interval_list; """"""Converts a pandas dataframe of intervals to list(Interval). Annotations will be parsed; and added to the intervals as well. Args:; interval_list_pd: interval list as a pandas dataframe; input_tsv_file: path to the .tsv file associated to the dataframe; (only used to generate exception messages). Returns:; a list of intervals; """"""; """"""Write a list of interval list to .tsv file. Note:; If all intervals have an annotation, that annotation will be written to the .tsv files.; If only some intervals have an annotation, that annotation will be ignored and a warning; will be logged. Args:; output_file: output .tsv file; interval_list: list of intervals to write to .tsv file; sam_header_lines: (optional) SAM header lines. Returns:; None; """"""",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/io/io_intervals_and_counts.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/io/io_intervals_and_counts.py
Performance,load,load,"ame, counts, (and optionally a list of intervals if `return_interval_list` == True); """"""; """"""Loads an interval list .tsv file.; Args:; interval_list_tsv_file: input interval list .tsv file; comment: comment character; delimiter: delimiter character. Returns:; interval list; """"""; """"""Extract SAM header from a file. Notes:; Only contiguous SAM header lines (starting with '@') are considered. The parsing of the input file; stops as soon as a line starting with any other character is reached. Returns:; a list of str; """"""; """"""Loads read counts for a given cohort corresponding to a provided list of intervals. Args:; read_count_file_list: list of read counts .tsv files; modeling_interval_list: requested list of intervals. Raises:; AssertionError: if some of the intervals in `modeling_interval_list` are absent in the; provided read counts .tsv file. Note:; it is assumed that all read counts have the SAME intervals.; this assumption is not asserted for speed. Returns:; list of sample names, 2-dim (sample x interval) ndarray of read counts; """"""; # load intervals from the first read counts table; # do not load intervals again for speed, assume it is the same as the first sample; # subset the counts in the order dictated by modeling_interval_list; """"""Converts a pandas dataframe of intervals to list(Interval). Annotations will be parsed; and added to the intervals as well. Args:; interval_list_pd: interval list as a pandas dataframe; input_tsv_file: path to the .tsv file associated to the dataframe; (only used to generate exception messages). Returns:; a list of intervals; """"""; """"""Write a list of interval list to .tsv file. Note:; If all intervals have an annotation, that annotation will be written to the .tsv files.; If only some intervals have an annotation, that annotation will be ignored and a warning; will be logged. Args:; output_file: output .tsv file; interval_list: list of intervals to write to .tsv file; sam_header_lines: (optional) SAM header lines. Returns:; None; """"""",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/io/io_intervals_and_counts.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/io/io_intervals_and_counts.py
Testability,assert,asserted,"r character; comment: comment character. Returns:; sample name, counts, (and optionally a list of intervals if `return_interval_list` == True); """"""; """"""Loads an interval list .tsv file.; Args:; interval_list_tsv_file: input interval list .tsv file; comment: comment character; delimiter: delimiter character. Returns:; interval list; """"""; """"""Extract SAM header from a file. Notes:; Only contiguous SAM header lines (starting with '@') are considered. The parsing of the input file; stops as soon as a line starting with any other character is reached. Returns:; a list of str; """"""; """"""Loads read counts for a given cohort corresponding to a provided list of intervals. Args:; read_count_file_list: list of read counts .tsv files; modeling_interval_list: requested list of intervals. Raises:; AssertionError: if some of the intervals in `modeling_interval_list` are absent in the; provided read counts .tsv file. Note:; it is assumed that all read counts have the SAME intervals.; this assumption is not asserted for speed. Returns:; list of sample names, 2-dim (sample x interval) ndarray of read counts; """"""; # load intervals from the first read counts table; # do not load intervals again for speed, assume it is the same as the first sample; # subset the counts in the order dictated by modeling_interval_list; """"""Converts a pandas dataframe of intervals to list(Interval). Annotations will be parsed; and added to the intervals as well. Args:; interval_list_pd: interval list as a pandas dataframe; input_tsv_file: path to the .tsv file associated to the dataframe; (only used to generate exception messages). Returns:; a list of intervals; """"""; """"""Write a list of interval list to .tsv file. Note:; If all intervals have an annotation, that annotation will be written to the .tsv files.; If only some intervals have an annotation, that annotation will be ignored and a warning; will be logged. Args:; output_file: output .tsv file; interval_list: list of intervals to write to .tsv file; sam_hea",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/io/io_intervals_and_counts.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/io/io_intervals_and_counts.py
Deployability,update,updates,"""""""Write coverage metadata for all samples in a given `SampleMetadataCollection` to a single .tsv file; in the same order as `sample_names`. Args:; sample_metadata_collection: an instance of `SampleMetadataCollection`; sample_names: list of samples to process; output_file: output .tsv file. Raises:; AssertionError: if some of the samples do not have `SampleCoverageMetadata` annotation. Returns:; None; """"""; """"""Reads sample coverage metadata from a .tsv file and adds them to `sample_metadata_collection`. Args:; sample_metadata_collection: collection to which the coverage metadata is to be added; input_file: input sample coverage metadata .tsv file; comment: comment character; delimiter: delimiter character. Returns:; list of samples in the same order as encountered in `input_file`; """"""; """"""Reads the output of contig ploidy determination tool and updates the given instance of; `SampleMetadataCollection` for read depth and ploidy metadata. Args:; sample_metadata_collection: the instance of `SampleMetadataCollection` to be updated; input_calls_path: posterior output path of contig ploidy determination tool; comment: comment character; delimiter: delimiter character. Returns:; None; """"""",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/io/io_metadata.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/io/io_metadata.py
Deployability,update,updates,"""""""Writes global ploidy model parameters to disk.""""""; # write gcnvkernel version; # write ploidy config; # write global variables in the posterior; """"""Writes sample-specific ploidy model parameters and associated workspace variables to disk.""""""; # find best contig ploidy calls and calculate ploidy genotyping quality; # generate sample ploidy metadata; # generate sample read depth metadata; # write contig ploidy; # write read depth; # write sample name; # write sample-specific posteriors in the approximation; """"""Reads ploidy model parameters from disk and updates the provided approximation accordingly. Note:; It is assumed that the provided model instance and approximation are compatible with the model; parameters to be read. This has to be asserted beforehand by the CLI tool.; """"""; # check if the model is created with the same gcnvkernel version; # read model params",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/io/io_ploidy.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/io/io_ploidy.py
Modifiability,config,config,"""""""Writes global ploidy model parameters to disk.""""""; # write gcnvkernel version; # write ploidy config; # write global variables in the posterior; """"""Writes sample-specific ploidy model parameters and associated workspace variables to disk.""""""; # find best contig ploidy calls and calculate ploidy genotyping quality; # generate sample ploidy metadata; # generate sample read depth metadata; # write contig ploidy; # write read depth; # write sample name; # write sample-specific posteriors in the approximation; """"""Reads ploidy model parameters from disk and updates the provided approximation accordingly. Note:; It is assumed that the provided model instance and approximation are compatible with the model; parameters to be read. This has to be asserted beforehand by the CLI tool.; """"""; # check if the model is created with the same gcnvkernel version; # read model params",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/io/io_ploidy.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/io/io_ploidy.py
Testability,assert,asserted,"""""""Writes global ploidy model parameters to disk.""""""; # write gcnvkernel version; # write ploidy config; # write global variables in the posterior; """"""Writes sample-specific ploidy model parameters and associated workspace variables to disk.""""""; # find best contig ploidy calls and calculate ploidy genotyping quality; # generate sample ploidy metadata; # generate sample read depth metadata; # write contig ploidy; # write read depth; # write sample name; # write sample-specific posteriors in the approximation; """"""Reads ploidy model parameters from disk and updates the provided approximation accordingly. Note:; It is assumed that the provided model instance and approximation are compatible with the model; parameters to be read. This has to be asserted beforehand by the CLI tool.; """"""; # check if the model is created with the same gcnvkernel version; # read model params",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/io/io_ploidy.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/io/io_ploidy.py
Testability,test,tests,"#for GATK PythonUnitTestRunner/Java tests; # for running in IntelliJ/Python tests; # test_sub_dir = current_dir + ""/../../../../../../../../src/test/resources/org/broadinstitute/hellbender/tools/copynumber/gcnv-postprocess/""; #should match number of chr 14 lines in clustered VCF (12); # no segments on contig 1; # all samples should have the same number of intervals",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/io/test_io_vcf_parsing.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/io/test_io_vcf_parsing.py
Availability,toler,tolerated,"# np.log(2 * np.pi); # 10 / np.log(10); """"""Normalizes the probability vector of a categorical RV to unity. Args:; prob_vector: input probability vector a categorical RV of choice; prob_sum_tol: tolerated amount of deviation from unity before performing normalization. Returns:; A new and normalized probability vector if it deviates from unity more than `prob_sum_tol`; Otherwise, `prob_vector` is returned unchanged.; """"""; """"""Generates symbolic negative binomial logp. Args:; mu: negative binomial mean tensor; alpha: negative binomial over-dispersion tensor; value: negative binomial counts. Note:; `mu`, `alpha` and `value` must be either shape-compatible or be commensurately broadcastable. Returns:; symbolic negative binomial logp; """"""; """"""Generates symbolic Gaussian approximation to negative binomial logp. Args:; mu: negative binomial mean tensor; alpha: negative binomial over-dispersion tensor; value: negative binomial counts. Note:; `mu`, `alpha` and `value` must be either shape-compatible or be commensurately broadcastable. Returns:; symbolic approximate negative binomial logp; """"""; # precision; # todo; """"""Generates symbolic negative binomial logp with conditional switching to Gaussian approximation; if the approximation is valid. Args:; mu: negative binomial mean tensor; alpha: negative binomial over-dispersion tensor; value: negative binomial counts. Returns:; symbolic approximate negative binomial logp; """"""; """"""This distribution is obtained by taking X ~ Exp and performing a Bose transformation; Y = (exp(X) - 1)^{-1}. The result is:. p(y) = (1 + 2 \mu) y^{2\mu} (1 + y)^{-2(1 + \mu)}. It is a heavy-tail distribution with non-existent first moment. Args:; mu: exponential parameter of X; value: values of Y. Returns:; symbolic logp; """"""; """"""Symbolic log(exp(a) + exp(b)). The edge case where `a` - `b` is undefined is handled by; setting the difference to 0. This occurs if both `a` and `b` are +inf or -inf. Returns:; symbolic log(exp(a) + exp(b)); """"""; """"""Symbolic Jense",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/models/commons.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/models/commons.py
Modifiability,variab,variable,"` - `b` is undefined is handled by; setting the difference to 0. This occurs if both `a` and `b` are +inf or -inf. Returns:; symbolic log(exp(a) + exp(b)); """"""; """"""Symbolic Jensen-Shannon distance (symmetric KL divergence) between two discrete distributions. Args:; log_p_1: first discrete probability distribution in log space; log_p_2: second discrete probability distribution in log space. Returns:; Symbolic Jensen-Shannon distance; """"""; """"""Symbolic Hellinger distance between two discrete distributions. Args:; log_p_1: first discrete probability distribution in log space; log_p_2: second discrete probability distribution in log space. Returns:; Symbolic Hellinger distance; """"""; """"""Takes a vector of probabilities in log space and perform genotyping. Args:; log_p: a vector probabilities in log scape. Note:; log_p must be properly normalized, i.e. np.sum(np.exp(log_p)) == 1; (this is not explicitly asserted). Returns:; A tuple (most likely genotype index, phred-scaled genotyping quality); """"""; # PyMC/pytensor logsumexp doesn't include the stability trick, so we port the PyMC3/theano version here for consistency; # Adapted from https://github.com/Theano/Theano/issues/1563; """"""Symbolic mean of a given PyMC3 stochastic node with respect to a given variational; posterior approximation.; Args:; approx: an instance of PyMC3 approximation; node: stochastic node; size: the number of samples to use for calculating the mean; Returns:; Symbolic approximate mean of the stochastic node; """"""; # see Approximation.sample_node(); """"""Get a generator that returns samples of a precomputed model approximation for a specific variable in that model; Args:; approx: an instance of PyMC3 mean-field approximation; node: a stochastic node in the model; num_samples: number of samples to draw; Returns:; A generator that will yield `num_samples` samples from an approximation to a posterior; """"""; # see Approximation.sample_node(); # must use compile_pymc to pass random_seed for reproducible sampling",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/models/commons.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/models/commons.py
Performance,perform,performing,"# np.log(2 * np.pi); # 10 / np.log(10); """"""Normalizes the probability vector of a categorical RV to unity. Args:; prob_vector: input probability vector a categorical RV of choice; prob_sum_tol: tolerated amount of deviation from unity before performing normalization. Returns:; A new and normalized probability vector if it deviates from unity more than `prob_sum_tol`; Otherwise, `prob_vector` is returned unchanged.; """"""; """"""Generates symbolic negative binomial logp. Args:; mu: negative binomial mean tensor; alpha: negative binomial over-dispersion tensor; value: negative binomial counts. Note:; `mu`, `alpha` and `value` must be either shape-compatible or be commensurately broadcastable. Returns:; symbolic negative binomial logp; """"""; """"""Generates symbolic Gaussian approximation to negative binomial logp. Args:; mu: negative binomial mean tensor; alpha: negative binomial over-dispersion tensor; value: negative binomial counts. Note:; `mu`, `alpha` and `value` must be either shape-compatible or be commensurately broadcastable. Returns:; symbolic approximate negative binomial logp; """"""; # precision; # todo; """"""Generates symbolic negative binomial logp with conditional switching to Gaussian approximation; if the approximation is valid. Args:; mu: negative binomial mean tensor; alpha: negative binomial over-dispersion tensor; value: negative binomial counts. Returns:; symbolic approximate negative binomial logp; """"""; """"""This distribution is obtained by taking X ~ Exp and performing a Bose transformation; Y = (exp(X) - 1)^{-1}. The result is:. p(y) = (1 + 2 \mu) y^{2\mu} (1 + y)^{-2(1 + \mu)}. It is a heavy-tail distribution with non-existent first moment. Args:; mu: exponential parameter of X; value: values of Y. Returns:; symbolic logp; """"""; """"""Symbolic log(exp(a) + exp(b)). The edge case where `a` - `b` is undefined is handled by; setting the difference to 0. This occurs if both `a` and `b` are +inf or -inf. Returns:; symbolic log(exp(a) + exp(b)); """"""; """"""Symbolic Jense",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/models/commons.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/models/commons.py
Testability,log,log,"# np.log(2 * np.pi); # 10 / np.log(10); """"""Normalizes the probability vector of a categorical RV to unity. Args:; prob_vector: input probability vector a categorical RV of choice; prob_sum_tol: tolerated amount of deviation from unity before performing normalization. Returns:; A new and normalized probability vector if it deviates from unity more than `prob_sum_tol`; Otherwise, `prob_vector` is returned unchanged.; """"""; """"""Generates symbolic negative binomial logp. Args:; mu: negative binomial mean tensor; alpha: negative binomial over-dispersion tensor; value: negative binomial counts. Note:; `mu`, `alpha` and `value` must be either shape-compatible or be commensurately broadcastable. Returns:; symbolic negative binomial logp; """"""; """"""Generates symbolic Gaussian approximation to negative binomial logp. Args:; mu: negative binomial mean tensor; alpha: negative binomial over-dispersion tensor; value: negative binomial counts. Note:; `mu`, `alpha` and `value` must be either shape-compatible or be commensurately broadcastable. Returns:; symbolic approximate negative binomial logp; """"""; # precision; # todo; """"""Generates symbolic negative binomial logp with conditional switching to Gaussian approximation; if the approximation is valid. Args:; mu: negative binomial mean tensor; alpha: negative binomial over-dispersion tensor; value: negative binomial counts. Returns:; symbolic approximate negative binomial logp; """"""; """"""This distribution is obtained by taking X ~ Exp and performing a Bose transformation; Y = (exp(X) - 1)^{-1}. The result is:. p(y) = (1 + 2 \mu) y^{2\mu} (1 + y)^{-2(1 + \mu)}. It is a heavy-tail distribution with non-existent first moment. Args:; mu: exponential parameter of X; value: values of Y. Returns:; symbolic logp; """"""; """"""Symbolic log(exp(a) + exp(b)). The edge case where `a` - `b` is undefined is handled by; setting the difference to 0. This occurs if both `a` and `b` are +inf or -inf. Returns:; symbolic log(exp(a) + exp(b)); """"""; """"""Symbolic Jense",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/models/commons.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/models/commons.py
Modifiability,variab,variable,"""""""An extension of PyMC `Model` class with the added functionality of labeling RVs; as either global or sample-specific (for the purpose of I/O, and structured optimization).; """"""; """"""Register a variable as global. Args:; var: a PyMC free variable. Returns:; None; """"""; """"""Register a variable as sample-specific. Args:; var: a PyMC free variable; sample_axis: axis corresponding to sample index (it is used for slicing `var` to obtain single-sample; parameters). Returns:; None; """"""; """"""Verifies that all variables are registered as either as global or sample-specific.""""""",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/models/fancy_model.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/models/fancy_model.py
Performance,optimiz,optimization,"""""""An extension of PyMC `Model` class with the added functionality of labeling RVs; as either global or sample-specific (for the purpose of I/O, and structured optimization).; """"""; """"""Register a variable as global. Args:; var: a PyMC free variable. Returns:; None; """"""; """"""Register a variable as sample-specific. Args:; var: a PyMC free variable; sample_axis: axis corresponding to sample index (it is used for slicing `var` to obtain single-sample; parameters). Returns:; None; """"""; """"""Verifies that all variables are registered as either as global or sample-specific.""""""",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/models/fancy_model.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/models/fancy_model.py
Availability,error,error,"l declaration (continuous RVs only; discrete posteriors are assumed; to be given).""""""; # interval-specific unexplained variance; # sample-specific unexplained variance; # convert ""unexplained variance"" to negative binomial over-dispersion; # interval-specific mean log bias; # log-normal read depth centered at the global read depth; # log bias modelling, starting with the log mean bias; # PR #8651 NOTE: originally used HalfFlat in PyMC3, but this now raises; # NotImplementedError: Cannot sample from half_flat variable.; # we instead use a Uniform with a very large, unexposed upper bound; # ARD prior precisions; # bias factors; # sample-specific bias factor loadings; # add contribution to total log bias; # GC bias; # sample-specific GC bias factor loadings; # add contribution to total log bias; # useful expressions; # the expected number of erroneously mapped reads; # n_st (observed); # for CNV-active classes, calculate exact posterior expectation; # PR #8561 switched indexing and dimshuffle to account for case when active_class_indices has a single element; # PR #8561 switched indexing and dimshuffle to account for case when active_class_indices has a single element, inv to reciprocal; # PR #8561 switched indexing and dimshuffle to account for case when active_class_indices has a single element; # for CNV-silent classes, use MAP copy number state; # originally DensityDist in PyMC3, but this now raises an error about sampling;; # changed in https://github.com/broadinstitute/gatk/pull/8561; """"""Draws posterior samples from log copy number emission probabilities for a given variational; approximation to the denoising model continuous RVs.""""""; """"""Generates a new compiled sampler based on a given approximation.; Args:; approx: an instance of PyMC mean-field approximation. Returns:; None; """"""; """"""For a given variational approximation, returns a compiled pytensor function that draws posterior samples; from log copy number emission probabilities.""""""; # must use compile_pymc to",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/models/model_denoising_calling.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/models/model_denoising_calling.py
Deployability,update,updated,"o a given instance of `ArgumentParser`. Args:; args: an instance of `ArgumentParser`; hide: a set of arguments not to expose. Returns:; None; """"""; """"""Initialize an instance of `CopyNumberCallingConfig` from a dictionary of arguments. Args:; args_dict: a dictionary of arguments; the keys must match argument names in; `CopyNumberCallingConfig.__init__`. Returns:; an instance of `CopyNumberCallingConfig`; """"""; """"""Base class for posterior initializers.""""""; """"""Initialize posteriors to reasonable values based on priors.""""""; # interval class log posterior probs; # copy number log posterior probs; """"""This class contains objects (numpy arrays, pytensor tensors, etc) shared between the denoising model; and the copy number caller.""""""; # a list of unique contigs appearing in the interval list; the ordering is arbitrary and; # is only used internally; # Note: j is the index subscript used for contig index hereafter; # shared pytensor tensors from the input data; # copy-number event stay probability; # copy number values for each copy number state; # copy number log posterior and derived quantities (to be initialized by `PosteriorInitializer`); # latest MAP estimate of integer copy number (to be initialized and periodically updated by; # `DenoisingCallingWorkspace.update_auxiliary_vars); # latest bitmask of CNV-active intervals (to be initialized and periodically updated by; # `DenoisingCallingWorkspace.update_auxiliary_vars if q_c_expectation_mode == 'hybrid'); # copy number emission log posterior; # class log posterior (to be initialized by `PosteriorInitializer`); # class emission log posterior; # (to be initialized by calling `initialize_copy_number_class_inference_vars`); # class assignment prior probabilities; # (to be initialized by calling `initialize_copy_number_class_inference_vars`); # class Markov chain log prior (initialized here and remains constant throughout); # (to be initialized by calling `initialize_copy_number_class_inference_vars`); # class Markov chain log ",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/models/model_denoising_calling.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/models/model_denoising_calling.py
Energy Efficiency,reduce,reduces,"on for forward-backward update of class posterior; # Note:; # if p_active == 0, we have to deal with inf - inf expressions properly.; # setting resolve_nans = True takes care of such ambiguities.; # compiled function for update of class log emission; # compiled function for variational update of copy number HMM specs; """"""Returns copy-number prior probabilities for each contig (j) and class (k) as a 3d ndarray. Args:; num_copy_number_states: total number of copy-number states; p_alt: total probability of alt copy-number states; baseline_copy_number_j: baseline copy-number state for each contig. Returns:; a 3d ndarray; """"""; # the silent class; # the active class; """"""Perform a round of update of q(tau) and q(c). Note:; This function must be called until q(tau) and q(c) converge to a self-consistent solution. Args:; copy_number_update_summary_statistic_reducer: a function that reduces vectors to scalars and; is used to compile a summary of copy number posterior updates across intervals for each sample; class_update_summary_statistic_reducer: a function that reduces vectors to scalars and; is used to compile a summary of interval class posterior updates across intervals. Returns:; copy number update summary (ndarray of size `num_samples`),; copy number Markov chain log likelihoods (ndarray of size `num_samples`),; interval class update summary,; interval class Markov chain log likelihood; """"""; # copy number posterior update; # class posterior update; # step 1. calculate copy-number HMM log prior and log transition matrix; # step 2. run forward-backward and update copy-number posteriors; # todo multiprocessing; # with mp.Pool(processes=num_calling_processes) as pool:; # for fb_result in pool.map(_run_single_sample_fb, range(begin_index, end_index)):; # update log posterior in the workspace; # update summary stats; """"""Returns a compiled function that calculates the interval-class-averaged and probability-sum-normalized; log copy number transition matrix and log copy number",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/models/model_denoising_calling.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/models/model_denoising_calling.py
Integrability,depend,depending,"prior (initialized here and remains constant throughout); # class Markov chain log transition (initialized here and remains constant throughout); """"""Initializes `DenoisingCallingWorkspace.W_gc_tg` and `DenoisingCallingWorkspace.interval_neighbor_index_list`; if required by the model configuration.""""""; """"""Updates `DenoisingCallingWorkspace.c_map_st' and `DenoisingCallingWorkspace.active_class_bitmask_t`.""""""; # MAP copy number call; # bitmask for intervals of which the probability of being in the silent class is below 0.5; """"""Pads a given interval list, finds the index of overlapping neighbors, and returns a list of indices of; overlapping neighbors. Note:; It is assumed that the `interval_list` is sorted (this is not asserted). Args:; interval_list: list of intervals; maximum_neighbor_distance: Maximum distance between intervals to be considered neighbors. Returns:; A list of indices of overlapping neighbors with the same length as `interval_list`. Each element; in a variable-length list, depending on the number of neighbors.; """"""; """"""Calculates the log transition probability between copy number classes.""""""; """"""Creates a sparse 2d pytensor tensor with shape (num_intervals, gc_bin). The sparse; tensor represents a 1-hot mapping of each interval to its GC bin index. The range [0, 1]; is uniformly divided into num_gc_bins.; """"""; """"""Generates global read depth array, average ploidy array, and baseline copy numbers for all; samples. Args:; sample_metadata_collection: a instance of `SampleMetadataCollection` containing required metadata; for all samples in `sample_names`; sample_names: list of sample names; contig_list: list of contigs appearing in the modeling interval list. Returns:; global read depth, average ploudy, baseline copy number; """"""; """"""Base class for suppliers of initial global model parameters""""""; """"""Initial interval-specific unexplained variance.""""""; """"""Initial mean bias in log space.""""""; """"""Initial ARD prior precisions.""""""; """"""Trivial initial model supplier",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/models/model_denoising_calling.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/models/model_denoising_calling.py
Modifiability,config,configuration,"on; # (to be initialized by calling `initialize_bias_inference_vars`); # denoised copy ratios; # initialize posterior; """"""Initializes members required for copy number class inference (must be called in the cohort mode).; The following members are initialized:; - `DenoisingCallingWorkspace.log_class_emission_tk`; - `DenoisingCallingWorkspace.class_probs_k`; - `DenoisingCallingWorkspace.log_prior_k`; - `DenoisingCallingWorkspace.log_trans_tkk`; """"""; # class emission log posterior; # class assignment prior probabilities; # Note:; # The first class is the CNV-silent class (highly biased toward the baseline copy number); # The second class is a CNV-active class (all copy number states are equally probable); # class Markov chain log prior (initialized here and remains constant throughout); # class Markov chain log transition (initialized here and remains constant throughout); """"""Initializes `DenoisingCallingWorkspace.W_gc_tg` and `DenoisingCallingWorkspace.interval_neighbor_index_list`; if required by the model configuration.""""""; """"""Updates `DenoisingCallingWorkspace.c_map_st' and `DenoisingCallingWorkspace.active_class_bitmask_t`.""""""; # MAP copy number call; # bitmask for intervals of which the probability of being in the silent class is below 0.5; """"""Pads a given interval list, finds the index of overlapping neighbors, and returns a list of indices of; overlapping neighbors. Note:; It is assumed that the `interval_list` is sorted (this is not asserted). Args:; interval_list: list of intervals; maximum_neighbor_distance: Maximum distance between intervals to be considered neighbors. Returns:; A list of indices of overlapping neighbors with the same length as `interval_list`. Each element; in a variable-length list, depending on the number of neighbors.; """"""; """"""Calculates the log transition probability between copy number classes.""""""; """"""Creates a sparse 2d pytensor tensor with shape (num_intervals, gc_bin). The sparse; tensor represents a 1-hot mapping of each interval ",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/models/model_denoising_calling.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/models/model_denoising_calling.py
Performance,load,loadings,"l declaration (continuous RVs only; discrete posteriors are assumed; to be given).""""""; # interval-specific unexplained variance; # sample-specific unexplained variance; # convert ""unexplained variance"" to negative binomial over-dispersion; # interval-specific mean log bias; # log-normal read depth centered at the global read depth; # log bias modelling, starting with the log mean bias; # PR #8651 NOTE: originally used HalfFlat in PyMC3, but this now raises; # NotImplementedError: Cannot sample from half_flat variable.; # we instead use a Uniform with a very large, unexposed upper bound; # ARD prior precisions; # bias factors; # sample-specific bias factor loadings; # add contribution to total log bias; # GC bias; # sample-specific GC bias factor loadings; # add contribution to total log bias; # useful expressions; # the expected number of erroneously mapped reads; # n_st (observed); # for CNV-active classes, calculate exact posterior expectation; # PR #8561 switched indexing and dimshuffle to account for case when active_class_indices has a single element; # PR #8561 switched indexing and dimshuffle to account for case when active_class_indices has a single element, inv to reciprocal; # PR #8561 switched indexing and dimshuffle to account for case when active_class_indices has a single element; # for CNV-silent classes, use MAP copy number state; # originally DensityDist in PyMC3, but this now raises an error about sampling;; # changed in https://github.com/broadinstitute/gatk/pull/8561; """"""Draws posterior samples from log copy number emission probabilities for a given variational; approximation to the denoising model continuous RVs.""""""; """"""Generates a new compiled sampler based on a given approximation.; Args:; approx: an instance of PyMC mean-field approximation. Returns:; None; """"""; """"""For a given variational approximation, returns a compiled pytensor function that draws posterior samples; from log copy number emission probabilities.""""""; # must use compile_pymc to",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/models/model_denoising_calling.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/models/model_denoising_calling.py
Safety,avoid,avoid,"o_j_map: a mapping from interval indices (t) to contig indices (j); it is used to unpack; `pi_jkc` to `pi_tkc` (see below). Returned pytensor function outputs:; log_prior_c_first_interval: log probability of copy-number states for the first interval; log_trans_tab: log transition probability matrix from interval `t` to interval `t+1`. Note:; In the following, we use ""a"" and ""b"" subscripts in the variable names to refer to the departure; and destination states, respectively. Like before, ""t"" and ""k"" denote interval and class, and ""j""; refers to contig index.; """"""; # shorthands; # log prior probability for the first interval; # log transition matrix; # map contig to interval and obtain pi_tkc for the rest of the targets; # calculate normalized log transition matrix; # todo use logaddexp; """"""Returns a compiled function that calculates the log interval class emission probability and; directly updates `log_class_emission_tk` in the workspace. Note:; In the following,. xi_tab ~ posterior copy number probability of two subsequent intervals. We ignore correlations, i.e. we assume:. xi_st(a, b) \equiv q_c(c_{s,t} = a, c_{s,t+1} = b); \approx q_c(c_{s,t} = a) q_c(c_{s,t+1} = b). If needed, xi can be calculated exactly from the forward-backward tables.; """"""; # shorthands; # log copy number transition matrix for each class; # calculate log class emission by reducing over samples; see below; # this converts TensorType from row to matrix in the edge case when number of intervals is equal to 2; # (to avoid type mismatch later on); """"""Adds the contribution of a given sample to the log class emission (symbolically). Args:; pi_jkc: copy number prior inventory for the sample; q_c_tc: copy number posteriors for the sample; cum_sum_tk: current cumulative sum of log class emission. Returns:; Symbolically updated cumulative sum of log class emission; """"""; # map contigs to targets (starting from the second interval); # todo use logaddexp; # the first interval; # concatenate first and rest",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/models/model_denoising_calling.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/models/model_denoising_calling.py
Security,expose,expose,"""""""Configuration for the coverage denoising model, including hyper-parameters, model feature selection,; and choice of approximation schemes.""""""; # approximation schemes for calculating expectations with respect to copy number posteriors; """"""See `expose_args` for the description of arguments""""""; """"""Exposes arguments of `__init__` to a given instance of `ArgumentParser`. Args:; args: an instance of `ArgumentParser`; hide: a set of arguments not to expose. Returns:; None; """"""; """"""Initialize an instance of `DenoisingModelConfig` from a dictionary of arguments. Args:; args_dict: a dictionary of arguments; the keys must match argument names in; `DenoisingModelConfig.__init__`. Returns:; an instance of `DenoisingModelConfig`; """"""; """"""Configuration of the copy number caller.""""""; """"""See `expose_args` for the description of arguments""""""; """"""Exposes arguments of `__init__` to a given instance of `ArgumentParser`. Args:; args: an instance of `ArgumentParser`; hide: a set of arguments not to expose. Returns:; None; """"""; """"""Initialize an instance of `CopyNumberCallingConfig` from a dictionary of arguments. Args:; args_dict: a dictionary of arguments; the keys must match argument names in; `CopyNumberCallingConfig.__init__`. Returns:; an instance of `CopyNumberCallingConfig`; """"""; """"""Base class for posterior initializers.""""""; """"""Initialize posteriors to reasonable values based on priors.""""""; # interval class log posterior probs; # copy number log posterior probs; """"""This class contains objects (numpy arrays, pytensor tensors, etc) shared between the denoising model; and the copy number caller.""""""; # a list of unique contigs appearing in the interval list; the ordering is arbitrary and; # is only used internally; # Note: j is the index subscript used for contig index hereafter; # shared pytensor tensors from the input data; # copy-number event stay probability; # copy number values for each copy number state; # copy number log posterior and derived quantities (to be initialized by ",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/models/model_denoising_calling.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/models/model_denoising_calling.py
Testability,log,log,"ance of `DenoisingModelConfig` from a dictionary of arguments. Args:; args_dict: a dictionary of arguments; the keys must match argument names in; `DenoisingModelConfig.__init__`. Returns:; an instance of `DenoisingModelConfig`; """"""; """"""Configuration of the copy number caller.""""""; """"""See `expose_args` for the description of arguments""""""; """"""Exposes arguments of `__init__` to a given instance of `ArgumentParser`. Args:; args: an instance of `ArgumentParser`; hide: a set of arguments not to expose. Returns:; None; """"""; """"""Initialize an instance of `CopyNumberCallingConfig` from a dictionary of arguments. Args:; args_dict: a dictionary of arguments; the keys must match argument names in; `CopyNumberCallingConfig.__init__`. Returns:; an instance of `CopyNumberCallingConfig`; """"""; """"""Base class for posterior initializers.""""""; """"""Initialize posteriors to reasonable values based on priors.""""""; # interval class log posterior probs; # copy number log posterior probs; """"""This class contains objects (numpy arrays, pytensor tensors, etc) shared between the denoising model; and the copy number caller.""""""; # a list of unique contigs appearing in the interval list; the ordering is arbitrary and; # is only used internally; # Note: j is the index subscript used for contig index hereafter; # shared pytensor tensors from the input data; # copy-number event stay probability; # copy number values for each copy number state; # copy number log posterior and derived quantities (to be initialized by `PosteriorInitializer`); # latest MAP estimate of integer copy number (to be initialized and periodically updated by; # `DenoisingCallingWorkspace.update_auxiliary_vars); # latest bitmask of CNV-active intervals (to be initialized and periodically updated by; # `DenoisingCallingWorkspace.update_auxiliary_vars if q_c_expectation_mode == 'hybrid'); # copy number emission log posterior; # class log posterior (to be initialized by `PosteriorInitializer`); # class emission log posterior; # (to be ini",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/models/model_denoising_calling.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/models/model_denoising_calling.py
Availability,error,error,"""""""Germline contig ploidy model hyper-parameters.""""""; """"""Initializer. Args:; contig_ploidy_prior_map: map from contigs to prior probabilities of each ploidy state; mean_bias_sd: standard deviation of mean contig-level coverage bias; psi_j_scale: typical scale of contig-specific unexplained variance; psi_s_scale: typical scale of sample-specific unexplained variance; mapping_error_rate: typical mapping error probability; """"""; """"""Exposes arguments of `__init__` to a given instance of `ArgumentParser`. Args:; args: an instance of `ArgumentParser`; hide: a set of arguments not to expose. Returns:; None; """"""; """"""Initialize an instance of `PloidyModelConfig` from a dictionary of arguments. Args:; args_dict: a dictionary of arguments; the keys must match argument names in; `PloidyModelConfig.__init__`. Returns:; an instance of `PloidyModelConfig`; """"""; """"""Workspace for storing data structures that are shared between continuous and discrete sectors; of the germline contig ploidy model.""""""; # number of intervals per contig as a shared pytensor tensor; # count per contig and total count as shared pytensor tensors; # integer ploidy values; # ploidy priors; # ploidy log posteriors (initial value is immaterial); # ploidy log emission (initial value is immaterial); # exclusion mask; mask(j, k) = 1 - delta(j, k); """"""Declaration of the germline contig ploidy model (continuous variables only; posterior of discrete; variables are assumed to be known).""""""; # shorthands; # mean per-contig bias; # contig coverage unexplained variance; # sample-specific contig unexplained variance; # convert ""unexplained variance"" to negative binomial over-dispersion; # mean ploidy per contig per sample; # mean-field amplification coefficient per contig; # gamma_rest_sj \equiv sum_{j' \neq j} gamma_sj; # NB per-contig counts; # average number of reads erroneously mapped to contig j; # the switch is required for a single contig edge case; # mean; # over-dispersion; # contig counts; # originally DensityDist",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/models/model_ploidy.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/models/model_ploidy.py
Deployability,continuous,continuous,"""""""Germline contig ploidy model hyper-parameters.""""""; """"""Initializer. Args:; contig_ploidy_prior_map: map from contigs to prior probabilities of each ploidy state; mean_bias_sd: standard deviation of mean contig-level coverage bias; psi_j_scale: typical scale of contig-specific unexplained variance; psi_s_scale: typical scale of sample-specific unexplained variance; mapping_error_rate: typical mapping error probability; """"""; """"""Exposes arguments of `__init__` to a given instance of `ArgumentParser`. Args:; args: an instance of `ArgumentParser`; hide: a set of arguments not to expose. Returns:; None; """"""; """"""Initialize an instance of `PloidyModelConfig` from a dictionary of arguments. Args:; args_dict: a dictionary of arguments; the keys must match argument names in; `PloidyModelConfig.__init__`. Returns:; an instance of `PloidyModelConfig`; """"""; """"""Workspace for storing data structures that are shared between continuous and discrete sectors; of the germline contig ploidy model.""""""; # number of intervals per contig as a shared pytensor tensor; # count per contig and total count as shared pytensor tensors; # integer ploidy values; # ploidy priors; # ploidy log posteriors (initial value is immaterial); # ploidy log emission (initial value is immaterial); # exclusion mask; mask(j, k) = 1 - delta(j, k); """"""Declaration of the germline contig ploidy model (continuous variables only; posterior of discrete; variables are assumed to be known).""""""; # shorthands; # mean per-contig bias; # contig coverage unexplained variance; # sample-specific contig unexplained variance; # convert ""unexplained variance"" to negative binomial over-dispersion; # mean ploidy per contig per sample; # mean-field amplification coefficient per contig; # gamma_rest_sj \equiv sum_{j' \neq j} gamma_sj; # NB per-contig counts; # average number of reads erroneously mapped to contig j; # the switch is required for a single contig edge case; # mean; # over-dispersion; # contig counts; # originally DensityDist",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/models/model_ploidy.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/models/model_ploidy.py
Modifiability,variab,variables,"ge bias; psi_j_scale: typical scale of contig-specific unexplained variance; psi_s_scale: typical scale of sample-specific unexplained variance; mapping_error_rate: typical mapping error probability; """"""; """"""Exposes arguments of `__init__` to a given instance of `ArgumentParser`. Args:; args: an instance of `ArgumentParser`; hide: a set of arguments not to expose. Returns:; None; """"""; """"""Initialize an instance of `PloidyModelConfig` from a dictionary of arguments. Args:; args_dict: a dictionary of arguments; the keys must match argument names in; `PloidyModelConfig.__init__`. Returns:; an instance of `PloidyModelConfig`; """"""; """"""Workspace for storing data structures that are shared between continuous and discrete sectors; of the germline contig ploidy model.""""""; # number of intervals per contig as a shared pytensor tensor; # count per contig and total count as shared pytensor tensors; # integer ploidy values; # ploidy priors; # ploidy log posteriors (initial value is immaterial); # ploidy log emission (initial value is immaterial); # exclusion mask; mask(j, k) = 1 - delta(j, k); """"""Declaration of the germline contig ploidy model (continuous variables only; posterior of discrete; variables are assumed to be known).""""""; # shorthands; # mean per-contig bias; # contig coverage unexplained variance; # sample-specific contig unexplained variance; # convert ""unexplained variance"" to negative binomial over-dispersion; # mean ploidy per contig per sample; # mean-field amplification coefficient per contig; # gamma_rest_sj \equiv sum_{j' \neq j} gamma_sj; # NB per-contig counts; # average number of reads erroneously mapped to contig j; # the switch is required for a single contig edge case; # mean; # over-dispersion; # contig counts; # originally DensityDist, but this raised an error about random;; # changed in https://github.com/broadinstitute/gatk/pull/8561; # for log ploidy emission sampling; """"""Draws posterior samples from the ploidy log emission probability for a given var",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/models/model_ploidy.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/models/model_ploidy.py
Security,expose,expose,"""""""Germline contig ploidy model hyper-parameters.""""""; """"""Initializer. Args:; contig_ploidy_prior_map: map from contigs to prior probabilities of each ploidy state; mean_bias_sd: standard deviation of mean contig-level coverage bias; psi_j_scale: typical scale of contig-specific unexplained variance; psi_s_scale: typical scale of sample-specific unexplained variance; mapping_error_rate: typical mapping error probability; """"""; """"""Exposes arguments of `__init__` to a given instance of `ArgumentParser`. Args:; args: an instance of `ArgumentParser`; hide: a set of arguments not to expose. Returns:; None; """"""; """"""Initialize an instance of `PloidyModelConfig` from a dictionary of arguments. Args:; args_dict: a dictionary of arguments; the keys must match argument names in; `PloidyModelConfig.__init__`. Returns:; an instance of `PloidyModelConfig`; """"""; """"""Workspace for storing data structures that are shared between continuous and discrete sectors; of the germline contig ploidy model.""""""; # number of intervals per contig as a shared pytensor tensor; # count per contig and total count as shared pytensor tensors; # integer ploidy values; # ploidy priors; # ploidy log posteriors (initial value is immaterial); # ploidy log emission (initial value is immaterial); # exclusion mask; mask(j, k) = 1 - delta(j, k); """"""Declaration of the germline contig ploidy model (continuous variables only; posterior of discrete; variables are assumed to be known).""""""; # shorthands; # mean per-contig bias; # contig coverage unexplained variance; # sample-specific contig unexplained variance; # convert ""unexplained variance"" to negative binomial over-dispersion; # mean ploidy per contig per sample; # mean-field amplification coefficient per contig; # gamma_rest_sj \equiv sum_{j' \neq j} gamma_sj; # NB per-contig counts; # average number of reads erroneously mapped to contig j; # the switch is required for a single contig edge case; # mean; # over-dispersion; # contig counts; # originally DensityDist",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/models/model_ploidy.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/models/model_ploidy.py
Testability,log,log,"ge bias; psi_j_scale: typical scale of contig-specific unexplained variance; psi_s_scale: typical scale of sample-specific unexplained variance; mapping_error_rate: typical mapping error probability; """"""; """"""Exposes arguments of `__init__` to a given instance of `ArgumentParser`. Args:; args: an instance of `ArgumentParser`; hide: a set of arguments not to expose. Returns:; None; """"""; """"""Initialize an instance of `PloidyModelConfig` from a dictionary of arguments. Args:; args_dict: a dictionary of arguments; the keys must match argument names in; `PloidyModelConfig.__init__`. Returns:; an instance of `PloidyModelConfig`; """"""; """"""Workspace for storing data structures that are shared between continuous and discrete sectors; of the germline contig ploidy model.""""""; # number of intervals per contig as a shared pytensor tensor; # count per contig and total count as shared pytensor tensors; # integer ploidy values; # ploidy priors; # ploidy log posteriors (initial value is immaterial); # ploidy log emission (initial value is immaterial); # exclusion mask; mask(j, k) = 1 - delta(j, k); """"""Declaration of the germline contig ploidy model (continuous variables only; posterior of discrete; variables are assumed to be known).""""""; # shorthands; # mean per-contig bias; # contig coverage unexplained variance; # sample-specific contig unexplained variance; # convert ""unexplained variance"" to negative binomial over-dispersion; # mean ploidy per contig per sample; # mean-field amplification coefficient per contig; # gamma_rest_sj \equiv sum_{j' \neq j} gamma_sj; # NB per-contig counts; # average number of reads erroneously mapped to contig j; # the switch is required for a single contig edge case; # mean; # over-dispersion; # contig counts; # originally DensityDist, but this raised an error about random;; # changed in https://github.com/broadinstitute/gatk/pull/8561; # for log ploidy emission sampling; """"""Draws posterior samples from the ploidy log emission probability for a given var",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/models/model_ploidy.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/models/model_ploidy.py
Deployability,update,update,"""""""Implementation of the forward-backward algorithm in pytensor.""""""; """"""Initializes the forward-backward algorithm by compiling a pytensor function according to the; boolean flags. Args:; log_posterior_probs_output_tc: if not None, the new log posterior will be written to this shared tensor;; otherwise, it will be returned as an ndarray; resolve_nans: if True, expression such as inf - inf resulting in NaNs will be properly handled; do_thermalization: if True, performs thermalization of HMM parameters; do_admixing: if True, perform admixing of old and new hidden-state posterior probabilities; include_update_size_output: if True, include update size in the returned values; include_alpha_beta_output: include forward and backward tables in the return values; """"""; """"""Runs the forward-backward algorithm. Notes:; The inputs args must be compatible with the compiled pytensor function according to the; class initializer flags. Args:; log_prior_c: prior probability vector for the first node; log_trans_tcc: transition probability matrices for each directed vertex; log_emission_tc: emission probability vector for each node; prev_log_posterior_tc: (optional) previous estimate of the log posterior; (used if `self.do_admixing` is True); admixing_rate: (optional) a float in range [0, 1] denoting the amount of the new posterior probabilities; to admix with the old posterior probabilities (higher = more of the new posterior); temperature: (optional) temperature (used if `self.do_thermalization` is True). Returns:; an instance of `ForwardBackwardResult`; """"""; """"""Returns a compiled pytensor function that computes the posterior probabilities of hidden states using; the forward-backward algorithm. Note:; The input arguments and the output of the compiled pytensor function is determined by the initializer flags; as follows:. There are 3 basic input arguments:. * log_prior_c (float vector),; * log_trans_tcc (float tensor3),; * log_emission_tc (float matrix). The rest of the input arguments ",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/models/pytensor_hmm.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/models/pytensor_hmm.py
Performance,perform,performs,"""""""Implementation of the forward-backward algorithm in pytensor.""""""; """"""Initializes the forward-backward algorithm by compiling a pytensor function according to the; boolean flags. Args:; log_posterior_probs_output_tc: if not None, the new log posterior will be written to this shared tensor;; otherwise, it will be returned as an ndarray; resolve_nans: if True, expression such as inf - inf resulting in NaNs will be properly handled; do_thermalization: if True, performs thermalization of HMM parameters; do_admixing: if True, perform admixing of old and new hidden-state posterior probabilities; include_update_size_output: if True, include update size in the returned values; include_alpha_beta_output: include forward and backward tables in the return values; """"""; """"""Runs the forward-backward algorithm. Notes:; The inputs args must be compatible with the compiled pytensor function according to the; class initializer flags. Args:; log_prior_c: prior probability vector for the first node; log_trans_tcc: transition probability matrices for each directed vertex; log_emission_tc: emission probability vector for each node; prev_log_posterior_tc: (optional) previous estimate of the log posterior; (used if `self.do_admixing` is True); admixing_rate: (optional) a float in range [0, 1] denoting the amount of the new posterior probabilities; to admix with the old posterior probabilities (higher = more of the new posterior); temperature: (optional) temperature (used if `self.do_thermalization` is True). Returns:; an instance of `ForwardBackwardResult`; """"""; """"""Returns a compiled pytensor function that computes the posterior probabilities of hidden states using; the forward-backward algorithm. Note:; The input arguments and the output of the compiled pytensor function is determined by the initializer flags; as follows:. There are 3 basic input arguments:. * log_prior_c (float vector),; * log_trans_tcc (float tensor3),; * log_emission_tc (float matrix). The rest of the input arguments ",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/models/pytensor_hmm.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/models/pytensor_hmm.py
Testability,log,log,"""""""Implementation of the forward-backward algorithm in pytensor.""""""; """"""Initializes the forward-backward algorithm by compiling a pytensor function according to the; boolean flags. Args:; log_posterior_probs_output_tc: if not None, the new log posterior will be written to this shared tensor;; otherwise, it will be returned as an ndarray; resolve_nans: if True, expression such as inf - inf resulting in NaNs will be properly handled; do_thermalization: if True, performs thermalization of HMM parameters; do_admixing: if True, perform admixing of old and new hidden-state posterior probabilities; include_update_size_output: if True, include update size in the returned values; include_alpha_beta_output: include forward and backward tables in the return values; """"""; """"""Runs the forward-backward algorithm. Notes:; The inputs args must be compatible with the compiled pytensor function according to the; class initializer flags. Args:; log_prior_c: prior probability vector for the first node; log_trans_tcc: transition probability matrices for each directed vertex; log_emission_tc: emission probability vector for each node; prev_log_posterior_tc: (optional) previous estimate of the log posterior; (used if `self.do_admixing` is True); admixing_rate: (optional) a float in range [0, 1] denoting the amount of the new posterior probabilities; to admix with the old posterior probabilities (higher = more of the new posterior); temperature: (optional) temperature (used if `self.do_thermalization` is True). Returns:; an instance of `ForwardBackwardResult`; """"""; """"""Returns a compiled pytensor function that computes the posterior probabilities of hidden states using; the forward-backward algorithm. Note:; The input arguments and the output of the compiled pytensor function is determined by the initializer flags; as follows:. There are 3 basic input arguments:. * log_prior_c (float vector),; * log_trans_tcc (float tensor3),; * log_emission_tc (float matrix). The rest of the input arguments ",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/models/pytensor_hmm.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/models/pytensor_hmm.py
Availability,error,error,"f hidden state paths composed; from a subset X of all hidden states S. More explicitly, this function calculates the logp of all paths constrained to the hidden-state set; X for t_0 <= t <= t_N but unconstrained for before (t < t_0) and after (t > t_N):. unconstrained constrained unconstrained; t < t_0 | t_0 t_1 ... t_N | t > t_N; c in S | c in X c in X c in X | c in S. The inputs for the returned pytensor function are as follows:. alpha_first_c: forward log likelihood (alpha) for t = t_0 and c in X; beta_last_c: backward log likelihood (beta) for t = t_N and c in X; log_emission_tc: log emission probabilities for t \in [t_0, ..., t_N] and c in X; log_trans_tcc: log transition probabilities from `t` to `t+1` for t in [t_0, ..., t_N]; and departure and destination states in X; log_data_likelihood: log data likelihood of the unconstrained problem. The output is a non-positive scalar value that signifies the desired probability in log space. Examples:. If X = S (all hidden states), we expect logp = 0 (up to round-off error). if X = {a single hidden state}, then we expect the logp of a single path that takes on the same; hidden-state for all positions [t_0, ..., t_N]. In general, if X is a proper subset of S, we expect logp <= 0 (with logp = 0 iff the removed states; are strictly forbidden by the prior and/or the transition matrix). Returns:; a pytensor function; """"""; # make a private static instance; """"""Calculates the constrained log posterior probability for contiguous set of sites in a Markov chain.; At each site, only a subset of all states (as set by `allowed_states`) are allowed and the other states; are strictly avoided. Args:; start_index: first site index (inclusive); end_index: last site index (inclusive); allowed_states: the list of allowed states in the segment. Returns:; log constrained posterior probability (float); """"""; # single-site segment; # calculate the required slices of the log emission and log transition representing; # paths that only contain the",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/postprocess/segment_quality_utils.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/postprocess/segment_quality_utils.py
Safety,avoid,avoided,"tc: log emission probabilities for t \in [t_0, ..., t_N] and c in X; log_trans_tcc: log transition probabilities from `t` to `t+1` for t in [t_0, ..., t_N]; and departure and destination states in X; log_data_likelihood: log data likelihood of the unconstrained problem. The output is a non-positive scalar value that signifies the desired probability in log space. Examples:. If X = S (all hidden states), we expect logp = 0 (up to round-off error). if X = {a single hidden state}, then we expect the logp of a single path that takes on the same; hidden-state for all positions [t_0, ..., t_N]. In general, if X is a proper subset of S, we expect logp <= 0 (with logp = 0 iff the removed states; are strictly forbidden by the prior and/or the transition matrix). Returns:; a pytensor function; """"""; # make a private static instance; """"""Calculates the constrained log posterior probability for contiguous set of sites in a Markov chain.; At each site, only a subset of all states (as set by `allowed_states`) are allowed and the other states; are strictly avoided. Args:; start_index: first site index (inclusive); end_index: last site index (inclusive); allowed_states: the list of allowed states in the segment. Returns:; log constrained posterior probability (float); """"""; # single-site segment; # calculate the required slices of the log emission and log transition representing; # paths that only contain the allowed states; """"""Calculates the phred-scaled posterior probability that one or more (""some"") sites in a segment have; the same hidden state (""call""). Args:; start_index: first site index (inclusive); end_index: last site index (inclusive); call_state: segment call state index. Returns:; a phred-scaled probability; """"""; """"""Calculates the complementary phred-scaled posterior probability that ""all"" sites in a segment have; the same hidden state (""call""). Note:; If all of the intervals in the segment overwhelmingly support the call state, the probability of; deviations from the cal",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/postprocess/segment_quality_utils.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/postprocess/segment_quality_utils.py
Testability,log,log,"""""""Calculates quality metrics for hidden state segments for a given HMM. Note:; The initializer requires the emission and transition probabilities, as well as the forward; and backward tables and the log posterior probability.; """"""; """"""Initializer. Args:; log_emission_tc: log copy-number emission matrix; log_trans_tcc: log copy-number transition tensor; alpha_tc: forward log likelihood matrix (from forward-backward algorithm); beta_tc: backward log likelihood matrix (from forward-backward algorithm); log_posterior_prob_tc: log copy-number posterior matrix (from forward-backward algorithm); log_data_likelihood: log data likelihood (from forward-backward algorithm); """"""; """"""Returns a pytensor function that calculates the log posterior probability of hidden state paths composed; from a subset X of all hidden states S. More explicitly, this function calculates the logp of all paths constrained to the hidden-state set; X for t_0 <= t <= t_N but unconstrained for before (t < t_0) and after (t > t_N):. unconstrained constrained unconstrained; t < t_0 | t_0 t_1 ... t_N | t > t_N; c in S | c in X c in X c in X | c in S. The inputs for the returned pytensor function are as follows:. alpha_first_c: forward log likelihood (alpha) for t = t_0 and c in X; beta_last_c: backward log likelihood (beta) for t = t_N and c in X; log_emission_tc: log emission probabilities for t \in [t_0, ..., t_N] and c in X; log_trans_tcc: log transition probabilities from `t` to `t+1` for t in [t_0, ..., t_N]; and departure and destination states in X; log_data_likelihood: log data likelihood of the unconstrained problem. The output is a non-positive scalar value that signifies the desired probability in log space. Examples:. If X = S (all hidden states), we expect logp = 0 (up to round-off error). if X = {a single hidden state}, then we expect the logp of a single path that takes on the same; hidden-state for all positions [t_0, ..., t_N]. In general, if X is a proper subset of S, we expect logp <= 0 ",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/postprocess/segment_quality_utils.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/postprocess/segment_quality_utils.py
Testability,test,tests,"#for GATK PythonUnitTestRunner/Java tests; # for running in IntelliJ/Python tests; # test_sub_dir = current_dir + ""/../../../../../../../../src/test/resources/org/broadinstitute/hellbender/tools/copynumber/gcnv-postprocess/""; #to match the number of VCs in the clustering VCF; #should be the same, but numerical precision; # any test VCF that doesn't have SAMPLE_000",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/postprocess/test_viterbiSegmentationEngine.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/postprocess/test_viterbiSegmentationEngine.py
Modifiability,config,configs,"generator; """"""Performs Viterbi segmentation and segment quality calculation for a single sample in; the call-set and returns a generator for segments. Returns:; a generator for segments; """"""; # load copy number log emission for the sample; # iterate over contigs and perform segmentation; # copy-number prior probabilities for each class; # contig interval list and indices; # mapping from intervals to contig index (since we have a single contig, all intervals map to index=0); # copy-number class log probability; # copy-number log emission probability for contig intervals; # get HMM specs; # run forward-back algorithm; # initialize the segment quality calculator; # validate args -- should be both none or neither none; # run viterbi algorithm; # coalesce into piecewise constant copy-number segments; # use events from clustered_vcf; # calculate qualities; # for single-interval segments, all qualities must be the same; """"""Performs Viterbi segmentation and segment quality calculation for a single sample in; the call-set and saves the results to disk. """"""; # write configs, gcnvkernel version and sample name to output path; # copy SAM header lines from model/calls interval list; # add sample name header; # add table column headers; # add segments; # assert interval lists are identical; # assert gcnvkernel versions are identical; # assert denoising configs are identical; # assert callings configs are identical; # extract and store sample names for the current shard; # all scattered calls have the same set of samples and in the same order; # all samples have ploidy calls in the metadata collection; """"""Coalesces a sequence of objects into piecewise constant segments, along with start and end indices; for each constant segment. Example:; seq = ['a', 'a', 'a', 'a', 'b', 'c', 'c', 'a', 'a', 'a']; result = [('a', 0, 3), ('b', 4, 4), ('c', 5, 6), ('a', 7, 9)]. Args:; seq: a sequence of objects that implement __equals__. Returns:; a generator for (object, start_index, end_index); """"""",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/postprocess/viterbi_segmentation.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/postprocess/viterbi_segmentation.py
Performance,load,load," number calls for all intervals; clustered_vcf: file with clustered breakpoints and calls for each sample; """"""; # assemble scattered global entities (interval list, log_q_tau_tk); # extract SAM header lines from one of the interval lists; # sample names; # interval list metadata; # cnv stay probability for each contig; # forward-backward algorithm; # viterbi algorithm; # copy-number HMM specs generator; """"""Performs Viterbi segmentation and segment quality calculation for a single sample in; the call-set and returns a generator for segments. Returns:; a generator for segments; """"""; # load copy number log emission for the sample; # iterate over contigs and perform segmentation; # copy-number prior probabilities for each class; # contig interval list and indices; # mapping from intervals to contig index (since we have a single contig, all intervals map to index=0); # copy-number class log probability; # copy-number log emission probability for contig intervals; # get HMM specs; # run forward-back algorithm; # initialize the segment quality calculator; # validate args -- should be both none or neither none; # run viterbi algorithm; # coalesce into piecewise constant copy-number segments; # use events from clustered_vcf; # calculate qualities; # for single-interval segments, all qualities must be the same; """"""Performs Viterbi segmentation and segment quality calculation for a single sample in; the call-set and saves the results to disk. """"""; # write configs, gcnvkernel version and sample name to output path; # copy SAM header lines from model/calls interval list; # add sample name header; # add table column headers; # add segments; # assert interval lists are identical; # assert gcnvkernel versions are identical; # assert denoising configs are identical; # assert callings configs are identical; # extract and store sample names for the current shard; # all scattered calls have the same set of samples and in the same order; # all samples have ploidy calls in the metadata co",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/postprocess/viterbi_segmentation.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/postprocess/viterbi_segmentation.py
Security,validat,validate," number calls for all intervals; clustered_vcf: file with clustered breakpoints and calls for each sample; """"""; # assemble scattered global entities (interval list, log_q_tau_tk); # extract SAM header lines from one of the interval lists; # sample names; # interval list metadata; # cnv stay probability for each contig; # forward-backward algorithm; # viterbi algorithm; # copy-number HMM specs generator; """"""Performs Viterbi segmentation and segment quality calculation for a single sample in; the call-set and returns a generator for segments. Returns:; a generator for segments; """"""; # load copy number log emission for the sample; # iterate over contigs and perform segmentation; # copy-number prior probabilities for each class; # contig interval list and indices; # mapping from intervals to contig index (since we have a single contig, all intervals map to index=0); # copy-number class log probability; # copy-number log emission probability for contig intervals; # get HMM specs; # run forward-back algorithm; # initialize the segment quality calculator; # validate args -- should be both none or neither none; # run viterbi algorithm; # coalesce into piecewise constant copy-number segments; # use events from clustered_vcf; # calculate qualities; # for single-interval segments, all qualities must be the same; """"""Performs Viterbi segmentation and segment quality calculation for a single sample in; the call-set and saves the results to disk. """"""; # write configs, gcnvkernel version and sample name to output path; # copy SAM header lines from model/calls interval list; # add sample name header; # add table column headers; # add segments; # assert interval lists are identical; # assert gcnvkernel versions are identical; # assert denoising configs are identical; # assert callings configs are identical; # extract and store sample names for the current shard; # all scattered calls have the same set of samples and in the same order; # all samples have ploidy calls in the metadata co",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/postprocess/viterbi_segmentation.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/postprocess/viterbi_segmentation.py
Testability,log,log," number calls for all intervals; clustered_vcf: file with clustered breakpoints and calls for each sample; """"""; # assemble scattered global entities (interval list, log_q_tau_tk); # extract SAM header lines from one of the interval lists; # sample names; # interval list metadata; # cnv stay probability for each contig; # forward-backward algorithm; # viterbi algorithm; # copy-number HMM specs generator; """"""Performs Viterbi segmentation and segment quality calculation for a single sample in; the call-set and returns a generator for segments. Returns:; a generator for segments; """"""; # load copy number log emission for the sample; # iterate over contigs and perform segmentation; # copy-number prior probabilities for each class; # contig interval list and indices; # mapping from intervals to contig index (since we have a single contig, all intervals map to index=0); # copy-number class log probability; # copy-number log emission probability for contig intervals; # get HMM specs; # run forward-back algorithm; # initialize the segment quality calculator; # validate args -- should be both none or neither none; # run viterbi algorithm; # coalesce into piecewise constant copy-number segments; # use events from clustered_vcf; # calculate qualities; # for single-interval segments, all qualities must be the same; """"""Performs Viterbi segmentation and segment quality calculation for a single sample in; the call-set and saves the results to disk. """"""; # write configs, gcnvkernel version and sample name to output path; # copy SAM header lines from model/calls interval list; # add sample name header; # add table column headers; # add segments; # assert interval lists are identical; # assert gcnvkernel versions are identical; # assert denoising configs are identical; # assert callings configs are identical; # extract and store sample names for the current shard; # all scattered calls have the same set of samples and in the same order; # all samples have ploidy calls in the metadata co",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/postprocess/viterbi_segmentation.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/postprocess/viterbi_segmentation.py
Availability,mask,masks,"""""""This class implements different filters (""masks"") on interval lists.""""""; """"""Applies the mask on a given interval list and read count array. Args:; n_st: a read count matrix. Returns:; a view of the provided n_st,; a new list containing references to the provided interval list; """"""; """"""Only keep intervals in the given contig and mask the rest. Args:; contigs_to_keep: set of contigs to keep. Returns:; None; """"""; """"""Mask any interval that overlaps with a list of blacklisted intervals. Args:; blacklisted_intervals: list of blacklisted intervals. Returns:; None; """"""; """"""Mask any interval that has zero coverage for all samples in a given read count matrix. Args:; n_st: read count matrix. Returns:; None; """"""",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/preprocess/interval_list_mask.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/preprocess/interval_list_mask.py
Security,hash,hashing,"""""""This class represents a genomic interval along with optional annotations. Note:; Equality test and hashing is based on get_key() which excludes all annotations.; """"""; """"""Base class for all interval annotations.""""""; """"""Takes a raw value (e.g. a value that is directly read from a .tsv file) and casts it to; the correct type.""""""; """"""Returns a string identifier key for the annotation. The key is used for reading the annotation from; and writing the annotation to a .tsv file.""""""; """"""This class represents GC content annotation for an interval.""""""",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/structs/interval.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/structs/interval.py
Testability,test,test,"""""""This class represents a genomic interval along with optional annotations. Note:; Equality test and hashing is based on get_key() which excludes all annotations.; """"""; """"""Base class for all interval annotations.""""""; """"""Takes a raw value (e.g. a value that is directly read from a .tsv file) and casts it to; the correct type.""""""; """"""Returns a string identifier key for the annotation. The key is used for reading the annotation from; and writing the annotation to a .tsv file.""""""; """"""This class represents GC content annotation for an interval.""""""",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/structs/interval.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/structs/interval.py
Availability,toler,tolerance,"he continuous sector. (2) a ""sampler"" that provides samples from the cross term, which we call ""log emission"",; defined as:. log_emission(DRVs) = E_{CRVs ~ q(CRVs)} [-F_cd (CRVs, DRV, observed)]. (3) a ""caller"" that updates q(DRVs) given log_emission(DRV), i.e.:. q(DRVs) \propto \exp[log_emission(DRVs) - F_d(DRVs, observed)]. In practice, one does not need the complete joint posterior of DRVs: only sufficient; statistics, to the extent required for calculating F_c^{eff} is needed. Calculating such; sufficient statistics could be as simple as using the Bayes rule, or more complicated if; the DRVs are strongly correlated. The general implementation motif is:. (a) to store sufficient statistics from q(DRVs) as a shared pytensor tensor such that the the; model can access it,; (b) to store log_emission(DRVs) as a shared pytensor tensor (or ndarray) such that the caller; can access it, and:; (c) let the caller directly update the shared sufficient statistics.; """"""; # if the temperature is within the following tolerance of 1.0, it is assumed that annealing; # has finished; """"""Initializer. Args:; hybrid_inference_params: inference configuration; continuous_model: a PyMC model representing the continuous sector of the PGM; sampler: log emission probability sampler; caller: discrete RV posterior updater; **kwargs: extra keywords. Keyword Args:; custom_optimizer: a custom stochastic optimizer to be used in place of the default optimizer (adamax; elbo_normalization_factor: normalization factor of the full model ELBO (for logging); advi_task_name: name of the ADVI step (for logging); sampling_task_name: name of the sampling step (for logging); calling_task_name: name of the calling step (for logging); """"""; # no annealing; # linear annealing; # reset ADVI convergence tracker so that ADVI is run again; # suppress signal if deemed premature; # clear out log emission; # draw new log emission posterior samples; # update the estimator; # relative update (and ensuring no NaNs are presen",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/tasks/inference_task_base.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/tasks/inference_task_base.py
Deployability,update,update,"""""""Exception raised in case inference optimizer produces a NaN. """"""; """"""Base class for log emission posterior probability samplers to be used in the hybrid ADVI scheme.""""""; """"""Take a new mean-field approximation and update the sampler routine accordingly. Args:; approx: an instance of PyMC mean-field posterior approximation. Returns:; None; """"""; """"""Draw one sample (or average of several samples) from log emission posterior probability.""""""; """"""Reset the internal state of the sampler (e.g. previously accumulated samples).""""""; """"""Add an incremental update to the current estimate of the log emission posterior mean.""""""; """"""Returns the latest estimate of the log emission posterior mean.""""""; """"""Base class for callers, i.e. routines that update the posterior of discrete RVs, to be used in the; hybrid ADVI scheme.""""""; """"""Takes a snapshot of the variables that change by `call` method. Taking a snapshot is useful if; several calls are necessary to achieve convergence among discrete variables themselves.; `finalize` may then admix the snapshot with the converged result.""""""; """"""Update the posterior of discrete RVs and return a summary""""""; """"""This method is called after exiting the call internal loop and before `update_auxiliary_vars` for; finalizing the posteriors (e.g. admixing with the snapshot).""""""; """"""Update auxiliary variables in workspaces, if any. This routine is called after one; (or more) round(s) of invoking `Caller.call`.""""""; """"""Represents a summary of updates made to discrete RV posteriors by a `Caller`.""""""; """"""A function that reduces arrays to scalars. It is used to summarize tensor-valued updates.""""""; """"""Represents the caller update summary in a human readable format (used in logging).""""""; """"""Output stream for `tqdm` which will output to logger module instead of `stderr`.""""""; """"""Base class of all inference tasks.""""""; # Lay in a course for starbase one two warp nine point five...; """"""Initiate inference algorithm.""""""; """"""Wrap up the inference algorithm (clean up works",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/tasks/inference_task_base.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/tasks/inference_task_base.py
Energy Efficiency,reduce,reduces,"pdate to the current estimate of the log emission posterior mean.""""""; """"""Returns the latest estimate of the log emission posterior mean.""""""; """"""Base class for callers, i.e. routines that update the posterior of discrete RVs, to be used in the; hybrid ADVI scheme.""""""; """"""Takes a snapshot of the variables that change by `call` method. Taking a snapshot is useful if; several calls are necessary to achieve convergence among discrete variables themselves.; `finalize` may then admix the snapshot with the converged result.""""""; """"""Update the posterior of discrete RVs and return a summary""""""; """"""This method is called after exiting the call internal loop and before `update_auxiliary_vars` for; finalizing the posteriors (e.g. admixing with the snapshot).""""""; """"""Update auxiliary variables in workspaces, if any. This routine is called after one; (or more) round(s) of invoking `Caller.call`.""""""; """"""Represents a summary of updates made to discrete RV posteriors by a `Caller`.""""""; """"""A function that reduces arrays to scalars. It is used to summarize tensor-valued updates.""""""; """"""Represents the caller update summary in a human readable format (used in logging).""""""; """"""Output stream for `tqdm` which will output to logger module instead of `stderr`.""""""; """"""Base class of all inference tasks.""""""; # Lay in a course for starbase one two warp nine point five...; """"""Initiate inference algorithm.""""""; """"""Wrap up the inference algorithm (clean up workspaces, etc.)""""""; """"""The hybrid inference framework is applicable to PGMs with the following general structure:. +--------------+ +----------------+; | discrete RVs + --------> + continuous RVs |; +--------------+ +----------------+. Note that discrete RVs do not have any continuous parents. The inference is approximately; performed by factorizing the true posterior into an uncorrelated product of discrete RVs (DRVs); and continuous RVs (CRVs):. p(CRVs, DRVs | observed) ~ q(CRVs) q(DRVs). q(CRVs) is updated via deterministic annealing mean-field A",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/tasks/inference_task_base.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/tasks/inference_task_base.py
Integrability,rout,routine,"""""""Exception raised in case inference optimizer produces a NaN. """"""; """"""Base class for log emission posterior probability samplers to be used in the hybrid ADVI scheme.""""""; """"""Take a new mean-field approximation and update the sampler routine accordingly. Args:; approx: an instance of PyMC mean-field posterior approximation. Returns:; None; """"""; """"""Draw one sample (or average of several samples) from log emission posterior probability.""""""; """"""Reset the internal state of the sampler (e.g. previously accumulated samples).""""""; """"""Add an incremental update to the current estimate of the log emission posterior mean.""""""; """"""Returns the latest estimate of the log emission posterior mean.""""""; """"""Base class for callers, i.e. routines that update the posterior of discrete RVs, to be used in the; hybrid ADVI scheme.""""""; """"""Takes a snapshot of the variables that change by `call` method. Taking a snapshot is useful if; several calls are necessary to achieve convergence among discrete variables themselves.; `finalize` may then admix the snapshot with the converged result.""""""; """"""Update the posterior of discrete RVs and return a summary""""""; """"""This method is called after exiting the call internal loop and before `update_auxiliary_vars` for; finalizing the posteriors (e.g. admixing with the snapshot).""""""; """"""Update auxiliary variables in workspaces, if any. This routine is called after one; (or more) round(s) of invoking `Caller.call`.""""""; """"""Represents a summary of updates made to discrete RV posteriors by a `Caller`.""""""; """"""A function that reduces arrays to scalars. It is used to summarize tensor-valued updates.""""""; """"""Represents the caller update summary in a human readable format (used in logging).""""""; """"""Output stream for `tqdm` which will output to logger module instead of `stderr`.""""""; """"""Base class of all inference tasks.""""""; # Lay in a course for starbase one two warp nine point five...; """"""Initiate inference algorithm.""""""; """"""Wrap up the inference algorithm (clean up works",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/tasks/inference_task_base.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/tasks/inference_task_base.py
Modifiability,variab,variables,"""""""Exception raised in case inference optimizer produces a NaN. """"""; """"""Base class for log emission posterior probability samplers to be used in the hybrid ADVI scheme.""""""; """"""Take a new mean-field approximation and update the sampler routine accordingly. Args:; approx: an instance of PyMC mean-field posterior approximation. Returns:; None; """"""; """"""Draw one sample (or average of several samples) from log emission posterior probability.""""""; """"""Reset the internal state of the sampler (e.g. previously accumulated samples).""""""; """"""Add an incremental update to the current estimate of the log emission posterior mean.""""""; """"""Returns the latest estimate of the log emission posterior mean.""""""; """"""Base class for callers, i.e. routines that update the posterior of discrete RVs, to be used in the; hybrid ADVI scheme.""""""; """"""Takes a snapshot of the variables that change by `call` method. Taking a snapshot is useful if; several calls are necessary to achieve convergence among discrete variables themselves.; `finalize` may then admix the snapshot with the converged result.""""""; """"""Update the posterior of discrete RVs and return a summary""""""; """"""This method is called after exiting the call internal loop and before `update_auxiliary_vars` for; finalizing the posteriors (e.g. admixing with the snapshot).""""""; """"""Update auxiliary variables in workspaces, if any. This routine is called after one; (or more) round(s) of invoking `Caller.call`.""""""; """"""Represents a summary of updates made to discrete RV posteriors by a `Caller`.""""""; """"""A function that reduces arrays to scalars. It is used to summarize tensor-valued updates.""""""; """"""Represents the caller update summary in a human readable format (used in logging).""""""; """"""Output stream for `tqdm` which will output to logger module instead of `stderr`.""""""; """"""Base class of all inference tasks.""""""; # Lay in a course for starbase one two warp nine point five...; """"""Initiate inference algorithm.""""""; """"""Wrap up the inference algorithm (clean up works",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/tasks/inference_task_base.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/tasks/inference_task_base.py
Performance,optimiz,optimizer,"""""""Exception raised in case inference optimizer produces a NaN. """"""; """"""Base class for log emission posterior probability samplers to be used in the hybrid ADVI scheme.""""""; """"""Take a new mean-field approximation and update the sampler routine accordingly. Args:; approx: an instance of PyMC mean-field posterior approximation. Returns:; None; """"""; """"""Draw one sample (or average of several samples) from log emission posterior probability.""""""; """"""Reset the internal state of the sampler (e.g. previously accumulated samples).""""""; """"""Add an incremental update to the current estimate of the log emission posterior mean.""""""; """"""Returns the latest estimate of the log emission posterior mean.""""""; """"""Base class for callers, i.e. routines that update the posterior of discrete RVs, to be used in the; hybrid ADVI scheme.""""""; """"""Takes a snapshot of the variables that change by `call` method. Taking a snapshot is useful if; several calls are necessary to achieve convergence among discrete variables themselves.; `finalize` may then admix the snapshot with the converged result.""""""; """"""Update the posterior of discrete RVs and return a summary""""""; """"""This method is called after exiting the call internal loop and before `update_auxiliary_vars` for; finalizing the posteriors (e.g. admixing with the snapshot).""""""; """"""Update auxiliary variables in workspaces, if any. This routine is called after one; (or more) round(s) of invoking `Caller.call`.""""""; """"""Represents a summary of updates made to discrete RV posteriors by a `Caller`.""""""; """"""A function that reduces arrays to scalars. It is used to summarize tensor-valued updates.""""""; """"""Represents the caller update summary in a human readable format (used in logging).""""""; """"""Output stream for `tqdm` which will output to logger module instead of `stderr`.""""""; """"""Base class of all inference tasks.""""""; # Lay in a course for starbase one two warp nine point five...; """"""Initiate inference algorithm.""""""; """"""Wrap up the inference algorithm (clean up works",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/tasks/inference_task_base.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/tasks/inference_task_base.py
Security,access,access,"Vs)} [F_cd(CRVs, DRVs, observed)]; + E_{DRVs ~ q(DRVs)} [F_d(DRVs, observed)]. Note: the last term is fully determined by q(DRVs) and can be dropped while performing; ADVI updates in the continuous sector. (2) a ""sampler"" that provides samples from the cross term, which we call ""log emission"",; defined as:. log_emission(DRVs) = E_{CRVs ~ q(CRVs)} [-F_cd (CRVs, DRV, observed)]. (3) a ""caller"" that updates q(DRVs) given log_emission(DRV), i.e.:. q(DRVs) \propto \exp[log_emission(DRVs) - F_d(DRVs, observed)]. In practice, one does not need the complete joint posterior of DRVs: only sufficient; statistics, to the extent required for calculating F_c^{eff} is needed. Calculating such; sufficient statistics could be as simple as using the Bayes rule, or more complicated if; the DRVs are strongly correlated. The general implementation motif is:. (a) to store sufficient statistics from q(DRVs) as a shared pytensor tensor such that the the; model can access it,; (b) to store log_emission(DRVs) as a shared pytensor tensor (or ndarray) such that the caller; can access it, and:; (c) let the caller directly update the shared sufficient statistics.; """"""; # if the temperature is within the following tolerance of 1.0, it is assumed that annealing; # has finished; """"""Initializer. Args:; hybrid_inference_params: inference configuration; continuous_model: a PyMC model representing the continuous sector of the PGM; sampler: log emission probability sampler; caller: discrete RV posterior updater; **kwargs: extra keywords. Keyword Args:; custom_optimizer: a custom stochastic optimizer to be used in place of the default optimizer (adamax; elbo_normalization_factor: normalization factor of the full model ELBO (for logging); advi_task_name: name of the ADVI step (for logging); sampling_task_name: name of the sampling step (for logging); calling_task_name: name of the calling step (for logging); """"""; # no annealing; # linear annealing; # reset ADVI convergence tracker so that ADVI is run agai",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/tasks/inference_task_base.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/tasks/inference_task_base.py
Testability,log,log,"""""""Exception raised in case inference optimizer produces a NaN. """"""; """"""Base class for log emission posterior probability samplers to be used in the hybrid ADVI scheme.""""""; """"""Take a new mean-field approximation and update the sampler routine accordingly. Args:; approx: an instance of PyMC mean-field posterior approximation. Returns:; None; """"""; """"""Draw one sample (or average of several samples) from log emission posterior probability.""""""; """"""Reset the internal state of the sampler (e.g. previously accumulated samples).""""""; """"""Add an incremental update to the current estimate of the log emission posterior mean.""""""; """"""Returns the latest estimate of the log emission posterior mean.""""""; """"""Base class for callers, i.e. routines that update the posterior of discrete RVs, to be used in the; hybrid ADVI scheme.""""""; """"""Takes a snapshot of the variables that change by `call` method. Taking a snapshot is useful if; several calls are necessary to achieve convergence among discrete variables themselves.; `finalize` may then admix the snapshot with the converged result.""""""; """"""Update the posterior of discrete RVs and return a summary""""""; """"""This method is called after exiting the call internal loop and before `update_auxiliary_vars` for; finalizing the posteriors (e.g. admixing with the snapshot).""""""; """"""Update auxiliary variables in workspaces, if any. This routine is called after one; (or more) round(s) of invoking `Caller.call`.""""""; """"""Represents a summary of updates made to discrete RV posteriors by a `Caller`.""""""; """"""A function that reduces arrays to scalars. It is used to summarize tensor-valued updates.""""""; """"""Represents the caller update summary in a human readable format (used in logging).""""""; """"""Output stream for `tqdm` which will output to logger module instead of `stderr`.""""""; """"""Base class of all inference tasks.""""""; # Lay in a course for starbase one two warp nine point five...; """"""Initiate inference algorithm.""""""; """"""Wrap up the inference algorithm (clean up works",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/tasks/inference_task_base.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/tasks/inference_task_base.py
Usability,simpl,simple,"inuous sectors. The user must supply the following components:. (1) a pm.Model that yields the DRV-posterior-expectation of the free energy,. F_c^{eff}(CRVs, observed) = E_{DRVs ~ q(DRVs)} [-log_P(CRVs, DRVs, observed)]; = F_c(CRVs, observed); + E_{DRVs ~ q(DRVs)} [F_cd(CRVs, DRVs, observed)]; + E_{DRVs ~ q(DRVs)} [F_d(DRVs, observed)]. Note: the last term is fully determined by q(DRVs) and can be dropped while performing; ADVI updates in the continuous sector. (2) a ""sampler"" that provides samples from the cross term, which we call ""log emission"",; defined as:. log_emission(DRVs) = E_{CRVs ~ q(CRVs)} [-F_cd (CRVs, DRV, observed)]. (3) a ""caller"" that updates q(DRVs) given log_emission(DRV), i.e.:. q(DRVs) \propto \exp[log_emission(DRVs) - F_d(DRVs, observed)]. In practice, one does not need the complete joint posterior of DRVs: only sufficient; statistics, to the extent required for calculating F_c^{eff} is needed. Calculating such; sufficient statistics could be as simple as using the Bayes rule, or more complicated if; the DRVs are strongly correlated. The general implementation motif is:. (a) to store sufficient statistics from q(DRVs) as a shared pytensor tensor such that the the; model can access it,; (b) to store log_emission(DRVs) as a shared pytensor tensor (or ndarray) such that the caller; can access it, and:; (c) let the caller directly update the shared sufficient statistics.; """"""; # if the temperature is within the following tolerance of 1.0, it is assumed that annealing; # has finished; """"""Initializer. Args:; hybrid_inference_params: inference configuration; continuous_model: a PyMC model representing the continuous sector of the PGM; sampler: log emission probability sampler; caller: discrete RV posterior updater; **kwargs: extra keywords. Keyword Args:; custom_optimizer: a custom stochastic optimizer to be used in place of the default optimizer (adamax; elbo_normalization_factor: normalization factor of the full model ELBO (for logging); advi_task_n",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/tasks/inference_task_base.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/tasks/inference_task_base.py
Deployability,update,updates,"""""""This class is a wrapper around `HHMMClassAndCopyNumberBasicCaller` to be used in a case denoising and; calling task. Note:; Update of copy number class is disabled since it is considered a global part of the model and is; set by the imported model.; """"""; # admix q_c_stc with the snapshot; # the copy number emission sampler is the same as the cohort task; # the optimizer is a custom adamax that only updates sample-specific model variables",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/tasks/task_case_denoising_calling.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/tasks/task_case_denoising_calling.py
Integrability,wrap,wrapper,"""""""This class is a wrapper around `HHMMClassAndCopyNumberBasicCaller` to be used in a case denoising and; calling task. Note:; Update of copy number class is disabled since it is considered a global part of the model and is; set by the imported model.; """"""; # admix q_c_stc with the snapshot; # the copy number emission sampler is the same as the cohort task; # the optimizer is a custom adamax that only updates sample-specific model variables",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/tasks/task_case_denoising_calling.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/tasks/task_case_denoising_calling.py
Modifiability,variab,variables,"""""""This class is a wrapper around `HHMMClassAndCopyNumberBasicCaller` to be used in a case denoising and; calling task. Note:; Update of copy number class is disabled since it is considered a global part of the model and is; set by the imported model.; """"""; # admix q_c_stc with the snapshot; # the copy number emission sampler is the same as the cohort task; # the optimizer is a custom adamax that only updates sample-specific model variables",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/tasks/task_case_denoising_calling.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/tasks/task_case_denoising_calling.py
Performance,optimiz,optimizer,"""""""This class is a wrapper around `HHMMClassAndCopyNumberBasicCaller` to be used in a case denoising and; calling task. Note:; Update of copy number class is disabled since it is considered a global part of the model and is; set by the imported model.; """"""; # admix q_c_stc with the snapshot; # the copy number emission sampler is the same as the cohort task; # the optimizer is a custom adamax that only updates sample-specific model variables",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/tasks/task_case_denoising_calling.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/tasks/task_case_denoising_calling.py
Deployability,update,updates,"""""""Case sample ploidy inference task.""""""; # the caller and sampler are the same as the cohort tool; # the optimizer is a custom adamax that only updates sample-specific model variables",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/tasks/task_case_ploidy_determination.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/tasks/task_case_ploidy_determination.py
Modifiability,variab,variables,"""""""Case sample ploidy inference task.""""""; # the caller and sampler are the same as the cohort tool; # the optimizer is a custom adamax that only updates sample-specific model variables",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/tasks/task_case_ploidy_determination.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/tasks/task_case_ploidy_determination.py
Performance,optimiz,optimizer,"""""""Case sample ploidy inference task.""""""; # the caller and sampler are the same as the cohort tool; # the optimizer is a custom adamax that only updates sample-specific model variables",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/tasks/task_case_ploidy_determination.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/tasks/task_case_ploidy_determination.py
Deployability,update,update,"""""""This class is a wrapper around `HHMMClassAndCopyNumberBasicCaller` to be used in a cohort denoising and; calling task.""""""; # admix q_c_stc with the snapshot; # admix q_tau_tk with the snapshot; """"""Copy number and interval class posterior update summary. All vector-, matrix-, and tensor- valued; updates are reduced to scalar with a single reducer function.""""""; """"""Returns the largest of interval class update and copy number update. This scalar value; is used for checking convergence (i.e. self-consistency between class and copy number posteriors).""""""; """"""This class is a wrapper around `CopyNumberEmissionBasicSampler` to be used in a `HybridInferenceTask`.""""""; """"""Cohort denoising and calling warm-up task (no sampling/calling -- just DA-ADVI).""""""; """"""Cohort denoising and calling inference task (w/ sampling and calling).""""""; # initialize hybrid ADVI; # temperature; # mean-field parameters; # optimizer state",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/tasks/task_cohort_denoising_calling.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/tasks/task_cohort_denoising_calling.py
Energy Efficiency,reduce,reduced,"""""""This class is a wrapper around `HHMMClassAndCopyNumberBasicCaller` to be used in a cohort denoising and; calling task.""""""; # admix q_c_stc with the snapshot; # admix q_tau_tk with the snapshot; """"""Copy number and interval class posterior update summary. All vector-, matrix-, and tensor- valued; updates are reduced to scalar with a single reducer function.""""""; """"""Returns the largest of interval class update and copy number update. This scalar value; is used for checking convergence (i.e. self-consistency between class and copy number posteriors).""""""; """"""This class is a wrapper around `CopyNumberEmissionBasicSampler` to be used in a `HybridInferenceTask`.""""""; """"""Cohort denoising and calling warm-up task (no sampling/calling -- just DA-ADVI).""""""; """"""Cohort denoising and calling inference task (w/ sampling and calling).""""""; # initialize hybrid ADVI; # temperature; # mean-field parameters; # optimizer state",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/tasks/task_cohort_denoising_calling.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/tasks/task_cohort_denoising_calling.py
Integrability,wrap,wrapper,"""""""This class is a wrapper around `HHMMClassAndCopyNumberBasicCaller` to be used in a cohort denoising and; calling task.""""""; # admix q_c_stc with the snapshot; # admix q_tau_tk with the snapshot; """"""Copy number and interval class posterior update summary. All vector-, matrix-, and tensor- valued; updates are reduced to scalar with a single reducer function.""""""; """"""Returns the largest of interval class update and copy number update. This scalar value; is used for checking convergence (i.e. self-consistency between class and copy number posteriors).""""""; """"""This class is a wrapper around `CopyNumberEmissionBasicSampler` to be used in a `HybridInferenceTask`.""""""; """"""Cohort denoising and calling warm-up task (no sampling/calling -- just DA-ADVI).""""""; """"""Cohort denoising and calling inference task (w/ sampling and calling).""""""; # initialize hybrid ADVI; # temperature; # mean-field parameters; # optimizer state",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/tasks/task_cohort_denoising_calling.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/tasks/task_cohort_denoising_calling.py
Performance,optimiz,optimizer,"""""""This class is a wrapper around `HHMMClassAndCopyNumberBasicCaller` to be used in a cohort denoising and; calling task.""""""; # admix q_c_stc with the snapshot; # admix q_tau_tk with the snapshot; """"""Copy number and interval class posterior update summary. All vector-, matrix-, and tensor- valued; updates are reduced to scalar with a single reducer function.""""""; """"""Returns the largest of interval class update and copy number update. This scalar value; is used for checking convergence (i.e. self-consistency between class and copy number posteriors).""""""; """"""This class is a wrapper around `CopyNumberEmissionBasicSampler` to be used in a `HybridInferenceTask`.""""""; """"""Cohort denoising and calling warm-up task (no sampling/calling -- just DA-ADVI).""""""; """"""Cohort denoising and calling inference task (w/ sampling and calling).""""""; # initialize hybrid ADVI; # temperature; # mean-field parameters; # optimizer state",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/tasks/task_cohort_denoising_calling.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/tasks/task_cohort_denoising_calling.py
Integrability,wrap,wrapper,"""""""This class is a wrapper around `PloidyBasicCaller` to be used in a `HybridInferenceTask`.""""""; """"""Snapshot is not necessary since there is no internal consistency loop.""""""; """"""Finalizing is not necessary since there is no internal consistency loop.""""""; """"""This class is a wrapper around `PloidyEmissionBasicSampler` to be used in a `HybridInferenceTask`.""""""; """"""Cohort germline contig ploidy determination task.""""""",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/tasks/task_cohort_ploidy_determination.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/tasks/task_cohort_ploidy_determination.py
Testability,log,logging-related,"""""""Argument parser help formatter for gcnvkernel CLI scripts.""""""; """"""Adds logging-related arguments to a given `ArgumentParser`.""""""; """"""Configures python logger according to parsed arguments.""""""",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/utils/cli_commons.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/utils/cli_commons.py
Availability,error,error,"# 10 / ln(10); # ln(1/2); # maximum possible phred-scaled value; """"""Converts probabilities from natural log scale to phred scale. Args:; logp: a probability in the natural log scale; complement: if True, returns the result for the complement of 'logp'. Returns:; phred-scaled probability; """"""; """"""Calculates the complement of a probability in the natural log scale:. log(1 - exp(logp)),. in a numerically stable fashion. Args:; logp: a probability in the natural log scale. Returns:; complement of the the probability in the natural log scale; """"""; """"""Calculates the following expression in a numerically stable fashion:. log(1 - (1 - exp(a_0)) x (1 - exp(a_1)) x ...). where a_i are the entries of `a` and assumed to be non-positive. The algorithm is as follows:. We define:. exp(x_n) = 1 - \prod_{i=0}^n (1 - exp(a_n)),. Thus, we have x_0 = a_0 and the recursion relation:. exp(x_{n+1}) = exp(x_n) + exp(b_{n+1}),. where. b_{n+1} = a_{n+1} + log(1 - exp(x_n)). We sort `a` in the descending order and update `x` term by term. It is easy to show that x_{n} is monotonically; increasing and that |x_{N} - x_{n}| < (N - n) |x_{n} - x_{n-1}|. We use the last inequality to bound the error; for early stopping. Args:; a: a float array; rel_tol: relative error tolerance for early stopping of calculation. Returns:; a float scalar; """"""; # enforce all entries of a to be negative or zero; """"""; Implements Welford’s method for computing variance online using samples from a generator. Note: it's assumed that the generator eventually runs out of samples and throws StopIteration exception. Args:; values_generator: a generator of values. Returns:; (mean, variance) tuple; """"""",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/utils/math.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/utils/math.py
Deployability,update,update,"# 10 / ln(10); # ln(1/2); # maximum possible phred-scaled value; """"""Converts probabilities from natural log scale to phred scale. Args:; logp: a probability in the natural log scale; complement: if True, returns the result for the complement of 'logp'. Returns:; phred-scaled probability; """"""; """"""Calculates the complement of a probability in the natural log scale:. log(1 - exp(logp)),. in a numerically stable fashion. Args:; logp: a probability in the natural log scale. Returns:; complement of the the probability in the natural log scale; """"""; """"""Calculates the following expression in a numerically stable fashion:. log(1 - (1 - exp(a_0)) x (1 - exp(a_1)) x ...). where a_i are the entries of `a` and assumed to be non-positive. The algorithm is as follows:. We define:. exp(x_n) = 1 - \prod_{i=0}^n (1 - exp(a_n)),. Thus, we have x_0 = a_0 and the recursion relation:. exp(x_{n+1}) = exp(x_n) + exp(b_{n+1}),. where. b_{n+1} = a_{n+1} + log(1 - exp(x_n)). We sort `a` in the descending order and update `x` term by term. It is easy to show that x_{n} is monotonically; increasing and that |x_{N} - x_{n}| < (N - n) |x_{n} - x_{n-1}|. We use the last inequality to bound the error; for early stopping. Args:; a: a float array; rel_tol: relative error tolerance for early stopping of calculation. Returns:; a float scalar; """"""; # enforce all entries of a to be negative or zero; """"""; Implements Welford’s method for computing variance online using samples from a generator. Note: it's assumed that the generator eventually runs out of samples and throws StopIteration exception. Args:; values_generator: a generator of values. Returns:; (mean, variance) tuple; """"""",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/utils/math.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/utils/math.py
Testability,log,log,"# 10 / ln(10); # ln(1/2); # maximum possible phred-scaled value; """"""Converts probabilities from natural log scale to phred scale. Args:; logp: a probability in the natural log scale; complement: if True, returns the result for the complement of 'logp'. Returns:; phred-scaled probability; """"""; """"""Calculates the complement of a probability in the natural log scale:. log(1 - exp(logp)),. in a numerically stable fashion. Args:; logp: a probability in the natural log scale. Returns:; complement of the the probability in the natural log scale; """"""; """"""Calculates the following expression in a numerically stable fashion:. log(1 - (1 - exp(a_0)) x (1 - exp(a_1)) x ...). where a_i are the entries of `a` and assumed to be non-positive. The algorithm is as follows:. We define:. exp(x_n) = 1 - \prod_{i=0}^n (1 - exp(a_n)),. Thus, we have x_0 = a_0 and the recursion relation:. exp(x_{n+1}) = exp(x_n) + exp(b_{n+1}),. where. b_{n+1} = a_{n+1} + log(1 - exp(x_n)). We sort `a` in the descending order and update `x` term by term. It is easy to show that x_{n} is monotonically; increasing and that |x_{N} - x_{n}| < (N - n) |x_{n} - x_{n-1}|. We use the last inequality to bound the error; for early stopping. Args:; a: a float array; rel_tol: relative error tolerance for early stopping of calculation. Returns:; a float scalar; """"""; # enforce all entries of a to be negative or zero; """"""; Implements Welford’s method for computing variance online using samples from a generator. Note: it's assumed that the generator eventually runs out of samples and throws StopIteration exception. Args:; values_generator: a generator of values. Returns:; (mean, variance) tuple; """"""",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/utils/math.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/utils/math.py
Availability,avail,available,"""""""This class performs maximum-likelihood linear regression for sequentially observed data; on an equally spaced grid. The data can be non-stationary, and a window size needs; to be provided that determined the forgetting factor. This is a non-recursive implementation of; the recursive least squares (RLS) algorithm.; """"""; """"""Convert averaging window length to forgetting factor.""""""; """"""Get the latest estimate of the linear regression slope. Returns:; float value of the slope if estimate is available; None if the estimate is not available yet; """"""; """"""Get the latest estimate of the linear regression intercept. Returns:; float value of the intercept if estimate is available; None if the estimate is not available yet; """"""; """"""Get the latest estimate of the linear regression variance. Returns:; float value of the variance if estimate is available; None if the estimate is not available yet; """"""",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/utils/rls.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/utils/rls.py
Performance,perform,performs,"""""""This class performs maximum-likelihood linear regression for sequentially observed data; on an equally spaced grid. The data can be non-stationary, and a window size needs; to be provided that determined the forgetting factor. This is a non-recursive implementation of; the recursive least squares (RLS) algorithm.; """"""; """"""Convert averaging window length to forgetting factor.""""""; """"""Get the latest estimate of the linear regression slope. Returns:; float value of the slope if estimate is available; None if the estimate is not available yet; """"""; """"""Get the latest estimate of the linear regression intercept. Returns:; float value of the intercept if estimate is available; None if the estimate is not available yet; """"""; """"""Get the latest estimate of the linear regression variance. Returns:; float value of the variance if estimate is available; None if the estimate is not available yet; """"""",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/gcnvkernel/utils/rls.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/gcnvkernel/utils/rls.py
Modifiability,extend,extends,"he indices of the insertions; # do not change as we modify the reference; # get sequence specific indel dict; # this read's bases will be present in the tensor,; # so do not add *'s for the insertions covered by this read; # add *'s for bases any deletions; # only add additional insertions from all reads if; # they are not in this reads insertions; # pad the sequence and quality scores for the window; # chop off the left side of the sequence if it is outside; # the window; # pad the left side if needed; # pad the internal bits where there are insertions in the pileup; # that are not present in this read; # this is probably not great, for longer reads we will prep a bunch; # a bunch of extra sequence; # skip beginning of the sequence (do not fill); # if this is the first base, indicate we have started; # the :4 indexing could change if the tensor channels change; # this matches vqsr_cnn/inference.py, the training.py had a more; # general/extensible approach, but following this for sake of matching; # the inference code; # filters HaplotypeCaller artificial haplotypes; # this is the index with respect to the tensor; """"""; Strategy for determining reference window used by gatk; """"""; """"""; Encodes a string as a tensor of a window centered; around a position. Args:; window:; Optional int. Determines with width of the tensor.; offset:; Optional int. When offset is 0, the variant POS; is located at middle. negative shifts it left; and positive shifts it right, with respect; to the output tensor.; base_encoder:; Optional Encoder. Encodes a base from the; string as an int representing the channel; in the output tensor.; handle_start:; Optional str or callable. Strategy for handling; the start of the tensor when the window extends; beyond the left side of the reference. Options:; * 'left': the first base of the reference is; the first base in the tensor; * 'pad': the reference's start is padded such; that the variant POS remains unchanged; with respect to the output tensor. """"""",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/scorevariants/encoders.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/scorevariants/encoders.py
Availability,down,down-sampler,"# Implementation of random number generator to get the same result as GATK CNNScoreVariants reservoir down-sampler; # Reservoir Downsampler: Selects n reads out of a stream whose size is not known in advance, with; # every read in the stream having an equal chance of being selected for inclusion.; # An implementation of ""Algorithm R"" from the paper ""Random Sampling with a Reservoir"" (Jeffrey Scott Vitter, 1985); # i.e., n is a power of 2",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/scorevariants/random_generator.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/scorevariants/random_generator.py
Energy Efficiency,power,power,"# Implementation of random number generator to get the same result as GATK CNNScoreVariants reservoir down-sampler; # Reservoir Downsampler: Selects n reads out of a stream whose size is not known in advance, with; # every read in the stream having an equal chance of being selected for inclusion.; # An implementation of ""Algorithm R"" from the paper ""Random Sampling with a Reservoir"" (Jeffrey Scott Vitter, 1985); # i.e., n is a power of 2",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/scorevariants/random_generator.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/scorevariants/random_generator.py
Availability,checkpoint,checkpointing,"""""""PyTorch Lighting wrapper for training and evaluation; ; Args:; model: nn.Module, pytorch model to train/evaluate; additional_hparams: saved in hparams; ; """"""; # save all hyperparameters; # in addition to provenance, this helps; # with model checkpointing by saving the model",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/scorevariants/models/wrapper.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/scorevariants/models/wrapper.py
Integrability,wrap,wrapper,"""""""PyTorch Lighting wrapper for training and evaluation; ; Args:; model: nn.Module, pytorch model to train/evaluate; additional_hparams: saved in hparams; ; """"""; # save all hyperparameters; # in addition to provenance, this helps; # with model checkpointing by saving the model",MatchSource.CODE_COMMENT,src/main/python/org/broadinstitute/hellbender/scorevariants/models/wrapper.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/python/org/broadinstitute/hellbender/scorevariants/models/wrapper.py
Deployability,configurat,configuration,"# set pytensor flags; # logging args; # add tool-specific args; # one or more; # add denoising config args; # Note: we are hiding parameters that are either set by the model or are irrelevant to the case calling task; # add calling config args; # Note: we are hiding parameters that are either set by the model or are irrelevant to the case calling task; # override some inference parameters; # load arguments from the model denoising config that are hidden by the tool; # parse arguments; # check gcnvkernel version in the input model path; # copy the intervals to the calls path; # (we do this early to avoid inadvertent cleanup of temporary files); # load modeling interval list from the model; # load sample names, truncated counts, and interval list from the sample read counts table; # load read depth and ploidy metadata; # setup the inference task; # read model configuration and update args dict; # instantiate config classes; # instantiate and initialize the workspace; # go!; # if inference diverged, pass an exit code to the Java side indicating that restart is needed; # save calls; # save optimizer state; # save ELBO history",MatchSource.CODE_COMMENT,src/main/resources/org/broadinstitute/hellbender/tools/copynumber/case_denoising_calling.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/resources/org/broadinstitute/hellbender/tools/copynumber/case_denoising_calling.py
Modifiability,config,config,"# set pytensor flags; # logging args; # add tool-specific args; # one or more; # add denoising config args; # Note: we are hiding parameters that are either set by the model or are irrelevant to the case calling task; # add calling config args; # Note: we are hiding parameters that are either set by the model or are irrelevant to the case calling task; # override some inference parameters; # load arguments from the model denoising config that are hidden by the tool; # parse arguments; # check gcnvkernel version in the input model path; # copy the intervals to the calls path; # (we do this early to avoid inadvertent cleanup of temporary files); # load modeling interval list from the model; # load sample names, truncated counts, and interval list from the sample read counts table; # load read depth and ploidy metadata; # setup the inference task; # read model configuration and update args dict; # instantiate config classes; # instantiate and initialize the workspace; # go!; # if inference diverged, pass an exit code to the Java side indicating that restart is needed; # save calls; # save optimizer state; # save ELBO history",MatchSource.CODE_COMMENT,src/main/resources/org/broadinstitute/hellbender/tools/copynumber/case_denoising_calling.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/resources/org/broadinstitute/hellbender/tools/copynumber/case_denoising_calling.py
Performance,load,load,"# set pytensor flags; # logging args; # add tool-specific args; # one or more; # add denoising config args; # Note: we are hiding parameters that are either set by the model or are irrelevant to the case calling task; # add calling config args; # Note: we are hiding parameters that are either set by the model or are irrelevant to the case calling task; # override some inference parameters; # load arguments from the model denoising config that are hidden by the tool; # parse arguments; # check gcnvkernel version in the input model path; # copy the intervals to the calls path; # (we do this early to avoid inadvertent cleanup of temporary files); # load modeling interval list from the model; # load sample names, truncated counts, and interval list from the sample read counts table; # load read depth and ploidy metadata; # setup the inference task; # read model configuration and update args dict; # instantiate config classes; # instantiate and initialize the workspace; # go!; # if inference diverged, pass an exit code to the Java side indicating that restart is needed; # save calls; # save optimizer state; # save ELBO history",MatchSource.CODE_COMMENT,src/main/resources/org/broadinstitute/hellbender/tools/copynumber/case_denoising_calling.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/resources/org/broadinstitute/hellbender/tools/copynumber/case_denoising_calling.py
Safety,avoid,avoid,"# set pytensor flags; # logging args; # add tool-specific args; # one or more; # add denoising config args; # Note: we are hiding parameters that are either set by the model or are irrelevant to the case calling task; # add calling config args; # Note: we are hiding parameters that are either set by the model or are irrelevant to the case calling task; # override some inference parameters; # load arguments from the model denoising config that are hidden by the tool; # parse arguments; # check gcnvkernel version in the input model path; # copy the intervals to the calls path; # (we do this early to avoid inadvertent cleanup of temporary files); # load modeling interval list from the model; # load sample names, truncated counts, and interval list from the sample read counts table; # load read depth and ploidy metadata; # setup the inference task; # read model configuration and update args dict; # instantiate config classes; # instantiate and initialize the workspace; # go!; # if inference diverged, pass an exit code to the Java side indicating that restart is needed; # save calls; # save optimizer state; # save ELBO history",MatchSource.CODE_COMMENT,src/main/resources/org/broadinstitute/hellbender/tools/copynumber/case_denoising_calling.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/resources/org/broadinstitute/hellbender/tools/copynumber/case_denoising_calling.py
Testability,log,logging,"# set pytensor flags; # logging args; # add tool-specific args; # one or more; # add denoising config args; # Note: we are hiding parameters that are either set by the model or are irrelevant to the case calling task; # add calling config args; # Note: we are hiding parameters that are either set by the model or are irrelevant to the case calling task; # override some inference parameters; # load arguments from the model denoising config that are hidden by the tool; # parse arguments; # check gcnvkernel version in the input model path; # copy the intervals to the calls path; # (we do this early to avoid inadvertent cleanup of temporary files); # load modeling interval list from the model; # load sample names, truncated counts, and interval list from the sample read counts table; # load read depth and ploidy metadata; # setup the inference task; # read model configuration and update args dict; # instantiate config classes; # instantiate and initialize the workspace; # go!; # if inference diverged, pass an exit code to the Java side indicating that restart is needed; # save calls; # save optimizer state; # save ELBO history",MatchSource.CODE_COMMENT,src/main/resources/org/broadinstitute/hellbender/tools/copynumber/case_denoising_calling.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/resources/org/broadinstitute/hellbender/tools/copynumber/case_denoising_calling.py
Integrability,inject,inject,"# set pytensor flags; # logging args; # add tool-specific args; # optional arguments; # optional arguments; # Note: we are hiding parameters that are either set by the model or are irrelevant to the case calling task; # override some inference parameters; # parse arguments; # check gcnvkernel version in the input model path; # read contig ploidy prior map from the model; # load interval list from the model; # load sample coverage metadata; # generate intervals metadata; # inject ploidy prior map to the dictionary of parsed args; # setup the case ploidy inference task; # go!; # sample sample-specific posteriors",MatchSource.CODE_COMMENT,src/main/resources/org/broadinstitute/hellbender/tools/copynumber/case_determine_ploidy_and_depth.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/resources/org/broadinstitute/hellbender/tools/copynumber/case_determine_ploidy_and_depth.py
Performance,load,load,"# set pytensor flags; # logging args; # add tool-specific args; # optional arguments; # optional arguments; # Note: we are hiding parameters that are either set by the model or are irrelevant to the case calling task; # override some inference parameters; # parse arguments; # check gcnvkernel version in the input model path; # read contig ploidy prior map from the model; # load interval list from the model; # load sample coverage metadata; # generate intervals metadata; # inject ploidy prior map to the dictionary of parsed args; # setup the case ploidy inference task; # go!; # sample sample-specific posteriors",MatchSource.CODE_COMMENT,src/main/resources/org/broadinstitute/hellbender/tools/copynumber/case_determine_ploidy_and_depth.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/resources/org/broadinstitute/hellbender/tools/copynumber/case_determine_ploidy_and_depth.py
Security,inject,inject,"# set pytensor flags; # logging args; # add tool-specific args; # optional arguments; # optional arguments; # Note: we are hiding parameters that are either set by the model or are irrelevant to the case calling task; # override some inference parameters; # parse arguments; # check gcnvkernel version in the input model path; # read contig ploidy prior map from the model; # load interval list from the model; # load sample coverage metadata; # generate intervals metadata; # inject ploidy prior map to the dictionary of parsed args; # setup the case ploidy inference task; # go!; # sample sample-specific posteriors",MatchSource.CODE_COMMENT,src/main/resources/org/broadinstitute/hellbender/tools/copynumber/case_determine_ploidy_and_depth.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/resources/org/broadinstitute/hellbender/tools/copynumber/case_determine_ploidy_and_depth.py
Testability,log,logging,"# set pytensor flags; # logging args; # add tool-specific args; # optional arguments; # optional arguments; # Note: we are hiding parameters that are either set by the model or are irrelevant to the case calling task; # override some inference parameters; # parse arguments; # check gcnvkernel version in the input model path; # read contig ploidy prior map from the model; # load interval list from the model; # load sample coverage metadata; # generate intervals metadata; # inject ploidy prior map to the dictionary of parsed args; # setup the case ploidy inference task; # go!; # sample sample-specific posteriors",MatchSource.CODE_COMMENT,src/main/resources/org/broadinstitute/hellbender/tools/copynumber/case_determine_ploidy_and_depth.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/resources/org/broadinstitute/hellbender/tools/copynumber/case_determine_ploidy_and_depth.py
Deployability,update,update,"# set pytensor flags; # logging args; # add tool-specific args; # one or more; # add denoising config args; # add calling config args; # override some inference parameters; # parse arguments; # copy the intervals to the model and calls paths; # (we do this early to avoid inadvertent cleanup of temporary files); # load modeling interval list; # load sample names, truncated counts, and interval list from the sample read counts table; # load read depth and ploidy metadata; # setup the inference task; # instantiate config classes for the main task; # instantiate config classes for the warm-up task; # update the contigs for the two-stage task; # the main task should start from sampling and calling; # instantiate and initialize the workspace; # warm-up task; # go!; # if inference diverged, pass an exit code to the Java side indicating that restart is needed; # main task; # go!; # if inference diverged, pass an exit code to the Java side indicating that restart is needed; # save model; # save calls; # save optimizer state; # save ELBO history",MatchSource.CODE_COMMENT,src/main/resources/org/broadinstitute/hellbender/tools/copynumber/cohort_denoising_calling.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/resources/org/broadinstitute/hellbender/tools/copynumber/cohort_denoising_calling.py
Modifiability,config,config,"# set pytensor flags; # logging args; # add tool-specific args; # one or more; # add denoising config args; # add calling config args; # override some inference parameters; # parse arguments; # copy the intervals to the model and calls paths; # (we do this early to avoid inadvertent cleanup of temporary files); # load modeling interval list; # load sample names, truncated counts, and interval list from the sample read counts table; # load read depth and ploidy metadata; # setup the inference task; # instantiate config classes for the main task; # instantiate config classes for the warm-up task; # update the contigs for the two-stage task; # the main task should start from sampling and calling; # instantiate and initialize the workspace; # warm-up task; # go!; # if inference diverged, pass an exit code to the Java side indicating that restart is needed; # main task; # go!; # if inference diverged, pass an exit code to the Java side indicating that restart is needed; # save model; # save calls; # save optimizer state; # save ELBO history",MatchSource.CODE_COMMENT,src/main/resources/org/broadinstitute/hellbender/tools/copynumber/cohort_denoising_calling.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/resources/org/broadinstitute/hellbender/tools/copynumber/cohort_denoising_calling.py
Performance,load,load,"# set pytensor flags; # logging args; # add tool-specific args; # one or more; # add denoising config args; # add calling config args; # override some inference parameters; # parse arguments; # copy the intervals to the model and calls paths; # (we do this early to avoid inadvertent cleanup of temporary files); # load modeling interval list; # load sample names, truncated counts, and interval list from the sample read counts table; # load read depth and ploidy metadata; # setup the inference task; # instantiate config classes for the main task; # instantiate config classes for the warm-up task; # update the contigs for the two-stage task; # the main task should start from sampling and calling; # instantiate and initialize the workspace; # warm-up task; # go!; # if inference diverged, pass an exit code to the Java side indicating that restart is needed; # main task; # go!; # if inference diverged, pass an exit code to the Java side indicating that restart is needed; # save model; # save calls; # save optimizer state; # save ELBO history",MatchSource.CODE_COMMENT,src/main/resources/org/broadinstitute/hellbender/tools/copynumber/cohort_denoising_calling.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/resources/org/broadinstitute/hellbender/tools/copynumber/cohort_denoising_calling.py
Safety,avoid,avoid,"# set pytensor flags; # logging args; # add tool-specific args; # one or more; # add denoising config args; # add calling config args; # override some inference parameters; # parse arguments; # copy the intervals to the model and calls paths; # (we do this early to avoid inadvertent cleanup of temporary files); # load modeling interval list; # load sample names, truncated counts, and interval list from the sample read counts table; # load read depth and ploidy metadata; # setup the inference task; # instantiate config classes for the main task; # instantiate config classes for the warm-up task; # update the contigs for the two-stage task; # the main task should start from sampling and calling; # instantiate and initialize the workspace; # warm-up task; # go!; # if inference diverged, pass an exit code to the Java side indicating that restart is needed; # main task; # go!; # if inference diverged, pass an exit code to the Java side indicating that restart is needed; # save model; # save calls; # save optimizer state; # save ELBO history",MatchSource.CODE_COMMENT,src/main/resources/org/broadinstitute/hellbender/tools/copynumber/cohort_denoising_calling.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/resources/org/broadinstitute/hellbender/tools/copynumber/cohort_denoising_calling.py
Testability,log,logging,"# set pytensor flags; # logging args; # add tool-specific args; # one or more; # add denoising config args; # add calling config args; # override some inference parameters; # parse arguments; # copy the intervals to the model and calls paths; # (we do this early to avoid inadvertent cleanup of temporary files); # load modeling interval list; # load sample names, truncated counts, and interval list from the sample read counts table; # load read depth and ploidy metadata; # setup the inference task; # instantiate config classes for the main task; # instantiate config classes for the warm-up task; # update the contigs for the two-stage task; # the main task should start from sampling and calling; # instantiate and initialize the workspace; # warm-up task; # go!; # if inference diverged, pass an exit code to the Java side indicating that restart is needed; # main task; # go!; # if inference diverged, pass an exit code to the Java side indicating that restart is needed; # save model; # save calls; # save optimizer state; # save ELBO history",MatchSource.CODE_COMMENT,src/main/resources/org/broadinstitute/hellbender/tools/copynumber/cohort_denoising_calling.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/resources/org/broadinstitute/hellbender/tools/copynumber/cohort_denoising_calling.py
Integrability,inject,inject,"# set pytensor flags; # logging args; # add tool-specific args; # optional arguments; # override some inference parameters; # parse arguments; # copy the intervals and ploidy priors to the model path; # (we do this early to avoid inadvertent cleanup of temporary files); # read contig ploidy prior map from file; # load interval list; # load sample coverage metadata; # generate interval list metadata; # inject ploidy prior map to the dictionary of parsed args; # go!; # save model parameters; # sample sample-specific posteriors",MatchSource.CODE_COMMENT,src/main/resources/org/broadinstitute/hellbender/tools/copynumber/cohort_determine_ploidy_and_depth.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/resources/org/broadinstitute/hellbender/tools/copynumber/cohort_determine_ploidy_and_depth.py
Performance,load,load,"# set pytensor flags; # logging args; # add tool-specific args; # optional arguments; # override some inference parameters; # parse arguments; # copy the intervals and ploidy priors to the model path; # (we do this early to avoid inadvertent cleanup of temporary files); # read contig ploidy prior map from file; # load interval list; # load sample coverage metadata; # generate interval list metadata; # inject ploidy prior map to the dictionary of parsed args; # go!; # save model parameters; # sample sample-specific posteriors",MatchSource.CODE_COMMENT,src/main/resources/org/broadinstitute/hellbender/tools/copynumber/cohort_determine_ploidy_and_depth.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/resources/org/broadinstitute/hellbender/tools/copynumber/cohort_determine_ploidy_and_depth.py
Safety,avoid,avoid,"# set pytensor flags; # logging args; # add tool-specific args; # optional arguments; # override some inference parameters; # parse arguments; # copy the intervals and ploidy priors to the model path; # (we do this early to avoid inadvertent cleanup of temporary files); # read contig ploidy prior map from file; # load interval list; # load sample coverage metadata; # generate interval list metadata; # inject ploidy prior map to the dictionary of parsed args; # go!; # save model parameters; # sample sample-specific posteriors",MatchSource.CODE_COMMENT,src/main/resources/org/broadinstitute/hellbender/tools/copynumber/cohort_determine_ploidy_and_depth.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/resources/org/broadinstitute/hellbender/tools/copynumber/cohort_determine_ploidy_and_depth.py
Security,inject,inject,"# set pytensor flags; # logging args; # add tool-specific args; # optional arguments; # override some inference parameters; # parse arguments; # copy the intervals and ploidy priors to the model path; # (we do this early to avoid inadvertent cleanup of temporary files); # read contig ploidy prior map from file; # load interval list; # load sample coverage metadata; # generate interval list metadata; # inject ploidy prior map to the dictionary of parsed args; # go!; # save model parameters; # sample sample-specific posteriors",MatchSource.CODE_COMMENT,src/main/resources/org/broadinstitute/hellbender/tools/copynumber/cohort_determine_ploidy_and_depth.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/resources/org/broadinstitute/hellbender/tools/copynumber/cohort_determine_ploidy_and_depth.py
Testability,log,logging,"# set pytensor flags; # logging args; # add tool-specific args; # optional arguments; # override some inference parameters; # parse arguments; # copy the intervals and ploidy priors to the model path; # (we do this early to avoid inadvertent cleanup of temporary files); # read contig ploidy prior map from file; # load interval list; # load sample coverage metadata; # generate interval list metadata; # inject ploidy prior map to the dictionary of parsed args; # go!; # save model parameters; # sample sample-specific posteriors",MatchSource.CODE_COMMENT,src/main/resources/org/broadinstitute/hellbender/tools/copynumber/cohort_determine_ploidy_and_depth.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/resources/org/broadinstitute/hellbender/tools/copynumber/cohort_determine_ploidy_and_depth.py
Performance,load,load,"# set pytensor flags; # logging args; # add tool-specific args; # one or more; # one or more; # add optional args; # parse arguments; # load read depth and ploidy metadata; # instantiate Viterbi segmentation engine",MatchSource.CODE_COMMENT,src/main/resources/org/broadinstitute/hellbender/tools/copynumber/segment_gcnv_calls.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/resources/org/broadinstitute/hellbender/tools/copynumber/segment_gcnv_calls.py
Testability,log,logging,"# set pytensor flags; # logging args; # add tool-specific args; # one or more; # one or more; # add optional args; # parse arguments; # load read depth and ploidy metadata; # instantiate Viterbi segmentation engine",MatchSource.CODE_COMMENT,src/main/resources/org/broadinstitute/hellbender/tools/copynumber/segment_gcnv_calls.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/resources/org/broadinstitute/hellbender/tools/copynumber/segment_gcnv_calls.py
Performance,load,load,"#!/usr/bin/python3; """"""; Args:; args: model specific and trainer arguments; model_file: model file to load parameters from a pretrained PyTorch model; """"""",MatchSource.CODE_COMMENT,src/main/resources/org/broadinstitute/hellbender/tools/walkers/vqsr/nvscorevariants.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/resources/org/broadinstitute/hellbender/tools/walkers/vqsr/nvscorevariants.py
Availability,down,downstream,"# read chunked annotations; # SimpleImputer will drop any features that are completely missing, resulting in different shapes for; # imputed_X_ni and X_ni and misalignment of features when training and scoring downstream if not checked.; # We externally check for and fail in the presence of any entirely missing features, but we do a redundant check here.; # TODO sklearn's implementation is single-threaded, but this could perhaps be parallelized; # the dill package can be used to pickle lambda functions; # this script can handle both training and scoring; we check the passed arguments to determine which is appropriate",MatchSource.CODE_COMMENT,src/main/resources/org/broadinstitute/hellbender/tools/walkers/vqsr/scalable/isolation-forest.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/resources/org/broadinstitute/hellbender/tools/walkers/vqsr/scalable/isolation-forest.py
Safety,redund,redundant,"# read chunked annotations; # SimpleImputer will drop any features that are completely missing, resulting in different shapes for; # imputed_X_ni and X_ni and misalignment of features when training and scoring downstream if not checked.; # We externally check for and fail in the presence of any entirely missing features, but we do a redundant check here.; # TODO sklearn's implementation is single-threaded, but this could perhaps be parallelized; # the dill package can be used to pickle lambda functions; # this script can handle both training and scoring; we check the passed arguments to determine which is appropriate",MatchSource.CODE_COMMENT,src/main/resources/org/broadinstitute/hellbender/tools/walkers/vqsr/scalable/isolation-forest.py,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/tree/4.6.0.0/src/main/resources/org/broadinstitute/hellbender/tools/walkers/vqsr/scalable/isolation-forest.py
