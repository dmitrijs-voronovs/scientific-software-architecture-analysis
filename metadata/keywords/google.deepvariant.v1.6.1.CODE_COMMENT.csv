quality_attribute,keyword,matched_word,sentence,source,filename,author,repo,version,wiki,url
Security,access,accessed,"g disclaimer.; #; # 2. Redistributions in binary form must reproduce the above copyright; # notice, this list of conditions and the following disclaimer in the; # documentation and/or other materials provided with the distribution.; #; # 3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Common constants shared across DeepVariant's codebase. This file is for very general constants in the code that end up needing to be; accessed in a variety of places, often in live code as well as throughout the; code in tests.; """"""; # Default width [in basepairs] for our DeepVariant data tensor.; # Default height [in rows] for our DeepVariant data tensor.; # Default height [in rows] for our DeepVariant parent data tensor.; # Default height [in rows] for our DeepVariant child data tensor.; # Not a default because it's hard-coded into the code.; # The dimensions of a pileup image tensor as height x width x rank.; # Number of classes represented in the data set. The three classes are; # homozygous reference (0), heterozygous (1) and homozygous alternative (2).",MatchSource.CODE_COMMENT,deeptrio/dt_constants.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/dt_constants.py
Testability,test,tests,"g disclaimer.; #; # 2. Redistributions in binary form must reproduce the above copyright; # notice, this list of conditions and the following disclaimer in the; # documentation and/or other materials provided with the distribution.; #; # 3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Common constants shared across DeepVariant's codebase. This file is for very general constants in the code that end up needing to be; accessed in a variety of places, often in live code as well as throughout the; code in tests.; """"""; # Default width [in basepairs] for our DeepVariant data tensor.; # Default height [in rows] for our DeepVariant data tensor.; # Default height [in rows] for our DeepVariant parent data tensor.; # Default height [in rows] for our DeepVariant child data tensor.; # Not a default because it's hard-coded into the code.; # The dimensions of a pileup image tensor as height x width x rank.; # Number of classes represented in the data set. The three classes are; # homozygous reference (0), heterozygous (1) and homozygous alternative (2).",MatchSource.CODE_COMMENT,deeptrio/dt_constants.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/dt_constants.py
Availability,down,downsampling,"e or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Step one of DeepTrio: creates tf.Example protos for training/calling.""""""; # Sentinel command line flag value indicating no downsampling should occur.; # 1 is the child of the trio.; # Adopt more general flags from make_examples_options.; # Flags related to samples in DeepTrio:; # We are using this flag for determining intervals for both child and parent; # models. In the future, we can consider extending into 3 samples.; # Change any flag defaults that differ for DeepTrio.; """"""Collects sample-related options into a list of samples.""""""; # Sample-specific options.; # Swap the two parents when calling on parent2.; # If --sample_name_to_train is not set, train on the child.; # This is for backward compatibility.; # Ordering here determines the default order of samples, and when a sample; # above has a custom .order, then this is the list those indices refer to.; """"""Creates a MakeExamplesOptions proto populated with reasonable defaults. Args:; add_flags: bool. defaults to True. If True, we will push the value of; certain FLAGS into our options. If False, those option fields are left; uninitialized",MatchSource.CODE_COMMENT,deeptrio/make_examples.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/make_examples.py
Modifiability,extend,extending,"NTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Step one of DeepTrio: creates tf.Example protos for training/calling.""""""; # Sentinel command line flag value indicating no downsampling should occur.; # 1 is the child of the trio.; # Adopt more general flags from make_examples_options.; # Flags related to samples in DeepTrio:; # We are using this flag for determining intervals for both child and parent; # models. In the future, we can consider extending into 3 samples.; # Change any flag defaults that differ for DeepTrio.; """"""Collects sample-related options into a list of samples.""""""; # Sample-specific options.; # Swap the two parents when calling on parent2.; # If --sample_name_to_train is not set, train on the child.; # This is for backward compatibility.; # Ordering here determines the default order of samples, and when a sample; # above has a custom .order, then this is the list those indices refer to.; """"""Creates a MakeExamplesOptions proto populated with reasonable defaults. Args:; add_flags: bool. defaults to True. If True, we will push the value of; certain FLAGS into our options. If False, those option fields are left; uninitialized.; flags_obj: object. If not None, use as the source of flags, else use global; FLAGS. Returns:; deepvariant_pb2.MakeExamplesOptions protobuf. Raises:; ValueError: If we observe invalid flag values.; """"""; """"""Checks that all the options chosen make sense together.""""""; # Check for genera",MatchSource.CODE_COMMENT,deeptrio/make_examples.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/make_examples.py
Availability,error,error,"e previously in training mode the; non training sample would not be phased. So this now tests to make sure; all of the training examples are phased correctly.; """"""; # If denovo test is enabled, then set the parameters for denovo testing.; # Check total number of denovo examples.; # Read the runinfo file; # Golden sets are created with learning/genomics/internal/create_golden.sh; # Verify that the variants in the examples are all good.; # Golden sets are created with learning/genomics/internal/create_golden.sh; # The following 4 lines are added.; # Verify that the variants in the examples are all good.; # Pileup image should now have 8 channels.; # Height should be 60 + 40 * 2 = 140.; # child_gvcf = test_utils.test_tmpfile(f'{name}.gvcf_child.tfrecord'); # child_candidates = test_utils.test_tmpfile(f'{name}.vsc_child.tfrecord'); # The assumption is just that these two lists of examples should be; # different. In this case, it happens to be that we got different numbers; # of examples:; # Training on parent2 in a duo is not supported (with a clear error; # message).; # This is only a simple test that it runs without errors.; # Verify that the variants in the examples are all good.; # Now, this is the main part of the test. I want to test the behavior after; # I set max_reads_for_dynamic_bases_per_region.; # Tests that we call almost all of the real variants (according to NIST's; # Genome in a Bottle callset for NA12878) in our candidate callset.; # Tests that we don't have an enormous number of FP calls. We should have; # no more than 5x (arbitrary) more candidate calls than real calls. If we; # have more it's likely due to some major pipeline problem.; """"""Asserts that actual and expected tf.Examples from DeepVariant are equal. Args:; actual: iterable of tf.Examples from DeepVariant. DeepVariant examples; that we want to check.; expected: iterable of tf.Examples. Expected results for actual.; """"""; """"""Asserts that actual and expected tf.Examples are not equal. Args:; ac",MatchSource.CODE_COMMENT,deeptrio/make_examples_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/make_examples_test.py
Deployability,pipeline,pipeline,"hannels.; # Height should be 60 + 40 * 2 = 140.; # child_gvcf = test_utils.test_tmpfile(f'{name}.gvcf_child.tfrecord'); # child_candidates = test_utils.test_tmpfile(f'{name}.vsc_child.tfrecord'); # The assumption is just that these two lists of examples should be; # different. In this case, it happens to be that we got different numbers; # of examples:; # Training on parent2 in a duo is not supported (with a clear error; # message).; # This is only a simple test that it runs without errors.; # Verify that the variants in the examples are all good.; # Now, this is the main part of the test. I want to test the behavior after; # I set max_reads_for_dynamic_bases_per_region.; # Tests that we call almost all of the real variants (according to NIST's; # Genome in a Bottle callset for NA12878) in our candidate callset.; # Tests that we don't have an enormous number of FP calls. We should have; # no more than 5x (arbitrary) more candidate calls than real calls. If we; # have more it's likely due to some major pipeline problem.; """"""Asserts that actual and expected tf.Examples from DeepVariant are equal. Args:; actual: iterable of tf.Examples from DeepVariant. DeepVariant examples; that we want to check.; expected: iterable of tf.Examples. Expected results for actual.; """"""; """"""Asserts that actual and expected tf.Examples are not equal. Args:; actual: iterable of tf.Examples from DeepVariant. DeepVariant examples; that we want to check.; expected: iterable of tf.Examples. Expected results for actual.; """"""; # Finds a call in our actual call set for each NIST variant, asserting; # that we found exactly one.; # Verify that every alt allele appears in the call (but the call might); # have more than just those calls.; # Verifies simple properties of the Variant protos in variants. For example,; # checks that the reference_name() is our expected chromosome. The flag; # is_gvcf determines how we check the VariantCall field of each variant,; # enforcing expectations for gVCF records if",MatchSource.CODE_COMMENT,deeptrio/make_examples_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/make_examples_test.py
Integrability,message,message,"e previously in training mode the; non training sample would not be phased. So this now tests to make sure; all of the training examples are phased correctly.; """"""; # If denovo test is enabled, then set the parameters for denovo testing.; # Check total number of denovo examples.; # Read the runinfo file; # Golden sets are created with learning/genomics/internal/create_golden.sh; # Verify that the variants in the examples are all good.; # Golden sets are created with learning/genomics/internal/create_golden.sh; # The following 4 lines are added.; # Verify that the variants in the examples are all good.; # Pileup image should now have 8 channels.; # Height should be 60 + 40 * 2 = 140.; # child_gvcf = test_utils.test_tmpfile(f'{name}.gvcf_child.tfrecord'); # child_candidates = test_utils.test_tmpfile(f'{name}.vsc_child.tfrecord'); # The assumption is just that these two lists of examples should be; # different. In this case, it happens to be that we got different numbers; # of examples:; # Training on parent2 in a duo is not supported (with a clear error; # message).; # This is only a simple test that it runs without errors.; # Verify that the variants in the examples are all good.; # Now, this is the main part of the test. I want to test the behavior after; # I set max_reads_for_dynamic_bases_per_region.; # Tests that we call almost all of the real variants (according to NIST's; # Genome in a Bottle callset for NA12878) in our candidate callset.; # Tests that we don't have an enormous number of FP calls. We should have; # no more than 5x (arbitrary) more candidate calls than real calls. If we; # have more it's likely due to some major pipeline problem.; """"""Asserts that actual and expected tf.Examples from DeepVariant are equal. Args:; actual: iterable of tf.Examples from DeepVariant. DeepVariant examples; that we want to check.; expected: iterable of tf.Examples. Expected results for actual.; """"""; """"""Asserts that actual and expected tf.Examples are not equal. Args:; ac",MatchSource.CODE_COMMENT,deeptrio/make_examples_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/make_examples_test.py
Security,integrity,integrity,"le should contain name, length, and pos_in_fasta. Returns:; A list of ContigInfo protos, one for each spec in specs.; """"""; """"""Makes a list of Range objects from literals.""""""; """"""Makes a RangeSet of intervals from literals.""""""; # Golden sets are created with; # learning/genomics/internal/create_golden_deep_trio.sh; # All tests are run with fast_pass_aligner enabled. There are no; # golden sets version for ssw realigner.; # Check that our run_info proto contains the basic fields we'd expect:; # (a) our options are written to the run_info.options field.; # (b) run_info.resource_metrics is present and contains our hostname.; # For candidate_sweep mode we verify that candidate positions match; # golden set exactly.; # In candidate_sweep mode the test stops here.; # Test that our candidates are reasonable, calling specific helper functions; # to check lots of properties of the output.; # Verify that the variants in the examples are all good.; # Verify the integrity of the examples and then check that they match our; # golden labeled examples. Note we expect the order for both training and; # calling modes to produce deterministic order because we fix the random; # seed.; # Check the quality of our generated gvcf file.; # Despite its name, assertCountEqual checks that all items are equal.; # The positional labeler doesn't track metrics, so don't try to read them; # in when that's the mode.; """"""Test end to end for long ONT reads with phasing enabled. Args:; denovo_test: If true, denovo parameters will be set.; expected_denovo_variants: Total number of denovo examples expected. This test runs ONT end to end and compares the output with the golden; output. This test is introduced because previously in training mode the; non training sample would not be phased. So this now tests to make sure; all of the training examples are phased correctly.; """"""; # If denovo test is enabled, then set the parameters for denovo testing.; # Check total number of denovo examples.; # Read the runi",MatchSource.CODE_COMMENT,deeptrio/make_examples_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/make_examples_test.py
Testability,test,tests," DeepVariant into a dict of Pythonic structures. Args:; example: tf.Example proto. The example to make into a dictionary. Returns:; A python dictionary with key/value pairs for each of the fields of example,; with each value decoded as needed into Python structures like protos, list,; etc. Raises:; KeyError: If example contains a feature without a known decoder.; """"""; """"""Makes ContigInfo protos from specs. Args:; specs: A list of 2- or 3-tuples. All tuples should be of the same length. If; 2-element, these should be the name and length in basepairs of each; contig, and their pos_in_fasta will be set to their index in the list. If; the 3-element, the tuple should contain name, length, and pos_in_fasta. Returns:; A list of ContigInfo protos, one for each spec in specs.; """"""; """"""Makes a list of Range objects from literals.""""""; """"""Makes a RangeSet of intervals from literals.""""""; # Golden sets are created with; # learning/genomics/internal/create_golden_deep_trio.sh; # All tests are run with fast_pass_aligner enabled. There are no; # golden sets version for ssw realigner.; # Check that our run_info proto contains the basic fields we'd expect:; # (a) our options are written to the run_info.options field.; # (b) run_info.resource_metrics is present and contains our hostname.; # For candidate_sweep mode we verify that candidate positions match; # golden set exactly.; # In candidate_sweep mode the test stops here.; # Test that our candidates are reasonable, calling specific helper functions; # to check lots of properties of the output.; # Verify that the variants in the examples are all good.; # Verify the integrity of the examples and then check that they match our; # golden labeled examples. Note we expect the order for both training and; # calling modes to produce deterministic order because we fix the random; # seed.; # Check the quality of our generated gvcf file.; # Despite its name, assertCountEqual checks that all items are equal.; # The positional labeler doesn't tra",MatchSource.CODE_COMMENT,deeptrio/make_examples_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/make_examples_test.py
Usability,learn,learning,"s to decoders for decode_example function.; """"""Decodes a tf.Example from DeepVariant into a dict of Pythonic structures. Args:; example: tf.Example proto. The example to make into a dictionary. Returns:; A python dictionary with key/value pairs for each of the fields of example,; with each value decoded as needed into Python structures like protos, list,; etc. Raises:; KeyError: If example contains a feature without a known decoder.; """"""; """"""Makes ContigInfo protos from specs. Args:; specs: A list of 2- or 3-tuples. All tuples should be of the same length. If; 2-element, these should be the name and length in basepairs of each; contig, and their pos_in_fasta will be set to their index in the list. If; the 3-element, the tuple should contain name, length, and pos_in_fasta. Returns:; A list of ContigInfo protos, one for each spec in specs.; """"""; """"""Makes a list of Range objects from literals.""""""; """"""Makes a RangeSet of intervals from literals.""""""; # Golden sets are created with; # learning/genomics/internal/create_golden_deep_trio.sh; # All tests are run with fast_pass_aligner enabled. There are no; # golden sets version for ssw realigner.; # Check that our run_info proto contains the basic fields we'd expect:; # (a) our options are written to the run_info.options field.; # (b) run_info.resource_metrics is present and contains our hostname.; # For candidate_sweep mode we verify that candidate positions match; # golden set exactly.; # In candidate_sweep mode the test stops here.; # Test that our candidates are reasonable, calling specific helper functions; # to check lots of properties of the output.; # Verify that the variants in the examples are all good.; # Verify the integrity of the examples and then check that they match our; # golden labeled examples. Note we expect the order for both training and; # calling modes to produce deterministic order because we fix the random; # seed.; # Check the quality of our generated gvcf file.; # Despite its name, assertCountEqu",MatchSource.CODE_COMMENT,deeptrio/make_examples_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/make_examples_test.py
Modifiability,variab,variables,"# are met:; #; # 1. Redistributions of source code must retain the above copyright notice,; # this list of conditions and the following disclaimer.; #; # 2. Redistributions in binary form must reproduce the above copyright; # notice, this list of conditions and the following disclaimer in the; # documentation and/or other materials provided with the distribution.; #; # 3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Utilities to help with testing DeepVariant code.""""""; """"""Gets the path to filename in genomics/deepvariant/testdata. These paths are only known at runtime, after flag parsing; has occurred. Args:; filename: The name of a testdata file in the core genomics testdata; directory. For example, if you have a test file in; ""learning/genomics/deepvariant/testdata/foo.txt"", filename should be; ""foo.txt"" to get a path to it. Returns:; The absolute path to a testdata file.; """"""; # Test data for ONT; """"""Initialize global variables from flag values.""""""; # For oxford nanopore; # For CustomizedClassesVariantLabeler.; # For alt-aligned pileups",MatchSource.CODE_COMMENT,deeptrio/testdata.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/testdata.py
Testability,test,testing,"# are met:; #; # 1. Redistributions of source code must retain the above copyright notice,; # this list of conditions and the following disclaimer.; #; # 2. Redistributions in binary form must reproduce the above copyright; # notice, this list of conditions and the following disclaimer in the; # documentation and/or other materials provided with the distribution.; #; # 3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Utilities to help with testing DeepVariant code.""""""; """"""Gets the path to filename in genomics/deepvariant/testdata. These paths are only known at runtime, after flag parsing; has occurred. Args:; filename: The name of a testdata file in the core genomics testdata; directory. For example, if you have a test file in; ""learning/genomics/deepvariant/testdata/foo.txt"", filename should be; ""foo.txt"" to get a path to it. Returns:; The absolute path to a testdata file.; """"""; # Test data for ONT; """"""Initialize global variables from flag values.""""""; # For oxford nanopore; # For CustomizedClassesVariantLabeler.; # For alt-aligned pileups",MatchSource.CODE_COMMENT,deeptrio/testdata.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/testdata.py
Usability,learn,learning,"# are met:; #; # 1. Redistributions of source code must retain the above copyright notice,; # this list of conditions and the following disclaimer.; #; # 2. Redistributions in binary form must reproduce the above copyright; # notice, this list of conditions and the following disclaimer in the; # documentation and/or other materials provided with the distribution.; #; # 3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Utilities to help with testing DeepVariant code.""""""; """"""Gets the path to filename in genomics/deepvariant/testdata. These paths are only known at runtime, after flag parsing; has occurred. Args:; filename: The name of a testdata file in the core genomics testdata; directory. For example, if you have a test file in; ""learning/genomics/deepvariant/testdata/foo.txt"", filename should be; ""foo.txt"" to get a path to it. Returns:; The absolute path to a testdata file.; """"""; # Test data for ONT; """"""Initialize global variables from flag values.""""""; # For oxford nanopore; # For CustomizedClassesVariantLabeler.; # For alt-aligned pileups",MatchSource.CODE_COMMENT,deeptrio/testdata.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/testdata.py
Availability,error,error,"CHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Functionality for including allele frequencies in DeepVariant pileups.""""""; """"""Gets allele frequency of the index-th alt_base of a Variant proto. Args:; variant: A Variant proto.; index: The index where we want to query allele frequency. Returns:; A float. The queried allele frequency. Raises:; ValueError: If the Variant proto does not include 'AF' field or the 'AF'; field encounters an out-of-bound error when querying at position `index`; """"""; """"""Gets REF allele frequency for a Variant proto.""""""; """"""Gets reference haplotype that overlaps with given variants and its offset. Reference offset is the starting position of the returned haplotype.; It is the minimal starting positions of dv_variant and cohort_variants.; Reference haplotype is the reference sequence from reference_offset to the; maximal ending position of dv_variant and cohort_variants. Args:; dv_variant: A Variant proto.; cohort_variants: A list of Variant protos.; ref_reader: A fasta.IndexedFastaReader. Returns:; A tuple of a string and an integer.; - String: Reference haplotype overlapping with dv_variant and; cohort_variants.; - Integer: Offset of the reference haplotype. Raises:; ValueError: If the queried region is invalid.; """"""; # Get the range for haplotypes to be compared.; """"""Updates haplotypes for a variant. A list of variant haplotypes are updated given a variant and a reference; haplotype (this co",MatchSource.CODE_COMMENT,deepvariant/allele_frequency.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/allele_frequency.py
Deployability,update,updated,"d encounters an out-of-bound error when querying at position `index`; """"""; """"""Gets REF allele frequency for a Variant proto.""""""; """"""Gets reference haplotype that overlaps with given variants and its offset. Reference offset is the starting position of the returned haplotype.; It is the minimal starting positions of dv_variant and cohort_variants.; Reference haplotype is the reference sequence from reference_offset to the; maximal ending position of dv_variant and cohort_variants. Args:; dv_variant: A Variant proto.; cohort_variants: A list of Variant protos.; ref_reader: A fasta.IndexedFastaReader. Returns:; A tuple of a string and an integer.; - String: Reference haplotype overlapping with dv_variant and; cohort_variants.; - Integer: Offset of the reference haplotype. Raises:; ValueError: If the queried region is invalid.; """"""; # Get the range for haplotypes to be compared.; """"""Updates haplotypes for a variant. A list of variant haplotypes are updated given a variant and a reference; haplotype (this consists of a sequence and an offset wrt to the reference).; All ALT alleles are updated as independent updated haplotypes. Args:; variant: A Variant proto.; reference_haplotype: A string extracted from the reference genome.; reference_offset: An integer. The offset of the starting position of; reference_haplotype on reference. Raises:; ValueError: Variant.start is smaller than reference_offset. Returns:; A list of haplotype objects. Haplotype objects are stored as dicts:; {'haplotype': a haplotype (string),; 'alt': an alt allele (string),; 'variant': a Variant proto}; """"""; """"""Match candidate haplotypes with cohort haplotypes and update frequency. First, we look for exact haplotype matches between candidate and cohorts.; If there're any matches, the REF allele frequency associated with the matching; ALT allele is updated as well. Second, if no matches are found, we try to find inexact matches, where only; REF alleles are matched. The inexact matching step is only used t",MatchSource.CODE_COMMENT,deepvariant/allele_frequency.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/allele_frequency.py
Performance,perform,performing,"values.; """"""; # Exact haplotype match.; # Update REF frequency if it is not in the dictionary.; # For an unmatched alt allele, set the frequency to 0.; # Calculate REF allele frequency if no exact match was found.; # It is possible a novel mutation happens at a site where there are other; # cohort variants. In this case, we cannot simply set REF frequency to 1.; # Left align variants.; # Try to find inexact matches to set REF allele frequency.; # Inexact matches here mean only REF alleles match.; # If still no match, set REF allele frequency to 1.; """"""Finds the allele frequencies of all the alt alleles for a candidate. Args:; variant: A Variant proto generated by make_examples. Note that it can be; multi-allelic.; population_vcf_reader: A VcfReader object that reads associated VCF file for; a candidate. We want to extract allele frequency information in the VCF.; ref_reader: A IndexedFastaReader object that reads the reference FASTA.; padding_bases: An integer that specifies the number of padding bases added; when performing a VCF query. By default it is set to 0. Returns:; A dict with alleles as keys, and allele frequencies as values; """"""; # Convert to list because we'll look through cohort_variants more than once.; # Init allele frequency dict using alt bases in the candidate.; # If the range associated with variant and cohort_variants is invalid,; # assume this candidate does not have any ALT alleles.; """"""Creates VcfReaders for the given VCF file paths, organized by reference. VcfReaders can be made either from a single VCF that covers all the relevant; reference sequences or strictly one VCF per reference sequence. By returning; a defaultdict, any code using the output of this function does not have to; consider whether there are multiple VCFs or not, it can simply query by; chromosome and get a reader. Args:; population_vcf_filenames: Paths to files (VCF or VCF.gz) with population; genotypes. Raises:; ValueError: If there is more than one VCF file containing va",MatchSource.CODE_COMMENT,deepvariant/allele_frequency.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/allele_frequency.py
Usability,simpl,simply,"ssociated with the matching; ALT allele is updated as well. Second, if no matches are found, we try to find inexact matches, where only; REF alleles are matched. The inexact matching step is only used to update REF; allele frequency. If no exact and inexact matches are found, set REF allele; frequency to 1. Args:; candidate_haps: A list of haplotype objects from a candidate.; cohort_haps_and_freqs: A list of haplotype objects from cohorts. Haplotype; objects are stored as dicts: {'haplotype': a haplotype (string), 'alt': an; alt allele (string), 'variant': a Variant proto}. Returns:; A dict with candidate alt alleles as keys, and associated frequencies; as values.; """"""; # Exact haplotype match.; # Update REF frequency if it is not in the dictionary.; # For an unmatched alt allele, set the frequency to 0.; # Calculate REF allele frequency if no exact match was found.; # It is possible a novel mutation happens at a site where there are other; # cohort variants. In this case, we cannot simply set REF frequency to 1.; # Left align variants.; # Try to find inexact matches to set REF allele frequency.; # Inexact matches here mean only REF alleles match.; # If still no match, set REF allele frequency to 1.; """"""Finds the allele frequencies of all the alt alleles for a candidate. Args:; variant: A Variant proto generated by make_examples. Note that it can be; multi-allelic.; population_vcf_reader: A VcfReader object that reads associated VCF file for; a candidate. We want to extract allele frequency information in the VCF.; ref_reader: A IndexedFastaReader object that reads the reference FASTA.; padding_bases: An integer that specifies the number of padding bases added; when performing a VCF query. By default it is set to 0. Returns:; A dict with alleles as keys, and allele frequencies as values; """"""; # Convert to list because we'll look through cohort_variants more than once.; # Init allele frequency dict using alt bases in the candidate.; # If the range associated with vari",MatchSource.CODE_COMMENT,deepvariant/allele_frequency.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/allele_frequency.py
Deployability,patch,patching,"f conditions and the following disclaimer.; #; # 2. Redistributions in binary form must reproduce the above copyright; # notice, this list of conditions and the following disclaimer in the; # documentation and/or other materials provided with the distribution.; #; # 3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Override _save_model in AverageModelCheckpoint to fix a bug (internal).""""""; # TODO: Externally, we can try to use older version of; # average_model_checkpoint.py. For example: r0.13, so that it will be compatible; # to this version we're patching internally.; # pylint: disable=bad-super-call; """"""_save_model from AverageModelCheckpoint is missing the batch arg.""""""; # Use super call two levels up to bypass the problematic function; # Note: `model.get_weights()` gives us the weights (non-ref); # whereas `model.variables` returns references to the variables.; # result is currently None, since `super._save_model` doesn't; # return anything, but this may change in the future.; # Use call two levels up to bypass the problematic function",MatchSource.CODE_COMMENT,deepvariant/average_model_checkpoint_patched.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/average_model_checkpoint_patched.py
Modifiability,variab,variables,"f conditions and the following disclaimer.; #; # 2. Redistributions in binary form must reproduce the above copyright; # notice, this list of conditions and the following disclaimer in the; # documentation and/or other materials provided with the distribution.; #; # 3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Override _save_model in AverageModelCheckpoint to fix a bug (internal).""""""; # TODO: Externally, we can try to use older version of; # average_model_checkpoint.py. For example: r0.13, so that it will be compatible; # to this version we're patching internally.; # pylint: disable=bad-super-call; """"""_save_model from AverageModelCheckpoint is missing the batch arg.""""""; # Use super call two levels up to bypass the problematic function; # Note: `model.get_weights()` gives us the weights (non-ref); # whereas `model.variables` returns references to the variables.; # result is currently None, since `super._save_model` doesn't; # return anything, but this may change in the future.; # Use call two levels up to bypass the problematic function",MatchSource.CODE_COMMENT,deepvariant/average_model_checkpoint_patched.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/average_model_checkpoint_patched.py
Availability,avail,available," promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Calling variants with a trained DeepVariant TF2/Keras model.""""""; # Default, no validation.; # Don't use accelerators, even if available.; # Must be hardware acceleration or an error will be raised.; # The number of digits past the decimal point that genotype likelihoods are; # rounded to, for numerical stability.; """"""Custom callbacks for `predict`.""""""; """"""Returns genotype likelihoods rounded to the desired precision level. Args:; gls: A list of floats. The input genotype likelihoods at any precision.; precision: Positive int. The number of places past the decimal point to; round to. If None, no rounding is performed. Returns:; A list of floats rounded to the desired precision. Raises:; ValueError: The input gls do not sum to nearly 1.; """"""; """"""Write the variant call based on prediction. Args:; writer: A object with a write() function that will be called for each; encoded_variant and genotype likelihoods.; prediction: A [3] tensor of floats. These are the predicted genotype; likelihoods (p00, p0x, pxx) for some alt allele x, in the same order as; encoded_variants.; include_debug_info: If true, inc",MatchSource.CODE_COMMENT,deepvariant/call_variants.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants.py
Performance,perform,performed,"DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Calling variants with a trained DeepVariant TF2/Keras model.""""""; # Default, no validation.; # Don't use accelerators, even if available.; # Must be hardware acceleration or an error will be raised.; # The number of digits past the decimal point that genotype likelihoods are; # rounded to, for numerical stability.; """"""Custom callbacks for `predict`.""""""; """"""Returns genotype likelihoods rounded to the desired precision level. Args:; gls: A list of floats. The input genotype likelihoods at any precision.; precision: Positive int. The number of places past the decimal point to; round to. If None, no rounding is performed. Returns:; A list of floats rounded to the desired precision. Raises:; ValueError: The input gls do not sum to nearly 1.; """"""; """"""Write the variant call based on prediction. Args:; writer: A object with a write() function that will be called for each; encoded_variant and genotype likelihoods.; prediction: A [3] tensor of floats. These are the predicted genotype; likelihoods (p00, p0x, pxx) for some alt allele x, in the same order as; encoded_variants.; include_debug_info: If true, include debug information.; debugging_true_label_mode: If true, include true label from the example. Returns:; The return status from writer.; """"""; # Write it out.; """"""Adds pileup curation to debug_info.""""""; """"""Returns a CallVariantsOutput proto from the relevant input information.""""""; # TODO: Consider creating one data loading function to re-use simliar; # code with training in train_inceptionv3.py.; """"""Parse TFRecords, do image preprocessing, and return the image dataset for inference and t",MatchSource.CODE_COMMENT,deepvariant/call_variants.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants.py
Safety,predict,predict,"UDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Calling variants with a trained DeepVariant TF2/Keras model.""""""; # Default, no validation.; # Don't use accelerators, even if available.; # Must be hardware acceleration or an error will be raised.; # The number of digits past the decimal point that genotype likelihoods are; # rounded to, for numerical stability.; """"""Custom callbacks for `predict`.""""""; """"""Returns genotype likelihoods rounded to the desired precision level. Args:; gls: A list of floats. The input genotype likelihoods at any precision.; precision: Positive int. The number of places past the decimal point to; round to. If None, no rounding is performed. Returns:; A list of floats rounded to the desired precision. Raises:; ValueError: The input gls do not sum to nearly 1.; """"""; """"""Write the variant call based on prediction. Args:; writer: A object with a write() function that will be called for each; encoded_variant and genotype likelihoods.; prediction: A [3] tensor of floats. These are the predicted genotype; likelihoods (p00, p0x, pxx) for some alt allele x, in the same order as; encoded_variants.; include_debug_info: If true, include debug information.; debugging_true_label_mode: If true, include true label from the example. Returns:; The return status from writer.; """"""; # Write it out.; """"""Adds pileup curation to debug_info.""""""; """"""Returns a C",MatchSource.CODE_COMMENT,deepvariant/call_variants.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants.py
Security,validat,validation,"contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Calling variants with a trained DeepVariant TF2/Keras model.""""""; # Default, no validation.; # Don't use accelerators, even if available.; # Must be hardware acceleration or an error will be raised.; # The number of digits past the decimal point that genotype likelihoods are; # rounded to, for numerical stability.; """"""Custom callbacks for `predict`.""""""; """"""Returns genotype likelihoods rounded to the desired precision level. Args:; gls: A list of floats. The input genotype likelihoods at any precision.; precision: Positive int. The number of places past the decimal point to; round to. If None, no rounding is performed. Returns:; A list of floats rounded to the desired precision. Raises:; ValueError: The input gls do not sum to nearly 1.; """"""; """"""Write the variant call based on prediction. Args:; writer: A object with a write() function that will be called for each; encoded_variant and genotype likelihoods.; prediction: A [3] tensor of floats. These are the predicted genotype; likelihoods (p00, p0x, pxx) for some alt allele x, in the same order as; encoded_varia",MatchSource.CODE_COMMENT,deepvariant/call_variants.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants.py
Availability,avail,available,"r promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Code for calling variants with a trained DeepVariant model.""""""; # Default, no validation.; # Don't use accelerators, even if available.; # Must be hardware acceleration or an error will be raised.; # The number of digits past the decimal point that genotype likelihoods are; # rounded to, for numerical stability.; # This number is estimated by the following logic:; # For a sample with 10,000,000 examples, if we log every 50,000 examples,; # there will be 200 lines per sample.; # Cloud TPU Cluster Resolvers; # pylint: disable=line-too-long; """"""Return a tf.data input_fn from the source_path. Args:; source_path: Path to a TFRecord file containing deepvariant tf.Example; protos.; use_tpu: boolean. Use the tpu code path.; num_readers: int > 0 or None. Number of parallel readers to use to read; examples from source_path. If None, uses FLAGS.num_readers instead. Returns:; A tf input_fn yielding batches of image, encoded_variant,; encoded_alt_allele_indices. The image is a [batch_size, height, width, channel] tensor. The; encoded_variants is a tf.string or tpu-encoded tensor containing a; serialized Vari",MatchSource.CODE_COMMENT,deepvariant/call_variants_slim.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants_slim.py
Performance,perform,performed,"eepvariant tf.Example; protos.; use_tpu: boolean. Use the tpu code path.; num_readers: int > 0 or None. Number of parallel readers to use to read; examples from source_path. If None, uses FLAGS.num_readers instead. Returns:; A tf input_fn yielding batches of image, encoded_variant,; encoded_alt_allele_indices. The image is a [batch_size, height, width, channel] tensor. The; encoded_variants is a tf.string or tpu-encoded tensor containing a; serialized Variant proto describing the variant call associated with; image. The encoded_alt_allele_indices is a tf.string or tpu-encoded; tensor containing a serialized CallVariantsOutput.AltAlleleIndices proto; containing the alternate alleles indices used as ""alt"" when constructing; the image.; """"""; """"""Returns genotype likelihoods rounded to the desired precision level. Args:; gls: A list of floats. The input genotype likelihoods at any precision.; precision: Positive int. The number of places past the decimal point to; round to. If None, no rounding is performed. Returns:; A list of floats rounded to the desired precision. Raises:; ValueError: The input gls do not sum to nearly 1.; """"""; """"""Write the variant call based on prediction. Args:; writer: A object with a write() function that will be called for each; encoded_variant and genotype likelihoods.; prediction: A [3] tensor of floats. These are the predicted genotype; likelihoods (p00, p0x, pxx) for some alt allele x, in the same order as; encoded_variants.; use_tpu: bool. Decode the tpu specific encoding of prediction. Returns:; The return status from writer.; """"""; # Write it out.; """"""Returns a CallVariantsOutput proto from the relevant input information.""""""; """"""Main driver of call_variants.""""""; # Read a single TFExample to make sure we're not loading an older version.; # Check if the checkpoint_path has the same shape.; # For a shape map of [3, 3, 6, 32] for the Conv2d_1a_3x3 layer, the 6; # is the number of channels.; # We can consider more strictly enforcing this.; # Che",MatchSource.CODE_COMMENT,deepvariant/call_variants_slim.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants_slim.py
Safety,predict,prediction,"rce_path. If None, uses FLAGS.num_readers instead. Returns:; A tf input_fn yielding batches of image, encoded_variant,; encoded_alt_allele_indices. The image is a [batch_size, height, width, channel] tensor. The; encoded_variants is a tf.string or tpu-encoded tensor containing a; serialized Variant proto describing the variant call associated with; image. The encoded_alt_allele_indices is a tf.string or tpu-encoded; tensor containing a serialized CallVariantsOutput.AltAlleleIndices proto; containing the alternate alleles indices used as ""alt"" when constructing; the image.; """"""; """"""Returns genotype likelihoods rounded to the desired precision level. Args:; gls: A list of floats. The input genotype likelihoods at any precision.; precision: Positive int. The number of places past the decimal point to; round to. If None, no rounding is performed. Returns:; A list of floats rounded to the desired precision. Raises:; ValueError: The input gls do not sum to nearly 1.; """"""; """"""Write the variant call based on prediction. Args:; writer: A object with a write() function that will be called for each; encoded_variant and genotype likelihoods.; prediction: A [3] tensor of floats. These are the predicted genotype; likelihoods (p00, p0x, pxx) for some alt allele x, in the same order as; encoded_variants.; use_tpu: bool. Decode the tpu specific encoding of prediction. Returns:; The return status from writer.; """"""; # Write it out.; """"""Returns a CallVariantsOutput proto from the relevant input information.""""""; """"""Main driver of call_variants.""""""; # Read a single TFExample to make sure we're not loading an older version.; # Check if the checkpoint_path has the same shape.; # For a shape map of [3, 3, 6, 32] for the Conv2d_1a_3x3 layer, the 6; # is the number of channels.; # We can consider more strictly enforcing this.; # Check accelerator status.; # Don't overwrite entire dictionary.; # Perform sanity check.; # TODO. Sort out auto-detection of TPU. Just calling; # sess.list_devices her",MatchSource.CODE_COMMENT,deepvariant/call_variants_slim.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants_slim.py
Security,validat,validation," contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Code for calling variants with a trained DeepVariant model.""""""; # Default, no validation.; # Don't use accelerators, even if available.; # Must be hardware acceleration or an error will be raised.; # The number of digits past the decimal point that genotype likelihoods are; # rounded to, for numerical stability.; # This number is estimated by the following logic:; # For a sample with 10,000,000 examples, if we log every 50,000 examples,; # there will be 200 lines per sample.; # Cloud TPU Cluster Resolvers; # pylint: disable=line-too-long; """"""Return a tf.data input_fn from the source_path. Args:; source_path: Path to a TFRecord file containing deepvariant tf.Example; protos.; use_tpu: boolean. Use the tpu code path.; num_readers: int > 0 or None. Number of parallel readers to use to read; examples from source_path. If None, uses FLAGS.num_readers instead. Returns:; A tf input_fn yielding batches of image, encoded_variant,; encoded_alt_allele_indices. The image is a [batch_size, height, width, channel] tensor. The; encoded_variants is a tf.string or tpu-encode",MatchSource.CODE_COMMENT,deepvariant/call_variants_slim.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants_slim.py
Testability,log,logic,"ABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Code for calling variants with a trained DeepVariant model.""""""; # Default, no validation.; # Don't use accelerators, even if available.; # Must be hardware acceleration or an error will be raised.; # The number of digits past the decimal point that genotype likelihoods are; # rounded to, for numerical stability.; # This number is estimated by the following logic:; # For a sample with 10,000,000 examples, if we log every 50,000 examples,; # there will be 200 lines per sample.; # Cloud TPU Cluster Resolvers; # pylint: disable=line-too-long; """"""Return a tf.data input_fn from the source_path. Args:; source_path: Path to a TFRecord file containing deepvariant tf.Example; protos.; use_tpu: boolean. Use the tpu code path.; num_readers: int > 0 or None. Number of parallel readers to use to read; examples from source_path. If None, uses FLAGS.num_readers instead. Returns:; A tf input_fn yielding batches of image, encoded_variant,; encoded_alt_allele_indices. The image is a [batch_size, height, width, channel] tensor. The; encoded_variants is a tf.string or tpu-encoded tensor containing a; serialized Variant proto describing the variant call associated with; image. The encoded_alt_allele_indices is a tf.string or tpu-encoded; tensor containing a serialized CallVariantsOutput.AltAlleleIndices proto; containing the alternate alleles indices used as ""alt"" when constructing; the image.; ",MatchSource.CODE_COMMENT,deepvariant/call_variants_slim.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants_slim.py
Availability,checkpoint,checkpoint,"DERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for deepvariant .call_variants_slim.""""""; # NB. This entire collection of tests will be invoked with '--use_tpu=' 'true'; # and 'false' by the BUILD file, and a tpu device will be allocated when; # necessary.; # For tests that don't actually want to read a real checkpoint,; # return a fake one. The estimator understands None to mean; # that all the variables should be left uninitialized.; # Return the stream of batched images from a dataset.; """"""Provides batches of pileup images from this dataset. This instantiates an iterator on the dataset, and returns the; image, variant, alt_allele_indices, features in batches. It calls; model.preprocess_images on the images (but note that we will be moving; that step into model_fn for the Estimator api). Args:; tf_dataset: DeepVariantInput.; model: DeepVariantModel.; batch_size: int. The batch size. Returns:; (image, variant, alt_allele_indices). Raises:; ValueError: if the dataset has the wrong mode.; """"""; # tensor_shape will be None if the input was an empty file.; # Check that we have the right number of output protos.; # Check that we have the right number of output protos.; # Get only up to 10 examples.; # Write to 15 shards, which means there will be multiple empty shards.; # Get only up ",MatchSource.CODE_COMMENT,deepvariant/call_variants_slim_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants_slim_test.py
Energy Efficiency,allocate,allocated,"erived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for deepvariant .call_variants_slim.""""""; # NB. This entire collection of tests will be invoked with '--use_tpu=' 'true'; # and 'false' by the BUILD file, and a tpu device will be allocated when; # necessary.; # For tests that don't actually want to read a real checkpoint,; # return a fake one. The estimator understands None to mean; # that all the variables should be left uninitialized.; # Return the stream of batched images from a dataset.; """"""Provides batches of pileup images from this dataset. This instantiates an iterator on the dataset, and returns the; image, variant, alt_allele_indices, features in batches. It calls; model.preprocess_images on the images (but note that we will be moving; that step into model_fn for the Estimator api). Args:; tf_dataset: DeepVariantInput.; model: DeepVariantModel.; batch_size: int. The batch size. Returns:; (image, variant, alt_allele_indices). Raises:; ValueError: if the dataset has the wrong mode.; """"""; # tensor_shape will be None if the input was an empty file.; # Check that we have the right number of output protos.; # Check that we have the right number of output pr",MatchSource.CODE_COMMENT,deepvariant/call_variants_slim_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants_slim_test.py
Modifiability,variab,variables,"LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for deepvariant .call_variants_slim.""""""; # NB. This entire collection of tests will be invoked with '--use_tpu=' 'true'; # and 'false' by the BUILD file, and a tpu device will be allocated when; # necessary.; # For tests that don't actually want to read a real checkpoint,; # return a fake one. The estimator understands None to mean; # that all the variables should be left uninitialized.; # Return the stream of batched images from a dataset.; """"""Provides batches of pileup images from this dataset. This instantiates an iterator on the dataset, and returns the; image, variant, alt_allele_indices, features in batches. It calls; model.preprocess_images on the images (but note that we will be moving; that step into model_fn for the Estimator api). Args:; tf_dataset: DeepVariantInput.; model: DeepVariantModel.; batch_size: int. The batch size. Returns:; (image, variant, alt_allele_indices). Raises:; ValueError: if the dataset has the wrong mode.; """"""; # tensor_shape will be None if the input was an empty file.; # Check that we have the right number of output protos.; # Check that we have the right number of output protos.; # Get only up to 10 examples.; # Write to 15 shards, which means there will be multiple empty shards.; # Get only up to 10 examples.; # Create a sharded version of our golden examples.; # If we point the test",MatchSource.CODE_COMMENT,deepvariant/call_variants_slim_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants_slim_test.py
Safety,predict,predict,"s that at least some of the `true_label`s are filled.; # pylint: disable=g-complex-comprehension; # pylint: enable=g-complex-comprehension; # Check that we have the right number of output protos.; # Check that our CallVariantsOutput (CVO) have the following critical; # properties:; # - we have one CVO for each example we processed.; # - the variant in the CVO is exactly what was in the example.; # - the alt_allele_indices of the CVO match those of its corresponding; # example.; # - there are 3 genotype probabilities and these are between 0.0 and 1.0.; # We can only do this test when processing all of the variants (max_batches; # is None), since we processed all of the examples with that model.; # Check the CVO debug_info: not filled if include_debug_info is False;; # else, filled by logic based on CVO.; # Find all matching examples.; # We should have exactly one match.; # Check that we've faithfully copied in the alt alleles (though currently; # as implemented we find our example using this information so it cannot; # fail). Included here in case that changes in the future.; # We should have exactly three genotype probabilities (assuming our; # ploidy == 2).; # These are probabilities so they should be between 0 and 1.; # Read one good record from a valid file.; # Remove image/shape.; # Make sure that prepare_inputs don't crash on empty input.; # The API specifies that OutOfRangeError is thrown in this case.; # file_string_input could be a comma-separated list. Add the prefix to all; # of them, and join it back to a string.; # predict batch size must be divisible by number of replicas.; # We cannot access the full _DeviceAttribute as it's not exported. So use a; # namedtuple with the same field names instead.; # Mocking the list_devices call means the framework attempts to use a bogus; # TPU device, which fails, so don't do that. Handle the TPU case elsewhere.; # Only run the tpu cases when we have an actual tpu device, supplied; # by the flags from the BUILD rule.",MatchSource.CODE_COMMENT,deepvariant/call_variants_slim_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants_slim_test.py
Security,access,access,"s that at least some of the `true_label`s are filled.; # pylint: disable=g-complex-comprehension; # pylint: enable=g-complex-comprehension; # Check that we have the right number of output protos.; # Check that our CallVariantsOutput (CVO) have the following critical; # properties:; # - we have one CVO for each example we processed.; # - the variant in the CVO is exactly what was in the example.; # - the alt_allele_indices of the CVO match those of its corresponding; # example.; # - there are 3 genotype probabilities and these are between 0.0 and 1.0.; # We can only do this test when processing all of the variants (max_batches; # is None), since we processed all of the examples with that model.; # Check the CVO debug_info: not filled if include_debug_info is False;; # else, filled by logic based on CVO.; # Find all matching examples.; # We should have exactly one match.; # Check that we've faithfully copied in the alt alleles (though currently; # as implemented we find our example using this information so it cannot; # fail). Included here in case that changes in the future.; # We should have exactly three genotype probabilities (assuming our; # ploidy == 2).; # These are probabilities so they should be between 0 and 1.; # Read one good record from a valid file.; # Remove image/shape.; # Make sure that prepare_inputs don't crash on empty input.; # The API specifies that OutOfRangeError is thrown in this case.; # file_string_input could be a comma-separated list. Add the prefix to all; # of them, and join it back to a string.; # predict batch size must be divisible by number of replicas.; # We cannot access the full _DeviceAttribute as it's not exported. So use a; # namedtuple with the same field names instead.; # Mocking the list_devices call means the framework attempts to use a bogus; # TPU device, which fails, so don't do that. Handle the TPU case elsewhere.; # Only run the tpu cases when we have an actual tpu device, supplied; # by the flags from the BUILD rule.",MatchSource.CODE_COMMENT,deepvariant/call_variants_slim_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants_slim_test.py
Testability,test,tests,"erived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for deepvariant .call_variants_slim.""""""; # NB. This entire collection of tests will be invoked with '--use_tpu=' 'true'; # and 'false' by the BUILD file, and a tpu device will be allocated when; # necessary.; # For tests that don't actually want to read a real checkpoint,; # return a fake one. The estimator understands None to mean; # that all the variables should be left uninitialized.; # Return the stream of batched images from a dataset.; """"""Provides batches of pileup images from this dataset. This instantiates an iterator on the dataset, and returns the; image, variant, alt_allele_indices, features in batches. It calls; model.preprocess_images on the images (but note that we will be moving; that step into model_fn for the Estimator api). Args:; tf_dataset: DeepVariantInput.; model: DeepVariantModel.; batch_size: int. The batch size. Returns:; (image, variant, alt_allele_indices). Raises:; ValueError: if the dataset has the wrong mode.; """"""; # tensor_shape will be None if the input was an empty file.; # Check that we have the right number of output protos.; # Check that we have the right number of output pr",MatchSource.CODE_COMMENT,deepvariant/call_variants_slim_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants_slim_test.py
Testability,test,test,"right 2023 Google LLC.; #; # Redistribution and use in source and binary forms, with or without; # modification, are permitted provided that the following conditions; # are met:; #; # 1. Redistributions of source code must retain the above copyright notice,; # this list of conditions and the following disclaimer.; #; # 2. Redistributions in binary form must reproduce the above copyright; # notice, this list of conditions and the following disclaimer in the; # documentation and/or other materials provided with the distribution.; #; # 3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Test cases for call variants.""""""; # Load in test data and get input shape; # Input a sharded version of our golden examples; # Load and save a model with random weights; # set up output directory; # Run end to end variant calling; # Assert; # Check that we have the right number of output protos; # Let's just check the first record.; # Make sure all the pileup_curation_* fields are filled.; # Because all the meaningful values are > 0, we'll check that they are >0.",MatchSource.CODE_COMMENT,deepvariant/call_variants_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants_test.py
Availability,checkpoint,checkpoint," above copyright; # notice, this list of conditions and the following disclaimer in the; # documentation and/or other materials provided with the distribution.; #; # 3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; # Outputs:; # Model checkpoint:; """"""Initializes the model and gathers parameters. Args:; example_info_json: Path to json file containing example shape.; checkpoint_path: Path to model checkpoint. Returns:; An initialized model.; """"""; # Load model; # model.load_weights(checkpoint_path).expect_partial(); # checkpoint = tf.train.Checkpoint(model=model); # Note that the `print_model_summary` is necessary because we need to run a; # forward pass with the model in order for assert_existing_objects_matched to; # work as expected. If you don't do this, then assert_existing_objects_matched; # will not raise an error even if the wrong checkpoint is used.; # Some context here: internal.; # checkpoint.restore(; # checkpoint_path; # ).expect_partial().assert_existing_objects_matched(); """"""Main entry point.""""""; # Copy over the example_info.json.",MatchSource.CODE_COMMENT,deepvariant/convert_to_saved_model.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/convert_to_saved_model.py
Integrability,wrap,wrapping,"N; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Library code for creating visual reports or dashboards from Altair charts. This is used by different dashboards that have multiple Altair charts to put; together into a single report or dashboard.; """"""; """"""; <style>; body {; font-family: sans-serif;; }; .chart-container {; padding: 30px;; }; .dataframe {; border-collapse: collapse;; white-space: nowrap;; }; .dataframe tr:nth-child(even){background-color: #ddd;}; .dataframe td,th {; border: 1px solid #ddd;; padding: 8px;; }; .dataframe tr:hover {background-color: #a8a8a8;}; .dataframe th {; text-align: left;; background-color: #4c78a8;; padding-top: 12px;; padding-bottom: 12px;; color: white;; }; .chart-container {; padding: 30px;; }; </style>; """"""; """"""Makes the html report with all the charts inserted. Args:; specs: A list of dictionaries with keys ""id"" (unique name) and either; ""chart"" (should be an Altair chart object) or ""html"" (a string to be; inserted as html into the report).; html_output: A writable file object.; title: The title to show at the top of the report.; subtitle: The subtitle to show just below the title on the report.; charts_on_separate_lines: Put charts on separate lines. If false, charts; will set next to each other as space allows and flow to the next line,; similar to text wrapping.; include_outline: If true, an outline with chart IDs will be added on top. Returns:; None. Writes into the html_output file object.; """"""; # First sanity check input specs list.; # Start the HTML document.; # Add dependencies vega and vega-lite, which render the altair charts.; # Add styles (CSS).; # Titles; # Make a div containing all the charts.; # End the chart container and start the JavaScript section.; # Add JSON vega specs and hook them up to the divs with VegaEmbed.; # pylint: disable=bare-except; # Close HTML document.",MatchSource.CODE_COMMENT,deepvariant/dashboard_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/dashboard_utils.py
Safety,sanity check,sanity check,"N; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Library code for creating visual reports or dashboards from Altair charts. This is used by different dashboards that have multiple Altair charts to put; together into a single report or dashboard.; """"""; """"""; <style>; body {; font-family: sans-serif;; }; .chart-container {; padding: 30px;; }; .dataframe {; border-collapse: collapse;; white-space: nowrap;; }; .dataframe tr:nth-child(even){background-color: #ddd;}; .dataframe td,th {; border: 1px solid #ddd;; padding: 8px;; }; .dataframe tr:hover {background-color: #a8a8a8;}; .dataframe th {; text-align: left;; background-color: #4c78a8;; padding-top: 12px;; padding-bottom: 12px;; color: white;; }; .chart-container {; padding: 30px;; }; </style>; """"""; """"""Makes the html report with all the charts inserted. Args:; specs: A list of dictionaries with keys ""id"" (unique name) and either; ""chart"" (should be an Altair chart object) or ""html"" (a string to be; inserted as html into the report).; html_output: A writable file object.; title: The title to show at the top of the report.; subtitle: The subtitle to show just below the title on the report.; charts_on_separate_lines: Put charts on separate lines. If false, charts; will set next to each other as space allows and flow to the next line,; similar to text wrapping.; include_outline: If true, an outline with chart IDs will be added on top. Returns:; None. Writes into the html_output file object.; """"""; # First sanity check input specs list.; # Start the HTML document.; # Add dependencies vega and vega-lite, which render the altair charts.; # Add styles (CSS).; # Titles; # Make a div containing all the charts.; # End the chart container and start the JavaScript section.; # Add JSON vega specs and hook them up to the divs with VegaEmbed.; # pylint: disable=bare-except; # Close HTML document.",MatchSource.CODE_COMMENT,deepvariant/dashboard_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/dashboard_utils.py
Availability,error,error,"olean. If true, the input examples are; created with ""training"" mode. We'll parse the 'label' field even if the; `mode` is PREDICT. Raises:; ValueError: if `num_examples` not provided, in a context requiring it.; """"""; # We update our num_examples in the situation where num_examples is set; # (i.e., is not None) to the smaller of max_examples and num_examples.; """"""Returns a dict describing features from a TF.example.""""""; # N.B. int32 fails here on TPU.; """"""Parse a DeepVariant pileup tf.Example to features and labels. This potentially stores parsed strings as fixed length tensors of integers,; as required by TPU. They have to be handled properly by consumers. Args:; tf_example: a serialized tf.Example for a DeepVariant ""pileup"". Returns:; If (mode is EVAL or TRAIN) or debugging_true_label_mode:; (features, label) ...; If mode is PREDICT,; features ...; """"""; # If the input is empty there won't be a tensor_shape.; # Cast to int32 for loading onto the TPU; # Passing a string to a TPU draws this error: TypeError: <dtype:; # 'string'> is not a supported TPU infeed type. Supported types are:; # [tf.float32, tf.int32, tf.complex64, tf.int64, tf.bool, tf.bfloat16]; # Thus, we must encode the string as a tensor of int.; # Add variant_type to our features if are in TRAIN or EVAL mode.; # For predict model, label is not present. So, returns features only.; """"""Interface to get a data batch, fulfilling `input_fn` contract. Args:; params: a dict containing an integer value for key 'batch_size'. Returns:; the tuple (features, labels), where:; - features is a dict of Tensor-valued input features; keys populated; are:; 'image'; 'variant'; 'alt_allele_indices'; and, if not PREDICT mode, also:; 'locus'. Aside from 'image', these may be encoded specially for TPU. - label is the Tensor-valued prediction label; in train/eval; mode the label value is is populated from the data source; in; inference mode, the value is a constant empty Tensor value ""()"".; """"""; # See https://cloud.google.com/tp",MatchSource.CODE_COMMENT,deepvariant/data_providers.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers.py
Deployability,configurat,configuration,"TA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Data providers for deepvariant images. tf.data.Dataset and data providers for standard DeepVariant datasets for; training and evaluating germline calling accuracy.; """"""; # These are empirically determined to work well on TPU with our data sets,; # where lots of buffering and concurrency is necessary to keep the device; # busy.; # These are settable in the constructor.; """"""Generates a function for parsing tf.train.Examples.""""""; """"""Parses a serialized tf.Example, preprocesses the image, and one-hot encodes the label.""""""; # Preprocess image; """"""tf.data.Dataset loading function. Args:; path: the input filename for a tfrecord[.gz] file containing examples. Can; contain sharding designators.; config: A configuration file.; mode: One of ['train', 'tune', 'predict']; strategy: A tf.distribute.Strategy.; n_epochs: Number of epochs.; limit: Limit the number of batches for testing purposes. Returns:; tf.data.Dataset; """"""; # Get input shape from input path.; # Retrieve preprocess function; # Limit the number of batches.; # Prefetch overlaps in-feed with training; # Distribute the dataset; """"""This class serves as an `input_fn` for the `tf.estimator` framework.""""""; # Calling this object like a function returns a stream of variadic tuples.; # Essentially it is a buffered io library, that handles concurrently; # reading and possibly shuffling input records from a set of files. It; # knows how to parse features we care about from tf.examples. It records; # some extra information about the source of the input, such as the name; # and number of classes.; """"""Create a DeepVariantInput object, usable as an `input_fn`. Args:; mode: the mode string (from `tf.estimator.ModeKeys`).; input_file_spec: the inp",MatchSource.CODE_COMMENT,deepvariant/data_providers.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers.py
Energy Efficiency,schedul,schedule,"; tf.data.Dataset; """"""; # Get input shape from input path.; # Retrieve preprocess function; # Limit the number of batches.; # Prefetch overlaps in-feed with training; # Distribute the dataset; """"""This class serves as an `input_fn` for the `tf.estimator` framework.""""""; # Calling this object like a function returns a stream of variadic tuples.; # Essentially it is a buffered io library, that handles concurrently; # reading and possibly shuffling input records from a set of files. It; # knows how to parse features we care about from tf.examples. It records; # some extra information about the source of the input, such as the name; # and number of classes.; """"""Create a DeepVariantInput object, usable as an `input_fn`. Args:; mode: the mode string (from `tf.estimator.ModeKeys`).; input_file_spec: the input filename for a tfrecord[.gz] file containing; examples. Can contain sharding designators.; num_examples: the number of examples contained in the input file. Required; for setting learning rate schedule in train/eval only.; num_classes: The number of classes in the labels of this dataset.; Currently defaults to DEFAULT_NUM_CLASSES.; max_examples: The maximum number of examples to use. If None, all examples; will be used. If not None, the first n = min(max_examples, num_examples); will be used. This works with training, and the n examples will repeat; over and over.; tensor_shape: None (which means we get the shape from the first example in; source), or list of int [height, width, channel] for testing.; name: string, name of the dataset.; use_tpu: use code paths tuned for TPU, in particular protobuf encoding.; Default False.; input_read_threads: number of threads for reading data. Default 32.; shuffle_buffer_size: size of the final shuffle buffer, in elements.; Default 100.; initial_shuffle_buffer_size: int; the size of the dataset.shuffle buffer; in elements. Default is 1024.; prefetch_dataset_buffer_size: int; the size of the TFRecordDataset buffer; in bytes. Default is ",MatchSource.CODE_COMMENT,deepvariant/data_providers.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers.py
Integrability,contract,contract,"res from a TF.example.""""""; # N.B. int32 fails here on TPU.; """"""Parse a DeepVariant pileup tf.Example to features and labels. This potentially stores parsed strings as fixed length tensors of integers,; as required by TPU. They have to be handled properly by consumers. Args:; tf_example: a serialized tf.Example for a DeepVariant ""pileup"". Returns:; If (mode is EVAL or TRAIN) or debugging_true_label_mode:; (features, label) ...; If mode is PREDICT,; features ...; """"""; # If the input is empty there won't be a tensor_shape.; # Cast to int32 for loading onto the TPU; # Passing a string to a TPU draws this error: TypeError: <dtype:; # 'string'> is not a supported TPU infeed type. Supported types are:; # [tf.float32, tf.int32, tf.complex64, tf.int64, tf.bool, tf.bfloat16]; # Thus, we must encode the string as a tensor of int.; # Add variant_type to our features if are in TRAIN or EVAL mode.; # For predict model, label is not present. So, returns features only.; """"""Interface to get a data batch, fulfilling `input_fn` contract. Args:; params: a dict containing an integer value for key 'batch_size'. Returns:; the tuple (features, labels), where:; - features is a dict of Tensor-valued input features; keys populated; are:; 'image'; 'variant'; 'alt_allele_indices'; and, if not PREDICT mode, also:; 'locus'. Aside from 'image', these may be encoded specially for TPU. - label is the Tensor-valued prediction label; in train/eval; mode the label value is is populated from the data source; in; inference mode, the value is a constant empty Tensor value ""()"".; """"""; # See https://cloud.google.com/tpu/docs/tutorials/inception-v3-advanced; # for some background on tuning this on TPU.; # TPU optimized implementation for prediction mode; # Optimized following:; # https://www.tensorflow.org/guide/performance/datasets; # using the information available from xprof.; # NOTE: The order of the file names returned can be non-deterministic,; # even if shuffle is false. See internal and the note in in",MatchSource.CODE_COMMENT,deepvariant/data_providers.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers.py
Modifiability,config,config,"TA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Data providers for deepvariant images. tf.data.Dataset and data providers for standard DeepVariant datasets for; training and evaluating germline calling accuracy.; """"""; # These are empirically determined to work well on TPU with our data sets,; # where lots of buffering and concurrency is necessary to keep the device; # busy.; # These are settable in the constructor.; """"""Generates a function for parsing tf.train.Examples.""""""; """"""Parses a serialized tf.Example, preprocesses the image, and one-hot encodes the label.""""""; # Preprocess image; """"""tf.data.Dataset loading function. Args:; path: the input filename for a tfrecord[.gz] file containing examples. Can; contain sharding designators.; config: A configuration file.; mode: One of ['train', 'tune', 'predict']; strategy: A tf.distribute.Strategy.; n_epochs: Number of epochs.; limit: Limit the number of batches for testing purposes. Returns:; tf.data.Dataset; """"""; # Get input shape from input path.; # Retrieve preprocess function; # Limit the number of batches.; # Prefetch overlaps in-feed with training; # Distribute the dataset; """"""This class serves as an `input_fn` for the `tf.estimator` framework.""""""; # Calling this object like a function returns a stream of variadic tuples.; # Essentially it is a buffered io library, that handles concurrently; # reading and possibly shuffling input records from a set of files. It; # knows how to parse features we care about from tf.examples. It records; # some extra information about the source of the input, such as the name; # and number of classes.; """"""Create a DeepVariantInput object, usable as an `input_fn`. Args:; mode: the mode string (from `tf.estimator.ModeKeys`).; input_file_spec: the inp",MatchSource.CODE_COMMENT,deepvariant/data_providers.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers.py
Performance,concurren,concurrency,"PYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Data providers for deepvariant images. tf.data.Dataset and data providers for standard DeepVariant datasets for; training and evaluating germline calling accuracy.; """"""; # These are empirically determined to work well on TPU with our data sets,; # where lots of buffering and concurrency is necessary to keep the device; # busy.; # These are settable in the constructor.; """"""Generates a function for parsing tf.train.Examples.""""""; """"""Parses a serialized tf.Example, preprocesses the image, and one-hot encodes the label.""""""; # Preprocess image; """"""tf.data.Dataset loading function. Args:; path: the input filename for a tfrecord[.gz] file containing examples. Can; contain sharding designators.; config: A configuration file.; mode: One of ['train', 'tune', 'predict']; strategy: A tf.distribute.Strategy.; n_epochs: Number of epochs.; limit: Limit the number of batches for testing purposes. Returns:; tf.data.Dataset; """"""; # Get input shape from input path.; # Retrieve preprocess function; # Limit the number of batches.; # Prefetch overlaps in-feed with training; # Distribute the dataset; """"""This class serves as an `input_fn` for the `tf.estimator` framework.""""""; # Calling this object like a function returns a stream of variadic tuples.; ",MatchSource.CODE_COMMENT,deepvariant/data_providers.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers.py
Safety,predict,predict,"OWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Data providers for deepvariant images. tf.data.Dataset and data providers for standard DeepVariant datasets for; training and evaluating germline calling accuracy.; """"""; # These are empirically determined to work well on TPU with our data sets,; # where lots of buffering and concurrency is necessary to keep the device; # busy.; # These are settable in the constructor.; """"""Generates a function for parsing tf.train.Examples.""""""; """"""Parses a serialized tf.Example, preprocesses the image, and one-hot encodes the label.""""""; # Preprocess image; """"""tf.data.Dataset loading function. Args:; path: the input filename for a tfrecord[.gz] file containing examples. Can; contain sharding designators.; config: A configuration file.; mode: One of ['train', 'tune', 'predict']; strategy: A tf.distribute.Strategy.; n_epochs: Number of epochs.; limit: Limit the number of batches for testing purposes. Returns:; tf.data.Dataset; """"""; # Get input shape from input path.; # Retrieve preprocess function; # Limit the number of batches.; # Prefetch overlaps in-feed with training; # Distribute the dataset; """"""This class serves as an `input_fn` for the `tf.estimator` framework.""""""; # Calling this object like a function returns a stream of variadic tuples.; # Essentially it is a buffered io library, that handles concurrently; # reading and possibly shuffling input records from a set of files. It; # knows how to parse features we care about from tf.examples. It records; # some extra information about the source of the input, such as the name; # and number of classes.; """"""Create a DeepVariantInput object, usable as an `input_fn`. Args:; mode: the mode string (from `tf.estimator.ModeKeys`).; input_file_spec: the input filename for a tfrecord[.gz] file containi",MatchSource.CODE_COMMENT,deepvariant/data_providers.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers.py
Testability,test,testing,"EGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Data providers for deepvariant images. tf.data.Dataset and data providers for standard DeepVariant datasets for; training and evaluating germline calling accuracy.; """"""; # These are empirically determined to work well on TPU with our data sets,; # where lots of buffering and concurrency is necessary to keep the device; # busy.; # These are settable in the constructor.; """"""Generates a function for parsing tf.train.Examples.""""""; """"""Parses a serialized tf.Example, preprocesses the image, and one-hot encodes the label.""""""; # Preprocess image; """"""tf.data.Dataset loading function. Args:; path: the input filename for a tfrecord[.gz] file containing examples. Can; contain sharding designators.; config: A configuration file.; mode: One of ['train', 'tune', 'predict']; strategy: A tf.distribute.Strategy.; n_epochs: Number of epochs.; limit: Limit the number of batches for testing purposes. Returns:; tf.data.Dataset; """"""; # Get input shape from input path.; # Retrieve preprocess function; # Limit the number of batches.; # Prefetch overlaps in-feed with training; # Distribute the dataset; """"""This class serves as an `input_fn` for the `tf.estimator` framework.""""""; # Calling this object like a function returns a stream of variadic tuples.; # Essentially it is a buffered io library, that handles concurrently; # reading and possibly shuffling input records from a set of files. It; # knows how to parse features we care about from tf.examples. It records; # some extra information about the source of the input, such as the name; # and number of classes.; """"""Create a DeepVariantInput object, usable as an `input_fn`. Args:; mode: the mode string (from `tf.estimator.ModeKeys`).; input_file_spec: the input filename for a tfrecord[.gz] file containing; examples. Can contain sharding designators.; num_examples: the number of examples contained in the input",MatchSource.CODE_COMMENT,deepvariant/data_providers.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers.py
Usability,usab,usable,"th: the input filename for a tfrecord[.gz] file containing examples. Can; contain sharding designators.; config: A configuration file.; mode: One of ['train', 'tune', 'predict']; strategy: A tf.distribute.Strategy.; n_epochs: Number of epochs.; limit: Limit the number of batches for testing purposes. Returns:; tf.data.Dataset; """"""; # Get input shape from input path.; # Retrieve preprocess function; # Limit the number of batches.; # Prefetch overlaps in-feed with training; # Distribute the dataset; """"""This class serves as an `input_fn` for the `tf.estimator` framework.""""""; # Calling this object like a function returns a stream of variadic tuples.; # Essentially it is a buffered io library, that handles concurrently; # reading and possibly shuffling input records from a set of files. It; # knows how to parse features we care about from tf.examples. It records; # some extra information about the source of the input, such as the name; # and number of classes.; """"""Create a DeepVariantInput object, usable as an `input_fn`. Args:; mode: the mode string (from `tf.estimator.ModeKeys`).; input_file_spec: the input filename for a tfrecord[.gz] file containing; examples. Can contain sharding designators.; num_examples: the number of examples contained in the input file. Required; for setting learning rate schedule in train/eval only.; num_classes: The number of classes in the labels of this dataset.; Currently defaults to DEFAULT_NUM_CLASSES.; max_examples: The maximum number of examples to use. If None, all examples; will be used. If not None, the first n = min(max_examples, num_examples); will be used. This works with training, and the n examples will repeat; over and over.; tensor_shape: None (which means we get the shape from the first example in; source), or list of int [height, width, channel] for testing.; name: string, name of the dataset.; use_tpu: use code paths tuned for TPU, in particular protobuf encoding.; Default False.; input_read_threads: number of threads for r",MatchSource.CODE_COMMENT,deepvariant/data_providers.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers.py
Availability,avail,available,"ntDatasetConfig(**kwargs) and writes it to filename.""""""; # Note that we use input_fn to get an iterator, while we use; # expected_dataset to get a filename, even though they are the same; # type (DeepVariantInput), and may even be the same object.; # NB, this looks like: array(['chr20:10001019-10001019'], dtype=object); # This really only works for loci, because those are string valued and; # are expected to show up in sorted order. For arbitrary data that's; # not true. In prod we have the version of tf that lets us turn off; # shuffling so this path is skipped, but kokoro hits this.; # Note that this expected shape comes from the golden dataset. If the data; # is remade in the future, the values might need to be modified accordingly.; # pylint: disable=g-complex-comprehension; # pylint: enable=g-complex-comprehension; # It looks like tf.data.Dataset.list_files is potentially nondeterministic.; # There's no guaranteed way to get around that (yet, internal).; # A list_files() flag I want is only available in tf 1.7,; # so for the short term, work around the problem by asking; # self.assertTfDataSetExamplesMatchExpected to sort the; # loci it sees. That doesn't generalize well, but we should; # be able to fix this soon.; # pylint: disable=g-complex-comprehension; # pylint: enable=g-complex-comprehension; # workaround_list_files is needed because wildcards, and so sharded; # files, are nondeterministicly ordered (for now).; # Get our images, labels, and variants for further testing.; # Checks that our labels are the right shape and are one-hot encoded.; # Note that the shape is 100, not 107, because we only adjust the image; # in the model_fn now, where previously it was done in the input_fn.; # pylint: disable=g-generic-assert; # Check that our variants has the shape we expect and actually contain; # variants by decoding them and checking the reference_name.; # pylint: disable=g-complex-comprehension; # pylint: enable=g-complex-comprehension; # pylint: disable=g-compl",MatchSource.CODE_COMMENT,deepvariant/data_providers_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers_test.py
Deployability,update,update,"labels are the right shape and are one-hot encoded.; # Note that the shape is 100, not 107, because we only adjust the image; # in the model_fn now, where previously it was done in the input_fn.; # pylint: disable=g-generic-assert; # Check that our variants has the shape we expect and actually contain; # variants by decoding them and checking the reference_name.; # pylint: disable=g-complex-comprehension; # pylint: enable=g-complex-comprehension; # pylint: disable=g-complex-comprehension; # pylint: enable=g-complex-comprehension; # assertLen not available OSS.; # pylint: disable=g-generic-assert; # pylint: enable=g-generic-assert; # When max_examples is None, dataset.num_examples will equal num_examples; # arg.; # When max_examples is larger than num_examples, dataset.num_examples will; # equal the smaller value.; # When max_examples is smaller than num_examples, dataset.num_examples; # will equal the smaller max_examples value.; # When num_examples isn't provided (None), but max_examples is, we don't; # update num_examples so it remains None.; # Use predict mode so we can have num_examples == None.; """"""Tests of input_fn, doing end-to-end I/O. These tests instantiate an input stream and then check it in various ways,; in increasing complexity.; """"""; # This is an input_fn reading test_utils.N_GOLDEN_CALLING_EXAMPLES records.; # Use PREDICT mode so we get finite input.; # Consume batch_feed, check that the right number of things is seen.; # np.ndarray; # Read batch_feed one at a time, check the shape of each, and the; # total count.; # Test reading with a larger batch size. Similar to testInputStream,; # but note that the last batch may be truncated when not in predict mode,; # so current_batch_size has to be recovered from the actual output.; # Read the golden calling examples, and read the batch_feed instantiated; # from the golden calling examples, and ensure that we get the same; # parsed records in both cases.; # Read and parse the canonical data.; # Read and pars",MatchSource.CODE_COMMENT,deepvariant/data_providers_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers_test.py
Safety,predict,predict,"107, because we only adjust the image; # in the model_fn now, where previously it was done in the input_fn.; # pylint: disable=g-generic-assert; # Check that our variants has the shape we expect and actually contain; # variants by decoding them and checking the reference_name.; # pylint: disable=g-complex-comprehension; # pylint: enable=g-complex-comprehension; # pylint: disable=g-complex-comprehension; # pylint: enable=g-complex-comprehension; # assertLen not available OSS.; # pylint: disable=g-generic-assert; # pylint: enable=g-generic-assert; # When max_examples is None, dataset.num_examples will equal num_examples; # arg.; # When max_examples is larger than num_examples, dataset.num_examples will; # equal the smaller value.; # When max_examples is smaller than num_examples, dataset.num_examples; # will equal the smaller max_examples value.; # When num_examples isn't provided (None), but max_examples is, we don't; # update num_examples so it remains None.; # Use predict mode so we can have num_examples == None.; """"""Tests of input_fn, doing end-to-end I/O. These tests instantiate an input stream and then check it in various ways,; in increasing complexity.; """"""; # This is an input_fn reading test_utils.N_GOLDEN_CALLING_EXAMPLES records.; # Use PREDICT mode so we get finite input.; # Consume batch_feed, check that the right number of things is seen.; # np.ndarray; # Read batch_feed one at a time, check the shape of each, and the; # total count.; # Test reading with a larger batch size. Similar to testInputStream,; # but note that the last batch may be truncated when not in predict mode,; # so current_batch_size has to be recovered from the actual output.; # Read the golden calling examples, and read the batch_feed instantiated; # from the golden calling examples, and ensure that we get the same; # parsed records in both cases.; # Read and parse the canonical data.; # Read and parse the data using tf. This is the function under test,; # although we indirectly check p",MatchSource.CODE_COMMENT,deepvariant/data_providers_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers_test.py
Testability,assert,assertTfDataSetExamplesMatchExpected,"taset to get a filename, even though they are the same; # type (DeepVariantInput), and may even be the same object.; # NB, this looks like: array(['chr20:10001019-10001019'], dtype=object); # This really only works for loci, because those are string valued and; # are expected to show up in sorted order. For arbitrary data that's; # not true. In prod we have the version of tf that lets us turn off; # shuffling so this path is skipped, but kokoro hits this.; # Note that this expected shape comes from the golden dataset. If the data; # is remade in the future, the values might need to be modified accordingly.; # pylint: disable=g-complex-comprehension; # pylint: enable=g-complex-comprehension; # It looks like tf.data.Dataset.list_files is potentially nondeterministic.; # There's no guaranteed way to get around that (yet, internal).; # A list_files() flag I want is only available in tf 1.7,; # so for the short term, work around the problem by asking; # self.assertTfDataSetExamplesMatchExpected to sort the; # loci it sees. That doesn't generalize well, but we should; # be able to fix this soon.; # pylint: disable=g-complex-comprehension; # pylint: enable=g-complex-comprehension; # workaround_list_files is needed because wildcards, and so sharded; # files, are nondeterministicly ordered (for now).; # Get our images, labels, and variants for further testing.; # Checks that our labels are the right shape and are one-hot encoded.; # Note that the shape is 100, not 107, because we only adjust the image; # in the model_fn now, where previously it was done in the input_fn.; # pylint: disable=g-generic-assert; # Check that our variants has the shape we expect and actually contain; # variants by decoding them and checking the reference_name.; # pylint: disable=g-complex-comprehension; # pylint: enable=g-complex-comprehension; # pylint: disable=g-complex-comprehension; # pylint: enable=g-complex-comprehension; # assertLen not available OSS.; # pylint: disable=g-generic-assert; # py",MatchSource.CODE_COMMENT,deepvariant/data_providers_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers_test.py
Usability,learn,learning,"3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for learning.genomics.deepvariant.data_provider.""""""; # Return a DeepVariantInput attached to the golden training data.; # Run with shuffling off, and in eval mode.; """"""Creates a DeepVariantDatasetConfig(**kwargs) and writes it to filename.""""""; # Note that we use input_fn to get an iterator, while we use; # expected_dataset to get a filename, even though they are the same; # type (DeepVariantInput), and may even be the same object.; # NB, this looks like: array(['chr20:10001019-10001019'], dtype=object); # This really only works for loci, because those are string valued and; # are expected to show up in sorted order. For arbitrary data that's; # not true. In prod we have the version of tf that lets us turn off; # shuffling so this path is skipped, but kokoro hits this.; # Note that this expected shape comes from the golden dataset. If the data; # is remade in the future, the values might need to be modified accordingly.; # pylint: disable=g-complex-comprehension; # pylint: enable=g-compl",MatchSource.CODE_COMMENT,deepvariant/data_providers_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers_test.py
Modifiability,config,config,"n, are permitted provided that the following conditions; # are met:; #; # 1. Redistributions of source code must retain the above copyright notice,; # this list of conditions and the following disclaimer.; #; # 2. Redistributions in binary form must reproduce the above copyright; # notice, this list of conditions and the following disclaimer in the; # documentation and/or other materials provided with the distribution.; #; # 3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Config for use with the custom training DeepVariant Loop.""""""; """"""Config parameters for exome training.""""""; # Exome Dataset; # If set to 0, use full validation dataset.; """"""Training parameters.""""""; # Used to allow for replicates during training.; # Default Dataset; # Training hyperparameters; # Stop training when this many consecutive evaluations yield no improvement.; # TensorBoard Options; # Tuning happens at every epoch. The frequency can be increased here.; # Data Pipeline Options; # Placeholder value for limiting training examples. 0=No limit.; # Use the base config.",MatchSource.CODE_COMMENT,deepvariant/dv_config.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/dv_config.py
Security,validat,validation,"n, are permitted provided that the following conditions; # are met:; #; # 1. Redistributions of source code must retain the above copyright notice,; # this list of conditions and the following disclaimer.; #; # 2. Redistributions in binary form must reproduce the above copyright; # notice, this list of conditions and the following disclaimer in the; # documentation and/or other materials provided with the distribution.; #; # 3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Config for use with the custom training DeepVariant Loop.""""""; """"""Config parameters for exome training.""""""; # Exome Dataset; # If set to 0, use full validation dataset.; """"""Training parameters.""""""; # Used to allow for replicates during training.; # Default Dataset; # Training hyperparameters; # Stop training when this many consecutive evaluations yield no improvement.; # TensorBoard Options; # Tuning happens at every epoch. The frequency can be increased here.; # Data Pipeline Options; # Placeholder value for limiting training examples. 0=No limit.; # Use the base config.",MatchSource.CODE_COMMENT,deepvariant/dv_config.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/dv_config.py
Availability,avail,available,"; #; # 3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Common constants shared across DeepVariant's codebase. This file is for very general constants in the code that end up needing to be; accessed in a variety of places, often in live code as well as throughout the; code in tests.; """"""; # Default width [in basepairs] for our DeepVariant data tensor.; # Default height [in rows] for our DeepVariant data tensor.; # Not a default because it's hard-coded into the code.; # The dimensions of a pileup image tensor as height x width x rank.; # Number of classes represented in the data set. The three classes are; # homozygous reference (0), heterozygous (1) and homozygous alternative (2).; # Default sample name if no sample name is found from the BAM header.; # Define available OptChannels (optional extra channels).; # Used only when phasing is on (phase_reads=true). It allows to set the; # region padding as a percantage over the region length. candidates are; # calculated over an extended region. Output examples are not affected by; # this value.",MatchSource.CODE_COMMENT,deepvariant/dv_constants.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/dv_constants.py
Modifiability,extend,extended,"; #; # 3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Common constants shared across DeepVariant's codebase. This file is for very general constants in the code that end up needing to be; accessed in a variety of places, often in live code as well as throughout the; code in tests.; """"""; # Default width [in basepairs] for our DeepVariant data tensor.; # Default height [in rows] for our DeepVariant data tensor.; # Not a default because it's hard-coded into the code.; # The dimensions of a pileup image tensor as height x width x rank.; # Number of classes represented in the data set. The three classes are; # homozygous reference (0), heterozygous (1) and homozygous alternative (2).; # Default sample name if no sample name is found from the BAM header.; # Define available OptChannels (optional extra channels).; # Used only when phasing is on (phase_reads=true). It allows to set the; # region padding as a percantage over the region length. candidates are; # calculated over an extended region. Output examples are not affected by; # this value.",MatchSource.CODE_COMMENT,deepvariant/dv_constants.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/dv_constants.py
Security,access,accessed,"; #; # 3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Common constants shared across DeepVariant's codebase. This file is for very general constants in the code that end up needing to be; accessed in a variety of places, often in live code as well as throughout the; code in tests.; """"""; # Default width [in basepairs] for our DeepVariant data tensor.; # Default height [in rows] for our DeepVariant data tensor.; # Not a default because it's hard-coded into the code.; # The dimensions of a pileup image tensor as height x width x rank.; # Number of classes represented in the data set. The three classes are; # homozygous reference (0), heterozygous (1) and homozygous alternative (2).; # Default sample name if no sample name is found from the BAM header.; # Define available OptChannels (optional extra channels).; # Used only when phasing is on (phase_reads=true). It allows to set the; # region padding as a percantage over the region length. candidates are; # calculated over an extended region. Output examples are not affected by; # this value.",MatchSource.CODE_COMMENT,deepvariant/dv_constants.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/dv_constants.py
Testability,test,tests,"; #; # 3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Common constants shared across DeepVariant's codebase. This file is for very general constants in the code that end up needing to be; accessed in a variety of places, often in live code as well as throughout the; code in tests.; """"""; # Default width [in basepairs] for our DeepVariant data tensor.; # Default height [in rows] for our DeepVariant data tensor.; # Not a default because it's hard-coded into the code.; # The dimensions of a pileup image tensor as height x width x rank.; # Number of classes represented in the data set. The three classes are; # homozygous reference (0), heterozygous (1) and homozygous alternative (2).; # Default sample name if no sample name is found from the BAM header.; # Define available OptChannels (optional extra channels).; # Used only when phasing is on (phase_reads=true). It allows to set the; # region padding as a percantage over the region length. candidates are; # calculated over an extended region. Output examples are not affected by; # this value.",MatchSource.CODE_COMMENT,deepvariant/dv_constants.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/dv_constants.py
Availability,checkpoint,checkpoint,"f example to variant.SerializeToString(). Args:; example: a tf.Example proto.; variant: third_party.nucleus.protos.Variant protobuf containing information; about a candidate variant call.; """"""; """"""Get the first record from `source`. Args:; source: str. A pattern or a comma-separated list of patterns that represent; file names.; proto: A proto class. proto.FromString() will be called on each serialized; record in path to parse it. Returns:; The first record, or None.; """"""; # Getting a StopIteration from one next() means source_path is empty.; # Move on to the next one to try to get one example.; """"""Reads one record from source to determine the tensor shape for all.""""""; """"""Returns a new Variant with only the basic fields of variant.""""""; """"""Returns a new VariantCall with the basic fields of call.""""""; # dict() is necessary to actually set info.; """"""Returns the shape of each tensor in the model at checkpoint_path. Args:; checkpoint_path: string. The path to a tensorflow checkpoint containing a; model whose tensor shapes we want to get.; variables_to_get: options, list of strings. If provided, only returns the; shapes of tensors in variables whose name is present in this list. If; None, the default, gets all of the tensors. A KeyError will be raised if; any variable name in variables_to_get isn't present in the checkpointed; model. Returns:; A dictionary mapping variable names [string] to tensor shapes [tuple].; """"""; """"""Returns the number of classes in the checkpoint.""""""; # Figure out how many classes this inception model was trained to predict.; """"""Graph operations decode a string into a fixed-size tensor of ints.""""""; # clip to allowed max_len; # pad to desired max_len; """"""Python operations to encode a tensor of ints into string of bytes.""""""; """"""Return GZIP or None for the compression type of the files.""""""; """"""Return true if a TPU device is available to the default session.""""""; """"""Resolve the master's URL given standard flags.""""""; # For k8s TPU we do not have/need tpu_na",MatchSource.CODE_COMMENT,deepvariant/dv_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/dv_utils.py
Energy Efficiency,efficient,efficiently,"_path. Args:; checkpoint_path: string. The path to a tensorflow checkpoint containing a; model whose tensor shapes we want to get.; variables_to_get: options, list of strings. If provided, only returns the; shapes of tensors in variables whose name is present in this list. If; None, the default, gets all of the tensors. A KeyError will be raised if; any variable name in variables_to_get isn't present in the checkpointed; model. Returns:; A dictionary mapping variable names [string] to tensor shapes [tuple].; """"""; """"""Returns the number of classes in the checkpoint.""""""; # Figure out how many classes this inception model was trained to predict.; """"""Graph operations decode a string into a fixed-size tensor of ints.""""""; # clip to allowed max_len; # pad to desired max_len; """"""Python operations to encode a tensor of ints into string of bytes.""""""; """"""Return GZIP or None for the compression type of the files.""""""; """"""Return true if a TPU device is available to the default session.""""""; """"""Resolve the master's URL given standard flags.""""""; # For k8s TPU we do not have/need tpu_name. See; # https://cloud.google.com/tpu/docs/kubernetes-engine-setup#tensorflow-code; """"""Returns corresponding example_info.json filename for examples_filename.""""""; # If examples_filename has the @shards representation, resolve it into; # the first shard. We only write .example_info.json to the first shard.; # In all other cases, including non-sharded files,; # or sharded filenames with -ddddd-of-ddddd, just append.; """"""Returns the shape and channels list from the input json.""""""; """"""Applies preprocessing operations for Inception images. Because this will run in model_fn, on the accelerator, we use operations; that efficiently execute there. Args:; images: A Tensor of shape [batch_size height, width, channel] with uint8; values. Returns:; A tensor of images of shape [batch_size height, width, channel]; containing floating point values, with all points rescaled between; -1 and 1 and possibly resized.; """"""",MatchSource.CODE_COMMENT,deepvariant/dv_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/dv_utils.py
Modifiability,variab,variables,"ng information; about a candidate variant call.; """"""; """"""Get the first record from `source`. Args:; source: str. A pattern or a comma-separated list of patterns that represent; file names.; proto: A proto class. proto.FromString() will be called on each serialized; record in path to parse it. Returns:; The first record, or None.; """"""; # Getting a StopIteration from one next() means source_path is empty.; # Move on to the next one to try to get one example.; """"""Reads one record from source to determine the tensor shape for all.""""""; """"""Returns a new Variant with only the basic fields of variant.""""""; """"""Returns a new VariantCall with the basic fields of call.""""""; # dict() is necessary to actually set info.; """"""Returns the shape of each tensor in the model at checkpoint_path. Args:; checkpoint_path: string. The path to a tensorflow checkpoint containing a; model whose tensor shapes we want to get.; variables_to_get: options, list of strings. If provided, only returns the; shapes of tensors in variables whose name is present in this list. If; None, the default, gets all of the tensors. A KeyError will be raised if; any variable name in variables_to_get isn't present in the checkpointed; model. Returns:; A dictionary mapping variable names [string] to tensor shapes [tuple].; """"""; """"""Returns the number of classes in the checkpoint.""""""; # Figure out how many classes this inception model was trained to predict.; """"""Graph operations decode a string into a fixed-size tensor of ints.""""""; # clip to allowed max_len; # pad to desired max_len; """"""Python operations to encode a tensor of ints into string of bytes.""""""; """"""Return GZIP or None for the compression type of the files.""""""; """"""Return true if a TPU device is available to the default session.""""""; """"""Resolve the master's URL given standard flags.""""""; # For k8s TPU we do not have/need tpu_name. See; # https://cloud.google.com/tpu/docs/kubernetes-engine-setup#tensorflow-code; """"""Returns corresponding example_info.json filename fo",MatchSource.CODE_COMMENT,deepvariant/dv_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/dv_utils.py
Safety,predict,predict,"source_path is empty.; # Move on to the next one to try to get one example.; """"""Reads one record from source to determine the tensor shape for all.""""""; """"""Returns a new Variant with only the basic fields of variant.""""""; """"""Returns a new VariantCall with the basic fields of call.""""""; # dict() is necessary to actually set info.; """"""Returns the shape of each tensor in the model at checkpoint_path. Args:; checkpoint_path: string. The path to a tensorflow checkpoint containing a; model whose tensor shapes we want to get.; variables_to_get: options, list of strings. If provided, only returns the; shapes of tensors in variables whose name is present in this list. If; None, the default, gets all of the tensors. A KeyError will be raised if; any variable name in variables_to_get isn't present in the checkpointed; model. Returns:; A dictionary mapping variable names [string] to tensor shapes [tuple].; """"""; """"""Returns the number of classes in the checkpoint.""""""; # Figure out how many classes this inception model was trained to predict.; """"""Graph operations decode a string into a fixed-size tensor of ints.""""""; # clip to allowed max_len; # pad to desired max_len; """"""Python operations to encode a tensor of ints into string of bytes.""""""; """"""Return GZIP or None for the compression type of the files.""""""; """"""Return true if a TPU device is available to the default session.""""""; """"""Resolve the master's URL given standard flags.""""""; # For k8s TPU we do not have/need tpu_name. See; # https://cloud.google.com/tpu/docs/kubernetes-engine-setup#tensorflow-code; """"""Returns corresponding example_info.json filename for examples_filename.""""""; # If examples_filename has the @shards representation, resolve it into; # the first shard. We only write .example_info.json to the first shard.; # In all other cases, including non-sharded files,; # or sharded filenames with -ddddd-of-ddddd, just append.; """"""Returns the shape and channels list from the input json.""""""; """"""Applies preprocessing operations for I",MatchSource.CODE_COMMENT,deepvariant/dv_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/dv_utils.py
Availability,checkpoint,checkpoint,"st of conditions and the following disclaimer in the; # documentation and/or other materials provided with the distribution.; #; # 3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for deepvariant.dv_utils.""""""; # Builds a graph.; # Saves a checkpoint.; # Model shapes without any variable requests gives you all variables.; # Asking for v0 gives you only v0's shape.; # Asking for v1 gives you only v1's shape.; # Verifies model_shapes() fails for non-existent tensors.; # Builds a graph.; # Saves a checkpoint.; # If you pass in the correct class_variable_name, you'll find the number; # of classes.; # If the class variable name doesn't existin the checkpoint, return None.; # If the checkpoint doesn't exist, return none.; # Create an empty example that doesn't have the required image/shape field.; # clean up; # Clean up; # This calls tf.io.gfile.Glob, which will raise errors.OpError,; # at least on a Posix filesystem. Other filesystems might; # not fail like that, and will return an empty list, which; # is turned into a different exception.",MatchSource.CODE_COMMENT,deepvariant/dv_utils_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/dv_utils_test.py
Modifiability,variab,variable,"st of conditions and the following disclaimer in the; # documentation and/or other materials provided with the distribution.; #; # 3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for deepvariant.dv_utils.""""""; # Builds a graph.; # Saves a checkpoint.; # Model shapes without any variable requests gives you all variables.; # Asking for v0 gives you only v0's shape.; # Asking for v1 gives you only v1's shape.; # Verifies model_shapes() fails for non-existent tensors.; # Builds a graph.; # Saves a checkpoint.; # If you pass in the correct class_variable_name, you'll find the number; # of classes.; # If the class variable name doesn't existin the checkpoint, return None.; # If the checkpoint doesn't exist, return none.; # Create an empty example that doesn't have the required image/shape field.; # clean up; # Clean up; # This calls tf.io.gfile.Glob, which will raise errors.OpError,; # at least on a Posix filesystem. Other filesystems might; # not fail like that, and will return an empty list, which; # is turned into a different exception.",MatchSource.CODE_COMMENT,deepvariant/dv_utils_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/dv_utils_test.py
Integrability,depend,dependencies,"the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Utility functions that uses dependencies with CLIF under the hood.""""""; """"""Enum capturing the int64 values we encode for different variant types. TPUs really like fixed length features, which makes it very difficult to use; extract the type of a variant for an example using an encoded Variant; protobufs or even a string value like ""snp"". The current best option appears; to be to encode the type of a variant directly in an example as an int64. This; enum provides a mapping between those raw int64 values in the example and a; human-meaningful name for that type.; """"""; # A variant of unknown type.; # The variant is a SNP.; # The variant is an indel.; """"""Gets the EncodedVariantType for variant. This function examines variant and returns the EncodedVariantType that best; describes the variation type of variant. For example, if variant has; `reference_bases = ""A""` and `alternative_bases = [""C""]` this function would; return EncodedVariantType.SNP. Args:; variant: nucleus.Variant proto. The variant whose EncodedVariantType w",MatchSource.CODE_COMMENT,deepvariant/dv_utils_using_clif.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/dv_utils_using_clif.py
Performance,load,load,"# Copyright 2023 Google LLC.; #; # Redistribution and use in source and binary forms, with or without; # modification, are permitted provided that the following conditions; # are met:; #; # 1. Redistributions of source code must retain the above copyright notice,; # this list of conditions and the following disclaimer.; #; # 2. Redistributions in binary form must reproduce the above copyright; # notice, this list of conditions and the following disclaimer in the; # documentation and/or other materials provided with the distribution.; #; # 3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for deepvariant.dv_utils_using_clif.""""""; # Providing GG, AA checks that we're sorting the indices.; # Providing variant directly avoids the call to example_variant().; # Checks that we load the variant if needed and that our mock is working.",MatchSource.CODE_COMMENT,deepvariant/dv_utils_using_clif_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/dv_utils_using_clif_test.py
Safety,avoid,avoids,"# Copyright 2023 Google LLC.; #; # Redistribution and use in source and binary forms, with or without; # modification, are permitted provided that the following conditions; # are met:; #; # 1. Redistributions of source code must retain the above copyright notice,; # this list of conditions and the following disclaimer.; #; # 2. Redistributions in binary form must reproduce the above copyright; # notice, this list of conditions and the following disclaimer in the; # documentation and/or other materials provided with the distribution.; #; # 3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for deepvariant.dv_utils_using_clif.""""""; # Providing GG, AA checks that we're sorting the indices.; # Providing variant directly avoids the call to example_variant().; # Checks that we load the variant if needed and that our mock is working.",MatchSource.CODE_COMMENT,deepvariant/dv_utils_using_clif_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/dv_utils_using_clif_test.py
Testability,mock,mock,"# Copyright 2023 Google LLC.; #; # Redistribution and use in source and binary forms, with or without; # modification, are permitted provided that the following conditions; # are met:; #; # 1. Redistributions of source code must retain the above copyright notice,; # this list of conditions and the following disclaimer.; #; # 2. Redistributions in binary form must reproduce the above copyright; # notice, this list of conditions and the following disclaimer in the; # documentation and/or other materials provided with the distribution.; #; # 3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for deepvariant.dv_utils_using_clif.""""""; # Providing GG, AA checks that we're sorting the indices.; # Providing variant directly avoids the call to example_variant().; # Checks that we load the variant if needed and that our mock is working.",MatchSource.CODE_COMMENT,deepvariant/dv_utils_using_clif_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/dv_utils_using_clif_test.py
Deployability,release,release,"claimer in the; # documentation and/or other materials provided with the distribution.; #; # 3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Library for generating VCF information created by DeepVariant.""""""; # Current release version of DeepVariant.; # FILTER field IDs.; # FORMAT field IDs.; # Genotype codes:; """"""Returns a VcfHeader used for writing VCF output. This function fills out the FILTER, INFO, FORMAT, and extra header information; created by the DeepVariant pipeline using consistent fields that DeepVariant; creates. The `contigs` and `sample_names` fields are unique depending on the; input data used, so are required inputs. Args:; contigs: list(ContigInfo). The list of contigs on which variants were; called.; sample_names: list(str). The list of samples present in the run.; add_info_candidates: Adds the 'CANDIDATES' info field for debugging; purposes.; include_med_dp: boolean. If True, we will include MED_DP. Returns:; A nucleus.genomics.v1.VcfHeader proto with known fixed headers and the given; samples and contigs populated.; """"""",MatchSource.CODE_COMMENT,deepvariant/dv_vcf_constants.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/dv_vcf_constants.py
Integrability,depend,depending,"claimer in the; # documentation and/or other materials provided with the distribution.; #; # 3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Library for generating VCF information created by DeepVariant.""""""; # Current release version of DeepVariant.; # FILTER field IDs.; # FORMAT field IDs.; # Genotype codes:; """"""Returns a VcfHeader used for writing VCF output. This function fills out the FILTER, INFO, FORMAT, and extra header information; created by the DeepVariant pipeline using consistent fields that DeepVariant; creates. The `contigs` and `sample_names` fields are unique depending on the; input data used, so are required inputs. Args:; contigs: list(ContigInfo). The list of contigs on which variants were; called.; sample_names: list(str). The list of samples present in the run.; add_info_candidates: Adds the 'CANDIDATES' info field for debugging; purposes.; include_med_dp: boolean. If True, we will include MED_DP. Returns:; A nucleus.genomics.v1.VcfHeader proto with known fixed headers and the given; samples and contigs populated.; """"""",MatchSource.CODE_COMMENT,deepvariant/dv_vcf_constants.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/dv_vcf_constants.py
Deployability,configurat,configuration,"EQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Library for resolving variants into consistent haplotypes. The convolutional neural network that evaluates the probability of a candidate; variant being non-reference evaluates each candidate variant independently.; This can lead to overlapping variant calls that cannot actually exist in an; organism: for example, a diploid human cannot have overlapping variants for; which one is homozygous alternate and the other is heterozygous alternate, since; that implies three total alternate alleles. This library tries to resolve overlapping variant calls into consistent; haplotypes by using the most likely configuration based on individual call; probabilities that is a valid set of two haplotypes. In rare cases where this; is not possible, the haplotypes are left unmodified.; """"""; # The maximum number of overlapping variants to try to resolve into compatible; # haplotypes. This corresponds to generating 3^12 (= 531,441) possible variant; # configurations for diploid individuals.; """"""Yields Variant protos in sorted order after fixing conflicting haplotypes. The input is an iterable of Variants in chromosome and position sorted order,; with potential incompatibilies as described in this module's docstring. This; function tries to resolve variants into valid haplotypes, though is not; guaranteed to do so if the variant composition is not amenable to this or it; would be computationally intractable. Args:; sorted_variants: Iterable of Variant protos. Sorted in coordinate order, but; with potentially incompatible haplotypes. Yields:; Variant protos in coordinate-sorted order with no ",MatchSource.CODE_COMMENT,deepvariant/haplotypes.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py
Integrability,depend,depending,"ility of each genotype for the indel is:; # 0/0: 0.0002 + 0.0048 + 0.0050 = 0.01; # 0/1: 0.0180 + 0.4320 = 0.45; # 1/1: 0.0018 = 0.0018; #; # which after normalizing to sum to 1 is roughly 0.022, 0.974, 0.004.; # The marginal probability for the SNP, after performing similar; # calculations, is 0.043, 0.946, 0.011. So the marginals also predict a het; # indel and a het SNP. Since the two calculations agree, we use this; # genotype call and modified likelihoods.; #; # First, we find all non-reference count configurations that are compatible.; # This represents each variant solely based on its number of non-reference; # genotypes, and assumes that variants are compatible if the total number of; # non-reference genotypes at a single position is at most two. By using; # non-reference counts, we avoid testing multiple allele configurations that; # will return the same result (e.g. a variant with two possible alternate; # alleles has three allele configurations that are homozygous alternate; # [1/1, 1/2, 2/2] and either all or none of them will be valid depending on; # the variants it interacts with).; # Next, we find the single compatible variant assignment with the individually; # highest likelihood and track the total likelihood distributed to all variant; # genotypes.; # Collapse the probabilities of all configurations to a single GL for each; # allele, independently for each variant.; # TODO: Do something better than just punting.; """"""Returns an iterable of allele configurations that satisfy the genotype. Args:; variants: list(Variant). The list of variants for which to generate; configurations of valid allele_indices.; nonref_count_configuration: list(int). The list of numbers of non-reference; genotypes that should be generated for each variant. Returns:; Iterable of lists of allele indices to assign to each Variant to satisfy the; desired configuration of number of non-reference genotypes for each variant. Raises:; ValueError: variants and nonref_count_configurati",MatchSource.CODE_COMMENT,deepvariant/haplotypes.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py
Modifiability,config,configuration,"EQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Library for resolving variants into consistent haplotypes. The convolutional neural network that evaluates the probability of a candidate; variant being non-reference evaluates each candidate variant independently.; This can lead to overlapping variant calls that cannot actually exist in an; organism: for example, a diploid human cannot have overlapping variants for; which one is homozygous alternate and the other is heterozygous alternate, since; that implies three total alternate alleles. This library tries to resolve overlapping variant calls into consistent; haplotypes by using the most likely configuration based on individual call; probabilities that is a valid set of two haplotypes. In rare cases where this; is not possible, the haplotypes are left unmodified.; """"""; # The maximum number of overlapping variants to try to resolve into compatible; # haplotypes. This corresponds to generating 3^12 (= 531,441) possible variant; # configurations for diploid individuals.; """"""Yields Variant protos in sorted order after fixing conflicting haplotypes. The input is an iterable of Variants in chromosome and position sorted order,; with potential incompatibilies as described in this module's docstring. This; function tries to resolve variants into valid haplotypes, though is not; guaranteed to do so if the variant composition is not amenable to this or it; would be computationally intractable. Args:; sorted_variants: Iterable of Variant protos. Sorted in coordinate order, but; with potentially incompatible haplotypes. Yields:; Variant protos in coordinate-sorted order with no ",MatchSource.CODE_COMMENT,deepvariant/haplotypes.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py
Performance,tune,tune,"ction tries to resolve variants into valid haplotypes, though is not; guaranteed to do so if the variant composition is not amenable to this or it; would be computationally intractable. Args:; sorted_variants: Iterable of Variant protos. Sorted in coordinate order, but; with potentially incompatible haplotypes. Yields:; Variant protos in coordinate-sorted order with no incompatible haplotypes.; """"""; """"""Yields lists of Variant protos that overlap on the reference sequence. Args:; sorted_variants: Iterable of Variant protos, sorted in coordinate order. Yields:; Lists of variants within `sorted_variants` that overlap with each other on; the reference sequence.; """"""; # Fencepost.; """"""Yields variants with compatible genotype calls in order. This function differs from `_resolve_overlapping_variants` below in that the; input here is a block of all candidate calls that overlap in a region, which; may contain candidates that are deemed to be most likely reference calls.; We often tune DeepVariant to be highly sensitive. Consequently, there can be; many candidate calls that are predicted as reference. Since those do not; contribute to potential incompatibilities, we split them out from variants; predicted to contain non-reference genotypes since the computation of; compatible haplotypes is exponential in the number of inputs. Args:; overlapping_candidates: list(Variant). A non-empty list of Variant protos in; coordinate-sorted order that overlap on the reference genome. Yields:; Variant protos in coordinate-sorted order that try to resolve incompatible; haplotypes.; """"""; # Short circuit the simplest case: A single variant in a region is compatible; # with itself by definition.; # Merge the reference and resolved variants back together in sorted order.; # Note: This could be done in an interleaving fashion, but since the total; # number of variants in the input is nearly always < 20 this is not an issue.; """"""Represents the reference genome spanned by overlapping Variants. Each ",MatchSource.CODE_COMMENT,deepvariant/haplotypes.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py
Safety,predict,predicted,"t; guaranteed to do so if the variant composition is not amenable to this or it; would be computationally intractable. Args:; sorted_variants: Iterable of Variant protos. Sorted in coordinate order, but; with potentially incompatible haplotypes. Yields:; Variant protos in coordinate-sorted order with no incompatible haplotypes.; """"""; """"""Yields lists of Variant protos that overlap on the reference sequence. Args:; sorted_variants: Iterable of Variant protos, sorted in coordinate order. Yields:; Lists of variants within `sorted_variants` that overlap with each other on; the reference sequence.; """"""; # Fencepost.; """"""Yields variants with compatible genotype calls in order. This function differs from `_resolve_overlapping_variants` below in that the; input here is a block of all candidate calls that overlap in a region, which; may contain candidates that are deemed to be most likely reference calls.; We often tune DeepVariant to be highly sensitive. Consequently, there can be; many candidate calls that are predicted as reference. Since those do not; contribute to potential incompatibilities, we split them out from variants; predicted to contain non-reference genotypes since the computation of; compatible haplotypes is exponential in the number of inputs. Args:; overlapping_candidates: list(Variant). A non-empty list of Variant protos in; coordinate-sorted order that overlap on the reference genome. Yields:; Variant protos in coordinate-sorted order that try to resolve incompatible; haplotypes.; """"""; # Short circuit the simplest case: A single variant in a region is compatible; # with itself by definition.; # Merge the reference and resolved variants back together in sorted order.; # Note: This could be done in an interleaving fashion, but since the total; # number of variants in the input is nearly always < 20 this is not an issue.; """"""Represents the reference genome spanned by overlapping Variants. Each Variant affects a portion of the reference genome that is determin",MatchSource.CODE_COMMENT,deepvariant/haplotypes.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py
Testability,log,log-sum-exp,"pping_variants: list(Variant). The Variant protos of interest.; """"""; """"""Returns True if and only if all variants are compatible. Args:; nonref_genotype_counts: list of ints in [0, ploidy]. Element i in this; list represents the number of non-reference genotypes for the i'th; variant.; ploidy: int. The ploidy of the individual. Returns:; True if and only if the variants are compatible. Raises:; ValueError: nonref_genotype_counts is not the same length as; self.variant_indices.; ValueError: nonref_genotype_counts does not contain elements in [0,; ploidy].; """"""; """"""Container class for genotype likelihoods of allele configurations. When evaluating valid genotype configurations across multiple variants, we; calculate the likelihood of each configuration. To then calculate the marginal; likelihoods for each variant's genotypes, for each genotype we need to sum the; probabilities of all configurations that include that genotype. For numerical stability we do this by storing the genotype likelihoods; = log10(p) and then aggregate using the log-sum-exp trick.; """"""; """"""Constructor. Args:; num_alts: int. The number of alternate alleles in the variant.; """"""; # At each GL index, we keep a list that will include the joint GL across all; # variants that include that particular set of allele indices for this; # variant.; """"""Add some likelihood to a particular allele configuration. Args:; allele_indices: Pair of (g1, g2) ints representing the genotype.; likelihood: float. log10(probability of this genotype configuration).; """"""; """"""Returns the scaled likelihood of each genotype.""""""; """"""Returns allele indices for the genotype with the largest likelihood.""""""; """"""Yields variants with compatible haplotypes, if possible. Args:; overlapping_variants: list(Variant). A non-empty list of Variant protos in; coordinate-sorted order that overlap on the reference genome and are; predicted to contain alternate allele genotypes. Yields:; Variant protos in coordinate-sorted order that try to resolve ",MatchSource.CODE_COMMENT,deepvariant/haplotypes.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py
Usability,simpl,simplest,"on; the reference sequence.; """"""; # Fencepost.; """"""Yields variants with compatible genotype calls in order. This function differs from `_resolve_overlapping_variants` below in that the; input here is a block of all candidate calls that overlap in a region, which; may contain candidates that are deemed to be most likely reference calls.; We often tune DeepVariant to be highly sensitive. Consequently, there can be; many candidate calls that are predicted as reference. Since those do not; contribute to potential incompatibilities, we split them out from variants; predicted to contain non-reference genotypes since the computation of; compatible haplotypes is exponential in the number of inputs. Args:; overlapping_candidates: list(Variant). A non-empty list of Variant protos in; coordinate-sorted order that overlap on the reference genome. Yields:; Variant protos in coordinate-sorted order that try to resolve incompatible; haplotypes.; """"""; # Short circuit the simplest case: A single variant in a region is compatible; # with itself by definition.; # Merge the reference and resolved variants back together in sorted order.; # Note: This could be done in an interleaving fashion, but since the total; # number of variants in the input is nearly always < 20 this is not an issue.; """"""Represents the reference genome spanned by overlapping Variants. Each Variant affects a portion of the reference genome that is determined by; its start and end coordinates. For a given set of Variants, they are deemed; compatible if the total area along the reference genome that is called as; non-reference genotypes never exceeds the ploidy of the organism.; """"""; """"""Constructor. Args:; overlapping_variants: list(Variant). The Variant protos of interest.; """"""; """"""Returns True if and only if all variants are compatible. Args:; nonref_genotype_counts: list of ints in [0, ploidy]. Element i in this; list represents the number of non-reference genotypes for the i'th; variant.; ploidy: int. The ploidy o",MatchSource.CODE_COMMENT,deepvariant/haplotypes.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py
Safety,detect,detection,"TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for deepvariant .haplotypes.""""""; """"""Creates a Variant record for testing. Args:; chrom: reference name for this variant; start: start position on the contig; end: end position on the contig; ref: reference base(s); alt: list(str). alternate base(s); qual: PHRED scaled detection probability; genotype: list of integers corresponding to the called genotype; likelihoods: genotype likelihoods for this variant; sample_name: sample name for the single call in the variant. Returns:; A Variant record created with the specified arguments. Raises:; ValueError: Both ref and end are specified, and are inconsistent.; """"""; """"""Returns a list of variants that are incompatible but can be resolved.""""""; """"""Returns a list of het variants that are correctly resolved.""""""; # Note: Most of the resolution code is tested below in the; # test_resolve_overlapping_variants function. This test mostly just ensures; # that the interaction with RefCall variants is properly handled.; # Not a real likelihood -- if we weren't just punting; # this would get rescaled to sum to 1.; # The simple case where there is a single variant.; # Cases where the actual genotype calls are compatible.; # Cases where the actual genotype calls are incompatible.; # Issues we can't currently resolve.; # Too many variants to resolve.; # Not a real likelihood -- if we weren't just puntin",MatchSource.CODE_COMMENT,deepvariant/haplotypes_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes_test.py
Testability,test,testing,"he names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for deepvariant .haplotypes.""""""; """"""Creates a Variant record for testing. Args:; chrom: reference name for this variant; start: start position on the contig; end: end position on the contig; ref: reference base(s); alt: list(str). alternate base(s); qual: PHRED scaled detection probability; genotype: list of integers corresponding to the called genotype; likelihoods: genotype likelihoods for this variant; sample_name: sample name for the single call in the variant. Returns:; A Variant record created with the specified arguments. Raises:; ValueError: Both ref and end are specified, and are inconsistent.; """"""; """"""Returns a list of variants that are incompatible but can be resolved.""""""; """"""Returns a list of het variants that are correctly resolved.""""""; # Note: Most of the resolution code is tested below in the; # test_resolve_overlapping_variants function. This test mostly just ensures; # that the interaction with RefCall variants is properly handled.; # Not a real likelihood -- if we weren't just punting; # this would get rescaled to sum",MatchSource.CODE_COMMENT,deepvariant/haplotypes_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes_test.py
Usability,simpl,simple,"NCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for deepvariant .haplotypes.""""""; """"""Creates a Variant record for testing. Args:; chrom: reference name for this variant; start: start position on the contig; end: end position on the contig; ref: reference base(s); alt: list(str). alternate base(s); qual: PHRED scaled detection probability; genotype: list of integers corresponding to the called genotype; likelihoods: genotype likelihoods for this variant; sample_name: sample name for the single call in the variant. Returns:; A Variant record created with the specified arguments. Raises:; ValueError: Both ref and end are specified, and are inconsistent.; """"""; """"""Returns a list of variants that are incompatible but can be resolved.""""""; """"""Returns a list of het variants that are correctly resolved.""""""; # Note: Most of the resolution code is tested below in the; # test_resolve_overlapping_variants function. This test mostly just ensures; # that the interaction with RefCall variants is properly handled.; # Not a real likelihood -- if we weren't just punting; # this would get rescaled to sum to 1.; # The simple case where there is a single variant.; # Cases where the actual genotype calls are compatible.; # Cases where the actual genotype calls are incompatible.; # Issues we can't currently resolve.; # Too many variants to resolve.; # Not a real likelihood -- if we weren't just punting; # this would get rescaled to sum to 1.; # Not a real likelihood -- if we weren't just punting; # this would get rescaled to sum to 1.; # Test finding overlaps and different chromosomes not overlapping.; # Test one large variant spanning multiple others.; # Test mix of non-overlapping and ending with an overlap.; # Same as prior test but using a generator as input.; """"""Helper method to compare a generator of Variant protos to a list.""""""; """"""Asserts variant equality allowing numerical differences in GLs.""""""",MatchSource.CODE_COMMENT,deepvariant/haplotypes_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes_test.py
Availability,checkpoint,checkpoint,"tion added to each `layer_class` layer.; """"""; # Save the original model weights.; # Clone the original model.; # Set the L2 `regularizer_attr` on all layers of type `layer_class`. This; # change is only reflected in the model's config file.; # Save the updated model configuration.; # Create a ""new"" model from the updated configuration and load the original; # model's weights.; # Ensure model weights have not changed after adding regularization layers.; # Ensure the newly added regularizers are registered as losses.; """"""Initialize `model` with weights from `input_model` (different #channels). Args:; model: The model we want to output.; input_model: The input model that contains the weights to initialize from. Returns:; `model` with updated weights from `input_model`; """"""; # Create a list of ndarray, which will be used input for `set_weights`; # at the end.; # Now that the new_layer_weights list has the value we want to load with,; # and has the right shape.; """"""Determine the number of channels from a checkpoint path.""""""; # Loop over variables in the checkpoint.; # 'layer_with_weights-0/kernel/.ATTRIBUTES/VARIABLE_VALUE' seems to the main; # variable to look at. I'm not sure if this heuristics will always work.; # TODO; # We used to wire the model a bit differently.; # If we see 'layer_with_weights-0/layer_with_weights-0/kernel', stop and; # alert the user.; """"""Returns `inceptionv3` model with 3 channels; init with `weights=imagenet`. Our `inceptionv3` model (defined in this file as well) allows #channels other; than 3. When the #channels is not 3, we couldn't set `weights=imagenet` to; our backbone tf.keras.applications.InceptionV3 because it will complain the; number of channels is not 3. We created this ""inceptionv3_with_imagenet""; model which has the same architecture, which we can then use our own; ""load_weights_to_model_with_different_channels"" function to initiate an; inceptionv3 model with any numbers of channels. The reason why this function is separate (inste",MatchSource.CODE_COMMENT,deepvariant/keras_modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py
Deployability,update,updates,"ABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Provides an abstraction around deep learning Keras models in DeepVariant.""""""; """"""Returns an output head tensor configured for classification. In the future, this can be extended for regression, or with different params; for different heads. Args:; inputs: The backbone output tensor; used as the input to the head.; l2: The l2 regularization factor used in `tf.keras.layers.Dense` layers. Returns:; A tensor representing the output of the given head.; """"""; """"""Adds L2 regularizers to all `layer_class` layers in `model`. Models from `tf.keras.applications` do not support specifying kernel or bias; regularizers. However, adding regularization is important when fine tuning; 'imagenet' pretrained weights. In order to do this, this function updates the; current model's configuration to include regularizers and reloads the model so; that the newly created losses are registered.; Note: this will not overwrite existing `kernel_regularizer` regularizers on; the given layer.; Args:; model: The base model.; layer_class: We add regularizers to all layers of type `layer_class`.; l2: The l2 regularization factor.; regularizer_attr: The layer's regularizer attribute. Returns:; A model with l2 regularization added to each `layer_class` layer.; """"""; # Save the original model weights.; # Clone the original model.; # Set the L2 `regularizer_attr` on all layers of type `layer_class`. This; # change is only reflected in the model's config file.; # Save the updated model configuration.; # Create a ""new"" model from the updated configuration and load the original; # model's weights.; # Ensure model weights have not changed after adding regularization layers.; # Ensure the newly added regularizers are registered as losses.; """"""Initialize `model` with weights from `input_model` (different #ch",MatchSource.CODE_COMMENT,deepvariant/keras_modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py
Modifiability,config,configured,"rse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Provides an abstraction around deep learning Keras models in DeepVariant.""""""; """"""Returns an output head tensor configured for classification. In the future, this can be extended for regression, or with different params; for different heads. Args:; inputs: The backbone output tensor; used as the input to the head.; l2: The l2 regularization factor used in `tf.keras.layers.Dense` layers. Returns:; A tensor representing the output of the given head.; """"""; """"""Adds L2 regularizers to all `layer_class` layers in `model`. Models from `tf.keras.applications` do not support specifying kernel or bias; regularizers. However, adding regularization is important when fine tuning; 'imagenet' pretrained weights. In order to do this, this function updates the; current model's configuration to include regularizers and reloads the model so; that the newly created losses are registered.; Note: this will not overwrite existing `kernel_regularizer` regularizers on; the given layer.; Args:; model: The base model.; layer_class: We add regularizers to all layers of type `layer_class`.; l2: The l2 regularization fac",MatchSource.CODE_COMMENT,deepvariant/keras_modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py
Performance,load,load,"m `tf.keras.applications` do not support specifying kernel or bias; regularizers. However, adding regularization is important when fine tuning; 'imagenet' pretrained weights. In order to do this, this function updates the; current model's configuration to include regularizers and reloads the model so; that the newly created losses are registered.; Note: this will not overwrite existing `kernel_regularizer` regularizers on; the given layer.; Args:; model: The base model.; layer_class: We add regularizers to all layers of type `layer_class`.; l2: The l2 regularization factor.; regularizer_attr: The layer's regularizer attribute. Returns:; A model with l2 regularization added to each `layer_class` layer.; """"""; # Save the original model weights.; # Clone the original model.; # Set the L2 `regularizer_attr` on all layers of type `layer_class`. This; # change is only reflected in the model's config file.; # Save the updated model configuration.; # Create a ""new"" model from the updated configuration and load the original; # model's weights.; # Ensure model weights have not changed after adding regularization layers.; # Ensure the newly added regularizers are registered as losses.; """"""Initialize `model` with weights from `input_model` (different #channels). Args:; model: The model we want to output.; input_model: The input model that contains the weights to initialize from. Returns:; `model` with updated weights from `input_model`; """"""; # Create a list of ndarray, which will be used input for `set_weights`; # at the end.; # Now that the new_layer_weights list has the value we want to load with,; # and has the right shape.; """"""Determine the number of channels from a checkpoint path.""""""; # Loop over variables in the checkpoint.; # 'layer_with_weights-0/kernel/.ATTRIBUTES/VARIABLE_VALUE' seems to the main; # variable to look at. I'm not sure if this heuristics will always work.; # TODO; # We used to wire the model a bit differently.; # If we see 'layer_with_weights-0/layer_with",MatchSource.CODE_COMMENT,deepvariant/keras_modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py
Safety,avoid,avoid,"ad of parameterized in the same; implementation of inceptionv3) is to make it easier to read. Args:; input_shape: a 3-tuple describing the input shape. The 3rd dimension is not; used in this function. We always set that to 3 in this function. Returns:; An InceptionV3-based model with 3 channels and init with `weights=imagenet`.; """"""; """"""Returns an InceptionV3 architecture. See https://tensorflow.org/api_docs/python/tf/keras/applications/InceptionV3. Args:; input_shape: a 3-tuple describing the input shape.; weights: str. To initial weights from.; init_backbone_with_imagenet: If True, get a model with InceptionV3 that has; `weights='imagenet'` to start with. This will download a model. It should; be set to False in unit tests, or when specific model weights will be; loaded afterwards.; config: a model configuration. Returns:; An InceptionV3-based model.; """"""; # If no weights file is specified, initialize with `imagenet`.; # The `init_backbone_with_imagenet` flag should be set to False for unit; # tests to avoid loading the `imagenet` model from online.; # If the input weights have different number of channels, need some special; # care:; # This step is harder to do directly from `weights`, or even the Checkpoint; # file format. So, create a `input_model` with expected #chanenls, load; # the weights, and then post-process.; # Improve later if possible: find a more readable alternative for this.; """"""Runs a forward pass with dummy data then prints the model summary.""""""; # Without calling this forward pass, we won't be able to print the summary.; """"""Reports F1 Score for a target class.""""""; # TODO: Create custom metrics.py module.; # Leave mean loss as the last metric as it is updated differently.; """"""Initializes a checkpoint manager, and restores a checkpoint if one exists. Args:; config: Training configuration.; model_dir: Where model is stored.; model: a tf Model.; optimizer: A tf Optimizer.; strategy: Distribution strategy. Returns:; The state as `tf.train.Checkpoint`",MatchSource.CODE_COMMENT,deepvariant/keras_modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py
Testability,test,tests,"v3_with_imagenet""; model which has the same architecture, which we can then use our own; ""load_weights_to_model_with_different_channels"" function to initiate an; inceptionv3 model with any numbers of channels. The reason why this function is separate (instead of parameterized in the same; implementation of inceptionv3) is to make it easier to read. Args:; input_shape: a 3-tuple describing the input shape. The 3rd dimension is not; used in this function. We always set that to 3 in this function. Returns:; An InceptionV3-based model with 3 channels and init with `weights=imagenet`.; """"""; """"""Returns an InceptionV3 architecture. See https://tensorflow.org/api_docs/python/tf/keras/applications/InceptionV3. Args:; input_shape: a 3-tuple describing the input shape.; weights: str. To initial weights from.; init_backbone_with_imagenet: If True, get a model with InceptionV3 that has; `weights='imagenet'` to start with. This will download a model. It should; be set to False in unit tests, or when specific model weights will be; loaded afterwards.; config: a model configuration. Returns:; An InceptionV3-based model.; """"""; # If no weights file is specified, initialize with `imagenet`.; # The `init_backbone_with_imagenet` flag should be set to False for unit; # tests to avoid loading the `imagenet` model from online.; # If the input weights have different number of channels, need some special; # care:; # This step is harder to do directly from `weights`, or even the Checkpoint; # file format. So, create a `input_model` with expected #chanenls, load; # the weights, and then post-process.; # Improve later if possible: find a more readable alternative for this.; """"""Runs a forward pass with dummy data then prints the model summary.""""""; # Without calling this forward pass, we won't be able to print the summary.; """"""Reports F1 Score for a target class.""""""; # TODO: Create custom metrics.py module.; # Leave mean loss as the last metric as it is updated differently.; """"""Initializes a check",MatchSource.CODE_COMMENT,deepvariant/keras_modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py
Usability,learn,learning,"copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Provides an abstraction around deep learning Keras models in DeepVariant.""""""; """"""Returns an output head tensor configured for classification. In the future, this can be extended for regression, or with different params; for different heads. Args:; inputs: The backbone output tensor; used as the input to the head.; l2: The l2 regularization factor used in `tf.keras.layers.Dense` layers. Returns:; A tensor representing the output of the given head.; """"""; """"""Adds L2 regularizers to all `layer_class` layers in `model`. Models from `tf.keras.applications` do not support specifying kernel or bias; regularizers. However, adding regularization is important when fine tuning; 'imagenet' pretrained weights. In order to do this, this function updates the; current model's configuration to include regularizers and reloads the model so; that the newly created losses are registered.; Note: this will not overwrite existing `kernel_regularizer` regularizers on; the given layer.; Args:; model: The base model.; layer_class: We add regular",MatchSource.CODE_COMMENT,deepvariant/keras_modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py
Availability,checkpoint,checkpoint,"otice, this list of conditions and the following disclaimer in the; # documentation and/or other materials provided with the distribution.; #; # 3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for keras_modeling.""""""; # Confirm that imcompatible shape causes an issue.; # Define a model.; # Generate random input and target data.; # Compile the model.; # Train the model for a few steps.; # Check that the loss has decreased after training.; # Create a model and save it to a checkpoint. Then test whether we can; # detect its number of channels correctly.; # Load it back and determine the num_channels.; """"""keras_modeling.inceptionv3 can load weights (even different #channels). Args:; checkpoint_weights_shape: The shape of the weights (checkpoint) file.; input_shape: The shape of the model we're training now.; """"""; # Create a model and save it to a checkpoint. Then test whether we can; # detect its number of channels correctly.; # This test should not throw any errors when retrieving the model; # and it's corresponding preprocess function.",MatchSource.CODE_COMMENT,deepvariant/keras_modeling_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling_test.py
Performance,load,load,"otice, this list of conditions and the following disclaimer in the; # documentation and/or other materials provided with the distribution.; #; # 3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for keras_modeling.""""""; # Confirm that imcompatible shape causes an issue.; # Define a model.; # Generate random input and target data.; # Compile the model.; # Train the model for a few steps.; # Check that the loss has decreased after training.; # Create a model and save it to a checkpoint. Then test whether we can; # detect its number of channels correctly.; # Load it back and determine the num_channels.; """"""keras_modeling.inceptionv3 can load weights (even different #channels). Args:; checkpoint_weights_shape: The shape of the weights (checkpoint) file.; input_shape: The shape of the model we're training now.; """"""; # Create a model and save it to a checkpoint. Then test whether we can; # detect its number of channels correctly.; # This test should not throw any errors when retrieving the model; # and it's corresponding preprocess function.",MatchSource.CODE_COMMENT,deepvariant/keras_modeling_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling_test.py
Safety,detect,detect,"otice, this list of conditions and the following disclaimer in the; # documentation and/or other materials provided with the distribution.; #; # 3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for keras_modeling.""""""; # Confirm that imcompatible shape causes an issue.; # Define a model.; # Generate random input and target data.; # Compile the model.; # Train the model for a few steps.; # Check that the loss has decreased after training.; # Create a model and save it to a checkpoint. Then test whether we can; # detect its number of channels correctly.; # Load it back and determine the num_channels.; """"""keras_modeling.inceptionv3 can load weights (even different #channels). Args:; checkpoint_weights_shape: The shape of the weights (checkpoint) file.; input_shape: The shape of the model we're training now.; """"""; # Create a model and save it to a checkpoint. Then test whether we can; # detect its number of channels correctly.; # This test should not throw any errors when retrieving the model; # and it's corresponding preprocess function.",MatchSource.CODE_COMMENT,deepvariant/keras_modeling_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling_test.py
Testability,test,test,"otice, this list of conditions and the following disclaimer in the; # documentation and/or other materials provided with the distribution.; #; # 3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for keras_modeling.""""""; # Confirm that imcompatible shape causes an issue.; # Define a model.; # Generate random input and target data.; # Compile the model.; # Train the model for a few steps.; # Check that the loss has decreased after training.; # Create a model and save it to a checkpoint. Then test whether we can; # detect its number of channels correctly.; # Load it back and determine the num_channels.; """"""keras_modeling.inceptionv3 can load weights (even different #channels). Args:; checkpoint_weights_shape: The shape of the weights (checkpoint) file.; input_shape: The shape of the model we're training now.; """"""; # Create a model and save it to a checkpoint. Then test whether we can; # detect its number of channels correctly.; # This test should not throw any errors when retrieving the model; # and it's corresponding preprocess function.",MatchSource.CODE_COMMENT,deepvariant/keras_modeling_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling_test.py
Integrability,message,messages,"# Copyright 2017 Google LLC.; #; # Redistribution and use in source and binary forms, with or without; # modification, are permitted provided that the following conditions; # are met:; #; # 1. Redistributions of source code must retain the above copyright notice,; # this list of conditions and the following disclaimer.; #; # 2. Redistributions in binary form must reproduce the above copyright; # notice, this list of conditions and the following disclaimer in the; # documentation and/or other materials provided with the distribution.; #; # 3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Control the verbosity of the program. Normally logging at info priority is silent; this; provides flags to adjust that. Note that TF tries to send log messages to stdout,; instead of stderr, if it thinks it is interactive.; There's no flag to override that.; """"""",MatchSource.CODE_COMMENT,deepvariant/logging_level.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/logging_level.py
Testability,log,logging,"# Copyright 2017 Google LLC.; #; # Redistribution and use in source and binary forms, with or without; # modification, are permitted provided that the following conditions; # are met:; #; # 1. Redistributions of source code must retain the above copyright notice,; # this list of conditions and the following disclaimer.; #; # 2. Redistributions in binary form must reproduce the above copyright; # notice, this list of conditions and the following disclaimer in the; # documentation and/or other materials provided with the distribution.; #; # 3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Control the verbosity of the program. Normally logging at info priority is silent; this; provides flags to adjust that. Note that TF tries to send log messages to stdout,; instead of stderr, if it thinks it is interactive.; There's no flag to override that.; """"""",MatchSource.CODE_COMMENT,deepvariant/logging_level.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/logging_level.py
Availability,down,downsampling,"bution.; #; # 3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Step one of DeepVariant: creates tf.Example protos for training/calling.""""""; # Sentinel command line flag value indicating no downsampling should occur.; # 0 is the only sample.; # Adopt more general flags from make_examples_options.; # Flags related to the sample in DeepVariant:; """"""Collect sample-related options into a list of samples.""""""; # Sample-specific options.; """"""Creates a MakeExamplesOptions proto populated with reasonable defaults. Args:; add_flags: bool. defaults to True. If True, we will push the value of; certain FLAGS into our options. If False, those option fields are left; uninitialized.; flags_obj: object. If not None, use as the source of flags, else use global; FLAGS. Returns:; deepvariant_pb2.MakeExamplesOptions protobuf. Raises:; ValueError: If we observe invalid flag values.; """"""; """"""Checks that all the options chosen make sense together.""""""; # Check for general flags (shared for DeepVariant and DeepTrio).; # Unused.; # Set up options; may do I/O.; # Run!",MatchSource.CODE_COMMENT,deepvariant/make_examples.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples.py
Availability,avail,available,", BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Core functionality for step one of DeepVariant: Making examples.""""""; # pylint: disable=g-direct-tensorflow-import; # pylint: enable=g-direct-tensorflow-import; # For --runtime_by_region, these columns will be written out in this order.; # For --read_phases_output, these columns will be written out in this order.; # The name used for a sample if one is not specified or present in the reads.; # candidate position -1 designates the end of region.; # candidate position -2 designate the end of partition. This is used to merge; # candidate positions from all shards.; # Maximum length of partition in bases. It is limited by available memory.; # TODO: For better flexibility it may be benefitial to expose it as a; # flag.; # Non DNA regions larger than this value are excluded from processing.; # ---------------------------------------------------------------------------; # Selecting variants of specific types (e.g., SNPs); # ---------------------------------------------------------------------------; # ---------------------------------------------------------------------------; # Option handling; # ---------------------------------------------------------------------------; """"""Returns sample name derived from either sample_name flag or input BAM. Function derives sample_name from the flag. If flag is not set then; sample_name is derived from input BAM. Args:; sample_name_flag: string. sample_name flag value.; reads_filenames: A list of filenames of an alignments file, e.g. BAM. The; first of these will be used. May be empty. Returns:; string. Derived sample name.; """"""; # Not specified by default: fraction_r",MatchSource.CODE_COMMENT,deepvariant/make_examples_core.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core.py
Deployability,update,updated," if any of the filenames were empty.; """"""; """"""Initialize the resources needed for this work in the current env.""""""; """"""Creates the labeler from options.""""""; """"""Creates the variant_caller from options.""""""; """"""Generates and writes out the examples in a region. Args:; candidates: List of candidates to be processed into examples.; region: The region to generate examples.; sample_order: Order of the samples to use when generating examples.; writer: A OutputsWriter used to write out examples.; n_stats: A dictionary that is used to accumulate counts for reporting.; runtimes: A dictionary that recorded runtime information for reporting. Returns:; example_shape: a list of 3 integers, representing the example shape in the; region. If the region contains no examples, return None.; """"""; # Create A tf.Example proto, which includes the candidate variant, the; # pileup image, and, if in training mode, the truth variants and labels; # needed for training.; # Get all denovo regions; # Initialize labels and types to be updated in the for loop below.; # If the variant overlaps with provided de novo regions then set label.; """"""Finds all candidate positions within a given region.""""""; # TODO: Refactor this loop. It is used in other places.; # By default, raise the ValueError as is for now.; # end of self.samples loop:; # TODO: For phasing we calculate candidates for all samples.; # If it is done here then we can reuse these results for phasing thus; # saving runtime.; # Mark the end of partition; # TODO: Use | instead.; """"""Finds candidates and creates corresponding examples in a region. Args:; region: A nucleus.genomics.v1.Range proto. Specifies the region on the; genome we should process.; region_n: Order number of the region being processed by this process. Returns:; (candidates_by_sample, gvcfs_by_sample, runtimes); 1. candidates_by_sample: A dict keyed by sample role, each a list of; candidates found, which are deepvariant.DeepVariantCall objects.; 2. gvcfs_by_sample: A dict keyed by",MatchSource.CODE_COMMENT,deepvariant/make_examples_core.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core.py
Integrability,protocol,protocol-buffers,"--------; # Option handling; # ---------------------------------------------------------------------------; """"""Returns sample name derived from either sample_name flag or input BAM. Function derives sample_name from the flag. If flag is not set then; sample_name is derived from input BAM. Args:; sample_name_flag: string. sample_name flag value.; reads_filenames: A list of filenames of an alignments file, e.g. BAM. The; first of these will be used. May be empty. Returns:; string. Derived sample name.; """"""; # Not specified by default: fraction_reference_sites_to_emit,; # Fixed random seed produced with 'od -vAn -N4 -tu4 < /dev/urandom'.; """"""Parses a command line flag string value into a protobuf Enum value. Args:; proto_enum_pb2: a enum_type_wrapper.EnumTypeWrapper type containing a proto; enum definition. For example, this would be; deepvariant_pb2.MakeExamplesOptions.Mode to get the MakeExamplesOptions; Mode enum. See:; https://developers.google.com/protocol-buffers/docs/reference/python-generated#enum; for more information.; flag_value: str. The name of the proto enum option from the command line we; want to convert into the enum value.; skip_unspecified_option: bool. If True, any enum options that include the; string 'unspecified' (in any case) will be excluded from the list of; allowed options in the ValueError raised if flag_value isn't valid. Returns:; The enum value for flag_value in proto_enum_pb2. Raises:; ValueError: if flag_value isn't a valid enum name in proto_enum_pb2.; """"""; """"""Decide value of parse_sam_aux_fields based on other flags.""""""; # User didn't set the 'parse_sam_aux_fields' flag, so default to False; # unless a flag is on that would use it.; """"""If options contain multiple shards, log with task/shard prefix.""""""; # ---------------------------------------------------------------------------; # Simple utilities; # ---------------------------------------------------------------------------; """"""Returns True if we should be generating gVCF output.""""""",MatchSource.CODE_COMMENT,deepvariant/make_examples_core.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core.py
Modifiability,variab,variable,"instead.; """"""Finds candidates and creates corresponding examples in a region. Args:; region: A nucleus.genomics.v1.Range proto. Specifies the region on the; genome we should process.; region_n: Order number of the region being processed by this process. Returns:; (candidates_by_sample, gvcfs_by_sample, runtimes); 1. candidates_by_sample: A dict keyed by sample role, each a list of; candidates found, which are deepvariant.DeepVariantCall objects.; 2. gvcfs_by_sample: A dict keyed by sample, each a list of; nucleus.genomics.v1.Variant protos containing gVCF information for all; reference sites, if gvcf generation is enabled, otherwise this value is; [].; 3. runtimes: A dict of runtimes in seconds keyed by stage.; """"""; # Collect reads from multiple BAMs. Each BAM contains a sample.; # Realigner is called outside region_reads_norealign(); # Region is expanded by region_padding number of bases. This functionality; # is only needed when phase_reads flag is on.; # When candidate partitioning is used region size is variable. Therefore; # we need to calculate the padding for each region.; # Get allele frequencies for candidates.; # After any filtering and other changes above, set candidates for sample.; """"""Gets reads overlapping the region. Args:; region: A nucleus.genomics.v1.Range object specifying the region we want; to query reads.; sam_readers: An iterable of sam.SamReader to query from.; reads_filenames: Filenames matching sam_readers. This is only used for; throwing more informative error messages. Returns:; [genomics.deepvariant.core.genomics.Read], reads overlapping the region.; """"""; # reads = itertools.chain([reader.query(region) for reader in sam_readers]); # By default, raise the ValueError as is for now.; """"""Realign reads overlapping the region. Args:; reads: list of reads.; region: A nucleus.genomics.v1.Range object specifying the region we want; to realign reads. Returns:; genomics.deepvariant.core.genomics.Read: realigned reads; """"""; # Long reads will be list",MatchSource.CODE_COMMENT,deepvariant/make_examples_core.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core.py
Safety,safe,safely," works for single sample.; # Once we extend to multi-sample, we can remove this assert.; """"""Logs, if enabled, graph construction information for region.""""""; """"""Finds candidates in the region using the designated variant caller. Args:; region: A nucleus.genomics.v1.Range object specifying the region we want; to get candidates for.; region_n: Order number of the region being processed by this process.; padded_region: A nucleus.genomics.v1.Range object specifying the padded; region. Returns:; A 2-tuple of (candidates, gvcfs).; The first value, candidates, is a dict keyed by sample role, where each; item is a list of deepvariant_pb2.DeepVariantCalls objects, in; coordidate order.; The second value, gvcfs, is a dict keyed by sample role, where; each item is a list of nucleus.genomics.v1.Variant protos containing gVCF; information for all reference sites, if gvcf generation is enabled,; otherwise the gvcfs value is [].; """"""; # If we are generating gVCF output we cannot safely abort early here as; # we need to return the gVCF records calculated by the caller below.; # Calculate potential candidate positions from allele counts.; # Calculate potential candidate positions from allele counts; # Reads iterator needs to be reset since it used in the code below.; # Remove existing values; # Skip phasing if number of candidates is over the phase_max_candidates.; # Assign phase tag to reads.; # Remove existing values; # This logic below will write out the DOT files under the directory; # specified by the flag --realigner_diagnostics, if phase_reads is; # set to True.; # TODO: Extend the logic to work for multi-sample cases.; # TODO: Use | instead.; """"""For each alternate allele, realign reads to it and get ""ref"" sequences. For alt-aligned pileups, this realigns the reads to each of the alternate; haplotypes. It also outputs the sequence for each alternate allele, which; is also needed to build the pileup image. Args:; variant: a nucleus.genomics.v1.Variant containing the alt alleles",MatchSource.CODE_COMMENT,deepvariant/make_examples_core.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core.py
Security,expose,expose,"R SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Core functionality for step one of DeepVariant: Making examples.""""""; # pylint: disable=g-direct-tensorflow-import; # pylint: enable=g-direct-tensorflow-import; # For --runtime_by_region, these columns will be written out in this order.; # For --read_phases_output, these columns will be written out in this order.; # The name used for a sample if one is not specified or present in the reads.; # candidate position -1 designates the end of region.; # candidate position -2 designate the end of partition. This is used to merge; # candidate positions from all shards.; # Maximum length of partition in bases. It is limited by available memory.; # TODO: For better flexibility it may be benefitial to expose it as a; # flag.; # Non DNA regions larger than this value are excluded from processing.; # ---------------------------------------------------------------------------; # Selecting variants of specific types (e.g., SNPs); # ---------------------------------------------------------------------------; # ---------------------------------------------------------------------------; # Option handling; # ---------------------------------------------------------------------------; """"""Returns sample name derived from either sample_name flag or input BAM. Function derives sample_name from the flag. If flag is not set then; sample_name is derived from input BAM. Args:; sample_name_flag: string. sample_name flag value.; reads_filenames: A list of filenames of an alignments file, e.g. BAM. The; first of these will be used. May be empty. Returns:; string. Derived sample name.; """"""; # Not specified by default: fraction_reference_sites_to_emit,; # Fixed random seed produced wit",MatchSource.CODE_COMMENT,deepvariant/make_examples_core.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core.py
Testability,log,log,"to_enum_pb2: a enum_type_wrapper.EnumTypeWrapper type containing a proto; enum definition. For example, this would be; deepvariant_pb2.MakeExamplesOptions.Mode to get the MakeExamplesOptions; Mode enum. See:; https://developers.google.com/protocol-buffers/docs/reference/python-generated#enum; for more information.; flag_value: str. The name of the proto enum option from the command line we; want to convert into the enum value.; skip_unspecified_option: bool. If True, any enum options that include the; string 'unspecified' (in any case) will be excluded from the list of; allowed options in the ValueError raised if flag_value isn't valid. Returns:; The enum value for flag_value in proto_enum_pb2. Raises:; ValueError: if flag_value isn't a valid enum name in proto_enum_pb2.; """"""; """"""Decide value of parse_sam_aux_fields based on other flags.""""""; # User didn't set the 'parse_sam_aux_fields' flag, so default to False; # unless a flag is on that would use it.; """"""If options contain multiple shards, log with task/shard prefix.""""""; # ---------------------------------------------------------------------------; # Simple utilities; # ---------------------------------------------------------------------------; """"""Returns True if we should be generating gVCF output.""""""; """"""Returns the sublist of elements that evaluate to True.""""""; """"""Returns the sample name as derived from the BAM file of reads. Args:; sam_reader: Already opened sam_reader to use to extract the sample names; from. This sam_reader will not be closed after this function returns. Returns:; The sample ID annotated in the read group.; """"""; """"""Round seconds (float) to the nearest millisecond.""""""; # ---------------------------------------------------------------------------; # Utilities for working with labeling metrics; #; # ---------------------------------------------------------------------------; """"""Reads a MakeExamplesRunInfo proto in text_format from path.""""""; """"""Writes a MakeExamplesRunInfo proto in text_format ",MatchSource.CODE_COMMENT,deepvariant/make_examples_core.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core.py
Usability,simpl,simpler," must be part of; VARIANT_TYPE_SELECTORS or an error will be raised. Raises:; ValueError: if any str in select_variant_types isn't present in; VARIANT_TYPE_SELECTORS. Yields:; Candidates in order.; """"""; # ---------------------------------------------------------------------------; # A modified version of reservoir_sample for reads.; # ---------------------------------------------------------------------------; """"""Samples k reads (or cover up to `max_bases_to_cover`) uniformly. Args:; iterable_of_reads: The iterable to sample from.; k: The number of elements to sample.; region: The region we're sampling from. This can be used to determine how; many bases are covered in the region.; max_bases_to_cover: If this maximum number of bases is reached, the; samplling will stop.; random: A random number generator or None. Returns:; A list containing the sample reads. Raises:; ValueError: If k is negative. Or, if k and max_bases_to_cover are both 0.; """"""; # If `max_bases_to_cover` is not set, use the simpler; # reservoir_sample implementation.; # Because this function is now used both for selecting up to `k` or; # covering `max_bases_to_cover`, if k is 0, we should set it to a large; # number (meaning not limiting on that).; # Keep a list of the number of bases each `sampled_reads` have in the region.; # Because this replaces the read at sampled_reads[j], subtract first.; # At the end, report cases where we covered max_bases_to_cover or more.; # Empirically, bases_covered is likely much more than max_bases_to_cover at; # this point. Let's do another round of trimming.; """"""Writes diagnostic information about the assembler.""""""; """"""Returns the path to a file in a region-specific subdirectory.""""""; """"""Logs, if enabled, the realigned reads for region.""""""; """"""Manages all of the outputs of make_examples in a single place.""""""; """"""Adds suffix to file name if a suffix is given.""""""; """"""Writes chrom,pos,ref,alt,label to a sitelist file.""""""; """"""API function to support with syntax.""""""; """"""Cr",MatchSource.CODE_COMMENT,deepvariant/make_examples_core.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core.py
Availability,error,error,"e should contain name, length, and pos_in_fasta. Returns:; A list of ContigInfo protos, one for each spec in specs.; """"""; """"""Makes a list of Range objects from literals.""""""; """"""Makes a RangeSet of intervals from literals.""""""; # We don't really want to inject too much knowledge about the golden right; # here, so we only use a minimal test that (a) the run_info_filename is; # a non-empty string and (b) the number of candidates sites in the labeling; # metrics field is greater than 0. Any reasonable golden output will have at; # least one candidate variant, and the reader should have filled in the; # value.; # Check that reading + writing the data produces the same lines:; # No samples could be found in the reads.; # Check that we detect an empty sample name and use default instead.; # We have more than one sample in the reads.; # Our expected intervals, inlined from CONFIDENT_REGIONS_BED.; # Our confident regions should be exactly those found in the BED file.; # Fully covered reference contigs don't trigger an error.; # No common contigs always blows up.; # Dropping either contig brings up below our 0.9 threshold.; # Our actual overlap is 50%, so check that we raise when appropriate.; # all intervals are shared.; # No common intervals.; # The names are the same but sizes are different, so not common.; # One common interval and one not.; # Check that the order doesn't matter.; # Three-way merges.; # calling_regions = contigs & calling_regions.; # Note that _from_literals() decreases start coordinate of an interval; # by 1. But, candidate positions are given in real coordinates.; # One interval 2 partitions.; # 2 intervals.; # 2 intervals, different contigs.; # Distance between candidates > max partition; # Note that these tests aren't so comprehensive as we are trusting that; # the intersection code logic itself is good and well-tested elsewhere.; # Here we are focusing on some basic tests and handling of missing; # calling_region and confident_region data.; # Chr3 isn'",MatchSource.CODE_COMMENT,deepvariant/make_examples_core_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core_test.py
Integrability,inject,inject,"ES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for deepvariant.make_examples_core.""""""; """"""Makes ContigInfo protos from specs. Args:; specs: A list of 2- or 3-tuples. All tuples should be of the same length. If; 2-element, these should be the name and length in basepairs of each; contig, and their pos_in_fasta will be set to their index in the list. If; the 3-element, the tuple should contain name, length, and pos_in_fasta. Returns:; A list of ContigInfo protos, one for each spec in specs.; """"""; """"""Makes a list of Range objects from literals.""""""; """"""Makes a RangeSet of intervals from literals.""""""; # We don't really want to inject too much knowledge about the golden right; # here, so we only use a minimal test that (a) the run_info_filename is; # a non-empty string and (b) the number of candidates sites in the labeling; # metrics field is greater than 0. Any reasonable golden output will have at; # least one candidate variant, and the reader should have filled in the; # value.; # Check that reading + writing the data produces the same lines:; # No samples could be found in the reads.; # Check that we detect an empty sample name and use default instead.; # We have more than one sample in the reads.; # Our expected intervals, inlined from CONFIDENT_REGIONS_BED.; # Our confident regions should be exactly those found in the BED file.; # Fully covered reference contigs don't trigger an error.; # No common contigs always blows up.; # Dropping either contig brings up below our 0.9 threshold.; # Our actual overlap is 50%, so check that we raise when appropriate.; # all intervals are shared.; # No common intervals.; # The names are the same but sizes are different, so not common.; # One common interval and one not",MatchSource.CODE_COMMENT,deepvariant/make_examples_core_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core_test.py
Safety,detect,detect,"specs: A list of 2- or 3-tuples. All tuples should be of the same length. If; 2-element, these should be the name and length in basepairs of each; contig, and their pos_in_fasta will be set to their index in the list. If; the 3-element, the tuple should contain name, length, and pos_in_fasta. Returns:; A list of ContigInfo protos, one for each spec in specs.; """"""; """"""Makes a list of Range objects from literals.""""""; """"""Makes a RangeSet of intervals from literals.""""""; # We don't really want to inject too much knowledge about the golden right; # here, so we only use a minimal test that (a) the run_info_filename is; # a non-empty string and (b) the number of candidates sites in the labeling; # metrics field is greater than 0. Any reasonable golden output will have at; # least one candidate variant, and the reader should have filled in the; # value.; # Check that reading + writing the data produces the same lines:; # No samples could be found in the reads.; # Check that we detect an empty sample name and use default instead.; # We have more than one sample in the reads.; # Our expected intervals, inlined from CONFIDENT_REGIONS_BED.; # Our confident regions should be exactly those found in the BED file.; # Fully covered reference contigs don't trigger an error.; # No common contigs always blows up.; # Dropping either contig brings up below our 0.9 threshold.; # Our actual overlap is 50%, so check that we raise when appropriate.; # all intervals are shared.; # No common intervals.; # The names are the same but sizes are different, so not common.; # One common interval and one not.; # Check that the order doesn't matter.; # Three-way merges.; # calling_regions = contigs & calling_regions.; # Note that _from_literals() decreases start coordinate of an interval; # by 1. But, candidate positions are given in real coordinates.; # One interval 2 partitions.; # 2 intervals.; # 2 intervals, different contigs.; # Distance between candidates > max partition; # Note that these tests ",MatchSource.CODE_COMMENT,deepvariant/make_examples_core_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core_test.py
Security,inject,inject,"ES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for deepvariant.make_examples_core.""""""; """"""Makes ContigInfo protos from specs. Args:; specs: A list of 2- or 3-tuples. All tuples should be of the same length. If; 2-element, these should be the name and length in basepairs of each; contig, and their pos_in_fasta will be set to their index in the list. If; the 3-element, the tuple should contain name, length, and pos_in_fasta. Returns:; A list of ContigInfo protos, one for each spec in specs.; """"""; """"""Makes a list of Range objects from literals.""""""; """"""Makes a RangeSet of intervals from literals.""""""; # We don't really want to inject too much knowledge about the golden right; # here, so we only use a minimal test that (a) the run_info_filename is; # a non-empty string and (b) the number of candidates sites in the labeling; # metrics field is greater than 0. Any reasonable golden output will have at; # least one candidate variant, and the reader should have filled in the; # value.; # Check that reading + writing the data produces the same lines:; # No samples could be found in the reads.; # Check that we detect an empty sample name and use default instead.; # We have more than one sample in the reads.; # Our expected intervals, inlined from CONFIDENT_REGIONS_BED.; # Our confident regions should be exactly those found in the BED file.; # Fully covered reference contigs don't trigger an error.; # No common contigs always blows up.; # Dropping either contig brings up below our 0.9 threshold.; # Our actual overlap is 50%, so check that we raise when appropriate.; # all intervals are shared.; # No common intervals.; # The names are the same but sizes are different, so not common.; # One common interval and one not",MatchSource.CODE_COMMENT,deepvariant/make_examples_core_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core_test.py
Testability,test,test,"ES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for deepvariant.make_examples_core.""""""; """"""Makes ContigInfo protos from specs. Args:; specs: A list of 2- or 3-tuples. All tuples should be of the same length. If; 2-element, these should be the name and length in basepairs of each; contig, and their pos_in_fasta will be set to their index in the list. If; the 3-element, the tuple should contain name, length, and pos_in_fasta. Returns:; A list of ContigInfo protos, one for each spec in specs.; """"""; """"""Makes a list of Range objects from literals.""""""; """"""Makes a RangeSet of intervals from literals.""""""; # We don't really want to inject too much knowledge about the golden right; # here, so we only use a minimal test that (a) the run_info_filename is; # a non-empty string and (b) the number of candidates sites in the labeling; # metrics field is greater than 0. Any reasonable golden output will have at; # least one candidate variant, and the reader should have filled in the; # value.; # Check that reading + writing the data produces the same lines:; # No samples could be found in the reads.; # Check that we detect an empty sample name and use default instead.; # We have more than one sample in the reads.; # Our expected intervals, inlined from CONFIDENT_REGIONS_BED.; # Our confident regions should be exactly those found in the BED file.; # Fully covered reference contigs don't trigger an error.; # No common contigs always blows up.; # Dropping either contig brings up below our 0.9 threshold.; # Our actual overlap is 50%, so check that we raise when appropriate.; # all intervals are shared.; # No common intervals.; # The names are the same but sizes are different, so not common.; # One common interval and one not",MatchSource.CODE_COMMENT,deepvariant/make_examples_core_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core_test.py
Usability,simpl,simplicity,"; # add_label_to_example.; # Check that sitelist exists; # Check that last column is -1 in calling mode, indicating no label.; # Check that sitelist exists; # Check that last column is -1 in calling mode, indicating no label.; # align_to_all_haplotypes() will pull from the reference, so choose a; # real variant.; # We picked this region to have exactly one known variant:; # reference_bases: ""AAGAAAGAAAG""; # alternate_bases: ""A"", a deletion of 10 bp; # start: 10046177; # end: 10046188; # reference_name: ""chr20""; # Using a real ref_reader to test that the reference allele matches; # between the variant and the reference at the variant's coordinates.; # Both outputs are keyed by alt allele.; # Sequence must be the length of the window.; # align_to_haplotype should be called once for each alt (1 alt here).; # If variant reference_bases are wrong, it should raise a ValueError.; # Although interface allows for multiple alt alleles, the test only supports a; # single alt allele. This is done for simplicity. Otherwise we would need to; # prove input_read_attributes/expected_read_attributes for each alt allele; # which will make the source code hard to follow.; # Simple test with INS.; # Simple test with DEL.; # Variant is at the end of the reference.; # Because variant is at the very end of the reference, reads will; # be trimmed to half a window (7 bases). And all reads less than; # 15 bases are discarded. Therefore, we expect no reads here.; # Create test variant.; # Create test reads.; # pylint: disable=g-complex-comprehension; # Expected read's length can be shortend because reads are trimmed by; # align_to_all_haplotypes.; # pylint: disable=g-complex-comprehension; # Calling align_to_all_haplotypes. We expect that reads are trimmed and; # realigned to all possible haplotypes. So for example, if a read has an; # insertion and there is an alt allele with the same insertion, we expect; # that this reads would align perferctly and resulting cigar contain all; # matches.; # ",MatchSource.CODE_COMMENT,deepvariant/make_examples_core_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core_test.py
Availability,down,downsampling," endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Shared flags and option handling for DeepVariant and DeepTrio.""""""; # Sentinel command line flag value indicating no downsampling should occur.; # Sentinel command line flag value indicating no random ref sites should be; # emitted.; # The name used for a sample if one is not specified or present in the reads.; # The extension we add to our examples path to write our MakeExamplesRunInfo; # protobuf.; # Use a default hts_block_size value of 128 MB (see internal for details) to; # improve SAM/BAM reading throughput, particularly on remote filesystems. Do not; # modify this default parameter without a systematic evaluation of the impact; # across a variety of distributed filesystems!; """"""Creates options from flags that are shared, along with given samples.""""""; # Fixed random seed produced with 'od -vAn -N4 -tu4 < /dev/urandom'.; # # Not specified by default: calling_regions = 3;; # DirectPhasing related flags.; """"""Checks that all the options chosen make sense together.""""""; # Check arguments that apply to any mode.; # In candidate_sweep mode there is nothing to check here.; # Check for argu",MatchSource.CODE_COMMENT,deepvariant/make_examples_options.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_options.py
Performance,throughput,throughput,"OLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Shared flags and option handling for DeepVariant and DeepTrio.""""""; # Sentinel command line flag value indicating no downsampling should occur.; # Sentinel command line flag value indicating no random ref sites should be; # emitted.; # The name used for a sample if one is not specified or present in the reads.; # The extension we add to our examples path to write our MakeExamplesRunInfo; # protobuf.; # Use a default hts_block_size value of 128 MB (see internal for details) to; # improve SAM/BAM reading throughput, particularly on remote filesystems. Do not; # modify this default parameter without a systematic evaluation of the impact; # across a variety of distributed filesystems!; """"""Creates options from flags that are shared, along with given samples.""""""; # Fixed random seed produced with 'od -vAn -N4 -tu4 < /dev/urandom'.; # # Not specified by default: calling_regions = 3;; # DirectPhasing related flags.; """"""Checks that all the options chosen make sense together.""""""; # Check arguments that apply to any mode.; # In candidate_sweep mode there is nothing to check here.; # Check for argument issues specific to calling mode.; # If there are reads, there must be a sample name too.; # Height constraint for Slim InceptionV3 implementation.",MatchSource.CODE_COMMENT,deepvariant/make_examples_options.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_options.py
Availability,down,downsampling," endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""A prototype to create tumor-normal images (tf.Example protos).""""""; # Sentinel command line flag value indicating no downsampling should occur.; # 1 is the tumor, 0 is the normal match.; # Tumor sample is the ""main"" sample because the goal here is somatic calling.; # Adopt more general flags from make_examples_options.; # Flags related to samples in DeepSomatic:; # Change any flag defaults that differ for DeepSomatic.; # I'm setting this to float('inf') because we don't want to include any; # candidates from the non-target (i.e., normal) sample.; """"""Collects sample-related options into a list of samples.""""""; # Sample-specific options.; # Ordering here determines the default order of samples, and when a sample; # above has a custom .order, then this is the list those indices refer to.; """"""Creates a MakeExamplesOptions proto populated with reasonable defaults. Args:; add_flags: bool. defaults to True. If True, we will push the value of; certain FLAGS into our options. If False, those option fields are left; uninitialized.; flags_obj: object. If not None, use as the source of flags, else u",MatchSource.CODE_COMMENT,deepvariant/make_examples_somatic.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_somatic.py
Availability,error,errors,"Raises:; KeyError: If example contains a feature without a known decoder.; """"""; """"""Enum capturing what the test condition we're using.""""""; """"""Confirms the channels with diff_channels are ordered as expected.""""""; # We need to overwrite bam_fname for USE_CRAM test since Golden Set; # generated from BAM file. BAM filename is stored in candidates. If we; # don't overwrite default_options variants won't match and test fail.; # Test that our candidates are reasonable, calling specific helper; # functions to check lots of properties of the output.; # Verify that the variants in the examples are all good.; # Because this test is with just one sample, whether; # enable_joint_realignment is True or False doesn't make a difference.; # NOTE: When creating this test, I deliberately change the behavior of; # enable_joint_realignment==False and confirm that this test can fail,; # if the outputs are different when we alter enable_joint_realignment.; # For 'candidate_sweep' mode, it won't create examples, so we just aim; # to run it through without errors.; # We need to overwrite bam_fname for USE_CRAM test since Golden Set; # generated from BAM file. BAM filename is stored in candidates. If we; # don't overwrite default_options variants won't match and test fail.; # Now, this is the main part of the test. I want to test the behavior after; # I set max_reads_for_dynamic_bases_per_region.; # Golden sets are created with learning/genomics/internal/create_golden.sh; # All tests are run with fast_pass_aligner enabled. There are no; # golden sets version for ssw realigner.; # The following tests are for CRAM input:; # The following tests are for multiple BAM inputs:; # We need to overwrite bam_fname for USE_CRAM test since Golden Set; # generated from BAM file. BAM filename is stored in candidates. If we; # don't overwrite default_options variants won't match and test fail.; # Check that our run_info proto contains the basic fields we'd expect:; # (a) our options are written to the run_in",MatchSource.CODE_COMMENT,deepvariant/make_examples_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_test.py
Deployability,pipeline,pipeline,"le.; # Verify that the variants in the examples are all good.; # Pileup image should have 3 rows of height 100, so resulting height is 300.; # Use same number of shards for profiling files as examples.; # Run make_examples with those FLAGS.; # Sharded output ending in @4 becomes -00002-of-00004 for task 2.; # Run make_examples with the flags above.; # Run make_examples with the flags above.; # Verify that the variants in the examples are all good.; # Pileup images should have one extra channel.; # Test there is something in the added channel.; # Values capture whether each loci has been seen in the observed examples.; # Check against the golden file (same for all modes).; # Tests that we call almost all of the real variants (according to NIST's; # Genome in a Bottle callset for NA12878) in our candidate callset.; # Tests that we don't have an enormous number of FP calls. We should have; # no more than 5x (arbitrary) more candidate calls than real calls. If we; # have more it's likely due to some major pipeline problem.; """"""Asserts that actual and expected tf.Examples from DeepVariant are equal. Args:; actual: iterable of tf.Examples from DeepVariant. DeepVariant examples; that we want to check.; expected: iterable of tf.Examples. Expected results for actual.; """"""; # Finds a call in our actual call set for each NIST variant, asserting; # that we found exactly one.; # Verify that every alt allele appears in the call (but the call might); # have more than just those calls.; # Verifies simple properties of the Variant protos in variants. For example,; # checks that the reference_name() is our expected chromosome. The flag; # is_gvcf determines how we check the VariantCall field of each variant,; # enforcing expectations for gVCF records if true or variant calls if false.; # GVCF records should have 0/0 or ./. (un-called) genotypes as they are; # reference sites, have genotype likelihoods and a GQ value.; """"""Verifies region is fully covered by gvcf records.""""""; # We expec",MatchSource.CODE_COMMENT,deepvariant/make_examples_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_test.py
Integrability,message,message,"ontains the basic fields we'd expect:; # (a) our options are written to the run_info.options field.; # (b) run_info.resource_metrics is present and contains our hostname.; # For candidate_sweep mode we verify that candidate positions match; # golden set exactly.; # In candidate_sweep mode the test stops here.; # Test that our candidates are reasonable, calling specific helper functions; # to check lots of properties of the output.; # Verify that the variants in the examples are all good.; # Verify the integrity of the examples and then check that they match our; # golden labeled examples. Note we expect the order for both training and; # calling modes to produce deterministic order because we fix the random; # seed.; # Check the quality of our generated gvcf file.; # Despite the name, assertCountEqual checks that all elements match.; # The positional labeler doesn't track metrics, so don't try to read them; # in when that's the mode.; # This shows an example of what the error message looks like:; # TODO: OpError exception not propagated.; # Golden sets are created with learning/genomics/internal/create_golden.sh; # Verify that the variants in the examples are all good.; """"""Set very low vsc_max_fraction_{snps,indels} and confirm they're used.""""""; # Setting min_fractions to larger than 100% to confirm that this will end; # up removing all examples.; # Golden sets are created with learning/genomics/internal/create_golden.sh; # Adding the following flags to match how the testdata was created.; # Verify that the variants in the examples are all good.; """"""Confirms confident_regions is used in vcf_candidate_importer training.""""""; # `flag_name` can be either 'confident_regions' or 'regions'. Both should; # be used to constrain the set of candidates generated, and as a result; # generating the same examples.; # Verify that the variants in the examples are all good.; # Golden sets are created with learning/genomics/internal/create_golden.sh; # This is the only input change.; ",MatchSource.CODE_COMMENT,deepvariant/make_examples_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_test.py
Security,integrity,integrity,"lden.sh; # All tests are run with fast_pass_aligner enabled. There are no; # golden sets version for ssw realigner.; # The following tests are for CRAM input:; # The following tests are for multiple BAM inputs:; # We need to overwrite bam_fname for USE_CRAM test since Golden Set; # generated from BAM file. BAM filename is stored in candidates. If we; # don't overwrite default_options variants won't match and test fail.; # Check that our run_info proto contains the basic fields we'd expect:; # (a) our options are written to the run_info.options field.; # (b) run_info.resource_metrics is present and contains our hostname.; # For candidate_sweep mode we verify that candidate positions match; # golden set exactly.; # In candidate_sweep mode the test stops here.; # Test that our candidates are reasonable, calling specific helper functions; # to check lots of properties of the output.; # Verify that the variants in the examples are all good.; # Verify the integrity of the examples and then check that they match our; # golden labeled examples. Note we expect the order for both training and; # calling modes to produce deterministic order because we fix the random; # seed.; # Check the quality of our generated gvcf file.; # Despite the name, assertCountEqual checks that all elements match.; # The positional labeler doesn't track metrics, so don't try to read them; # in when that's the mode.; # This shows an example of what the error message looks like:; # TODO: OpError exception not propagated.; # Golden sets are created with learning/genomics/internal/create_golden.sh; # Verify that the variants in the examples are all good.; """"""Set very low vsc_max_fraction_{snps,indels} and confirm they're used.""""""; # Setting min_fractions to larger than 100% to confirm that this will end; # up removing all examples.; # Golden sets are created with learning/genomics/internal/create_golden.sh; # Adding the following flags to match how the testdata was created.; # Verify that the variants in",MatchSource.CODE_COMMENT,deepvariant/make_examples_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_test.py
Testability,test,test," ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for deepvariant.make_examples.""""""; # Dictionary mapping keys to decoders for decode_example function.; """"""Decodes a tf.Example from DeepVariant into a dict of Pythonic structures. Args:; example: tf.Example proto. The example to make into a dictionary. Returns:; A python dictionary with key/value pairs for each of the fields of example,; with each value decoded as needed into Python structures like protos, list,; etc. Raises:; KeyError: If example contains a feature without a known decoder.; """"""; """"""Enum capturing what the test condition we're using.""""""; """"""Confirms the channels with diff_channels are ordered as expected.""""""; # We need to overwrite bam_fname for USE_CRAM test since Golden Set; # generated from BAM file. BAM filename is stored in candidates. If we; # don't overwrite default_options variants won't match and test fail.; # Test that our candidates are reasonable, calling specific helper; # functions to check lots of properties of the output.; # Verify that the variants in the examples are all good.; # Because this test is with just one sample, whether; # enable_joint_realignment is True or False doesn't make a difference.; # NOTE: When creating this test, I deliberately change the behavior of; # enable_joint_realignment==False and confirm that this test can fail,; # if the outputs are different when we alter enable_joint_realignment.; # For 'candidate_sweep' mode, it won't create examples, so we just aim; # to run it through without errors.; # We need to overwrite bam_fname for USE_CRAM t",MatchSource.CODE_COMMENT,deepvariant/make_examples_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_test.py
Usability,learn,learning," that our candidates are reasonable, calling specific helper; # functions to check lots of properties of the output.; # Verify that the variants in the examples are all good.; # Because this test is with just one sample, whether; # enable_joint_realignment is True or False doesn't make a difference.; # NOTE: When creating this test, I deliberately change the behavior of; # enable_joint_realignment==False and confirm that this test can fail,; # if the outputs are different when we alter enable_joint_realignment.; # For 'candidate_sweep' mode, it won't create examples, so we just aim; # to run it through without errors.; # We need to overwrite bam_fname for USE_CRAM test since Golden Set; # generated from BAM file. BAM filename is stored in candidates. If we; # don't overwrite default_options variants won't match and test fail.; # Now, this is the main part of the test. I want to test the behavior after; # I set max_reads_for_dynamic_bases_per_region.; # Golden sets are created with learning/genomics/internal/create_golden.sh; # All tests are run with fast_pass_aligner enabled. There are no; # golden sets version for ssw realigner.; # The following tests are for CRAM input:; # The following tests are for multiple BAM inputs:; # We need to overwrite bam_fname for USE_CRAM test since Golden Set; # generated from BAM file. BAM filename is stored in candidates. If we; # don't overwrite default_options variants won't match and test fail.; # Check that our run_info proto contains the basic fields we'd expect:; # (a) our options are written to the run_info.options field.; # (b) run_info.resource_metrics is present and contains our hostname.; # For candidate_sweep mode we verify that candidate positions match; # golden set exactly.; # In candidate_sweep mode the test stops here.; # Test that our candidates are reasonable, calling specific helper functions; # to check lots of properties of the output.; # Verify that the variants in the examples are all good.; # Verify the inte",MatchSource.CODE_COMMENT,deepvariant/make_examples_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_test.py
Availability,checkpoint,checkpoint,"arger metric values are better; or worse.; """"""; # NB. This includes only a subset of our usual metrics.; # We'll add the rest back in a subsequent change.; """"""Calculate eval metrics from Tensors, on CPU host. Args:; labels: the ground-truth labels for the examples.; predictions: the predicted labels for the examples.; variant_types: variant types (int64 of EncodedVariantType.value) as a tensor; of (batch_size,) or None. The types of these variants. If None, no type; specific evals will be performed. Returns:; A dictionary of string name to metric.; """"""; # Add the metrics stratified by variant_type; # Add the metrics stratified by predicted class.; # Special case F1/All to avoid a clash between the two different ways that we; # can compute Precision and Recall (e.g., get_class_precision vs.; # tf.compat.v1.metrics.precision.; # Make sure our metrics are consistent with the expected names from; # eval_function_metrics.; # The following two classes support loading exponential moving averages into; # their corresponding variables when a checkpoint is loaded. They're called; # as hooks by the Estimators. Note for future work: this is the documented; # way, but someone on the mailing list suggested that using the scaffold_fn; # mechanism might be better.; """"""Hook to load EMA into their corresponding variables. This looks for the latest checkpoint in the model dir.; """"""; """"""Hook to load EMA into their corresponding variables. This reads the specified checkpoint.; """"""; """"""Base class for models that compute genotype likelihoods from an image. This class is intended for use anywhere in DeepVariant where we want to train; or evaluate a model that computes genotype likelihoods from a pileup image. A; bit of encapsulation helps us to try new models (beyond inception_v3) and unit; test our code. The base class cannot be used directly; concrete subclasses actually implement; specific models and all of the associated machinery to create/load/save; models. Attributes:; name: str. Th",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
Deployability,update,updates,"r the examples.; target_class: index of the class that is left as non-zero. Returns:; Tensor containing the recall value.; """"""; """"""Compute precision from labels and predicted_class for target_class. Examples with label target_class are positives. Other classes are negatives. Args:; labels: the ground-truth labels for the examples.; predicted_class: the predicted labels for the examples.; target_class: index of the class that is left as non-zero. Returns:; Tensor containing the precision value.; """"""; # TODO: Verify this F1 score is correct.; """"""Compute F1 score of predictions with respect to the labels. Args:; labels: tensor whose dimensions must match predictions. The ground-truth; labels for the examples.; predictions: tensor of arbitrary dimension. The predicted labels for the; examples.; target_class: int. Index of the class that is left as non-zero. Returns:; f1_score: scalar float tensor whose dimensions match predictions. The; calculated f1 score.; update_op: operation that updates the f1 score streaming metric.; """"""; """"""Returns a bool tensor indicating which variant_types match type_to_select. Args:; variant_types_tensor: Tensor of shape (batch_size, 1) containing; EncodedVariantType.value int64 values. Each element of this tensor should; be a EncodedVariantType.value int64 value indicating the type of the; variant.; type_to_select: EncodedVariantType. The type of variant we want to select. Returns:; Tensor of shape (batch_size, 1) of type tf.bool. A True value indicates that; the variant_type at that position matched type_to_select. Has a False; otherwise.; """"""; # This dictionary contains a mapping from the human readable name of a metric; # function (e.g., Accuracy) and its associated TensorFlow metric function. All; # of the entries here will be stratified by variant_type in eval_metric_fn.; # A set containing the names of the variant types we split our metrics by type; # by. This data structure isn't a dictionary like it's neighbors because; # eval_metric",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
Energy Efficiency,efficient,efficiently,"ust return vars_to_include.; """"""Baseclass for DeepVariant models based on Slim networks.""""""; """"""Creates an DeepVariant CNN network based on a tf.slim model. Args:; name: see baseclass.; pretrained_model_path: see baseclass.; n_classes_model_variable: str. A fully-qualitified TF variable name in the; model that we can use to determine the shape of the output; classification layer of the model. For example, in inception-v3 from; slim this is 'InceptionV3/Logits/Conv2d_1c_1x1/weights'.; excluded_scopes_for_incompatible_classes: set of str. A set of scopes that; will be excluded when restoring from a checkpoint to avoid loading; incompatible #classes.; excluded_scopes_for_incompatible_channels: set of str. A set of scopes; that will be excluded when restoring from a checkpoint to avoid loading; incompatible #channels. Raises:; ValueError: If any of the arguments are invalid.; """"""; """"""Applies preprocessing operations for Inception images. Because this will run in model_fn, on the accelerator, we use operations; that efficiently execute there. Args:; images: An Tensor of shape [batch_size height, width, channel] with uint8; values. Returns:; A tensor of images of shape [batch_size height, width, channel]; containing floating point values, with all points rescaled between; -1 and 1 and possibly resized.; """"""; """"""A model_fn for slim (really inception_v3), satisfying the Estimator API. Args:; features: a single Tensor or dict of same (from input_fn).; labels: a single Tensor or dict of same (from input_fn).; mode: tf.estimator.ModeKeys.; params: dict. Returns:; EstimatorSpec or TPUEstimatorSpec depending on self.use_tpu.; """"""; # NB. The basic structure of this started from; # //third_party/cloud_tpu/models/inception/inception_v3.py; # TODO: get this from the model.; # Compute loss.; """"""Make EstimatorSpec for the current model. Args:; features: a single Tensor or dict of same (from input_fn).; endpoints: a dictionary, containing string keys mapped to endpoint; tensors of this",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
Integrability,interface,interface,"ICT modes).; model_dir: an (optional) string directory to use as the model directory.; max_checkpoints_to_keep: an (optional) integer count of saved checkpoints.; iterations_per_loop: an (optional) integer count of log_step_count_steps.; params: an (optional) dictionary of parameters to pass to the Estimator; constructor.; unused_device_fn: a device_fn to pass to RunConfig, if not use_tpu.; master: a string necessary for TPU, pass FLAGS.master through.; use_tpu: boolean. set self.use_tpu if not None.; start_from_checkpoint: string. If not None, initialize model from this; path. According to the current implementation of Estimator, this will; only be used in training. The inference checkpoint is loaded in a; different place.; session_config: a tf.ConfigProto to pass to RunConfig, if not use_tpu.; include_debug_info: from call_variants. If True, PREDICT mode will include; extra info such as logits and prelogits. Returns:; an object implementing the tf.estimator.Estimator interface (will be a; TPUEstimator if self.use_tpu is True).; """"""; # Set the model dir of this class to the model_dir passed in here. It's not; # so clean but it appears to be necessary due to the way estimators are; # constructed (i.e., model_dir is set late).; # These flags are exclusive if not None, and 0 means disable.; # TODO: enable setting these independently.; # device_fn=device_fn, # Not in tf1.8?; # The TPUEstimator interface implicitly adds batch_size to the params; # dict. Do so explicitly here, so that we can use the same model_fn.; """"""A model_fn satisfying the Estimator API. Args:; features: a dictionary supplying features.; labels: a tensor of labels.; mode: one of tf.estimator.ModeKeys.{EVAL,TRAIN}; params: a dictionary of parameters. Returns:; a tf.estimator.EstimatorSpec or tpu_estimator.TPUEstimatorSpec,; depending on self.use_tpu.; """"""; """"""Returns a list of tf.train.SessionRunHook classes. A typical use case is to provide a hook to load the EMA variables. These will be instantiated ",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
Modifiability,variab,variables,"arger metric values are better; or worse.; """"""; # NB. This includes only a subset of our usual metrics.; # We'll add the rest back in a subsequent change.; """"""Calculate eval metrics from Tensors, on CPU host. Args:; labels: the ground-truth labels for the examples.; predictions: the predicted labels for the examples.; variant_types: variant types (int64 of EncodedVariantType.value) as a tensor; of (batch_size,) or None. The types of these variants. If None, no type; specific evals will be performed. Returns:; A dictionary of string name to metric.; """"""; # Add the metrics stratified by variant_type; # Add the metrics stratified by predicted class.; # Special case F1/All to avoid a clash between the two different ways that we; # can compute Precision and Recall (e.g., get_class_precision vs.; # tf.compat.v1.metrics.precision.; # Make sure our metrics are consistent with the expected names from; # eval_function_metrics.; # The following two classes support loading exponential moving averages into; # their corresponding variables when a checkpoint is loaded. They're called; # as hooks by the Estimators. Note for future work: this is the documented; # way, but someone on the mailing list suggested that using the scaffold_fn; # mechanism might be better.; """"""Hook to load EMA into their corresponding variables. This looks for the latest checkpoint in the model dir.; """"""; """"""Hook to load EMA into their corresponding variables. This reads the specified checkpoint.; """"""; """"""Base class for models that compute genotype likelihoods from an image. This class is intended for use anywhere in DeepVariant where we want to train; or evaluate a model that computes genotype likelihoods from a pileup image. A; bit of encapsulation helps us to try new models (beyond inception_v3) and unit; test our code. The base class cannot be used directly; concrete subclasses actually implement; specific models and all of the associated machinery to create/load/save; models. Attributes:; name: str. Th",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
Performance,load,loading,"t specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Provides an abstraction around deep learning models in DeepVariant. This class allows us to encapsulate all of the model management, loading,; saving, and data processing in a single place so those details don't spill over; into the more general deepvariant codebase. The key thing we are aiming for here; is to make sure we can easily play with other model architectures without; modifying the surrounding training and evaluation code.; """"""; # pylint: disable=g-direct-tensorflow-import; # pylint: enable=g-direct-tensorflow-import; # Training parameters.; """"""Exception indicating the image dimensions aren't supported by our model.""""""; """"""Binarize labels and predictions. The labels that are equal to target_class parameter are set to 0, else; set to 1. Args:; labels: the ground-truth labels for the examples.; target_class: index of the class that is left as zero. Returns:; Tensor of the same shape as labels.; """"""; """"""Compute recall from labels and predicted_class for target_class. Examples with label target_class are positives. Other classes are negatives. Args:; labels: the ground-truth labels for the examples.; predicted_class: the predicted labels for t",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
Safety,predict,predictions,"MENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Provides an abstraction around deep learning models in DeepVariant. This class allows us to encapsulate all of the model management, loading,; saving, and data processing in a single place so those details don't spill over; into the more general deepvariant codebase. The key thing we are aiming for here; is to make sure we can easily play with other model architectures without; modifying the surrounding training and evaluation code.; """"""; # pylint: disable=g-direct-tensorflow-import; # pylint: enable=g-direct-tensorflow-import; # Training parameters.; """"""Exception indicating the image dimensions aren't supported by our model.""""""; """"""Binarize labels and predictions. The labels that are equal to target_class parameter are set to 0, else; set to 1. Args:; labels: the ground-truth labels for the examples.; target_class: index of the class that is left as zero. Returns:; Tensor of the same shape as labels.; """"""; """"""Compute recall from labels and predicted_class for target_class. Examples with label target_class are positives. Other classes are negatives. Args:; labels: the ground-truth labels for the examples.; predicted_class: the predicted labels for the examples.; target_class: index of the class that is left as non-zero. Returns:; Tensor containing the recall value.; """"""; """"""Compute precision from labels and predicted_class for target_class. Examples with label target_class are positives. Other classes are negatives. Args:; labels: the ground-truth labels for the examples.; predicted_class: the predicted labels for the examples.; target_class: index of the class that is left as non-zero. Returns:; Tensor containing the precisi",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
Testability,log,logic,"e f1 score streaming metric.; """"""; """"""Returns a bool tensor indicating which variant_types match type_to_select. Args:; variant_types_tensor: Tensor of shape (batch_size, 1) containing; EncodedVariantType.value int64 values. Each element of this tensor should; be a EncodedVariantType.value int64 value indicating the type of the; variant.; type_to_select: EncodedVariantType. The type of variant we want to select. Returns:; Tensor of shape (batch_size, 1) of type tf.bool. A True value indicates that; the variant_type at that position matched type_to_select. Has a False; otherwise.; """"""; # This dictionary contains a mapping from the human readable name of a metric; # function (e.g., Accuracy) and its associated TensorFlow metric function. All; # of the entries here will be stratified by variant_type in eval_metric_fn.; # A set containing the names of the variant types we split our metrics by type; # by. This data structure isn't a dictionary like it's neighbors because; # eval_metric_fn requires special logic to compute the values here associated; # with each of these names.; # This dictionary contains a mapping from the human readable name of a genotype; # class (e.g., Het) and its associated class label (e.g., 1). All of the entries; # here will be stratified by genotype_class in eval_metric_fn.; # This dictionary contains a mapping from the human readable name of a metric; # function (e.g., Accuracy) and its associated metric function. All; # of the entries here will be stratified by genotype class (e.g., Het) in; # eval_metric_fn.; """"""Enum capturing whether a better metric should be larger or smaller.""""""; """"""Gets the set of eval_metrics names and their directionality. Args:; has_variant_types: bool. Will we be providing variant_type information; during eval so that we'll have metrics stratified by variant_type?. Returns:; dict mapping from a metric name string (e.g., ""F1/All"") and a; EvalMetricOrdering enum indicating whether larger metric values are better; or wors",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
Usability,learn,learning,"he copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Provides an abstraction around deep learning models in DeepVariant. This class allows us to encapsulate all of the model management, loading,; saving, and data processing in a single place so those details don't spill over; into the more general deepvariant codebase. The key thing we are aiming for here; is to make sure we can easily play with other model architectures without; modifying the surrounding training and evaluation code.; """"""; # pylint: disable=g-direct-tensorflow-import; # pylint: enable=g-direct-tensorflow-import; # Training parameters.; """"""Exception indicating the image dimensions aren't supported by our model.""""""; """"""Binarize labels and predictions. The labels that are equal to target_class parameter are set to 0, else; set to 1. Args:; labels: the ground-truth labels for the examples.; target_class: index of the class that is left as zero. Returns:; Tensor of the same shape as labels.; """"""; """"""Compute recall from labels and predicted_class for target_class. Examples with label target_class are posit",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
Modifiability,variab,variable,"ermission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for learning.genomics.deepvariant.modeling.""""""; # We haven't created a slim model, so the variables_to_restore_from_model; # should be returning an empty list.; # Create two model variable and one regular variables.; # The only variables in the system are the three we've created.; # We get just the three model variables without any excludes.; # As well as when exclude_scopes is an empty list.; # Excluding model/l1 variables gives us w2 and w3.; # Excluding model/l2 gives us just w1 back.; # Excluding multiple scopes works as expected.; # Excluding the root model scope also produces no variables..; # Hide the baseclass inside an enclosing scope so that unittest doesn't try to; # run our baseclass tests directly. http://stackoverflow.com/a/1323554.; # Creates a training=False model.; # Check that our image has the right shape and that all values are; # floats between between -1 and 1.; # The preprocess step resizes the image to h x w as needed by; # inception. We don't really care where it goes in the image (and the; # calculation is complex. So we are simply checking here that all; # values are zero except for the transformed values we see in values.; # We are relying h",MatchSource.CODE_COMMENT,deepvariant/modeling_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling_test.py
Testability,test,tests," BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for learning.genomics.deepvariant.modeling.""""""; # We haven't created a slim model, so the variables_to_restore_from_model; # should be returning an empty list.; # Create two model variable and one regular variables.; # The only variables in the system are the three we've created.; # We get just the three model variables without any excludes.; # As well as when exclude_scopes is an empty list.; # Excluding model/l1 variables gives us w2 and w3.; # Excluding model/l2 gives us just w1 back.; # Excluding multiple scopes works as expected.; # Excluding the root model scope also produces no variables..; # Hide the baseclass inside an enclosing scope so that unittest doesn't try to; # run our baseclass tests directly. http://stackoverflow.com/a/1323554.; # Creates a training=False model.; # Check that our image has the right shape and that all values are; # floats between between -1 and 1.; # The preprocess step resizes the image to h x w as needed by; # inception. We don't really care where it goes in the image (and the; # calculation is complex. So we are simply checking here that all; # values are zero except for the transformed values we see in values.; # We are relying here on the tf operations to be correct and to not; # change their behavior over time. Because we are doing assertEqual; # we are also testing the order of the values, which means that we; # are sure that the pixels have been translated in the right order in; # the image, wherever the actual translation might be.; # Note this test is only applied to inception_v3.; # We shouldn't get an exception creating images with these sizes.",MatchSource.CODE_COMMENT,deepvariant/modeling_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling_test.py
Usability,learn,learning,"3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for learning.genomics.deepvariant.modeling.""""""; # We haven't created a slim model, so the variables_to_restore_from_model; # should be returning an empty list.; # Create two model variable and one regular variables.; # The only variables in the system are the three we've created.; # We get just the three model variables without any excludes.; # As well as when exclude_scopes is an empty list.; # Excluding model/l1 variables gives us w2 and w3.; # Excluding model/l2 gives us just w1 back.; # Excluding multiple scopes works as expected.; # Excluding the root model scope also produces no variables..; # Hide the baseclass inside an enclosing scope so that unittest doesn't try to; # run our baseclass tests directly. http://stackoverflow.com/a/1323554.; # Creates a training=False model.; # Check that our image has the right shape and that all values are; # floats between between -1 and 1.; # The preprocess step resizes the image to h x w as needed by; # inception. We don't really care where i",MatchSource.CODE_COMMENT,deepvariant/modeling_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling_test.py
Availability,down,downstream,"ird_party.nucleus.protos.Variant proto describing the variant; we are creating the pileup image of.; sam_reader: Nucleus sam_reader from which to query. Returns:; A list of third_party.nucleus.protos.Read protos.; """"""; """"""Gets the reference bases used to make the pileup image around variant. Args:; variant: A third_party.nucleus.protos.Variant proto describing the variant; we are creating the pileup image of. Returns:; A string of reference bases or None. Returns None if the reference; interval for variant isn't valid for some reason.; """"""; """"""Yields the set of all alt_alleles for variant. This function computes the sets of alt_alleles we want to use to cover all; genotype likelihood calculations we need for n alt alleles (see class docs; for background). The easiest way to do this is to calculate all combinations; of 2 alleles from ref + alts and then strip away the reference alleles,; leaving us with the set of alts for the pileup image encoder. The sets are; converted to sorted lists at the end for downstream consistency. Args:; variant: third_party.nucleus.protos.Variant to generate the alt allele; combinations for. Yields:; A series of lists containing the alt alleles we want to use for a single; pileup image. The entire series covers all combinations of alt alleles; needed for variant. Raises:; ValueError: if options.multi_allelic_mode is UNSPECIFIED.; """"""; """"""Creates a pileup tensor for dv_call. Args:; dv_call: learning.genomics.deepvariant.DeepVariantCall object with; information on our candidate call and allele support information.; refbases: A string options.width in length containing the reference base; sequence to encode. The middle base of this string should be at the; start of the variant in dv_call.; reads_for_samples: list by sample of Iterable of; third_party.nucleus.protos.Read objects that we'll use to encode the; read information supporting our call. Assumes each read is aligned and; is well-formed (e.g., has bases and quality scores, cigar). Rows",MatchSource.CODE_COMMENT,deepvariant/pileup_image.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/pileup_image.py
Safety,predict,predict,"nnel 5 (base differs from ref) of both alts as channels.; """"""High-level API for creating images of pileups of reads and reference bases. This class provides a higher-level and more natural API for constructing; images at a candidate variant call site. Given a DeepVariantCall, which; contains the candidate variant call along with key supplementary information,; this class provides create_pileup_images() that will do all of the necessary; fetching of reads and reference bases from readers and pass those off to the; lower-level PileupImageEncoder to construct the image Tensor. for dv_call in candidates:; allele_and_images = pic.create_pileup_images(dv_call); ... A quick note on how we deal with multiple alt alleles:. Suppose variant has ref and two alt alleles. Assuming the sample is diploid,; we have the following six possible genotypes:. ref/ref => 0/0; ref/alt1 => 0/1; alt1/alt1 => 1/1; ref/alt2 => 0/2; alt1/alt2 => 1/2; alt2/alt2 => 2/2. In DeepVariant we predict the genotype count (0, 1, 2) for a specific set of; alternate alleles. If we only had a single alt, we'd construct an image for; ref vs. alt1:. image1 => ref vs. alt1 => determine if we are 0/0, 0/1, 1/1. If we add a second image for alt2, we get:. image2 => ref vs. alt2 => determine if we are 0/0, 0/2, 2/2. but the problem here is that we don't have a good estimate for the het-alt; state 1/2. So we construct a third image contrasting ref vs. either alt1 or; alt2:. image3 => ref vs. alt1 or alt2 => determines 0/0, 0/{1,2}, {1,2}/{1,2}. Given the predictions for each image:. image1 => p00, p01, p11; image2 => p00, p02, p22; image3 => p00, p0x, pxx where x is {1,2}. we calculate our six genotype likelihoods as:. 0/0 => p00 [from any image]; 0/1 => p01 [image1]; 1/1 => p11 [image1]; 0/2 => p02 [image2]; 2/2 => p22 [image2]; 1/2 => pxx [image3]. The function create_pileup_images() returns all of the necessary images, along; with the alt alleles used for each image.; """"""; """"""Gets attributes from self._options as",MatchSource.CODE_COMMENT,deepvariant/pileup_image.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/pileup_image.py
Usability,learn,learning,"erence bases or None. Returns None if the reference; interval for variant isn't valid for some reason.; """"""; """"""Yields the set of all alt_alleles for variant. This function computes the sets of alt_alleles we want to use to cover all; genotype likelihood calculations we need for n alt alleles (see class docs; for background). The easiest way to do this is to calculate all combinations; of 2 alleles from ref + alts and then strip away the reference alleles,; leaving us with the set of alts for the pileup image encoder. The sets are; converted to sorted lists at the end for downstream consistency. Args:; variant: third_party.nucleus.protos.Variant to generate the alt allele; combinations for. Yields:; A series of lists containing the alt alleles we want to use for a single; pileup image. The entire series covers all combinations of alt alleles; needed for variant. Raises:; ValueError: if options.multi_allelic_mode is UNSPECIFIED.; """"""; """"""Creates a pileup tensor for dv_call. Args:; dv_call: learning.genomics.deepvariant.DeepVariantCall object with; information on our candidate call and allele support information.; refbases: A string options.width in length containing the reference base; sequence to encode. The middle base of this string should be at the; start of the variant in dv_call.; reads_for_samples: list by sample of Iterable of; third_party.nucleus.protos.Read objects that we'll use to encode the; read information supporting our call. Assumes each read is aligned and; is well-formed (e.g., has bases and quality scores, cigar). Rows of the; image are encoded in the same order as reads.; alt_alleles: A collection of alternative_bases from dv_call.variant that; we are treating as ""alt"" when constructing this pileup image. A read; will be considered supporting the ""alt"" allele if it occurs in the; support list for any alt_allele in this collection.; sample_order: A list of indices representing the order in which samples; should be represented in the pileup image. ",MatchSource.CODE_COMMENT,deepvariant/pileup_image.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/pileup_image.py
Availability,error,error,"otypes flag.; """"""Tests of PileupImageCreator build_pileup routine for Trio.""""""; # Setup our shared mocks.; # pylint: disable=unused-argument; """"""Checks that actual_image matches an image from constructed row_names.""""""; # This image is created just from reference and no reads. Checks that the; # function is listening to all of our image creation parameters (e.g.,; # reference_band_height, width, height, etc) and is filling the image with; # empty rows when it runs out of reads.; # This image is created just from reference and no reads. Checks that the; # function is listening to all of our image creation parameters (e.g.,; # reference_band_height, width, height, etc) and is filling the image with; # empty rows when it runs out of reads.; # We add a single read to our image.; # Read1 should be dropped because there's only space for Read2 and Read4.; # If there are more reads than rows, a deterministic random subset is used.; # Read 3 is bad (return value is None) so it should be skipped.; # Read 3 is bad (return value is None) so it should be skipped. Read2 should; # also be dropped because there's only space for Read1 and Read4. If there; # are more reads than rows, a deterministic random subset is used.; # Parent and child image heights differ.; # Read1 should be dropped because there's only space for Read2 and Read4.; # If there are more reads than rows, a deterministic random subset is used.; # For parents, Read4 will also be dropped.; # Order of pileup images in build_pileup can be controlled by sample_order.; # The represent_alt_aligned_pileups function checks for shape of the; # arrays, so mock with actual numpy arrays here.; # Pileup for 'C':; # Pileup for 'T':; # Pileup for 'C/T':; # Deliberatly make the length different from self.pic.width.; # Test with one alt image.; # Test with two alt images.; # Representation must be one of the valid options.; # Different shapes of input images should raise error.; # Different shapes of input images should raise error.",MatchSource.CODE_COMMENT,deepvariant/pileup_image_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/pileup_image_test.py
Integrability,rout,routine,"ard reads with low mapping quality. We have the following scenario:. position 0 1 2 3 4 5; reference A A C A G; read A A A; variant C. We set the mapping quality of the read to different values of; `mapping_qual`. All bases in the read have base quality greater than; `min_base_qual`. The read should only be kept if; `mapping_qual` > `min_mapping_qual`. Args:; min_base_qual: Reads are discarded if the base at a variant start position; does not meet this base quality requirement.; min_mapping_qual: Reads are discarded if they do not meet this mapping; quality requirement.; """"""; # alt_allele is C, supported by only frag 1 of read1 and frag 2 of read 3.; # alt_allele is now G, so only read2 (both frags) support alt.; """"""supports_alt is encoded as the 5th channel out of the 7 channels.""""""; # This read isn't present in allele support for 'C'.; # This read isn't present in allele support for 'C'.; """"""supports_alt is encoded as the 5th channel out of the 7 channels.""""""; """"""Tests of PileupImageCreator build_pileup routine.""""""; # Setup our shared mocks.; # pylint: disable=unused-argument; """"""Checks that actual_image matches an image from constructed row_names.""""""; # This image is created just from reference and no reads. Checks that the; # function is listening to all of our image creation parameters (e.g.,; # reference_band_height, width, height, etc) and is filling the image with; # empty rows when it runs out of reads.; # We add a single read to our image.; # Read1 should be dropped because there's only space for Read2 and Read4.; # If there are more reads than rows, a deterministic random subset is used.; # Read 3 is bad (return value is None) so it should be skipped.; # Read 3 is bad (return value is None) so it should be skipped. Read2 should; # also be dropped because there's only space for Read1 and Read4. If there; # are more reads than rows, a deterministic random subset is used.; # hp_tag_for_assembly_polishing=0 is the same as not setting it.; # The sorting order s",MatchSource.CODE_COMMENT,deepvariant/pileup_image_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/pileup_image_test.py
Testability,test,test,"WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for deepvariant.pileup_image.""""""; """"""Make a PileupImageEncoderNative with overrideable default options.""""""; """"""Make a PileupImageEncoderNative with overrideable default options.""""""; """"""Make a PileupImageEncoderNative with overrideable default options.""""""; # Base.; # Base quality.; # Mapping quality.; # Strand channel (forward or reverse); # Supports alt or not.; # Matches ref or not.; # Base.; # Base quality.; # Mapping quality.; # Strand channel (forward or reverse); # Supports alt or not.; # Matches ref or not.; # The corresponding colors here are defined in HPValueColor in; # pileup_image_native.cc.; # Reads with no HP values will resulted in a value of 0.; # And, the color of 1 and 2 should swap when; # hp_tag_for_assembly_polishing is set to 2.; # Same test case as test_encode_read_matches(), with --add_hp_channel.; # Base.; # Base quality.; # Mapping quality.; # Strand channel (forward or reverse); # Supports alt or not.; # Matches ref or not.; # HP value; # Same test case as test_encode_read_matches(), with allele frequency.; # Base.; # Base quality.; # Mapping quality.; # Strand channel (forward or reverse); # Supports alt or not.; # Matches ref or not.; # Allele frequencies; # pylint:disable=g-complex-comprehension; # pylint:enable=g-complex-comprehension; # Create our expected image row encoding.; # Base.; # Base quality.; # Mapping quality.; # Strand channel (forward or reverse); # Supports alt or not.; # Matches ref or not.; # ref: AACAG; # read: AA--G; # Base. The second A is 0 because it's the anchor of the deletion.; # Base quality.; # Mapping quality.; # Strand channel (forward or reverse); # Supports alt or not.; # Matches ref or not.; # ref: AA-CAG; # read: AAACAG; # Base.; # Base quality.; # Mapping quality.; # Strand channel (forward or reverse)",MatchSource.CODE_COMMENT,deepvariant/pileup_image_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/pileup_image_test.py
Availability,avail,available,"nd; position.; """"""; """"""Performs the grouping of CVOs and packages them into a list of kwargs. Args:; input_sorted_tfrecord_path: str. TFRecord format file containing sorted; CallVariantsOutput protos. Returns:; List of kwargs to be passed to invocations of the transform function.; """"""; """"""Unpacks the arguments to individual keyword arguments.""""""; """"""Return True if CSI index is to be used over tabix index format. If the length of any reference chromosomes exceeds 512M; (here we use 5e8 to keep a safety margin), we will choose csi; as the index format. Otherwise we use tbi as default. Args:; contigs: list of contigs. Returns:; A boolean variable indicating if the csi format is to be used or not.; """"""; """"""A helper function for indexing VCF files. Args:; vcf_file: string. Path to the VCF file to be indexed.; csi: bool. If true, index using the CSI format.; """"""; """"""Returns sharded filenames for and one record from CVO input file.""""""; # Input is already sharded, so dynamic sharding check is disabled.; # Input is expected to be dynamically sharded.; # This check is to make sure all files we glob is exactly the same as the; # paths we create, otherwise we have multiple file patterns.; """"""Determines the sample name to be used for the output VCF and gVCF. We check the following sources to determine the sample name and use the first; name available:; 1) CallVariantsOutput; 2) nonvariant site TFRecords; 3) --sample_name flag; 4) default sample name. Returns:; sample_name used when writing the output VCF and gVCF.; """"""; # Unused.; # Using the heuristic #CVOs / #cpus; # Dump all processed variants to the disk so that the C++; # merge_and_write_variants_and_nonvariants logic can access them.; # Note: This takes a really long time, but not because of the writing to; # the disk, but rather because it runs all the transformations on the; # variants at this point and not later on.; # That is fine, and there is no need to blame this part of the code when; # noticing how long it takes.",MatchSource.CODE_COMMENT,deepvariant/postprocess_variants.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants.py
Deployability,update,update," # exactly one element. There are the pileup images that contains information; # like:; # p00, p01, p11; # or p00, p02, p22; # ...p00, p0N, pNN; # From here, we want to see which ones of these alt alleles (1-N) that we; # can skip. We can use the concept of QUAL in VCF, and filter out ones; # where QUAL < FLAGS.qual_filter. This is because if QUAL is too low,; # it means it is unlikely this has a variant genotype.; # Keep track of one alt allele with the highest qual score.; # If all alt alleles are below `qual_filter`, keep at least one.; """"""Facilitates removing alt alleles from a Variant. This class provides a one-to-shop for managing the information needed to; remove alternative alleles from Variant. It provides functions and properties; to get the original alts, the new alts, and asking if alleles (strings) or; indices (integers) should be retained or eliminated.; """"""; """"""Updates variant.call fields indexed by ref + alt_alleles. Args:; variant: Variant proto. We will update the info fields of the Variant.call; protos.; fields: Iterable of string. Each string should provide a key to an; alternative allele indexed field in VariantCall.info fields. Each field; specified here will be updated to remove values associated with alleles; no longer wanted according to this remapper object.; """"""; # We cannot do entry.values[:] = updated as the ListValue type ""does; # not support assignment"" so we have to do this grossness.; """"""Remove the alt alleles in alt_alleles_to_remove from canonical_variant. Args:; variant: variants_pb2.Variant.; alt_alleles_to_remove: iterable of str. Alt alleles to remove from variant. Returns:; variants_pb2.Variant with the alt alleles removed from alternate_bases.; """"""; # If we aren't removing any alt alleles, just return the unmodified variant.; # Cleanup any VariantCall.info fields indexed by alt allele.; """"""Return 9 values for 3 distributions from given multiallelic CVOs. This function is only called for sites with two alt alleles remaining aft",MatchSource.CODE_COMMENT,deepvariant/postprocess_variants.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants.py
Modifiability,config,configured," was set, it's about 20 seconds per log.; # When outputting all alt alleles, use placeholder value to indicate genotype; # will be soft-filtered.; """"""Returns the name of the single sample within the CallVariantsOutput file. Args:; record: A deepvariant_pb2.CallVariantsOutput record. Returns:; The name of the single individual in the first proto in the file. Raises:; ValueError: There is not exactly one VariantCall in the proto or the; call_set_name of the VariantCall is not populated.; """"""; """"""Computes the filter fields for this variant. Variant filters are generated based on its quality score value and particular; genotype call. Args:; variant: Variant to filter.; min_quality: Minimum acceptable phred scaled variant detection probability. Returns:; Filter field strings to be added to the variant.; """"""; """"""Prepends a prefix to the file_path when accessing Google files. Args:; file_path: str. Full path pointing a specific file to access with pysam. Returns:; str. The full configured file path for pysam to open.; """"""; # BEGN_INTERNAL; # END_INTERNAL; """"""Gets the most likely genotype from predictions. From https://samtools.github.io/hts-specs/VCFv4.3.pdf:. Genotype Ordering. In general case of ploidy P and N alternate alleles (0 is; the REF and 1..N the alternate alleles), the ordering of genotypes for the; likelihoods can be expressed by the following pseudocode with as many nested; loops as ploidy:. * Note that we use inclusive for loop boundaries.; for a_P = 0 . . . N; for a_P-1 = 0 . . . aP; . . .; for a_1 = 0 . . . a2; println a1 a2 . . . aP. Alternatively, the same can be achieved recursively with the following; pseudocode:. Ordering (P , N , suffix =""""):; for a in 0 . . . N; if (P == 1) println str (a) + suffix; if (P > 1) Ordering (P -1 , a, str (a) + suffix). Examples:; * for P=2 and N=1, the ordering is 00,01,11; * for P=2 and N=2, the ordering is 00,01,11,02,12,22; * for P=3 and N=2, the ordering is 000,001,011,111,002,012,112,022,122,222; * for P=1, the inde",MatchSource.CODE_COMMENT,deepvariant/postprocess_variants.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants.py
Safety,detect,detection,"need to be cleaned up if we remove any alt alleles. Any info field; # listed here will be have its values cleaned up if we've removed any alt; # alleles.; # Each tuple contains: field name, ref_is_zero.; # The number of places past the decimal point to round QUAL estimates to.; # When this was set, it's about 20 seconds per log.; # When outputting all alt alleles, use placeholder value to indicate genotype; # will be soft-filtered.; """"""Returns the name of the single sample within the CallVariantsOutput file. Args:; record: A deepvariant_pb2.CallVariantsOutput record. Returns:; The name of the single individual in the first proto in the file. Raises:; ValueError: There is not exactly one VariantCall in the proto or the; call_set_name of the VariantCall is not populated.; """"""; """"""Computes the filter fields for this variant. Variant filters are generated based on its quality score value and particular; genotype call. Args:; variant: Variant to filter.; min_quality: Minimum acceptable phred scaled variant detection probability. Returns:; Filter field strings to be added to the variant.; """"""; """"""Prepends a prefix to the file_path when accessing Google files. Args:; file_path: str. Full path pointing a specific file to access with pysam. Returns:; str. The full configured file path for pysam to open.; """"""; # BEGN_INTERNAL; # END_INTERNAL; """"""Gets the most likely genotype from predictions. From https://samtools.github.io/hts-specs/VCFv4.3.pdf:. Genotype Ordering. In general case of ploidy P and N alternate alleles (0 is; the REF and 1..N the alternate alleles), the ordering of genotypes for the; likelihoods can be expressed by the following pseudocode with as many nested; loops as ploidy:. * Note that we use inclusive for loop boundaries.; for a_P = 0 . . . N; for a_P-1 = 0 . . . aP; . . .; for a_1 = 0 . . . a2; println a1 a2 . . . aP. Alternatively, the same can be achieved recursively with the following; pseudocode:. Ordering (P , N , suffix =""""):; for a in 0 . . . N; if ",MatchSource.CODE_COMMENT,deepvariant/postprocess_variants.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants.py
Security,access,accessing,"any alt; # alleles.; # Each tuple contains: field name, ref_is_zero.; # The number of places past the decimal point to round QUAL estimates to.; # When this was set, it's about 20 seconds per log.; # When outputting all alt alleles, use placeholder value to indicate genotype; # will be soft-filtered.; """"""Returns the name of the single sample within the CallVariantsOutput file. Args:; record: A deepvariant_pb2.CallVariantsOutput record. Returns:; The name of the single individual in the first proto in the file. Raises:; ValueError: There is not exactly one VariantCall in the proto or the; call_set_name of the VariantCall is not populated.; """"""; """"""Computes the filter fields for this variant. Variant filters are generated based on its quality score value and particular; genotype call. Args:; variant: Variant to filter.; min_quality: Minimum acceptable phred scaled variant detection probability. Returns:; Filter field strings to be added to the variant.; """"""; """"""Prepends a prefix to the file_path when accessing Google files. Args:; file_path: str. Full path pointing a specific file to access with pysam. Returns:; str. The full configured file path for pysam to open.; """"""; # BEGN_INTERNAL; # END_INTERNAL; """"""Gets the most likely genotype from predictions. From https://samtools.github.io/hts-specs/VCFv4.3.pdf:. Genotype Ordering. In general case of ploidy P and N alternate alleles (0 is; the REF and 1..N the alternate alleles), the ordering of genotypes for the; likelihoods can be expressed by the following pseudocode with as many nested; loops as ploidy:. * Note that we use inclusive for loop boundaries.; for a_P = 0 . . . N; for a_P-1 = 0 . . . aP; . . .; for a_1 = 0 . . . a2; println a1 a2 . . . aP. Alternatively, the same can be achieved recursively with the following; pseudocode:. Ordering (P , N , suffix =""""):; for a in 0 . . . N; if (P == 1) println str (a) + suffix; if (P > 1) Ordering (P -1 , a, str (a) + suffix). Examples:; * for P=2 and N=1, the ordering is 00,",MatchSource.CODE_COMMENT,deepvariant/postprocess_variants.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants.py
Testability,log,log,"R CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Postprocess output from call_variants to produce a VCF file.""""""; # TODO: Add type annotations to this module; # Some format fields are indexed by alt allele, such as AD (depth by allele).; # These need to be cleaned up if we remove any alt alleles. Any info field; # listed here will be have its values cleaned up if we've removed any alt; # alleles.; # Each tuple contains: field name, ref_is_zero.; # The number of places past the decimal point to round QUAL estimates to.; # When this was set, it's about 20 seconds per log.; # When outputting all alt alleles, use placeholder value to indicate genotype; # will be soft-filtered.; """"""Returns the name of the single sample within the CallVariantsOutput file. Args:; record: A deepvariant_pb2.CallVariantsOutput record. Returns:; The name of the single individual in the first proto in the file. Raises:; ValueError: There is not exactly one VariantCall in the proto or the; call_set_name of the VariantCall is not populated.; """"""; """"""Computes the filter fields for this variant. Variant filters are generated based on its quality score value and particular; genotype call. Args:; variant: Variant to filter.; min_quality: Minimum acceptable phred scaled variant detection probability. Returns:; Filter field strings to be added to the variant.; """"""; """"""Prepends a prefix to the file_path when accessing Google files. Args:; file_path: str. Full path pointing a specific file to access with pysam. Returns:; str. The full configured file path for pys",MatchSource.CODE_COMMENT,deepvariant/postprocess_variants.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants.py
Usability,simpl,simplify,"t_likely_genotype for details.; # Each heterozyhous probability is zeroed. For example, for biallelic case; # the probability of 0/1 genotype becomes zero.; """"""Returns True if variant is non_autosome.""""""; """"""Returns True of variant overlaps one of the regions.""""""; """"""Merges the predictions from the multi-allelic calls.""""""; # See the logic described in the class PileupImageCreator pileup_image.py; #; # Because of the logic above, this function expects all cases above to have; # genotype_predictions that we can combine from.; # Removed par regions from parameter because RangeSet is not pickle-able.; # Special handling of multiallelic variants; # flattened_probs_dict is only used with the multiallelic model; # Run alternate model for multiallelic cases.; # We have 3 CVOs for 2 alts. In this case, there are 6 possible genotypes.; # Note the simplify_variant_alleles call *must* happen after the predictions; # calculation above. flattened_probs_dict is indexed by alt allele, and; # simplify can change those alleles so we cannot simplify until afterwards.; """"""Writes Variant protos to a VCF file. Args:; variant_iterable: iterable. An iterable of sorted Variant protos.; output_vcf_path: str. Output file in VCF format.; header: VcfHeader proto. The VCF header to use for writing the variants.; """"""; """"""Transforms a group of CalVariantOutput to VariantOutput. The group of CVOs present in the call_variants_group are converted to the; Variant proto, with the following filters applied: 1) variants are omitted; if their quality is lower than the `qual_filter` threshold. 2) multi-allelic; variants omit individual alleles whose qualities are lower than the; `multi_allelic_qual_filter` threshold. Args:; call_variant_group: list[CVO]. A group of CallVariantsOutput protos.; qual_filter: double. The qual value below which to filter variants.; multi_allelic_qual_filter: double. The qual value below which to filter; multi-allelic variants.; sample_name: str. Sample name to write to VCF file",MatchSource.CODE_COMMENT,deepvariant/postprocess_variants.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants.py
Availability,robust,robust," Example where all alt alleles are below qual_filter, but we keep one; # where the qual is highest among the ones filtered out.; # With 1 alt allele, we expect to see 1 alt_allele_indices: [0].; # With 2 alt alleles, we expect to see 3 alt_allele_indices.; # With 2 alt alleles, we expect to see 3 alt_allele_indices:; # [0], [1], [0, 1].; # With 3 alt alleles, we expect to see 6 alt_allele_indices.; # reference_bases have to be exactly the same.; # alternate_bases have to be exactly the same. Different orders are; # not acceptable either.; # Multi-allelic test examples.; """"""Ensures the order of GLs are interpreted correctly for triallelics.""""""; # Create a probability with 6 elements, one of them 0.995 (best genotype),; # and the rest 0.001.; # Q20 tests; # Q30 tests; # Q40 tests; # Test that this works with any sized genotype vector.; # Test that probabilities more extreme than genomics_math._MAX_CONFIDENCE; # are appropriately rounded.; # Make sure code is robust to minor numerical issues where the sum of; # the vector isn't exactly 1.0.; # This vector sums to ~1.0, minus any parsing uncertainty, and will; # return a GQ of 40 but a qual of MAX_QUAL.; # This vector sums to >1.0, but we should get back a max qual value; # instead of throwing an exception.; # Standard diploid case with 1 alt allele.; # Diploid case with 2 alt alleles.; # This generates too many tests as a parameterized test.; # First test with no alleleic depth.; # Now add hom ref genotype and AD --> qual shouldn't affect filter field; # Now add variant genotype --> qual filter should matter again; # Example where all alt alleles are below qual_filter, but we keep one; # where the qual is highest among the ones filtered out.; # Check that we are simplifying alleles and that the simplification deps; # on the alleles we've removed.; # Removing the C allele allows us to simplify CAA + CA => CA + C.; # Removing the CA allele doesn't allow any simplification.; # Make sure we keep at least one anchor base wh",MatchSource.CODE_COMMENT,deepvariant/postprocess_variants_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants_test.py
Modifiability,parameteriz,parameterized,"lt_allele_indices.; # reference_bases have to be exactly the same.; # alternate_bases have to be exactly the same. Different orders are; # not acceptable either.; # Multi-allelic test examples.; """"""Ensures the order of GLs are interpreted correctly for triallelics.""""""; # Create a probability with 6 elements, one of them 0.995 (best genotype),; # and the rest 0.001.; # Q20 tests; # Q30 tests; # Q40 tests; # Test that this works with any sized genotype vector.; # Test that probabilities more extreme than genomics_math._MAX_CONFIDENCE; # are appropriately rounded.; # Make sure code is robust to minor numerical issues where the sum of; # the vector isn't exactly 1.0.; # This vector sums to ~1.0, minus any parsing uncertainty, and will; # return a GQ of 40 but a qual of MAX_QUAL.; # This vector sums to >1.0, but we should get back a max qual value; # instead of throwing an exception.; # Standard diploid case with 1 alt allele.; # Diploid case with 2 alt alleles.; # This generates too many tests as a parameterized test.; # First test with no alleleic depth.; # Now add hom ref genotype and AD --> qual shouldn't affect filter field; # Now add variant genotype --> qual filter should matter again; # Example where all alt alleles are below qual_filter, but we keep one; # where the qual is highest among the ones filtered out.; # Check that we are simplifying alleles and that the simplification deps; # on the alleles we've removed.; # Removing the C allele allows us to simplify CAA + CA => CA + C.; # Removing the CA allele doesn't allow any simplification.; # Make sure we keep at least one anchor base when pruning.; """"""Test that prune_alleles + simplify_variant_alleles works as expected.""""""; """"""Checks that merge_predictions simplifies alleles.""""""; # qual_filter=2 is needed so we remove our middle 'C' allele.; # Define valid flags to ensure raise occurs due to argv issues.; # This is the bad flag.; # TODO use itertools.permutations to improve the test.; # In sorted output, 1st ha",MatchSource.CODE_COMMENT,deepvariant/postprocess_variants_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants_test.py
Safety,detect,detection,"YRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for deepvariant .postprocess_variants.""""""; # Start: 9995000, End: 63025519; """"""A mock VcfWriter that records the variants written in a list.""""""; """"""Creates a Variant record for testing. Args:; ref_name: reference name for this variant; start: start position on the contig; ref_base: reference base(s); alt_bases: list(str). alternate base(s); qual: PHRED scaled detection probability; filter_field: filter string for this variant; genotype: list of integers corresponding to the called genotype; gq: PHRED scaled genotype quality; likelihoods: genotype likelihoods for this variant; ad: list of integers corresponding to allelic depths. Returns:; A Variant record created with the specified arguments.; """"""; """"""Creates a Variant record with specified alternate_bases.""""""; """"""Creates a non-variant Variant record for testing. Args:; ref_name: str. Reference name for this variant.; start: int. start position on the contig [0-based, half open).; end: int. end position on the contig [0-based, half open).; ref_base: str. reference base at the start position. Returns:; A non-variant Variant record created with the specified arguments.; """"""; # Call variants now produce sharded outputs so the golden test has been; # changed to have sharded input.; # However, the input filename should still not be in sharded pattern.; # So replacing the shard pattern to input pattern.; # When our i is 1 for the first alt allele, we expect that we will get back; # our keep_index_expected but al",MatchSource.CODE_COMMENT,deepvariant/postprocess_variants_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants_test.py
Testability,mock,mock,"used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for deepvariant .postprocess_variants.""""""; # Start: 9995000, End: 63025519; """"""A mock VcfWriter that records the variants written in a list.""""""; """"""Creates a Variant record for testing. Args:; ref_name: reference name for this variant; start: start position on the contig; ref_base: reference base(s); alt_bases: list(str). alternate base(s); qual: PHRED scaled detection probability; filter_field: filter string for this variant; genotype: list of integers corresponding to the called genotype; gq: PHRED scaled genotype quality; likelihoods: genotype likelihoods for this variant; ad: list of integers corresponding to allelic depths. Returns:; A Variant record created with the specified arguments.; """"""; """"""Creates a Variant record with specified alternate_bases.""""""; """"""Creates a non-variant Variant record for testing. Args:; ref_name: str. Reference name for this variant.; start: int. start position on the contig [0-based, half open).; end: int. end position on the contig [0-based, half open).; ref_base: str. reference base at the start position. Returns:; A non-variant Variant",MatchSource.CODE_COMMENT,deepvariant/postprocess_variants_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants_test.py
Usability,simpl,simplifying,"ly the same. Different orders are; # not acceptable either.; # Multi-allelic test examples.; """"""Ensures the order of GLs are interpreted correctly for triallelics.""""""; # Create a probability with 6 elements, one of them 0.995 (best genotype),; # and the rest 0.001.; # Q20 tests; # Q30 tests; # Q40 tests; # Test that this works with any sized genotype vector.; # Test that probabilities more extreme than genomics_math._MAX_CONFIDENCE; # are appropriately rounded.; # Make sure code is robust to minor numerical issues where the sum of; # the vector isn't exactly 1.0.; # This vector sums to ~1.0, minus any parsing uncertainty, and will; # return a GQ of 40 but a qual of MAX_QUAL.; # This vector sums to >1.0, but we should get back a max qual value; # instead of throwing an exception.; # Standard diploid case with 1 alt allele.; # Diploid case with 2 alt alleles.; # This generates too many tests as a parameterized test.; # First test with no alleleic depth.; # Now add hom ref genotype and AD --> qual shouldn't affect filter field; # Now add variant genotype --> qual filter should matter again; # Example where all alt alleles are below qual_filter, but we keep one; # where the qual is highest among the ones filtered out.; # Check that we are simplifying alleles and that the simplification deps; # on the alleles we've removed.; # Removing the C allele allows us to simplify CAA + CA => CA + C.; # Removing the CA allele doesn't allow any simplification.; # Make sure we keep at least one anchor base when pruning.; """"""Test that prune_alleles + simplify_variant_alleles works as expected.""""""; """"""Checks that merge_predictions simplifies alleles.""""""; # qual_filter=2 is needed so we remove our middle 'C' allele.; # Define valid flags to ensure raise occurs due to argv issues.; # This is the bad flag.; # TODO use itertools.permutations to improve the test.; # In sorted output, 1st has indices=[0].; # In sorted output, 2nd has indices=[0, 1].; # In sorted output, 3rd has indices=[1].",MatchSource.CODE_COMMENT,deepvariant/postprocess_variants_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants_test.py
Availability,avail,available,"e:. with ResourceMonitor() as monitor:; ... do work ...; metrics = monitor.metrics(); """"""; """"""Class for collecting resource usage info from this or child process.""""""; """"""Constructs a ResourceMonitor object.""""""; """"""Returns an initialized ResourceMetrics proto. This function also fills in the ""constant"" fields of the ResourceMetrics; proto that don't depend on the actual running commands, such as host_name. Returns:; learning.genomics.deepvariant.ResourceMetrics proto.; """"""; """"""Starts timers associated with resource collection. This method must be called before metrics(). Returns:; self to enable the idiom `monitor = ResourceMonitor().start()`.; """"""; """"""Collects and return runtime metrics as a ResourceMetrics proto. This method can be called multiple times, but wall clock time is always; reckoned from the time of the last start() call. Returns:; A learning.genomics.deepvariant.ResourceMetrics proto message. Raises:; RuntimeError: if start() was not called previously.; """"""; # Consider using psutil.cpu_times() instead to get more detailed information; # about the usage in self and all children.; # The OS call to get rusage failed, so just don't set the field values,; # leaving them as the default values of 0.; # Create a psutil.Process pointed at the current process.; # ------------------------------------------------------------------------------; # Simple functions for getting host_name, cpu count, etc. Isolated here to make; # them mockable.; # ------------------------------------------------------------------------------; """"""Gets the host name of this machine.""""""; """"""Gets the number of physical cores in this machine. Returns:; int >= 1 if the call to get the cpu_count succeeded, or 0 if not.; """"""; """"""Gets the frequency in MHz of the cpus in this machine. Returns:; float > 0 if the call to get the cpu_frequency succeeded. This information; may not be available on all systems, in which case we return 0.0.; """"""; """"""Gets the total memory in megabytes in this machine.""""""",MatchSource.CODE_COMMENT,deepvariant/resources.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/resources.py
Energy Efficiency,monitor,monitor,"THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Library to gather runtime performance metrics. This module exposes the ResourceMonitor class, which client code can use to; gather resource usage metrics about their program. An example usage would look; something like:. with ResourceMonitor() as monitor:; ... do work ...; metrics = monitor.metrics(); """"""; """"""Class for collecting resource usage info from this or child process.""""""; """"""Constructs a ResourceMonitor object.""""""; """"""Returns an initialized ResourceMetrics proto. This function also fills in the ""constant"" fields of the ResourceMetrics; proto that don't depend on the actual running commands, such as host_name. Returns:; learning.genomics.deepvariant.ResourceMetrics proto.; """"""; """"""Starts timers associated with resource collection. This method must be called before metrics(). Returns:; self to enable the idiom `monitor = ResourceMonitor().start()`.; """"""; """"""Collects and return runtime metrics as a ResourceMetrics proto. This method can be called multiple times, but wall clock time is always; reckoned from the time of the last start() call. Returns:; A learning.genomics.deepvariant.ResourceMetrics proto message. Raises:; RuntimeError: if start() was not called previously.; """"""; # Consider using psutil.cpu_times() ",MatchSource.CODE_COMMENT,deepvariant/resources.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/resources.py
Integrability,depend,depend,"CT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Library to gather runtime performance metrics. This module exposes the ResourceMonitor class, which client code can use to; gather resource usage metrics about their program. An example usage would look; something like:. with ResourceMonitor() as monitor:; ... do work ...; metrics = monitor.metrics(); """"""; """"""Class for collecting resource usage info from this or child process.""""""; """"""Constructs a ResourceMonitor object.""""""; """"""Returns an initialized ResourceMetrics proto. This function also fills in the ""constant"" fields of the ResourceMetrics; proto that don't depend on the actual running commands, such as host_name. Returns:; learning.genomics.deepvariant.ResourceMetrics proto.; """"""; """"""Starts timers associated with resource collection. This method must be called before metrics(). Returns:; self to enable the idiom `monitor = ResourceMonitor().start()`.; """"""; """"""Collects and return runtime metrics as a ResourceMetrics proto. This method can be called multiple times, but wall clock time is always; reckoned from the time of the last start() call. Returns:; A learning.genomics.deepvariant.ResourceMetrics proto message. Raises:; RuntimeError: if start() was not called previously.; """"""; # Consider using psutil.cpu_times() instead to get more detailed information; # about the usage in self and all children.; # The OS call to get rusage failed, so just don't set the field values,; # leaving them as the default values of 0.; # Create a psutil.Process pointed at the current process.; # -----------------------------------------------",MatchSource.CODE_COMMENT,deepvariant/resources.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/resources.py
Performance,perform,performance,"e name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Library to gather runtime performance metrics. This module exposes the ResourceMonitor class, which client code can use to; gather resource usage metrics about their program. An example usage would look; something like:. with ResourceMonitor() as monitor:; ... do work ...; metrics = monitor.metrics(); """"""; """"""Class for collecting resource usage info from this or child process.""""""; """"""Constructs a ResourceMonitor object.""""""; """"""Returns an initialized ResourceMetrics proto. This function also fills in the ""constant"" fields of the ResourceMetrics; proto that don't depend on the actual running commands, such as host_name. Returns:; learning.genomics.deepvariant.ResourceMetrics proto.; """"""; """"""Starts timers associated with resource collection. This method must be called before metrics(). Returns:; self to enable the idiom `monitor = ResourceMonitor().start()`.; """"""; """"""Collects and return runtime metrics as a ResourceMetrics proto. This method can be called multiple times, but wall clock time is always; reckone",MatchSource.CODE_COMMENT,deepvariant/resources.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/resources.py
Security,expose,exposes," or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Library to gather runtime performance metrics. This module exposes the ResourceMonitor class, which client code can use to; gather resource usage metrics about their program. An example usage would look; something like:. with ResourceMonitor() as monitor:; ... do work ...; metrics = monitor.metrics(); """"""; """"""Class for collecting resource usage info from this or child process.""""""; """"""Constructs a ResourceMonitor object.""""""; """"""Returns an initialized ResourceMetrics proto. This function also fills in the ""constant"" fields of the ResourceMetrics; proto that don't depend on the actual running commands, such as host_name. Returns:; learning.genomics.deepvariant.ResourceMetrics proto.; """"""; """"""Starts timers associated with resource collection. This method must be called before metrics(). Returns:; self to enable the idiom `monitor = ResourceMonitor().start()`.; """"""; """"""Collects and return runtime metrics as a ResourceMetrics proto. This method can be called multiple times, but wall clock time is always; reckoned from the time of the last start() call. Returns:; A learning.genomics.deepvariant.Resou",MatchSource.CODE_COMMENT,deepvariant/resources.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/resources.py
Testability,mock,mockable,"e:. with ResourceMonitor() as monitor:; ... do work ...; metrics = monitor.metrics(); """"""; """"""Class for collecting resource usage info from this or child process.""""""; """"""Constructs a ResourceMonitor object.""""""; """"""Returns an initialized ResourceMetrics proto. This function also fills in the ""constant"" fields of the ResourceMetrics; proto that don't depend on the actual running commands, such as host_name. Returns:; learning.genomics.deepvariant.ResourceMetrics proto.; """"""; """"""Starts timers associated with resource collection. This method must be called before metrics(). Returns:; self to enable the idiom `monitor = ResourceMonitor().start()`.; """"""; """"""Collects and return runtime metrics as a ResourceMetrics proto. This method can be called multiple times, but wall clock time is always; reckoned from the time of the last start() call. Returns:; A learning.genomics.deepvariant.ResourceMetrics proto message. Raises:; RuntimeError: if start() was not called previously.; """"""; # Consider using psutil.cpu_times() instead to get more detailed information; # about the usage in self and all children.; # The OS call to get rusage failed, so just don't set the field values,; # leaving them as the default values of 0.; # Create a psutil.Process pointed at the current process.; # ------------------------------------------------------------------------------; # Simple functions for getting host_name, cpu count, etc. Isolated here to make; # them mockable.; # ------------------------------------------------------------------------------; """"""Gets the host name of this machine.""""""; """"""Gets the number of physical cores in this machine. Returns:; int >= 1 if the call to get the cpu_count succeeded, or 0 if not.; """"""; """"""Gets the frequency in MHz of the cpus in this machine. Returns:; float > 0 if the call to get the cpu_frequency succeeded. This information; may not be available on all systems, in which case we return 0.0.; """"""; """"""Gets the total memory in megabytes in this machine.""""""",MatchSource.CODE_COMMENT,deepvariant/resources.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/resources.py
Usability,learn,learning,"IMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Library to gather runtime performance metrics. This module exposes the ResourceMonitor class, which client code can use to; gather resource usage metrics about their program. An example usage would look; something like:. with ResourceMonitor() as monitor:; ... do work ...; metrics = monitor.metrics(); """"""; """"""Class for collecting resource usage info from this or child process.""""""; """"""Constructs a ResourceMonitor object.""""""; """"""Returns an initialized ResourceMetrics proto. This function also fills in the ""constant"" fields of the ResourceMetrics; proto that don't depend on the actual running commands, such as host_name. Returns:; learning.genomics.deepvariant.ResourceMetrics proto.; """"""; """"""Starts timers associated with resource collection. This method must be called before metrics(). Returns:; self to enable the idiom `monitor = ResourceMonitor().start()`.; """"""; """"""Collects and return runtime metrics as a ResourceMetrics proto. This method can be called multiple times, but wall clock time is always; reckoned from the time of the last start() call. Returns:; A learning.genomics.deepvariant.ResourceMetrics proto message. Raises:; RuntimeError: if start() was not called previously.; """"""; # Consider using psutil.cpu_times() instead to get more detailed information; # about the usage in self and all children.; # The OS call to get rusage failed, so just don't set the field values,; # leaving them as the default values of 0.; # Create a psutil.Process pointed at the current process.; # ------------------------------------------------------------------------------; # Simple functions for getting host_name, cpu count",MatchSource.CODE_COMMENT,deepvariant/resources.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/resources.py
Availability,avail,available,"INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for learning.genomics.deepvariant.resources.""""""; # https://stackoverflow.com/questions/34630393/python2-7-contextlib-exitstack-equivalent; # We want to actually make all of the real function calls under test, but; # we of course don't know their values and can only do sanity checks.; # We unfortunately cannot make sure that read_bytes and write_bytes is; # greater than zero, so these tests are commented out.; # self.assertGreater(metrics.read_bytes, 0); # self.assertGreater(metrics.write_bytes, 0); # CPU frequency may not be available on all systems, so the value is; # either a real frequency (> 0) or the magic value of 0.0 indicating that; # the value could not be determined.; # 3 Megabytes; # Environment metrics; all mocked out.; # Runtime metrics; they are all mocked out.; # Some psutil functions, such as cpu_freq(), can return None depending on; # the environment; make sure we don't crash when that occurs.; # Some psutil functions, such as cpu_freq(), can return None depending on; # the environment; make sure we don't crash when that occurs.; # psutil.cpu_freq() can throw NotImplementedError in certain environments;; # make sure we don't crash when that occurs.; # Some psutil functions, such as cpu_freq(), can return None depending on; # the environment; make sure we don't crash when that occurs.",MatchSource.CODE_COMMENT,deepvariant/resources_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/resources_test.py
Integrability,depend,depending,"INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for learning.genomics.deepvariant.resources.""""""; # https://stackoverflow.com/questions/34630393/python2-7-contextlib-exitstack-equivalent; # We want to actually make all of the real function calls under test, but; # we of course don't know their values and can only do sanity checks.; # We unfortunately cannot make sure that read_bytes and write_bytes is; # greater than zero, so these tests are commented out.; # self.assertGreater(metrics.read_bytes, 0); # self.assertGreater(metrics.write_bytes, 0); # CPU frequency may not be available on all systems, so the value is; # either a real frequency (> 0) or the magic value of 0.0 indicating that; # the value could not be determined.; # 3 Megabytes; # Environment metrics; all mocked out.; # Runtime metrics; they are all mocked out.; # Some psutil functions, such as cpu_freq(), can return None depending on; # the environment; make sure we don't crash when that occurs.; # Some psutil functions, such as cpu_freq(), can return None depending on; # the environment; make sure we don't crash when that occurs.; # psutil.cpu_freq() can throw NotImplementedError in certain environments;; # make sure we don't crash when that occurs.; # Some psutil functions, such as cpu_freq(), can return None depending on; # the environment; make sure we don't crash when that occurs.",MatchSource.CODE_COMMENT,deepvariant/resources_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/resources_test.py
Safety,sanity check,sanity checks,"written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for learning.genomics.deepvariant.resources.""""""; # https://stackoverflow.com/questions/34630393/python2-7-contextlib-exitstack-equivalent; # We want to actually make all of the real function calls under test, but; # we of course don't know their values and can only do sanity checks.; # We unfortunately cannot make sure that read_bytes and write_bytes is; # greater than zero, so these tests are commented out.; # self.assertGreater(metrics.read_bytes, 0); # self.assertGreater(metrics.write_bytes, 0); # CPU frequency may not be available on all systems, so the value is; # either a real frequency (> 0) or the magic value of 0.0 indicating that; # the value could not be determined.; # 3 Megabytes; # Environment metrics; all mocked out.; # Runtime metrics; they are all mocked out.; # Some psutil functions, such as cpu_freq(), can return None depending on; # the environment; make sure we don't crash when that occurs.; # Some psutil functions, such as cpu_freq(), can return None depending on; # the environment; make sure we don't crash when that occurs.; # psutil.cpu_freq() can throw NotImplementedError in certain environments;; # make sure we don't crash when that oc",MatchSource.CODE_COMMENT,deepvariant/resources_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/resources_test.py
Testability,test,test,"written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for learning.genomics.deepvariant.resources.""""""; # https://stackoverflow.com/questions/34630393/python2-7-contextlib-exitstack-equivalent; # We want to actually make all of the real function calls under test, but; # we of course don't know their values and can only do sanity checks.; # We unfortunately cannot make sure that read_bytes and write_bytes is; # greater than zero, so these tests are commented out.; # self.assertGreater(metrics.read_bytes, 0); # self.assertGreater(metrics.write_bytes, 0); # CPU frequency may not be available on all systems, so the value is; # either a real frequency (> 0) or the magic value of 0.0 indicating that; # the value could not be determined.; # 3 Megabytes; # Environment metrics; all mocked out.; # Runtime metrics; they are all mocked out.; # Some psutil functions, such as cpu_freq(), can return None depending on; # the environment; make sure we don't crash when that occurs.; # Some psutil functions, such as cpu_freq(), can return None depending on; # the environment; make sure we don't crash when that occurs.; # psutil.cpu_freq() can throw NotImplementedError in certain environments;; # make sure we don't crash when that oc",MatchSource.CODE_COMMENT,deepvariant/resources_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/resources_test.py
Usability,learn,learning,"3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for learning.genomics.deepvariant.resources.""""""; # https://stackoverflow.com/questions/34630393/python2-7-contextlib-exitstack-equivalent; # We want to actually make all of the real function calls under test, but; # we of course don't know their values and can only do sanity checks.; # We unfortunately cannot make sure that read_bytes and write_bytes is; # greater than zero, so these tests are commented out.; # self.assertGreater(metrics.read_bytes, 0); # self.assertGreater(metrics.write_bytes, 0); # CPU frequency may not be available on all systems, so the value is; # either a real frequency (> 0) or the magic value of 0.0 indicating that; # the value could not be determined.; # 3 Megabytes; # Environment metrics; all mocked out.; # Runtime metrics; they are all mocked out.; # Some psutil functions, such as cpu_freq(), can return None depending on; # the environment; make sure we don't crash when that occurs.; # Some psutil functions, such as cpu_freq(), can return None depending on; #",MatchSource.CODE_COMMENT,deepvariant/resources_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/resources_test.py
Deployability,update,updated,"XEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; # Altair uses a lot of method chaining, such as; # chart.mark_bar().encode(...).properties(...), so using backslash; # continuation to break this into separate lines makes the code more readable.; # pylint: disable=g-backslash-continuation; """"""; <style>; body {; font-family: sans-serif;; }; .chart-container {; padding: 30px;; }; </style>; """"""; """"""Imports data from a single or sharded path into a pandas dataframe. Args:; path_string: The path to the input file, which may be sharded. Returns:; A dataframe matching the TSV file(s) but with added Task column.; """"""; # Once pandas is updated to 0.24+, pd.read_csv will work for gs://; # without this workaround.; """"""Creates a nice format string from a potentially large number of seconds. Args:; raw_seconds: A number of seconds. Returns:; The seconds divided into hours, minutes, and remaining seconds, formatted; nicely. For example, 2h3m5.012s.; """"""; """"""Calculates total runtime, formats it nicely, and sorts by it. Args:; df: A dataframe of runtime profiling numbers. Returns:; The same dataframe with some additional summary columns.; """"""; # 'total runtime' is a simple sum of the runtime columns.; # Create a formatted runtime string for tooltips.; # Sort by descending total region runtime.; """"""Groups regions to get the total runtime for each task. Args:; df: A dataframe of runtime profiling numbers. Returns:; The dataframe grouped by task.; """"""; """"""Plots a histogram of runtimes stacked by stage. Args:; d: A dataframe of runtimes, either by region or by task.; title: A title for the plot. Returns:; An altair chart.;",MatchSource.CODE_COMMENT,deepvariant/runtime_by_region_vis.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/runtime_by_region_vis.py
Energy Efficiency,reduce,reduce,"p description. Args:; row: A Pandas Series, one row of a dataframe containing some specific; cumulative sum columns. Returns:; A string to show as the tooltip for a pareto curve.; """"""; """"""Calculates cumulative sums for a subset of a dataframe. Args:; df_subset: A dataframe subset of one task. Returns:; The same dataframe subset with some additional columns.; """"""; # These are the same for all regions in the same task, for the scatter plot:; # These are cumulative sums for the pareto curves:; """"""Creates an interactive Pareto curve and scatter plot of task runtimes. Tracing each curve shows to what extent a small proportion of long-running; regions contribute disproportionately to the overall runtime. That is,; ""The longest-running X% of regions account for Y% of the total runtime.""; There is a curve for each task. Args:; df: A dataframe of all regions. Returns:; An altair chart.; """"""; # Sample along the Pareto curve, ensuring the longest regions are shown.; # Limit columns to greatly reduce the size of the html report.; # Brushing on the task_scatter plot highlights the same tasks in the Pareto; # curve.; # This chart needs to use the same dataframe as the first chart to enable the; # brushing on one to affect the other. Using max(task) for 'text' is a; # trick that causes bundling by task to avoid showing multiple overlapping; # points which otherwise make the text look funky.; """"""Makes a stacked bar chart with runtime of each stage for individual regions. Args:; small_df: A dataframe of regions, each of which will be shown as a bar.; title: A title for the plot. If a dict, it should contain 'title' and/or; 'subtitle'. Returns:; An altair chart.; """"""; """"""Creates a stacked bar charts of the top 20 and median 20 regions. Args:; df: A dataframe of all regions. Returns:; An altair chart.; """"""; """"""Creates a chart of the top regions that produced zero examples. Args:; df: A dataframe of all regions. Returns:; An altair chart.; """"""; """"""Loads data from a file into one datafr",MatchSource.CODE_COMMENT,deepvariant/runtime_by_region_vis.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/runtime_by_region_vis.py
Safety,avoid,avoid,"rame subset with some additional columns.; """"""; # These are the same for all regions in the same task, for the scatter plot:; # These are cumulative sums for the pareto curves:; """"""Creates an interactive Pareto curve and scatter plot of task runtimes. Tracing each curve shows to what extent a small proportion of long-running; regions contribute disproportionately to the overall runtime. That is,; ""The longest-running X% of regions account for Y% of the total runtime.""; There is a curve for each task. Args:; df: A dataframe of all regions. Returns:; An altair chart.; """"""; # Sample along the Pareto curve, ensuring the longest regions are shown.; # Limit columns to greatly reduce the size of the html report.; # Brushing on the task_scatter plot highlights the same tasks in the Pareto; # curve.; # This chart needs to use the same dataframe as the first chart to enable the; # brushing on one to affect the other. Using max(task) for 'text' is a; # trick that causes bundling by task to avoid showing multiple overlapping; # points which otherwise make the text look funky.; """"""Makes a stacked bar chart with runtime of each stage for individual regions. Args:; small_df: A dataframe of regions, each of which will be shown as a bar.; title: A title for the plot. If a dict, it should contain 'title' and/or; 'subtitle'. Returns:; An altair chart.; """"""; """"""Creates a stacked bar charts of the top 20 and median 20 regions. Args:; df: A dataframe of all regions. Returns:; An altair chart.; """"""; """"""Creates a chart of the top regions that produced zero examples. Args:; df: A dataframe of all regions. Returns:; An altair chart.; """"""; """"""Loads data from a file into one dataframe as-is and one by task. Args:; input_path: str, path of the input TSV file (may be sharded). Returns:; df: A dataframe with one row per region.; by_task: A dataframe with one row per task.; """"""; """"""Creates charts and puts them in a list with their ID names. Args:; df: A dataframe with one row per region.; by_task:",MatchSource.CODE_COMMENT,deepvariant/runtime_by_region_vis.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/runtime_by_region_vis.py
Testability,test,testing,"es bundling by task to avoid showing multiple overlapping; # points which otherwise make the text look funky.; """"""Makes a stacked bar chart with runtime of each stage for individual regions. Args:; small_df: A dataframe of regions, each of which will be shown as a bar.; title: A title for the plot. If a dict, it should contain 'title' and/or; 'subtitle'. Returns:; An altair chart.; """"""; """"""Creates a stacked bar charts of the top 20 and median 20 regions. Args:; df: A dataframe of all regions. Returns:; An altair chart.; """"""; """"""Creates a chart of the top regions that produced zero examples. Args:; df: A dataframe of all regions. Returns:; An altair chart.; """"""; """"""Loads data from a file into one dataframe as-is and one by task. Args:; input_path: str, path of the input TSV file (may be sharded). Returns:; df: A dataframe with one row per region.; by_task: A dataframe with one row per task.; """"""; """"""Creates charts and puts them in a list with their ID names. Args:; df: A dataframe with one row per region.; by_task: A dataframe with one row per task. Returns:; list of dicts, each containing a chart and a descriptive ID.; """"""; # Altair shows a max of 5000 data points.; # With up to 5000 points, just show them all.; # With too many points, make different subsets to show trends better.; # Sample the bottom 99% to avoid outliers that obscure general trends.; """"""Reads data, creates charts, and composes the charts into an HTML report. Args:; input_path: Path of the input TSV file (or sharded files).; title: Title to put at the top of the report.; html_output: Writable file object where output will be written.; """"""; # Load data into pandas dataframes and add summary columns.; # Build all the charts.; # Write a subtitle with some top-level stats.; # Write the HTML report with all the charts.; # Add html to the output path if that is not already the suffix.; # Start HTML document. Using GFile enables writing to GCS too.; # Abstracted out the file open/close to enable testing.",MatchSource.CODE_COMMENT,deepvariant/runtime_by_region_vis.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/runtime_by_region_vis.py
Usability,simpl,simple,"ntinuation to break this into separate lines makes the code more readable.; # pylint: disable=g-backslash-continuation; """"""; <style>; body {; font-family: sans-serif;; }; .chart-container {; padding: 30px;; }; </style>; """"""; """"""Imports data from a single or sharded path into a pandas dataframe. Args:; path_string: The path to the input file, which may be sharded. Returns:; A dataframe matching the TSV file(s) but with added Task column.; """"""; # Once pandas is updated to 0.24+, pd.read_csv will work for gs://; # without this workaround.; """"""Creates a nice format string from a potentially large number of seconds. Args:; raw_seconds: A number of seconds. Returns:; The seconds divided into hours, minutes, and remaining seconds, formatted; nicely. For example, 2h3m5.012s.; """"""; """"""Calculates total runtime, formats it nicely, and sorts by it. Args:; df: A dataframe of runtime profiling numbers. Returns:; The same dataframe with some additional summary columns.; """"""; # 'total runtime' is a simple sum of the runtime columns.; # Create a formatted runtime string for tooltips.; # Sort by descending total region runtime.; """"""Groups regions to get the total runtime for each task. Args:; df: A dataframe of runtime profiling numbers. Returns:; The dataframe grouped by task.; """"""; """"""Plots a histogram of runtimes stacked by stage. Args:; d: A dataframe of runtimes, either by region or by task.; title: A title for the plot. Returns:; An altair chart.; """"""; """"""Produces a grid of scatter plots of runtimes of stages versus covariates. Args:; d: A pandas dataframe of runtime by regions.; title: A title for the plot. Returns:; An altair chart; """"""; """"""Plots total runtimes for each stage. Args:; d: A dataframe of runtimes. Returns:; An altair chart.; """"""; """"""For one row of a dataframe, computes a tooltip description. Args:; row: A Pandas Series, one row of a dataframe containing some specific; cumulative sum columns. Returns:; A string to show as the tooltip for a pareto curve.; """"""; """"""",MatchSource.CODE_COMMENT,deepvariant/runtime_by_region_vis.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/runtime_by_region_vis.py
Testability,test,testdata,"# Copyright 2020 Google LLC.; #; # Redistribution and use in source and binary forms, with or without; # modification, are permitted provided that the following conditions; # are met:; #; # 1. Redistributions of source code must retain the above copyright notice,; # this list of conditions and the following disclaimer.; #; # 2. Redistributions in binary form must reproduce the above copyright; # notice, this list of conditions and the following disclaimer in the; # documentation and/or other materials provided with the distribution.; #; # 3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for DeepVariant runtime_by_region_vis visual report script.""""""; # Json strings of dataframes from testdata.RUNTIME_BY_REGION.; # Chart type strings look like: ""<class 'altair.vegalite.v3.api.FacetChart'>""; # Chart, FacetChart, LayerChart, and VConcatChart.; # Compare as json strings.",MatchSource.CODE_COMMENT,deepvariant/runtime_by_region_vis_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/runtime_by_region_vis_test.py
Testability,log,logging,"ases, e.g. X:100_A.; """"""Prepare a locus ID, shortening ref and alt if necessary. Examples of long alleles replaced with their sizes:; 20:62456134_INS103bp.png; 20:62481177_DEL51bp.png; Examples of short alleles where the full string is included:; 1:55424995_TC->T.png; 1:55424996_CT->CTT.png; 1:55424996_CT->C.png; 1:55424996_CT->TTT.png; 1:55424996_CT->C|CTT.png. Args:; variant: Variant object from which to get locus position and alleles.; indices: list of allele indices for this particular pileup image. Returns:; A short ID packed with variant information.; """"""; # If any ref or alt strings are too long, shorten them all.; # If any alts are the same length (rare but possible), include their IDs.; # If ref and alts are short enough, show them fully: e.g. A->AG|C; """"""Create a function that acts as a regions filter. Args:; region_flag_string: string from --regions.; verbose: bool. Whether to print regions after parsing. Returns:; A function that given a variant will return True or False whether the; variant falls inside the regions.; """"""; """"""Create pileup images from examples, filtered in various ways.""""""; # Use nucleus.io.tfrecord to read all shards.; # Prepare output directory:; # Only when scanning many examples, print a dot for each one to; # indicate that the script is making progress and not stalled.; # Print another dot on the same line, using print since logging does; # not support printing without a newline.; # Extract variant from example.; # Use locus ID in the filename, replacing long alleles with INS/DEL sizes.; # Optionally filter to variants in the VCF.; # Check if the locus is in the VCF.; # Skip this example since it doesn't match the VCF.; # If the example has a truth label, optionally include it.; # Extract and format example into channels.; # Create image with a grey-scale row of channels and save to file.; # Create RGB image and save to file.; # Pileup window, e.g. for IGV automation ""goto"" command:; # Check if --num_records quota has been hit yet.",MatchSource.CODE_COMMENT,deepvariant/show_examples.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/show_examples.py
Availability,error,error,"# Copyright 2020 Google LLC.; #; # Redistribution and use in source and binary forms, with or without; # modification, are permitted provided that the following conditions; # are met:; #; # 1. Redistributions of source code must retain the above copyright notice,; # this list of conditions and the following disclaimer.; #; # 2. Redistributions in binary form must reproduce the above copyright; # notice, this list of conditions and the following disclaimer in the; # documentation and/or other materials provided with the distribution.; #; # 3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for deepvariant .show_examples.""""""; # The first allele is the ref, the rest are alts.; # The first allele is the ref, the rest are alts.; # The first allele is the ref, the rest are alts.; # Set all the optional parameters to check that they all work together.; # On by default for training examples.; # Despite ""Count"", this checks that the items are the same, unordered.; # With 6 channel names, it should run without error:",MatchSource.CODE_COMMENT,deepvariant/show_examples_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/show_examples_test.py
Modifiability,variab,variables," INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Utilities to help with testing DeepVariant code.""""""; """"""Gets the path to filename in genomics/deepvariant/testdata. These paths are only known at runtime, after flag parsing; has occurred. Args:; filename: The name of a testdata file in the core genomics testdata; directory. For example, if you have a test file in; ""learning/genomics/deepvariant/testdata/foo.txt"", filename should be; ""foo.txt"" to get a path to it. Returns:; The absolute path to a testdata file.; """"""; # For CustomizedClassesVariantLabeler:; # For VcfCandidateImporter:; # For alt-aligned pileups:; # For allele frequency:; """"""Initialize global variables from flag values.""""""; # # Here is how ""NA12878_S1.chr20.10_10p1mb.first_half.bam""; # # and ""NA12878_S1.chr20.10_10p1mb.second_half.bam"" are split; # # from NA12878_S1.chr20.10_10p1mb.bam.; # READS_FIRST_HALF=${TESTDATA_DIR}/NA12878_S1.chr20.10_10p1mb.first_half.bam; # READS_SECOND_HALF=${TESTDATA_DIR}/NA12878_S1.chr20.10_10p1mb.second_half.bam; # READS=${TESTDATA_DIR}/NA12878_S1.chr20.10_10p1mb.bam; # samtools view -H ${READS} > /tmp/f1.sam; # cp /tmp/f1.sam /tmp/f2.sam; # # Because ${READS} has total of 52035 lines, we split in roughly half.; # samtools view ${READS} | head -26000 >> /tmp/f1.sam; # samtools view ${READS} | tail -26035 >> /tmp/f2.sam; # samtools view -S -b /tmp/f1.sam > ${READS_FIRST_HALF}; # samtools view -S -b /tmp/f2.sam > ${READS_SECOND_HALF}; # samtools index ${READS_FIRST_HALF}; # samtools index ${READS_SECOND_HALF}; # # Here is how the ""HG002_NIST_150bp_downsampled_30x.chr20.10_10p1mb.bam""; #",MatchSource.CODE_COMMENT,deepvariant/testdata.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/testdata.py
Testability,test,testing," name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Utilities to help with testing DeepVariant code.""""""; """"""Gets the path to filename in genomics/deepvariant/testdata. These paths are only known at runtime, after flag parsing; has occurred. Args:; filename: The name of a testdata file in the core genomics testdata; directory. For example, if you have a test file in; ""learning/genomics/deepvariant/testdata/foo.txt"", filename should be; ""foo.txt"" to get a path to it. Returns:; The absolute path to a testdata file.; """"""; # For CustomizedClassesVariantLabeler:; # For VcfCandidateImporter:; # For alt-aligned pileups:; # For allele frequency:; """"""Initialize global variables from flag values.""""""; # # Here is how ""NA12878_S1.chr20.10_10p1mb.first_half.bam""; # # and ""NA12878_S1.chr20.10_10p1mb.second_half.bam"" are split; # # from NA12878_S1.chr20.10_10p1mb.bam.; # READS_FIRST_HALF=${TESTDATA_DIR}/NA12878_S1.chr20.10_10p1mb.first_half.bam; # READS_SECOND_HALF=${TESTDATA_DIR}/NA12878_S1.chr20.10_10p1mb.second_half.bam; # READS=${TESTDATA_DIR}/NA12878_S1.chr20.10_10p1mb",MatchSource.CODE_COMMENT,deepvariant/testdata.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/testdata.py
Usability,learn,learning,"RRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Utilities to help with testing DeepVariant code.""""""; """"""Gets the path to filename in genomics/deepvariant/testdata. These paths are only known at runtime, after flag parsing; has occurred. Args:; filename: The name of a testdata file in the core genomics testdata; directory. For example, if you have a test file in; ""learning/genomics/deepvariant/testdata/foo.txt"", filename should be; ""foo.txt"" to get a path to it. Returns:; The absolute path to a testdata file.; """"""; # For CustomizedClassesVariantLabeler:; # For VcfCandidateImporter:; # For alt-aligned pileups:; # For allele frequency:; """"""Initialize global variables from flag values.""""""; # # Here is how ""NA12878_S1.chr20.10_10p1mb.first_half.bam""; # # and ""NA12878_S1.chr20.10_10p1mb.second_half.bam"" are split; # # from NA12878_S1.chr20.10_10p1mb.bam.; # READS_FIRST_HALF=${TESTDATA_DIR}/NA12878_S1.chr20.10_10p1mb.first_half.bam; # READS_SECOND_HALF=${TESTDATA_DIR}/NA12878_S1.chr20.10_10p1mb.second_half.bam; # READS=${TESTDATA_DIR}/NA12878_S1.chr20.10_10p1mb.bam; # samtools view -H ${READS} > /tmp/f1.sam; # cp /tmp/f1.sam /tmp/f2.sam; # # Because ${READS} has total of 52035 lines, we split in roughly half.; # samtools view ${READS} | head -26000 >> /tmp/f1.sam; # samtools view ${READS} | tail -26035 >> /tmp/f2.sam; # samtools view -S -b /tmp/f1.sam",MatchSource.CODE_COMMENT,deepvariant/testdata.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/testdata.py
Availability,checkpoint,checkpoint,"f its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Train a model.""""""; # Load config; # Copy example_info.json to checkpoint path.; # =========== #; # Setup Model #; # =========== #; # Define Loss Function.; # TODO: Add function for retrieving custom loss fn.; # We divide per-replica losses by global batch size and sum this value; # across all replicas to compute average loss scaled by global batch size.; # TODO: Define learning rate via config.; # This is initial learning rate.; # Define Optimizer.; # TODO: Add function for retrieving custom optimizer.; # ================= #; # Setup Checkpoint #; # ================= #; # The state object allows checkpointing of the model and associated variables; # for the optimizer, step, and train/tune metrics.; """"""Single non-distributed tune step.""""""; # ============== #; # Setup Datasets #; # ============== #; # ============= #; # Training Loop #; # ============= #; """"""Returns the metric we are optimizing for.""""""; # Calculate current epoch; # If we are warmstarting, establish an initial best_checkpoint_metric; # value before beginning any training.; # Reset tune ",MatchSource.CODE_COMMENT,deepvariant/train.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/train.py
Modifiability,config,config,"copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Train a model.""""""; # Load config; # Copy example_info.json to checkpoint path.; # =========== #; # Setup Model #; # =========== #; # Define Loss Function.; # TODO: Add function for retrieving custom loss fn.; # We divide per-replica losses by global batch size and sum this value; # across all replicas to compute average loss scaled by global batch size.; # TODO: Define learning rate via config.; # This is initial learning rate.; # Define Optimizer.; # TODO: Add function for retrieving custom optimizer.; # ================= #; # Setup Checkpoint #; # ================= #; # The state object allows checkpointing of the model and associated variables; # for the optimizer, step, and train/tune metrics.; """"""Single non-distributed tune step.""""""; # ============== #; # Setup Datasets #; # ============== #; # ============= #; # Training Loop #; # ============= #; """"""Returns the metric we are optimizing for.""""""; # Calculate current epoch; # If we are warmstarting, establish an initial best_checkpoint_metric; # value before beginn",MatchSource.CODE_COMMENT,deepvariant/train.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/train.py
Performance,optimiz,optimizer,"HE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Train a model.""""""; # Load config; # Copy example_info.json to checkpoint path.; # =========== #; # Setup Model #; # =========== #; # Define Loss Function.; # TODO: Add function for retrieving custom loss fn.; # We divide per-replica losses by global batch size and sum this value; # across all replicas to compute average loss scaled by global batch size.; # TODO: Define learning rate via config.; # This is initial learning rate.; # Define Optimizer.; # TODO: Add function for retrieving custom optimizer.; # ================= #; # Setup Checkpoint #; # ================= #; # The state object allows checkpointing of the model and associated variables; # for the optimizer, step, and train/tune metrics.; """"""Single non-distributed tune step.""""""; # ============== #; # Setup Datasets #; # ============== #; # ============= #; # Training Loop #; # ============= #; """"""Returns the metric we are optimizing for.""""""; # Calculate current epoch; # If we are warmstarting, establish an initial best_checkpoint_metric; # value before beginning any training.; # Reset tune metrics; # ===== #; # train #; # ===== #; # Calculate full train step.; # Quick indication that training is happening.; # Log metrics; # Reset train metrics.; # ==== #; # tune #; # ==== #; # Run tune at every epoch, periodically, and at final step.; # Reset early stopping counter; # Reset tune metrics; # After training completes, load the latest checkpoint and create; # a saved model (.pb) and keras model forma",MatchSource.CODE_COMMENT,deepvariant/train.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/train.py
Usability,learn,learning,"RRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Train a model.""""""; # Load config; # Copy example_info.json to checkpoint path.; # =========== #; # Setup Model #; # =========== #; # Define Loss Function.; # TODO: Add function for retrieving custom loss fn.; # We divide per-replica losses by global batch size and sum this value; # across all replicas to compute average loss scaled by global batch size.; # TODO: Define learning rate via config.; # This is initial learning rate.; # Define Optimizer.; # TODO: Add function for retrieving custom optimizer.; # ================= #; # Setup Checkpoint #; # ================= #; # The state object allows checkpointing of the model and associated variables; # for the optimizer, step, and train/tune metrics.; """"""Single non-distributed tune step.""""""; # ============== #; # Setup Datasets #; # ============== #; # ============= #; # Training Loop #; # ============= #; """"""Returns the metric we are optimizing for.""""""; # Calculate current epoch; # If we are warmstarting, establish an initial best_checkpoint_metric; # value before beginning any training.; # Reset tune metrics; # ===== #; # train #; # ===== #; # Calculate full train step.; # Quick indication that training is happening.; # Log metrics; # Reset train metrics.; # ==== #; # tune #; # ==== #; # Run tune at every epoch, periodically, and at final step.; # Reset early stopping counter; # Reset tune metrics; # Afte",MatchSource.CODE_COMMENT,deepvariant/train.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/train.py
Performance,load,loading,"DER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; # This gets set by XManager even though we don't pass it as a coordinator_flag; """"""Registers metrics with XManager.""""""; """"""Reports F1 Score for a target class.""""""; # TODO: Create custom metrics.py module.; """"""Parses a serialized tf.Example, preprocesses the image, and one-hot encodes the label.""""""; # Image preprocessing and one-hot encoding were previously done inside the; # TF Estimator API's model_fn. Though we can subclass the Keras InceptionV3; # class and do it in the forward pass, it seems more fitting to do it during; # dataset loading along with the above image loading steps.; # If the example is denovo then set the denovo example weights for this.; """"""Load the dataset and shuffle for training.""""""; # Best practices suggest batching before mapping, but this fails so I swapped; # the order.; # Prefetch overlaps in-feed with training; """"""Train a model.""""""; # Set the total number epochs. This is the number of times we will iterate; # over the data.; # Calculate the total number of mini_epochs, we use it to report metrics; # sooner. This divides a long waited epoch into smaller epochs. This is the; # value fed into model.fit so it is assumed to be one epoch when it reaches; # a mini epoch.; # Steps per epoch is the total number of steps/batches we have in each epoch.; # Steps per mini-epoch is after how many batches we report a metric. This is; # what used in model.fit so it reports metrics after steps_per_mini_epoch; # numbers.; # This is initial learning rate.; # Our """,MatchSource.CODE_COMMENT,deepvariant/train_inceptionv3.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/train_inceptionv3.py
Safety,safe,safe,"then set the denovo example weights for this.; """"""Load the dataset and shuffle for training.""""""; # Best practices suggest batching before mapping, but this fails so I swapped; # the order.; # Prefetch overlaps in-feed with training; """"""Train a model.""""""; # Set the total number epochs. This is the number of times we will iterate; # over the data.; # Calculate the total number of mini_epochs, we use it to report metrics; # sooner. This divides a long waited epoch into smaller epochs. This is the; # value fed into model.fit so it is assumed to be one epoch when it reaches; # a mini epoch.; # Steps per epoch is the total number of steps/batches we have in each epoch.; # Steps per mini-epoch is after how many batches we report a metric. This is; # what used in model.fit so it reports metrics after steps_per_mini_epoch; # numbers.; # This is initial learning rate.; # Our ""steps_per_epoch"" in model.fit is:; # steps_per_epoch // FLAGS.train_config.num_mini_epochs_per_epoch.; # I divided that by 10 just to be safe. In case that gets too small,; # I set a max with 128 here.; # Note that this might only make sense for TPUs. In the future we'll want to; # check whether this works for GPU or not.; # We should also keep an eye on this feature which might allow autotune in; # the future: https://github.com/keras-team/keras/issues/16573.; # TODO: Try different optimizers; # and sweep over these hyperparams; # This is from:; # https://www.tensorflow.org/guide/tpu#train_the_model_using_keras_high-level_apis.; # Anything between 2 and `steps_per_epoch` could help here.; # TODO: Sweep over these hyperparams; # TODO: Does computing fewer TensorBoard metrics speed up; # training?; # XManager callback.; # `patient` below might need to be tuned.; # Calculate validation attributes.; # Even with ""mini epoch"", we still want to evaluate the same amount of; # validation examples per point. So, I'm not dividing this by; # FLAGS.train_config.num_mini_epochs_per_epoch; # Training completed successf",MatchSource.CODE_COMMENT,deepvariant/train_inceptionv3.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/train_inceptionv3.py
Security,validat,validation,"t the denovo example weights for this.; """"""Load the dataset and shuffle for training.""""""; # Best practices suggest batching before mapping, but this fails so I swapped; # the order.; # Prefetch overlaps in-feed with training; """"""Train a model.""""""; # Set the total number epochs. This is the number of times we will iterate; # over the data.; # Calculate the total number of mini_epochs, we use it to report metrics; # sooner. This divides a long waited epoch into smaller epochs. This is the; # value fed into model.fit so it is assumed to be one epoch when it reaches; # a mini epoch.; # Steps per epoch is the total number of steps/batches we have in each epoch.; # Steps per mini-epoch is after how many batches we report a metric. This is; # what used in model.fit so it reports metrics after steps_per_mini_epoch; # numbers.; # This is initial learning rate.; # Our ""steps_per_epoch"" in model.fit is:; # steps_per_epoch // FLAGS.train_config.num_mini_epochs_per_epoch.; # I divided that by 10 just to be safe. In case that gets too small,; # I set a max with 128 here.; # Note that this might only make sense for TPUs. In the future we'll want to; # check whether this works for GPU or not.; # We should also keep an eye on this feature which might allow autotune in; # the future: https://github.com/keras-team/keras/issues/16573.; # TODO: Try different optimizers; # and sweep over these hyperparams; # This is from:; # https://www.tensorflow.org/guide/tpu#train_the_model_using_keras_high-level_apis.; # Anything between 2 and `steps_per_epoch` could help here.; # TODO: Sweep over these hyperparams; # TODO: Does computing fewer TensorBoard metrics speed up; # training?; # XManager callback.; # `patient` below might need to be tuned.; # Calculate validation attributes.; # Even with ""mini epoch"", we still want to evaluate the same amount of; # validation examples per point. So, I'm not dividing this by; # FLAGS.train_config.num_mini_epochs_per_epoch; # Training completed successfully.",MatchSource.CODE_COMMENT,deepvariant/train_inceptionv3.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/train_inceptionv3.py
Usability,learn,learning,"n the forward pass, it seems more fitting to do it during; # dataset loading along with the above image loading steps.; # If the example is denovo then set the denovo example weights for this.; """"""Load the dataset and shuffle for training.""""""; # Best practices suggest batching before mapping, but this fails so I swapped; # the order.; # Prefetch overlaps in-feed with training; """"""Train a model.""""""; # Set the total number epochs. This is the number of times we will iterate; # over the data.; # Calculate the total number of mini_epochs, we use it to report metrics; # sooner. This divides a long waited epoch into smaller epochs. This is the; # value fed into model.fit so it is assumed to be one epoch when it reaches; # a mini epoch.; # Steps per epoch is the total number of steps/batches we have in each epoch.; # Steps per mini-epoch is after how many batches we report a metric. This is; # what used in model.fit so it reports metrics after steps_per_mini_epoch; # numbers.; # This is initial learning rate.; # Our ""steps_per_epoch"" in model.fit is:; # steps_per_epoch // FLAGS.train_config.num_mini_epochs_per_epoch.; # I divided that by 10 just to be safe. In case that gets too small,; # I set a max with 128 here.; # Note that this might only make sense for TPUs. In the future we'll want to; # check whether this works for GPU or not.; # We should also keep an eye on this feature which might allow autotune in; # the future: https://github.com/keras-team/keras/issues/16573.; # TODO: Try different optimizers; # and sweep over these hyperparams; # This is from:; # https://www.tensorflow.org/guide/tpu#train_the_model_using_keras_high-level_apis.; # Anything between 2 and `steps_per_epoch` could help here.; # TODO: Sweep over these hyperparams; # TODO: Does computing fewer TensorBoard metrics speed up; # training?; # XManager callback.; # `patient` below might need to be tuned.; # Calculate validation attributes.; # Even with ""mini epoch"", we still want to evaluate the same amo",MatchSource.CODE_COMMENT,deepvariant/train_inceptionv3.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/train_inceptionv3.py
Availability,down,down,"GQ value to quantize.; binsize: positive int. The size of bins to quantize within. Returns:; A quantized GQ integer.; """"""; """"""BaseClass for variant callers.""""""; # pylint: disable=g-complex-comprehension; # pylint: enable=g-complex-comprehension; """"""Computes the confidence that a site in the genome has no variation. Computes this confidence using only the counts of the number of reads; supporting the reference allele and the total number of reads at this site. See: https:www.broadinstitute.org/gatk/guide/article?id=4017 for; background. Computes the reference confidence for site allele_count. Examines the number of reference supporting and alternate supporting reads; in allele_count and estimates the genotype likelihoods and confidence that; this site is homozygous reference. These values are written into the first; VariantCall record of variant, into the repeated field genotype_likelihood; and the map field GQ. The genotype likelihoods are computed against any possible alternative; allele, the so-called <*> allele, which boils down to a model that looks; like:. log10_p_ref = (1 - p_error)^(ref_n) (p_error)^(non_ref_n); log10_p_het = (0.5)^(total_n); log10_p_hom_alt = (p_e)^(ref_n) (1 - p_error)^(non_ref_n). ref_n is the number of reference supporting reads and non_ref_n is the sum; of any reads supporting any alternate alleles. Non-informative reads are; excluded from the calculation. and written in as the normalized log10 values so that:. sum(10^genotype_likelihoods) = 1. The GQ, according to the VCF specification, is the conditional genotype; quality, encoded as a phred quality -10 * log10 p(genotype call is wrong,; conditioned on the site's being variant, as an integer. See:; https:samtools.github.io/hts-specs/VCFv4.3.pdf; We are calculating the GQ not for the best genotype, but the GQ of the 0/0; genotype, regardless of the likelihoods.; 1 = pRR + pRA + pAA; [R is reference, A=<*> is any alternative alternative]; GQ of 0/0 = -10 * log10(pRA + pAA) [prob that any ",MatchSource.CODE_COMMENT,deepvariant/variant_caller.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/variant_caller.py
Deployability,configurat,configurations,"alues so that:. sum(10^genotype_likelihoods) = 1. The GQ, according to the VCF specification, is the conditional genotype; quality, encoded as a phred quality -10 * log10 p(genotype call is wrong,; conditioned on the site's being variant, as an integer. See:; https:samtools.github.io/hts-specs/VCFv4.3.pdf; We are calculating the GQ not for the best genotype, but the GQ of the 0/0; genotype, regardless of the likelihoods.; 1 = pRR + pRA + pAA; [R is reference, A=<*> is any alternative alternative]; GQ of 0/0 = -10 * log10(pRA + pAA) [prob that any other differen genotype]; = -10 * log10(1 - pRR) [substitution from the previous equation]; Here we don't have pRR directly, but rather log10(pRR). Args:; n_ref: int >= 0 and <= n_total: The number of reads supporting the; reference allele.; n_total: int >= 0 and >= n_ref: The number of reads supporting any allele; at this site. Returns:; A tuple of two values. The first is an integer value for the GQ (genotype; quality) and the second is an array-like of the log10 probabilities for; each of the three genotype configurations.; """"""; """"""Performs the calculation described in reference_confidence().""""""; # No coverage case - all likelihoods are log10 of 1/3, 1/3, 1/3.; """"""Primary interface function for computing gVCF confidence at a site. Looks at the counts in the provided list of AlleleCountSummary protos and; returns properly-formatted Variant protos containing gVCF reference; blocks for all sites in allele_count_summaries. The returned Variant has; reference_name, start, end are set and contains a single VariantCall in the; calls field with call_set_name of options.sample_name, genotypes set to 0/0; (diploid reference), a GQ value bound in the info field appropriate to the; data in allele_count, and a MIN_DP value which is the minimum read coverage; seen in the block. The provided allele count must have either a canonical DNA sequence base (; A, C, G, T) or be ""N"". Args:; allele_count_summaries: iterable of AlleleCountSummar",MatchSource.CODE_COMMENT,deepvariant/variant_caller.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/variant_caller.py
Integrability,interface,interface,"https:samtools.github.io/hts-specs/VCFv4.3.pdf; We are calculating the GQ not for the best genotype, but the GQ of the 0/0; genotype, regardless of the likelihoods.; 1 = pRR + pRA + pAA; [R is reference, A=<*> is any alternative alternative]; GQ of 0/0 = -10 * log10(pRA + pAA) [prob that any other differen genotype]; = -10 * log10(1 - pRR) [substitution from the previous equation]; Here we don't have pRR directly, but rather log10(pRR). Args:; n_ref: int >= 0 and <= n_total: The number of reads supporting the; reference allele.; n_total: int >= 0 and >= n_ref: The number of reads supporting any allele; at this site. Returns:; A tuple of two values. The first is an integer value for the GQ (genotype; quality) and the second is an array-like of the log10 probabilities for; each of the three genotype configurations.; """"""; """"""Performs the calculation described in reference_confidence().""""""; # No coverage case - all likelihoods are log10 of 1/3, 1/3, 1/3.; """"""Primary interface function for computing gVCF confidence at a site. Looks at the counts in the provided list of AlleleCountSummary protos and; returns properly-formatted Variant protos containing gVCF reference; blocks for all sites in allele_count_summaries. The returned Variant has; reference_name, start, end are set and contains a single VariantCall in the; calls field with call_set_name of options.sample_name, genotypes set to 0/0; (diploid reference), a GQ value bound in the info field appropriate to the; data in allele_count, and a MIN_DP value which is the minimum read coverage; seen in the block. The provided allele count must have either a canonical DNA sequence base (; A, C, G, T) or be ""N"". Args:; allele_count_summaries: iterable of AlleleCountSummary protos in; coordinate-sorted order. Each proto is used to get the read counts for; reference and alternate alleles, the reference position, and reference; base.; include_med_dp: boolean. If True, in the gVCF records, we will include; MED_DP. Yields:; third_p",MatchSource.CODE_COMMENT,deepvariant/variant_caller.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/variant_caller.py
Modifiability,config,configurations,"alues so that:. sum(10^genotype_likelihoods) = 1. The GQ, according to the VCF specification, is the conditional genotype; quality, encoded as a phred quality -10 * log10 p(genotype call is wrong,; conditioned on the site's being variant, as an integer. See:; https:samtools.github.io/hts-specs/VCFv4.3.pdf; We are calculating the GQ not for the best genotype, but the GQ of the 0/0; genotype, regardless of the likelihoods.; 1 = pRR + pRA + pAA; [R is reference, A=<*> is any alternative alternative]; GQ of 0/0 = -10 * log10(pRA + pAA) [prob that any other differen genotype]; = -10 * log10(1 - pRR) [substitution from the previous equation]; Here we don't have pRR directly, but rather log10(pRR). Args:; n_ref: int >= 0 and <= n_total: The number of reads supporting the; reference allele.; n_total: int >= 0 and >= n_ref: The number of reads supporting any allele; at this site. Returns:; A tuple of two values. The first is an integer value for the GQ (genotype; quality) and the second is an array-like of the log10 probabilities for; each of the three genotype configurations.; """"""; """"""Performs the calculation described in reference_confidence().""""""; # No coverage case - all likelihoods are log10 of 1/3, 1/3, 1/3.; """"""Primary interface function for computing gVCF confidence at a site. Looks at the counts in the provided list of AlleleCountSummary protos and; returns properly-formatted Variant protos containing gVCF reference; blocks for all sites in allele_count_summaries. The returned Variant has; reference_name, start, end are set and contains a single VariantCall in the; calls field with call_set_name of options.sample_name, genotypes set to 0/0; (diploid reference), a GQ value bound in the info field appropriate to the; data in allele_count, and a MIN_DP value which is the minimum read coverage; seen in the block. The provided allele count must have either a canonical DNA sequence base (; A, C, G, T) or be ""N"". Args:; allele_count_summaries: iterable of AlleleCountSummar",MatchSource.CODE_COMMENT,deepvariant/variant_caller.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/variant_caller.py
Usability,guid,guide,"ads' and n_total_reads' so; that n_total_reads' == max_allowed_reads and n_ref_reads' / n_total_reads' ~; n_ref_reads / n_total_reads. Args:; n_ref_reads: int. Number of reference supporting reads.; n_total_reads: int. Total number of reads.; max_allowed_reads: int. The maximum value allowed for n_total after; rescaling, if necessary. Returns:; New values for n_ref_reads and n_total_reads.; """"""; """"""Returns a quantized value of GQ in units of binsize. Args:; raw_gq: int. The raw GQ value to quantize.; binsize: positive int. The size of bins to quantize within. Returns:; A quantized GQ integer.; """"""; """"""BaseClass for variant callers.""""""; # pylint: disable=g-complex-comprehension; # pylint: enable=g-complex-comprehension; """"""Computes the confidence that a site in the genome has no variation. Computes this confidence using only the counts of the number of reads; supporting the reference allele and the total number of reads at this site. See: https:www.broadinstitute.org/gatk/guide/article?id=4017 for; background. Computes the reference confidence for site allele_count. Examines the number of reference supporting and alternate supporting reads; in allele_count and estimates the genotype likelihoods and confidence that; this site is homozygous reference. These values are written into the first; VariantCall record of variant, into the repeated field genotype_likelihood; and the map field GQ. The genotype likelihoods are computed against any possible alternative; allele, the so-called <*> allele, which boils down to a model that looks; like:. log10_p_ref = (1 - p_error)^(ref_n) (p_error)^(non_ref_n); log10_p_het = (0.5)^(total_n); log10_p_hom_alt = (p_e)^(ref_n) (1 - p_error)^(non_ref_n). ref_n is the number of reference supporting reads and non_ref_n is the sum; of any reads supporting any alternate alleles. Non-informative reads are; excluded from the calculation. and written in as the normalized log10 values so that:. sum(10^genotype_likelihoods) = 1. The GQ, according to",MatchSource.CODE_COMMENT,deepvariant/variant_caller.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/variant_caller.py
Performance,cache,cached," # Checks that the rescaling works when n_total_reads > max_allowed.; # I saw a bug at runtime, and the testcase makes sure we scale values of; # n_ref_reads close to n_total_reads appropriately.; # pylint: disable=g-complex-comprehension; # pylint: enable=g-complex-comprehension; """"""Tests that we don't blow up when the coverage gets really high.""""""; # Check some basics.; # Two equal records are merged, and the reference base is the first one.; # Three equal records are merged into a single block.; # We don't merge together different GQ value blocks:; # Binning by 3 does not cause any records to be merged.; # Binning by 4 causes the first merge, of the first two records.; # 25 comes from int(median([31, 35, 20, 19])).; # Each count tuple is n_alt, n_ref, ref_base.; # The third, fourth, and the fifth ones should never be merged, since; # either het or hom_alt has bigger GL than hom_ref.; # Only tests the 'gvcfs' creation part of calls_and_gvcfs. The `calls`; # portion of this method needs to be tested in subclasses, which have; # implemented the get_candidates method.; # We expect our gvcfs to occur at the 10 position and that 12 and 13 have; # been merged into a 2 bp block, if enabled. Otherwise should be empty.; # Expected diploid genotype likelihoods when there's no coverage. The; # chance of having each genotype is 1/3, in log10 space.; # The genotype should NOT be called here (""./."") as the likelihood; # for het is greater than hom_ref.; # Outside class so we can refer to it in @Parameters.; # pylint: disable=g-complex-comprehension; # pylint: enable=g-complex-comprehension; # Note that we only expect the gq and gls to be close if we are not; # rescaling the counts, so we are only looping over values that should be; # cached. In practice the cache is set to values sufficiently large that; # these differences don't matter, but for this test we are limiting the; # cache size to a small value in _CACHE_COVERAGE so we can test that the; # cache lookups are correct.",MatchSource.CODE_COMMENT,deepvariant/variant_caller_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/variant_caller_test.py
Testability,test,tested,"ed from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for deepvariant .variant_caller.""""""; """"""A placeholder VariantCaller. This class provides a get_candidates implementation and so allows; the base class to be instantiated and its methods tested.; """"""; # pylint: disable=g-complex-comprehension; # pylint: enable=g-complex-comprehension; # R code to produce the testdata expectation table.; # expected <- function(n_ref, n_alt, perr, max_gq = 100) {; # p_ref <- dbinom(n_alt, n_ref, perr); # p_het <- dbinom(n_alt, n_ref, 0.5); # p_alt <- dbinom(n_ref - n_alt, n_ref, perr); # raw <- c(p_ref, p_het, p_alt); # norm <- raw / sum(raw); # gq = min(floor(-10 * log10(1 - norm[1])), max_gq); # likelihoods = paste(sprintf(""%.6f"", log10(norm)), collapse="", ""); # likelihoods = paste(""["", likelihoods, ""]"", sep=""""); # result = paste(n_ref, n_alt, perr, 100, 1, likelihoods, gq, sep="", ""); # cat(paste(""["", result, ""],\n"", sep="""")); # }; #; # for (n in c(10, 20)) {; # for (k in seq(0, n)) {; # expected(n, k, 0.01); # }; # }; #; # for (perr in c(0.1, 0.01, 0.001, 0.0001)) {; # expected(10, 0, perr); # expected(10, 1, perr); # }; #; # for (n_ref in c(10, 20, 30, 40, 50, 60, 70, 80, 90, 100",MatchSource.CODE_COMMENT,deepvariant/variant_caller_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/variant_caller_test.py
Performance,cache,cached,"llowed_reads are returned without modification.; # Checks that the rescaling works when n_total_reads > max_allowed.; # I saw a bug at runtime, and the testcase makes sure we scale values of; # n_ref_reads close to n_total_reads appropriately.; # pylint: disable=g-complex-comprehension; # pylint: enable=g-complex-comprehension; """"""Tests that we don't blow up when the coverage gets really high.""""""; # Check some basics.; # Two equal records are merged, and the reference base is the first one.; # Three equal records are merged into a single block.; # We don't merge together different GQ value blocks:; # Binning by 3 does not cause any records to be merged.; # Binning by 4 causes the first merge, of the first two records.; # Each count tuple is n_alt, n_ref, ref_base.; # The third, fourth, and the fifth ones should never be merged, since; # either het or hom_alt has bigger GL than hom_ref.; # Only tests the 'gvcfs' creation part of calls_and_gvcfs. The `calls`; # portion of this method needs to be tested in subclasses, which have; # implemented the get_candidates method.; # We expect our gvcfs to occur at the 10 position and that 12 and 13 have; # been merged into a 2 bp block, if enabled. Otherwise should be empty.; # Expected diploid genotype likelihoods when there's no coverage. The; # chance of having each genotype is 1/3, in log10 space.; # The genotype should NOT be called here (""./."") as the likelihood; # for het is greater than hom_ref.; # Outside class so we can refer to it in @Parameters.; # pylint: disable=g-complex-comprehension; # pylint: enable=g-complex-comprehension; # Note that we only expect the gq and gls to be close if we are not; # rescaling the counts, so we are only looping over values that should be; # cached. In practice the cache is set to values sufficiently large that; # these differences don't matter, but for this test we are limiting the; # cache size to a small value in _CACHE_COVERAGE so we can test that the; # cache lookups are correct.",MatchSource.CODE_COMMENT,deepvariant/variant_caller_trio_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/variant_caller_trio_test.py
Testability,test,tested,"ed from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for deepvariant .variant_caller.""""""; """"""A placeholder VariantCaller. This class provides a get_candidates implementation and so allows; the base class to be instantiated and its methods tested.; """"""; # pylint: disable=g-complex-comprehension; # pylint: enable=g-complex-comprehension; # R code to produce the testdata expectation table.; # expected <- function(n_ref, n_alt, perr, max_gq = 100) {; # p_ref <- dbinom(n_alt, n_ref, perr); # p_het <- dbinom(n_alt, n_ref, 0.5); # p_alt <- dbinom(n_ref - n_alt, n_ref, perr); # raw <- c(p_ref, p_het, p_alt); # norm <- raw / sum(raw); # gq = min(floor(-10 * log10(1 - norm[1])), max_gq); # likelihoods = paste(sprintf(""%.6f"", log10(norm)), collapse="", ""); # likelihoods = paste(""["", likelihoods, ""]"", sep=""""); # result = paste(n_ref, n_alt, perr, 100, 1, likelihoods, gq, sep="", ""); # cat(paste(""["", result, ""],\n"", sep="""")); # }; #; # for (n in c(10, 20)) {; # for (k in seq(0, n)) {; # expected(n, k, 0.01); # }; # }; #; # for (perr in c(0.1, 0.01, 0.001, 0.0001)) {; # expected(10, 0, perr); # expected(10, 1, perr); # }; #; # for (n_ref in c(10, 20, 30, 40, 50, 60, 70, 80, 90, 100",MatchSource.CODE_COMMENT,deepvariant/variant_caller_trio_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/variant_caller_trio_test.py
Testability,test,test,"in the; # documentation and/or other materials provided with the distribution.; #; # 3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for deepvariant .vcf_candidate_importer.""""""; # pylint: disable=g-complex-comprehension; # pylint: enable=g-complex-comprehension; # Our test AlleleCounts are 5 positions:; #; # 10: A ref [no reads]; # 11: G/C variant; # 12: G ref [no reads]; # 13: G ref [no reads]; # 14: T/C variant; #; # The ref sites have no reads for ref or any alt simply because it; # simplifies comparing them with the expected variant genotype likelihoods.; # We aren't testing the correctness of the gvcf calculation here (that's; # elsewhere) but rather focusing here on the separation of variants from; # gvcf records, and the automatic merging of the gvcf blocks.; # Golden sets are created with learning/genomics/internal/create_golden.sh.; # Confirming that the proposed VCF (input) has the same variants; # as the VCF output converted from the output of make_examples.; # This checks the keys (like chr20:10099832:A->G) are the same.",MatchSource.CODE_COMMENT,deepvariant/vcf_candidate_importer_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/vcf_candidate_importer_test.py
Usability,simpl,simply,"in the; # documentation and/or other materials provided with the distribution.; #; # 3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for deepvariant .vcf_candidate_importer.""""""; # pylint: disable=g-complex-comprehension; # pylint: enable=g-complex-comprehension; # Our test AlleleCounts are 5 positions:; #; # 10: A ref [no reads]; # 11: G/C variant; # 12: G ref [no reads]; # 13: G ref [no reads]; # 14: T/C variant; #; # The ref sites have no reads for ref or any alt simply because it; # simplifies comparing them with the expected variant genotype likelihoods.; # We aren't testing the correctness of the gvcf calculation here (that's; # elsewhere) but rather focusing here on the separation of variants from; # gvcf records, and the automatic merging of the gvcf blocks.; # Golden sets are created with learning/genomics/internal/create_golden.sh.; # Confirming that the proposed VCF (input) has the same variants; # as the VCF output converted from the output of make_examples.; # This checks the keys (like chr20:10099832:A->G) are the same.",MatchSource.CODE_COMMENT,deepvariant/vcf_candidate_importer_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/vcf_candidate_importer_test.py
Availability,error,error,"# Copyright 2019 Google LLC.; #; # Redistribution and use in source and binary forms, with or without; # modification, are permitted provided that the following conditions; # are met:; #; # 1. Redistributions of source code must retain the above copyright notice,; # this list of conditions and the following disclaimer.; #; # 2. Redistributions in binary form must reproduce the above copyright; # notice, this list of conditions and the following disclaimer in the; # documentation and/or other materials provided with the distribution.; #; # 3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; # Check for missing GT in VCF to avoid a confusing error downstream.",MatchSource.CODE_COMMENT,deepvariant/vcf_stats_report.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/vcf_stats_report.py
Safety,avoid,avoid,"# Copyright 2019 Google LLC.; #; # Redistribution and use in source and binary forms, with or without; # modification, are permitted provided that the following conditions; # are met:; #; # 1. Redistributions of source code must retain the above copyright notice,; # this list of conditions and the following disclaimer.; #; # 2. Redistributions in binary form must reproduce the above copyright; # notice, this list of conditions and the following disclaimer in the; # documentation and/or other materials provided with the distribution.; #; # 3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; # Check for missing GT in VCF to avoid a confusing error downstream.",MatchSource.CODE_COMMENT,deepvariant/vcf_stats_report.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/vcf_stats_report.py
Integrability,interface,interface," given genotype.""""""; """"""Create a chart of the counts of each variant type.""""""; """"""Create the Quality(QUAL) histogram.""""""; # s = bin_start, e = bin_end, c = count; """"""Create the Genotype quality (GQ) histogram.""""""; # gq = genotype quality, found at :GQ: in FORMAT column of VCF; # standardize x-axis limits across reports; # s = bin_start, e = bin_end, c = count; """"""Create VAF histograms split by genotype.""""""; # pretty genotype name; # main/other genotypes; # vertical line as guide; # Main genotypes (ref, het, hom-alt); # Histogram bars themselves; # s = bin_start, e = bin_end, c = count; # Vertical lines; # Facet into 3 plots by genotype; # Other genotypes (uncalled, het with two alt alleles); # s = bin_start, e = bin_end, c = count; """"""Create the base change chart.""""""; # 4 charts, plus constant spacing; """"""Turn paired numbers and their counts into data for a histogram. This centers the bars on the exact integer for clarity. For example, the bar; for 3 is centered on 3 instead of being between 3 and 4 as in numpy's default; histogram. Args:; num_count_pairs: list of [num, count] pairs. Returns:; a pandas dataframe with num, count (bin count), s (bin start), e (bin end); """"""; # For a proper histogram, use s and e to force each bar to cover; # exactly one integer position:; """"""Create the indel size chart.""""""; # 2 charts, plus spacing; """"""Build histogram with depth (DP).""""""; # s = bin_start, e = bin_end, c = count; """"""Built chart showing counts of transitions and transversions.""""""; # Show TiTv ratio with fallback to avoid division by 0; """"""Build all charts and combine into a single interface.""""""; # Row 1; # Row 2; # Row 3; # Putting it all together; """"""Write to a temporary string stand-in for the file to replace import URLs. Args:; altair_chart: a chart object made by Altair.; download_filename: string filename base for when users export images. Returns:; HTML in string format.; """"""; """"""Save Altair chart as an HTML file.""""""; """"""Build visual report with several charts.""""""",MatchSource.CODE_COMMENT,deepvariant/vcf_stats_vis.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/vcf_stats_vis.py
Safety,avoid,avoid," given genotype.""""""; """"""Create a chart of the counts of each variant type.""""""; """"""Create the Quality(QUAL) histogram.""""""; # s = bin_start, e = bin_end, c = count; """"""Create the Genotype quality (GQ) histogram.""""""; # gq = genotype quality, found at :GQ: in FORMAT column of VCF; # standardize x-axis limits across reports; # s = bin_start, e = bin_end, c = count; """"""Create VAF histograms split by genotype.""""""; # pretty genotype name; # main/other genotypes; # vertical line as guide; # Main genotypes (ref, het, hom-alt); # Histogram bars themselves; # s = bin_start, e = bin_end, c = count; # Vertical lines; # Facet into 3 plots by genotype; # Other genotypes (uncalled, het with two alt alleles); # s = bin_start, e = bin_end, c = count; """"""Create the base change chart.""""""; # 4 charts, plus constant spacing; """"""Turn paired numbers and their counts into data for a histogram. This centers the bars on the exact integer for clarity. For example, the bar; for 3 is centered on 3 instead of being between 3 and 4 as in numpy's default; histogram. Args:; num_count_pairs: list of [num, count] pairs. Returns:; a pandas dataframe with num, count (bin count), s (bin start), e (bin end); """"""; # For a proper histogram, use s and e to force each bar to cover; # exactly one integer position:; """"""Create the indel size chart.""""""; # 2 charts, plus spacing; """"""Build histogram with depth (DP).""""""; # s = bin_start, e = bin_end, c = count; """"""Built chart showing counts of transitions and transversions.""""""; # Show TiTv ratio with fallback to avoid division by 0; """"""Build all charts and combine into a single interface.""""""; # Row 1; # Row 2; # Row 3; # Putting it all together; """"""Write to a temporary string stand-in for the file to replace import URLs. Args:; altair_chart: a chart object made by Altair.; download_filename: string filename base for when users export images. Returns:; HTML in string format.; """"""; """"""Save Altair chart as an HTML file.""""""; """"""Build visual report with several charts.""""""",MatchSource.CODE_COMMENT,deepvariant/vcf_stats_vis.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/vcf_stats_vis.py
Usability,guid,guide,"chart.mark_bar().encode(...).properties(...), so allowing backslash; # continuation to break this into separate lines makes the code more readable.; # pylint: disable=g-backslash-continuation; # ""pretty"" genotype strings:; # Establish ordering of bases to keep it consistent; """"""Turn a dict object into a dataframe of with label and value columns.""""""; """"""Get more human-readable display name and grouping for a given genotype.""""""; """"""Create a chart of the counts of each variant type.""""""; """"""Create the Quality(QUAL) histogram.""""""; # s = bin_start, e = bin_end, c = count; """"""Create the Genotype quality (GQ) histogram.""""""; # gq = genotype quality, found at :GQ: in FORMAT column of VCF; # standardize x-axis limits across reports; # s = bin_start, e = bin_end, c = count; """"""Create VAF histograms split by genotype.""""""; # pretty genotype name; # main/other genotypes; # vertical line as guide; # Main genotypes (ref, het, hom-alt); # Histogram bars themselves; # s = bin_start, e = bin_end, c = count; # Vertical lines; # Facet into 3 plots by genotype; # Other genotypes (uncalled, het with two alt alleles); # s = bin_start, e = bin_end, c = count; """"""Create the base change chart.""""""; # 4 charts, plus constant spacing; """"""Turn paired numbers and their counts into data for a histogram. This centers the bars on the exact integer for clarity. For example, the bar; for 3 is centered on 3 instead of being between 3 and 4 as in numpy's default; histogram. Args:; num_count_pairs: list of [num, count] pairs. Returns:; a pandas dataframe with num, count (bin count), s (bin start), e (bin end); """"""; # For a proper histogram, use s and e to force each bar to cover; # exactly one integer position:; """"""Create the indel size chart.""""""; # 2 charts, plus spacing; """"""Build histogram with depth (DP).""""""; # s = bin_start, e = bin_end, c = count; """"""Built chart showing counts of transitions and transversions.""""""; # Show TiTv ratio with fallback to avoid division by 0; """"""Build all charts and combine ",MatchSource.CODE_COMMENT,deepvariant/vcf_stats_vis.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/vcf_stats_vis.py
Integrability,interface,interface,"# Copyright 2019 Google LLC.; #; # Redistribution and use in source and binary forms, with or without; # modification, are permitted provided that the following conditions; # are met:; #; # 1. Redistributions of source code must retain the above copyright notice,; # this list of conditions and the following disclaimer.; #; # 2. Redistributions in binary form must reproduce the above copyright; # notice, this list of conditions and the following disclaimer in the; # documentation and/or other materials provided with the distribution.; #; # 3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""A VerySensitiveCaller producing DeepVariantCall and gVCF records. This module provides the primary interface for calling candidate variants using; for the AlleleCounts in an AlleleCounter by wrapping the low-level C++ code and; adding a nicer API and functions to compute gVCF records as well.; """"""; """"""Call variants and gvcf records from an AlleleCounter.""""""",MatchSource.CODE_COMMENT,deepvariant/very_sensitive_caller.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/very_sensitive_caller.py
Testability,test,test,"; # 1. Redistributions of source code must retain the above copyright notice,; # this list of conditions and the following disclaimer.; #; # 2. Redistributions in binary form must reproduce the above copyright; # notice, this list of conditions and the following disclaimer in the; # documentation and/or other materials provided with the distribution.; #; # 3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for deepvariant .very_sensitive_caller.""""""; # pylint: disable=g-complex-comprehension; # pylint: enable=g-complex-comprehension; # Our test AlleleCounts are 5 positions:; #; # 10: A ref [no reads]; # 11: G/C variant; # 12: G ref [no reads]; # 13: G ref [no reads]; # 14: T/C variant; #; # The ref sites have no reads for ref or any alt simply because it; # simplifies comparing them with the expected variant genotype likelihoods.; # We aren't testing the correctness of the gvcf calculation here (that's; # elsewhere) but rather focusing here on the separation of variants from; # gvcf records, and the automatic merging of the gvcf blocks.",MatchSource.CODE_COMMENT,deepvariant/very_sensitive_caller_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/very_sensitive_caller_test.py
Usability,simpl,simply,"; # 1. Redistributions of source code must retain the above copyright notice,; # this list of conditions and the following disclaimer.; #; # 2. Redistributions in binary form must reproduce the above copyright; # notice, this list of conditions and the following disclaimer in the; # documentation and/or other materials provided with the distribution.; #; # 3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for deepvariant .very_sensitive_caller.""""""; # pylint: disable=g-complex-comprehension; # pylint: enable=g-complex-comprehension; # Our test AlleleCounts are 5 positions:; #; # 10: A ref [no reads]; # 11: G/C variant; # 12: G ref [no reads]; # 13: G ref [no reads]; # 14: T/C variant; #; # The ref sites have no reads for ref or any alt simply because it; # simplifies comparing them with the expected variant genotype likelihoods.; # We aren't testing the correctness of the gvcf calculation here (that's; # elsewhere) but rather focusing here on the separation of variants from; # gvcf records, and the automatic merging of the gvcf blocks.",MatchSource.CODE_COMMENT,deepvariant/very_sensitive_caller_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/very_sensitive_caller_test.py
Testability,test,test,"; # 1. Redistributions of source code must retain the above copyright notice,; # this list of conditions and the following disclaimer.; #; # 2. Redistributions in binary form must reproduce the above copyright; # notice, this list of conditions and the following disclaimer in the; # documentation and/or other materials provided with the distribution.; #; # 3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for deepvariant .very_sensitive_caller.""""""; # pylint: disable=g-complex-comprehension; # pylint: enable=g-complex-comprehension; # Our test AlleleCounts are 5 positions:; #; # 10: A ref [no reads]; # 11: G/C variant; # 12: G ref [no reads]; # 13: G ref [no reads]; # 14: T/C variant; #; # The ref sites have no reads for ref or any alt simply because it; # simplifies comparing them with the expected variant genotype likelihoods.; # We aren't testing the correctness of the gvcf calculation here (that's; # elsewhere) but rather focusing here on the separation of variants from; # gvcf records, and the automatic merging of the gvcf blocks.",MatchSource.CODE_COMMENT,deepvariant/very_sensitive_caller_trio_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/very_sensitive_caller_trio_test.py
Usability,simpl,simply,"; # 1. Redistributions of source code must retain the above copyright notice,; # this list of conditions and the following disclaimer.; #; # 2. Redistributions in binary form must reproduce the above copyright; # notice, this list of conditions and the following disclaimer in the; # documentation and/or other materials provided with the distribution.; #; # 3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for deepvariant .very_sensitive_caller.""""""; # pylint: disable=g-complex-comprehension; # pylint: enable=g-complex-comprehension; # Our test AlleleCounts are 5 positions:; #; # 10: A ref [no reads]; # 11: G/C variant; # 12: G ref [no reads]; # 13: G ref [no reads]; # 14: T/C variant; #; # The ref sites have no reads for ref or any alt simply because it; # simplifies comparing them with the expected variant genotype likelihoods.; # We aren't testing the correctness of the gvcf calculation here (that's; # elsewhere) but rather focusing here on the separation of variants from; # gvcf records, and the automatic merging of the gvcf blocks.",MatchSource.CODE_COMMENT,deepvariant/very_sensitive_caller_trio_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/very_sensitive_caller_trio_test.py
Modifiability,variab,variable,"# Copyright 2017 Google LLC.; #; # Redistribution and use in source and binary forms, with or without; # modification, are permitted provided that the following conditions; # are met:; #; # 1. Redistributions of source code must retain the above copyright notice,; # this list of conditions and the following disclaimer.; #; # 2. Redistributions in binary form must reproduce the above copyright; # notice, this list of conditions and the following disclaimer in the; # documentation and/or other materials provided with the distribution.; #; # 3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Smoke tests for the genomics environment.""""""; # We use unittest and not TF Test because the point of this test is to be; # able to test our environment without having to build TensorFlow.; """"""End-to-end test of model_train script.""""""; # Test various imports work; # pylint: disable=unused-variable; # pylint: disable=g-import-not-at-top; # pylint: enable=unused-variable; # pylint: enable=g-import-not-at-top",MatchSource.CODE_COMMENT,deepvariant/environment_tests/env_smoke_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/environment_tests/env_smoke_test.py
Testability,test,tests,"# Copyright 2017 Google LLC.; #; # Redistribution and use in source and binary forms, with or without; # modification, are permitted provided that the following conditions; # are met:; #; # 1. Redistributions of source code must retain the above copyright notice,; # this list of conditions and the following disclaimer.; #; # 2. Redistributions in binary form must reproduce the above copyright; # notice, this list of conditions and the following disclaimer in the; # documentation and/or other materials provided with the distribution.; #; # 3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Smoke tests for the genomics environment.""""""; # We use unittest and not TF Test because the point of this test is to be; # able to test our environment without having to build TensorFlow.; """"""End-to-end test of model_train script.""""""; # Test various imports work; # pylint: disable=unused-variable; # pylint: disable=g-import-not-at-top; # pylint: enable=unused-variable; # pylint: enable=g-import-not-at-top",MatchSource.CODE_COMMENT,deepvariant/environment_tests/env_smoke_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/environment_tests/env_smoke_test.py
Safety,predict,predict,"CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""variant_labeler for DeepVariant.""""""; # ---------------------------------------------------------------------------; # CustomizedClassesVariantLabel; #; """"""Dataclass containing information about a label assigned to a variant. Attributes:; is_confident: bool. True if we could confidently assign a label to this; variant, False otherwise.; variant: nucleus.protos.Variant proto that we assigned a label for.; class_status: string. One of the keys in classes_dict; """"""; """"""Computes the label value for an example. This function computes the TensorFlow label value (0, 1, 2, .. N-1) we train; DeepVariant to predict.; The `alt_alleles_indices` being passed in is from the candidates (not; truth), so they could still have multiple alts. If any of the alt alleles; matches the truth, we'll return the label of the truth.; TODO: Fix multi-allelic cases. Add corresponding unit test cases.; Note that this function currently doesn't handle multi-allelic cases; correctly. For example it assumes `truth_alt` is the first one. Args:; alt_alleles_indices: list[int]. A list of the alt_allele_indices. Returns:; int >= 0. Label for the classes in `classes_dict`.; """"""; # If the ref of the candidate and the truth doesn't match, return 0 (ref).; # Default is label 0. Usually reference.; # Note that this logic below might not be the best when; # `alt_alleles_indices` is a composite one, like [0, 1]. For now we'll; # return the corresponding label if any of them matches truth_alt.; # allele in called variant is the same as truth_alt; """"""Extract class status from nucleus.protos.Variant.info. Args:; in",MatchSource.CODE_COMMENT,deepvariant/labeler/customized_classes_labeler.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/customized_classes_labeler.py
Testability,test,test,"GLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""variant_labeler for DeepVariant.""""""; # ---------------------------------------------------------------------------; # CustomizedClassesVariantLabel; #; """"""Dataclass containing information about a label assigned to a variant. Attributes:; is_confident: bool. True if we could confidently assign a label to this; variant, False otherwise.; variant: nucleus.protos.Variant proto that we assigned a label for.; class_status: string. One of the keys in classes_dict; """"""; """"""Computes the label value for an example. This function computes the TensorFlow label value (0, 1, 2, .. N-1) we train; DeepVariant to predict.; The `alt_alleles_indices` being passed in is from the candidates (not; truth), so they could still have multiple alts. If any of the alt alleles; matches the truth, we'll return the label of the truth.; TODO: Fix multi-allelic cases. Add corresponding unit test cases.; Note that this function currently doesn't handle multi-allelic cases; correctly. For example it assumes `truth_alt` is the first one. Args:; alt_alleles_indices: list[int]. A list of the alt_allele_indices. Returns:; int >= 0. Label for the classes in `classes_dict`.; """"""; # If the ref of the candidate and the truth doesn't match, return 0 (ref).; # Default is label 0. Usually reference.; # Note that this logic below might not be the best when; # `alt_alleles_indices` is a composite one, like [0, 1]. For now we'll; # return the corresponding label if any of them matches truth_alt.; # allele in called variant is the same as truth_alt; """"""Extract class status from nucleus.protos.Variant.info. Args:; info_field: INFO field of nucleus.protos.Variant proto to extract the; classes status from. Must contain `info_field_name` field which is set; to one of self.classes_dict.keys(). Returns:; string. Class status. Has to be one of the keys of `classes_dict`. Raises:; ValueErro",MatchSource.CODE_COMMENT,deepvariant/labeler/customized_classes_labeler.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/customized_classes_labeler.py
Availability,error,error,"ND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for deepvariant .variant_labeler.""""""; # Confident variants: SNP, deletion, and multi-allelic.; # Outside our confident regions.; # TODO: check the following cases:; # no_class_status; # invalid_class_status; # (Value error should be produced in both cases); # Simple tests: we get back our matching variants in the confident regions; # For multiallelic variants, we default to class 0.; # Test the behavior outside of our confident regions.; # If we provide a variant outside the confident regions (non_confident) we; # don't get back any expected_truth variants.; # No matching variant, so we get a None as well as False.; # This variant doesn't have any match but we're confident in it.; # These variant start at our SNP but has a different allele. We are; # confident and we get back the true snp variant.; # However, we are on a different allele, so its status is unknown.; # TODO: Confirm this case.; # TODO: checking this assumption is correct:; # If the alleles don't match, return class 0?; # Checks that we don't match against the filtered truth variant in our; # database. This means that we return not the filtered variant but one; # with a (0, 0) genotype.; # These variant start at our SNP but has a different first alt allele 'G'.; # The seco",MatchSource.CODE_COMMENT,deepvariant/labeler/customized_classes_labeler_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/customized_classes_labeler_test.py
Testability,test,tests,"ND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for deepvariant .variant_labeler.""""""; # Confident variants: SNP, deletion, and multi-allelic.; # Outside our confident regions.; # TODO: check the following cases:; # no_class_status; # invalid_class_status; # (Value error should be produced in both cases); # Simple tests: we get back our matching variants in the confident regions; # For multiallelic variants, we default to class 0.; # Test the behavior outside of our confident regions.; # If we provide a variant outside the confident regions (non_confident) we; # don't get back any expected_truth variants.; # No matching variant, so we get a None as well as False.; # This variant doesn't have any match but we're confident in it.; # These variant start at our SNP but has a different allele. We are; # confident and we get back the true snp variant.; # However, we are on a different allele, so its status is unknown.; # TODO: Confirm this case.; # TODO: checking this assumption is correct:; # If the alleles don't match, return class 0?; # Checks that we don't match against the filtered truth variant in our; # database. This means that we return not the filtered variant but one; # with a (0, 0) genotype.; # These variant start at our SNP but has a different first alt allele 'G'.; # The seco",MatchSource.CODE_COMMENT,deepvariant/labeler/customized_classes_labeler_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/customized_classes_labeler_test.py
Deployability,update,updates,"n.; # Filter out homozygous reference labels.; # Now loop over our grouped variants, labeling them, and yielding; # VariantLabel objects.; # Note this test must be 'is None' since label_variants can return an; # empty list.; # This logic doesn't make a huge amount of sense when you are doing; # haplotype-based labeling. Currently we only say a variant is confident; # if it overlaps the confident regions, which is the baseline behavior.; # However, it may be useful to rethink how we establish a variant is; # confident, as the ""event"" may be within the confident regions but; # shifted outside due to differences in representational choices. Seems; # like another approach would be to assign confidence if it has a; # non-ref genotype (as we only consider confident truth variants) or if; # it overlaps the confident regions.; """"""Gets the LabelingMetrics proto tracking metrics for this labeler.""""""; """"""Update self._metrics with the HaplotypeMatch labeling results. This function updates the LabelingMetrics information in self._metrics using; the labeling results in labeling. Args:; labeling: HaplotypeMatch. The labeling information to use to update our; LabelingMetrics.; """"""; """"""Returns the number of distinct alt alleles with non-zero genotype.""""""; """"""Are all genotypes in gt the reference alleles (i.e., == 0)?""""""; """"""Is any genotype in gt a non-ref (> 0) genotype?""""""; # Iterate over the truth variant and its associated original genotypes; # (those provided by the input VCF) and the assigned genotypes (i.e., the; # genotypes assigned to truth to make candidates and truth match haplotypes); # and compute a few metric values.; # If we have more than one alt allele in the original genotypes and the; # assigned genotypes imply more or more are missing then we've got a; # multi-allelic truth variant with some missing alleles.; # Iterate over the original and assigned genotypes for the truth variants; # and count up the number of true positive alleles (i.e. original and; # assigned g",MatchSource.CODE_COMMENT,deepvariant/labeler/haplotype_labeler.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler.py
Energy Efficiency,efficient,efficiently,"tion_type isn't one of the valid options.; """"""; """"""Splits variants_and_genotypes into an overlapping group and remaining.""""""; """"""Yields all diploid combinations of prefix_haplotypes_list x haplotypes. Args:; prefix_haplotypes_list: list[set[string]]: prefix_haplotypes_list contains a; list of set[string], which are just like haplotypes (i.e., contains 1 or 2; strings), that collectively represent all possible prefixes of haplotypes.; haplotypes: set[string]. A set containing 1 or 2 haplotype strings. So it; looks like {h} or {h1, h2}. Yields:; A series of set[string], each containing 1 or 2 haplotype strings. Raises:; ValueError: if any of the arguments are invalid.; """"""; """"""Returns a map from phased genotypes => haplotype sequences. This function creates a map from all possible haploid genotypes of the; genotypes in variants_and_genotypes to their corresponding haplotype sequences; implied by the variants, ref, start, and their genotypes. This map can be used; to efficiently look up the haplotype sequence for any haploid genotype. Args:; variants_and_genotypes: list[VariantAndGenotypes]. The variants and; associated genotypes to use to build the dictionary.; start: int >= 0. The position on the genome to start constructing our; haplotypes at.; ref: ReferenceRegion. Object containing the reference genome bases we use to; construct our haplotypes. Returns:; A 2-tuple. The first element is a dictionary[tuple, string], where each key; is a phased haploid genotype and its value is the haplotype sequence implied; by that genotype given the variants and the reference genome. The second; position is the ending position of the haplotype on the reference genome.; """"""; """"""Builds the haplotype string from variants and its phased gneotypes. This function takes a list of variants and associated phased genotypes and; constructs the haplotype sequence implied by variants and its genotypes. For; example, suppose we have two variants:. ref: CAGC where the first base (C) is at positi",MatchSource.CODE_COMMENT,deepvariant/labeler/haplotype_labeler.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler.py
Modifiability,config,configuration,"s.; """"""Returns a set of genotypes that includes false negatives. This function takes a concrete genotype for a Variant, such as (0, 1), and; returns a set of genotypes that includes gt as well as all possible genotypes; consistent with some of the alleles in gt being missed. For example, here are; a few outputs for help understand what this means:. input genotype (gt) => returned set of genotypes; ------------------------------------------------. # A hom-ref genotype doesn't have any alleles to miss.; (0, 0) => {(0, 0)}. # Might miss the 1 allele, or not.; (0, 1) => {(0, 0), (0, 1)}. # We could miss one, or both of the 1 alleles.; (1, 1) => {(0, 0), (0, 1), (1, 1)}. # Multi-allelics are more complex, in that we could miss either the 1 or the; # 2 allele, or both.; (1, 2) => {(0, 0), (0, 1), (0, 2), (1, 2)}. Args:; gt: iterable[int]: A genotype for a Variant, such as [0, 1] or [1, 1]. Returns:; A sorted list of tuples containing diploid genotypes.; """"""; """"""Indicates that an impossible haplotype configuration has been observed.""""""; """"""Returns all possible haplotype/genotype combinations for variants. Args:; variants: list[nucleus.protos.Variant]. A list of candidate variants, in; coordinate-sorted order, all on the same chromosome.; ref: ReferenceRegion. Used to get reference bases for variants. Must cover; at least the span of the variants.; enumeration_type: EnumerationType enum value. What kind of enumeration do we; want to do? Can be either CANDIDATES or TRUTH. Returns:; Dict[Haplotypes, List[Genotypes]]; where; Genotypes = List[Genotype]; Haplotypes = FrozenSet[str]. Haplotypes is a set of either one or two strings, where each string is a; haplotype (i.e., a series of bases) generated by the genotypes assigned to; each variant. genotypes is a list of genotype tuples, in the same order as; variants, indicating the genotype assignment for each variant. These; genotypes are phased, so [(0, 1), (0, 1)] is not the same as; [(0, 1), (1, 0)].; """"""; """"""Recursive driver to",MatchSource.CODE_COMMENT,deepvariant/labeler/haplotype_labeler.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler.py
Performance,cache,cached,"; # Create a dict from the start of truth to the truth variant itself and its; # assigned genotypes. This is needed to compute site match counts below.; # Iterate over the candidates and their assigned genotypes to compute; # the remaining metrics.; #; # Note that this counts all candidates, not just the ones in the confident; # regions of the genome. This seems like a reasonable first approach, but it; # may be necessary to restrict ourselves to only those overlapping the; # confident regions.; # If candidate isn't confident, add it to the non_confident count and; # continue as the other metrics are only computed over confident; # candidates.; # Use the truth_by_pos dict to determine which candidates occur at the; # same position as a truth variant. If there is one, grab it and its; # genotypes so we can compute metrics on exact position, allele, genotype; # matches. If not, update the number of inexact matches if our candidate; # is non-reference itself.; """"""Allows us to get bases from a cached reference interval.""""""; # We don't want to worry about the chromosome we are working on for code; # clarity, so we create an InMemoryFastaReader that has a single chromosome; # named _PLACEHOLDER_CHROM_NAME which allows us to provide a bases(start, end); # function for convenient reading of bases.; """"""Raises a ValueError if variants isn't sorted on the same chromosome.""""""; """"""Splits candidate and truth variants into smaller groups if necessary. This function takes in a list of candidate and truth variants and splits up; those lists into groups that respect the requirements of the max_group_size; and max_separation arguments. This is necessary because the labeling algorithm; is very expensive as a function of the number of input variants, so to avoid; excessive runtime we break up our potentially large list of candidate and; truth variants into smaller groups (max number controlled by max_group_size); based on a maximum distance allowed between the closest variants within the",MatchSource.CODE_COMMENT,deepvariant/labeler/haplotype_labeler.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler.py
Safety,safe,safely,"""""""Haplotype-based variant labeler.""""""; """"""Creates a new HaplotypeVariantLabeler. Args:; truth_vcf_reader: a VcfReader object that points to our truth variant set.; ref_reader: A FastaReader object we can use to get reference bases.; confident_regions: A RangeSet containing all of the confidently called; regions. A variant that falls outside of one of these regions will be; receive a special not-confident marker.; max_group_size: int >= 1. The maximum number of variants we'll attempt to; label together. Larger values increase the runtime of the algorithm.; max_separation: int >= 0. The maximum distance between variants within a; group. Sequential variants separated by more than this value will be; placed in separate groups for labeling.; max_gt_options_product: int >= 0. The maximum number of combinations of; genotypes (product of all genotypes in the group). Raises:; ValueError: if vcf_reader is None.; """"""; # Grab our truth variants and group up variants + truth into small enough; # chunks that we can safely send them into our find_best_matching_haplotypes; # function.; # Filter out homozygous reference labels.; # Now loop over our grouped variants, labeling them, and yielding; # VariantLabel objects.; # Note this test must be 'is None' since label_variants can return an; # empty list.; # This logic doesn't make a huge amount of sense when you are doing; # haplotype-based labeling. Currently we only say a variant is confident; # if it overlaps the confident regions, which is the baseline behavior.; # However, it may be useful to rethink how we establish a variant is; # confident, as the ""event"" may be within the confident regions but; # shifted outside due to differences in representational choices. Seems; # like another approach would be to assign confidence if it has a; # non-ref genotype (as we only consider confident truth variants) or if; # it overlaps the confident regions.; """"""Gets the LabelingMetrics proto tracking metrics for this labeler.""""""; """"""Update sel",MatchSource.CODE_COMMENT,deepvariant/labeler/haplotype_labeler.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler.py
Testability,benchmark,benchmarking-tools,"PRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Haplotype-based labeling algorithm for DeepVariant. This module provides a haplotype-aware labeling algorithm. This is a more; sophisticated approach to labeling that allows for slight representational; differences between candidate and truth variant sets. See:. https://github.com/ga4gh/benchmarking-tools; https://www.biorxiv.org/content/early/2018/03/15/270157. for an introduction to the concepts and why this is important. The module is implemented in two big pieces of functionality:. find_best_matching_haplotypes(candidates, truths) provides an function that; accepts a list of candidate variants and a list of truth variants with known; genotypes and finds an assignment of genotypes for candidates and truth that; results in the same two haplotype sequences in the region. Since the truth; variants have known genotypes, the search there is constrained to those; genotypes and their potential set of false negatives (e.g., if truth is (0, 1); we may have missed the variant so we consider both (0, 1) and (0, 0)). The; returned value is a HaplotypeMatch object describing the genotype assignments; for candidates and truth. HaplotypeLabeler implements the variant_labeler.VariantLabeler API by calling; our find_best_matching_haplotypes function to get the HaplotypeMatch objects and; retu",MatchSource.CODE_COMMENT,deepvariant/labeler/haplotype_labeler.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler.py
Usability,simpl,simple,"# clarity, so we create an InMemoryFastaReader that has a single chromosome; # named _PLACEHOLDER_CHROM_NAME which allows us to provide a bases(start, end); # function for convenient reading of bases.; """"""Raises a ValueError if variants isn't sorted on the same chromosome.""""""; """"""Splits candidate and truth variants into smaller groups if necessary. This function takes in a list of candidate and truth variants and splits up; those lists into groups that respect the requirements of the max_group_size; and max_separation arguments. This is necessary because the labeling algorithm; is very expensive as a function of the number of input variants, so to avoid; excessive runtime we break up our potentially large list of candidate and; truth variants into smaller groups (max number controlled by max_group_size); based on a maximum distance allowed between the closest variants within the; group. The current algorithm is a simple greedy one; we effectively merge the two; variant lists together, make groups greedily on that list until either the; maximum number of elements of a specific type (i.e., max_group_size of 2; implies we can have up to two candidate variants or truth variants within a; group) or we encounter a variant further away from the closest variant within; the current group than allowed by max_separation. Args:; candidates: list[nucleus.proto.Variant]. A sorted list of candidate variants; on the same chromosome.; truths: list[nucleus.proto.Variant]. A sorted list of truth variants on the; same chromosome.; max_group_size: int >= 0. The maximum number of variants of a specific type; allowed within a group.; max_separation: int >= 0. The maximum distance, in basepairs, allowed; between the closest variants within a group.; max_gt_options_product: int >= 0. The maximum number of combinations of; genotypes (product of all genotypes in the group).; force_group_within_bp: int >= 0. Variants within this many bps will be; forced to be put in the same group. This is to ",MatchSource.CODE_COMMENT,deepvariant/labeler/haplotype_labeler.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler.py
Availability,down,downstream," #; # The first variant genotype is hom-ref so we have one FP.; # The second variant genotype is hom-ref so we have one FP.; # Both variant genotypes are hom-ref, so we have two FPs.; # Many of these tests are cases from our labeler analysis doc:; # https://docs.google.com/document/d/1V89IIT0YM3P0gH_tQb-ahodf8Jvnz0alXEnjCf6JVNo; # Check that the genotypes of our labeled variants are the ones we expect.; # The reference sequence is xAAAAAy.; # Test a SNP at a few positions.; # Test an insertion at a few positions.; # Test a deletion at a few positions.; # A complete example with multiple variants.; # All possible genotypes for a simple tri-allelic case.; # Simple bi-allelic configurations:; # Multi-allelic configurations:; # Check that the next_pos calculation is working.; # A single deletion overlapping a SNP:; # ref: xTG; # v1: A-; # v2: C; # haplotype 0|0.; # haplotype 0|1.; # haplotype 1|0.; # haplotype 1|1 => invalid.; # Deletion overlapping two downstream events (SNP and insertion):; # ref: xTGC; # v1: A--; # v2: C; # v3: TTT; # haplotype 0|0|0.; # haplotype 0|0|1.; # haplotype 0|1|0.; # haplotype 0|1|1.; # haplotype 1|0|0.; # haplotype 1|0|1 => invalid.; # haplotype 1|1|0 => invalid.; # haplotype 1|1|1 => invalid.; # Two incompatible deletions to check that the end extension is working:; # pos: 01234; # ref: xTGCA; # v1: T-; # v2: G-; # haplotype 0|0.; # haplotype 0|1.; # haplotype 1|0.; # haplotype 1|1 => invalid.; # Multiple overlapping deletions with complex incompatibilities:; # ref: xTGCGA; # v1: A--; # v2: G--- [conflicts with v1]; # v3: C- [conflicts with v1 and v2]; # v4: G- [conflicts with v2 and v3, ok with v1]; # v5: C [conflicts with v2 and v4, ok with v1, v3]; # haplotype 0|0|0|0|0.; # haplotype 0|0|0|0|1.; # haplotype 0|0|0|1|0.; # haplotype 0|0|0|1|1.; # haplotype 0|0|1|0|0.; # haplotype 0|0|1|0|1.; # haplotype 0|0|1|1|0.; # haplotype 0|0|1|1|1.; # haplotype 0|1|0|0|0.; # haplotype 0|1|0|0|1.; # haplotype 0|1|0|1|0.; # haplotype 0|1|0|1|1.; # hap",MatchSource.CODE_COMMENT,deepvariant/labeler/haplotype_labeler_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler_test.py
Deployability,configurat,configurations,"gatives.; #; # True het is 0, 0 in second true variant.; # True hom-alt is het in second true variant.; # True hom-alts are het in first and second true variants.; # True hom-alts are hom-ref in first and second true variants.; #; # Here are a few cases where we false positives.; #; # The first variant genotype is hom-ref so we have one FP.; # The second variant genotype is hom-ref so we have one FP.; # Both variant genotypes are hom-ref, so we have two FPs.; # Many of these tests are cases from our labeler analysis doc:; # https://docs.google.com/document/d/1V89IIT0YM3P0gH_tQb-ahodf8Jvnz0alXEnjCf6JVNo; # Check that the genotypes of our labeled variants are the ones we expect.; # The reference sequence is xAAAAAy.; # Test a SNP at a few positions.; # Test an insertion at a few positions.; # Test a deletion at a few positions.; # A complete example with multiple variants.; # All possible genotypes for a simple tri-allelic case.; # Simple bi-allelic configurations:; # Multi-allelic configurations:; # Check that the next_pos calculation is working.; # A single deletion overlapping a SNP:; # ref: xTG; # v1: A-; # v2: C; # haplotype 0|0.; # haplotype 0|1.; # haplotype 1|0.; # haplotype 1|1 => invalid.; # Deletion overlapping two downstream events (SNP and insertion):; # ref: xTGC; # v1: A--; # v2: C; # v3: TTT; # haplotype 0|0|0.; # haplotype 0|0|1.; # haplotype 0|1|0.; # haplotype 0|1|1.; # haplotype 1|0|0.; # haplotype 1|0|1 => invalid.; # haplotype 1|1|0 => invalid.; # haplotype 1|1|1 => invalid.; # Two incompatible deletions to check that the end extension is working:; # pos: 01234; # ref: xTGCA; # v1: T-; # v2: G-; # haplotype 0|0.; # haplotype 0|1.; # haplotype 1|0.; # haplotype 1|1 => invalid.; # Multiple overlapping deletions with complex incompatibilities:; # ref: xTGCGA; # v1: A--; # v2: G--- [conflicts with v1]; # v3: C- [conflicts with v1 and v2]; # v4: G- [conflicts with v2 and v3, ok with v1]; # v5: C [conflicts with v2 and v4, ok with v1, v3]; # haplotype 0",MatchSource.CODE_COMMENT,deepvariant/labeler/haplotype_labeler_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler_test.py
Energy Efficiency,efficient,efficiently," 0|0|1|0|1.; # haplotype 0|0|1|1|0.; # haplotype 0|0|1|1|1.; # haplotype 0|1|0|0|0.; # haplotype 0|1|0|0|1.; # haplotype 0|1|0|1|0.; # haplotype 0|1|0|1|1.; # haplotype 0|1|1|0|0.; # haplotype 0|1|1|0|1.; # haplotype 0|1|1|1|0.; # haplotype 0|1|1|1|1.; # haplotype 1|0|0|0|0.; # haplotype 1|0|0|0|1.; # haplotype 1|0|0|1|0.; # haplotype 1|0|0|1|1.; # haplotype 1|0|1|0|0.; # haplotype 1|0|1|0|1.; # haplotype 1|0|1|1|0.; # haplotype 1|0|1|1|1.; # haplotype 1|1|0|0|0.; # haplotype 1|1|0|0|1.; # haplotype 1|1|0|1|0.; # haplotype 1|1|0|1|1.; # haplotype 1|1|1|0|0.; # haplotype 1|1|1|0|1.; # haplotype 1|1|1|1|0.; # haplotype 1|1|1|1|1.; # Check that simple bi-allelic matching works for all possible possible; # genotypes and a variety of types of alleles.; # Returns [0, 1] even if truth is [1, 0], so sort the genotypes for; # the expected value.; # Since we don't have any candidates, our relabeled variants should be [].; # This test will time out if we aren't able to efficiently handle the case; # where we have a lot of candidate or truth variants but none of the other.; # Since we don't have any truth variants, all of the variants should get a; # (0, 0) [i.e., hom-ref] genotype assigned.; # Check all configurations for the TRUTH enumeration:; # Bi-allelic cases.; # Multi-allelic cases.; # Check all configurations for the CANDIDATES enumeration:; # Note we don't need to provide a genotype for the candidate enumeration.; # Check all configurations for the ONLY_HOM_REF enumeration:; # All enumeration types return [] if not provided with any variants.; # A/C => 0/C; # G/C => 0/C; # G/G => 0/0; # C/C => C/C; # A/C => 0/C; # G/C => 0/C; # G/G => 0/0; # C/C => C/C; # Here the candidate is also multi-allelic; # example 20:3528533 and 20:3528534; # example 20:4030071; # example 20:4568152; # example 20:1689636, 20:1689639, 20:1689640, 20:1689641; # CTGTAAACAGAA [phased alts] + CGTGAATGAAA [phased ref]; # 20:2401511; # 20:2525695: genotype assign was incorrect in a previous run. This ",MatchSource.CODE_COMMENT,deepvariant/labeler/haplotype_labeler_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler_test.py
Integrability,depend,depends," functionality to start:; # We group a single variant without associated truth variants.; # We group an isolated truth variant in isolation without any candidates.; # A single candidate + truth at the same position are grouped together.; # We respect our distance between variants across positional boundaries.; # Another test of grouping across candidates and truth.; # These tests actually result in broken up groups, with isolated truth; # and candidates as well as grouped ones.; # Now some tests to exercise the max group size with both candidates and; # truth variants. We vary the max group size to make sure the grouping; # algorithm splits correctly.; # Force group variants within 1bp distance; # Force group variants within 1bp distance with 8 variants with; # max_group_size of 1; # Deletion spans from 10-15 as it's a deletion.; # The actual result returned by group_variants is a list of tuples; # containing the grouped candidates and truth. The order they appear depends; # on the truth_position, since our deletion starts at 10.; # The 8 variants each have #GT: 10, 6, 6, 3, 15, 15, 6, 6.; # Combining any of them will be 10*6*6*3*15*15*6*6 = 8748000.; # Here we set a max_gt_options_product larger than that. So they are all; # grouped together.; # The 8 variants each have #GT: 10, 6, 6, 3, 15, 15, 6, 6.; # Because _MAX_GT_OPTIONS_PRODUCT is 100000, the split is:; # 5 variants in one group: 10*6*6*3*15 = 16200; # 3 variants in the next group: 15*6*6 = 540; # The 8 variants each have #GT: 10, 6, 6, 3, 15, 15, 6, 6.; # Combining any of them will be more than max_gt_options_product=10.; # So each individual is split into their own group.; # This is an extreme case from a DeepTrio exome training run. internal.; # Check a simple case of two SNPs.; # Check that we respect the deletion's span in the last candidate.; # Check that we respect handle truth variants, as the interval is entirely; # determined by truth variants here.; # Check that bufsize is respected.; # 10 is the ",MatchSource.CODE_COMMENT,deepvariant/labeler/haplotype_labeler_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler_test.py
Modifiability,parameteriz,parameterized,"ts here.; # Check that bufsize is respected.; # 10 is the bufsize.; # Check that we don't issue a query with a bad start if the variant is at; # position 0 on the genome. See internal.; # Check that we don't issue a query with a bad end if the variant is at; # the last position on the genome. See internal.; # Test for a bug encountered in make_examples.; #; # variants: candidates [0]; # variants: truth [1]; # 20:6299587:C->T gt=(1, 1); # Top-level exception: ('Failed to assign labels for variants', []); # A single TP bi-allelic variant.; # A single TP tri-allelic variant.; # Here we have an extra alt in our candidate and one tri-allelic truth.; # Because of this we have a FP allele and our exact matching counts are; # different than the above example.; # A single FP variant in candidates with 3 alt alleles.; # A single FN variant in truth with 4 alt alleles.; # We only have 2 non-ref alleles in truth, so this is 2 not 3.; # This is parameterized over the max_separation so we can test that the; # metrics are properly calculated no matter the grouping. The candidates and; # truth variants below should give the same metrics regardless of grouping.; # Example one from our narrative in LabelerMetrics proto.; # Example two from our narrative in LabelerMetrics proto.; # A genuine false positive => no corresponding truth variant.; # A genuine false negative => no corresponding variant in truth.; # ref looks like AACTG. Truth is just a single SNP turning the C into a G.; # Candidates do the same but via an insertion + deletion. This test ensures; # that the metrics work even in the case where we have different; # representations for the same haplotype.; # The confident region is 2-4, so we should only count the variant starting; # at 3.; # Computed fields.; # Assert that we have no genotypes in self.variants to check that; # candidates_with_assigned_genotypes isn't modifying our variants.; # All genotypes match, so we have no FNs and no FPs.; #; # Here are a few cases where ",MatchSource.CODE_COMMENT,deepvariant/labeler/haplotype_labeler_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler_test.py
Testability,test,tests,"POSSIBILITY OF SUCH DAMAGE.; """"""Tests for deepvariant.haplotype_labeler.""""""; # Use the reference of the truth variants if possible, otherwise just use; # a placeholder placeholder value for the contig name and make the confident; # region a giant span.; # If there are no variants, we don't get any groups.; # A single variant at 10 gets put in a single group.; # A two variants (at 10 and 11) get grouped because 1 < the max_dist=10.; # A two variants at 10 and 50 get grouped separately because their; # distance > max_dist=10.; # Check the behavior right around max_dist.; # A few complex examples with multiple variants getting grouped.; # The distance calculation compares not first variant in the group but the; # closest one, so we can have a group with collective distance > max_dist; # as long as the distance between successive variants <= max_dist; # Because separation <= max_separation, all variants should be in a; # single group.; # A few basic tests of functionality to start:; # We group a single variant without associated truth variants.; # We group an isolated truth variant in isolation without any candidates.; # A single candidate + truth at the same position are grouped together.; # We respect our distance between variants across positional boundaries.; # Another test of grouping across candidates and truth.; # These tests actually result in broken up groups, with isolated truth; # and candidates as well as grouped ones.; # Now some tests to exercise the max group size with both candidates and; # truth variants. We vary the max group size to make sure the grouping; # algorithm splits correctly.; # Force group variants within 1bp distance; # Force group variants within 1bp distance with 8 variants with; # max_group_size of 1; # Deletion spans from 10-15 as it's a deletion.; # The actual result returned by group_variants is a list of tuples; # containing the grouped candidates and truth. The order they appear depends; # on the truth_position, since our deletion ",MatchSource.CODE_COMMENT,deepvariant/labeler/haplotype_labeler_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler_test.py
Usability,simpl,simple,"h 8 variants with; # max_group_size of 1; # Deletion spans from 10-15 as it's a deletion.; # The actual result returned by group_variants is a list of tuples; # containing the grouped candidates and truth. The order they appear depends; # on the truth_position, since our deletion starts at 10.; # The 8 variants each have #GT: 10, 6, 6, 3, 15, 15, 6, 6.; # Combining any of them will be 10*6*6*3*15*15*6*6 = 8748000.; # Here we set a max_gt_options_product larger than that. So they are all; # grouped together.; # The 8 variants each have #GT: 10, 6, 6, 3, 15, 15, 6, 6.; # Because _MAX_GT_OPTIONS_PRODUCT is 100000, the split is:; # 5 variants in one group: 10*6*6*3*15 = 16200; # 3 variants in the next group: 15*6*6 = 540; # The 8 variants each have #GT: 10, 6, 6, 3, 15, 15, 6, 6.; # Combining any of them will be more than max_gt_options_product=10.; # So each individual is split into their own group.; # This is an extreme case from a DeepTrio exome training run. internal.; # Check a simple case of two SNPs.; # Check that we respect the deletion's span in the last candidate.; # Check that we respect handle truth variants, as the interval is entirely; # determined by truth variants here.; # Check that bufsize is respected.; # 10 is the bufsize.; # Check that we don't issue a query with a bad start if the variant is at; # position 0 on the genome. See internal.; # Check that we don't issue a query with a bad end if the variant is at; # the last position on the genome. See internal.; # Test for a bug encountered in make_examples.; #; # variants: candidates [0]; # variants: truth [1]; # 20:6299587:C->T gt=(1, 1); # Top-level exception: ('Failed to assign labels for variants', []); # A single TP bi-allelic variant.; # A single TP tri-allelic variant.; # Here we have an extra alt in our candidate and one tri-allelic truth.; # Because of this we have a FP allele and our exact matching counts are; # different than the above example.; # A single FP variant in candidates with 3 al",MatchSource.CODE_COMMENT,deepvariant/labeler/haplotype_labeler_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler_test.py
Availability,down,down,"s by matching the chrom:position of a; candidate variant with ones in truth, and then if one exists, assigns the; label based on the genotype of the matched truth variant. This method works; reasonably well but cannot handle complex representational differences between; the candidate variants and the truth variants.; """"""; """"""Creates a new VariantLabeler. Args:; truth_vcf_reader: a VcfReader object that points to our truth variant set.; confident_regions: A RangeSet containing all of the confidently called; regions. A variant that falls outside of one of these regions will be; receive a special not-confident marker. If None, the confident regions; constraint won't be enforced, and all variants will be included. Raises:; ValueError: if vcf_reader is None.; """"""; """"""Get a truth variant matching variant. A matching variant is defined here as one that starts at the same position; on the genome as variant. The best match is then narrowed down by finding; the variant with a matching alt allele, if it exists, otherwise the first; matching variant is used regardless of alt alleles. This allows the client; to make decisions on how to translate a matched between variant and; truth_variant into a label (e.g. by comparing the alleles). If multiple variants are detected, this code will attempt to find the best; match by comparing to `variant`. Note that some simplification of alleles; are applied first before we compare. For example, 'GAAA->GAA' should be the; same as 'GA->G'. If no good matches are detected, the logic currently falls; back to the first element in matches. Args:; variant: Our candidate third_party.nucleus.protos.Variant variant. Returns:; A tuple of (match_status, truth_variant) where match_status is True if; we are confident in our truth_variant call or False if not. truth_variant; is a third_party.nucleus.protos.Variant object of; the truth variant that matched; variant, or None if none was found and we aren't confident in being; hom-ref here, or a synthetic var",MatchSource.CODE_COMMENT,deepvariant/labeler/positional_labeler.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/positional_labeler.py
Integrability,rout,routine,"thetic variant with the same position and alleles as; variant but with a hom-ref genotype.; """"""; """"""Creates a version of variant with a hom-ref genotype. Args:; variant: Our candidate third_party.nucleus.protos.Variant variant. Returns:; A new Variant with the same position and alleles as variant but with a; hom-ref genotype.; """"""; """"""Finds a variant in vcf_reader compatible with variant, if one exists.""""""; # TODO: The behavior of falling back to the first match is; # likely not the best. Think about what to do for different use cases.; """"""Gets the diploid genotype for candidate_variant from matched truth_variant. This method figures out the genotype for candidate_variant by matching alleles; in candidate_variant with those used by the genotype assigned to; truth_variant. For example, if candidate is A/C and truth is A/C with a 0/1; genotype, then this function would return (0, 1) indicating that there's one; copy of the A allele and one of C in truth. If the true genotype is 1/1, then; this routine would return (1, 1). The routine allows candidate_variant and truth_variant to differ in both; the number of alternate alleles, and even in the representation of the same; alleles due to those differences. For example, candidate could be:. AGT/A/AGTGT => 2 bp deletion and 2 bp insertion. and truth could have:. A/AGT => just the simplified 2 bp insertion. And this routine will correctly equate the AGT/AGTGT allele in candidate; with the A/AGT in truth and use the number of copies of AGT in truth to; compute the number of copies of AGTGT when determining the returned genotype. Args:; candidate_variant: Our candidate third_party.nucleus.protos.Variant variant.; truth_variant: Our third_party.nucleus.protos.Variant truth variant; containing true alleles and genotypes. Returns:; A tuple genotypes with the same semantics at the genotype field of the; VariantCall proto. Raises:; ValueError: If candidate_variant is None, truth_variant is None, or; truth_variant doesn't have genot",MatchSource.CODE_COMMENT,deepvariant/labeler/positional_labeler.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/positional_labeler.py
Safety,detect,detected,"nd the truth variants.; """"""; """"""Creates a new VariantLabeler. Args:; truth_vcf_reader: a VcfReader object that points to our truth variant set.; confident_regions: A RangeSet containing all of the confidently called; regions. A variant that falls outside of one of these regions will be; receive a special not-confident marker. If None, the confident regions; constraint won't be enforced, and all variants will be included. Raises:; ValueError: if vcf_reader is None.; """"""; """"""Get a truth variant matching variant. A matching variant is defined here as one that starts at the same position; on the genome as variant. The best match is then narrowed down by finding; the variant with a matching alt allele, if it exists, otherwise the first; matching variant is used regardless of alt alleles. This allows the client; to make decisions on how to translate a matched between variant and; truth_variant into a label (e.g. by comparing the alleles). If multiple variants are detected, this code will attempt to find the best; match by comparing to `variant`. Note that some simplification of alleles; are applied first before we compare. For example, 'GAAA->GAA' should be the; same as 'GA->G'. If no good matches are detected, the logic currently falls; back to the first element in matches. Args:; variant: Our candidate third_party.nucleus.protos.Variant variant. Returns:; A tuple of (match_status, truth_variant) where match_status is True if; we are confident in our truth_variant call or False if not. truth_variant; is a third_party.nucleus.protos.Variant object of; the truth variant that matched; variant, or None if none was found and we aren't confident in being; hom-ref here, or a synthetic variant with the same position and alleles as; variant but with a hom-ref genotype.; """"""; """"""Creates a version of variant with a hom-ref genotype. Args:; variant: Our candidate third_party.nucleus.protos.Variant variant. Returns:; A new Variant with the same position and alleles as variant but with",MatchSource.CODE_COMMENT,deepvariant/labeler/positional_labeler.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/positional_labeler.py
Testability,log,logic," falls outside of one of these regions will be; receive a special not-confident marker. If None, the confident regions; constraint won't be enforced, and all variants will be included. Raises:; ValueError: if vcf_reader is None.; """"""; """"""Get a truth variant matching variant. A matching variant is defined here as one that starts at the same position; on the genome as variant. The best match is then narrowed down by finding; the variant with a matching alt allele, if it exists, otherwise the first; matching variant is used regardless of alt alleles. This allows the client; to make decisions on how to translate a matched between variant and; truth_variant into a label (e.g. by comparing the alleles). If multiple variants are detected, this code will attempt to find the best; match by comparing to `variant`. Note that some simplification of alleles; are applied first before we compare. For example, 'GAAA->GAA' should be the; same as 'GA->G'. If no good matches are detected, the logic currently falls; back to the first element in matches. Args:; variant: Our candidate third_party.nucleus.protos.Variant variant. Returns:; A tuple of (match_status, truth_variant) where match_status is True if; we are confident in our truth_variant call or False if not. truth_variant; is a third_party.nucleus.protos.Variant object of; the truth variant that matched; variant, or None if none was found and we aren't confident in being; hom-ref here, or a synthetic variant with the same position and alleles as; variant but with a hom-ref genotype.; """"""; """"""Creates a version of variant with a hom-ref genotype. Args:; variant: Our candidate third_party.nucleus.protos.Variant variant. Returns:; A new Variant with the same position and alleles as variant but with a; hom-ref genotype.; """"""; """"""Finds a variant in vcf_reader compatible with variant, if one exists.""""""; # TODO: The behavior of falling back to the first match is; # likely not the best. Think about what to do for different use cases.; """"",MatchSource.CODE_COMMENT,deepvariant/labeler/positional_labeler.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/positional_labeler.py
Usability,simpl,simplification,"ader object that points to our truth variant set.; confident_regions: A RangeSet containing all of the confidently called; regions. A variant that falls outside of one of these regions will be; receive a special not-confident marker. If None, the confident regions; constraint won't be enforced, and all variants will be included. Raises:; ValueError: if vcf_reader is None.; """"""; """"""Get a truth variant matching variant. A matching variant is defined here as one that starts at the same position; on the genome as variant. The best match is then narrowed down by finding; the variant with a matching alt allele, if it exists, otherwise the first; matching variant is used regardless of alt alleles. This allows the client; to make decisions on how to translate a matched between variant and; truth_variant into a label (e.g. by comparing the alleles). If multiple variants are detected, this code will attempt to find the best; match by comparing to `variant`. Note that some simplification of alleles; are applied first before we compare. For example, 'GAAA->GAA' should be the; same as 'GA->G'. If no good matches are detected, the logic currently falls; back to the first element in matches. Args:; variant: Our candidate third_party.nucleus.protos.Variant variant. Returns:; A tuple of (match_status, truth_variant) where match_status is True if; we are confident in our truth_variant call or False if not. truth_variant; is a third_party.nucleus.protos.Variant object of; the truth variant that matched; variant, or None if none was found and we aren't confident in being; hom-ref here, or a synthetic variant with the same position and alleles as; variant but with a hom-ref genotype.; """"""; """"""Creates a version of variant with a hom-ref genotype. Args:; variant: Our candidate third_party.nucleus.protos.Variant variant. Returns:; A new Variant with the same position and alleles as variant but with a; hom-ref genotype.; """"""; """"""Finds a variant in vcf_reader compatible with variant, if one e",MatchSource.CODE_COMMENT,deepvariant/labeler/positional_labeler.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/positional_labeler.py
Testability,test,tests,"sion.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for deepvariant .variant_labeler.""""""; # Confident variants: SNP, deletion, and multi-allelic.; # Outside our confident regions.; # Simple tests: we get back our matching variants in the confident regions; # Test the behavior outside of our confident regions.; # If we provide a variant outside the confident regions (non_confident) we; # don't get back any expected_truth variants.; # No matching variant, so we get a None as well as False.; # This variant doesn't have any match but we're confident in it.; # These variant start at our SNP but has a different allele. We are; # confident and we get back the true snp variant, despite having the; # different alleles. snp has alleles=['A', 'C'] and gt=[0, 1].; # Checks that we don't match against the filtered truth variant in our; # database. This means that we return not the filtered variant but one; # with a (0, 0) genotype.; # Call _match so we can compare our expected truth with the actual one.; # Now call label_variants to exercise the higher-level API.; # Tests that match() selects the variant at the same start even if that; # variant doesn't have the same alleles at candidate and there's an; # overlapping with the same alleles",MatchSource.CODE_COMMENT,deepvariant/labeler/positional_labeler_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/positional_labeler_test.py
Usability,simpl,simplify,"O EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for deepvariant .variant_labeler.""""""; # Confident variants: SNP, deletion, and multi-allelic.; # Outside our confident regions.; # Simple tests: we get back our matching variants in the confident regions; # Test the behavior outside of our confident regions.; # If we provide a variant outside the confident regions (non_confident) we; # don't get back any expected_truth variants.; # No matching variant, so we get a None as well as False.; # This variant doesn't have any match but we're confident in it.; # These variant start at our SNP but has a different allele. We are; # confident and we get back the true snp variant, despite having the; # different alleles. snp has alleles=['A', 'C'] and gt=[0, 1].; # Checks that we don't match against the filtered truth variant in our; # database. This means that we return not the filtered variant but one; # with a (0, 0) genotype.; # Call _match so we can compare our expected truth with the actual one.; # Now call label_variants to exercise the higher-level API.; # Tests that match() selects the variant at the same start even if that; # variant doesn't have the same alleles at candidate and there's an; # overlapping with the same alleles.; # No candidate variant with matching alt, so use first candidate.; # GAAA->GAA is the same as GA->A (the second one in matches), but if we; # don't simplify the alleles before comparing, there will be no match and; # will incorrectly fall back to the first one.",MatchSource.CODE_COMMENT,deepvariant/labeler/positional_labeler_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/positional_labeler_test.py
Availability,down,down,". The VariantLabel can be used to determine the genotype label for; each variant suitable for training a DeepVariant model. The API accepts; an iterable of Variants because, in the general case, the labeling of; variants aren't independent, in that the label assigned to one variant may; impact the label we assign to a nearby variant. Args:; variants: iterable[nucleus.protos.Variant]: An iterable of variants to; label. The variants should be in coordinate-sorted order and all on the; same chromosome.; region: A nucleus.genomics.v1.Range object specifying the region over; which we are labeling variants. This should span at least the span of; variants, but may be larger. Statistics about the labeling will be; computed over region. Yields:; A VariantLabel object for each variant in variants, in order.; """"""; """"""Gets truth variants within region to use in labeling calculations. This function queries _truth_vcf_reader in region to get a complete list of; truth variants that overlap region, and then filters them down by removing; filtered truth variants and ones that aren't contained in the truth; intervals. Args:; region: nucleus.Range proto describing the region on the genome where we; want to get our truth variants. Yields:; nucleus.Variant proto.; """"""; """"""Gets the diploid genotype for candidate_variant from matched truth_variant. This method figures out the genotype for candidate_variant by matching alleles; in candidate_variant with those used by the genotype assigned to; truth_variant. For example, if candidate is A/C and truth is A/C with a 0/1; genotype, then this function would return (0, 1) indicating that there's one; copy of the A allele and one of C in truth. If the true genotype is 1/1, then; this routine would return (1, 1). The routine allows candidate_variant and truth_variant to differ in both; the number of alternate alleles, and even in the representation of the same; alleles due to those differences. For example, candidate could be:. AGT/A/AGTGT => 2 bp ",MatchSource.CODE_COMMENT,deepvariant/labeler/variant_labeler.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/variant_labeler.py
Integrability,rout,routine,"ver region. Yields:; A VariantLabel object for each variant in variants, in order.; """"""; """"""Gets truth variants within region to use in labeling calculations. This function queries _truth_vcf_reader in region to get a complete list of; truth variants that overlap region, and then filters them down by removing; filtered truth variants and ones that aren't contained in the truth; intervals. Args:; region: nucleus.Range proto describing the region on the genome where we; want to get our truth variants. Yields:; nucleus.Variant proto.; """"""; """"""Gets the diploid genotype for candidate_variant from matched truth_variant. This method figures out the genotype for candidate_variant by matching alleles; in candidate_variant with those used by the genotype assigned to; truth_variant. For example, if candidate is A/C and truth is A/C with a 0/1; genotype, then this function would return (0, 1) indicating that there's one; copy of the A allele and one of C in truth. If the true genotype is 1/1, then; this routine would return (1, 1). The routine allows candidate_variant and truth_variant to differ in both; the number of alternate alleles, and even in the representation of the same; alleles due to those differences. For example, candidate could be:. AGT/A/AGTGT => 2 bp deletion and 2 bp insertion. and truth could have:. A/AGT => just the simplified 2 bp insertion. And this routine will correctly equate the AGT/AGTGT allele in candidate; with the A/AGT in truth and use the number of copies of AGT in truth to; compute the number of copies of AGTGT when determining the returned genotype. Args:; candidate_variant: Our candidate third_party.nucleus.protos.Variant variant.; truth_variant: Our third_party.nucleus.protos.Variant truth variant; containing true alleles and genotypes. Returns:; A tuple genotypes with the same semantics at the genotype field of the; VariantCall proto. Raises:; ValueError: If candidate_variant is None, truth_variant is None, or; truth_variant doesn't have genot",MatchSource.CODE_COMMENT,deepvariant/labeler/variant_labeler.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/variant_labeler.py
Safety,predict,predict,"EORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""variant_labeler for DeepVariant.""""""; # ---------------------------------------------------------------------------; # VariantLabel; #; """"""Dataclass containing information about a label assigned to a variant. Attributes:; is_confident: bool. True if we could confidently assign a label to this; variant, False otherwise.; variant: nucleus.protos.Variant proto that we assigned a label for.; genotype: tuple of ints. The labeled genotype (e.g., (0, 1) for a het) in; the standard nucleus.proto.VariantCall style. Genotype can be None if the; labeler doesn't have any genotype to assign. If Genotype is not None, the; genotype of variant will be set to genotype.; """"""; """"""Computes the label value for an example using alt_alleles_indices. This function computes the TensorFlow label value (0, 1, 2) we train; DeepVariant to predict. The label value is an int >= which is the number of; copies of the alt allele present, which is computed from the true genotypes; (self.genotypes) and the alt_allele_indices ([0] for the first alt, [1] for; the second, [0, 1] to combine the first and second). For example, suppose we; have a variant with alts A and C, and a true genotype of (0, 1), indicating; that we have 1 copy of the A allele. We'd expect:. label_for_alt_alleles([0]) => 1 since there's 1 copy of the first alt.; label_for_alt_alleles([1]) => 0 since there's 0 copies of the second alt.; label_for_alt_alleles([0, 1]) => 1 since there's 1 copy of the first or; second allele. Args:; alt_alleles_indices: list[int]. A list of the alt_allele_indices used to; compute the tf.Example for this candidate. Returns:; int >= 0. The number of copies of alt_allele_indices we'd expect to be; called for this example.; """"""; """"""Convert label to the class id.""""""; # Set the label of the exampl",MatchSource.CODE_COMMENT,deepvariant/labeler/variant_labeler.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/variant_labeler.py
Security,access,accessible,"ant with alts A and C, and a true genotype of (0, 1), indicating; that we have 1 copy of the A allele. We'd expect:. label_for_alt_alleles([0]) => 1 since there's 1 copy of the first alt.; label_for_alt_alleles([1]) => 0 since there's 0 copies of the second alt.; label_for_alt_alleles([0, 1]) => 1 since there's 1 copy of the first or; second allele. Args:; alt_alleles_indices: list[int]. A list of the alt_allele_indices used to; compute the tf.Example for this candidate. Returns:; int >= 0. The number of copies of alt_allele_indices we'd expect to be; called for this example.; """"""; """"""Convert label to the class id.""""""; # Set the label of the example to the # alts given our alt_alleles_indices.; # ---------------------------------------------------------------------------; # _VariantLabeler base class; #; """"""BaseClass for systems that want to provide training labels for examples. A VariantLabeler provides methods to assign a genotype label to each of a; series of candidate variants using data from a truth set of variants; accessible with vcf_reader and an optional RangeSet of confident regions. The basic logic of this class is something like:. candidates = [third_party.nucleus.protos.Variant(...), ...]; labeler = ConcreteSubclassOfVariantLabeler(vcf_reader, confident_regions); for label in labeler.label_variants(candidates):; if label.is_confident:; for i in range(len(label.variant.alternate_bases); genotype_label_value = label.label_for_alt_alleles([i]). See the docs on each individual function to get a better understanding of what; each function does and the meaning of the return values.; """"""; """"""Gets the LabelingMetrics proto tracking metrics for this labeler. A variant labeler may provide information information about the labeling of; variants via the metrics property. If the labeler provides metrics, a; filled in LabelingMetrics protobuf will be returned by this property. If; metrics aren't supported, a None value will be returned.; """"""; """"""Gets label information",MatchSource.CODE_COMMENT,deepvariant/labeler/variant_labeler.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/variant_labeler.py
Testability,log,logic,"les([0]) => 1 since there's 1 copy of the first alt.; label_for_alt_alleles([1]) => 0 since there's 0 copies of the second alt.; label_for_alt_alleles([0, 1]) => 1 since there's 1 copy of the first or; second allele. Args:; alt_alleles_indices: list[int]. A list of the alt_allele_indices used to; compute the tf.Example for this candidate. Returns:; int >= 0. The number of copies of alt_allele_indices we'd expect to be; called for this example.; """"""; """"""Convert label to the class id.""""""; # Set the label of the example to the # alts given our alt_alleles_indices.; # ---------------------------------------------------------------------------; # _VariantLabeler base class; #; """"""BaseClass for systems that want to provide training labels for examples. A VariantLabeler provides methods to assign a genotype label to each of a; series of candidate variants using data from a truth set of variants; accessible with vcf_reader and an optional RangeSet of confident regions. The basic logic of this class is something like:. candidates = [third_party.nucleus.protos.Variant(...), ...]; labeler = ConcreteSubclassOfVariantLabeler(vcf_reader, confident_regions); for label in labeler.label_variants(candidates):; if label.is_confident:; for i in range(len(label.variant.alternate_bases); genotype_label_value = label.label_for_alt_alleles([i]). See the docs on each individual function to get a better understanding of what; each function does and the meaning of the return values.; """"""; """"""Gets the LabelingMetrics proto tracking metrics for this labeler. A variant labeler may provide information information about the labeling of; variants via the metrics property. If the labeler provides metrics, a; filled in LabelingMetrics protobuf will be returned by this property. If; metrics aren't supported, a None value will be returned.; """"""; """"""Gets label information for each variant in variants. This is the primary API for assigning labels to variants. This function; takes and iterable of variants",MatchSource.CODE_COMMENT,deepvariant/labeler/variant_labeler.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/variant_labeler.py
Usability,simpl,simplified," in region to get a complete list of; truth variants that overlap region, and then filters them down by removing; filtered truth variants and ones that aren't contained in the truth; intervals. Args:; region: nucleus.Range proto describing the region on the genome where we; want to get our truth variants. Yields:; nucleus.Variant proto.; """"""; """"""Gets the diploid genotype for candidate_variant from matched truth_variant. This method figures out the genotype for candidate_variant by matching alleles; in candidate_variant with those used by the genotype assigned to; truth_variant. For example, if candidate is A/C and truth is A/C with a 0/1; genotype, then this function would return (0, 1) indicating that there's one; copy of the A allele and one of C in truth. If the true genotype is 1/1, then; this routine would return (1, 1). The routine allows candidate_variant and truth_variant to differ in both; the number of alternate alleles, and even in the representation of the same; alleles due to those differences. For example, candidate could be:. AGT/A/AGTGT => 2 bp deletion and 2 bp insertion. and truth could have:. A/AGT => just the simplified 2 bp insertion. And this routine will correctly equate the AGT/AGTGT allele in candidate; with the A/AGT in truth and use the number of copies of AGT in truth to; compute the number of copies of AGTGT when determining the returned genotype. Args:; candidate_variant: Our candidate third_party.nucleus.protos.Variant variant.; truth_variant: Our third_party.nucleus.protos.Variant truth variant; containing true alleles and genotypes. Returns:; A tuple genotypes with the same semantics at the genotype field of the; VariantCall proto. Raises:; ValueError: If candidate_variant is None, truth_variant is None, or; truth_variant doesn't have genotypes.; """"""; # If nothing matched, we don't have this alt, so the alt allele index for; # should be 0 (i.e., not any alt).; # If our candidate_variant is a reference call, return a (0, 0) genotype.",MatchSource.CODE_COMMENT,deepvariant/labeler/variant_labeler.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/variant_labeler.py
Deployability,configurat,configuration,"; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for deepvariant .variant_labeler.""""""; """"""A placeholder VariantLabeler. This class provides a label_variants implementation and so allows the base; class to be instantiated and its methods tested.; """"""; # Check that we get v1 and v2 specifically when only they are covered by the; # query.; # We don't include filtered variants.; # Check that we get all overlapping variants of our query.; # Checks that a simple query gets all our non-filtered variants.; # Even through our query covers v5, it's not confident, so we don't get it.; # Make sure we get the right alt counts for all diploid genotypes.; # Make sure get back a zero alt count for a reference variant.; # Basic multi-allelic tests, without having to deal with simplifying; # alleles as all of the alleles are SNPs. Our candidates have an extra; # allele, but the true GT is A/C.; # When considering A/G our answer should be 0 as we have no copies; # of the G allele.; # We are considering the het-alt configuration here of A vs. C+G. We've; # got one copy of the C allele so our true genotype is het. If truth is; # hom-var for the C, though, we again label the composite as hom_var as; # we have two copies of the C/G alt.; # Here we have an extra allele in truth, while candidate is bi-allelic.; # This example 'G' is unused in truth, so we are simply the normal; # bi-allelic result.; # We check here that we get the bi-allelic result even when the extra; # allele is in position 1 not 2.; # Now for a real het-alt. We've got three alleles in both, and the true; # genotype is 1/2.; # Test all possible values in candidate against het-alt:; # Simple start for indel alleles => exact matching works here.; # We've got a multi-allelic truth, but again exact matching is enough.; # This case has an extra allele (A) in truth but the true genotype; # corresponds to our candidate alleles exactly.; # If the true genotype involved just the deletion (A) allele, we don't; # have that allele in our ca",MatchSource.CODE_COMMENT,deepvariant/labeler/variant_labeler_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/variant_labeler_test.py
Modifiability,config,configuration,"; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for deepvariant .variant_labeler.""""""; """"""A placeholder VariantLabeler. This class provides a label_variants implementation and so allows the base; class to be instantiated and its methods tested.; """"""; # Check that we get v1 and v2 specifically when only they are covered by the; # query.; # We don't include filtered variants.; # Check that we get all overlapping variants of our query.; # Checks that a simple query gets all our non-filtered variants.; # Even through our query covers v5, it's not confident, so we don't get it.; # Make sure we get the right alt counts for all diploid genotypes.; # Make sure get back a zero alt count for a reference variant.; # Basic multi-allelic tests, without having to deal with simplifying; # alleles as all of the alleles are SNPs. Our candidates have an extra; # allele, but the true GT is A/C.; # When considering A/G our answer should be 0 as we have no copies; # of the G allele.; # We are considering the het-alt configuration here of A vs. C+G. We've; # got one copy of the C allele so our true genotype is het. If truth is; # hom-var for the C, though, we again label the composite as hom_var as; # we have two copies of the C/G alt.; # Here we have an extra allele in truth, while candidate is bi-allelic.; # This example 'G' is unused in truth, so we are simply the normal; # bi-allelic result.; # We check here that we get the bi-allelic result even when the extra; # allele is in position 1 not 2.; # Now for a real het-alt. We've got three alleles in both, and the true; # genotype is 1/2.; # Test all possible values in candidate against het-alt:; # Simple start for indel alleles => exact matching works here.; # We've got a multi-allelic truth, but again exact matching is enough.; # This case has an extra allele (A) in truth but the true genotype; # corresponds to our candidate alleles exactly.; # If the true genotype involved just the deletion (A) allele, we don't; # have that allele in our ca",MatchSource.CODE_COMMENT,deepvariant/labeler/variant_labeler_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/variant_labeler_test.py
Testability,test,tested," from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for deepvariant .variant_labeler.""""""; """"""A placeholder VariantLabeler. This class provides a label_variants implementation and so allows the base; class to be instantiated and its methods tested.; """"""; # Check that we get v1 and v2 specifically when only they are covered by the; # query.; # We don't include filtered variants.; # Check that we get all overlapping variants of our query.; # Checks that a simple query gets all our non-filtered variants.; # Even through our query covers v5, it's not confident, so we don't get it.; # Make sure we get the right alt counts for all diploid genotypes.; # Make sure get back a zero alt count for a reference variant.; # Basic multi-allelic tests, without having to deal with simplifying; # alleles as all of the alleles are SNPs. Our candidates have an extra; # allele, but the true GT is A/C.; # When considering A/G our answer should be 0 as we have no copies; # of the G allele.; # We are considering the het-alt configuration here of A vs. C+G. We've; # got one copy of the C allele so our true genotype is het. If truth is; # hom-var for the C, though, we again label the composite ",MatchSource.CODE_COMMENT,deepvariant/labeler/variant_labeler_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/variant_labeler_test.py
Usability,simpl,simple,"ICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for deepvariant .variant_labeler.""""""; """"""A placeholder VariantLabeler. This class provides a label_variants implementation and so allows the base; class to be instantiated and its methods tested.; """"""; # Check that we get v1 and v2 specifically when only they are covered by the; # query.; # We don't include filtered variants.; # Check that we get all overlapping variants of our query.; # Checks that a simple query gets all our non-filtered variants.; # Even through our query covers v5, it's not confident, so we don't get it.; # Make sure we get the right alt counts for all diploid genotypes.; # Make sure get back a zero alt count for a reference variant.; # Basic multi-allelic tests, without having to deal with simplifying; # alleles as all of the alleles are SNPs. Our candidates have an extra; # allele, but the true GT is A/C.; # When considering A/G our answer should be 0 as we have no copies; # of the G allele.; # We are considering the het-alt configuration here of A vs. C+G. We've; # got one copy of the C allele so our true genotype is het. If truth is; # hom-var for the C, though, we again label the composite as hom_var as; # we have two copies of the C/G alt.; # Here we have an extra allele in truth, while candidate is bi-allelic.; # This example 'G' is unused in truth, so we are simply the normal; # bi-allelic result.; # We check here that we get the bi-allelic result even when the extra; ",MatchSource.CODE_COMMENT,deepvariant/labeler/variant_labeler_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/variant_labeler_test.py
Integrability,wrap,wrappers,"# Copyright 2017 Google LLC.; #; # Redistribution and use in source and binary forms, with or without; # modification, are permitted provided that the following conditions; # are met:; #; # 1. Redistributions of source code must retain the above copyright notice,; # this list of conditions and the following disclaimer.; #; # 2. Redistributions in binary form must reproduce the above copyright; # notice, this list of conditions and the following disclaimer in the; # documentation and/or other materials provided with the distribution.; #; # 3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for AlleleCounter CLIF python wrappers.""""""",MatchSource.CODE_COMMENT,deepvariant/python/allelecounter_wrap_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/python/allelecounter_wrap_test.py
Integrability,wrap,wrappers,"# Copyright 2017 Google LLC.; #; # Redistribution and use in source and binary forms, with or without; # modification, are permitted provided that the following conditions; # are met:; #; # 1. Redistributions of source code must retain the above copyright notice,; # this list of conditions and the following disclaimer.; #; # 2. Redistributions in binary form must reproduce the above copyright; # notice, this list of conditions and the following disclaimer in the; # documentation and/or other materials provided with the distribution.; #; # 3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for VariantCalling CLIF python wrappers.""""""; # Grab all of the reads in our region and add them to the allele_counter.; # Get the candidates records for this whole region.; # We should have at least some candidates and some gvcf records.; # Each candidate should be a DeepVariantCall.",MatchSource.CODE_COMMENT,deepvariant/python/variant_calling_multisample_wrap_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/python/variant_calling_multisample_wrap_test.py
Integrability,wrap,wrappers,"# Copyright 2017 Google LLC.; #; # Redistribution and use in source and binary forms, with or without; # modification, are permitted provided that the following conditions; # are met:; #; # 1. Redistributions of source code must retain the above copyright notice,; # this list of conditions and the following disclaimer.; #; # 2. Redistributions in binary form must reproduce the above copyright; # notice, this list of conditions and the following disclaimer in the; # documentation and/or other materials provided with the distribution.; #; # 3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for VariantCalling CLIF python wrappers.""""""; # Grab all of the reads in our region and add them to the allele_counter.; # Get the candidates records for this whole region.; # We should have at least some candidates and some gvcf records.; # Each candidate should be a DeepVariantCall.",MatchSource.CODE_COMMENT,deepvariant/python/variant_calling_wrap_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/python/variant_calling_wrap_test.py
Availability,down,down,"of the final read alignment,; after the left and/or right have been trimmed off.; read_trim: The number of bases of the read that are trimmed off.; new_read_length: The number of bases of the read that remain after trimming.; This is different from the final number of reference bases; for example,; an insertion makes the read longer without affecting the reference.; """"""; # First consume the ref until the trim is covered.; # Then consume the ref until the ref_length is covered.; # Each operation moves forward in the ref, the read, or both.; # First, use up each operation until the trimmed area is covered.; # Fully apply to the trim.; # Partially apply to finish the trim.; # If trim finishes here, the rest of the ref_step can apply to the; # next stage and count towards covering the given ref window.; # Once the trim is done, start applying cigar entries to covering the ref; # window.; # Fully apply to the window.; # Partially apply to finish the window.; """"""Trim a read down to the part that aligns within a given region. The following properties of the read are updated, trimming on both sides as; necessary to save only the parts of the read that fit fully within the; region, potentially starting and ending at the region's boundaries:; - The alignment position (read.alignment.position.position).; - The read sequence (read.aligned_sequence).; - Base qualities (read.aligned_quality).; - The cigar string of the alignment (read.alignment.cigar). Args:; read: A `nucleus.protos.Read` that is aligned to the region.; region: A `nucleus.protos.Range` region. Returns:; a new `nucleus.protos.Read` trimmed to the region.; """"""; # Copy everything but aligned_sequence and aligned_quality fields of the read; # to get all recursive properties and prevent mutating the original.; # Following fields are not needed but we copy them for consistency:; # Set aligned_sequence, a string:; # Set aligned_quality, a repeated integer:; # Direct assignment on a repeated message field is not allowed,",MatchSource.CODE_COMMENT,deepvariant/realigner/realigner.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/realigner.py
Deployability,configurat,configuration,"IMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Correct read alignment by realigning the read to its most likely haplotype. This is achieved by constructing de-Bruijn graphs in candidate regions with; potential variations, and determining the mostly likely X haplotypes (where X is; the ploidy).; """"""; # Margin added to the reference sequence for the aligner module.; # Minimum length of read to retain following splitting with --split_skip_reads.; # ---------------------------------------------------------------------------; # Set configuration settings.; # ---------------------------------------------------------------------------; """"""Creates a WindowSelectorOptions proto based on input and default settings. Args:; flags_obj: configuration FLAGS. Returns:; realigner_pb2.WindowSelector protobuf. Raises:; ValueError: If either ws_{min,max}_supporting_reads are set and; ws_use_window_selector_model is True.; Or if ws_window_selector_model > ws_max_num_supporting_reads.; Or if ws_use_window_selector_model is False and; ws_window_selector_model is not None.; """"""; """"""Creates a RealignerOptions proto based on input and default settings. Args:; flags_obj: configuration FLAGS. Returns:; realigner_pb2.RealignerOptions protobuf. Raises:; ValueError: If we observe invalid flag values.; """"""; # The normalize_reads flag could came from the `flags_obj` arg, passed in; # from make_examples_options.py. It is already part of AlleleCounterOptions in; # MakeExamplesOptions. Here, we need to set it in",MatchSource.CODE_COMMENT,deepvariant/realigner/realigner.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/realigner.py
Energy Efficiency,reduce,reduced," this_haplotype: string. Sequence of the haplotype to treat as reference,; reporting alignments according to its coordinates.; haplotypes: list of strings. All haplotypes to use in the graph, including; this_haplotype.; prefix: string. Sequence to the left of where the haplotypes differ.; suffix: string. Sequence to the right of where the haplotypes differ.; reads: reads to align.; contig: string. Name of the 'reference' to report in read alignments.; ref_start: integer. Start position of the region to report in read; alignments. This should mark the beginning of the prefix sequence. Returns:; Reads. Realigned and reported relative to the chosen haplotype.; """"""; # Testing found that when the prefix and suffix both go right up to the; # ref/alt variants, the alignment does not work well, so a margin of 100; # bases on each side of the variant are used here to pad each; # haplotype with enough sequence to align against. While some further; # testing showed this could be reduced, 100 is the only value that has been; # tested with a full training experiment.; """"""Trim a cigar string to a certain reference length. Args:; cigar: list of `nucleus.protos.CigarUnit`s of the original read alignment.; ref_trim: integer. Number of reference bases to trim off the beginning of; the read.; ref_length: integer. Number of reference bases to cover with the read, the; middle part that is not trimmed from the start or end of the read. Returns:; new_cigar: list of `nucleus.protos.CigarUnit`s of the final read alignment,; after the left and/or right have been trimmed off.; read_trim: The number of bases of the read that are trimmed off.; new_read_length: The number of bases of the read that remain after trimming.; This is different from the final number of reference bases; for example,; an insertion makes the read longer without affecting the reference.; """"""; # First consume the ref until the trim is covered.; # Then consume the ref until the ref_length is covered.; # Each operation moves ",MatchSource.CODE_COMMENT,deepvariant/realigner/realigner.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/realigner.py
Integrability,message,message," and/or right have been trimmed off.; read_trim: The number of bases of the read that are trimmed off.; new_read_length: The number of bases of the read that remain after trimming.; This is different from the final number of reference bases; for example,; an insertion makes the read longer without affecting the reference.; """"""; # First consume the ref until the trim is covered.; # Then consume the ref until the ref_length is covered.; # Each operation moves forward in the ref, the read, or both.; # First, use up each operation until the trimmed area is covered.; # Fully apply to the trim.; # Partially apply to finish the trim.; # If trim finishes here, the rest of the ref_step can apply to the; # next stage and count towards covering the given ref window.; # Once the trim is done, start applying cigar entries to covering the ref; # window.; # Fully apply to the window.; # Partially apply to finish the window.; """"""Trim a read down to the part that aligns within a given region. The following properties of the read are updated, trimming on both sides as; necessary to save only the parts of the read that fit fully within the; region, potentially starting and ending at the region's boundaries:; - The alignment position (read.alignment.position.position).; - The read sequence (read.aligned_sequence).; - Base qualities (read.aligned_quality).; - The cigar string of the alignment (read.alignment.cigar). Args:; read: A `nucleus.protos.Read` that is aligned to the region.; region: A `nucleus.protos.Range` region. Returns:; a new `nucleus.protos.Read` trimmed to the region.; """"""; # Copy everything but aligned_sequence and aligned_quality fields of the read; # to get all recursive properties and prevent mutating the original.; # Following fields are not needed but we copy them for consistency:; # Set aligned_sequence, a string:; # Set aligned_quality, a repeated integer:; # Direct assignment on a repeated message field is not allowed, so setting; # the cigar by using 'extend'.",MatchSource.CODE_COMMENT,deepvariant/realigner/realigner.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/realigner.py
Modifiability,config,configuration,"IMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Correct read alignment by realigning the read to its most likely haplotype. This is achieved by constructing de-Bruijn graphs in candidate regions with; potential variations, and determining the mostly likely X haplotypes (where X is; the ploidy).; """"""; # Margin added to the reference sequence for the aligner module.; # Minimum length of read to retain following splitting with --split_skip_reads.; # ---------------------------------------------------------------------------; # Set configuration settings.; # ---------------------------------------------------------------------------; """"""Creates a WindowSelectorOptions proto based on input and default settings. Args:; flags_obj: configuration FLAGS. Returns:; realigner_pb2.WindowSelector protobuf. Raises:; ValueError: If either ws_{min,max}_supporting_reads are set and; ws_use_window_selector_model is True.; Or if ws_window_selector_model > ws_max_num_supporting_reads.; Or if ws_use_window_selector_model is False and; ws_window_selector_model is not None.; """"""; """"""Creates a RealignerOptions proto based on input and default settings. Args:; flags_obj: configuration FLAGS. Returns:; realigner_pb2.RealignerOptions protobuf. Raises:; ValueError: If we observe invalid flag values.; """"""; # The normalize_reads flag could came from the `flags_obj` arg, passed in; # from make_examples_options.py. It is already part of AlleleCounterOptions in; # MakeExamplesOptions. Here, we need to set it in",MatchSource.CODE_COMMENT,deepvariant/realigner/realigner.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/realigner.py
Performance,cache,cache,"rmation for region.""""""; """"""A region to assemble, holding the region Range and the reads. It is not safe to directly modify any of the attributes here. Use the accessor; functions to add a read to the reads. Attributes:; candidate_haplotypes: realigner.CandidateHaplotypes for this region.; reads: list[reads_pb2.Read]. Reads for this region.; region: range_pb2.Range. This is the span of the assembled region on the; genome.; read_span: range_pb2.Range. This is the span of reads added to this region.; The read_span in general is expected to be wider than the region itself,; since we often include all reads that overlap the region at all. It is; possible that read_span will be smaller than region, which can happen, for; example, when we only have reads starts in the middle of the region.; Here's a picture of when this can happen: ref : acgtACGTACgtgt region; : ------ read1 : GGa; read_span: ---; """"""; """"""Returns the haplotypes list[str] of our candidate_haplotypes.""""""; # Adding a read invalidates our _read_span cache.; """"""Assign each read to the maximally overlapped window. Args:; assembled_regions: list[AssemblyRegion], list of AssemblyRegion to assign; reads to. Does not assume AssemblyRegion are sorted.; reads: iterable[learning.genomics.genomics.Read], to be processed. Does not; assume the reads are sorted. Returns:; [AssemblyRegion], information on assigned reads for each assembled region.; list[learning.genomics.genomics.Read], the list of unassigned reads.; """"""; """"""Copies a read proto to create a new read part.""""""; # Reset alignment information.; # Note: If long reads will be used here, convert; # to approach used for read trimming.; """"""Splits reads containing SKIP cigar operations into multiple parts.""""""; # Check for SKIP operations within the Cigar String; # Get alignment position; # Set position where the first ref op encountered.; """"""Realign reads in regions to assembled haplotypes. This class helps us to realign reads in regions by:. (1) Create smaller windows",MatchSource.CODE_COMMENT,deepvariant/realigner/realigner.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/realigner.py
Safety,safe,safe,"on FLAGS. Returns:; realigner_pb2.RealignerOptions protobuf. Raises:; ValueError: If we observe invalid flag values.; """"""; # The normalize_reads flag could came from the `flags_obj` arg, passed in; # from make_examples_options.py. It is already part of AlleleCounterOptions in; # MakeExamplesOptions. Here, we need to set it in RealignerOptions as well; # because an if statement in fast_pass_aligner.cc needs it to decide whether; # to run a specific logic.; # This is not ideal. If there's a way to improve this, please do.; """"""Writes diagnostic information about the assembler.""""""; # Setup diagnostics outputs if requested.; """"""Returns the path to a file in a region-specific subdirectory.""""""; """"""Logs, if enabled, the realigned reads for region.""""""; # For realigned reads, sorting by just looking at starting position is; # enough.; """"""Logs, if enabled, graph construction information for region.""""""; """"""A region to assemble, holding the region Range and the reads. It is not safe to directly modify any of the attributes here. Use the accessor; functions to add a read to the reads. Attributes:; candidate_haplotypes: realigner.CandidateHaplotypes for this region.; reads: list[reads_pb2.Read]. Reads for this region.; region: range_pb2.Range. This is the span of the assembled region on the; genome.; read_span: range_pb2.Range. This is the span of reads added to this region.; The read_span in general is expected to be wider than the region itself,; since we often include all reads that overlap the region at all. It is; possible that read_span will be smaller than region, which can happen, for; example, when we only have reads starts in the middle of the region.; Here's a picture of when this can happen: ref : acgtACGTACgtgt region; : ------ read1 : GGa; read_span: ---; """"""; """"""Returns the haplotypes list[str] of our candidate_haplotypes.""""""; # Adding a read invalidates our _read_span cache.; """"""Assign each read to the maximally overlapped window. Args:; assembled_regions: list[Ass",MatchSource.CODE_COMMENT,deepvariant/realigner/realigner.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/realigner.py
Security,access,accessor,". Raises:; ValueError: If we observe invalid flag values.; """"""; # The normalize_reads flag could came from the `flags_obj` arg, passed in; # from make_examples_options.py. It is already part of AlleleCounterOptions in; # MakeExamplesOptions. Here, we need to set it in RealignerOptions as well; # because an if statement in fast_pass_aligner.cc needs it to decide whether; # to run a specific logic.; # This is not ideal. If there's a way to improve this, please do.; """"""Writes diagnostic information about the assembler.""""""; # Setup diagnostics outputs if requested.; """"""Returns the path to a file in a region-specific subdirectory.""""""; """"""Logs, if enabled, the realigned reads for region.""""""; # For realigned reads, sorting by just looking at starting position is; # enough.; """"""Logs, if enabled, graph construction information for region.""""""; """"""A region to assemble, holding the region Range and the reads. It is not safe to directly modify any of the attributes here. Use the accessor; functions to add a read to the reads. Attributes:; candidate_haplotypes: realigner.CandidateHaplotypes for this region.; reads: list[reads_pb2.Read]. Reads for this region.; region: range_pb2.Range. This is the span of the assembled region on the; genome.; read_span: range_pb2.Range. This is the span of reads added to this region.; The read_span in general is expected to be wider than the region itself,; since we often include all reads that overlap the region at all. It is; possible that read_span will be smaller than region, which can happen, for; example, when we only have reads starts in the middle of the region.; Here's a picture of when this can happen: ref : acgtACGTACgtgt region; : ------ read1 : GGa; read_span: ---; """"""; """"""Returns the haplotypes list[str] of our candidate_haplotypes.""""""; # Adding a read invalidates our _read_span cache.; """"""Assign each read to the maximally overlapped window. Args:; assembled_regions: list[AssemblyRegion], list of AssemblyRegion to assign; reads to. D",MatchSource.CODE_COMMENT,deepvariant/realigner/realigner.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/realigner.py
Testability,log,logic,"--------------------------------; """"""Creates a WindowSelectorOptions proto based on input and default settings. Args:; flags_obj: configuration FLAGS. Returns:; realigner_pb2.WindowSelector protobuf. Raises:; ValueError: If either ws_{min,max}_supporting_reads are set and; ws_use_window_selector_model is True.; Or if ws_window_selector_model > ws_max_num_supporting_reads.; Or if ws_use_window_selector_model is False and; ws_window_selector_model is not None.; """"""; """"""Creates a RealignerOptions proto based on input and default settings. Args:; flags_obj: configuration FLAGS. Returns:; realigner_pb2.RealignerOptions protobuf. Raises:; ValueError: If we observe invalid flag values.; """"""; # The normalize_reads flag could came from the `flags_obj` arg, passed in; # from make_examples_options.py. It is already part of AlleleCounterOptions in; # MakeExamplesOptions. Here, we need to set it in RealignerOptions as well; # because an if statement in fast_pass_aligner.cc needs it to decide whether; # to run a specific logic.; # This is not ideal. If there's a way to improve this, please do.; """"""Writes diagnostic information about the assembler.""""""; # Setup diagnostics outputs if requested.; """"""Returns the path to a file in a region-specific subdirectory.""""""; """"""Logs, if enabled, the realigned reads for region.""""""; # For realigned reads, sorting by just looking at starting position is; # enough.; """"""Logs, if enabled, graph construction information for region.""""""; """"""A region to assemble, holding the region Range and the reads. It is not safe to directly modify any of the attributes here. Use the accessor; functions to add a read to the reads. Attributes:; candidate_haplotypes: realigner.CandidateHaplotypes for this region.; reads: list[reads_pb2.Read]. Reads for this region.; region: range_pb2.Range. This is the span of the assembled region on the; genome.; read_span: range_pb2.Range. This is the span of reads added to this region.; The read_span in general is expected to be wid",MatchSource.CODE_COMMENT,deepvariant/realigner/realigner.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/realigner.py
Usability,learn,learning,"plotypes: realigner.CandidateHaplotypes for this region.; reads: list[reads_pb2.Read]. Reads for this region.; region: range_pb2.Range. This is the span of the assembled region on the; genome.; read_span: range_pb2.Range. This is the span of reads added to this region.; The read_span in general is expected to be wider than the region itself,; since we often include all reads that overlap the region at all. It is; possible that read_span will be smaller than region, which can happen, for; example, when we only have reads starts in the middle of the region.; Here's a picture of when this can happen: ref : acgtACGTACgtgt region; : ------ read1 : GGa; read_span: ---; """"""; """"""Returns the haplotypes list[str] of our candidate_haplotypes.""""""; # Adding a read invalidates our _read_span cache.; """"""Assign each read to the maximally overlapped window. Args:; assembled_regions: list[AssemblyRegion], list of AssemblyRegion to assign; reads to. Does not assume AssemblyRegion are sorted.; reads: iterable[learning.genomics.genomics.Read], to be processed. Does not; assume the reads are sorted. Returns:; [AssemblyRegion], information on assigned reads for each assembled region.; list[learning.genomics.genomics.Read], the list of unassigned reads.; """"""; """"""Copies a read proto to create a new read part.""""""; # Reset alignment information.; # Note: If long reads will be used here, convert; # to approach used for read trimming.; """"""Splits reads containing SKIP cigar operations into multiple parts.""""""; # Check for SKIP operations within the Cigar String; # Get alignment position; # Set position where the first ref op encountered.; """"""Realign reads in regions to assembled haplotypes. This class helps us to realign reads in regions by:. (1) Create smaller windows in which to operate over the region. These windows; are created by finding evidence of genetic variation surrounded by stretches; of reference-matching seqence. (2) Build a de-Bruijn assembly graph of the window. Edges are pruned if",MatchSource.CODE_COMMENT,deepvariant/realigner/realigner.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/realigner.py
Availability,down,down,"ntig. Note that the; # reference bases in this interval are all Ns as well.; # pylint: disable=g-complex-comprehension; # pylint: enable=g-complex-comprehension; # Make sure that by default we aren't emitting any diagnostic outputs.; # Force close all resources.; # Make sure our diagnostic output isn't emitted.; # Our root directory exists.; # We expect a realigner_metrics.csv in our rootdir with 1 entry in it.; # Check that our runtime is reasonable (greater than 0, less than 10 s).; # As does the subdirectory for this region.; # We always have a graph.dot; # if emit_reads=False then file should not exist and vice versa.; # Align to each haplotype in turn.; # At or below read_buffer_length=15 the reads start to come back; # unaligned, but this depends on the specific ref and alt alleles, so; # this does not include exhaustive tests for how low these values can go.; """"""Testing what happens when read and reference sequences are shorter.""""""; # Start with long prefix and suffix to enable cutting it down as necessary; # Make two haplotypes.; # Simulate one read from the reference and one from the alt haplotype.; # Aligning to ref haplotype: Insertion.; # Aligning to alt haplotype: All matching.; # Align to each haplotype in turn.; # Empty reads as input should return empty reads as output.; # No change.; # Basic split.; # Split with 15bp filter.; # Many small splits filtered out.; # Large split.; # Insertion.; # Insertion + Split.; # Deletion.; # Deletion + Split.; # Sequence Match/Mismatch + Split.; # Soft Clip + Split.; # Hard Clip + Split.; # Check sequences; # Check cigars; # Check reference positions; # We should always get back all of the reads we sent in. Instead of just; # checking the lengths are the same, make sure all the read names are the; # same.; # Check each window to make sure it's reasonable.; # We always expect the reference sequence to be one of our haplotypes.; # Window region literals are 1-based, but all other coordinates are; # 0-based: chr1:11-20",MatchSource.CODE_COMMENT,deepvariant/realigner/realigner_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/realigner_test.py
Integrability,depend,depends,"at chr20:10046178.""""""; """"""Tests that read sets don't result in a crash in reference_fai.cc.""""""; # pylint: disable=g-complex-comprehension; # pylint: enable=g-complex-comprehension; # These reads are aligned off the edge of the contig. Note that the; # reference bases in this interval are all Ns as well.; # pylint: disable=g-complex-comprehension; # pylint: enable=g-complex-comprehension; # Make sure that by default we aren't emitting any diagnostic outputs.; # Force close all resources.; # Make sure our diagnostic output isn't emitted.; # Our root directory exists.; # We expect a realigner_metrics.csv in our rootdir with 1 entry in it.; # Check that our runtime is reasonable (greater than 0, less than 10 s).; # As does the subdirectory for this region.; # We always have a graph.dot; # if emit_reads=False then file should not exist and vice versa.; # Align to each haplotype in turn.; # At or below read_buffer_length=15 the reads start to come back; # unaligned, but this depends on the specific ref and alt alleles, so; # this does not include exhaustive tests for how low these values can go.; """"""Testing what happens when read and reference sequences are shorter.""""""; # Start with long prefix and suffix to enable cutting it down as necessary; # Make two haplotypes.; # Simulate one read from the reference and one from the alt haplotype.; # Aligning to ref haplotype: Insertion.; # Aligning to alt haplotype: All matching.; # Align to each haplotype in turn.; # Empty reads as input should return empty reads as output.; # No change.; # Basic split.; # Split with 15bp filter.; # Many small splits filtered out.; # Large split.; # Insertion.; # Insertion + Split.; # Deletion.; # Deletion + Split.; # Sequence Match/Mismatch + Split.; # Soft Clip + Split.; # Hard Clip + Split.; # Check sequences; # Check cigars; # Check reference positions; # We should always get back all of the reads we sent in. Instead of just; # checking the lengths are the same, make sure all the read names a",MatchSource.CODE_COMMENT,deepvariant/realigner/realigner_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/realigner_test.py
Modifiability,extend,extends," # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for deepvariant .realigner.realigner.""""""; # We haven't added any reads, so reads is empty and the span is None.; # Add read2, giving us a real read span and a read in our region's reads.; # Add read1, increasing the span on the left.; # Finally, add in all of the reads.; # Single read tests.; # read1 overlaps r1.; # read2 falls between r1 and r2, should be unassigned.; # read3 starts before r2 but overlaps it.; # read4 starts in r3 but extends beyond it.; # read5 overlaps r1 and r2 but is more in r2 then r1.; # Let's make sure adding all of the reads together results in the correct; # assignment across all regions.; # Every read should be in the assembled regions or unassigned.; # Go through each region and make sure the reads that are supposed to; # appear in each region do in appear there.; # TODO: Update the tests to reflect the new default (False).; # Arguments passed by ws_{min,max}_supporting_reads.; # No flags passed for the window_selection.; # VariantReadsThresholdModel.; # AlleleCountLinearModel.; # Use the default AlleleCountLinearModel.; # This indirection is needed because the symbols in testdata are not set; # when the @parameterized decorator is called.; # We only make sure that reading the model does not crash or raise; # exceptions.; """"""All overlapping reads should include 10bp deletion at chr20:10046178.""""""; """"""Tests that read sets don't result in a crash in reference_fai.cc.""""""; # pylint: disab",MatchSource.CODE_COMMENT,deepvariant/realigner/realigner_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/realigner_test.py
Testability,test,tests,"# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for deepvariant .realigner.realigner.""""""; # We haven't added any reads, so reads is empty and the span is None.; # Add read2, giving us a real read span and a read in our region's reads.; # Add read1, increasing the span on the left.; # Finally, add in all of the reads.; # Single read tests.; # read1 overlaps r1.; # read2 falls between r1 and r2, should be unassigned.; # read3 starts before r2 but overlaps it.; # read4 starts in r3 but extends beyond it.; # read5 overlaps r1 and r2 but is more in r2 then r1.; # Let's make sure adding all of the reads together results in the correct; # assignment across all regions.; # Every read should be in the assembled regions or unassigned.; # Go through each region and make sure the reads that are supposed to; # appear in each region do in appear there.; # TODO: Update the tests to reflect the new default (False).; # Arguments passed by ws_{min,max}_supporting_reads.; # No flags passed for the window_selection.; # VariantReadsThresholdModel.; # AlleleCountLinearModel.; # Use the default AlleleCountLinearModel.; # This indirection is needed because the symbols in testdata are not set; # when the @parameterized decorator is called.; # We only make sure that reading the model does not crash or raise; # exceptions.; """"""All ove",MatchSource.CODE_COMMENT,deepvariant/realigner/realigner_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/realigner_test.py
Modifiability,config,config,"e or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Determine genomic ranges to perform local assembly.""""""; """"""Returns a list of candidate positions. Args:; config: learning.genomics.deepvariant.realigner.WindowSelectorOptions; options determining the behavior of this window selector.; ref_reader: GenomeReference. Indexed reference genome to query bases.; reads: list[nucleus.protos.Read]. The reads we are processing into candidate; positions.; region: nucleus.protos.Range. The region we are processing. Returns:; A list. The elements are reference positions within region. Raises:; ValueError: if config.window_selector_model.model_type isn't a valid enum; name in realigner_pb2.WindowSelectorModel.ModelType.; """"""; """"""Returns a list of candidate positions. Following cigar operations generate candidate position:; - ALIGNMENT_MATCH, SEQUENCE_MISMATCH, SEQUENCE_MATCH: at mismatch positions; in the read when compared to the reference sequence.; - DELETE: at positions within [cigar_start, cigar_start + cigar_len); - INSERT, CLIP_SOFT: at positions within; [cigar_start - cigar_len, cigar_start + cigar_len). Note. Function implementation has changed to re",MatchSource.CODE_COMMENT,deepvariant/realigner/window_selector.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/window_selector.py
Performance,perform,perform,"ame of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Determine genomic ranges to perform local assembly.""""""; """"""Returns a list of candidate positions. Args:; config: learning.genomics.deepvariant.realigner.WindowSelectorOptions; options determining the behavior of this window selector.; ref_reader: GenomeReference. Indexed reference genome to query bases.; reads: list[nucleus.protos.Read]. The reads we are processing into candidate; positions.; region: nucleus.protos.Range. The region we are processing. Returns:; A list. The elements are reference positions within region. Raises:; ValueError: if config.window_selector_model.model_type isn't a valid enum; name in realigner_pb2.WindowSelectorModel.ModelType.; """"""; """"""Returns a list of candidate positions. Following cigar operations generate candidate position:; - ALIGNMENT_MATCH, SEQUENCE_MISMATCH, SEQUENCE_MATCH: at mismatch positions; in the read when compared to the reference sequence.; - DELETE: at positions within [cigar_start, cigar_start + cigar_len); - INSERT, CLIP_SOFT: at positions within; [cigar_start",MatchSource.CODE_COMMENT,deepvariant/realigner/window_selector.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/window_selector.py
Usability,learn,learning,"e or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Determine genomic ranges to perform local assembly.""""""; """"""Returns a list of candidate positions. Args:; config: learning.genomics.deepvariant.realigner.WindowSelectorOptions; options determining the behavior of this window selector.; ref_reader: GenomeReference. Indexed reference genome to query bases.; reads: list[nucleus.protos.Read]. The reads we are processing into candidate; positions.; region: nucleus.protos.Range. The region we are processing. Returns:; A list. The elements are reference positions within region. Raises:; ValueError: if config.window_selector_model.model_type isn't a valid enum; name in realigner_pb2.WindowSelectorModel.ModelType.; """"""; """"""Returns a list of candidate positions. Following cigar operations generate candidate position:; - ALIGNMENT_MATCH, SEQUENCE_MISMATCH, SEQUENCE_MATCH: at mismatch positions; in the read when compared to the reference sequence.; - DELETE: at positions within [cigar_start, cigar_start + cigar_len); - INSERT, CLIP_SOFT: at positions within; [cigar_start - cigar_len, cigar_start + cigar_len). Note. Function implementation has changed to re",MatchSource.CODE_COMMENT,deepvariant/realigner/window_selector.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/window_selector.py
Modifiability,extend,extended,"r; # length bases.; # The skip (N) and hard clip (H) operators are both ignored.; # The python version raises an exception when seeing a PAD, which is ok; # but isn't strictly necessary. The C++ implementation handles PADs when; # counting alleles, so we've commented out this test.; # C++ version:; # dict(bases='AA', cigar='1M1P1M', expected=[]),; # dict(bases='AA', cigar='1M2P1M', expected=[]),; # Python version:; # dict(bases='AA', cigar='1M1P1M', expected=ValueError),; # dict(bases='AA', cigar='1M2P1M', expected=ValueError),; """"""Test WindowSelector.process_read() with reads of low quality.""""""; # Tests that a read with a mismatch at position read_start + 1 produces a; # single candidate position at read_start + 1 regardless of where it occurs; # within a single region spanning region_start - region_end.; # Our region is 5-8 and we are testing that the read's mismatch is only; # included when it's within the region and not when it's outside.; # Expected region boundaries are extended according to region_expansion_in_bp; # flag. region_expansion_in_bp is set to 20 by default,; # so 5 to 8 becomes 5 - 20 to 8 + 20 <=> 0 to 28; # Our region is 5-8 and we have a 4 basepair deletion in our read. We expect; # a mismatch count of one for each position in the deletion that overlaps the; # interval.; # Expected region boundaries are extended according to region_expansion_in_bp; # flag. region_expansion_in_bp is set to 20 by default,; # so 5 to 8 becomes 5 - 20 to 8 + 20 <=> 0 to 28; # This read has a mismatch at position 2 and a 2 bp insertion at position 4,; # so we need to double count the candidate positions from the mismatch and; # insertion at position 2.; # Check that this works with 3 isolated regions.; # Check a simple example where we have two candidates from the same; # region:; # Check a simple example where we have candidates from two regions:; # Check boundary conditions for merging windows: should merge.; # Check boundary conditions for merging windows: should",MatchSource.CODE_COMMENT,deepvariant/realigner/window_selector_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/window_selector_test.py
Testability,test,test,"ducts derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for deepvariant.realigner.window_selector.""""""; # ------------------------------------------------------------------------; # These reads are all simple and just test the basic position calculation.; # ------------------------------------------------------------------------; """"""Test WindowSelector.process_read() with reads of low quality.""""""; # --------------------------------------------------; # Systematic combination of simple CIGAR operations.; # --------------------------------------------------; """"""Test WindowSelector.process_read() with reads of low quality.""""""; # ------------------------------------------------------------------------; # These reads are all simple and just test the basic position calculation.; # ------------------------------------------------------------------------; # ------------------------------------------------------------------------; # These reads test that we correctly ignore bases with low qualities.; # ------------------------------------------------------------------------; # Only insertions/soft clips where all bases have above our minimum base; # quality are includ",MatchSource.CODE_COMMENT,deepvariant/realigner/window_selector_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/window_selector_test.py
Usability,simpl,simple,"ducts derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for deepvariant.realigner.window_selector.""""""; # ------------------------------------------------------------------------; # These reads are all simple and just test the basic position calculation.; # ------------------------------------------------------------------------; """"""Test WindowSelector.process_read() with reads of low quality.""""""; # --------------------------------------------------; # Systematic combination of simple CIGAR operations.; # --------------------------------------------------; """"""Test WindowSelector.process_read() with reads of low quality.""""""; # ------------------------------------------------------------------------; # These reads are all simple and just test the basic position calculation.; # ------------------------------------------------------------------------; # ------------------------------------------------------------------------; # These reads test that we correctly ignore bases with low qualities.; # ------------------------------------------------------------------------; # Only insertions/soft clips where all bases have above our minimum base; # quality are includ",MatchSource.CODE_COMMENT,deepvariant/realigner/window_selector_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/window_selector_test.py
Integrability,wrap,wrapped," name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Basic tests for the wrapped DeBruijnGraph class.""""""; """"""Get a DeBruijnGraphOptions allowing us to try a single kmer size.""""""; """"""Assert that the DeBruijn has the given graphviz representation. Args:; graphviz_string: the graphviz representation, potentially including common; leading whitespace.; dbg: the DeBruijn graph object.; """"""; # Remove all whitespace before comparison to avoid failing over trivial; # indentation / newline differences.; """"""Basic example.""""""; # Use two reads so read path doesn't get pruned.; """"""\; digraph G {; 0[label=GAT];; 1[label=ATT];; 2[label=TTA];; 3[label=TAC];; 4[label=ACA];; 5[label=ATG];; 6[label=TGA];; 7[label=GAC];; 0->1 [label=1 color=red];; 1->2 [label=1 color=red];; 2->3 [label=1 color=red];; 3->4 [label=1 color=red];; 0->5 [label=2];; 5->6 [label=2];; 6->7 [label=2];; 7->4 [label=2];; }; """"""; """"""Test that pruning removes a path traced by only one read.""""""; """"""\; digraph G {; 0[label=GAT];; 1[label=ATT];; 2[label=TTA];; 3[label=TAC];; 4[label=ACA];; 0->1 [label=1 color=re",MatchSource.CODE_COMMENT,deepvariant/realigner/python/debruijn_graph_wrap_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/python/debruijn_graph_wrap_test.py
Safety,avoid,avoid,"F MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Basic tests for the wrapped DeBruijnGraph class.""""""; """"""Get a DeBruijnGraphOptions allowing us to try a single kmer size.""""""; """"""Assert that the DeBruijn has the given graphviz representation. Args:; graphviz_string: the graphviz representation, potentially including common; leading whitespace.; dbg: the DeBruijn graph object.; """"""; # Remove all whitespace before comparison to avoid failing over trivial; # indentation / newline differences.; """"""Basic example.""""""; # Use two reads so read path doesn't get pruned.; """"""\; digraph G {; 0[label=GAT];; 1[label=ATT];; 2[label=TTA];; 3[label=TAC];; 4[label=ACA];; 5[label=ATG];; 6[label=TGA];; 7[label=GAC];; 0->1 [label=1 color=red];; 1->2 [label=1 color=red];; 2->3 [label=1 color=red];; 3->4 [label=1 color=red];; 0->5 [label=2];; 5->6 [label=2];; 6->7 [label=2];; 7->4 [label=2];; }; """"""; """"""Test that pruning removes a path traced by only one read.""""""; """"""\; digraph G {; 0[label=GAT];; 1[label=ATT];; 2[label=TTA];; 3[label=TAC];; 4[label=ACA];; 0->1 [label=1 color=red];; 1->2 [label=1 color=red];; 2->3 [label=1 color=red];; 3->4 [label=1 color=red];; }; """"""; """"""Test that pruning removes edges not between source and sink.""""""; # Use two reads so read path doesn't get pruned.; """"""\; digraph G {; 0[label=GAT];; 1[label=ATT];; 2[label=TTA];; 3[label=TAC];; 4[label=ACA];; 5[label=ATG];; 6[label=TGA];; 7[label=GAC];; 0->1 [label=1",MatchSource.CODE_COMMENT,deepvariant/realigner/python/debruijn_graph_wrap_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/python/debruijn_graph_wrap_test.py
Testability,test,tests," name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Basic tests for the wrapped DeBruijnGraph class.""""""; """"""Get a DeBruijnGraphOptions allowing us to try a single kmer size.""""""; """"""Assert that the DeBruijn has the given graphviz representation. Args:; graphviz_string: the graphviz representation, potentially including common; leading whitespace.; dbg: the DeBruijn graph object.; """"""; # Remove all whitespace before comparison to avoid failing over trivial; # indentation / newline differences.; """"""Basic example.""""""; # Use two reads so read path doesn't get pruned.; """"""\; digraph G {; 0[label=GAT];; 1[label=ATT];; 2[label=TTA];; 3[label=TAC];; 4[label=ACA];; 5[label=ATG];; 6[label=TGA];; 7[label=GAC];; 0->1 [label=1 color=red];; 1->2 [label=1 color=red];; 2->3 [label=1 color=red];; 3->4 [label=1 color=red];; 0->5 [label=2];; 5->6 [label=2];; 6->7 [label=2];; 7->4 [label=2];; }; """"""; """"""Test that pruning removes a path traced by only one read.""""""; """"""\; digraph G {; 0[label=GAT];; 1[label=ATT];; 2[label=TTA];; 3[label=TAC];; 4[label=ACA];; 0->1 [label=1 color=re",MatchSource.CODE_COMMENT,deepvariant/realigner/python/debruijn_graph_wrap_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/python/debruijn_graph_wrap_test.py
Integrability,wrap,wrapped,"# Copyright 2017 Google LLC.; #; # Redistribution and use in source and binary forms, with or without; # modification, are permitted provided that the following conditions; # are met:; #; # 1. Redistributions of source code must retain the above copyright notice,; # this list of conditions and the following disclaimer.; #; # 2. Redistributions in binary form must reproduce the above copyright; # notice, this list of conditions and the following disclaimer in the; # documentation and/or other materials provided with the distribution.; #; # 3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for the wrapped SSW aligner in a way that fails with gcc5.4.""""""; """"""Test very short strings.""""""; """"""Test longer strings, so the second-best alignment is considered.""""""",MatchSource.CODE_COMMENT,deepvariant/realigner/python/ssw_misc_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/python/ssw_misc_test.py
Integrability,wrap,wrapped,"# Copyright 2017 Google LLC.; #; # Redistribution and use in source and binary forms, with or without; # modification, are permitted provided that the following conditions; # are met:; #; # 1. Redistributions of source code must retain the above copyright notice,; # this list of conditions and the following disclaimer.; #; # 2. Redistributions in binary form must reproduce the above copyright; # notice, this list of conditions and the following disclaimer in the; # documentation and/or other materials provided with the distribution.; #; # 3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; # Expected alignment:; # CAGCCTTTCTGACCCGG-AAATCAAAATAGGCACAACAAA; # ||||*|||| |||||; # CTGAGCCGGTAAATC; """"""Basic tests for the wrapped SSW aligner.""""""; """"""Tests the Align method.""""""; """"""Tests the Align method, reversing query and ref from above.""""""",MatchSource.CODE_COMMENT,deepvariant/realigner/python/ssw_wrap_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/python/ssw_wrap_test.py
Testability,test,tests,"# Copyright 2017 Google LLC.; #; # Redistribution and use in source and binary forms, with or without; # modification, are permitted provided that the following conditions; # are met:; #; # 1. Redistributions of source code must retain the above copyright notice,; # this list of conditions and the following disclaimer.; #; # 2. Redistributions in binary form must reproduce the above copyright; # notice, this list of conditions and the following disclaimer in the; # documentation and/or other materials provided with the distribution.; #; # 3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; # Expected alignment:; # CAGCCTTTCTGACCCGG-AAATCAAAATAGGCACAACAAA; # ||||*|||| |||||; # CTGAGCCGGTAAATC; """"""Basic tests for the wrapped SSW aligner.""""""; """"""Tests the Align method.""""""; """"""Tests the Align method, reversing query and ref from above.""""""",MatchSource.CODE_COMMENT,deepvariant/realigner/python/ssw_wrap_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/python/ssw_wrap_test.py
Integrability,interface,interface,"Manager type. Returns:; False. This means that any exceptions raised within the body of the; caller's with statement will propagate up the stack without interference.; """"""; """"""Resets and starts a timer. Common implementation for Start and __enter__.; """"""; """"""Stops a timer and records the duration. Common implementation for Stop and __exit__.; """"""; """"""Returns the elapsed time, in seconds. Returns:; If timer is still running: the time (in seconds) elapsed since the start; Otherwise: the time (in seconds) for which the timer ran.; """"""; """"""Returns start time of the timer. Returns:; The start time of the timer, floating-point seconds since the epoch.; Raises:; TimerError: if the timer was not started; """"""; """"""Returns stop time of the timer. Returns:; The stop time of the timer, floating-point seconds since the epoch.; Raises:; TimerError: if the timer was never started or is still running; """"""; """"""A timer that automatically starts when you construct it. This is otherwise identical in interface to the Timer class in this module.; """"""; """"""A timer that records cumulative time intervals. Example usage:. from deepvariant.vendor import timer; a_timer = timer.MultiIntervalTimer(). # Do stuff the first time; a_timer.Start(); # ... stuff ...; a_timer.Stop(). # Do stuff the second time (repeat as many times as you like); a_timer.Start(); # ... stuff ...; a_timer.Stop(). if a_timer.GetDuration() > 1000:; print 'Total time spent doing stuff is too much!'. Another way to use this class is the with statement:. t = timer.MultiIntervalTimer(); with t:; # Do stuff the first time. with t:; # Do stuff the second time (repeat as many times as you like). print 'Total time spent doing stuff was %f seconds.' % t.GetDuration(); """"""; """"""Resets the measured cumulative time to zero.""""""; """"""Stops a timer and adds the current duration to the total. Common implementation for Stop and __exit__.; """"""; """"""Returns the total elapsed time, in seconds. Returns:; The total time (in seconds) accumulated so fa",MatchSource.CODE_COMMENT,deepvariant/vendor/timer.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/vendor/timer.py
Modifiability,variab,variable," NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""This module implements classes useful for timing how long an action took.""""""; """"""Timer Error Exception.""""""; """"""Measure time elapsed since some event. Example usage:. from deepvariant.vendor import timer; a_timer = timer.Timer(); a_timer.Start(). # Do stuff here ... a_timer.Stop(); if a_timer.GetDuration() > 100:; print 'This took too long'. Another way to use this class is the with statement:. with timer.Timer() as t:; # Do time consuming stuff ...; print 'Time consuming stuff took %f seconds.' % t.GetDuration(); """"""; """"""Initializes a timer.""""""; """"""Resets and starts a timer.""""""; """"""Stops a timer, and records the duration. Stop is idempotent. Returns:; The duration, i.e., the time (in seconds) for which the timer ran.; """"""; """"""Resets and starts a timer. This allows Timer to be used as a ContextManager type. Returns:; The object itself so that it can be bound to a variable in a with; statement.; """"""; """"""Stops a timer and records the duration. This allows Timer to be used as a ContextManager type. Returns:; False. This means that any exceptions raised within the body of the; caller's with statement will propagate up the stack without interference.; """"""; """"""Resets and starts a timer. Common implementation for Start and __enter__.; """"""; """"""Stops a timer and records the duration. Common implementation for Stop and __exit__.; """"""; """"""Returns the elapsed time, in seconds. Returns:; If timer is still running: the time (in seconds) elapsed since the start; Otherwise: the time (in seconds) for which the timer ran.; """"""; """"""Returns start time of the timer. Returns:; The start time of the timer, floating-point seconds since the epoch.; Raises:; TimerError: if the timer was not started; """"""; """"""Returns stop time of the timer. Returns:; The stop time of the timer, floating-point seconds since the epoch.; Raises:; TimerError: if the timer was ne",MatchSource.CODE_COMMENT,deepvariant/vendor/timer.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/vendor/timer.py
Availability,avail,available,"IGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Runs all 3 steps to go from input DNA reads to output VCF/gVCF files. This script is used to run DeepSomatic, which is an extension of DeepVariant.; If you want to access more flags that are available in `make_examples_somatic`,; `call_variants`, and `postprocess_variants`, you can also call them separately; using the binaries in the Docker image. DeepSomatic is not officially supported or released yet. This script does not; include a released model yet.; """"""; # Required flags.; # Optional flags.; # TODO; # Optional flags for call_variants.; # Optional flags for make_examples_somatic.; # Optional flags for postprocess_variants.; # Optional flags for vcf_stats_report.; # Current release version of DeepVariant.; # Should be the same in dv_vcf_constants.py.; """"""Parses comma-separated list of flag_name=flag_value to dict.""""""; # Check for boolean values.; """"""Adds `extra_args` to the command string.""""""; """"""Updates `kwargs` with `extra_args`; gives a warning if values changed.""""""; """"""Returns a make_examples_somatic (command, logfile) for subprocess. Args:; ref: Input FASTA file.; reads_tumor: Input tumor BAM file.; reads_normal: Input normal BAM file.; examples: Output tfrecord file containing tensorflow.Example files.; extra_args: Com",MatchSource.CODE_COMMENT,scripts/run_deepsomatic.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/scripts/run_deepsomatic.py
Deployability,release,released,"RANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Runs all 3 steps to go from input DNA reads to output VCF/gVCF files. This script is used to run DeepSomatic, which is an extension of DeepVariant.; If you want to access more flags that are available in `make_examples_somatic`,; `call_variants`, and `postprocess_variants`, you can also call them separately; using the binaries in the Docker image. DeepSomatic is not officially supported or released yet. This script does not; include a released model yet.; """"""; # Required flags.; # Optional flags.; # TODO; # Optional flags for call_variants.; # Optional flags for make_examples_somatic.; # Optional flags for postprocess_variants.; # Optional flags for vcf_stats_report.; # Current release version of DeepVariant.; # Should be the same in dv_vcf_constants.py.; """"""Parses comma-separated list of flag_name=flag_value to dict.""""""; # Check for boolean values.; """"""Adds `extra_args` to the command string.""""""; """"""Updates `kwargs` with `extra_args`; gives a warning if values changed.""""""; """"""Returns a make_examples_somatic (command, logfile) for subprocess. Args:; ref: Input FASTA file.; reads_tumor: Input tumor BAM file.; reads_normal: Input normal BAM file.; examples: Output tfrecord file containing tensorflow.Example files.; extra_args: Comma-separated list of flag_name=flag_value.; runtime_by_region_path: Output path for runtime by region metrics.; **kwargs: Addition",MatchSource.CODE_COMMENT,scripts/run_deepsomatic.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/scripts/run_deepsomatic.py
Security,access,access,"IGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Runs all 3 steps to go from input DNA reads to output VCF/gVCF files. This script is used to run DeepSomatic, which is an extension of DeepVariant.; If you want to access more flags that are available in `make_examples_somatic`,; `call_variants`, and `postprocess_variants`, you can also call them separately; using the binaries in the Docker image. DeepSomatic is not officially supported or released yet. This script does not; include a released model yet.; """"""; # Required flags.; # Optional flags.; # TODO; # Optional flags for call_variants.; # Optional flags for make_examples_somatic.; # Optional flags for postprocess_variants.; # Optional flags for vcf_stats_report.; # Current release version of DeepVariant.; # Should be the same in dv_vcf_constants.py.; """"""Parses comma-separated list of flag_name=flag_value to dict.""""""; # Check for boolean values.; """"""Adds `extra_args` to the command string.""""""; """"""Updates `kwargs` with `extra_args`; gives a warning if values changed.""""""; """"""Returns a make_examples_somatic (command, logfile) for subprocess. Args:; ref: Input FASTA file.; reads_tumor: Input tumor BAM file.; reads_normal: Input normal BAM file.; examples: Output tfrecord file containing tensorflow.Example files.; extra_args: Com",MatchSource.CODE_COMMENT,scripts/run_deepsomatic.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/scripts/run_deepsomatic.py
Testability,log,logfile,"o from input DNA reads to output VCF/gVCF files. This script is used to run DeepSomatic, which is an extension of DeepVariant.; If you want to access more flags that are available in `make_examples_somatic`,; `call_variants`, and `postprocess_variants`, you can also call them separately; using the binaries in the Docker image. DeepSomatic is not officially supported or released yet. This script does not; include a released model yet.; """"""; # Required flags.; # Optional flags.; # TODO; # Optional flags for call_variants.; # Optional flags for make_examples_somatic.; # Optional flags for postprocess_variants.; # Optional flags for vcf_stats_report.; # Current release version of DeepVariant.; # Should be the same in dv_vcf_constants.py.; """"""Parses comma-separated list of flag_name=flag_value to dict.""""""; # Check for boolean values.; """"""Adds `extra_args` to the command string.""""""; """"""Updates `kwargs` with `extra_args`; gives a warning if values changed.""""""; """"""Returns a make_examples_somatic (command, logfile) for subprocess. Args:; ref: Input FASTA file.; reads_tumor: Input tumor BAM file.; reads_normal: Input normal BAM file.; examples: Output tfrecord file containing tensorflow.Example files.; extra_args: Comma-separated list of flag_name=flag_value.; runtime_by_region_path: Output path for runtime by region metrics.; **kwargs: Additional arguments to pass in for make_examples_somatic. Returns:; (string, string) A command to run, and a log file to output to.; """"""; # Specific flags that are not default can be added here.; # Extend the command with all items in kwargs and extra_args.; """"""Returns a call_variants (command, logfile) for subprocess.""""""; # Extend the command with all items in extra_args.; """"""Returns a postprocess_variants (command, logfile) for subprocess.""""""; # Extend the command with all items in kwargs and extra_args.; """"""Returns a vcf_stats_report (command, logfile) for subprocess. Args:; vcf_path: Path to VCF, which will be passed to --input_vcf and; s",MatchSource.CODE_COMMENT,scripts/run_deepsomatic.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/scripts/run_deepsomatic.py
Availability,avail,available,"HT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Runs all 3 steps to go from input DNA reads_child to output VCF/gVCF files. This script currently provides the most common use cases and standard models.; If you want to access more flags that are available in `make_examples`,; `call_variants`, and `postprocess_variants`, you can also call them separately; using the binaries in the Docker image.; """"""; # Required flags.; # Optional flags.; # TODO: Change to True as default before release.; # Optional flags for call_variants.; # Optional flags for make_examples.; # Optional flags for postprocess_variants.; # Optional flags for vcf_stats_report.; # Current release version of DeepTrio.; # Should be the same in dv_vcf_constants.py.; """"""make_examples mode for candidate partition.""""""; # Candidate sweep; # Inference with candidate partition; """"""Parses comma-separated list of flag_name=flag_value to dict.""""""; # Check for boolean values.; """"""Adds `extra_args` to the command string.""""""; """"""Updates `kwargs` with `extra_args`; gives a warning if values changed.""""""; """"""Returns a make_examples command for subprocess.check_call. Args:; ref: Input FASTA file.; reads_child: Input BAM file for child.; reads_parent1: Input BAM file for parent1.; reads_parent2: Input BAM file for parent2.; examples: O",MatchSource.CODE_COMMENT,scripts/run_deeptrio.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/scripts/run_deeptrio.py
Deployability,release,release," FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Runs all 3 steps to go from input DNA reads_child to output VCF/gVCF files. This script currently provides the most common use cases and standard models.; If you want to access more flags that are available in `make_examples`,; `call_variants`, and `postprocess_variants`, you can also call them separately; using the binaries in the Docker image.; """"""; # Required flags.; # Optional flags.; # TODO: Change to True as default before release.; # Optional flags for call_variants.; # Optional flags for make_examples.; # Optional flags for postprocess_variants.; # Optional flags for vcf_stats_report.; # Current release version of DeepTrio.; # Should be the same in dv_vcf_constants.py.; """"""make_examples mode for candidate partition.""""""; # Candidate sweep; # Inference with candidate partition; """"""Parses comma-separated list of flag_name=flag_value to dict.""""""; # Check for boolean values.; """"""Adds `extra_args` to the command string.""""""; """"""Updates `kwargs` with `extra_args`; gives a warning if values changed.""""""; """"""Returns a make_examples command for subprocess.check_call. Args:; ref: Input FASTA file.; reads_child: Input BAM file for child.; reads_parent1: Input BAM file for parent1.; reads_parent2: Input BAM file for parent2.; examples: Output tfrecord files suffix.; sample_name_child: Sample name to use for child.; sample_name_parent1: Sample name for parent1.; sample_name_parent2: Sample name for pa",MatchSource.CODE_COMMENT,scripts/run_deeptrio.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/scripts/run_deeptrio.py
Safety,avoid,avoid,"an values.; """"""Adds `extra_args` to the command string.""""""; """"""Updates `kwargs` with `extra_args`; gives a warning if values changed.""""""; """"""Returns a make_examples command for subprocess.check_call. Args:; ref: Input FASTA file.; reads_child: Input BAM file for child.; reads_parent1: Input BAM file for parent1.; reads_parent2: Input BAM file for parent2.; examples: Output tfrecord files suffix.; sample_name_child: Sample name to use for child.; sample_name_parent1: Sample name for parent1.; sample_name_parent2: Sample name for parent2.; runtime_by_region_path: Path for runtime statistics output.; candidate_positions_path: Path to candidate positions file.; extra_args: Comma-separated list of flag_name=flag_value.; candidate_partition_mode: If set adds extra parameters to allow candidate; partition.; **kwargs: Additional arguments to pass in for make_examples. Returns:; (string) A command to run.; """"""; # Should be approximately read; # length to avoid having high; # coverage intervals in multiple shards at a time; # Extend the command with all items in kwargs and extra_args.; """"""Returns a call_variants command for subprocess.check_call.""""""; # Extend the command with all items in extra_args.; """"""Returns a postprocess_variants command for subprocess.check_call.""""""; # Extend the command with all items in extra_args.; """"""Returns a vcf_stats_report command for subprocess. Args:; vcf_path: Path to VCF, which will be passed to --input_vcf and; suffix-trimmed for --outfile_base. Returns:; command string for subprocess; """"""; """"""Returns a runtime_by_region_vis command for subprocess.""""""; """"""Checks or creates the path to the directory for intermediate results.""""""; # If it's a Slim model, we also expect a .meta file.; """"""Additional logic to make sure flags are set appropriately.""""""; """"""Return the path to the model checkpoint based on the input args.""""""; """"""Helper function to generate call_variants command line.""""""; """"""Helper function to generate post_process command line.""""""; """,MatchSource.CODE_COMMENT,scripts/run_deeptrio.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/scripts/run_deeptrio.py
Security,access,access,"HT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Runs all 3 steps to go from input DNA reads_child to output VCF/gVCF files. This script currently provides the most common use cases and standard models.; If you want to access more flags that are available in `make_examples`,; `call_variants`, and `postprocess_variants`, you can also call them separately; using the binaries in the Docker image.; """"""; # Required flags.; # Optional flags.; # TODO: Change to True as default before release.; # Optional flags for call_variants.; # Optional flags for make_examples.; # Optional flags for postprocess_variants.; # Optional flags for vcf_stats_report.; # Current release version of DeepTrio.; # Should be the same in dv_vcf_constants.py.; """"""make_examples mode for candidate partition.""""""; # Candidate sweep; # Inference with candidate partition; """"""Parses comma-separated list of flag_name=flag_value to dict.""""""; # Check for boolean values.; """"""Adds `extra_args` to the command string.""""""; """"""Updates `kwargs` with `extra_args`; gives a warning if values changed.""""""; """"""Returns a make_examples command for subprocess.check_call. Args:; ref: Input FASTA file.; reads_child: Input BAM file for child.; reads_parent1: Input BAM file for parent1.; reads_parent2: Input BAM file for parent2.; examples: O",MatchSource.CODE_COMMENT,scripts/run_deeptrio.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/scripts/run_deeptrio.py
Testability,log,logic,"tra parameters to allow candidate; partition.; **kwargs: Additional arguments to pass in for make_examples. Returns:; (string) A command to run.; """"""; # Should be approximately read; # length to avoid having high; # coverage intervals in multiple shards at a time; # Extend the command with all items in kwargs and extra_args.; """"""Returns a call_variants command for subprocess.check_call.""""""; # Extend the command with all items in extra_args.; """"""Returns a postprocess_variants command for subprocess.check_call.""""""; # Extend the command with all items in extra_args.; """"""Returns a vcf_stats_report command for subprocess. Args:; vcf_path: Path to VCF, which will be passed to --input_vcf and; suffix-trimmed for --outfile_base. Returns:; command string for subprocess; """"""; """"""Returns a runtime_by_region_vis command for subprocess.""""""; """"""Checks or creates the path to the directory for intermediate results.""""""; # If it's a Slim model, we also expect a .meta file.; """"""Additional logic to make sure flags are set appropriately.""""""; """"""Return the path to the model checkpoint based on the input args.""""""; """"""Helper function to generate call_variants command line.""""""; """"""Helper function to generate post_process command line.""""""; """"""Creates commands for all stages to be executed later.""""""; # make_examples; # The path to runtime metrics output is sharded just like the examples.; # If _USE_CANDIDATE_PARTITION is set add a call to make_examples to generate; # candidates.; # If _USE_CANDIDATE_PARTITION is set we generate two make_examples commands.; # The first one to generate candidate_positions. The second command is for; # generating DeepVariant examples. _USE_CANDIDATE_PARTITION is an option that; # helps to better distribute the work between shards.; # In DeepTrio PacBio and ONT mode, we always enable use_candidate_partition; # because otherwise it can run out of memory.; # kwargs:; # Calling variants for child sample; # Calling variants for parent1 sample; # postprocess_variants f",MatchSource.CODE_COMMENT,scripts/run_deeptrio.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/scripts/run_deeptrio.py
Integrability,message,messages,"d to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for deepvariant .run_deeptrio.""""""; # pylint: disable=line-too-long; # Confirm that these basic commands don't have extra messages printed out; # to stdout.; # Because PACBIO model will always have use_candidate_partition on,; # so there will be one extra make_examples command.; # Because PACBIO model will always have use_candidate_partition on,; # so there will be one extra make_examples command.; # pylint: disable=g-complex-comprehension; # pylint: enable=g-complex-comprehension; # Because PACBIO model will always have use_candidate_partition on,; # so there will be one extra make_examples command.; # pylint: disable=g-generic-assert; # Because PACBIO model will always have use_candidate_partition on,; # so there will be one extra make_examples command.; # For pacbio candidate paritionning is turned on by default.; # Currently, there is no way to disable it.; # make_examples command with candidat_sweep mode; # # make_examples command with call mode; # Because PacBio uses candidate_sweep, make_examples got run twice.; """"""Confirms that adding extra flags can overwrite the defau",MatchSource.CODE_COMMENT,scripts/run_deeptrio_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/scripts/run_deeptrio_test.py
Testability,assert,assert,"romote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for deepvariant .run_deeptrio.""""""; # pylint: disable=line-too-long; # Confirm that these basic commands don't have extra messages printed out; # to stdout.; # Because PACBIO model will always have use_candidate_partition on,; # so there will be one extra make_examples command.; # Because PACBIO model will always have use_candidate_partition on,; # so there will be one extra make_examples command.; # pylint: disable=g-complex-comprehension; # pylint: enable=g-complex-comprehension; # Because PACBIO model will always have use_candidate_partition on,; # so there will be one extra make_examples command.; # pylint: disable=g-generic-assert; # Because PACBIO model will always have use_candidate_partition on,; # so there will be one extra make_examples command.; # For pacbio candidate paritionning is turned on by default.; # Currently, there is no way to disable it.; # make_examples command with candidat_sweep mode; # # make_examples command with call mode; # Because PacBio uses candidate_sweep, make_examples got run twice.; """"""Confirms that adding extra flags can overwrite the default from mode.""""""",MatchSource.CODE_COMMENT,scripts/run_deeptrio_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/scripts/run_deeptrio_test.py
Availability,avail,available,"OPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Runs all 3 steps to go from input DNA reads to output VCF/gVCF files. This script currently provides the most common use cases and standard models.; If you want to access more flags that are available in `make_examples`,; `call_variants`, and `postprocess_variants`, you can also call them separately; using the binaries in the Docker image. For more details, see:; https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-quick-start.md; """"""; # Required flags.; # Optional flags.; # TODO: Change to True as default before release.; # Optional flags for call_variants.; # Optional flags for make_examples.; # Optional flag for postprocess variants; # Optional flags for postprocess_variants.; # Optional flags for vcf_stats_report.; # Current release version of DeepVariant.; # Should be the same in dv_vcf_constants.py.; """"""Parses comma-separated list of flag_name=flag_value to dict.""""""; # Check for boolean values.; """"""Adds `extra_args` to the command string.""""""; """"""Updates `kwargs` with `extra_args`; gives a warning if values changed.""""""; """"""Returns a make_examples (command, logfile) for subprocess. Args:; ref: Input FASTA file.; reads: Input BAM file.; examples: Output tfrecord file containing tensorflow.Example files.; ext",MatchSource.CODE_COMMENT,scripts/run_deepvariant.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/scripts/run_deepvariant.py
Deployability,release,release,"BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Runs all 3 steps to go from input DNA reads to output VCF/gVCF files. This script currently provides the most common use cases and standard models.; If you want to access more flags that are available in `make_examples`,; `call_variants`, and `postprocess_variants`, you can also call them separately; using the binaries in the Docker image. For more details, see:; https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-quick-start.md; """"""; # Required flags.; # Optional flags.; # TODO: Change to True as default before release.; # Optional flags for call_variants.; # Optional flags for make_examples.; # Optional flag for postprocess variants; # Optional flags for postprocess_variants.; # Optional flags for vcf_stats_report.; # Current release version of DeepVariant.; # Should be the same in dv_vcf_constants.py.; """"""Parses comma-separated list of flag_name=flag_value to dict.""""""; # Check for boolean values.; """"""Adds `extra_args` to the command string.""""""; """"""Updates `kwargs` with `extra_args`; gives a warning if values changed.""""""; """"""Returns a make_examples (command, logfile) for subprocess. Args:; ref: Input FASTA file.; reads: Input BAM file.; examples: Output tfrecord file containing tensorflow.Example files.; extra_args: Comma-separated list of flag_name=flag_value.; runtime_by_region_path: Output path for runtime by region metrics.; **kwargs: Additional arguments to pass in for make_examples. Returns:; (string, string) A command to run, and a log file to output to.; """"""; # Exten",MatchSource.CODE_COMMENT,scripts/run_deepvariant.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/scripts/run_deepvariant.py
Security,access,access,"OPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Runs all 3 steps to go from input DNA reads to output VCF/gVCF files. This script currently provides the most common use cases and standard models.; If you want to access more flags that are available in `make_examples`,; `call_variants`, and `postprocess_variants`, you can also call them separately; using the binaries in the Docker image. For more details, see:; https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-quick-start.md; """"""; # Required flags.; # Optional flags.; # TODO: Change to True as default before release.; # Optional flags for call_variants.; # Optional flags for make_examples.; # Optional flag for postprocess variants; # Optional flags for postprocess_variants.; # Optional flags for vcf_stats_report.; # Current release version of DeepVariant.; # Should be the same in dv_vcf_constants.py.; """"""Parses comma-separated list of flag_name=flag_value to dict.""""""; # Check for boolean values.; """"""Adds `extra_args` to the command string.""""""; """"""Updates `kwargs` with `extra_args`; gives a warning if values changed.""""""; """"""Returns a make_examples (command, logfile) for subprocess. Args:; ref: Input FASTA file.; reads: Input BAM file.; examples: Output tfrecord file containing tensorflow.Example files.; ext",MatchSource.CODE_COMMENT,scripts/run_deepvariant.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/scripts/run_deepvariant.py
Testability,log,logfile,"urrently provides the most common use cases and standard models.; If you want to access more flags that are available in `make_examples`,; `call_variants`, and `postprocess_variants`, you can also call them separately; using the binaries in the Docker image. For more details, see:; https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-quick-start.md; """"""; # Required flags.; # Optional flags.; # TODO: Change to True as default before release.; # Optional flags for call_variants.; # Optional flags for make_examples.; # Optional flag for postprocess variants; # Optional flags for postprocess_variants.; # Optional flags for vcf_stats_report.; # Current release version of DeepVariant.; # Should be the same in dv_vcf_constants.py.; """"""Parses comma-separated list of flag_name=flag_value to dict.""""""; # Check for boolean values.; """"""Adds `extra_args` to the command string.""""""; """"""Updates `kwargs` with `extra_args`; gives a warning if values changed.""""""; """"""Returns a make_examples (command, logfile) for subprocess. Args:; ref: Input FASTA file.; reads: Input BAM file.; examples: Output tfrecord file containing tensorflow.Example files.; extra_args: Comma-separated list of flag_name=flag_value.; runtime_by_region_path: Output path for runtime by region metrics.; **kwargs: Additional arguments to pass in for make_examples. Returns:; (string, string) A command to run, and a log file to output to.; """"""; # Extend the command with all items in kwargs and extra_args.; """"""Returns a call_variants (command, logfile) for subprocess.""""""; # Extend the command with all items in extra_args.; """"""Returns a postprocess_variants (command, logfile) for subprocess.""""""; # Extend the command with all items in kwargs and extra_args.; """"""Returns a vcf_stats_report (command, logfile) for subprocess. Args:; vcf_path: Path to VCF, which will be passed to --input_vcf and; suffix-trimmed for --outfile_base.; title: Passed straight to command unless it's None. Returns:; [command string for sub",MatchSource.CODE_COMMENT,scripts/run_deepvariant.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/scripts/run_deepvariant.py
Integrability,wrap,wrapper,"# Copyright 2018 Google LLC.; #; # Redistribution and use in source and binary forms, with or without; # modification, are permitted provided that the following conditions; # are met:; #; # 1. Redistributions of source code must retain the above copyright notice,; # this list of conditions and the following disclaimer.; #; # 2. Redistributions in binary form must reproduce the above copyright; # notice, this list of conditions and the following disclaimer in the; # documentation and/or other materials provided with the distribution.; #; # 3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; # TODO: OpError exception not propagated.; # See CLIF wrapper for a discussion of why this is commented out.; # def test_make_str_ok_stripped_type(self):; # self.assertEqual(statusor_examples.MakeStrOKStrippedType(), 'hello'); # TODO: OpError exception not propagated.; # TODO: OpError exception not propagated.; # TODO: OpError exception not propagated.; # TODO: OpError exception not propagated.",MatchSource.CODE_COMMENT,third_party/nucleus/core/statusor_examples_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/core/statusor_examples_test.py
Testability,assert,assertEqual,"# Copyright 2018 Google LLC.; #; # Redistribution and use in source and binary forms, with or without; # modification, are permitted provided that the following conditions; # are met:; #; # 1. Redistributions of source code must retain the above copyright notice,; # this list of conditions and the following disclaimer.; #; # 2. Redistributions in binary form must reproduce the above copyright; # notice, this list of conditions and the following disclaimer in the; # documentation and/or other materials provided with the distribution.; #; # 3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; # TODO: OpError exception not propagated.; # See CLIF wrapper for a discussion of why this is commented out.; # def test_make_str_ok_stripped_type(self):; # self.assertEqual(statusor_examples.MakeStrOKStrippedType(), 'hello'); # TODO: OpError exception not propagated.; # TODO: OpError exception not propagated.; # TODO: OpError exception not propagated.; # TODO: OpError exception not propagated.",MatchSource.CODE_COMMENT,third_party/nucleus/core/statusor_examples_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/core/statusor_examples_test.py
Integrability,wrap,wrapper,"# Copyright 2018 Google LLC.; #; # Redistribution and use in source and binary forms, with or without; # modification, are permitted provided that the following conditions; # are met:; #; # 1. Redistributions of source code must retain the above copyright notice,; # this list of conditions and the following disclaimer.; #; # 2. Redistributions in binary form must reproduce the above copyright; # notice, this list of conditions and the following disclaimer in the; # documentation and/or other materials provided with the distribution.; #; # 3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; # TODO: OpError exception not propagated.; # See CLIF wrapper for a discussion of why this is commented out.; # def test_make_str_ok_stripped_type(self):; # self.assertEqual(statusor_examples.MakeStrOKStrippedType(), 'hello'); # TODO: OpError exception not propagated.; # TODO: OpError exception not propagated.; # TODO: OpError exception not propagated.; # TODO: OpError exception not propagated.",MatchSource.CODE_COMMENT,third_party/nucleus/core/python/statusor_examples_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/core/python/statusor_examples_test.py
Testability,assert,assertEqual,"# Copyright 2018 Google LLC.; #; # Redistribution and use in source and binary forms, with or without; # modification, are permitted provided that the following conditions; # are met:; #; # 1. Redistributions of source code must retain the above copyright notice,; # this list of conditions and the following disclaimer.; #; # 2. Redistributions in binary form must reproduce the above copyright; # notice, this list of conditions and the following disclaimer in the; # documentation and/or other materials provided with the distribution.; #; # 3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; # TODO: OpError exception not propagated.; # See CLIF wrapper for a discussion of why this is commented out.; # def test_make_str_ok_stripped_type(self):; # self.assertEqual(statusor_examples.MakeStrOKStrippedType(), 'hello'); # TODO: OpError exception not propagated.; # TODO: OpError exception not propagated.; # TODO: OpError exception not propagated.; # TODO: OpError exception not propagated.",MatchSource.CODE_COMMENT,third_party/nucleus/core/python/statusor_examples_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/core/python/statusor_examples_test.py
Integrability,protocol,protocol,"PLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Classes for reading and writing BED files. The BED format is described at; https://genome.ucsc.edu/FAQ/FAQformat.html#format1. API for reading:. ```python; from third_party.nucleus.io import bed. # Iterate through all records.; with bed.BedReader(input_path) as reader:; for record in reader:; print(record); ```. where `record` is a `nucleus.genomics.v1.BedRecord` protocol buffer. API for writing:. ```python; from third_party.nucleus.io import bed; from third_party.nucleus.protos import bed_pb2. # records is an iterable of nucleus.genomics.v1.BedRecord protocol buffers.; records = ... # header defines how many fields to write out.; header = bed_pb2.BedHeader(num_fields=5). # Write all records to the desired output path.; with bed.BedWriter(output_path, header) as writer:; for record in records:; writer.write(record); ```. For both reading and writing, if the path provided to the constructor contains; '.tfrecord' as an extension, a `TFRecord` file is assumed and attempted to be; read or written. Otherwise, the filename is treated as a true BED file. Files that end in a '.gz' suffix cause the file to be treated as compressed; (with BGZF if it is a true BED file, and with gzip if it is a TFRecord file).; """"""; """"""Class for reading from native BED files. Most users will want to use BedReader instead, because it dynamically; dispatches between reading na",MatchSource.CODE_COMMENT,third_party/nucleus/io/bed.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/bed.py
Integrability,protocol,protocol,"NTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Classes for reading and writing BedGraph files. The BedGraph format is described at; https://genome.ucsc.edu/goldenpath/help/bedgraph.html. API for reading:. ```python; from third_party.nucleus.io import bedgraph. # Iterate through all records.; with bed.BedGraphReader(input_path) as reader:; for record in reader:; print(record); ```. where `record` is a `nucleus.genomics.v1.BedGraphRecord` protocol buffer. API for writing:. ```python; from third_party.nucleus.io import bedgraph; from third_party.nucleus.protos import bedgraph_pb2. # records is an iterable of nucleus.genomics.v1.BedGraphRecord protocol buffers.; records = ... # Write all records to the desired output path.; with bed.BedGraphWriter(output_path) as writer:; for record in records:; writer.write(record); ```. For both reading and writing, if the path provided to the constructor contains; '.tfrecord' as an extension, a `TFRecord` file is assumed and attempted to be; read or written. Otherwise, the filename is treated as a true BedGraph file. Files that end in a '.gz' suffix cause the file to be treated as compressed; (with BGZF if it is a BedGraph file, and with gzip if it is a TFRecord file).; """"""; """"""Class for reading from native BedGraph files. Most users will want to use BedGraphReader instead, because it dynamically; dispatches between reading native BedGraph files and TFRecord files based on; the filenam",MatchSource.CODE_COMMENT,third_party/nucleus/io/bedgraph.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/bedgraph.py
Availability,error,error,"G IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""A universal converter program for nucleus-supported genomics file formats. Invoked with a single argument, this program will open a genomics data file and; iterate over its contents, doing no writing. This is a good benchmark for I/O; and reader processing speed. Invoked with two arguments, the program will open the first file, read its; records, and write them, one at a time, to the second file. The filetypes for; the first and second filename must be compatible ways of encoding the same; nucleus genomics record type (for example, `infile.gff` and; `outfile.gff.tfrecord.gz` are compatible, but `infile.gff` and `outfile.bam` are; not. Note: at present we have no convention for encoding a file *header* in; tfrecords, so conversion is not possible from tfrecord to any native file format; for which a header is compulsory.; """"""; """"""Returns true if filename is a native (non-tfrecord) genomics data file.""""""; """"""Returns an re matching native or tfrecord files of format `ext`.""""""; """"""An exception used to signal file conversion error.""""""; """"""A writer class whose .write() method is a no-op. This allows us to create and use a writer object where one is required by; context but we do not wish to write to any file.; """"""; """"""Returns reader, writer classes for filenames, if conversion is possible. Args:; in_filename: filename of a genomics data file to use as input.; out_filename: filename of a genomics data file to use as output, or None,; if no output should be written. Raises:; ConversionError: if in_filename is not convertible to out_filename.; """"""; """"""Converts a recognized genomics file `in_filename` to `out_filename`. Args:; in_filename: str; filename of a genomics data file to use as input.; out_filename: str; filename of a genomics data file to use as output, or; None, if no output should be written. Raises:; ConversionError, if the conversion could not be executed.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/io/converter.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/converter.py
Testability,benchmark,benchmark,"IDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""A universal converter program for nucleus-supported genomics file formats. Invoked with a single argument, this program will open a genomics data file and; iterate over its contents, doing no writing. This is a good benchmark for I/O; and reader processing speed. Invoked with two arguments, the program will open the first file, read its; records, and write them, one at a time, to the second file. The filetypes for; the first and second filename must be compatible ways of encoding the same; nucleus genomics record type (for example, `infile.gff` and; `outfile.gff.tfrecord.gz` are compatible, but `infile.gff` and `outfile.bam` are; not. Note: at present we have no convention for encoding a file *header* in; tfrecords, so conversion is not possible from tfrecord to any native file format; for which a header is compulsory.; """"""; """"""Returns true if filename is a native (non-tfrecord) genomics data file.""""""; """"""Returns an re matching native or tfrecord files of format `ext`.""""""; """"""An exception used to signal file conversion error.""""""; """"""A writer class whose .write() method is a no-op. This allows us to create and use a writer object where one is required by; context but we do not wish to write to any file.; """"""; """"""R",MatchSource.CODE_COMMENT,third_party/nucleus/io/converter.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/converter.py
Availability,error,error," # notice, this list of conditions and the following disclaimer in the; # documentation and/or other materials provided with the distribution.; #; # 3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for third_party.nucleus.examples.convert_genomics_file. These tests do NOT establish the correctness of conversions---tests of the; fidelity of the Reader and Writer classes exist elsewhere in Nucleus. Rather,; these tests simply exercise that the conversion *runs* for each input/output; file type.; """"""; # Initial (native) input files we will use to begin conversions.; # These formats require a header, so conversion from tfrecord to a native file; # format cannot be done faithfully.; """"""Test conversion from a native file format to tfrecord.gz, then back.""""""; # Test conversion from native format to tfrecord.; # TODO: remove this when SAM writer is implemented.; # Test conversion from tfrecord format back to native format. Ensure that; # conversions where we would need a header, but don't have one from the; # input, trigger an error message.",MatchSource.CODE_COMMENT,third_party/nucleus/io/converter_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/converter_test.py
Integrability,message,message," # notice, this list of conditions and the following disclaimer in the; # documentation and/or other materials provided with the distribution.; #; # 3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for third_party.nucleus.examples.convert_genomics_file. These tests do NOT establish the correctness of conversions---tests of the; fidelity of the Reader and Writer classes exist elsewhere in Nucleus. Rather,; these tests simply exercise that the conversion *runs* for each input/output; file type.; """"""; # Initial (native) input files we will use to begin conversions.; # These formats require a header, so conversion from tfrecord to a native file; # format cannot be done faithfully.; """"""Test conversion from a native file format to tfrecord.gz, then back.""""""; # Test conversion from native format to tfrecord.; # TODO: remove this when SAM writer is implemented.; # Test conversion from tfrecord format back to native format. Ensure that; # conversions where we would need a header, but don't have one from the; # input, trigger an error message.",MatchSource.CODE_COMMENT,third_party/nucleus/io/converter_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/converter_test.py
Testability,test,tests," # notice, this list of conditions and the following disclaimer in the; # documentation and/or other materials provided with the distribution.; #; # 3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for third_party.nucleus.examples.convert_genomics_file. These tests do NOT establish the correctness of conversions---tests of the; fidelity of the Reader and Writer classes exist elsewhere in Nucleus. Rather,; these tests simply exercise that the conversion *runs* for each input/output; file type.; """"""; # Initial (native) input files we will use to begin conversions.; # These formats require a header, so conversion from tfrecord to a native file; # format cannot be done faithfully.; """"""Test conversion from a native file format to tfrecord.gz, then back.""""""; # Test conversion from native format to tfrecord.; # TODO: remove this when SAM writer is implemented.; # Test conversion from tfrecord format back to native format. Ensure that; # conversions where we would need a header, but don't have one from the; # input, trigger an error message.",MatchSource.CODE_COMMENT,third_party/nucleus/io/converter_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/converter_test.py
Usability,simpl,simply," # notice, this list of conditions and the following disclaimer in the; # documentation and/or other materials provided with the distribution.; #; # 3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for third_party.nucleus.examples.convert_genomics_file. These tests do NOT establish the correctness of conversions---tests of the; fidelity of the Reader and Writer classes exist elsewhere in Nucleus. Rather,; these tests simply exercise that the conversion *runs* for each input/output; file type.; """"""; # Initial (native) input files we will use to begin conversions.; # These formats require a header, so conversion from tfrecord to a native file; # format cannot be done faithfully.; """"""Test conversion from a native file format to tfrecord.gz, then back.""""""; # Test conversion from native format to tfrecord.; # TODO: remove this when SAM writer is implemented.; # Test conversion from tfrecord format back to native format. Ensure that; # conversions where we would need a header, but don't have one from the; # input, trigger an error message.",MatchSource.CODE_COMMENT,third_party/nucleus/io/converter_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/converter_test.py
Integrability,protocol,protocol,"INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Classes for reading FASTA files. The FASTA format is described at; https://en.wikipedia.org/wiki/FASTA_format. API for reading:. ```python; from third_party.nucleus.io import fasta; from third_party.nucleus.protos import range_pb2. with fasta.IndexedFastaReader(input_path) as reader:; region = range_pb2.Range(reference_name='chrM', start=1, end=6); basepair_string = reader.query(region); print(basepair_string); ```. If `input_path` ends with '.gz', it is assumed to be compressed. All FASTA; files are assumed to be indexed with the index file located at; `input_path + '.fai'`.; """"""; # TODO: Replace this with a real protocol buffer definition.; """"""Class for reading (name, bases) tuples from FASTA files.""""""; """"""Class for reading from FASTA files containing a reference genome.""""""; """"""Initializes an IndexedFastaReader. Args:; input_path: string. A path to a resource containing FASTA records.; keep_true_case: bool. If False, casts all bases to uppercase before; returning them.; cache_size: integer. Number of bases to cache from previous queries.; Defaults to 64K. The cache can be disabled using cache_size=0.; """"""; # Use the C++-defined default cache size.; # TODO: Define a RefFastaHeader proto, and use it instead of this.; """"""Returns an iterable of (name, bases) tuples contained in this file.""""""; """"""Returns the base pairs (as a string) in the given region.""""""; """"""Returns whether the region is contained in this FASTA file.""""""; """"""Returns a ContigInfo proto for contig_name.""""""; """"""Returns the underlying C++ reader.""""""; """"""Class for reading from unindexed FASTA files.""""""; """"""Initializes an Unindexe",MatchSource.CODE_COMMENT,third_party/nucleus/io/fasta.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/fasta.py
Performance,cache,cache,". The FASTA format is described at; https://en.wikipedia.org/wiki/FASTA_format. API for reading:. ```python; from third_party.nucleus.io import fasta; from third_party.nucleus.protos import range_pb2. with fasta.IndexedFastaReader(input_path) as reader:; region = range_pb2.Range(reference_name='chrM', start=1, end=6); basepair_string = reader.query(region); print(basepair_string); ```. If `input_path` ends with '.gz', it is assumed to be compressed. All FASTA; files are assumed to be indexed with the index file located at; `input_path + '.fai'`.; """"""; # TODO: Replace this with a real protocol buffer definition.; """"""Class for reading (name, bases) tuples from FASTA files.""""""; """"""Class for reading from FASTA files containing a reference genome.""""""; """"""Initializes an IndexedFastaReader. Args:; input_path: string. A path to a resource containing FASTA records.; keep_true_case: bool. If False, casts all bases to uppercase before; returning them.; cache_size: integer. Number of bases to cache from previous queries.; Defaults to 64K. The cache can be disabled using cache_size=0.; """"""; # Use the C++-defined default cache size.; # TODO: Define a RefFastaHeader proto, and use it instead of this.; """"""Returns an iterable of (name, bases) tuples contained in this file.""""""; """"""Returns the base pairs (as a string) in the given region.""""""; """"""Returns whether the region is contained in this FASTA file.""""""; """"""Returns a ContigInfo proto for contig_name.""""""; """"""Returns the underlying C++ reader.""""""; """"""Class for reading from unindexed FASTA files.""""""; """"""Initializes an UnindexedFastaReader. Args:; input_path: string. A path to a resource containing FASTA records.; """"""; """"""Returns an iterable of (name, bases) tuples contained in this file.""""""; """"""Returns the base pairs (as a string) in the given region.""""""; """"""Returns whether the region is contained in this FASTA file.""""""; """"""Returns a ContigInfo proto for contig_name.""""""; """"""Returns the underlying C++ reader.""""""; """"""An `IndexedFastaRe",MatchSource.CODE_COMMENT,third_party/nucleus/io/fasta.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/fasta.py
Safety,detect,detects,"ts; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for third_party.nucleus.io.fasta.""""""; # The reader is an instance of IndexedFastaReader which supports query().; # The reader is an instance of UnindexedFastaReader which doesn't support; # query().; # Check the indexed fasta file's iterable matches that of the unindexed; # fasta file.; # Check that our query operation works as expected with a start position.; # Start is 10, so this raises because it's before the bases starts.; # Spans into the start of the bases; make sure it detects it's bad.; # Spans off the end of the bases.; # Check that we can query the first base correctly.; # Check that we can query the last base correctly.; # Check that we can query the entire sequence correctly.; # Our contigs can have a different order, descriptions are dropped, etc so; # we need to check specific fields by hand.; # Check the in-memory fasta file's iterable matches the info in the header.; # Check the in-memory fasta file's iterable matches that of the indexed; # fasta file.; # bad start.; # end < start.; # off end of chromosome.; # unknown chromosome.",MatchSource.CODE_COMMENT,third_party/nucleus/io/fasta_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/fasta_test.py
Integrability,protocol,protocol,"BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Classes for reading and writing FASTQ files. The FASTQ format is described at; https://en.wikipedia.org/wiki/FASTQ_format. API for reading:. ```python; from third_party.nucleus.io import fastq. with fastq.FastqReader(input_path) as reader:; for record in reader:; print(record); ```. where `record` is a `nucleus.genomics.v1.FastqRecord` protocol buffer. API for writing:. ```python; from third_party.nucleus.io import fastq. # records is an iterable of nucleus.genomics.v1.FastqRecord protocol buffers.; records = ... with fastq.FastqWriter(output_path) as writer:; for record in records:; writer.write(record); ```. For both reading and writing, if the path provided to the constructor contains; '.tfrecord' as an extension, a `TFRecord` file is assumed and attempted to be; read or written. Otherwise, the filename is treated as a true FASTQ file. Files that end in a '.gz' suffix cause the file to be treated as compressed; (with BGZF if it is a true FASTQ file, and with gzip if it is a TFRecord file).; """"""; """"""Class for reading from native FASTQ files. Most users will want to use FastqReader instead, because it dynamically; dispatches between reading native FASTQ files and TFRecord files based on the; filename's extension.; """"""; """"""Initializes a NativeFastqReader. Args:; input_path: str. A path to a resource containing FASTQ re",MatchSource.CODE_COMMENT,third_party/nucleus/io/fastq.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/fastq.py
Availability,error,error,"# Copyright 2018 Google LLC.; #; # Redistribution and use in source and binary forms, with or without; # modification, are permitted provided that the following conditions; # are met:; #; # 1. Redistributions of source code must retain the above copyright notice,; # this list of conditions and the following disclaimer.; #; # 2. Redistributions in binary form must reproduce the above copyright; # notice, this list of conditions and the following disclaimer in the; # documentation and/or other materials provided with the distribution.; #; # 3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for genomics_io's plugin system.""""""; """"""Test that we get the right error when the plugin cannot load.""""""",MatchSource.CODE_COMMENT,third_party/nucleus/io/genomics_io_noplugin_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/genomics_io_noplugin_test.py
Modifiability,plugin,plugin,"# Copyright 2018 Google LLC.; #; # Redistribution and use in source and binary forms, with or without; # modification, are permitted provided that the following conditions; # are met:; #; # 1. Redistributions of source code must retain the above copyright notice,; # this list of conditions and the following disclaimer.; #; # 2. Redistributions in binary form must reproduce the above copyright; # notice, this list of conditions and the following disclaimer in the; # documentation and/or other materials provided with the distribution.; #; # 3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for genomics_io's plugin system.""""""; """"""Test that we get the right error when the plugin cannot load.""""""",MatchSource.CODE_COMMENT,third_party/nucleus/io/genomics_io_noplugin_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/genomics_io_noplugin_test.py
Performance,load,load,"# Copyright 2018 Google LLC.; #; # Redistribution and use in source and binary forms, with or without; # modification, are permitted provided that the following conditions; # are met:; #; # 1. Redistributions of source code must retain the above copyright notice,; # this list of conditions and the following disclaimer.; #; # 2. Redistributions in binary form must reproduce the above copyright; # notice, this list of conditions and the following disclaimer in the; # documentation and/or other materials provided with the distribution.; #; # 3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for genomics_io's plugin system.""""""; """"""Test that we get the right error when the plugin cannot load.""""""",MatchSource.CODE_COMMENT,third_party/nucleus/io/genomics_io_noplugin_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/genomics_io_noplugin_test.py
Integrability,interface,interface,"f the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Classes that provide the interface for reading genomics data. `GenomicsReader` defines the core API supported by readers, and is subclassed; directly or indirectly (via `DispatchingGenomicsReader`) for all concrete; implementations. `TFRecordReader` is an implementation of the `GenomicsReader` API for reading; `TFRecord` files. This is usable for all data types when encoding data in; protocol buffers. `DispatchingGenomicsReader` is an abstract class defined for convenience on top; of `GenomicsReader` that supports reading from either the native file format or; from `TFRecord` files of the corresponding protocol buffer used to encode data; of that file type. The input format assumed is dependent upon the filename of; the input data. Concrete implementations for individual file types (e.g. BED, SAM, VCF, etc.); reside in type-specific modules in this package. The instantiation of readers; may have reader-specific requirements documented there. General examples of the; `iterate()` and `query()` functionality are sho",MatchSource.CODE_COMMENT,third_party/nucleus/io/genomics_reader.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/genomics_reader.py
Modifiability,variab,variable,"s of the; `iterate()` and `query()` functionality are shown below. ```python; # Equivalent ways to iterate through all elements in a reader.; # 1. Using the reader itself as an iterable object.; kwargs = ... # Reader-specific keyword arguments.; with GenomicsReaderSubClass(output_path, **kwargs) as reader:; for proto in reader:; do_something(reader.header, proto). # 2. Calling the iterate() method of the reader explicitly.; with GenomicsReaderSubClass(output_path, **kwargs) as reader:; for proto in reader.iterate():; do_something(reader.header, proto). # Querying for all elements within a specific region of the genome.; from third_party.nucleus.protos import range_pb2; region = range_pb2.Range(reference_name='chr1', start=10, end=20). with GenomicsReaderSubClass(output_path, **kwargs) as reader:; for proto in reader.query(region):; do_something(reader.header, proto); ```; """"""; """"""Abstract base class for reading genomics data. In addition to the abstractmethods defined below, subclasses should; also set a `header` member variable in their objects.; """"""; """"""Returns an iterator for going through all the file's records.""""""; """"""Returns an iterator for going through the records in the region. Args:; region: A nucleus.genomics.v1.Range. Returns:; An iterator containing all and only records within the specified region.; """"""; """"""Enter a `with` block.""""""; """"""Exit a `with` block. Typically, this will close the file.""""""; """"""Initializer.""""""; # Some readers can only support one iterator at a time, so don't; # create one now. Rather, create it when needed in next().; """"""Allows users to use the object itself as an iterator.""""""; """"""Allows users to use the object itself as an iterator.""""""; """"""A GenomicsReader that reads protocol buffers from a TFRecord file. Example usage:; reader = TFRecordReader('/tmp/my_file.tfrecords.gz',; proto=tensorflow.Example); for example in reader:; process(example). Note that TFRecord files do not have headers, and do not need; to be wrapped in a ""with"" bl",MatchSource.CODE_COMMENT,third_party/nucleus/io/genomics_reader.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/genomics_reader.py
Security,access,access,"ne now. Rather, create it when needed in next().; """"""Allows users to use the object itself as an iterator.""""""; """"""Allows users to use the object itself as an iterator.""""""; """"""A GenomicsReader that reads protocol buffers from a TFRecord file. Example usage:; reader = TFRecordReader('/tmp/my_file.tfrecords.gz',; proto=tensorflow.Example); for example in reader:; process(example). Note that TFRecord files do not have headers, and do not need; to be wrapped in a ""with"" block.; """"""; """"""Initializes the TFRecordReader. Args:; input_path: The filename of the file to read.; proto: The protocol buffer type the TFRecord file is expected to; contain. For example, variants_pb2.Variant or reads_pb2.Read.; compression_type: Either 'ZLIB', 'GZIP', '' (uncompressed), or; None. If None, __init__ will guess the compression type based on; the input_path's suffix. Raises:; IOError: if there was any problem opening input_path for reading.; """"""; """"""Returns an iterator for going through all the file's records.""""""; """"""Returns an iterator for going through the records in the region. NOTE: This function is not currently implemented by TFRecordReader as the; TFRecord format does not provide a general mechanism for fast random access; to elements in genome order.; """"""; """"""Returns the underlying C++ reader.""""""; """"""A GenomicsReader that dispatches based on the file extension. If '.tfrecord' is present in the filename, a TFRecordReader is used.; Otherwise, a native reader is. Subclasses of DispatchingGenomicsReader must define the following methods:; * _native_reader(); * _record_proto(); """"""; # Remove compression_type, if present, from the arguments we pass to the; # native reader.; """"""Returns a GenomicsReader for reading the records `natively`. Args:; input_path: The path to the native file to read.; **kwargs: Zero or more keyword arguments. Returns:; A GenomicsReader.; """"""; """"""Returns the protocol buffer type used by this reader.""""""; """"""Hook for subclasses to run code at the end of __init__.""""""",MatchSource.CODE_COMMENT,third_party/nucleus/io/genomics_reader.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/genomics_reader.py
Usability,usab,usable,"IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Classes that provide the interface for reading genomics data. `GenomicsReader` defines the core API supported by readers, and is subclassed; directly or indirectly (via `DispatchingGenomicsReader`) for all concrete; implementations. `TFRecordReader` is an implementation of the `GenomicsReader` API for reading; `TFRecord` files. This is usable for all data types when encoding data in; protocol buffers. `DispatchingGenomicsReader` is an abstract class defined for convenience on top; of `GenomicsReader` that supports reading from either the native file format or; from `TFRecord` files of the corresponding protocol buffer used to encode data; of that file type. The input format assumed is dependent upon the filename of; the input data. Concrete implementations for individual file types (e.g. BED, SAM, VCF, etc.); reside in type-specific modules in this package. The instantiation of readers; may have reader-specific requirements documented there. General examples of the; `iterate()` and `query()` functionality are shown below. ```python; # Equivalent ways to iterate through all elements in a reader.; # 1. Using the reader itself as an iterable object.; kwargs = ... # Reader-specific keyword arguments.; with GenomicsReaderSubClass(output_path, **kwargs) as reader:; for proto in reader:; do_something(reader.header, proto). # 2. Calling the iterate() me",MatchSource.CODE_COMMENT,third_party/nucleus/io/genomics_reader.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/genomics_reader.py
Integrability,interface,interface,"f the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Classes that provide the interface for writing genomics data. `GenomicsWriter` defines the core API supported by writers, and is subclassed; directly or indirectly (via `DispatchingGenomicsWriter`) for all concrete; implementations. `TFRecordWriter` is an implementation of the `GenomicsWriter` API for reading; `TFRecord` files. This is usable for all data types when writing data as; serialized protocol buffers. `DispatchingGenomicsWriter` is an abstract class defined for convenience on top; of `GenomicsWriter` that supports writing to either the native file format or to; `TFRecord` files of the corresponding protocol buffer used to encode data of; that file type. The output format chosen is dependent upon the filename to which; the data are being written. Concrete implementations for individual file types (e.g. BED, SAM, VCF, etc.); reside in type-specific modules in this package. A general example of the write; functionality is shown below. ```python; # options is a writer-specific set of options.; options = ...",MatchSource.CODE_COMMENT,third_party/nucleus/io/genomics_writer.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/genomics_writer.py
Testability,log,logical,"ata type.; records = ... with GenomicsWriterSubClass(output_path, options) as writer:; for proto in records:; writer.write(proto); ```; """"""; """"""Abstract base class for writing genomics data. A GenomicsWriter only has one method, write, which writes a single; protocol buffer to a file.; """"""; """"""Writes proto to the file. Args:; proto: A protocol buffer.; """"""; """"""Writes proto to the file with somatic processing. Args:; proto: A protocol buffer.; """"""; """"""Enter a `with` block.""""""; """"""Exit a `with` block. Typically, this will close the file.""""""; """"""A GenomicsWriter that writes to a TFRecord file. Example usage:; writer = TFRecordWriter('/tmp/my_output.tfrecord.gz'); for record in records:; writer.write(record). Note that TFRecord files do not need to be wrapped in a ""with"" block.; """"""; """"""Initializer. Args:; output_path: str. The output path to which the records are written.; header: An optional header for the particular data type. This can be; useful for file types that have logical headers where some operations; depend on that header information (e.g. VCF using its headers to; determine type information of annotation fields).; compression_type: Either 'ZLIB', 'GZIP', '' (uncompressed), or; None. If None, __init__ will guess the compression type based on; the input_path's suffix. Raises:; IOError: if there was any problem opening output_path for writing.; """"""; """"""Writes the proto to the TFRecord file.""""""; """"""Explicitly closes writer.""""""; """"""A GenomicsWriter that dispatches based on the file extension. If '.tfrecord' is present in the filename, a TFRecordWriter is used.; Otherwise, a native writer is. Sub-classes of DispatchingGenomicsWriter must define a _native_writer(); method.; """"""; """"""Initializer. Args:; output_path: str. The output path to which the records are written.; **kwargs: k=v named args. Keyword arguments used to instantiate the native; writer, if applicable.; """"""; """"""Returns a GenomicsWriter for writing the records `natively`. Args:; output_path: The path ",MatchSource.CODE_COMMENT,third_party/nucleus/io/genomics_writer.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/genomics_writer.py
Usability,usab,usable,"ED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Classes that provide the interface for writing genomics data. `GenomicsWriter` defines the core API supported by writers, and is subclassed; directly or indirectly (via `DispatchingGenomicsWriter`) for all concrete; implementations. `TFRecordWriter` is an implementation of the `GenomicsWriter` API for reading; `TFRecord` files. This is usable for all data types when writing data as; serialized protocol buffers. `DispatchingGenomicsWriter` is an abstract class defined for convenience on top; of `GenomicsWriter` that supports writing to either the native file format or to; `TFRecord` files of the corresponding protocol buffer used to encode data of; that file type. The output format chosen is dependent upon the filename to which; the data are being written. Concrete implementations for individual file types (e.g. BED, SAM, VCF, etc.); reside in type-specific modules in this package. A general example of the write; functionality is shown below. ```python; # options is a writer-specific set of options.; options = ... # records is an iterable of protocol buffers of the specific data type.; records = ... with GenomicsWriterSubClass(output_path, options) as writer:; for proto in records:; writer.write(proto); ```; """"""; """"""Abstract base class for writing genomics data. A GenomicsWriter only has one method, write, which writes a single; protocol buffer to a f",MatchSource.CODE_COMMENT,third_party/nucleus/io/genomics_writer.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/genomics_writer.py
Integrability,protocol,protocol,"ANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Classes for reading and writing GFF files. The GFF format is described at; https://github.com/The-Sequence-Ontology/Specifications/blob/master/gff3.md. API for reading:. ```python; from third_party.nucleus.io import gff. # Iterate through all records.; with gff.GffReader(input_path) as reader:; for record in reader:; print(record); ```. where `record` is a `nucleus.genomics.v1.GffRecord` protocol buffer. API for writing:. ```python; from third_party.nucleus.io import gff; from third_party.nucleus.protos import gff_pb2. # records is an iterable of nucleus.genomics.v1.GffRecord protocol buffers.; records = ... header = gff_pb2.GffHeader(). # Write all records to the desired output path.; with gff.GffWriter(output_path, header) as writer:; for record in records:; writer.write(record); ```. For both reading and writing, if the path provided to the constructor contains; '.tfrecord' as an extension, a `TFRecord` file is assumed and attempted to be; read or written. Otherwise, the filename is treated as a true GFF file. Files that end in a '.gz' suffix cause the file to be treated as compressed; (with BGZF if it is a true GFF file, and with gzip if it is a TFRecord file).; """"""; """"""Class for reading from native GFF files. Most users will want to use GffReader instead, because it dynamically; dispatches between reading native GFF files and TFRecord files based on the; filename's e",MatchSource.CODE_COMMENT,third_party/nucleus/io/gff.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/gff.py
Testability,test,testdata,"# Copyright 2018 Google LLC.; #; # Redistribution and use in source and binary forms, with or without; # modification, are permitted provided that the following conditions; # are met:; #; # 1. Redistributions of source code must retain the above copyright notice,; # this list of conditions and the following disclaimer.; #; # 2. Redistributions in binary form must reproduce the above copyright; # notice, this list of conditions and the following disclaimer in the; # documentation and/or other materials provided with the distribution.; #; # 3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for third_party.nucleus.io.gff.""""""; # Names of testdata GFF files; we also reuse these basenames for output files; # in the tmp directory.; """"""Tests for GffWriter.""""""",MatchSource.CODE_COMMENT,third_party/nucleus/io/gff_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/gff_test.py
Integrability,interface,interface,"# Copyright 2018 Google LLC.; #; # Redistribution and use in source and binary forms, with or without; # modification, are permitted provided that the following conditions; # are met:; #; # 1. Redistributions of source code must retain the above copyright notice,; # this list of conditions and the following disclaimer.; #; # 2. Redistributions in binary form must reproduce the above copyright; # notice, this list of conditions and the following disclaimer in the; # documentation and/or other materials provided with the distribution.; #; # 3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""A Python interface for files.""""""; """"""Wraps gfile.ReadableFile to add iteration, enter/exit and readlines.""""""",MatchSource.CODE_COMMENT,third_party/nucleus/io/gfile.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/gfile.py
Integrability,protocol,protocol,"TICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; # pylint: disable=line-too-long; """"""Classes for reading and writing SAM and BAM files. The SAM/BAM/CRAM formats are described at; https://samtools.github.io/hts-specs/SAMv1.pdf; https://samtools.github.io/hts-specs/CRAMv3.pdf. API for reading:. ```python; from third_party.nucleus.io import sam. with sam.SamReader(input_path) as reader:; for read in reader:; print(read); ```. where `read` is a `nucleus.genomics.v1.Read` protocol buffer. input_path will; dynamically decode the underlying records depending the file extension, with; `.sam` for SAM files, `.bam` for BAM files, and `.cram` for CRAM files. It will; also search for an appropriate index file to use to enable calls to the; `query()` method. API for writing SAM/BAM:. ```python; from third_party.nucleus.io import sam. # reads is an iterable of nucleus.genomics.v1.Read protocol buffers.; reads = ... with sam.SamWriter(output_path, header=header) as writer:; for read in reads:; writer.write(read); ```. API for writing CRAM:. ```python; # ref_path is required for writing CRAM files. If embed_ref, the output CRAM; # file will embed reference sequences.; with sam.SamWriter(output_path, header=header, ref_path=ref_path,; embed_ref=embed_ref) as writer:; for read in reads:; writer.write(read); ```. For both reading and writing, if the path provided to the constructor contains; '.tfrecord' as an extension, a `TFRecord` file is assumed and attempted to be; re",MatchSource.CODE_COMMENT,third_party/nucleus/io/sam.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/sam.py
Modifiability,plugin,plugin,"ader; --------------------------------. Nucleus supports reading from CRAM files using the same API as for SAM/BAM:. ```python; from third_party.nucleus.io import sam. with sam.SamReader(""/path/to/sample.cram"") as reader:; for read in reader:; print(read); ```. There is one type of CRAM file, though, that has a slightly more complicated; API. If the CRAM file uses read sequence compression with an external reference; file, and this reference file is no longer accessible in the location specified; by the CRAM file's ""UR"" tag and cannot be found in the local genome cache, its; location must be passed to SamReader via the ref_path parameter:. ```python; from third_party.nucleus.io import sam. cram_path = ""/path/to/sample.cram""; ref_path = ""/path/to/genome.fasta""; with sam.SamReader(cram_path, ref_path=ref_path) as reader:; for read in reader:; print(read); ```. Unfortunately, htslib is unable to load the ref_path from anything other than a; POSIX filesystem. (htslib plugin filesystems like S3 or GCS buckets won't work).; For that reason, we don't recommend the use of CRAM files with external; reference files, but instead suggest using read sequence compression with; embedded reference data. (This has a minor impact on file size, but; significantly improves file access simplicity and safety.). For more information about CRAM, see:; * The `samtools` documentation at http://www.htslib.org/doc/samtools.html; * The ""Global Options"" section of the samtools docs at http://www.htslib.org/doc/samtools.html#GLOBAL_OPTIONS; * How reference sequences are encoded in CRAM at http://www.htslib.org/doc/samtools.html#REFERENCE_SEQUENCES; * Finally, benchmarking of different CRAM options http://www.htslib.org/benchmarks/CRAM.html; """"""; # pylint: enable=line-too-long; """"""Class for reading from native SAM/BAM/CRAM files. Most users will want to use SamReader instead, because it dynamically; dispatches between reading native SAM/BAM/CRAM files and TFRecord files based; on the filename's ext",MatchSource.CODE_COMMENT,third_party/nucleus/io/sam.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/sam.py
Performance,cache,cache,"riter(output_path, header=header, ref_path=ref_path,; embed_ref=embed_ref) as writer:; for read in reads:; writer.write(read); ```. For both reading and writing, if the path provided to the constructor contains; '.tfrecord' as an extension, a `TFRecord` file is assumed and attempted to be; read or written. Otherwise, the filename is treated as a true SAM/BAM/CRAM file. For `TFRecord` files, ending in a '.gz' suffix causes the file to be treated as; compressed with gzip. Notes on using CRAM with SamReader; --------------------------------. Nucleus supports reading from CRAM files using the same API as for SAM/BAM:. ```python; from third_party.nucleus.io import sam. with sam.SamReader(""/path/to/sample.cram"") as reader:; for read in reader:; print(read); ```. There is one type of CRAM file, though, that has a slightly more complicated; API. If the CRAM file uses read sequence compression with an external reference; file, and this reference file is no longer accessible in the location specified; by the CRAM file's ""UR"" tag and cannot be found in the local genome cache, its; location must be passed to SamReader via the ref_path parameter:. ```python; from third_party.nucleus.io import sam. cram_path = ""/path/to/sample.cram""; ref_path = ""/path/to/genome.fasta""; with sam.SamReader(cram_path, ref_path=ref_path) as reader:; for read in reader:; print(read); ```. Unfortunately, htslib is unable to load the ref_path from anything other than a; POSIX filesystem. (htslib plugin filesystems like S3 or GCS buckets won't work).; For that reason, we don't recommend the use of CRAM files with external; reference files, but instead suggest using read sequence compression with; embedded reference data. (This has a minor impact on file size, but; significantly improves file access simplicity and safety.). For more information about CRAM, see:; * The `samtools` documentation at http://www.htslib.org/doc/samtools.html; * The ""Global Options"" section of the samtools docs at http://www.htsli",MatchSource.CODE_COMMENT,third_party/nucleus/io/sam.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/sam.py
Safety,safe,safety,"```. There is one type of CRAM file, though, that has a slightly more complicated; API. If the CRAM file uses read sequence compression with an external reference; file, and this reference file is no longer accessible in the location specified; by the CRAM file's ""UR"" tag and cannot be found in the local genome cache, its; location must be passed to SamReader via the ref_path parameter:. ```python; from third_party.nucleus.io import sam. cram_path = ""/path/to/sample.cram""; ref_path = ""/path/to/genome.fasta""; with sam.SamReader(cram_path, ref_path=ref_path) as reader:; for read in reader:; print(read); ```. Unfortunately, htslib is unable to load the ref_path from anything other than a; POSIX filesystem. (htslib plugin filesystems like S3 or GCS buckets won't work).; For that reason, we don't recommend the use of CRAM files with external; reference files, but instead suggest using read sequence compression with; embedded reference data. (This has a minor impact on file size, but; significantly improves file access simplicity and safety.). For more information about CRAM, see:; * The `samtools` documentation at http://www.htslib.org/doc/samtools.html; * The ""Global Options"" section of the samtools docs at http://www.htslib.org/doc/samtools.html#GLOBAL_OPTIONS; * How reference sequences are encoded in CRAM at http://www.htslib.org/doc/samtools.html#REFERENCE_SEQUENCES; * Finally, benchmarking of different CRAM options http://www.htslib.org/benchmarks/CRAM.html; """"""; # pylint: enable=line-too-long; """"""Class for reading from native SAM/BAM/CRAM files. Most users will want to use SamReader instead, because it dynamically; dispatches between reading native SAM/BAM/CRAM files and TFRecord files based; on the filename's extensions.; """"""; """"""Initializes a NativeSamReader. Args:; input_path: str. A path to a resource containing SAM/BAM/CRAM records.; Currently supports SAM text format, BAM binary format, and CRAM.; ref_path: optional str or None. Only used for CRAM decoding, a",MatchSource.CODE_COMMENT,third_party/nucleus/io/sam.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/sam.py
Security,access,accessible,"riter(output_path, header=header, ref_path=ref_path,; embed_ref=embed_ref) as writer:; for read in reads:; writer.write(read); ```. For both reading and writing, if the path provided to the constructor contains; '.tfrecord' as an extension, a `TFRecord` file is assumed and attempted to be; read or written. Otherwise, the filename is treated as a true SAM/BAM/CRAM file. For `TFRecord` files, ending in a '.gz' suffix causes the file to be treated as; compressed with gzip. Notes on using CRAM with SamReader; --------------------------------. Nucleus supports reading from CRAM files using the same API as for SAM/BAM:. ```python; from third_party.nucleus.io import sam. with sam.SamReader(""/path/to/sample.cram"") as reader:; for read in reader:; print(read); ```. There is one type of CRAM file, though, that has a slightly more complicated; API. If the CRAM file uses read sequence compression with an external reference; file, and this reference file is no longer accessible in the location specified; by the CRAM file's ""UR"" tag and cannot be found in the local genome cache, its; location must be passed to SamReader via the ref_path parameter:. ```python; from third_party.nucleus.io import sam. cram_path = ""/path/to/sample.cram""; ref_path = ""/path/to/genome.fasta""; with sam.SamReader(cram_path, ref_path=ref_path) as reader:; for read in reader:; print(read); ```. Unfortunately, htslib is unable to load the ref_path from anything other than a; POSIX filesystem. (htslib plugin filesystems like S3 or GCS buckets won't work).; For that reason, we don't recommend the use of CRAM files with external; reference files, but instead suggest using read sequence compression with; embedded reference data. (This has a minor impact on file size, but; significantly improves file access simplicity and safety.). For more information about CRAM, see:; * The `samtools` documentation at http://www.htslib.org/doc/samtools.html; * The ""Global Options"" section of the samtools docs at http://www.htsli",MatchSource.CODE_COMMENT,third_party/nucleus/io/sam.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/sam.py
Testability,benchmark,benchmarking," third_party.nucleus.io import sam. cram_path = ""/path/to/sample.cram""; ref_path = ""/path/to/genome.fasta""; with sam.SamReader(cram_path, ref_path=ref_path) as reader:; for read in reader:; print(read); ```. Unfortunately, htslib is unable to load the ref_path from anything other than a; POSIX filesystem. (htslib plugin filesystems like S3 or GCS buckets won't work).; For that reason, we don't recommend the use of CRAM files with external; reference files, but instead suggest using read sequence compression with; embedded reference data. (This has a minor impact on file size, but; significantly improves file access simplicity and safety.). For more information about CRAM, see:; * The `samtools` documentation at http://www.htslib.org/doc/samtools.html; * The ""Global Options"" section of the samtools docs at http://www.htslib.org/doc/samtools.html#GLOBAL_OPTIONS; * How reference sequences are encoded in CRAM at http://www.htslib.org/doc/samtools.html#REFERENCE_SEQUENCES; * Finally, benchmarking of different CRAM options http://www.htslib.org/benchmarks/CRAM.html; """"""; # pylint: enable=line-too-long; """"""Class for reading from native SAM/BAM/CRAM files. Most users will want to use SamReader instead, because it dynamically; dispatches between reading native SAM/BAM/CRAM files and TFRecord files based; on the filename's extensions.; """"""; """"""Initializes a NativeSamReader. Args:; input_path: str. A path to a resource containing SAM/BAM/CRAM records.; Currently supports SAM text format, BAM binary format, and CRAM.; ref_path: optional str or None. Only used for CRAM decoding, and only; necessary if the UR encoded path in the CRAM itself needs to be; overridden. If provided, we will tell the CRAM decoder to use this FASTA; for the reference sequence.; read_requirements: optional ReadRequirement proto. If not None, this proto; is used to control which reads are filtered out by the reader before; they are passed to the client.; parse_aux_fields: optional bool, defaulting to False",MatchSource.CODE_COMMENT,third_party/nucleus/io/sam.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/sam.py
Usability,simpl,simplicity,"```. There is one type of CRAM file, though, that has a slightly more complicated; API. If the CRAM file uses read sequence compression with an external reference; file, and this reference file is no longer accessible in the location specified; by the CRAM file's ""UR"" tag and cannot be found in the local genome cache, its; location must be passed to SamReader via the ref_path parameter:. ```python; from third_party.nucleus.io import sam. cram_path = ""/path/to/sample.cram""; ref_path = ""/path/to/genome.fasta""; with sam.SamReader(cram_path, ref_path=ref_path) as reader:; for read in reader:; print(read); ```. Unfortunately, htslib is unable to load the ref_path from anything other than a; POSIX filesystem. (htslib plugin filesystems like S3 or GCS buckets won't work).; For that reason, we don't recommend the use of CRAM files with external; reference files, but instead suggest using read sequence compression with; embedded reference data. (This has a minor impact on file size, but; significantly improves file access simplicity and safety.). For more information about CRAM, see:; * The `samtools` documentation at http://www.htslib.org/doc/samtools.html; * The ""Global Options"" section of the samtools docs at http://www.htslib.org/doc/samtools.html#GLOBAL_OPTIONS; * How reference sequences are encoded in CRAM at http://www.htslib.org/doc/samtools.html#REFERENCE_SEQUENCES; * Finally, benchmarking of different CRAM options http://www.htslib.org/benchmarks/CRAM.html; """"""; # pylint: enable=line-too-long; """"""Class for reading from native SAM/BAM/CRAM files. Most users will want to use SamReader instead, because it dynamically; dispatches between reading native SAM/BAM/CRAM files and TFRecord files based; on the filename's extensions.; """"""; """"""Initializes a NativeSamReader. Args:; input_path: str. A path to a resource containing SAM/BAM/CRAM records.; Currently supports SAM text format, BAM binary format, and CRAM.; ref_path: optional str or None. Only used for CRAM decoding, a",MatchSource.CODE_COMMENT,third_party/nucleus/io/sam.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/sam.py
Availability,error,error,"BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for third_party.nucleus.util.io.""""""; """"""Test the iteration functionality provided by io.SamReader.""""""; """"""Verify that iteration provides results incrementally, not all at once.""""""; # We expect 106 records in total.; # Empty string.; # We skip H hex byte-array tags as they appear deprecated.; # Minimal header line to create a valid SAM file.; # Integer with character value.; # A string instead of the expected float.; # Supposed to be single char, but we none here.; # Supposed to be single char, but we have two here.; # Empty byte array.; # Integer byte array with a float.; # Integer byte array with a string.; # Float byte array with a string.; # z is not a valid subtype.; # If we didn't detect the error, make sure we actually still parsed the; # read itself.; # Minimal header line to create a valid SAM file.; # A single stock read we'll add our AUX fields to.; # These expected counts are deterministic because we always set the random; # seed in each test.; # There are 106 total reads if we iterate.; # There are 45 total reads if we don't downsample.; # Note that CRAM version 2.1 files work with Nucleus but they cannot be used in; # our test here because CRAM 2.1 embeds an exact path to the reference file; # which LEAKR flags as leaking internal google paths.; """"""Test io.SamReader on CRAM formatted files.""""""; # If we have an embedded reference, force the reader to use it by not; # providing an argument for ref_path.; # Otherwise we need to explicitly override the reference encoded in the UR; # of the CRAM file to use the path provided to our test.fasta.; """"""Tests for sam.SamWriter.""""""; # Test that the writer is a context manager and that we can write a read to; # it.; # Our output should have exa",MatchSource.CODE_COMMENT,third_party/nucleus/io/sam_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/sam_test.py
Safety,detect,detect,"BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for third_party.nucleus.util.io.""""""; """"""Test the iteration functionality provided by io.SamReader.""""""; """"""Verify that iteration provides results incrementally, not all at once.""""""; # We expect 106 records in total.; # Empty string.; # We skip H hex byte-array tags as they appear deprecated.; # Minimal header line to create a valid SAM file.; # Integer with character value.; # A string instead of the expected float.; # Supposed to be single char, but we none here.; # Supposed to be single char, but we have two here.; # Empty byte array.; # Integer byte array with a float.; # Integer byte array with a string.; # Float byte array with a string.; # z is not a valid subtype.; # If we didn't detect the error, make sure we actually still parsed the; # read itself.; # Minimal header line to create a valid SAM file.; # A single stock read we'll add our AUX fields to.; # These expected counts are deterministic because we always set the random; # seed in each test.; # There are 106 total reads if we iterate.; # There are 45 total reads if we don't downsample.; # Note that CRAM version 2.1 files work with Nucleus but they cannot be used in; # our test here because CRAM 2.1 embeds an exact path to the reference file; # which LEAKR flags as leaking internal google paths.; """"""Test io.SamReader on CRAM formatted files.""""""; # If we have an embedded reference, force the reader to use it by not; # providing an argument for ref_path.; # Otherwise we need to explicitly override the reference encoded in the UR; # of the CRAM file to use the path provided to our test.fasta.; """"""Tests for sam.SamWriter.""""""; # Test that the writer is a context manager and that we can write a read to; # it.; # Our output should have exa",MatchSource.CODE_COMMENT,third_party/nucleus/io/sam_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/sam_test.py
Testability,test,test,"ON) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for third_party.nucleus.util.io.""""""; """"""Test the iteration functionality provided by io.SamReader.""""""; """"""Verify that iteration provides results incrementally, not all at once.""""""; # We expect 106 records in total.; # Empty string.; # We skip H hex byte-array tags as they appear deprecated.; # Minimal header line to create a valid SAM file.; # Integer with character value.; # A string instead of the expected float.; # Supposed to be single char, but we none here.; # Supposed to be single char, but we have two here.; # Empty byte array.; # Integer byte array with a float.; # Integer byte array with a string.; # Float byte array with a string.; # z is not a valid subtype.; # If we didn't detect the error, make sure we actually still parsed the; # read itself.; # Minimal header line to create a valid SAM file.; # A single stock read we'll add our AUX fields to.; # These expected counts are deterministic because we always set the random; # seed in each test.; # There are 106 total reads if we iterate.; # There are 45 total reads if we don't downsample.; # Note that CRAM version 2.1 files work with Nucleus but they cannot be used in; # our test here because CRAM 2.1 embeds an exact path to the reference file; # which LEAKR flags as leaking internal google paths.; """"""Test io.SamReader on CRAM formatted files.""""""; # If we have an embedded reference, force the reader to use it by not; # providing an argument for ref_path.; # Otherwise we need to explicitly override the reference encoded in the UR; # of the CRAM file to use the path provided to our test.fasta.; """"""Tests for sam.SamWriter.""""""; # Test that the writer is a context manager and that we can write a read to; # it.; # Our output should have exactly one read in it.",MatchSource.CODE_COMMENT,third_party/nucleus/io/sam_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/sam_test.py
Availability,error,error,", OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Utility functions for working with sharded files. A sharded file is a single conceptual file that is broken into a collection; of files to make parallelization easier. A sharded file spec is like a; filename for a sharded file; the file spec ""/some/path/prefix@200.txt""; says that the sharded file consists of 200 actual files that have names like; ""/some/path/prefix-00000-of-00200.txt"", ""/some/path/prefix-00001-of-00200.txt"",; etc. This module contains functions for parsing, generating, detecting and; resolving sharded file specs.; """"""; # Important: Please keep this module free of TensorFlow c++ extensions.; # This makes it easy to build pure python packages for training that work with; # CMLE.; """"""An I/O error.""""""; """"""Parse a sharded file specification. Args:; spec: str. The sharded file specification. A sharded file spec is one like; 'gs://some/file@200.txt'. Here, '@200' specifies the number of shards. Returns:; basename: str. The basename for the files.; num_shards: int >= 0. The number of shards.; suffix: str. The suffix if there is one, or '' if not.; Raises:; ShardError: If the spec is not a valid sharded specification.; """"""; # If there's a non-empty suffix, we need to prepend '.' so we get files like; # foo@20.ext instead of foo@ext. The original C++ parser version has:; # string ext = StrCat(suff.empty() ? """" : ""."", suff);; """"""Return the width of the shard matcher based on the number of shards.""""""; """"""Generate the list of filenames corresponding to the sharding path. Args:; spec: str. Represents a filename with a sharding specification.; e.g., 'gs://some/file@200.txt' represents a file sharded 200 ways. Returns:; List of filenames. Raises:; ShardError: If spec is not a valid",MatchSource.CODE_COMMENT,third_party/nucleus/io/sharded_file_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/sharded_file_utils.py
Safety,detect,detecting,"PYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Utility functions for working with sharded files. A sharded file is a single conceptual file that is broken into a collection; of files to make parallelization easier. A sharded file spec is like a; filename for a sharded file; the file spec ""/some/path/prefix@200.txt""; says that the sharded file consists of 200 actual files that have names like; ""/some/path/prefix-00000-of-00200.txt"", ""/some/path/prefix-00001-of-00200.txt"",; etc. This module contains functions for parsing, generating, detecting and; resolving sharded file specs.; """"""; # Important: Please keep this module free of TensorFlow c++ extensions.; # This makes it easy to build pure python packages for training that work with; # CMLE.; """"""An I/O error.""""""; """"""Parse a sharded file specification. Args:; spec: str. The sharded file specification. A sharded file spec is one like; 'gs://some/file@200.txt'. Here, '@200' specifies the number of shards. Returns:; basename: str. The basename for the files.; num_shards: int >= 0. The number of shards.; suffix: str. The suffix if there is one, or '' if not.; Raises:; ShardError: If the spec is not a valid sharded specification.; """"""; # If there's a non-empty suffix, we need to prepend '.' so we get files like; # foo@20.ext instead of foo@ext. The original C++ parser version has:; # string ext = StrCat(suff.empty() ? """" : ""."", suff);; """"""Return the width of the shard matcher based on the number of shards.""""""; """"""Generate the list of filenames corresponding to the ",MatchSource.CODE_COMMENT,third_party/nucleus/io/sharded_file_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/sharded_file_utils.py
Integrability,protocol,protocol,"s may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""I/O for TFRecord files. Utilities for reading and writing TFRecord files, especially those containing; serialized TensorFlow Example protocol buffers.; """"""; # Important: Please keep this module free of TensorFlow C++ extensions.; # This makes it easy to build pure python packages for training that work with; # CMLE.; # pylint: disable=invalid-name; """"""A TFRecordReader that defaults to tf.Example protos.""""""; """"""A convenience wrapper around genomics_writer.TFRecordWriter.""""""; # pylint: enable=invalid-name; # TODO: Refactor all of the following (internal).; """"""Yields the parsed records in a TFRecord file path. Note that path can be sharded filespec (path@N) in which case this function; will read each shard in order; i.e. shard 0 will read each entry in order,; then shard 1, ... Args:; path: String. A path to a TFRecord file containing protos.; proto: A proto class. proto.FromString() will be called on each serialized; record in path to parse it.; max_records: int >= 0 or None. Maximum number of records to read from path.; If None, the default, all records will be read.; com",MatchSource.CODE_COMMENT,third_party/nucleus/io/tfrecord.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/tfrecord.py
Performance,perform,performed,"f records to read from path.; If None, the default, all records will be read.; compression_type: 'GZIP', 'ZLIB', '' (uncompressed), or None to autodetect; based on file extension. Yields:; proto.FromString() values on each record in path in order.; """"""; """"""Returns all file paths for the given (optionally sharded) tfrecord path. Args:; path: String. Path to the (optionally sharded) TFRecords. Returns a lits; with the original path if the tfrecord file is not sharded, or a list of; paths to all shards if it is.; """"""; """"""Yields the parsed records in a TFRecord file path in sorted order. The input TFRecord file must have each shard already in sorted order when; using the key function for comparison (but elements can be interleaved across; shards). Under those constraints, the elements will be yielded in a global; sorted order. Args:; path: String. A path to a TFRecord-formatted file containing protos.; key: Callable. A function that takes as input a single instance of the proto; class and returns a value on which the comparison for sorted ordering is; performed.; proto: A proto class. proto.FromString() will be called on each serialized; record in path to parse it.; max_records: int >= 0 or None. Maximum number of records to read from path.; If None, the default, all records will be read.; compression_type: 'GZIP', 'ZLIB', '' (uncompressed), or None to autodetect; based on file extension. Yields:; proto.FromString() values on each record in path in sorted order.; """"""; """"""Writes protos to output_path. This function writes serialized strings of each proto in protos to output_path; in their original order. If output_path is a sharded file (e.g., foo@2), this; function will write the protos spread out as evenly as possible among the; individual components of the sharded spec (e.g., foo-00000-of-00002 and; foo-00001-of-00002). Note that the order of records in the sharded files may; differ from the order in protos due to the striping. Args:; protos: An iterable of protobufs.",MatchSource.CODE_COMMENT,third_party/nucleus/io/tfrecord.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/tfrecord.py
Integrability,protocol,protocol,"ESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Classes for reading and writing VCF files. The VCF format is described at; https://samtools.github.io/hts-specs/VCFv4.3.pdf. API for reading:. ```python; from third_party.nucleus.io import vcf. with vcf.VcfReader(input_path) as reader:; for variant in reader:; print(variant); ```. API for writing:. ```python; from third_party.nucleus.io import vcf. # variants is an iterable of nucleus.genomics.v1.Variant protocol buffers.; variants = ... with vcf.VcfWriter(output_path, header=header) as writer:; for variant in variants:; writer.write(variant); ```. The class attempts to infer the file format (`TFRecord` vs VCF) from the file; path provided to the constructor. 1. For files that end with '.tfrecord' and '.tfrecord.gz' (a gzipped version),; a `TFRecord` file is assumed and is attempted to be read or written. 2. For all other files, the VCF format will be used. VCF format used in writing is inferred from file paths:; - ending in '.bcf.gz': BGZF compressed BCF format will be written;; - ending in '.bcf': uncompressed BCF format will be written;; - ending in '.gz' and not in '.bcf.gz': BGZP compressed VCF format will be; written;; - all other suffixes: uncompressed VCF format will be written. VCF format used in reading is inferred from the contents of the file.; """"""; """"""Returns a dictionary from field to a callable that extracts its value.""""""; """"""Returns a dictionary from field to a callable that",MatchSource.CODE_COMMENT,third_party/nucleus/io/vcf.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/vcf.py
Performance,cache,cache,"ath, header=header) as writer:; for variant in variants:; writer.write(variant); ```. The class attempts to infer the file format (`TFRecord` vs VCF) from the file; path provided to the constructor. 1. For files that end with '.tfrecord' and '.tfrecord.gz' (a gzipped version),; a `TFRecord` file is assumed and is attempted to be read or written. 2. For all other files, the VCF format will be used. VCF format used in writing is inferred from file paths:; - ending in '.bcf.gz': BGZF compressed BCF format will be written;; - ending in '.bcf': uncompressed BCF format will be written;; - ending in '.gz' and not in '.bcf.gz': BGZP compressed VCF format will be; written;; - all other suffixes: uncompressed VCF format will be written. VCF format used in reading is inferred from the contents of the file.; """"""; """"""Returns a dictionary from field to a callable that extracts its value.""""""; """"""Returns a dictionary from field to a callable that sets its value.""""""; """"""This class creates a cache of accessors to structured fields in Variants. The INFO and FORMAT fields within Variant protos are structured and typed,; with types defined by the corresponding VCF header. This cache object provides; provides {info,format}_field_{get,set}_fn functions that can be used to; extract information from the structured Variant protos based on the types; defined therein. NOTE: Users should not need to interact with this class at all. It is used; by the variant_utils.{get,set}_info and variantcall_utils.{get,set}_format; functions for interacting with the INFO and FORMAT fields in a Variant proto.; """"""; """"""Initializer. Args:; header: nucleus.genomics.v1.VcfHeader proto. Used to define the accessor; functions needed.; """"""; """"""Returns a callable that extracts the given INFO field based on its type. Args:; field_name: str. The INFO field name of interest, e.g. 'AA', 'DB', 'AF'. Returns:; A callable used to extract the given INFO field from a Variant proto.; """"""; """"""Returns a callable that sets the giv",MatchSource.CODE_COMMENT,third_party/nucleus/io/vcf.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/vcf.py
Safety,avoid,avoid,"import vcf; from third_party.nucleus.protos import variants_pb2. variants = [... Variant protos ...]; header = variants_pb2.VcfHeader(). with vcf.InMemoryVcfReader(variants, header) as reader:; for variant in reader:; print(variant); ```. This class accepts a collection of variants and optionally a header and; provides all of the standard API functions of VcfReader but instead of; fetching variants from a file the variants are queried from an in-memory cache; of variant protos. Note that the input variants provided to this class aren't checked in any way,; and their ordering determines the order of variants emitted by this class for; the iterate() and query() operations. This is intentional, to make this class; easy to use for testing where you often want to use less-than-perfectly formed; inputs. In order to fully meet the contract of a standard VcfReader, variants; should be sorted by their contig ordering and then by their start and finally; by their ends. Implementation note:; The current implementation will be very slow for query() if the provided; cache of variants is large, as we do a O(n) search to collect all of the; overlapping variants for each query. There are several straightforward; optimizations to do if we need/want to scale this up. (a) sort the variants; and use a binary search to find overlapping variants (b) partition the; variants by contig, so we have dict[contig] => [variants on contig], which; allows us to completely avoid considering any variants on any other contigs.; Neither of these optimizations are worth it if len(variants) is small, but; it may be worth considering if we want to use this functionality with a; large number of variants.; """"""; """"""Creates a VCFReader backed by a collection of variants. Args:; variants: list of nucleus.genomics.v1.Variant protos we will ""read""; from.; header: a VCFHeader object to provide as a result to calls to self.header,; or None, indicating that we don't have a header associated with this; reader.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/io/vcf.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/vcf.py
Security,access,accessors,"ath, header=header) as writer:; for variant in variants:; writer.write(variant); ```. The class attempts to infer the file format (`TFRecord` vs VCF) from the file; path provided to the constructor. 1. For files that end with '.tfrecord' and '.tfrecord.gz' (a gzipped version),; a `TFRecord` file is assumed and is attempted to be read or written. 2. For all other files, the VCF format will be used. VCF format used in writing is inferred from file paths:; - ending in '.bcf.gz': BGZF compressed BCF format will be written;; - ending in '.bcf': uncompressed BCF format will be written;; - ending in '.gz' and not in '.bcf.gz': BGZP compressed VCF format will be; written;; - all other suffixes: uncompressed VCF format will be written. VCF format used in reading is inferred from the contents of the file.; """"""; """"""Returns a dictionary from field to a callable that extracts its value.""""""; """"""Returns a dictionary from field to a callable that sets its value.""""""; """"""This class creates a cache of accessors to structured fields in Variants. The INFO and FORMAT fields within Variant protos are structured and typed,; with types defined by the corresponding VCF header. This cache object provides; provides {info,format}_field_{get,set}_fn functions that can be used to; extract information from the structured Variant protos based on the types; defined therein. NOTE: Users should not need to interact with this class at all. It is used; by the variant_utils.{get,set}_info and variantcall_utils.{get,set}_format; functions for interacting with the INFO and FORMAT fields in a Variant proto.; """"""; """"""Initializer. Args:; header: nucleus.genomics.v1.VcfHeader proto. Used to define the accessor; functions needed.; """"""; """"""Returns a callable that extracts the given INFO field based on its type. Args:; field_name: str. The INFO field name of interest, e.g. 'AA', 'DB', 'AF'. Returns:; A callable used to extract the given INFO field from a Variant proto.; """"""; """"""Returns a callable that sets the giv",MatchSource.CODE_COMMENT,third_party/nucleus/io/vcf.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/vcf.py
Testability,test,testing," field_access_cache. If we are dispatching to a; # NativeVcfWriter, we use its field_access_cache. Otherwise, we; # need to create a new one.; """"""Class for ""reading"" Variant protos from an in-memory cache of variants. ```python; from third_party.nucleus.io import vcf; from third_party.nucleus.protos import variants_pb2. variants = [... Variant protos ...]; header = variants_pb2.VcfHeader(). with vcf.InMemoryVcfReader(variants, header) as reader:; for variant in reader:; print(variant); ```. This class accepts a collection of variants and optionally a header and; provides all of the standard API functions of VcfReader but instead of; fetching variants from a file the variants are queried from an in-memory cache; of variant protos. Note that the input variants provided to this class aren't checked in any way,; and their ordering determines the order of variants emitted by this class for; the iterate() and query() operations. This is intentional, to make this class; easy to use for testing where you often want to use less-than-perfectly formed; inputs. In order to fully meet the contract of a standard VcfReader, variants; should be sorted by their contig ordering and then by their start and finally; by their ends. Implementation note:; The current implementation will be very slow for query() if the provided; cache of variants is large, as we do a O(n) search to collect all of the; overlapping variants for each query. There are several straightforward; optimizations to do if we need/want to scale this up. (a) sort the variants; and use a binary search to find overlapping variants (b) partition the; variants by contig, so we have dict[contig] => [variants on contig], which; allows us to completely avoid considering any variants on any other contigs.; Neither of these optimizations are worth it if len(variants) is small, but; it may be worth considering if we want to use this functionality with a; large number of variants.; """"""; """"""Creates a VCFReader backed by a collectio",MatchSource.CODE_COMMENT,third_party/nucleus/io/vcf.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/vcf.py
Integrability,wrap,wrappers,"# Copyright 2018 Google LLC.; #; # Redistribution and use in source and binary forms, with or without; # modification, are permitted provided that the following conditions; # are met:; #; # 1. Redistributions of source code must retain the above copyright notice,; # this list of conditions and the following disclaimer.; #; # 2. Redistributions in binary form must reproduce the above copyright; # notice, this list of conditions and the following disclaimer in the; # documentation and/or other materials provided with the distribution.; #; # 3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for bed_reader CLIF python wrappers.""""""; # TODO: OpError exception not propagated.; # At this point the reader is closed.",MatchSource.CODE_COMMENT,third_party/nucleus/io/python/bed_reader_wrap_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/python/bed_reader_wrap_test.py
Availability,error,error,"# Copyright 2018 Google LLC.; #; # Redistribution and use in source and binary forms, with or without; # modification, are permitted provided that the following conditions; # are met:; #; # 1. Redistributions of source code must retain the above copyright notice,; # this list of conditions and the following disclaimer.; #; # 2. Redistributions in binary form must reproduce the above copyright; # notice, this list of conditions and the following disclaimer in the; # documentation and/or other materials provided with the distribution.; #; # 3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for BedWriter CLIF python wrappers.""""""; """"""Tests writing all the records that are 'canned' in our tfrecord file.""""""; # This file is in TFRecord format.; # Writing within the context manager succeeds.; # self.writer should be closed, so writing again will fail.; # Writing within the context manager succeeds.; # Entering the closed writer should be fine.; # We want to raise an error on exit, so nothing to do in context.",MatchSource.CODE_COMMENT,third_party/nucleus/io/python/bed_writer_wrap_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/python/bed_writer_wrap_test.py
Integrability,wrap,wrappers,"# Copyright 2018 Google LLC.; #; # Redistribution and use in source and binary forms, with or without; # modification, are permitted provided that the following conditions; # are met:; #; # 1. Redistributions of source code must retain the above copyright notice,; # this list of conditions and the following disclaimer.; #; # 2. Redistributions in binary form must reproduce the above copyright; # notice, this list of conditions and the following disclaimer in the; # documentation and/or other materials provided with the distribution.; #; # 3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for BedWriter CLIF python wrappers.""""""; """"""Tests writing all the records that are 'canned' in our tfrecord file.""""""; # This file is in TFRecord format.; # Writing within the context manager succeeds.; # self.writer should be closed, so writing again will fail.; # Writing within the context manager succeeds.; # Entering the closed writer should be fine.; # We want to raise an error on exit, so nothing to do in context.",MatchSource.CODE_COMMENT,third_party/nucleus/io/python/bed_writer_wrap_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/python/bed_writer_wrap_test.py
Integrability,wrap,wrappers,"# Copyright 2018 Google LLC.; #; # Redistribution and use in source and binary forms, with or without; # modification, are permitted provided that the following conditions; # are met:; #; # 1. Redistributions of source code must retain the above copyright notice,; # this list of conditions and the following disclaimer.; #; # 2. Redistributions in binary form must reproduce the above copyright; # notice, this list of conditions and the following disclaimer in the; # documentation and/or other materials provided with the distribution.; #; # 3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for fastq_reader CLIF python wrappers.""""""; # TODO: OpError exception not propagated.; # At this point the reader is closed.",MatchSource.CODE_COMMENT,third_party/nucleus/io/python/fastq_reader_wrap_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/python/fastq_reader_wrap_test.py
Availability,error,error,":; #; # 1. Redistributions of source code must retain the above copyright notice,; # this list of conditions and the following disclaimer.; #; # 2. Redistributions in binary form must reproduce the above copyright; # notice, this list of conditions and the following disclaimer in the; # documentation and/or other materials provided with the distribution.; #; # 3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for FastqWriter CLIF python wrappers.""""""; """"""Tests writing all the variants that are 'canned' in our tfrecord file.""""""; # This file is in TFRecord format.; # Writing within the context manager succeeds.; # self.writer should be closed, so writing again will fail.; # Writing within the context manager succeeds.; # Entering the closed writer should be fine.; # We want to raise an error on exit, so nothing to do in context.; # Round-trip FASTQ records through writing and reading:; # 1. Read records v1 from FastqReader;; # 2. Write v1 to fastq using our FastqWriter;; # 3. Read back in using FastqReader -- v2;; # 4. compare v1 and v2.",MatchSource.CODE_COMMENT,third_party/nucleus/io/python/fastq_writer_wrap_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/python/fastq_writer_wrap_test.py
Integrability,wrap,wrappers,":; #; # 1. Redistributions of source code must retain the above copyright notice,; # this list of conditions and the following disclaimer.; #; # 2. Redistributions in binary form must reproduce the above copyright; # notice, this list of conditions and the following disclaimer in the; # documentation and/or other materials provided with the distribution.; #; # 3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for FastqWriter CLIF python wrappers.""""""; """"""Tests writing all the variants that are 'canned' in our tfrecord file.""""""; # This file is in TFRecord format.; # Writing within the context manager succeeds.; # self.writer should be closed, so writing again will fail.; # Writing within the context manager succeeds.; # Entering the closed writer should be fine.; # We want to raise an error on exit, so nothing to do in context.; # Round-trip FASTQ records through writing and reading:; # 1. Read records v1 from FastqReader;; # 2. Write v1 to fastq using our FastqWriter;; # 3. Read back in using FastqReader -- v2;; # 4. compare v1 and v2.",MatchSource.CODE_COMMENT,third_party/nucleus/io/python/fastq_writer_wrap_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/python/fastq_writer_wrap_test.py
Integrability,wrap,wrappers,"# Copyright 2018 Google LLC.; #; # Redistribution and use in source and binary forms, with or without; # modification, are permitted provided that the following conditions; # are met:; #; # 1. Redistributions of source code must retain the above copyright notice,; # this list of conditions and the following disclaimer.; #; # 2. Redistributions in binary form must reproduce the above copyright; # notice, this list of conditions and the following disclaimer in the; # documentation and/or other materials provided with the distribution.; #; # 3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for gff_reader CLIF python wrappers.""""""; # TODO: OpError exception not propagated.; # At this point the reader is closed.",MatchSource.CODE_COMMENT,third_party/nucleus/io/python/gff_reader_wrap_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/python/gff_reader_wrap_test.py
Availability,error,error,"# Copyright 2018 Google LLC.; #; # Redistribution and use in source and binary forms, with or without; # modification, are permitted provided that the following conditions; # are met:; #; # 1. Redistributions of source code must retain the above copyright notice,; # this list of conditions and the following disclaimer.; #; # 2. Redistributions in binary form must reproduce the above copyright; # notice, this list of conditions and the following disclaimer in the; # documentation and/or other materials provided with the distribution.; #; # 3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for GffWriter CLIF python wrappers.""""""; """"""Tests writing all the records that are 'canned' in our tfrecord file.""""""; # This file is in TFRecord format.; # Writing within the context manager succeeds.; # self.writer should be closed, so writing again will fail.; # Writing within the context manager succeeds.; # Entering the closed writer should be fine.; # We want to raise an error on exit, so nothing to do in context.",MatchSource.CODE_COMMENT,third_party/nucleus/io/python/gff_writer_wrap_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/python/gff_writer_wrap_test.py
Integrability,wrap,wrappers,"# Copyright 2018 Google LLC.; #; # Redistribution and use in source and binary forms, with or without; # modification, are permitted provided that the following conditions; # are met:; #; # 1. Redistributions of source code must retain the above copyright notice,; # this list of conditions and the following disclaimer.; #; # 2. Redistributions in binary form must reproduce the above copyright; # notice, this list of conditions and the following disclaimer in the; # documentation and/or other materials provided with the distribution.; #; # 3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for GffWriter CLIF python wrappers.""""""; """"""Tests writing all the records that are 'canned' in our tfrecord file.""""""; # This file is in TFRecord format.; # Writing within the context manager succeeds.; # self.writer should be closed, so writing again will fail.; # Writing within the context manager succeeds.; # Entering the closed writer should be fine.; # We want to raise an error on exit, so nothing to do in context.",MatchSource.CODE_COMMENT,third_party/nucleus/io/python/gff_writer_wrap_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/python/gff_writer_wrap_test.py
Integrability,wrap,wrappers,"# Copyright 2018 Google LLC.; #; # Redistribution and use in source and binary forms, with or without; # modification, are permitted provided that the following conditions; # are met:; #; # 1. Redistributions of source code must retain the above copyright notice,; # this list of conditions and the following disclaimer.; #; # 2. Redistributions in binary form must reproduce the above copyright; # notice, this list of conditions and the following disclaimer in the; # documentation and/or other materials provided with the distribution.; #; # 3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for GenomeReference CLIF python wrappers.""""""; # The fasta and the FAI are both missing.; # The fasta is present but the FAI is missing.; # The fasta is missing but the FAI is present.; # TODO: OpError exception not propagated.",MatchSource.CODE_COMMENT,third_party/nucleus/io/python/reference_wrap_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/python/reference_wrap_test.py
Integrability,wrap,wrappers,"# Copyright 2018 Google LLC.; #; # Redistribution and use in source and binary forms, with or without; # modification, are permitted provided that the following conditions; # are met:; #; # 1. Redistributions of source code must retain the above copyright notice,; # this list of conditions and the following disclaimer.; #; # 2. Redistributions in binary form must reproduce the above copyright; # notice, this list of conditions and the following disclaimer in the; # documentation and/or other materials provided with the distribution.; #; # 3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for sam_reader CLIF python wrappers.""""""; """"""Test that we can use context manager to do two queries in sequence.""""""; # TODO: OpError exception not propagated.; # At this point the reader is closed.",MatchSource.CODE_COMMENT,third_party/nucleus/io/python/sam_reader_wrap_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/python/sam_reader_wrap_test.py
Integrability,wrap,wrappers,"bove copyright notice,; # this list of conditions and the following disclaimer.; #; # 2. Redistributions in binary form must reproduce the above copyright; # notice, this list of conditions and the following disclaimer in the; # documentation and/or other materials provided with the distribution.; #; # 3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for vcf_reader CLIF python wrappers.""""""; # pylint: disable=line-too-long; # pylint: enable=line-too-long; # TODO: OpError exception not propagated.; # At this point the reader is closed.; # Commented out because we in fact don't detect the malformed VCF yet. It is; # unclear if it's even possible to detect the issue with the API provided by; # htslib.; # def test_vcf_iterate_raises_on_malformed_record(self):; # malformed = test_utils.genomics_core_testdata('malformed.vcf'); # reader = vcf_reader.VcfReader.from_file(malformed, self.unindexed_options); # iterable = iter(reader.iterate()); # self.assertIsNotNone(next(iterable)); # with self.assertRaises(ValueError):; # print(list(iterable))",MatchSource.CODE_COMMENT,third_party/nucleus/io/python/vcf_reader_wrap_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/python/vcf_reader_wrap_test.py
Safety,detect,detect,"bove copyright notice,; # this list of conditions and the following disclaimer.; #; # 2. Redistributions in binary form must reproduce the above copyright; # notice, this list of conditions and the following disclaimer in the; # documentation and/or other materials provided with the distribution.; #; # 3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for vcf_reader CLIF python wrappers.""""""; # pylint: disable=line-too-long; # pylint: enable=line-too-long; # TODO: OpError exception not propagated.; # At this point the reader is closed.; # Commented out because we in fact don't detect the malformed VCF yet. It is; # unclear if it's even possible to detect the issue with the API provided by; # htslib.; # def test_vcf_iterate_raises_on_malformed_record(self):; # malformed = test_utils.genomics_core_testdata('malformed.vcf'); # reader = vcf_reader.VcfReader.from_file(malformed, self.unindexed_options); # iterable = iter(reader.iterate()); # self.assertIsNotNone(next(iterable)); # with self.assertRaises(ValueError):; # print(list(iterable))",MatchSource.CODE_COMMENT,third_party/nucleus/io/python/vcf_reader_wrap_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/python/vcf_reader_wrap_test.py
Testability,assert,assertIsNotNone,"bove copyright notice,; # this list of conditions and the following disclaimer.; #; # 2. Redistributions in binary form must reproduce the above copyright; # notice, this list of conditions and the following disclaimer in the; # documentation and/or other materials provided with the distribution.; #; # 3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for vcf_reader CLIF python wrappers.""""""; # pylint: disable=line-too-long; # pylint: enable=line-too-long; # TODO: OpError exception not propagated.; # At this point the reader is closed.; # Commented out because we in fact don't detect the malformed VCF yet. It is; # unclear if it's even possible to detect the issue with the API provided by; # htslib.; # def test_vcf_iterate_raises_on_malformed_record(self):; # malformed = test_utils.genomics_core_testdata('malformed.vcf'); # reader = vcf_reader.VcfReader.from_file(malformed, self.unindexed_options); # iterable = iter(reader.iterate()); # self.assertIsNotNone(next(iterable)); # with self.assertRaises(ValueError):; # print(list(iterable))",MatchSource.CODE_COMMENT,third_party/nucleus/io/python/vcf_reader_wrap_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/python/vcf_reader_wrap_test.py
Availability,error,error,"lowing disclaimer.; #; # 2. Redistributions in binary form must reproduce the above copyright; # notice, this list of conditions and the following disclaimer in the; # documentation and/or other materials provided with the distribution.; #; # 3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for VcfWriter CLIF python wrappers.""""""; """"""Tests writing all the variants that are 'canned' in our tfrecord file.""""""; # This file is in the TF record format; # Check: are the variants written as expected?; # pylint: disable=line-too-long; # pylint: enable=line-too-long; # Out of order.; # Writing within the context manager succeeds.; # self.writer should be closed, so writing again will fail.; # Writing within the context manager succeeds.; # Entering the closed writer should be fine.; # We want to raise an error on exit, so nothing to do in context.; # Round-trip variants through writing and reading:; # 1. Read variants v1 from VcfReader;; # 2. Write v1 to vcf using our VcfWriter;; # 3. Read back in using VcfReader -- v2;; # 4. compare v1 and v2.",MatchSource.CODE_COMMENT,third_party/nucleus/io/python/vcf_writer_wrap_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/python/vcf_writer_wrap_test.py
Integrability,wrap,wrappers,"lowing disclaimer.; #; # 2. Redistributions in binary form must reproduce the above copyright; # notice, this list of conditions and the following disclaimer in the; # documentation and/or other materials provided with the distribution.; #; # 3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for VcfWriter CLIF python wrappers.""""""; """"""Tests writing all the variants that are 'canned' in our tfrecord file.""""""; # This file is in the TF record format; # Check: are the variants written as expected?; # pylint: disable=line-too-long; # pylint: enable=line-too-long; # Out of order.; # Writing within the context manager succeeds.; # self.writer should be closed, so writing again will fail.; # Writing within the context manager succeeds.; # Entering the closed writer should be fine.; # We want to raise an error on exit, so nothing to do in context.; # Round-trip variants through writing and reading:; # 1. Read variants v1 from VcfReader;; # 2. Write v1 to vcf using our VcfWriter;; # 3. Read back in using VcfReader -- v2;; # 4. compare v1 and v2.",MatchSource.CODE_COMMENT,third_party/nucleus/io/python/vcf_writer_wrap_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/python/vcf_writer_wrap_test.py
Availability,failure,failure," HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Fake setup.py module for installing Nucleus. Usually, setup.py is invoked twice: first, to build the pip package; and second to install it. This setup.py is only used for installation; build_pip_package.sh is; used to create the package. We do it this way because we need our; package to include symbolic links, which normal setup.py doesn't; support. For the same reason, this setup.py is not implemented using setuptools.; Instead, we directly implement the four commands run by pip install; (https://pip.pypa.io/en/stable/reference/pip_install/#id46):; * setup.py egg_info [--egg-base XXX]; * setup.py install --record XXX [--single-version-externally-managed]; [--root XXX] [--compile|--no-compile] [--install-headers XXX]; * setup.py bdist_wheel -d XXX; * setup.py clean; """"""; # Basename of the .egg-info directory.; """"""Returns the directory we are supposed to install into.""""""; """"""Copies the .egg-info directory to the specified location. Args:; dest_dir: str. The destination directory. Returns:; 0 on success, 1 on failure.; """"""; # Remove any trailing slash on the destination directory.; # Append the .egg-info directory (must include trailing '/') to the record.; # End by copying the .egg-info directory to the destination.; # Nothing to do",MatchSource.CODE_COMMENT,third_party/nucleus/pip_package/setup.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/pip_package/setup.py
Deployability,install,installing,"of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Fake setup.py module for installing Nucleus. Usually, setup.py is invoked twice: first, to build the pip package; and second to install it. This setup.py is only used for installation; build_pip_package.sh is; used to create the package. We do it this way because we need our; package to include symbolic links, which normal setup.py doesn't; support. For the same reason, this setup.py is not implemented using setuptools.; Instead, we directly implement the four commands run by pip install; (https://pip.pypa.io/en/stable/reference/pip_install/#id46):; * setup.py egg_info [--egg-base XXX]; * setup.py install --record XXX [--single-version-externally-managed]; [--root XXX] [--compile|--no-compile] [--install-headers XXX]; * setup.py bdist_wheel -d XXX; * setup.py clean; """"""; # Basename of the .egg-info directory.; """"""Returns the directory we are supposed to install into.""""""; """"""Copies the .egg-info directory to the specified location. Args:; dest_dir: str. The destination directory. Returns:; 0 on success, 1 on failu",MatchSource.CODE_COMMENT,third_party/nucleus/pip_package/setup.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/pip_package/setup.py
Testability,test,testing,"# Copyright 2018 Google LLC.; #; # Redistribution and use in source and binary forms, with or without; # modification, are permitted provided that the following conditions; # are met:; #; # 1. Redistributions of source code must retain the above copyright notice,; # this list of conditions and the following disclaimer.; #; # 2. Redistributions in binary form must reproduce the above copyright; # notice, this list of conditions and the following disclaimer in the; # documentation and/or other materials provided with the distribution.; #; # 3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Test that our protobuf implementation behaves as we'd expect.""""""; # This next import is unused, but we are testing that any program; # which includes a Nucleus library uses the cpp protobuf; # implementation.; # pylint: disable=unused-import; """"""Checks that our protobufs have the properties we expect.""""""; """"""Checks that we are using the fast cpp version of python protobufs.""""""",MatchSource.CODE_COMMENT,third_party/nucleus/testing/protobuf_implementation_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/protobuf_implementation_test.py
Deployability,install,installation,"# Copyright 2018 Google LLC.; #; # Redistribution and use in source and binary forms, with or without; # modification, are permitted provided that the following conditions; # are met:; #; # 1. Redistributions of source code must retain the above copyright notice,; # this list of conditions and the following disclaimer.; #; # 2. Redistributions in binary form must reproduce the above copyright; # notice, this list of conditions and the following disclaimer in the; # documentation and/or other materials provided with the distribution.; #; # 3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Test that our Nucleus installation does not cause issues with TensorFlow.""""""; """"""Checks that Nucleus and TensorFlow interact well together.""""""; """"""Checks that we can import TensorFlow.""""""; # N.B. This test is only invoked when testing the pip package.",MatchSource.CODE_COMMENT,third_party/nucleus/testing/tensorflow_smoke_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/tensorflow_smoke_test.py
Testability,test,test,"# Copyright 2018 Google LLC.; #; # Redistribution and use in source and binary forms, with or without; # modification, are permitted provided that the following conditions; # are met:; #; # 1. Redistributions of source code must retain the above copyright notice,; # this list of conditions and the following disclaimer.; #; # 2. Redistributions in binary form must reproduce the above copyright; # notice, this list of conditions and the following disclaimer in the; # documentation and/or other materials provided with the distribution.; #; # 3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Test that our Nucleus installation does not cause issues with TensorFlow.""""""; """"""Checks that Nucleus and TensorFlow interact well together.""""""; """"""Checks that we can import TensorFlow.""""""; # N.B. This test is only invoked when testing the pip package.",MatchSource.CODE_COMMENT,third_party/nucleus/testing/tensorflow_smoke_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/tensorflow_smoke_test.py
Deployability,patch,patch,"le_names: A list of strs or None. Must match the gts arg if specified.; Sets the call_set_name of the corresponding VariantCall.; glss: A list of array-lists of float, or None. Must match the gts arg if; specified. Sets the genotype_likelihoods of the corresponding VariantCall.; is_phased: list of bools. Must match the gts arg if specified. Indicates; whether the corresponding VariantCall should be phased.; ad: list of allelic depths. These are added together to calculate DP. Returns:; nucleus.genomics.v1.Variant proto.; """"""; """"""Makes a nucleus.genomics.v1.Read for testing.""""""; """"""Count the number of elements in an Iterable object. Args:; cc_iterable: a CLIF-wrap of a subclass of the C++ Iterable class. Returns:; integer count; """"""; """"""Returns the length of a Python iterable, by advancing it.""""""; # TODO: remove and replace uses when bug is fixed in mock.; """"""Asserts that a mock has not been called. There's a bug in mock where some of the assert functions on a mock are being; dropped when that mock is created with an autospec:. https://bugs.python.org/issue28380. The mock 2.0.0 backport doesn't have the fix yet. The required patch is:. https://bugs.python.org/file44991/fix_autospecced_mock_functions.patch. but the current mock (checked 07/22/17) backport code is missing the fix:. https://github.com/testing-cabal/mock/blob/master/mock/mock.py#L315. This is an open issue on the mock github repo:. https://github.com/testing-cabal/mock/issues/398. And they claim that it'll be a few months (as of April 2017) before it is; incorporated into the backport. Args:; mock: The mock to assert hasn't been called. Raises:; AssertionError: mock has been called.; """"""; # TODO: remove and replace uses when bug is fixed in mock.; """"""Asserts that a mock has been called exactly once. See assert_not_called_workaround for the backstory on why this function; exists. Args:; mock: The mock that should have been called exactly once. Raises:; AssertionError: mock wasn't called exactly once.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/testing/test_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py
Integrability,rout,routine,", BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Utilities to help with testing code.""""""; # In the OSS version these will be ''.; # In the OSS version this becomes 'nucleus/testdata'; """"""Gets the path to a testdata file in genomics at relative path. Args:; path: A path to a testdata file *relative* to the genomics root; directory. For example, if you have a test file in; ""datadir/nucleus/testdata/foo.txt"", path should be; ""nucleus/testdata/foo.txt"" to get a path to it.; datadir: The path of the genomics root directory *relative* to; the testing source directory. Returns:; The absolute path to a testdata file.; """"""; # Google code uses FLAG.test_srcdir; # TensorFlow uses a routine googletest.test_src_dir_path.; # In bazel TEST_SRCDIR points at the runfiles directory, and; # TEST_WORKSPACE names the workspace. We need to append to the; # path the name of the workspace in order to get to the root of our; # source tree.; # TODO: is this necessary?; """"""Gets the path to a testdata named filename in util/testdata. Args:; filename: The name of a testdata file in the core genomics testdata; directory. For example, if you have a test file in; ""third_party/nucleus/util/testdata/foo.txt"", filename should be; ""foo.txt"" to get a path to it. Returns:; The absolute path to a testdata file.; """"""; """"""Returns a path to a tempfile named name in the test_tmpdir. Args:; name: str; the name of the file, should not contain any slashes.; contents: bytes, or None. If not None, tmpfile's contents will be set to; contents before returning the path. Returns:; str path to a tmpfile with filename name in our test tmpfile directory.; """"""; """"""Sets a ListValue to have the values ",MatchSource.CODE_COMMENT,third_party/nucleus/testing/test_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py
Modifiability,extend,extend,"SRCDIR points at the runfiles directory, and; # TEST_WORKSPACE names the workspace. We need to append to the; # path the name of the workspace in order to get to the root of our; # source tree.; # TODO: is this necessary?; """"""Gets the path to a testdata named filename in util/testdata. Args:; filename: The name of a testdata file in the core genomics testdata; directory. For example, if you have a test file in; ""third_party/nucleus/util/testdata/foo.txt"", filename should be; ""foo.txt"" to get a path to it. Returns:; The absolute path to a testdata file.; """"""; """"""Returns a path to a tempfile named name in the test_tmpdir. Args:; name: str; the name of the file, should not contain any slashes.; contents: bytes, or None. If not None, tmpfile's contents will be set to; contents before returning the path. Returns:; str path to a tmpfile with filename name in our test tmpfile directory.; """"""; """"""Sets a ListValue to have the values in values.""""""; # list_value.values.extend(vals); """"""Creates a new Variant proto from args. Args:; chrom: str. The reference_name for this variant.; start: int. The starting position of this variant.; alleles: list of str with at least one element. alleles[0] is the reference; bases and alleles[1:] will be set to alternate_bases of variant. If None,; defaults to ['A', 'C'].; end: int or None. If not None, the variant's end will be set to this value.; If None, will be set to the start + len(reference_bases).; filters: str, list of str, or None. Sets the filters field of the variant to; this value if not None. If filters is a string `value`, this is equivalent; to an argument [`value`]. If None, no value will be assigned to the; filters field.; qual: int or None. The quality score for this variant. If None, no quality; score will be written in the Variant.; gt: A list of ints, or None. If present, creates a VariantCall in Variant; with genotype field set to this value. The special 'DEFAULT' value, if; provided, will set the genotype to [0, 1]. This i",MatchSource.CODE_COMMENT,third_party/nucleus/testing/test_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py
Testability,test,testing,"er the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Utilities to help with testing code.""""""; # In the OSS version these will be ''.; # In the OSS version this becomes 'nucleus/testdata'; """"""Gets the path to a testdata file in genomics at relative path. Args:; path: A path to a testdata file *relative* to the genomics root; directory. For example, if you have a test file in; ""datadir/nucleus/testdata/foo.txt"", path should be; ""nucleus/testdata/foo.txt"" to get a path to it.; datadir: The path of the genomics root directory *relative* to; the testing source directory. Returns:; The absolute path to a testdata file.; """"""; # Google code uses FLAG.test_srcdir; # TensorFlow uses a routine googletest.test_src_dir_path.; # In bazel TEST_SRCDIR points at the runfiles directory, and; # TEST_WORKSPACE names the workspace. We need to append to the; # path the name of the workspace in order to get to the root of our; # source tree.; # TODO: is this necessary?; """"""Gets the path to a testdata named filename in util/testdata. Args:; filename: The name of a testdata fil",MatchSource.CODE_COMMENT,third_party/nucleus/testing/test_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py
Testability,test,testing,"# Copyright 2018 Google LLC.; #; # Redistribution and use in source and binary forms, with or without; # modification, are permitted provided that the following conditions; # are met:; #; # 1. Redistributions of source code must retain the above copyright notice,; # this list of conditions and the following disclaimer.; #; # 2. Redistributions in binary form must reproduce the above copyright; # notice, this list of conditions and the following disclaimer in the; # documentation and/or other materials provided with the distribution.; #; # 3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for nucleus's testing.test_utils.""""""",MatchSource.CODE_COMMENT,third_party/nucleus/testing/test_utils_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils_test.py
Availability,avail,available," endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Utility functions for working with alignment CIGAR operations. The CIGAR format is defined within the SAM spec, available at; https://samtools.github.io/hts-specs/SAMv1.pdf. This module provides utility functions for interacting with the parsed; representations of CIGAR strings.; """"""; # A frozenset of all CigarUnit.Operation enum values that advance the alignment; # with respect to the reference genome and read, respectively.; # A map from CigarUnit.Operation (e.g., CigarUnit.ALIGNMENT_MATCH) enum values; # to their corresponding single character cigar codes (e.g., 'M').; # A map from single character cigar codes (e.g., 'M') to their corresponding; # CigarUnit.Operation (e.g., CigarUnit.ALIGNMENT_MATCH) enum values.; # All of the CigarUnit.Operation values in a frozen set.; # Regular expression that matches only valid full cigar strings.; # Regular expression that matches a single len/op cigar element. The match is; # grouped, so CIGAR_STR_SPLITTER_RE.finditer(cigar_str) returns grouped units; # of the cigar string in order.; """"""Returns the string version of an iterable of CigarUnit pro",MatchSource.CODE_COMMENT,third_party/nucleus/util/cigar.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/cigar.py
Integrability,wrap,wrapped,"s; # are met:; #; # 1. Redistributions of source code must retain the above copyright notice,; # this list of conditions and the following disclaimer.; #; # 2. Redistributions in binary form must reproduce the above copyright; # notice, this list of conditions and the following disclaimer in the; # documentation and/or other materials provided with the distribution.; #; # 3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for cigar.""""""; # Check we can convert a tuple and list of length and opstr.; # Check that we can convert a string version len+opstr.; # Check that we can pass a CigarUnit through without modification.; # Check that we can pass length as a string.; # Have to be wrapped in a list to stop parameterized from treating the; # tuple as the positional arguments to the test function.; # This integer is too large to fit in an int64 cigar, make sure an; # exception is thrown. Max int64 is 9,223,372,036,854,775,807, so we try; # one more.; # We can convert the raw form.; # We can also convert the string form by formatting actual.",MatchSource.CODE_COMMENT,third_party/nucleus/util/cigar_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/cigar_test.py
Modifiability,parameteriz,parameterized,"s; # are met:; #; # 1. Redistributions of source code must retain the above copyright notice,; # this list of conditions and the following disclaimer.; #; # 2. Redistributions in binary form must reproduce the above copyright; # notice, this list of conditions and the following disclaimer in the; # documentation and/or other materials provided with the distribution.; #; # 3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for cigar.""""""; # Check we can convert a tuple and list of length and opstr.; # Check that we can convert a string version len+opstr.; # Check that we can pass a CigarUnit through without modification.; # Check that we can pass length as a string.; # Have to be wrapped in a list to stop parameterized from treating the; # tuple as the positional arguments to the test function.; # This integer is too large to fit in an int64 cigar, make sure an; # exception is thrown. Max int64 is 9,223,372,036,854,775,807, so we try; # one more.; # We can convert the raw form.; # We can also convert the string form by formatting actual.",MatchSource.CODE_COMMENT,third_party/nucleus/util/cigar_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/cigar_test.py
Testability,test,test,"s; # are met:; #; # 1. Redistributions of source code must retain the above copyright notice,; # this list of conditions and the following disclaimer.; #; # 2. Redistributions in binary form must reproduce the above copyright; # notice, this list of conditions and the following disclaimer in the; # documentation and/or other materials provided with the distribution.; #; # 3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for cigar.""""""; # Check we can convert a tuple and list of length and opstr.; # Check that we can convert a string version len+opstr.; # Check that we can pass a CigarUnit through without modification.; # Check that we can pass length as a string.; # Have to be wrapped in a list to stop parameterized from treating the; # tuple as the positional arguments to the test function.; # This integer is too large to fit in an int64 cigar, make sure an; # exception is thrown. Max int64 is 9,223,372,036,854,775,807, so we try; # one more.; # We can convert the raw form.; # We can also convert the string form by formatting actual.",MatchSource.CODE_COMMENT,third_party/nucleus/util/cigar_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/cigar_test.py
Availability,error,errors," the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Library of application-specific errors.; """"""; """"""Base class for core error types.""""""; """"""Exception class related to invalid command-line flags.""""""; """"""Logs the given message at ERROR level and raises exception. Args:; msg: [`string`]. The message to log and use in the raised exception.; exception_class: [`Exception`]. The class of exception to raise. Raises:; Error: An exception of the type specified by the input exception_class.; """"""; """"""Wraps commands to capture certain exceptions and exit without stacktraces. This function is intended to wrap all code within main() of Python binaries; to provide a mechanism for user errors to exit abnormally without causing; exceptions to be thrown. Any exceptions that are subclasses of those listed; in `allowed_exceptions` will be caught and the program will quietly exit with; `exit_value`. Other exceptions are propagated normally. NOTE: This function should only be used as a context manager and its usage; should be limited to main(). Args:; allowed_exceptions: [`t",MatchSource.CODE_COMMENT,third_party/nucleus/util/errors.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/errors.py
Integrability,message,message,"c prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Library of application-specific errors.; """"""; """"""Base class for core error types.""""""; """"""Exception class related to invalid command-line flags.""""""; """"""Logs the given message at ERROR level and raises exception. Args:; msg: [`string`]. The message to log and use in the raised exception.; exception_class: [`Exception`]. The class of exception to raise. Raises:; Error: An exception of the type specified by the input exception_class.; """"""; """"""Wraps commands to capture certain exceptions and exit without stacktraces. This function is intended to wrap all code within main() of Python binaries; to provide a mechanism for user errors to exit abnormally without causing; exceptions to be thrown. Any exceptions that are subclasses of those listed; in `allowed_exceptions` will be caught and the program will quietly exit with; `exit_value`. Other exceptions are propagated normally. NOTE: This function should only be used as a context manager and its usage; should be limited to main(). Args:; allowed_exceptions: [`tuple of Exception`]. A tuple of Exception classes; that should not be raised, but instead quietly caused to exit the program.; exit_value: [`int`]. The value to",MatchSource.CODE_COMMENT,third_party/nucleus/util/errors.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/errors.py
Testability,log,log," AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Library of application-specific errors.; """"""; """"""Base class for core error types.""""""; """"""Exception class related to invalid command-line flags.""""""; """"""Logs the given message at ERROR level and raises exception. Args:; msg: [`string`]. The message to log and use in the raised exception.; exception_class: [`Exception`]. The class of exception to raise. Raises:; Error: An exception of the type specified by the input exception_class.; """"""; """"""Wraps commands to capture certain exceptions and exit without stacktraces. This function is intended to wrap all code within main() of Python binaries; to provide a mechanism for user errors to exit abnormally without causing; exceptions to be thrown. Any exceptions that are subclasses of those listed; in `allowed_exceptions` will be caught and the program will quietly exit with; `exit_value`. Other exceptions are propagated normally. NOTE: This function should only be used as a context manager and its usage; should be limited to main(). Args:; allowed_exceptions: [`tuple of Exception`]. A tuple of Exception classes; that should not be raised, but instead quietly caused to exit the program.; exit_value: [`int`]. The value to return upon program exit. Yields:; The yield in this function is used to allow the",MatchSource.CODE_COMMENT,third_party/nucleus/util/errors.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/errors.py
Availability,error,errors,"# Copyright 2018 Google LLC.; #; # Redistribution and use in source and binary forms, with or without; # modification, are permitted provided that the following conditions; # are met:; #; # 1. Redistributions of source code must retain the above copyright notice,; # this list of conditions and the following disclaimer.; #; # 2. Redistributions in binary form must reproduce the above copyright; # notice, this list of conditions and the following disclaimer in the; # documentation and/or other materials provided with the distribution.; #; # 3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for third_party.nucleus.util.errors.""""""",MatchSource.CODE_COMMENT,third_party/nucleus/util/errors_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/errors_test.py
Availability,avail,available,"formation. Briefly, the Phred-scale maintains resolution in the lower; parts of the probability space using integer quality scores (though using; ints is optional, really). The phred-scale is defined as. `phred(p) = -10 * log10(p)`. where p is a real-space probability. The functions in math.h dealing with probabilities are very explicit about what; kinds of probability and representation they expect and return, as unfortunately; these are all commonly represented as doubles in C++. Though it is tempting to; address this issue with classic software engineering practices like creating; a Probability class, in practice this is extremely difficult to do as this; code is often performance critical and the low-level mathematical operations; used in this code (e.g., log10) don't distiguish themselves among the types; of probabilities.; """"""; # C++ CLIF functions:; #; # We are enumerating the C++ functions exported by python/math.clif here, so; # it's clear to people what functions are available in python without digging; # into the raw python/C++ CLIF code.; # Maximum confidence in a variant call. Used to prevent overflow with log10.; # Note: -10 * log_10(1.25e-10) ~= 99.; """"""Computes log10(p) for the given probability. The log10 probability is capped by -_MAX_CONFIDENCE. Args:; perror: float. The probability to log10.; min_prob: float. The minimum allowed probability. Returns:; log10(p). Raises:; ValueError: If probability is outside of [0.0, 1.0].; """"""; """"""Computes the Phred-scaled confidence from the given ptrue probability. See https://en.wikipedia.org/wiki/Phred_quality_score for more information.; The quality score is capped by _MAX_CONFIDENCE. Args:; ptrue: float. The ptrue probability to Phred scale.; max_prob: float. The maximum allowed probability. Returns:; Phred-scaled version of 1 - ptrue. Raises:; ValueError: If ptrue is outside of [0.0, 1.0].; """"""; """"""Calculates numerically-stable value of log10(binomial(k, n, p)). Returns the log10 of the binomial density fo",MatchSource.CODE_COMMENT,third_party/nucleus/util/genomics_math.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/genomics_math.py
Integrability,depend,dependent," POSSIBILITY OF SUCH DAMAGE.; """"""Mathematics functions for working with genomics data. A quick note on terminology here. There are a bunch kinds of probabilities used commonly in genomics:. -- pError: the probability of being wrong.; -- pTrue: the probability of being correct. Normalized probabilities vs. unnormalized likelihoods:. -- Normalized probabilities: p_1, ..., p_n such that sum(p_i) == 1 are said; said to be normalized because they represent a valid probability; distribution over the states 1 ... n.; -- Unnormalized likelihoods: p_1, ..., p_n where sum(p_i) != 1. These are not; normalized and so aren't a valid probabilities distribution. To add even more complexity, probabilities are often represented in three; semi-equivalent spaces:. -- Real-space: the classic space, with values ranging from [0.0, 1.0]; inclusive.; -- log10-space: If p is the real-space value, in log10-space this would be; represented as log10(p). How the p == 0 case is handled is often function; dependent, which may accept/return -Inf or not handle the case entirely.; -- Phred-scaled: See https://en.wikipedia.org/wiki/Phred_quality_score for; more information. Briefly, the Phred-scale maintains resolution in the lower; parts of the probability space using integer quality scores (though using; ints is optional, really). The phred-scale is defined as. `phred(p) = -10 * log10(p)`. where p is a real-space probability. The functions in math.h dealing with probabilities are very explicit about what; kinds of probability and representation they expect and return, as unfortunately; these are all commonly represented as doubles in C++. Though it is tempting to; address this issue with classic software engineering practices like creating; a Probability class, in practice this is extremely difficult to do as this; code is often performance critical and the low-level mathematical operations; used in this code (e.g., log10) don't distiguish themselves among the types; of probabilities.; """"""; # C++ CL",MatchSource.CODE_COMMENT,third_party/nucleus/util/genomics_math.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/genomics_math.py
Performance,perform,performance,"e classic space, with values ranging from [0.0, 1.0]; inclusive.; -- log10-space: If p is the real-space value, in log10-space this would be; represented as log10(p). How the p == 0 case is handled is often function; dependent, which may accept/return -Inf or not handle the case entirely.; -- Phred-scaled: See https://en.wikipedia.org/wiki/Phred_quality_score for; more information. Briefly, the Phred-scale maintains resolution in the lower; parts of the probability space using integer quality scores (though using; ints is optional, really). The phred-scale is defined as. `phred(p) = -10 * log10(p)`. where p is a real-space probability. The functions in math.h dealing with probabilities are very explicit about what; kinds of probability and representation they expect and return, as unfortunately; these are all commonly represented as doubles in C++. Though it is tempting to; address this issue with classic software engineering practices like creating; a Probability class, in practice this is extremely difficult to do as this; code is often performance critical and the low-level mathematical operations; used in this code (e.g., log10) don't distiguish themselves among the types; of probabilities.; """"""; # C++ CLIF functions:; #; # We are enumerating the C++ functions exported by python/math.clif here, so; # it's clear to people what functions are available in python without digging; # into the raw python/C++ CLIF code.; # Maximum confidence in a variant call. Used to prevent overflow with log10.; # Note: -10 * log_10(1.25e-10) ~= 99.; """"""Computes log10(p) for the given probability. The log10 probability is capped by -_MAX_CONFIDENCE. Args:; perror: float. The probability to log10.; min_prob: float. The minimum allowed probability. Returns:; log10(p). Raises:; ValueError: If probability is outside of [0.0, 1.0].; """"""; """"""Computes the Phred-scaled confidence from the given ptrue probability. See https://en.wikipedia.org/wiki/Phred_quality_score for more information.; The",MatchSource.CODE_COMMENT,third_party/nucleus/util/genomics_math.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/genomics_math.py
Safety,risk,risks,"ulting array is sum(10^result) ~= 1.0. The ~=; indicates that the result is not necessarily == 1.0 but very close. This function is a fast and robust approximation of the true normalization of; a log10 transformed probability vector. To understand the approximation,; let's start with the exact calculation. Suppose I have three models, each; emitting a probability that some data was generated by that model:. data = {0.1, 0.01, 0.001} => probabilities from models A, B, and C. These probabilities are unnormalized, in the sense that the total probability; over the vector doesn't sum to 1 (sum(data) = 0.111). In many applications we; want to normalize this vector so that sum(normalized(data)) = 1 and the; relative magnitudes of the original probabilities are preserved (i.e,:. data[i] / data[j] = normalized(data)[i] / normalized(data)[j]. for all pairs of values indexed by i and j. For much of the work we do in; genomics, we have so much data that representing these raw probability; vectors in real-space risks numeric underflow/overflow, so we instead; represent our probability vectors in log10 space:. log10_data = log10(data) = {-1, -2, -3}. Given that we expect numeric problems in real-space, normalizing this log10; vector is hard, because the standard way you'd do the normalization is via:. data[i] = data[i] / sum(data); log10_data[i] = log10_data[i] - log10(sum(10^data)). But computing the sum of log10 values this way is dangerous because the naive; implementation converts back to real-space to do the sum, the very operation; we're trying to avoid due to numeric instability. This function implements an approximate normalization, which relaxes the need; for an exact calculation of the sum. This function ensures that the; normalization is numerically safe at the expense of the sum not being exactly; equal to 1 but rather just close. Args:; log10_probs: array-like of floats. An array of log10 probabilties. Returns:; np.array with the same shape as log10_probs but where su",MatchSource.CODE_COMMENT,third_party/nucleus/util/genomics_math.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/genomics_math.py
Testability,log,log,"0.; min_prob: float. The minimum allowed probability. Returns:; log10(p). Raises:; ValueError: If probability is outside of [0.0, 1.0].; """"""; """"""Computes the Phred-scaled confidence from the given ptrue probability. See https://en.wikipedia.org/wiki/Phred_quality_score for more information.; The quality score is capped by _MAX_CONFIDENCE. Args:; ptrue: float. The ptrue probability to Phred scale.; max_prob: float. The maximum allowed probability. Returns:; Phred-scaled version of 1 - ptrue. Raises:; ValueError: If ptrue is outside of [0.0, 1.0].; """"""; """"""Calculates numerically-stable value of log10(binomial(k, n, p)). Returns the log10 of the binomial density for k successes in n trials where; each success has a probability of occurring of p. In real-space, we would calculate:. result = (n choose k) * (1-p)^(n-k) * p^k. This function computes the log10 of result, which is:. log10(result) = log10(n choose k) + (n-k) * log10(1-p) + k * log10(p). This is equivalent to invoking the R function:; dbinom(x=k, size=n, prob=p, log=TRUE). See https://stat.ethz.ch/R-manual/R-devel/library/stats/html/Binomial.html; for more details on the binomial. Args:; k: int >= 0. Number of successes.; n: int >= k. Number of trials.; p: 0.0 <= float <= 1.0. Probability of success. Returns:; log10 probability of seeing k successes in n trials with p.; """"""; """"""Returns log10(sum(10^log10_probs)) computed in a numerically-stable way. Args:; log10_probs: array-like of floats. An array of log10 probabilties. Returns:; Float.; """"""; """"""Approximately normalizes log10 probabilities. This function normalizes log10 probabilities. What this means is that we; return an equivalent array of probabilities but whereas sum(10^log10_probs) is; not necessarily 1.0, the resulting array is sum(10^result) ~= 1.0. The ~=; indicates that the result is not necessarily == 1.0 but very close. This function is a fast and robust approximation of the true normalization of; a log10 transformed probability vector. To underst",MatchSource.CODE_COMMENT,third_party/nucleus/util/genomics_math.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/genomics_math.py
Usability,clear,clear,"formation. Briefly, the Phred-scale maintains resolution in the lower; parts of the probability space using integer quality scores (though using; ints is optional, really). The phred-scale is defined as. `phred(p) = -10 * log10(p)`. where p is a real-space probability. The functions in math.h dealing with probabilities are very explicit about what; kinds of probability and representation they expect and return, as unfortunately; these are all commonly represented as doubles in C++. Though it is tempting to; address this issue with classic software engineering practices like creating; a Probability class, in practice this is extremely difficult to do as this; code is often performance critical and the low-level mathematical operations; used in this code (e.g., log10) don't distiguish themselves among the types; of probabilities.; """"""; # C++ CLIF functions:; #; # We are enumerating the C++ functions exported by python/math.clif here, so; # it's clear to people what functions are available in python without digging; # into the raw python/C++ CLIF code.; # Maximum confidence in a variant call. Used to prevent overflow with log10.; # Note: -10 * log_10(1.25e-10) ~= 99.; """"""Computes log10(p) for the given probability. The log10 probability is capped by -_MAX_CONFIDENCE. Args:; perror: float. The probability to log10.; min_prob: float. The minimum allowed probability. Returns:; log10(p). Raises:; ValueError: If probability is outside of [0.0, 1.0].; """"""; """"""Computes the Phred-scaled confidence from the given ptrue probability. See https://en.wikipedia.org/wiki/Phred_quality_score for more information.; The quality score is capped by _MAX_CONFIDENCE. Args:; ptrue: float. The ptrue probability to Phred scale.; max_prob: float. The maximum allowed probability. Returns:; Phred-scaled version of 1 - ptrue. Raises:; ValueError: If ptrue is outside of [0.0, 1.0].; """"""; """"""Calculates numerically-stable value of log10(binomial(k, n, p)). Returns the log10 of the binomial density fo",MatchSource.CODE_COMMENT,third_party/nucleus/util/genomics_math.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/genomics_math.py
Safety,safe,safety," CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for third_party.nucleus.util.genomics_math.""""""; # Check that bounding works.; # Check that bounding works.; # A huge negative value is handled correctly.; # Check that we can pass in a 0.0 probability and get a good value.; # This probability is still calculated correctly, included for safety.; # Pass in a prob close to one, making sure we get bound value back.; # R code to produce the expectation table.; # expected <- function(k, n, p) {; # pbin <- dbinom(k, n, p, log=T) * log10(exp(1)); # likelihoods = paste(sprintf(""%.6f"", pbin), collapse="", ""); # result = paste(k, n, p, pbin, sep="", ""); # cat(paste(""("", result, ""),\n"", sep="""")); # }; #; # for (n in c(0, 5, 10)) {; # for (k in seq(0, n)) {; # for (p in c(0.01, 0.5)) {; # expected(k, n, p); # }; # }; # }; # expected(0, 1000, 0.5); # expected(0, 10000, 0.5); # expected(100, 10000, 0.5); # R code to compute expected results.; # expected <- function(lprobs) {; # result = lprobs - log10(sum(10^lprobs)); # lprob_str = paste(""["", paste(sprintf(""%.6f"", lprobs), collapse="", ""),; # ""]"", sep=""""); # result_str = paste(""["", paste(sprintf(""%.6f"", result), collapse="", ""),; # ""]"", sep=""""); # cat(paste(""("", lprob_str, "", "", result_str, ""),\n"", sep="""")); # }; #; # expected(c(0)); # expected(c(-1, -10));",MatchSource.CODE_COMMENT,third_party/nucleus/util/genomics_math_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/genomics_math_test.py
Testability,log,log," NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for third_party.nucleus.util.genomics_math.""""""; # Check that bounding works.; # Check that bounding works.; # A huge negative value is handled correctly.; # Check that we can pass in a 0.0 probability and get a good value.; # This probability is still calculated correctly, included for safety.; # Pass in a prob close to one, making sure we get bound value back.; # R code to produce the expectation table.; # expected <- function(k, n, p) {; # pbin <- dbinom(k, n, p, log=T) * log10(exp(1)); # likelihoods = paste(sprintf(""%.6f"", pbin), collapse="", ""); # result = paste(k, n, p, pbin, sep="", ""); # cat(paste(""("", result, ""),\n"", sep="""")); # }; #; # for (n in c(0, 5, 10)) {; # for (k in seq(0, n)) {; # for (p in c(0.01, 0.5)) {; # expected(k, n, p); # }; # }; # }; # expected(0, 1000, 0.5); # expected(0, 10000, 0.5); # expected(100, 10000, 0.5); # R code to compute expected results.; # expected <- function(lprobs) {; # result = lprobs - log10(sum(10^lprobs)); # lprob_str = paste(""["", paste(sprintf(""%.6f"", lprobs), collapse="", ""),; # ""]"", sep=""""); # result_str = paste(""["", paste(sprintf(""%.6f"", result), collapse="", ""),; # ""]"", sep=""""); # cat(paste(""("", lprob_str, "", "", result_str, ""),\n"", sep="""")); # }; #; # expected(c(0)); # expected(c(-1, -10)); # expected(c(-1, -100)); # expected(c(-1, -1000)); # expected(c(-1, -2)); # expected(c(-1, -2, -3)); # expected(c(-1, -2, -3, -100)); # expected(c(-1, -2, -100)); # expected(c(-1, -2, -100, -100))",MatchSource.CODE_COMMENT,third_party/nucleus/util/genomics_math_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/genomics_math_test.py
Availability,error,error,"# Copyright 2018 Google LLC.; #; # Redistribution and use in source and binary forms, with or without; # modification, are permitted provided that the following conditions; # are met:; #; # 1. Redistributions of source code must retain the above copyright notice,; # this list of conditions and the following disclaimer.; #; # 2. Redistributions in binary form must reproduce the above copyright; # notice, this list of conditions and the following disclaimer in the; # documentation and/or other materials provided with the distribution.; #; # 3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Utility library for working with protobufs.""""""; """"""Raises an error if a slow protobuf implementation is being used.""""""",MatchSource.CODE_COMMENT,third_party/nucleus/util/proto_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/proto_utils.py
Deployability,update,update,"T NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Utilities for Range overlap detection.""""""; # Regular expressions for matching literal chr:start-stop strings.; # Regular expressions for matching literal chr:start strings.; # Logging frequency when building our rangeset objects, which can take some time; # to complete. Rather than just pausing for a few minutes, we provide an update; # logging message every _LOG_EVERY_N_RANGES_IN_RANGESET_INIT records added. See; # internal for more information.; """"""Fast overlap detection of a genomic position against a database of Ranges. Enables O(log n) computation of whether a point chr:pos falls within one of a; large number of genomic ranges. This class does not supports overlapping or adjacent intervals. Any such; intervals will be automatically merged together in the constructor. This class is immutable. No methods should be added that directly modify the; ranges held by the class.; """"""; """"""Creates a RangeSet backed by ranges. Note that the Range objects in ranges are *not* stored directly here, so; they can safely be modified after they are passed to this RangeSet. Args:; ranges: list(nucleus.genomics.v1.Range) protos (or anything with; reference_name, start, and end properties following the Range; convention). If None, no ranges will be used, and overlaps() will always; return False.; contigs: list(nucleus.genomics.v1.ContigI",MatchSource.CODE_COMMENT,third_party/nucleus/util/ranges.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/ranges.py
Energy Efficiency,allocate,allocated,"*others, returning a RangeSet containing only intervals common to all. The; intersection here is an ranged intersection, not an identity intersection,; so the resulting set of intervals may not contain any of the original; intervals in any of the sets. To be concrete, suppose we have three sets to intersect, each having two; intervals:. self : chr1:1-10, chr2:20-30; other1 : chr1:5-8, chr3:10-40; other2 : chr1:3-7, chr3:10-30. self.intersection(other1, other2) produces a RangeSet with one interval; chr1:5-7, the common bases on chr1 in self, other1, and other2. No intervals; on chr2 or chr3 are included since the chr2 only occurs in self and the two; intervals on chr3, despite having some shared bases, don't have an; overlapping interval in self. Args:; *others: A list of RangeSet objects to intersect with the intervals in; this RangeSet. Returns:; A RangeSet. If *others is empty, this function returns self rather than; making an unnecessary copy. In all other cases, the returned value will be; a freshly allocated RangeSet.; """"""; """"""Intersects the intervals of two IntervalTrees.""""""; # Yields all of the overlapping intervals from each interval of tree1; # found in tree2. Since each tree has only non-adjacent, non-overlapping,; # intervals this calculation is straightforward and safe and produces only; # non-adjacent, non-overlapping intervals.; # Iteratively intersect each of our *other RangeSets with this RangeSet.; # Sort by size so we do the smallest number of element merge first.; # TODO: Note we could optimize this code by computing the set of; # common contigs upfront across all others and only looping over those.; # pylint: disable=protected-access; # So we can intersect intervals within each contig separately.; # If refname is present in other, intersect those two IntervalTrees; # directly and add those contigs to our growing list of intersected; # intervals. If refname isn't present, all of the intervals on refname; # should be dropped as there are no interv",MatchSource.CODE_COMMENT,third_party/nucleus/util/ranges.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/ranges.py
Integrability,message,message,"T NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Utilities for Range overlap detection.""""""; # Regular expressions for matching literal chr:start-stop strings.; # Regular expressions for matching literal chr:start strings.; # Logging frequency when building our rangeset objects, which can take some time; # to complete. Rather than just pausing for a few minutes, we provide an update; # logging message every _LOG_EVERY_N_RANGES_IN_RANGESET_INIT records added. See; # internal for more information.; """"""Fast overlap detection of a genomic position against a database of Ranges. Enables O(log n) computation of whether a point chr:pos falls within one of a; large number of genomic ranges. This class does not supports overlapping or adjacent intervals. Any such; intervals will be automatically merged together in the constructor. This class is immutable. No methods should be added that directly modify the; ranges held by the class.; """"""; """"""Creates a RangeSet backed by ranges. Note that the Range objects in ranges are *not* stored directly here, so; they can safely be modified after they are passed to this RangeSet. Args:; ranges: list(nucleus.genomics.v1.Range) protos (or anything with; reference_name, start, and end properties following the Range; convention). If None, no ranges will be used, and overlaps() will always; return False.; contigs: list(nucleus.genomics.v1.ContigI",MatchSource.CODE_COMMENT,third_party/nucleus/util/ranges.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/ranges.py
Performance,optimiz,optimize,"vals; on chr2 or chr3 are included since the chr2 only occurs in self and the two; intervals on chr3, despite having some shared bases, don't have an; overlapping interval in self. Args:; *others: A list of RangeSet objects to intersect with the intervals in; this RangeSet. Returns:; A RangeSet. If *others is empty, this function returns self rather than; making an unnecessary copy. In all other cases, the returned value will be; a freshly allocated RangeSet.; """"""; """"""Intersects the intervals of two IntervalTrees.""""""; # Yields all of the overlapping intervals from each interval of tree1; # found in tree2. Since each tree has only non-adjacent, non-overlapping,; # intervals this calculation is straightforward and safe and produces only; # non-adjacent, non-overlapping intervals.; # Iteratively intersect each of our *other RangeSets with this RangeSet.; # Sort by size so we do the smallest number of element merge first.; # TODO: Note we could optimize this code by computing the set of; # common contigs upfront across all others and only looping over those.; # pylint: disable=protected-access; # So we can intersect intervals within each contig separately.; # If refname is present in other, intersect those two IntervalTrees; # directly and add those contigs to our growing list of intersected; # intervals. If refname isn't present, all of the intervals on refname; # should be dropped as there are no intervals to overlap.; # Update our intersected RangeSet with the new intervals.; """"""Chops out all of the intervals in other from this this RangeSet. NOTE: This is a *MUTATING* operation for performance reasons. Make a copy; of self if you want to avoid modifying the RangeSet. Args:; other: A RangeSet object whose intervals will be removed from this; RangeSet.; """"""; # pylint: disable=protected-access; # If refname is present in self, difference those two IntervalTrees.; # Cleanup after ourselves by removing empty trees from our map.; """"""Gets the number of ranges used by this R",MatchSource.CODE_COMMENT,third_party/nucleus/util/ranges.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/ranges.py
Safety,detect,detection,"r the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Utilities for Range overlap detection.""""""; # Regular expressions for matching literal chr:start-stop strings.; # Regular expressions for matching literal chr:start strings.; # Logging frequency when building our rangeset objects, which can take some time; # to complete. Rather than just pausing for a few minutes, we provide an update; # logging message every _LOG_EVERY_N_RANGES_IN_RANGESET_INIT records added. See; # internal for more information.; """"""Fast overlap detection of a genomic position against a database of Ranges. Enables O(log n) computation of whether a point chr:pos falls within one of a; large number of genomic ranges. This class does not supports overlapping or adjacent intervals. Any such; intervals will be automatically merged together in the constructor. This class is immutable. No methods should be added that directly modify the; ranges held by the class.; """"""; """"""Creates a RangeSet backed by ranges. Note that the Range objects in ranges are *not* stored directly here, so; they can s",MatchSource.CODE_COMMENT,third_party/nucleus/util/ranges.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/ranges.py
Security,access,access,"e shared bases, don't have an; overlapping interval in self. Args:; *others: A list of RangeSet objects to intersect with the intervals in; this RangeSet. Returns:; A RangeSet. If *others is empty, this function returns self rather than; making an unnecessary copy. In all other cases, the returned value will be; a freshly allocated RangeSet.; """"""; """"""Intersects the intervals of two IntervalTrees.""""""; # Yields all of the overlapping intervals from each interval of tree1; # found in tree2. Since each tree has only non-adjacent, non-overlapping,; # intervals this calculation is straightforward and safe and produces only; # non-adjacent, non-overlapping intervals.; # Iteratively intersect each of our *other RangeSets with this RangeSet.; # Sort by size so we do the smallest number of element merge first.; # TODO: Note we could optimize this code by computing the set of; # common contigs upfront across all others and only looping over those.; # pylint: disable=protected-access; # So we can intersect intervals within each contig separately.; # If refname is present in other, intersect those two IntervalTrees; # directly and add those contigs to our growing list of intersected; # intervals. If refname isn't present, all of the intervals on refname; # should be dropped as there are no intervals to overlap.; # Update our intersected RangeSet with the new intervals.; """"""Chops out all of the intervals in other from this this RangeSet. NOTE: This is a *MUTATING* operation for performance reasons. Make a copy; of self if you want to avoid modifying the RangeSet. Args:; other: A RangeSet object whose intervals will be removed from this; RangeSet.; """"""; # pylint: disable=protected-access; # If refname is present in self, difference those two IntervalTrees.; # Cleanup after ourselves by removing empty trees from our map.; """"""Gets the number of ranges used by this RangeSet.""""""; """"""Returns True if this RangeSet is not empty.""""""; # Python 3 compatibility.; """"""Returns True if the varia",MatchSource.CODE_COMMENT,third_party/nucleus/util/ranges.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/ranges.py
Testability,log,logging,"T NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Utilities for Range overlap detection.""""""; # Regular expressions for matching literal chr:start-stop strings.; # Regular expressions for matching literal chr:start strings.; # Logging frequency when building our rangeset objects, which can take some time; # to complete. Rather than just pausing for a few minutes, we provide an update; # logging message every _LOG_EVERY_N_RANGES_IN_RANGESET_INIT records added. See; # internal for more information.; """"""Fast overlap detection of a genomic position against a database of Ranges. Enables O(log n) computation of whether a point chr:pos falls within one of a; large number of genomic ranges. This class does not supports overlapping or adjacent intervals. Any such; intervals will be automatically merged together in the constructor. This class is immutable. No methods should be added that directly modify the; ranges held by the class.; """"""; """"""Creates a RangeSet backed by ranges. Note that the Range objects in ranges are *not* stored directly here, so; they can safely be modified after they are passed to this RangeSet. Args:; ranges: list(nucleus.genomics.v1.Range) protos (or anything with; reference_name, start, and end properties following the Range; convention). If None, no ranges will be used, and overlaps() will always; return False.; contigs: list(nucleus.genomics.v1.ContigI",MatchSource.CODE_COMMENT,third_party/nucleus/util/ranges.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/ranges.py
Deployability,configurat,configurations,"STITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for ranges.py.""""""; # don't have any ranges by default; # make sure we can call overlaps without any ranges; # The set is empty.; # Overlapping intervals get merged.; # Adjacent intervals are merged.; # Sanity check that non-overlapping aren't merged.; # No start position before the first start range is enveloped.; # All regions within a single record are enveloped.; # Bridging across two ranges is not enveloped.; # Other chromosome is not spanned.; # For convenience we allow 'test.bed' in our regions but the actual file; # path is in our testdata directory.; # Intersection with 1, 2, 3 identical RangeSets produces the original set.; # Test some simple overlap configurations.; # Check cutting a single interval into multiple pieces.; # We have multiple overlapping intervals; make sure we merge intervals.; # Check that multiple intervals work.; # Check that multiple sets can be intersected.; # Check that different chromosomes are kept separate.; # Check that the intersection is as expected.; # Check that the intersection is as expected even if we do it in a different; # direction.; # Check that no one was modified.; # Excluding regions not in lhs has no impact.; # Check that excluding the whole region results in an empty RangeSet.; # An empty tree remains empty.; # Mutating operation returns None.; # Chop our contigs into 50 bp pieces.; # Chop our contigs in 120 bp pieces, leaving a 1 bp fragment in chr2.; # A 500 max size spans each of our contigs fully.; # list() is necessary to force the generator to execute.; # pylint: disable=line-too-long; # pylint: disable=line-too-long; # Iteration order over a RangeSet instantiated with a conti",MatchSource.CODE_COMMENT,third_party/nucleus/util/ranges_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/ranges_test.py
Modifiability,config,configurations,"STITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for ranges.py.""""""; # don't have any ranges by default; # make sure we can call overlaps without any ranges; # The set is empty.; # Overlapping intervals get merged.; # Adjacent intervals are merged.; # Sanity check that non-overlapping aren't merged.; # No start position before the first start range is enveloped.; # All regions within a single record are enveloped.; # Bridging across two ranges is not enveloped.; # Other chromosome is not spanned.; # For convenience we allow 'test.bed' in our regions but the actual file; # path is in our testdata directory.; # Intersection with 1, 2, 3 identical RangeSets produces the original set.; # Test some simple overlap configurations.; # Check cutting a single interval into multiple pieces.; # We have multiple overlapping intervals; make sure we merge intervals.; # Check that multiple intervals work.; # Check that multiple sets can be intersected.; # Check that different chromosomes are kept separate.; # Check that the intersection is as expected.; # Check that the intersection is as expected even if we do it in a different; # direction.; # Check that no one was modified.; # Excluding regions not in lhs has no impact.; # Check that excluding the whole region results in an empty RangeSet.; # An empty tree remains empty.; # Mutating operation returns None.; # Chop our contigs into 50 bp pieces.; # Chop our contigs in 120 bp pieces, leaving a 1 bp fragment in chr2.; # A 500 max size spans each of our contigs fully.; # list() is necessary to force the generator to execute.; # pylint: disable=line-too-long; # pylint: disable=line-too-long; # Iteration order over a RangeSet instantiated with a conti",MatchSource.CODE_COMMENT,third_party/nucleus/util/ranges_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/ranges_test.py
Testability,test,test,"ALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for ranges.py.""""""; # don't have any ranges by default; # make sure we can call overlaps without any ranges; # The set is empty.; # Overlapping intervals get merged.; # Adjacent intervals are merged.; # Sanity check that non-overlapping aren't merged.; # No start position before the first start range is enveloped.; # All regions within a single record are enveloped.; # Bridging across two ranges is not enveloped.; # Other chromosome is not spanned.; # For convenience we allow 'test.bed' in our regions but the actual file; # path is in our testdata directory.; # Intersection with 1, 2, 3 identical RangeSets produces the original set.; # Test some simple overlap configurations.; # Check cutting a single interval into multiple pieces.; # We have multiple overlapping intervals; make sure we merge intervals.; # Check that multiple intervals work.; # Check that multiple sets can be intersected.; # Check that different chromosomes are kept separate.; # Check that the intersection is as expected.; # Check that the intersection is as expected even if we do it in a different; # direction.; # Check that no one was modified.; # Excluding regions not in lhs has no impact.; # Check that excluding the whole region results in an empty RangeSet.; # An empty tree remains empty.; # Mutating operation returns None.; # Chop our contigs into 50 bp pieces.; # Chop our contigs in 120 bp pieces, leaving a 1 bp fragment in chr2.; # A 500 max size spans each of our contigs",MatchSource.CODE_COMMENT,third_party/nucleus/util/ranges_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/ranges_test.py
Usability,simpl,simple,"STITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for ranges.py.""""""; # don't have any ranges by default; # make sure we can call overlaps without any ranges; # The set is empty.; # Overlapping intervals get merged.; # Adjacent intervals are merged.; # Sanity check that non-overlapping aren't merged.; # No start position before the first start range is enveloped.; # All regions within a single record are enveloped.; # Bridging across two ranges is not enveloped.; # Other chromosome is not spanned.; # For convenience we allow 'test.bed' in our regions but the actual file; # path is in our testdata directory.; # Intersection with 1, 2, 3 identical RangeSets produces the original set.; # Test some simple overlap configurations.; # Check cutting a single interval into multiple pieces.; # We have multiple overlapping intervals; make sure we merge intervals.; # Check that multiple intervals work.; # Check that multiple sets can be intersected.; # Check that different chromosomes are kept separate.; # Check that the intersection is as expected.; # Check that the intersection is as expected even if we do it in a different; # direction.; # Check that no one was modified.; # Excluding regions not in lhs has no impact.; # Check that excluding the whole region results in an empty RangeSet.; # An empty tree remains empty.; # Mutating operation returns None.; # Chop our contigs into 50 bp pieces.; # Chop our contigs in 120 bp pieces, leaving a 1 bp fragment in chr2.; # A 500 max size spans each of our contigs fully.; # list() is necessary to force the generator to execute.; # pylint: disable=line-too-long; # pylint: disable=line-too-long; # Iteration order over a RangeSet instantiated with a conti",MatchSource.CODE_COMMENT,third_party/nucleus/util/ranges_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/ranges_test.py
Availability,error,error,"rm must reproduce the above copyright; # notice, this list of conditions and the following disclaimer in the; # documentation and/or other materials provided with the distribution.; #; # 3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Utility functions for manipulating DNA sequences.""""""; """"""Base error class.""""""; """"""Returns a dictionary with the lowercase keys and values entered.""""""; # R is A/G; # Y is C/T; # S is C/G; # W is A/T; # K is G/T; # M is A/C; # B is C/G/T; # V is A/C/G; # D is A/G/T; # H is A/C/T; # N is any base; """"""Returns the reverse complement of a DNA sequence. By default this will successfully reverse complement sequences comprised; solely of A, C, G, and T letters. Other complement dictionaries can be; passed in for more permissive matching. Args:; sequence: str. The input sequence to reverse complement.; complement_dict: dict[str, str]. The lookup dictionary holding the; complement base pairs. Returns:; The reverse complement DNA sequence. Raises:; Error: The sequence contains letters not present in complement_dict.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/util/sequence_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/sequence_utils.py
Availability,error,error,"# Copyright 2018 Google LLC.; #; # Redistribution and use in source and binary forms, with or without; # modification, are permitted provided that the following conditions; # are met:; #; # 1. Redistributions of source code must retain the above copyright notice,; # this list of conditions and the following disclaimer.; #; # 2. Redistributions in binary form must reproduce the above copyright; # notice, this list of conditions and the following disclaimer in the; # documentation and/or other materials provided with the distribution.; #; # 3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for third_party.nucleus.util.sequence_utils.""""""; """"""Tests canonical DNA sequences are reverse complemented correctly.""""""; """"""Tests error is raised when complement_dict does not cover given seq.""""""; """"""Tests that base set and complement dict definitions are consistent.""""""",MatchSource.CODE_COMMENT,third_party/nucleus/util/sequence_utils_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/sequence_utils_test.py
Integrability,wrap,wrappers,"its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Struct proto utilities. This class provides wrappers for conveniently interacting with protos defined; in struct.proto, mostly ListValue and Value objects. It should primarily be used; by variant_utils and variantcallutils rather than being used directly.; """"""; # Field names of values defined in struct_pb2.Value.; """"""Adds values to a particular map field containing a ListValue.""""""; """"""Sets values to a particular map field containing a ListValue.""""""; """"""Appends the given number value(s) to field_map[field_name]. Args:; field_map: Map(str --> ListValue) to modify.; field_name: str. The name of the field to append value to.; value: The number value(s) to append to the field. This can be a single; number or a list of numbers.; """"""; """"""Sets field_map[field_name] with the given number value(s). Args:; field_map: Map(str --> ListValue) to modify.; field_name: str. The name of the field to set.; value: The number value(s) to set the field to. This can be a single number; or a list of numbers.; """"""; """"""Returns the number value(s) stored in `field_map[field_name",MatchSource.CODE_COMMENT,third_party/nucleus/util/struct_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/struct_utils.py
Integrability,protocol,protocol,"# Copyright 2018 Google LLC.; #; # Redistribution and use in source and binary forms, with or without; # modification, are permitted provided that the following conditions; # are met:; #; # 1. Redistributions of source code must retain the above copyright notice,; # this list of conditions and the following disclaimer.; #; # 2. Redistributions in binary form must reproduce the above copyright; # notice, this list of conditions and the following disclaimer in the; # documentation and/or other materials provided with the distribution.; #; # 3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for third_party.nucleus.util.struct_utils.""""""; """"""Returns a proto Map(str --> ListValue) with the given fields set. Args:; d: dict(str --> list(Value)). The data to populate. Returns:; The protocol buffer-defined Map(str --> ListValue).; """"""; # We use a Variant as an intermediate data structure since it contains the; # desired output map types.; """"""Returns a list containing value plus the list's length.""""""; # Test long handling in Python 2",MatchSource.CODE_COMMENT,third_party/nucleus/util/struct_utils_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/struct_utils_test.py
Energy Efficiency,allocate,allocate,"N IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Utility functions for working with reads.""""""; """"""Returns True if read overlaps read. This function is equivalent to calling:. `ranges.ranges_overlap(region, read_range(read))`. But is optimized for speed and memory performance in C++. Args:; read: nucleus.genomics.v1.Read.; region: nucleus.genomics.v1.Range. Returns:; True if read and region overlap (i.e, have the same reference_name and their; start/ends overlap at least one basepair).; """"""; """"""Creates a Range proto from the alignment of Read. Args:; read: nucleus.genomics.v1.Read. The read to calculate the range for. Returns:; A nucleus.genomics.v1.Range for read.; """"""; """"""Returns the read start + alignment length for Read read.""""""; """"""Samples k elements with uniform probability from an iterable. Selects a subset of k elements from n input elements with uniform probability; without needing to hold all n elements in memory at the same time. This; implementation has max space complexity O(min(k, n)), i.e., we allocate up to; min(k, n) elements to store the samples. This means that we only use ~n; elements when n is smaller than k, which can be important when k is large. If; n elements are added to this sampler, and n <= k, all n elements will be; retained. If n > k, each added element will be retained with a uniform; probability of k / n. The order of the k retained samples from our n elements is undefined. In; particular that means that the elements in the returned list can occur in a; different order than they appeared in the iterable. More details about reservoir sampling (and the specific algorithm used here; called Algorithm R) can be found on wikipedia:. https://en.wikipedia.org/wiki/Reservoir_sampling#Algorithm_R. Args:; iterable: Python iterable. The iterable to sample from.; k: int. The number of elements to sample.; random: A random number generator or None. Returns:; A list containing the k sampled elements. Raises:; ValueError: If k is negative.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/util/utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/utils.py
Performance,optimiz,optimized,"#; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Utility functions for working with reads.""""""; """"""Returns True if read overlaps read. This function is equivalent to calling:. `ranges.ranges_overlap(region, read_range(read))`. But is optimized for speed and memory performance in C++. Args:; read: nucleus.genomics.v1.Read.; region: nucleus.genomics.v1.Range. Returns:; True if read and region overlap (i.e, have the same reference_name and their; start/ends overlap at least one basepair).; """"""; """"""Creates a Range proto from the alignment of Read. Args:; read: nucleus.genomics.v1.Read. The read to calculate the range for. Returns:; A nucleus.genomics.v1.Range for read.; """"""; """"""Returns the read start + alignment length for Read read.""""""; """"""Samples k elements with uniform probability from an iterable. Selects a subset of k elements from n input elements with uniform probability; without needing to hold all n elements in memory at the same time. This; implementation has max space complexity O(min(k, n)), i.e., we allocate up to; min(k, n) elements to store the samples. This means that we only use ~n; elements when n is smaller than k, which can be important when k is large. If; n elements are added to this sampler, and n <= k, all n element",MatchSource.CODE_COMMENT,third_party/nucleus/util/utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/utils.py
Testability,test,test,"f source code must retain the above copyright notice,; # this list of conditions and the following disclaimer.; #; # 2. Redistributions in binary form must reproduce the above copyright; # notice, this list of conditions and the following disclaimer in the; # documentation and/or other materials provided with the distribution.; #; # 3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for third_party.nucleus.util.utils.""""""; """"""Tests reads have their ranges calculated correctly.""""""; """"""Tests reads have their ends calculated correctly.""""""; """"""Tests samples have expected length.""""""; # Test sampling with k > len(iterable).; # Test sampling with k == len(iterable).; # Test sampling with k < len(iterable).; # Test sampling with k == 0.; # Test sampling with k < 0 (bad args).; """"""Tests observed frequency is close to expected frequency.""""""; # Use a fixed random number so our test is deterministic.; # dict(ref1='chr1', s1=0, e1=3, ref2='chr1', s2=3, e2=3, expected=False),; # This check ensures we get the same result calling ranges.ranges_overlap.",MatchSource.CODE_COMMENT,third_party/nucleus/util/utils_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/utils_test.py
Deployability,update,update,"PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""VariantCall utilities.""""""; # Special-cased FORMAT fields that are first-class fields in the VariantCall.; """"""Sets a field of the info map of the `VariantCall` to the given value(s). `variant_call.info` is analogous to the FORMAT field of a VCF call. Example usage:; with vcf.VcfReader('/path/to/my.vcf') as vcf_reader:; for variant in vcf_reader:; first_call = variant.calls[0]; # Type can be inferred for reserved VCF fields.; set_format(first_call, 'AD', 25); # Specify the reader explicitly for unknown fields.; set_format(first_call, 'MYFIELD', 30, vcf_reader). Args:; variant_call: VariantCall proto. The VariantCall to modify.; field_name: str. The name of the field to set.; value: A single value or list of values to update the VariantCall with.; The type of the value is determined by the `vcf_object` if one is given,; otherwise is looked up based on the reserved FORMAT fields in the VCF; specification.; vcf_object: (Optional) A VcfReader or VcfWriter object. If not None, the; type of the field is inferred from the associated VcfReader or VcfWriter; based on its name. Otherwise, the type is inferred if it is a reserved; field.; """"""; """"""Returns the value of the `field_name` FORMAT field. The `vcf_object` is used to determine the type of the resulting value. If it; is a single value or a Flag, that single value will be returned. Otherwise,; the list of values is returned. Args:; variant_call: VariantCall proto. The VariantCall of interest.; field_name: str. The name of the field to retrieve values from.; vcf_object: (Optional) A VcfReader or VcfWriter object. If not None, the; type of the field is inferred from the associated VcfReader or VcfWriter; based on its name. Otherwise, the type is i",MatchSource.CODE_COMMENT,third_party/nucleus/util/variantcall_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/variantcall_utils.py
Availability,down,down," """"""Is alt a deletion w.r.t. ref?. Args:; ref: A string of the reference allele.; alt: A string of the alternative allele. Returns:; True if alt is a deletion w.r.t. ref.; """"""; """"""Does variant have an insertion?. Args:; variant: nucleus.genomics.v1.Variant. Returns:; True if the alleles in variant indicate an insertion event; occurs at this site.; """"""; """"""Does variant have a deletion?. Args:; variant: nucleus.genomics.v1.Variant. Returns:; True if the alleles in variant indicate an deletion event; occurs at this site.; """"""; """"""An enumeration of the types of allele mismatches we detect.""""""; # Duplicate alleles.; # Truth has an allele that doesn't match any allele in eval.; # Eval has an allele that doesn't match any allele in truth.; """"""Determines the set of allele mismatch discordances between evalv and truev. Compares the alleles present in evalv and truev to determine if there are any; disagreements between the set of called alleles in the two Variant protos. The; type of differences basically boil down to:. -- Are there duplicate alt alleles?; -- Can we find a matching allele in the truev for each allele in evalv, and; vice versa?. Two alleles A and B match when they would produce the same sequence of bases; in ref and alt haplotypes starting at the same position. So CA=>TA is the same; as C=>T (position is the same, replacing A by A is a noop) but AC=>AT isn't; the same as C=>T because the former event changes bases 1 bp further along in; the reference genome than the C=>T allele. Args:; evalv: A nucleus.genomics.v1.Variant.; truev: A nucleus.genomics.v1.Variant. Returns:; A set of AlleleMismatchType values.; """"""; # Use set removes duplicate alleles in truth and eval variants.; # Loop over each possible alt allele, adding eval_alt to each matching alt; # allele.; # We are a match to true_alt, so record that fact in allele_matches; # We never found a match for eval_alt.; # At this point we've checked every alt against every eval allele, and are; # ready to summar",MatchSource.CODE_COMMENT,third_party/nucleus/util/variant_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/variant_utils.py
Deployability,configurat,configurations,"stfix, has at least len 1.; # For example, alleles = ['ATT', 'TT'] reduces to ['AT', 'T'] not ['A', ''].; # Fast path for the case where there's no shared postfix.; """"""Replaces the alleles in variants with their simplified versions. This function takes a variant and replaces its ref and alt alleles with those; produced by a call to variant_utils.simplify_alleles() to remove common; postfix bases in the alleles that may be present due to pruning away alleles. Args:; variant: learning.genomics.genomics.Variant proto we want to simplify. Returns:; variant with its ref and alt alleles replaced with their simplified; equivalents.; """"""; """"""Returns True if variant has a non-PASS filter field, or False otherwise.""""""; """"""Is variant a non-reference call?. A Variant proto doesn't always imply that there's a variant present in the; genome. The call may not have alternate bases, may be filtered, may a have; hom-ref genotype, etc. This function looks for all of those configurations; and returns true iff the variant is asserting that a mutation is present; in the same. Note that this code allows a variant without a calls field to be variant,; but one with a genotype call must have a non-reference genotype to be; considered variant (if require_non_ref_genotype is True, the default). If; False, a variant that passes all of the site-level requirements for being; a variant_call will return a True value, regardless of the genotypes, which; means that we'll consider a site with a sample with a hom-ref or no-call site; a variant call. Args:; variant: nucleus.genomics.v1.Variant.; require_non_ref_genotype: Should we require a site with a genotype call to; have a non-reference (het, hom-var) genotype for the site to be considered; a variant call?; no_calls_are_variant: If a site has genotypes, should we consider no_call; genotypes as being variant or not? e.g. -1/1 listed as ./. in VCF; call_indices: A list of 0-based indices. If specified, only the calls; at the given indices will be cons",MatchSource.CODE_COMMENT,third_party/nucleus/util/variant_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/variant_utils.py
Energy Efficiency,reduce,reduces,"nst every eval allele, and are; # ready to summarize the differences using our AlleleMismatchType enum.; """"""Simplifies alleles by stripping off common postfix bases. For example, simplify(""AC"", ""GC"") would produce the tuple ""A"", ""G"" as the ""C""; base is a common postfix of both alleles. But simplify(""AC"", ""GT"") would; produce ""AC"", ""GT"" as there is no common postfix. Note this function will never simplify any allele down to the empty string. So; if alleles = ['CACA', 'CA'], the longest common postfix is 'CA' but we will; not produce ['CA', ''] as this is an invalid Variant allele encoding. Instead; we produce ['CAC', 'C']. Args:; *alleles: A tuple of bases, each as a string, to simplify. Returns:; A tuple, one for each allele in alleles in order, with any common postfix; bases stripped off.; """"""; # Loop over the alleles to determine the length of the shared postfix. Start; # at 1 so every allele, even after trimming the postfix, has at least len 1.; # For example, alleles = ['ATT', 'TT'] reduces to ['AT', 'T'] not ['A', ''].; # Fast path for the case where there's no shared postfix.; """"""Replaces the alleles in variants with their simplified versions. This function takes a variant and replaces its ref and alt alleles with those; produced by a call to variant_utils.simplify_alleles() to remove common; postfix bases in the alleles that may be present due to pruning away alleles. Args:; variant: learning.genomics.genomics.Variant proto we want to simplify. Returns:; variant with its ref and alt alleles replaced with their simplified; equivalents.; """"""; """"""Returns True if variant has a non-PASS filter field, or False otherwise.""""""; """"""Is variant a non-reference call?. A Variant proto doesn't always imply that there's a variant present in the; genome. The call may not have alternate bases, may be filtered, may a have; hom-ref genotype, etc. This function looks for all of those configurations; and returns true iff the variant is asserting that a mutation is present; in the ",MatchSource.CODE_COMMENT,third_party/nucleus/util/variant_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/variant_utils.py
Integrability,depend,depending,"1/1 listed as ./. in VCF; call_indices: A list of 0-based indices. If specified, only the calls; at the given indices will be considered. The function will return; True if any of those calls are variant.; apply_filter: If set to True, will never treat this site as variant when; any filter other than PASS or . is set. Returns:; True if variant is really a mutation call.; """"""; # No actual alt allele listed in ALT column; # Anything other than PASS or . in FILTER column; # All tests after this point should only look at genotype-based fields, as; # we may have aborted out in the prev. line due to require_non_ref_genotype.; # Check for non-ref genotypes and optionally no-call (-1) genotypes; """"""Does variant have any genotype calls?. Args:; variant: nucleus.genomics.v1.Variant. Returns:; True if variant has one or more VariantCalls.; """"""; """"""Gets the GenotypeType for variant. If variant doesn't have genotypes, returns no_call. Otherwise; returns one of no_call, hom_ref, het, or hom_var depending on the; status of the genotypes in the call field of variant. Args:; variant: nucleus.genomics.v1.Variant. Returns:; A GenotypeType. Raises:; ValueError: If variant has more than one call (i.e., is multi-sample).; """"""; """"""Gets genotype of the sample in variant as a list of actual alleles. Returns the alleles specified by the genotype indices of variant.calls[0].; For example, if variant.reference_bases = 'A' and variant.alternative_bases; = ['C'] and the genotypes are [0, 1], this function will return; ['A', 'C']. Args:; variant: nucleus.genomics.v1.Variant.; call_ix: int. The index into the calls attribute indicating which; VariantCall to return alleles for. Returns:; A list of allele (string) from variant, one for each genotype in; variant.calls[call_ix], in order. Raises:; ValueError: If variant doesn't have a call at the specified index.; """"""; # Genotypes are encoded as integers, where 0 is the reference allele,; # indices > 0 refer to alt alleles, and the no-call genotypes is",MatchSource.CODE_COMMENT,third_party/nucleus/util/variant_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/variant_utils.py
Modifiability,config,configurations,"stfix, has at least len 1.; # For example, alleles = ['ATT', 'TT'] reduces to ['AT', 'T'] not ['A', ''].; # Fast path for the case where there's no shared postfix.; """"""Replaces the alleles in variants with their simplified versions. This function takes a variant and replaces its ref and alt alleles with those; produced by a call to variant_utils.simplify_alleles() to remove common; postfix bases in the alleles that may be present due to pruning away alleles. Args:; variant: learning.genomics.genomics.Variant proto we want to simplify. Returns:; variant with its ref and alt alleles replaced with their simplified; equivalents.; """"""; """"""Returns True if variant has a non-PASS filter field, or False otherwise.""""""; """"""Is variant a non-reference call?. A Variant proto doesn't always imply that there's a variant present in the; genome. The call may not have alternate bases, may be filtered, may a have; hom-ref genotype, etc. This function looks for all of those configurations; and returns true iff the variant is asserting that a mutation is present; in the same. Note that this code allows a variant without a calls field to be variant,; but one with a genotype call must have a non-reference genotype to be; considered variant (if require_non_ref_genotype is True, the default). If; False, a variant that passes all of the site-level requirements for being; a variant_call will return a True value, regardless of the genotypes, which; means that we'll consider a site with a sample with a hom-ref or no-call site; a variant call. Args:; variant: nucleus.genomics.v1.Variant.; require_non_ref_genotype: Should we require a site with a genotype call to; have a non-reference (het, hom-var) genotype for the site to be considered; a variant call?; no_calls_are_variant: If a site has genotypes, should we consider no_call; genotypes as being variant or not? e.g. -1/1 listed as ./. in VCF; call_indices: A list of 0-based indices. If specified, only the calls; at the given indices will be cons",MatchSource.CODE_COMMENT,third_party/nucleus/util/variant_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/variant_utils.py
Safety,detect,detect,"1: A string of the first allele, must be 1 bp in length.; allele2: A string of the second allele, must be 1 bp in length. Returns:; True if allele1/allele2 are a transition SNP. Raises:; ValueError: if allele1 and allele2 are equal or aren't 1 bp in length.; """"""; """"""Is alt an insertion w.r.t. ref?. Args:; ref: A string of the reference allele.; alt: A string of the alternative allele. Returns:; True if alt is an insertion w.r.t. ref.; """"""; """"""Is alt a deletion w.r.t. ref?. Args:; ref: A string of the reference allele.; alt: A string of the alternative allele. Returns:; True if alt is a deletion w.r.t. ref.; """"""; """"""Does variant have an insertion?. Args:; variant: nucleus.genomics.v1.Variant. Returns:; True if the alleles in variant indicate an insertion event; occurs at this site.; """"""; """"""Does variant have a deletion?. Args:; variant: nucleus.genomics.v1.Variant. Returns:; True if the alleles in variant indicate an deletion event; occurs at this site.; """"""; """"""An enumeration of the types of allele mismatches we detect.""""""; # Duplicate alleles.; # Truth has an allele that doesn't match any allele in eval.; # Eval has an allele that doesn't match any allele in truth.; """"""Determines the set of allele mismatch discordances between evalv and truev. Compares the alleles present in evalv and truev to determine if there are any; disagreements between the set of called alleles in the two Variant protos. The; type of differences basically boil down to:. -- Are there duplicate alt alleles?; -- Can we find a matching allele in the truev for each allele in evalv, and; vice versa?. Two alleles A and B match when they would produce the same sequence of bases; in ref and alt haplotypes starting at the same position. So CA=>TA is the same; as C=>T (position is the same, replacing A by A is a noop) but AC=>AT isn't; the same as C=>T because the former event changes bases 1 bp further along in; the reference genome than the C=>T allele. Args:; evalv: A nucleus.genomics.v1.Variant.; tr",MatchSource.CODE_COMMENT,third_party/nucleus/util/variant_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/variant_utils.py
Testability,assert,asserting,"stfix, has at least len 1.; # For example, alleles = ['ATT', 'TT'] reduces to ['AT', 'T'] not ['A', ''].; # Fast path for the case where there's no shared postfix.; """"""Replaces the alleles in variants with their simplified versions. This function takes a variant and replaces its ref and alt alleles with those; produced by a call to variant_utils.simplify_alleles() to remove common; postfix bases in the alleles that may be present due to pruning away alleles. Args:; variant: learning.genomics.genomics.Variant proto we want to simplify. Returns:; variant with its ref and alt alleles replaced with their simplified; equivalents.; """"""; """"""Returns True if variant has a non-PASS filter field, or False otherwise.""""""; """"""Is variant a non-reference call?. A Variant proto doesn't always imply that there's a variant present in the; genome. The call may not have alternate bases, may be filtered, may a have; hom-ref genotype, etc. This function looks for all of those configurations; and returns true iff the variant is asserting that a mutation is present; in the same. Note that this code allows a variant without a calls field to be variant,; but one with a genotype call must have a non-reference genotype to be; considered variant (if require_non_ref_genotype is True, the default). If; False, a variant that passes all of the site-level requirements for being; a variant_call will return a True value, regardless of the genotypes, which; means that we'll consider a site with a sample with a hom-ref or no-call site; a variant call. Args:; variant: nucleus.genomics.v1.Variant.; require_non_ref_genotype: Should we require a site with a genotype call to; have a non-reference (het, hom-var) genotype for the site to be considered; a variant call?; no_calls_are_variant: If a site has genotypes, should we consider no_call; genotypes as being variant or not? e.g. -1/1 listed as ./. in VCF; call_indices: A list of 0-based indices. If specified, only the calls; at the given indices will be cons",MatchSource.CODE_COMMENT,third_party/nucleus/util/variant_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/variant_utils.py
Usability,simpl,simply,"tion of the variant's position. Args:; variant: nucleus.genomics.v1.Variant. Returns:; A string chr:start + 1 (as start is zero-based).; """"""; """"""Exclude any alts listed, by default: '<*>', '.', and '<NON_REF>'. These alleles are sometimes listed in ALT column but they shouldn't be; analyzed and usually indicate reference blocks in formats like gVCF. E.g. 'A'->'<*>' is NOT an insertion, and 'A'->'.' is NOT a SNP. Args:; alts: a list of strings representing the alternate alleles.; exclude_alleles: list(str). The alleles in this list will be ignored. Returns:; alts alleles except those in exclude_alleles, by default excluding the GVCF; '<*>' allele, the '<NON_REF>' symbolic allele, and '.' missing field by; default.; """"""; """"""Is variant a SNP?. Args:; variant: nucleus.genomics.v1.Variant.; exclude_alleles: list(str). The alleles in this list will be ignored. Returns:; True if all alleles of variant are 1 bp in length.; """"""; """"""Is variant an indel?. An indel event is simply one where the size of at least one of the alleles; is > 1. Args:; variant: nucleus.genomics.v1.Variant.; exclude_alleles: list(str). The alleles in this list will be ignored. Returns:; True if the alleles in variant indicate an insertion/deletion event; occurs at this site.; """"""; """"""Returns True if variant has exactly one alternate allele. Args:; variant: nucleus.genomics.v1.Variant.; exclude_alleles: list(str). The alleles in this list will be ignored. Returns:; True if the variant has exactly one alternate allele.; """"""; """"""Does variant have multiple alt alleles?. Args:; variant: nucleus.genomics.v1.Variant.; exclude_alleles: list(str). The alleles in this list will be ignored. Returns:; True if variant has more than one alt allele.; """"""; """"""Are all the variant's alt alleles insertions?. Args:; variant: nucleus.genomics.v1.Variant.; exclude_alleles: list(str). The alleles in this list will be ignored. Returns:; True if variant has at least one alt allele and all alts are insertions.; """"""; """"""Are all ",MatchSource.CODE_COMMENT,third_party/nucleus/util/variant_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/variant_utils.py
Energy Efficiency,reduce,reduce," LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for variant_utils.""""""; """"""Creates a Variant record with specified alternate_bases.""""""; # We have an iterable, so actual isn't equal to variants.; # Making actual a list now makes it equal.; # variant => status if we require non_ref genotype / status if we don't.; # Check that default call checks for genotypes.; # Ask explicitly for genotypes to be included.; # Don't require non_ref genotypes.; # The default is apply_filter=True.; # These two are not allowed in VCF, but worth testing our; # code's behavior; # <NON_REF> is excluded by default; # Make sure we don't reduce an allele to nothing.; # Tests for multi-allelics.; # There's one extra T here.; # Another single base postfix where we can remove a 'G'.; # There are two extra Ts to remove.; # One pair can simplify, but not the other, so nothing can reduce.; # Example from internal.; """"""Test that simplify_variant_alleles works as expected.""""""; # Alleles are incompatible, so we have mismatches in both directions.; # Missing alts specific to eval and truth.; # Duplicate alleles.; # Dups in truth, discordant alleles.; # Simplification of alleles does the right matching.; # trailing A.; # preceding A, doesn't simplify so it's a mismatch.; # both training preceding A, doesn't simplify, so mismatches; # # Eval has 1 of the two alt alleles, so no eval mismatch.; # Eval has extra unmatched alleles, so it's got a mismatch.; # alleles followed by is_insertion and is_deletion expectation; # These are examples where ref is not simplified, such as could",MatchSource.CODE_COMMENT,third_party/nucleus/util/variant_utils_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/variant_utils_test.py
Safety,detect,detect,"ur; # code's behavior; # <NON_REF> is excluded by default; # Make sure we don't reduce an allele to nothing.; # Tests for multi-allelics.; # There's one extra T here.; # Another single base postfix where we can remove a 'G'.; # There are two extra Ts to remove.; # One pair can simplify, but not the other, so nothing can reduce.; # Example from internal.; """"""Test that simplify_variant_alleles works as expected.""""""; # Alleles are incompatible, so we have mismatches in both directions.; # Missing alts specific to eval and truth.; # Duplicate alleles.; # Dups in truth, discordant alleles.; # Simplification of alleles does the right matching.; # trailing A.; # preceding A, doesn't simplify so it's a mismatch.; # both training preceding A, doesn't simplify, so mismatches; # # Eval has 1 of the two alt alleles, so no eval mismatch.; # Eval has extra unmatched alleles, so it's got a mismatch.; # alleles followed by is_insertion and is_deletion expectation; # These are examples where ref is not simplified, such as could occur; # a multi-allelic record, such as the following:; # alleles = AT, A, ATT, CT (1 deletion, 1 insertion, 1 SNP); # a gVCF reference block record is counted as ref; # symbolic allele <NON_REF> practically counts as ref; # Ref without an alt isn't gVCF.; # SNPs and indels aren't gVCF records.; # These are gVCF records.; # These are close but not exactly gVCFs.; # Variants with one ref and one alt allele.; # Variants with one ref and two alt alleles.; # Variants with one ref and three alt alleles.; # Haploid.; # Diploid.; # Degenerate cases - no and one variant.; # Two variants on the same chromosome.; # The first variant has start > the second, but it's on a later chrom.; # Make sure the end is respected.; # Complex example with multiple chromosomes, ends, etc.; # Check that sorting the permutations produced sorted.; # Check that variants_are_sorted() is correct, which we detect if; # the range_tuples of permutation == the range_tuples of sorted_variants.",MatchSource.CODE_COMMENT,third_party/nucleus/util/variant_utils_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/variant_utils_test.py
Testability,test,testing," LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for variant_utils.""""""; """"""Creates a Variant record with specified alternate_bases.""""""; # We have an iterable, so actual isn't equal to variants.; # Making actual a list now makes it equal.; # variant => status if we require non_ref genotype / status if we don't.; # Check that default call checks for genotypes.; # Ask explicitly for genotypes to be included.; # Don't require non_ref genotypes.; # The default is apply_filter=True.; # These two are not allowed in VCF, but worth testing our; # code's behavior; # <NON_REF> is excluded by default; # Make sure we don't reduce an allele to nothing.; # Tests for multi-allelics.; # There's one extra T here.; # Another single base postfix where we can remove a 'G'.; # There are two extra Ts to remove.; # One pair can simplify, but not the other, so nothing can reduce.; # Example from internal.; """"""Test that simplify_variant_alleles works as expected.""""""; # Alleles are incompatible, so we have mismatches in both directions.; # Missing alts specific to eval and truth.; # Duplicate alleles.; # Dups in truth, discordant alleles.; # Simplification of alleles does the right matching.; # trailing A.; # preceding A, doesn't simplify so it's a mismatch.; # both training preceding A, doesn't simplify, so mismatches; # # Eval has 1 of the two alt alleles, so no eval mismatch.; # Eval has extra unmatched alleles, so it's got a mismatch.; # alleles followed by is_insertion and is_deletion expectation; # These are examples where ref is not simplified, such as could",MatchSource.CODE_COMMENT,third_party/nucleus/util/variant_utils_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/variant_utils_test.py
Usability,simpl,simplify,"LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for variant_utils.""""""; """"""Creates a Variant record with specified alternate_bases.""""""; # We have an iterable, so actual isn't equal to variants.; # Making actual a list now makes it equal.; # variant => status if we require non_ref genotype / status if we don't.; # Check that default call checks for genotypes.; # Ask explicitly for genotypes to be included.; # Don't require non_ref genotypes.; # The default is apply_filter=True.; # These two are not allowed in VCF, but worth testing our; # code's behavior; # <NON_REF> is excluded by default; # Make sure we don't reduce an allele to nothing.; # Tests for multi-allelics.; # There's one extra T here.; # Another single base postfix where we can remove a 'G'.; # There are two extra Ts to remove.; # One pair can simplify, but not the other, so nothing can reduce.; # Example from internal.; """"""Test that simplify_variant_alleles works as expected.""""""; # Alleles are incompatible, so we have mismatches in both directions.; # Missing alts specific to eval and truth.; # Duplicate alleles.; # Dups in truth, discordant alleles.; # Simplification of alleles does the right matching.; # trailing A.; # preceding A, doesn't simplify so it's a mismatch.; # both training preceding A, doesn't simplify, so mismatches; # # Eval has 1 of the two alt alleles, so no eval mismatch.; # Eval has extra unmatched alleles, so it's got a mismatch.; # alleles followed by is_insertion and is_deletion expectation; # These are examples where ref is not simplified, such as could occur; # a multi-allelic record, such as the following:; # alleles = AT, A, ATT, CT (1 deletion, 1 insertion, 1 SNP); # a gVCF reference block record is counted as ref; # symbolic allele <NON_REF> practically counts as ref; # Ref without an alt isn't gVCF.; # SNPs and",MatchSource.CODE_COMMENT,third_party/nucleus/util/variant_utils_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/variant_utils_test.py
Integrability,depend,depending,"e VCF 4.3 spec.; # Map from field type to the function used to set struct_pb2.Value elements; # of that type.; """"""Returns the desired reserved field. Args:; field_id: str. The id of the field to retrieve.; reserved_fields: list(fields). The reserved fields to search. Returns:; The reserved field with the given `field_id`. Raises:; ValueError: `field_id` is not a known reserved field.; """"""; """"""Returns the reserved FILTER field with the given ID.""""""; """"""Returns the reserved INFO field with the given ID.""""""; """"""Returns the reserved FORMAT field with the given ID.""""""; """"""Returns a callable that extracts the typed information from a ListValue. Args:; value_type: str. The value type stored as defined in the VCF 4.3 spec.; number: str. The number of entries of this value as defined in the VCF spec. Returns:; A callable that takes two inputs: A Map(str --> ListValue) and a string; field name and returns the associated typed value(s). The return value is; a list of typed values or a single typed value, depending on the expected; number of values returned.; """"""; # Map from INFO field name to the function used to set struct_pb2.Value elements; # of that field.; # Map from INFO field name to the function used to get struct_pb2.Value elements; # of that field.; # Map from FORMAT field name to the function used to set struct_pb2.Value; # elements of that field.; # Map from FORMAT field name to the function used to get struct_pb2.Value; # elements of that field.; """"""Returns the callable that sets the proper field for the given field_name. Args:; field_name: str. The field name of the reserved INFO field (e.g. 'MQ'). Returns:; The callable that takes in a Map(str --> ListValue), field name, and value; and modifies the map to populate the field_name entry with the given value. Raises:; ValueError: The field_name is not a known reserved INFO field.; """"""; """"""Returns the callable that gets the proper field for the given field_name. Args:; field_name: str. The field name of the reserved ",MatchSource.CODE_COMMENT,third_party/nucleus/util/vcf_constants.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/vcf_constants.py
Availability,error,error,"ual is the minimum of base quality and mapping quality at each position; # 254 is the max value for quality scores because the SAM specification has; # 255 reserved for unavailable values.; # alpha is <supports variant> * <base != reference>; """"""Scale an array to integers between 0 and 255 to prep it for a PNG image. Args:; arr: numpy array. Input array made up of integers or floats.; vmin: number. Minimum data value to map to 0. Values below this will be; clamped to this value and therefore become 0.; vmax: number. Maximum data value to map to 255. Values above this will be; clamped to this value and therefore become 255. Returns:; numpy array of dtype np.uint8 (integers between 0 and 255).; """"""; # Careful not to modify the original array; # Snap numbers in the array falling outside the range into the range,; # otherwise they will produce artifacts due to byte overflow; # Scale the input into the range of vmin to vmax; """"""Find image type based on array dimensions. Raises error on invalid image dimensions.; Args:; arr: numpy array. Input array. Returns:; str. ""RGB"" or ""L"", meant for PIL.Image.fromarray.; """"""; # 8-bit x 3 colors; # 8-bit, gray-scale; """"""Adjust an array to prepare it for saving to an image. Re-scale numbers in the input array to go from 0 to 255 to adapt them for a; PNG image. Args:; arr: numpy array. Should be 2-dimensional or 3-dimensional where the third; dimension has 3 channels.; vmin: number (float or int). Minimum data value, which will correspond to; black in greyscale or lack of each color in RGB images. Default None takes; the minimum of the data from arr.; vmax: number (float or int). Maximum data value, which will correspond to; white in greyscale or full presence of each color in RGB images. Default; None takes the max of the data from arr. Returns:; (modified numpy array, image_mode); """"""; # In cases where all elements are the same, fix the vmax so that even though; # the whole image will be black, the user can at least see the shape; """"",MatchSource.CODE_COMMENT,third_party/nucleus/util/vis.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/vis.py
Energy Efficiency,green,green," numpy array. Parse image/encoded and image/shape features from a tensorflow Example and; decode the image into that shape. Args:; example: a tensorflow Example containing features that include; ""image/encoded"" and ""image/shape"". Returns:; numpy array of dtype np.uint8.; """"""; """"""Split 3D array into a list of 2D arrays. e.g. given a numpy array of shape (100, 200, 6), return a list of 6 channels,; each with shape (100, 200). Args:; arr: a 3D numpy array. Returns:; list of 2D numpy arrays.; """"""; """"""Extract image from an Example and return the list of channels. Args:; example: a tensorflow Example containing features that include; ""image/encoded"" and ""image/shape"". Returns:; list of 2D numpy arrays, one for each channel.; """"""; """"""Convert 6-channel image from DeepVariant to RGB for quick visualization. The 6 channels are: ""read base"", ""base quality"", ""mapping quality"", ""strand"",; ""supports variant"", ""base != reference"". Args:; channels: a list of 6 numpy arrays. Returns:; 3D numpy array of 3 colors (Red, green, blue).; """"""; # qual is the minimum of base quality and mapping quality at each position; # 254 is the max value for quality scores because the SAM specification has; # 255 reserved for unavailable values.; # alpha is <supports variant> * <base != reference>; """"""Scale an array to integers between 0 and 255 to prep it for a PNG image. Args:; arr: numpy array. Input array made up of integers or floats.; vmin: number. Minimum data value to map to 0. Values below this will be; clamped to this value and therefore become 0.; vmax: number. Maximum data value to map to 255. Values above this will be; clamped to this value and therefore become 255. Returns:; numpy array of dtype np.uint8 (integers between 0 and 255).; """"""; # Careful not to modify the original array; # Snap numbers in the array falling outside the range into the range,; # otherwise they will produce artifacts due to byte overflow; # Scale the input into the range of vmin to vmax; """"""Find image type based on ",MatchSource.CODE_COMMENT,third_party/nucleus/util/vis.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/vis.py
Integrability,depend,dependency,".; """"""; # Get max value of each row, aka each read.; """"""Gets fraction of reads that support the variant. Args:; channels: A list of channels of a DeepVariant pileup image. This only uses; channels[4], the 'read supports variant' channel. Returns:; Fraction of reads supporting the alternate allele(s), ranging from [0, 1].; """"""; """"""Calculates read support and describes it categorically. Computes read support as a fraction and returns a convenient descriptive term; according to the following thresholds: LOW is [0, 0.3], HALF is (0.3, 0.8],; and ALL is (0.8, 1]. Args:; channels: A list of channels of a DeepVariant pileup image. This only uses; channels[4], the 'read supports variant' channel. Returns:; A ReadSupport value.; """"""; """"""Calculates a two-tailed binomial test with p=0.5, without scipy. Since the expected probability is 0.5, it simplifies a few things:; 1) (0.5**x)*(0.5**(n-x)) = (0.5**n); 2) A two-tailed test is simply doubling when p = 0.5.; Scipy is much larger than Nucleus, so this avoids adding it as a dependency. Args:; k: Number of ""successes"", in this case, the number of supporting reads.; n: Number of ""trials"", in this case, the total number of reads. Returns:; The p-value for the binomial test.; """"""; # With p=0.5, the distribution is symmetric, allowing this simplification:; # Add up all the exact probabilities for each scenario more extreme than k.; # After python 3.8, the following line can be replaced using math.comb.; # Doubling because it's a two-tailed test.; """"""Calculates a rough p-value for strand bias in pileup. Using the strand and read-supports-variant channels, compares the numbers of; forward and reverse reads among the supporting reads and returns a p-value; using a two-tailed binomial test. Args:; channels: List of DeepVariant channels. Uses channels[3] (strand) and; channels[4] (read support). Returns:; P-value for whether the supporting reads show strand bias.; """"""; """"""Analyzes which differences belong to nearby variants and which do ",MatchSource.CODE_COMMENT,third_party/nucleus/util/vis.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/vis.py
Modifiability,adapt,adapt,"gers between 0 and 255 to prep it for a PNG image. Args:; arr: numpy array. Input array made up of integers or floats.; vmin: number. Minimum data value to map to 0. Values below this will be; clamped to this value and therefore become 0.; vmax: number. Maximum data value to map to 255. Values above this will be; clamped to this value and therefore become 255. Returns:; numpy array of dtype np.uint8 (integers between 0 and 255).; """"""; # Careful not to modify the original array; # Snap numbers in the array falling outside the range into the range,; # otherwise they will produce artifacts due to byte overflow; # Scale the input into the range of vmin to vmax; """"""Find image type based on array dimensions. Raises error on invalid image dimensions.; Args:; arr: numpy array. Input array. Returns:; str. ""RGB"" or ""L"", meant for PIL.Image.fromarray.; """"""; # 8-bit x 3 colors; # 8-bit, gray-scale; """"""Adjust an array to prepare it for saving to an image. Re-scale numbers in the input array to go from 0 to 255 to adapt them for a; PNG image. Args:; arr: numpy array. Should be 2-dimensional or 3-dimensional where the third; dimension has 3 channels.; vmin: number (float or int). Minimum data value, which will correspond to; black in greyscale or lack of each color in RGB images. Default None takes; the minimum of the data from arr.; vmax: number (float or int). Maximum data value, which will correspond to; white in greyscale or full presence of each color in RGB images. Default; None takes the max of the data from arr. Returns:; (modified numpy array, image_mode); """"""; # In cases where all elements are the same, fix the vmax so that even though; # the whole image will be black, the user can at least see the shape; """"""Adds labels to the image, evenly distributed across the top. This is primarily useful for showing the names of channels. Args:; img: A PIL Image.; labels: list of strs. Labels for segments to write across the top.; mark_midpoints: bool. Whether to add a small vertica",MatchSource.CODE_COMMENT,third_party/nucleus/util/vis.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/vis.py
Safety,avoid,avoids,".; """"""; # Get max value of each row, aka each read.; """"""Gets fraction of reads that support the variant. Args:; channels: A list of channels of a DeepVariant pileup image. This only uses; channels[4], the 'read supports variant' channel. Returns:; Fraction of reads supporting the alternate allele(s), ranging from [0, 1].; """"""; """"""Calculates read support and describes it categorically. Computes read support as a fraction and returns a convenient descriptive term; according to the following thresholds: LOW is [0, 0.3], HALF is (0.3, 0.8],; and ALL is (0.8, 1]. Args:; channels: A list of channels of a DeepVariant pileup image. This only uses; channels[4], the 'read supports variant' channel. Returns:; A ReadSupport value.; """"""; """"""Calculates a two-tailed binomial test with p=0.5, without scipy. Since the expected probability is 0.5, it simplifies a few things:; 1) (0.5**x)*(0.5**(n-x)) = (0.5**n); 2) A two-tailed test is simply doubling when p = 0.5.; Scipy is much larger than Nucleus, so this avoids adding it as a dependency. Args:; k: Number of ""successes"", in this case, the number of supporting reads.; n: Number of ""trials"", in this case, the total number of reads. Returns:; The p-value for the binomial test.; """"""; # With p=0.5, the distribution is symmetric, allowing this simplification:; # Add up all the exact probabilities for each scenario more extreme than k.; # After python 3.8, the following line can be replaced using math.comb.; # Doubling because it's a two-tailed test.; """"""Calculates a rough p-value for strand bias in pileup. Using the strand and read-supports-variant channels, compares the numbers of; forward and reverse reads among the supporting reads and returns a p-value; using a two-tailed binomial test. Args:; channels: List of DeepVariant channels. Uses channels[3] (strand) and; channels[4] (read support). Returns:; P-value for whether the supporting reads show strand bias.; """"""; """"""Analyzes which differences belong to nearby variants and which do ",MatchSource.CODE_COMMENT,third_party/nucleus/util/vis.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/vis.py
Testability,test,test,"of channels of a DeepVariant pileup image. This only uses; channels[2], the mapping quality channel.; threshold: int. Default is 127 because this is half of the max (254). Returns:; The fraction of bases with mapping quality below the threshold.; """"""; # Get max value of each row, aka each read.; """"""Gets fraction of reads that support the variant. Args:; channels: A list of channels of a DeepVariant pileup image. This only uses; channels[4], the 'read supports variant' channel. Returns:; Fraction of reads supporting the alternate allele(s), ranging from [0, 1].; """"""; """"""Calculates read support and describes it categorically. Computes read support as a fraction and returns a convenient descriptive term; according to the following thresholds: LOW is [0, 0.3], HALF is (0.3, 0.8],; and ALL is (0.8, 1]. Args:; channels: A list of channels of a DeepVariant pileup image. This only uses; channels[4], the 'read supports variant' channel. Returns:; A ReadSupport value.; """"""; """"""Calculates a two-tailed binomial test with p=0.5, without scipy. Since the expected probability is 0.5, it simplifies a few things:; 1) (0.5**x)*(0.5**(n-x)) = (0.5**n); 2) A two-tailed test is simply doubling when p = 0.5.; Scipy is much larger than Nucleus, so this avoids adding it as a dependency. Args:; k: Number of ""successes"", in this case, the number of supporting reads.; n: Number of ""trials"", in this case, the total number of reads. Returns:; The p-value for the binomial test.; """"""; # With p=0.5, the distribution is symmetric, allowing this simplification:; # Add up all the exact probabilities for each scenario more extreme than k.; # After python 3.8, the following line can be replaced using math.comb.; # Doubling because it's a two-tailed test.; """"""Calculates a rough p-value for strand bias in pileup. Using the strand and read-supports-variant channels, compares the numbers of; forward and reverse reads among the supporting reads and returns a p-value; using a two-tailed binomial test. Args:; ",MatchSource.CODE_COMMENT,third_party/nucleus/util/vis.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/vis.py
Usability,simpl,simple,"y of dtype=np.uint8. Args:; arr: numpy array. Input array to save.; path: str. File path at which to save the image. A .png prefix is added if; the path does not already have one. Leave empty to save at /tmp/tmp.png,; which is useful when only temporarily showing the image in a Colab; notebook.; image_mode: ""RGB"" or ""L"". Leave as default=None to choose based on image; dimensions.; show: bool. Whether to display the image using IPython (for notebooks).; labels: list of str. Labels to show across the top of the image.; scale: integer. Number of pixels wide and tall to show each cell in the; array. This sizes up the image while keeping exactly the same number of; pixels for every cell in the array, preserving resolution and preventing; any interpolation or overlapping of pixels. Default None adapts to the; size of the image to multiply it up until a limit of 500 pixels, a; convenient size for use in notebooks. If saving to a file for automated; processing, scale=1 is recommended to keep output files small and simple; while still retaining all the information content. Returns:; None. Saves an image at path and optionally shows it with IPython.display.; """"""; # Saving to a temporary file is needed even when showing in a notebook; # Only PNG is supported because JPEG files are unnecessarily 3 times larger.; # Show image (great for notebooks); """"""Save an array as a PNG image with PIL and show it. Args:; arr: numpy array. Should be 2-dimensional or 3-dimensional where the third; dimension has 3 channels.; path: str. Path for the image output. Default is /tmp/tmp.png for quickly; showing the image in a notebook.; show: bool. Whether to show the image using IPython utilities, only works in; notebooks.; vmin: number. Minimum data value, which will correspond to black in; greyscale or lack of each color in RGB images. Default None takes the; minimum of the data from arr.; vmax: number. Maximum data value, which will correspond to white in; greyscale or full presence of each colo",MatchSource.CODE_COMMENT,third_party/nucleus/util/vis.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/vis.py
Availability,error,error,"ICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for third_party.nucleus.util.vis.""""""; # pylint: disable=g-direct-tensorflow-import; """"""Returns a bytes_list from a list of string / byte.""""""; """"""Returns a int64_list from a list of int / bool.""""""; # (height, width); # Top 5 rows and all other non-read space is left as 0.; # Like an actual pileup with 4 reads, each 8 bases long.; # One read with low value.; # Two bases of another read with low value.; # Test that it runs without error.; # Test that it runs without error.; # Original array should be unchanged.; # Output values have been scaled up and the array's data type changed.; # check the file doesn't already exist before function runs; # Check the file doesn't already exist before function runs.; # Since the ref band is all zero, the sum should stay the same.; # From scipy.stats.binom_test(x=1, n=6):; # For two-tailed, this must match the previous:; # Forward.; # Reverse.; # Supporting.; # Anything not 254 means not supporting.; # Not supporting.; # Supporting.; # All support: five forward, five reverse.; # Most not supporting.; # Two supporting from each strand.; # Most not supporting.; # One forward support.; # Five reverse support.; # Most not supporting.; # Five forward support.; # One reverse support.; # Five columns with homozygous variants:; # Less than five columns with homozygous variants:; # One read full of differences:; # No reads:; # Use the same pileup array for all of the channe",MatchSource.CODE_COMMENT,third_party/nucleus/util/vis_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/vis_test.py
Integrability,wrap,wrappers,"# Copyright 2018 Google LLC.; #; # Redistribution and use in source and binary forms, with or without; # modification, are permitted provided that the following conditions; # are met:; #; # 1. Redistributions of source code must retain the above copyright notice,; # this list of conditions and the following disclaimer.; #; # 2. Redistributions in binary form must reproduce the above copyright; # notice, this list of conditions and the following disclaimer in the; # documentation and/or other materials provided with the distribution.; #; # 3. Neither the name of the copyright holder nor the names of its; # contributors may be used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; """"""Tests for Math CLIF python wrappers.""""""",MatchSource.CODE_COMMENT,third_party/nucleus/util/python/math_wrap_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/python/math_wrap_test.py
Deployability,pipeline,pipeline,"e used to endorse or promote products derived from this; # software without specific prior written permission.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; # pylint: disable=line-too-long; # pylint: enable=line-too-long; """"""#; # --input_pattern_list={}; # --output_pattern_prefix={}; #; """"""; """"""Parse the commandline into known and pipeline arguments. The known arguments are required for this specific program to function,; and the other pipeline arguments can be used to configure beam and the; specific beam backend being used. See; https://github.com/apache/beam/blob/master/sdks/python/apache_beam/options/pipeline_options.py; for a list and description of the pipeline arguments accepted. Args:; argv: List containing command-line arguments. Returns:; A pair, the first of which are the known (non-pipeline) arguments; and the second of which are the pipeline arguments.; """"""; """"""Reads records from TFRecord files. Args:; pipeline: Beam pipeline object.; input_filename_pattern_list: List of filename patterns. Returns:; A PCollection of read tf.Examples.; """"""; """"""Shuffles the input_examples in a effectively random order.""""""; """"""Returns the sha1 hash of input_bytes.""""""; """"""Shuffles the input_examples in a effectively random order.""""""; """"""Retur",MatchSource.CODE_COMMENT,tools/shuffle_tfrecords_beam.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/tools/shuffle_tfrecords_beam.py
Modifiability,config,configure," IS""; # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE; # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE; # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE; # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF; # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS; # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN; # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE); # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; # pylint: disable=line-too-long; # pylint: enable=line-too-long; """"""#; # --input_pattern_list={}; # --output_pattern_prefix={}; #; """"""; """"""Parse the commandline into known and pipeline arguments. The known arguments are required for this specific program to function,; and the other pipeline arguments can be used to configure beam and the; specific beam backend being used. See; https://github.com/apache/beam/blob/master/sdks/python/apache_beam/options/pipeline_options.py; for a list and description of the pipeline arguments accepted. Args:; argv: List containing command-line arguments. Returns:; A pair, the first of which are the known (non-pipeline) arguments; and the second of which are the pipeline arguments.; """"""; """"""Reads records from TFRecord files. Args:; pipeline: Beam pipeline object.; input_filename_pattern_list: List of filename patterns. Returns:; A PCollection of read tf.Examples.; """"""; """"""Shuffles the input_examples in a effectively random order.""""""; """"""Returns the sha1 hash of input_bytes.""""""; """"""Shuffles the input_examples in a effectively random order.""""""; """"""Returns the label of input_example.""""""; """"""; name: ""{}""; tfrecord_path: ""{}-?????-of-?????.tfrecord.gz""; num_examples: {}; """"""; """"""Writes a file summarizing the PCollection of Examples. Args:; ",MatchSource.CODE_COMMENT,tools/shuffle_tfrecords_beam.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/tools/shuffle_tfrecords_beam.py
Security,hash,hash," IF ADVISED OF THE; # POSSIBILITY OF SUCH DAMAGE.; # pylint: disable=line-too-long; # pylint: enable=line-too-long; """"""#; # --input_pattern_list={}; # --output_pattern_prefix={}; #; """"""; """"""Parse the commandline into known and pipeline arguments. The known arguments are required for this specific program to function,; and the other pipeline arguments can be used to configure beam and the; specific beam backend being used. See; https://github.com/apache/beam/blob/master/sdks/python/apache_beam/options/pipeline_options.py; for a list and description of the pipeline arguments accepted. Args:; argv: List containing command-line arguments. Returns:; A pair, the first of which are the known (non-pipeline) arguments; and the second of which are the pipeline arguments.; """"""; """"""Reads records from TFRecord files. Args:; pipeline: Beam pipeline object.; input_filename_pattern_list: List of filename patterns. Returns:; A PCollection of read tf.Examples.; """"""; """"""Shuffles the input_examples in a effectively random order.""""""; """"""Returns the sha1 hash of input_bytes.""""""; """"""Shuffles the input_examples in a effectively random order.""""""; """"""Returns the label of input_example.""""""; """"""; name: ""{}""; tfrecord_path: ""{}-?????-of-?????.tfrecord.gz""; num_examples: {}; """"""; """"""Writes a file summarizing the PCollection of Examples. Args:; pipeline: Beam pipeline object.; output_examples: PCollection of examples.; input_pattern_list: str. A comma-separated string of input files.; dataset_name: str. The name of the dataset to be written in the output.; output_pattern_prefix: str. The prefix of the sharded output files.; output_filename: the output text file that contains the summary that can be; parsed into DeepVariantDatasetConfig.; """"""; # Beam currently has no way to materialize pipeline values, so we have; # to construct the file entirely in Beam pipeline operations.; """"""Main entry point; defines and runs the pipeline.""""""; # Copy over the example_info.json file before the pipeline starts.",MatchSource.CODE_COMMENT,tools/shuffle_tfrecords_beam.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/tools/shuffle_tfrecords_beam.py
